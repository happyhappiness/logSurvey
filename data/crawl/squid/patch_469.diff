@@ -32,6 +32,23 @@ Changes to squid-3.3.0.1 (21 Oct 2012):
 	- ... and many compile error fixes
 	- ... and a very large amount of code polish for faster compilation
 
+Changes to squid-3.2.7 (01 Feb 2013):
+
+	- Bug 3736: Floating point exception due to divide by zero
+	- Bug 3735: raw-IPv6 domain URLs crash if IPv6-disabled
+	- Bug 3732: Fix ConnOpener IPv6 awareness
+	- Bug 3729: 32-bit overflow in parsing 64-bit configuration values
+	- Bug 3728: Improve debug for cache_dir
+	- Bug 3687: unhandled exception: c when using interception and peers
+	- Bug 3678: external acl grace period causes acl lookup failures
+	- Bug 3567: Memory leak handling malformed requests
+	- Bug 3111: Mid-term fix for the forward.cc "err" assertion
+	- Support OpenSSL NO_Compression optio
+	- Fix IPv6 enabled pinger on split-stack or IPv6-disabled systems
+	- Fix "address.GetPort() != 0" assertion for helpers
+	- ... and several minor memory leaks
+	- ... and some cache.log message polishing
+
 Changes to squid-3.2.6 (09 Jan 2013):
 
 	- Regression Bug 3731: TOS setsockopt() requires int value
@@ -1,6 +1,6 @@
 <!doctype linuxdoc system>
 <article>
-<title>Squid 3.2.6 release notes</title>
+<title>Squid 3.2.7 release notes</title>
 <author>Squid Developers</author>
 
 <abstract>
@@ -13,10 +13,11 @@ for Applied Network Research and members of the Web Caching community.
 
 <sect>Notice
 <p>
-The Squid Team are pleased to announce the release of Squid-3.2.6 for 
+The Squid Team are pleased to announce the release of Squid-3.2.7 for 
 testing.
 
-This new release is available for download from <url url="http://www.squid-cache.org/Versions/v3/3.2/"> or the <url url="http://www.squid-cache.org/Mirrors/http-mirrors.html" name="mirrors">.
+This new release is available for download from <url url="http://www.squid-cache.org/Versions/v3/3.2/"> or the
+ <url url="http://www.squid-cache.org/Mirrors/http-mirrors.html" name="mirrors">.
 
 While this release is not deemed ready for production use, we believe it is ready for wider testing by the community.
 
@@ -25,7 +26,8 @@ report with a stack trace.
 
 <sect1>Known issues
 <p>
-Although this release is deemed good enough for use in many setups, please note the existence of <url url="http://bugs.squid-cache.org/buglist.cgi?query_format=advanced&amp;short_desc_type=allwordssubstr&amp;short_desc=&amp;target_milestone=3.2&amp;long_desc_type=allwordssubstr&amp;long_desc=&amp;bug_file_loc_type=allwordssubstr&amp;bug_file_loc=&amp;status_whiteboard_type=allwordssubstr&amp;status_whiteboard=&amp;bug_status=NEW&amp;bug_status=ASSIGNED&amp;bug_status=REOPENED&amp;emailtype1=substring&amp;email1=&amp;emailtype2=substring&amp;email2=&amp;bugidtype=include&amp;bug_id=&amp;votes=&amp;chfieldfrom=&amp;chfieldto=Now&amp;chfieldvalue=&amp;cmdtype=doit&amp;order=bugs.bug_severity&amp;field0-0-0=noop&amp;type0-0-0=noop&amp;value0-0-0=" name="open bugs against Squid-3.2">.
+Although this release is deemed good enough for use in many setups, please note the existence of 
+<url url="http://bugs.squid-cache.org/buglist.cgi?query_format=advanced&product=Squid&bug_status=UNCONFIRMED&bug_status=NEW&bug_status=ASSIGNED&bug_status=REOPENED&version=3.2" name="open bugs against Squid-3.2">.
 
 <p>Some issues to note as currently known in this release which are not able to be fixed in the 3.2 series are:
 
@@ -90,7 +92,7 @@ Most user-facing changes are reflected in squid.conf (see below).
   DNS lookups to locate alternative DIRECT destinations will not be done.
 
 <p>Known Issue: When non-strict validation fails Squid will relay the request, but can only do
-  so safely to the orginal destination IP the client was contacting. The client original
+  so safely to the original destination IP the client was contacting. The client original
   destination IP is lost when relaying to peers in a hierarchy. This means the upstream peers
   are still at risk of causing same-origin bypass CVE-2009-0801 vulnerability.
   Developer time is required to implement safe transit of these requests.
@@ -175,7 +177,7 @@ Most user-facing changes are reflected in squid.conf (see below).
    path and parameters as its own command parameters. The <em>concurrency</em> setting already
    existing in Squid is used to configure how many child helpers it may run.
 
-<p>For example, a traditional configration is
+<p>For example, a traditional configuration is
    <verb>
 	url_rewrite_program /your/redirector.sh
 	url_rewrite_children 5
@@ -204,10 +206,10 @@ Most user-facing changes are reflected in squid.conf (see below).
 <p>The on-demand helpers feature allows greater flexibility and resolves this problem by allowing
   maximum, initial and idle thresholds to be configured. Squid will start the initial set during
   start and reconfigure phases. However over the operational use new helpers up to the maxium will
-  be started as load demands. The idle threshold determins how many more helpers to start if the
+  be started as load demands. The idle threshold determines how many more helpers to start if the
   currently running set is not enough to handle current request loads.
 
-<p>For example, a traditional configration is
+<p>For example, a traditional configuration is
    <verb>
 	auth_param ntlm /usr/libexec/squid/ntlm_auth
 	auth_param ntlm children 200
@@ -258,7 +260,7 @@ Most user-facing changes are reflected in squid.conf (see below).
 <sect2>External ACL helpers
 <p><itemize>
 	<item>mswin_check_ad_group - ext_ad_group_acl - Check logged in users Group membership using Active Directory.
-	<item>ip_user_check - ext_file_userip_acl - Restrict users to cetain IP addresses, using a text file backend.
+	<item>ip_user_check - ext_file_userip_acl - Restrict users to certain IP addresses, using a text file backend.
 	<item>squid_kerb_ldap - ext_kerberos_ldap_group_acl - Check logged in Kerberos or NTLM users Group membership using LDAP.
 	<item>squid_ldap_group - ext_ldap_group_acl - Check logged in users Group membership using LDAP.
 	<item>mswin_check_lm_group - ext_lm_group_acl - Check logged in users Group membership using LanManager.
@@ -303,8 +305,8 @@ Most user-facing changes are reflected in squid.conf (see below).
 <sect1>Solaris 10 pthreads Support (Experimental)
 <p>Automatic detection and use of the pthreads library available from Solaris 10
 
-<p>The result of this addition means that faster more efficient AUFS cache storage mechanisims
-  are now available in Solaris 10.
+<p>The result of this addition means that faster more efficient AUFS cache storage mechanism
+  is now available in Solaris 10.
 
 <p>Support is experimental at this stage due to lack of feedback on the results of enabling it.
   We recommend giving AUFS a try for faster disk storage and encourage feedback.
@@ -316,14 +318,14 @@ Most user-facing changes are reflected in squid.conf (see below).
   feature support in Squid. This release opens Surrogate support to all reverse proxies.
 
 <p>Reverse proxy requests sent on to the web server include the HTTP header <em>Surrogate-Capabilities:</em>
-  specifying the capabilities of the reverse proxy along with an ID which can be used to target reponses with
+  specifying the capabilities of the reverse proxy along with an ID which can be used to target responses with
   a <em>Surrogate-Control:</em> HTTP header used instead of the <em>Cache-Control:</em> header.
 
 <p>The default surrogate ID is generated automatically from the Squid site-unique hostname as found by the
   automatic detection or manual configuration of <em>visible_hostname</em> although can be configured
   separately with the <em>httpd_accel_surrogate_id</em> option.
 
-<p><em>Security Considerations:</em> Websites sould be careful of accepting any surrogate ID.
+<p><em>Security Considerations:</em> Websites should be careful of accepting any surrogate ID.
   Older releases of Squid leak the Surrogate-Control headers to external servers.
   This 3.2 series of Squid will now prevent this leakage of its own ID destined responses, however it is possible
   and for some uses desirable to receive external reverse-proxies <em>Surrogate-Capabilities:</em> headers.
@@ -429,7 +431,7 @@ Most user-facing changes are reflected in squid.conf (see below).
 <itemize>
    <item>should contain a complete HTML page, with optional client-side scripting.
    <item>must not contain server-side scripting. 
-   <item>will have macro substitution performed on it using the same macros as used by the error page tempates.
+   <item>will have macro substitution performed on it using the same macros as used by the error page templates.
 </itemize>
 
 <p>Version 3.2 of the CGI cache manager tool now presents XHR scripted probes to detect
@@ -458,32 +460,32 @@ This section gives a thorough account of those changes in three categories:
 	   headers or eCAP options to Squid ICAP requests or eCAP transactions.
 
 	<tag>adaptation_send_client_ip</tag>
-	<p>Same as depricated icap_send_client_ip
+	<p>Same as deprecated icap_send_client_ip
 	   but applies to both ICAP and eCAP.</p>
 
 	<tag>adaptation_send_username</tag>
-	<p>Same as depricated icap_send_client_username
+	<p>Same as deprecated icap_send_client_username
 	   but applies to both ICAP and eCAP.</p>
 
 	<tag>adaptation_uses_indirect_client</tag>
-	<p>Same as depricated icap_uses_indirect_client
+	<p>Same as deprecated icap_uses_indirect_client
 	   but applies to both ICAP and eCAP.</p>
 
 	<tag>client_delay_pools</tag>
-	<p>New setting for client bandwith limits to specifies the number 
+	<p>New setting for client bandwidth limits to specifies the number 
 	  of client delay pools used.
 
 	<tag>client_delay_initial_bucket_level</tag>
-	<p>New setting for client bandwith limits to determine the initial 
+	<p>New setting for client bandwidth limits to determine the initial 
 	  bucket size as a percentage of  max_bucket_size from 
 	  client_delay_parameters.
             
 	<tag>client_delay_parameters</tag>
-	<p>New setting for client bandwith limits to configures client-side 
+	<p>New setting for client bandwidth limits to configures client-side 
 	   bandwidth limits.
 
 	<tag>client_delay_access</tag>
-	<p>New setting for client bandwith limits to determines the 
+	<p>New setting for client bandwidth limits to determines the 
 	  client-side delay pool for the request.
 
 	<tag>client_dst_passthru</tag>
@@ -590,8 +592,8 @@ This section gives a thorough account of those changes in three categories:
 	New installs, or installs with no logs configured explicitly will use this module by default.
 	<p>New <em>tcp</em> module to send each log line as text data to a TCP receiver.
 	<p>New <em>udp</em> module to send each log line as text data to a UDP receiver.
-	<p>New format <em>referrer</em> to log with the format prevously used by referer_log directive.
-	<p>New format <em>useragent</em> to log with the format prevously used by useragent_log directive.
+	<p>New format <em>referrer</em> to log with the format previously used by referer_log directive.
+	<p>New format <em>useragent</em> to log with the format previously used by useragent_log directive.
 
 	<tag>acl : random, localip, localport</tag>
 	<p>New type <em>random</em>. Pseudo-randomly match requests based on a configured probability.
@@ -610,7 +612,7 @@ This section gives a thorough account of those changes in three categories:
 
 	<tag>auth_param</tag>
 	<p>New options for Basic, Digest, NTLM, Negotiate <em>children</em> settings.
-	   <em>startup=N</em> determins minimum number of helper processes used.
+	   <em>startup=N</em> determines minimum number of helper processes used.
 	   <em>idle=N</em> determines how many helper to retain as buffer against sudden traffic loads.
 	   <em>concurrency=N</em> previously called <em>auth_param ... concurrency</em> as a separate option.
 	<p>Removed Basic, Digest, NTLM, Negotiate <em>auth_param ... concurrency</em> setting option.
@@ -644,8 +646,8 @@ This section gives a thorough account of those changes in three categories:
 	<p><em>%SRCEUI64</em> EUI-64 of clients with SLAAC address.
 	<p><em>%EXT_LOG</em> log= message returned by previous external ACL calls. An updated version may be returned.
 	<p><em>%EXT_TAG</em> tag= value returned by previous external ACL calls. Tag may not be altered once set.
-	<p><em>children-max=N</em> determins maximum number of helper processes used.
-	<p><em>children-startup=N</em> determins minimum number of helper processes used.
+	<p><em>children-max=N</em> determines maximum number of helper processes used.
+	<p><em>children-startup=N</em> determines minimum number of helper processes used.
 	<p><em>children-idle=N</em> determines how many helper to retain as buffer against sudden traffic loads.
 	<p>Deprecated <em>children=N</em> in favor of <em>children-max=N</em>.
 
@@ -939,6 +941,12 @@ This section gives an account of those changes in three categories:
 	<tag>server_http11</tag>
 	<p>Obsolete.
 
+        <tag>update_headers</tag>
+	<p>Obsolete. The experimental actions enabled in 2.7 by this option have been integrated as default
+	   actions for the <em>rock</em> storage type and memory caches.
+	   The configuration option is no longer necessary and has been dropped.
+	   NOTE: It is not yet supported by <em>ufs</em>, <em>aufs</em>, or <em>diskd</em> storage.
+
 	<tag>upgrade_http0.9</tag>
 	<p>Obsolete.
 
@@ -1110,8 +1118,5 @@ This section gives an account of those changes in three categories:
 	<tag>storeurl_rewrite_program</tag>
 	<p>Not yet ported from 2.7
 	
-	<tag>update_headers</tag>
-	<p>Not yet fully ported from 2.7. Memory and rock storage caches support this natively. UFS caches do not support it.
-
 </descrip>
 </article>
@@ -15,15 +15,19 @@ for Applied Network Research and members of the Web Caching community.
 <p>
 The Squid Team are pleased to announce the release of Squid-3.3.0.3 for testing.
 
-This new release is available for download from <url url="http://www.squid-cache.org/Versions/v3/3.3/"> or the <url url="http://www.squid-cache.org/Mirrors/http-mirrors.html" name="mirrors">.
+This new release is available for download from <url url="http://www.squid-cache.org/Versions/v3/3.3/"> or the 
+<url url="http://www.squid-cache.org/Mirrors/http-mirrors.html" name="mirrors">.
 
 While this release is not deemed ready for production use, we believe it is ready for wider testing by the community.
 
-We welcome feedback and bug reports. If you find a bug, please see <url url="http://wiki.squid-cache.org/SquidFaq/TroubleShooting#head-7067fc0034ce967e67911becaabb8c95a34d576d"> for how to submit a report with a stack trace.
+We welcome feedback and bug reports. If you find a bug, please see <url url="http://wiki.squid-cache.org/SquidFaq/BugReporting">
+ for how to submit a report with a stack trace.
 
 <sect1>Known issues
 <p>
-Although this release is deemed good enough for use in many setups, please note the existence of <url url="http://www.squid-cache.org/bugs/buglist.cgi?query_format=advanced&amp;short_desc_type=allwordssubstr&amp;short_desc=&amp;target_milestone=3.3&amp;long_desc_type=allwordssubstr&amp;long_desc=&amp;bug_file_loc_type=allwordssubstr&amp;bug_file_loc=&amp;status_whiteboard_type=allwordssubstr&amp;status_whiteboard=&amp;bug_status=NEW&amp;bug_status=ASSIGNED&amp;bug_status=REOPENED&amp;emailtype1=substring&amp;email1=&amp;emailtype2=substring&amp;email2=&amp;bugidtype=include&amp;bug_id=&amp;votes=&amp;chfieldfrom=&amp;chfieldto=Now&amp;chfieldvalue=&amp;cmdtype=doit&amp;order=bugs.bug_severity&amp;field0-0-0=noop&amp;type0-0-0=noop&amp;value0-0-0=" name="open bugs against Squid-3.3">.
+Although this release is deemed good enough for use in many setups, please note the existence of 
+<url url="http://bugs.squid-cache.org/buglist.cgi?query_format=advanced&product=Squid&bug_status=UNCONFIRMED&bug_status=NEW&bug_status=ASSIGNED&bug_status=REOPENED&version=3.3" name="open bugs against Squid-3.3">.
+
 
 <sect1>Changes since earlier releases of Squid-3.3
 <p>
@@ -184,16 +188,15 @@ This section gives a thorough account of those changes in three categories:
 	<tag>sslproxy_cert_adapt</tag>
 	<p>New option to adapt certain properties of outgoing SSL certificates generated for use when bumping SSL to an upstream server.
 
-
 </descrip>
 
 <sect1>Changes to existing tags<label id="modifiedtags">
 <p>
 <descrip>
 	<tag>acl</tag>
-	<p><em>myport</em> and <em>myip</em>ACL types replaced with <em>localport</em> and <em>localip</em> respecitively.
+	<p><em>myport</em> and <em>myip</em>ACL types replaced with <em>localport</em> and <em>localip</em> respectively.
 	   To reflect that it matches the TCP connection details and not the squid.conf port.
-	   This matters when dealing with interecepted traffic, where the Squid receiving port differs from the TCP connection IP:port.
+	   This matters when dealing with intercepted traffic, where the Squid receiving port differs from the TCP connection IP:port.
 	   Always use <em>myportname</em> type to match the squid.conf port details.
 	<p>New default built-in ACLs for testing SSL certificate properties.
 	<p><em>ssl::certHasExpired</em>,
@@ -205,8 +208,8 @@ This section gives a thorough account of those changes in three categories:
 	<tag>logformat</tag>
 	<p>New token <em>%ssl::bump_mode</em> to log the SSL-bump mode type performed on a request.
 	  Logs values of: <em>-</em>, <em>none</em>, <em>client-first</em>, or <em>server-first</em>.
-	<p>New token of <em>%ssl::&gt;cert_subject</em> to log the Subject field of a SSL certficate received from the client.
-	<p>New token of <em>%ssl::&gt;cert_issuer</em> to log the Issuer field of a SSL certficate received from the client.
+	<p>New token of <em>%ssl::&gt;cert_subject</em> to log the Subject field of a SSL certificate received from the client.
+	<p>New token of <em>%ssl::&gt;cert_issuer</em> to log the Issuer field of a SSL certificate received from the client.
 
 	<tag>ssl_bump</tag>
 	<p>New action types <em>none</em>, <em>client-first</em>, <em>server-first</em>. The default is <em>none</em>.
@@ -220,7 +223,8 @@ This section gives a thorough account of those changes in three categories:
 <sect1>Removed tags<label id="removedtags">
 <p>
 <descrip>
-	<p><em>There are no removed squid.conf tags in Squid-3.3.</em>
+
+	<p><em>There are no removed squid.conf options in Squid-3.3.</em>
 
 </descrip>
 
@@ -349,9 +353,6 @@ This section gives an account of those changes in three categories:
 	<tag>storeurl_rewrite_program</tag>
 	<p>Not yet ported from 2.7
 	
-	<tag>update_headers</tag>
-	<p>Not yet ported from 2.7
-
 </descrip>
 
 </article>
@@ -15,15 +15,19 @@ for Applied Network Research and members of the Web Caching community.
 <p>
 The Squid Team are pleased to announce the release of Squid-3.4.0.0 for testing.
 
-This new release is available for download from <url url="http://www.squid-cache.org/Versions/v3/3.HEAD/"> or the <url url="http://www.squid-cache.org/Mirrors/http-mirrors.html" name="mirrors">.
+This new release is available for download from <url url="http://www.squid-cache.org/Versions/v3/3.HEAD/"> or the
+ <url url="http://www.squid-cache.org/Mirrors/http-mirrors.html" name="mirrors">.
 
 While this release is not deemed ready for production use, we believe it is ready for wider testing by the community.
 
-We welcome feedback and bug reports. If you find a bug, please see <url url="http://wiki.squid-cache.org/SquidFaq/TroubleShooting#head-7067fc0034ce967e67911becaabb8c95a34d576d"> for how to submit a report with a stack trace.
+We welcome feedback and bug reports. If you find a bug, please see <url url="http://wiki.squid-cache.org/SquidFaq/BugReporting">
+ for how to submit a report with a stack trace.
 
 <sect1>Known issues
 <p>
-Although this release is deemed good enough for use in many setups, please note the existence of <url url="http://www.squid-cache.org/bugs/buglist.cgi?query_format=advanced&amp;short_desc_type=allwordssubstr&amp;short_desc=&amp;target_milestone=3.4&amp;long_desc_type=allwordssubstr&amp;long_desc=&amp;bug_file_loc_type=allwordssubstr&amp;bug_file_loc=&amp;status_whiteboard_type=allwordssubstr&amp;status_whiteboard=&amp;bug_status=NEW&amp;bug_status=ASSIGNED&amp;bug_status=REOPENED&amp;emailtype1=substring&amp;email1=&amp;emailtype2=substring&amp;email2=&amp;bugidtype=include&amp;bug_id=&amp;votes=&amp;chfieldfrom=&amp;chfieldto=Now&amp;chfieldvalue=&amp;cmdtype=doit&amp;order=bugs.bug_severity&amp;field0-0-0=noop&amp;type0-0-0=noop&amp;value0-0-0=" name="open bugs against Squid-3.4">.
+Although this release is deemed good enough for use in many setups, please note the existence of 
+<url url="http://bugs.squid-cache.org/buglist.cgi?query_format=advanced&bug_status=UNCONFIRMED&bug_status=NEW&bug_status=ASSIGNED&bug_status=REOPENED&bug_status=RESOLVED&bug_status=VERIFIED&bug_status=CLOSED&version=3.4" name="open bugs against Squid-3.4">.
+
 
 <sect1>Changes since earlier releases of Squid-3.4
 <p>
@@ -147,7 +147,7 @@ while (<>) {
 
     $status = "ERR";
     $cid =~ s/%(..)/pack("H*", $1)/ge;
-    $uid =~ s/%(..)/pack("H*", $2)/ge;
+    $uid =~ s/%(..)/pack("H*", $1)/ge;
 
     print(stderr "Received: Channel=".$cid.", UID='".$uid."'\n") if ($debug);
 
@@ -79,6 +79,7 @@ RFCNB_Call(char *Called_Name, char *Calling_Name, char *Called_Address, int port
     con->errn = 0;              /* no error yet */
     con->timeout = 0;           /* no timeout   */
     con->redirects = 0;
+    con->redirect_list = con->last_addr = NULL;
 
     /* Resolve that name into an IP address */
 
@@ -208,6 +209,7 @@ RFCNB_Send(struct RFCNB_Con *Con_Handle, struct RFCNB_Pkt *udata, int Length)
 
         /* No need to change RFCNB_errno as it was done by put_pkt ...     */
 
+        RFCNB_Free_Pkt(pkt);
         return (RFCNBE_Bad);    /* Should be able to write that lot ... */
 
     }
@@ -256,7 +258,7 @@ RFCNB_Recv(void *con_Handle, struct RFCNB_Pkt *Data, int Length)
 #ifdef RFCNB_DEBUG
         fprintf(stderr, "Bad packet return in RFCNB_Recv... \n");
 #endif
-
+        RFCNB_Free_Pkt(pkt);
         return (RFCNBE_Bad);
 
     }
@@ -3,9 +3,10 @@
 #include "HttpReply.h"
 #include "HttpRequest.h"
 #include "SquidConfig.h"
-#include "ssl/support.h"
 
 #if USE_SSL
+#include "ssl/support.h"
+
 AccessLogEntry::SslDetails::SslDetails(): user(NULL), bumpMode(::Ssl::bumpEnd)
 {
 }
@@ -8,6 +8,7 @@
 #include "helper.h"
 #include "rfc1738.h"
 #include "SquidString.h"
+#include "Debug.h"
 
 HelperReply::HelperReply(char *buf, size_t len) :
         result(HelperReply::Unknown),
@@ -19,9 +20,11 @@ HelperReply::HelperReply(char *buf, size_t len) :
 void
 HelperReply::parse(char *buf, size_t len)
 {
+    debugs(84, 3, "Parsing helper buffer");
     // check we have something to parse
     if (!buf || len < 1) {
         // for now ensure that legacy handlers are not presented with NULL strings.
+        debugs(84, 3, "Reply length is smaller than 1 or none at all ");
         other_.init(1,1);
         other_.terminate();
         return;
@@ -33,15 +36,19 @@ HelperReply::parse(char *buf, size_t len)
     // URL-rewriter may return relative URLs or empty response for a large portion
     // of its replies.
     if (len >= 2) {
+        debugs(84, 3, "Buff length is larger than 2");
         // some helper formats (digest auth, URL-rewriter) just send a data string
         // we must also check for the ' ' character after the response token (if anything)
         if (!strncmp(p,"OK",2) && (len == 2 || p[2] == ' ')) {
+            debugs(84, 3, "helper Result = OK");
             result = HelperReply::Okay;
             p+=2;
         } else if (!strncmp(p,"ERR",3) && (len == 3 || p[3] == ' ')) {
+            debugs(84, 3, "helper Result = ERR");
             result = HelperReply::Error;
             p+=3;
         } else if (!strncmp(p,"BH",2) && (len == 2 || p[2] == ' ')) {
+            debugs(84, 3, "helper Result = BH");
             result = HelperReply::BrokenHelper;
             p+=2;
         } else if (!strncmp(p,"TT ",3)) {
@@ -197,22 +197,23 @@ HttpHdrSc::parse(const String * str)
             int ma;
             if (p && httpHeaderParseInt(p, &ma)) {
                 sct->maxAge(ma);
+
+                if ((p = strchr (p, '+'))) {
+                    int ms;
+                    ++p; //skip the + char
+                    if (httpHeaderParseInt(p, &ms)) {
+                        sct->maxStale(ms);
+                    } else {
+                        debugs(90, 2, "sc: invalid max-stale specs near '" << item << "'");
+                        sct->clearMaxStale();
+                        /* leave the max-age alone */
+                    }
+                }
             } else {
                 debugs(90, 2, "sc: invalid max-age specs near '" << item << "'");
                 sct->clearMaxAge();
             }
 
-            if ((p = strchr (p, '+'))) {
-                int ms;
-                ++p; //skip the + char
-                if (httpHeaderParseInt(p, &ms)) {
-                    sct->maxStale(ms);
-                } else {
-                    debugs(90, 2, "sc: invalid max-stale specs near '" << item << "'");
-                    sct->clearMaxStale();
-                    /* leave the max-age alone */
-                }
-            }
             break;
         }
 
@@ -191,6 +191,11 @@ GetPercentage(void)
     int p;
     char *token = strtok(NULL, w_space);
 
+    if (!token) {
+        debugs(0, DBG_PARSE_NOTE(DBG_IMPORTANT), "ERROR: A percentage value is missing.");
+        self_destruct();
+    }
+
     //if there is a % in the end of the digits, we remove it and go on.
     char* end = &token[strlen(token)-1];
     if (*end == '%') {
@@ -104,9 +104,9 @@ class PeerDigest
     const char *req_result;     /**< text status of the last request */
 
     struct {
-        unsigned int needed:1;          /**< there were requests for this digest */
-        unsigned int usable:1;          /**< can be used for lookups */
-        unsigned int requested:1;       /**< in process of receiving [fresh] digest */
+        bool needed;          /**< there were requests for this digest */
+        bool usable;          /**< can be used for lookups */
+        bool requested;       /**< in process of receiving [fresh] digest */
     } flags;
 
     struct {
@@ -41,18 +41,18 @@ class RefreshPattern
     RefreshPattern *next;
 
     struct {
-        unsigned int icase:1;
-        unsigned int refresh_ims:1;
-        unsigned int store_stale:1;
+        bool icase;
+        bool refresh_ims;
+        bool store_stale;
 #if USE_HTTP_VIOLATIONS
-        unsigned int override_expire:1;
-        unsigned int override_lastmod:1;
-        unsigned int reload_into_ims:1;
-        unsigned int ignore_reload:1;
-        unsigned int ignore_no_store:1;
-        unsigned int ignore_must_revalidate:1;
-        unsigned int ignore_private:1;
-        unsigned int ignore_auth:1;
+        bool override_expire;
+        bool override_lastmod;
+        bool reload_into_ims;
+        bool ignore_reload;
+        bool ignore_no_store;
+        bool ignore_must_revalidate;
+        bool ignore_private;
+        bool ignore_auth;
 #endif
     } flags;
     int max_stale;
@@ -238,7 +238,7 @@ SwapDir::getOptionTree() const
 void
 SwapDir::parseOptions(int isaReconfig)
 {
-    unsigned int old_read_only = flags.read_only;
+    const bool old_read_only = flags.read_only;
     char *name, *value;
 
     ConfigOption *newOption = getOptionTree();
@@ -290,12 +290,12 @@ SwapDir::optionReadOnlyParse(char const *option, const char *value, int isaRecon
     if (strcmp(option, "no-store") != 0 && strcmp(option, "read-only") != 0)
         return false;
 
-    int read_only = 0;
+    bool read_only = 0;
 
     if (value)
-        read_only = xatoi(value);
+        read_only = (xatoi(value) != 0);
     else
-        read_only = 1;
+        read_only = true;
 
     flags.read_only = read_only;
 
@@ -192,9 +192,9 @@ class SwapDir : public Store
     int scanned;
 
     struct Flags {
-        Flags() : selected(0), read_only(0) {}
-        unsigned int selected:1;
-        unsigned int read_only:1;
+        Flags() : selected(false), read_only(false) {}
+        bool selected;
+        bool read_only;
     } flags;
     virtual void init() = 0;	/* Initialise the fs */
     virtual void create();	/* Create a new fs */
@@ -104,7 +104,7 @@ class ACL
     static ACL* FindByName(const char *name);
 
     ACL();
-    explicit ACL(const ACLFlag flgs[]) : cfgline(NULL), flags(flgs) {}
+    explicit ACL(const ACLFlag flgs[]) : cfgline(NULL), next(NULL), flags(flgs) { memset(name, '\0', sizeof(name)); }
     virtual ~ACL();
     virtual ACL *clone()const = 0;
     virtual void parse() = 0;
@@ -114,7 +114,7 @@ DestinationIPLookup::LookupDone(const ipcache_addrs *, const DnsLookupDetails &d
 {
     ACLFilledChecklist *checklist = Filled((ACLChecklist*)data);
     assert (checklist->asyncState() == DestinationIPLookup::Instance());
-    checklist->request->flags.destinationIpLookedUp=true;
+    checklist->request->flags.destinationIpLookedUp = true;
     checklist->request->recordLookup(details);
     checklist->asyncInProgress(false);
     checklist->changeState (ACLChecklist::NullState::Instance());
@@ -266,7 +266,7 @@ Auth::Negotiate::UserRequest::HandleReply(void *data, const HelperReply &reply)
     case HelperReply::TT:
         /* we have been given a blob to send to the client */
         safe_free(lm_request->server_blob);
-        lm_request->request->flags.mustKeepalive = 1;
+        lm_request->request->flags.mustKeepalive = true;
         if (lm_request->request->flags.proxyKeepalive) {
             Note::Pointer tokenNote = reply.notes.find("token");
             lm_request->server_blob = xstrdup(tokenNote->firstValue());
@@ -226,7 +226,7 @@ Auth::Negotiate::Config::fixHeader(Auth::UserRequest::Pointer auth_user_request,
         if (!keep_alive) {
             /* drop the connection */
             rep->header.delByName("keep-alive");
-            request->flags.proxyKeepalive = 0;
+            request->flags.proxyKeepalive = false;
         }
     } else {
         Auth::Negotiate::UserRequest *negotiate_request = dynamic_cast<Auth::Negotiate::UserRequest *>(auth_user_request.getRaw());
@@ -238,7 +238,7 @@ Auth::Negotiate::Config::fixHeader(Auth::UserRequest::Pointer auth_user_request,
             /* here it makes sense to drop the connection, as auth is
              * tied to it, even if MAYBE the client could handle it - Kinkie */
             rep->header.delByName("keep-alive");
-            request->flags.proxyKeepalive = 0;
+            request->flags.proxyKeepalive = false;
             /* fall through */
 
         case Auth::Ok:
@@ -259,7 +259,7 @@ Auth::Ntlm::UserRequest::HandleReply(void *data, const HelperReply &reply)
     case HelperReply::TT:
         /* we have been given a blob to send to the client */
         safe_free(lm_request->server_blob);
-        lm_request->request->flags.mustKeepalive = 1;
+        lm_request->request->flags.mustKeepalive = true;
         if (lm_request->request->flags.proxyKeepalive) {
             Note::Pointer serverBlob = reply.notes.find("token");
             lm_request->server_blob = xstrdup(serverBlob->firstValue());
@@ -215,7 +215,7 @@ Auth::Ntlm::Config::fixHeader(Auth::UserRequest::Pointer auth_user_request, Http
 
         if (!keep_alive) {
             /* drop the connection */
-            request->flags.proxyKeepalive = 0;
+            request->flags.proxyKeepalive = false;
         }
     } else {
         Auth::Ntlm::UserRequest *ntlm_request = dynamic_cast<Auth::Ntlm::UserRequest *>(auth_user_request.getRaw());
@@ -226,7 +226,7 @@ Auth::Ntlm::Config::fixHeader(Auth::UserRequest::Pointer auth_user_request, Http
         case Auth::Failed:
             /* here it makes sense to drop the connection, as auth is
              * tied to it, even if MAYBE the client could handle it - Kinkie */
-            request->flags.proxyKeepalive = 0;
+            request->flags.proxyKeepalive = false;
             /* fall through */
 
         case Auth::Ok:
@@ -2867,41 +2867,41 @@ parse_refreshpattern(RefreshPattern ** head)
     t->max = max;
 
     if (flags & REG_ICASE)
-        t->flags.icase = 1;
+        t->flags.icase = true;
 
     if (refresh_ims)
-        t->flags.refresh_ims = 1;
+        t->flags.refresh_ims = true;
 
     if (store_stale)
-        t->flags.store_stale = 1;
+        t->flags.store_stale = true;
 
     t->max_stale = max_stale;
 
 #if USE_HTTP_VIOLATIONS
 
     if (override_expire)
-        t->flags.override_expire = 1;
+        t->flags.override_expire = true;
 
     if (override_lastmod)
-        t->flags.override_lastmod = 1;
+        t->flags.override_lastmod = true;
 
     if (reload_into_ims)
-        t->flags.reload_into_ims = 1;
+        t->flags.reload_into_ims = true;
 
     if (ignore_reload)
-        t->flags.ignore_reload = 1;
+        t->flags.ignore_reload = true;
 
     if (ignore_no_store)
-        t->flags.ignore_no_store = 1;
+        t->flags.ignore_no_store = true;
 
     if (ignore_must_revalidate)
-        t->flags.ignore_must_revalidate = 1;
+        t->flags.ignore_must_revalidate = true;
 
     if (ignore_private)
-        t->flags.ignore_private = 1;
+        t->flags.ignore_private = true;
 
     if (ignore_auth)
-        t->flags.ignore_auth = 1;
+        t->flags.ignore_auth = true;
 
 #endif
 
@@ -104,6 +104,8 @@ COMMENT_START
 	across all Squid processes.
 COMMENT_END
 
+# no Options Removed in 3.3
+
 # Options Removed in 3.2
 NAME: ignore_expect_100
 TYPE: obsolete
@@ -114,7 +116,7 @@ DOC_END
 NAME: dns_v4_fallback
 TYPE: obsolete
 DOC_START
-	Remove this line.
+	Remove this line. Squid performs a 'Happy Eyeballs' algorithm, the 'fallback' algorithm is no longer relevant.
 DOC_END
 
 NAME: ftp_list_width
@@ -129,6 +131,12 @@ DOC_START
 	Replaced by connect_retries. The behaviour has changed, please read the documentation before altering.
 DOC_END
 
+NAME: update_headers
+TYPE: obsolete
+DOC_START
+	Remove this line. The feature is supported by default in storage types where update is implemented.
+DOC_END
+
 NAME: url_rewrite_concurrency
 TYPE: obsolete
 DOC_START
@@ -252,7 +260,7 @@ DOC_START
 		the user does not exist.
 
 	  BH
-		An internal error occured in the helper, preventing
+		An internal error occurred in the helper, preventing
 		a result being identified.
 
 	"ERR" and "BH" results may optionally be followed by message="..."
@@ -270,7 +278,7 @@ DOC_START
 	auth_param basic program @DEFAULT_PREFIX@/libexec/ncsa_auth @DEFAULT_PREFIX@/etc/passwd
 
 	"utf8" on|off
-	HTTP uses iso-latin-1 as characterset, while some authentication
+	HTTP uses iso-latin-1 as character set, while some authentication
 	backends such as LDAP expects UTF-8. If this is set to on Squid will
 	translate the HTTP iso-latin-1 charset to UTF-8 before sending the
 	username & password to the helper.
@@ -293,7 +301,7 @@ DOC_START
 	supports one request at a time. Setting this to a number greater than
 	0 changes the protocol used to include a channel number first on the
 	request/response line, allowing multiple requests to be sent to the
-	same helper in parallell without wating for the response.
+	same helper in parallel without waiting for the response.
 	Must not be set unless it's known the helper supports this.
 
 	auth_param basic children 20 startup=0 idle=1
@@ -339,7 +347,7 @@ DOC_START
 		the user does not exist.
 
 	  BH
-		An internal error occured in the helper, preventing
+		An internal error occurred in the helper, preventing
 		a result being identified.
 
 	"ERR" and "BH" results may optionally be followed by message="..."
@@ -354,7 +362,7 @@ DOC_START
 	auth_param digest program @DEFAULT_PREFIX@/bin/digest_pw_auth @DEFAULT_PREFIX@/etc/digpass
 
 	"utf8" on|off
-	HTTP uses iso-latin-1 as characterset, while some authentication
+	HTTP uses iso-latin-1 as character set, while some authentication
 	backends such as LDAP expects UTF-8. If this is set to on Squid will
 	translate the HTTP iso-latin-1 charset to UTF-8 before sending the
 	username & password to the helper.
@@ -377,7 +385,7 @@ DOC_START
 	supports one request at a time. Setting this to a number greater than
 	0 changes the protocol used to include a channel number first on the
 	request/response line, allowing multiple requests to be sent to the
-	same helper in parallell without wating for the response.
+	same helper in parallel without waiting for the response.
 	Must not be set unless it's known the helper supports this.
 
 	auth_param digest children 20 startup=0 idle=1
@@ -404,7 +412,7 @@ DOC_START
 	"nonce_strictness" on|off
 	Determines if squid requires strict increment-by-1 behavior
 	for nonce counts, or just incrementing (off - for use when
-	useragents generate nonce counts that occasionally miss 1
+	user agents generate nonce counts that occasionally miss 1
 	(ie, 1,2,4,6)). Default off.
 
 	"check_nonce_count" on|off
@@ -475,7 +483,7 @@ DOC_START
 	The maximum number of authenticator processes to spawn (default 5).
 	If you start too few Squid will have to wait for them to
 	process a backlog of credential verifications, slowing it
-	down. When crendential verifications are done via a (slow)
+	down. When credential verifications are done via a (slow)
 	network you are likely to need lots of authenticator
 	processes.
 
@@ -527,7 +535,7 @@ DEFAULT: 1 hour
 LOC: Config.authenticateGCInterval
 DOC_START
 	The time period between garbage collection across the username cache.
-	This is a tradeoff between memory utilization (long intervals - say
+	This is a trade-off between memory utilization (long intervals - say
 	2 days) and CPU (short intervals - say 1 minute). Only change if you
 	have good reason to.
 DOC_END
@@ -552,7 +560,7 @@ DOC_START
 	this directive controls how long Squid remembers the IP
 	addresses associated with each user.  Use a small value
 	(e.g., 60 seconds) if your users might change addresses
-	quickly, as is the case with dialups.   You might be safe
+	quickly, as is the case with dialup.   You might be safe
 	using a larger value (e.g., 2 hours) in a corporate LAN
 	environment with relatively static address assignments.
 DOC_END
@@ -689,7 +697,7 @@ DOC_START
 		the ACL test does not produce a match.
 
 	  BH
-		An internal error occured in the helper, preventing
+		An internal error occurred in the helper, preventing
 		a result being identified.
 
 	The meaning of 'a match' is determined by your squid.conf
@@ -4227,7 +4235,7 @@ DOC_START
 		Do not change the URL.
 
 	  BH
-		An internal error occured in the helper, preventing
+		An internal error occurred in the helper, preventing
 		a result being identified.
 
 
@@ -863,7 +863,7 @@ clientSetKeepaliveFlag(ClientHttpRequest * http)
            RequestMethodStr(request->method));
 
     // TODO: move to HttpRequest::hdrCacheInit, just like HttpReply.
-    request->flags.proxyKeepalive = request->persistent() ? 1 : 0;
+    request->flags.proxyKeepalive = request->persistent();
 }
 
 static int
@@ -2030,7 +2030,7 @@ prepareAcceleratedURL(ConnStateData * conn, ClientHttpRequest *http, char *url,
     char *host;
     char ipbuf[MAX_IPSTRLEN];
 
-    http->flags.accel = 1;
+    http->flags.accel = true;
 
     /* BUG: Squid cannot deal with '*' URLs (RFC2616 5.1.2) */
 
@@ -2317,7 +2317,7 @@ parseHttpRequest(ConnStateData *csd, HttpParser *hp, HttpRequestMethod * method_
         http->uri = xstrdup(internalLocalUri(NULL, url));
         // We just re-wrote the URL. Must replace the Host: header.
         //  But have not parsed there yet!! flag for local-only handling.
-        http->flags.internal = 1;
+        http->flags.internal = true;
 
     } else if (csd->port->flags.accelSurrogate || csd->switchedToHttps()) {
         /* accelerator mode */
@@ -2490,7 +2490,7 @@ ConnStateData::quitAfterError(HttpRequest *request)
     // at the client-side, but many such errors do require closure and the
     // client-side code is bad at handling errors so we play it safe.
     if (request)
-        request->flags.proxyKeepalive = 0;
+        request->flags.proxyKeepalive = false;
     flags.readMore = false;
     debugs(33,4, HERE << "Will close after error: " << clientConnection);
 }
@@ -2693,11 +2693,11 @@ clientProcessRequest(ConnStateData *conn, HttpParser *hp, ClientSocketContext *c
     if (internalCheck(request->urlpath.termedBuf())) {
         if (internalHostnameIs(request->GetHost()) &&
                 request->port == getMyPort()) {
-            http->flags.internal = 1;
+            http->flags.internal = true;
         } else if (Config.onoff.global_internal_static && internalStaticCheck(request->urlpath.termedBuf())) {
             request->SetHost(internalHostname());
             request->port = getMyPort();
-            http->flags.internal = 1;
+            http->flags.internal = true;
         }
     }
 
@@ -2985,7 +2985,7 @@ ConnStateData::clientReadRequest(const CommIoCbParams &io)
             }
 
             /* It might be half-closed, we can't tell */
-            fd_table[io.conn->fd].flags.socket_eof = 1;
+            fd_table[io.conn->fd].flags.socket_eof = true;
 
             commMarkHalfClosed(io.conn->fd);
 
@@ -3932,7 +3932,7 @@ ConnStateData::switchToHttps(HttpRequest *request, Ssl::BumpMode bumpServerMode)
     // and now want to switch to SSL to send the error to the client
     // without even peeking at the origin server certificate.
     if (bumpServerMode == Ssl::bumpServerFirst && !sslServerBump) {
-        request->flags.sslPeek = 1;
+        request->flags.sslPeek = true;
         sslServerBump = new Ssl::ServerBump(request);
 
         // will call httpsPeeked() with certificate and connection, eventually
@@ -129,7 +129,7 @@ void clientReplyContext::setReplyToError(const HttpRequestMethod& method, ErrorS
 {
     if (errstate->httpStatus == HTTP_NOT_IMPLEMENTED && http->request)
         /* prevent confusion over whether we default to persistent or not */
-        http->request->flags.proxyKeepalive = 0;
+        http->request->flags.proxyKeepalive = false;
 
     http->al->http.code = errstate->httpStatus;
 
@@ -273,7 +273,7 @@ clientReplyContext::processExpired()
         return;
     }
 
-    http->request->flags.refresh = 1;
+    http->request->flags.refresh = true;
 #if STORE_CLIENT_LIST_DEBUG
     /* Prevent a race with the store client memory free routines
      */
@@ -390,7 +390,7 @@ clientReplyContext::handleIMSReply(StoreIOBuffer result)
     // origin replied 304
     if (status == HTTP_NOT_MODIFIED) {
         http->logType = LOG_TCP_REFRESH_UNMODIFIED;
-        http->request->flags.staleIfHit = 0; // old_entry is no longer stale
+        http->request->flags.staleIfHit = false; // old_entry is no longer stale
 
         // update headers on existing entry
         old_rep->updateOnNotModified(http->storeEntry()->getReply());
@@ -558,7 +558,7 @@ clientReplyContext::cacheHit(StoreIOBuffer result)
          * request.  Otherwise two siblings could generate a loop if
          * both have a stale version of the object.
          */
-        r->flags.needValidation = 1;
+        r->flags.needValidation = true;
 
         if (e->lastmod < 0) {
             debugs(88, 3, "validate HIT object? NO. Missing Last-Modified header. Do MISS.");
@@ -734,7 +734,7 @@ clientReplyContext::processConditional(StoreIOBuffer &result)
     if (r.header.has(HDR_IF_NONE_MATCH)) {
         if (!e->hasIfNoneMatchEtag(r)) {
             // RFC 2616: ignore IMS if If-None-Match did not match
-            r.flags.ims = 0;
+            r.flags.ims = false;
             r.ims = -1;
             r.imslen = 0;
             r.header.delById(HDR_IF_MODIFIED_SINCE);
@@ -778,7 +778,7 @@ void
 clientReplyContext::purgeRequestFindObjectToPurge()
 {
     /* Try to find a base entry */
-    http->flags.purging = 1;
+    http->flags.purging = true;
     lookingforstore = 1;
 
     // TODO: can we use purgeAllCached() here instead of doing the
@@ -1407,7 +1407,7 @@ clientReplyContext::buildReplyHeader()
                         hdr->delAt(pos, connection_auth_blocked);
                         continue;
                     }
-                    request->flags.mustKeepalive = 1;
+                    request->flags.mustKeepalive = true;
                     if (!request->flags.accelerated && !request->flags.intercepted) {
                         httpHeaderPutStrf(hdr, HDR_PROXY_SUPPORT, "Session-Based-Authentication");
                         /*
@@ -1463,38 +1463,38 @@ clientReplyContext::buildReplyHeader()
     /* Check whether we should send keep-alive */
     if (!Config.onoff.error_pconns && reply->sline.status >= 400 && !request->flags.mustKeepalive) {
         debugs(33, 3, "clientBuildReplyHeader: Error, don't keep-alive");
-        request->flags.proxyKeepalive = 0;
+        request->flags.proxyKeepalive = false;
     } else if (!Config.onoff.client_pconns && !request->flags.mustKeepalive) {
         debugs(33, 2, "clientBuildReplyHeader: Connection Keep-Alive not requested by admin or client");
-        request->flags.proxyKeepalive = 0;
+        request->flags.proxyKeepalive = false;
     } else if (request->flags.proxyKeepalive && shutting_down) {
         debugs(88, 3, "clientBuildReplyHeader: Shutting down, don't keep-alive.");
-        request->flags.proxyKeepalive = 0;
+        request->flags.proxyKeepalive = false;
     } else if (request->flags.connectionAuth && !reply->keep_alive) {
         debugs(33, 2, "clientBuildReplyHeader: Connection oriented auth but server side non-persistent");
-        request->flags.proxyKeepalive = 0;
+        request->flags.proxyKeepalive = false;
     } else if (reply->bodySize(request->method) < 0 && !maySendChunkedReply) {
         debugs(88, 3, "clientBuildReplyHeader: can't keep-alive, unknown body size" );
-        request->flags.proxyKeepalive = 0;
+        request->flags.proxyKeepalive = false;
     } else if (fdUsageHigh()&& !request->flags.mustKeepalive) {
         debugs(88, 3, "clientBuildReplyHeader: Not many unused FDs, can't keep-alive");
-        request->flags.proxyKeepalive = 0;
+        request->flags.proxyKeepalive = false;
     } else if (request->flags.sslBumped && !reply->persistent()) {
         // We do not really have to close, but we pretend we are a tunnel.
         debugs(88, 3, "clientBuildReplyHeader: bumped reply forces close");
-        request->flags.proxyKeepalive = 0;
+        request->flags.proxyKeepalive = false;
     } else if (request->pinnedConnection() && !reply->persistent()) {
         // The peer wants to close the pinned connection
         debugs(88, 3, "pinned reply forces close");
-        request->flags.proxyKeepalive = 0;
+        request->flags.proxyKeepalive = false;
     }
 
     // Decide if we send chunked reply
     if (maySendChunkedReply &&
             request->flags.proxyKeepalive &&
             reply->bodySize(request->method) < 0) {
         debugs(88, 3, "clientBuildReplyHeader: chunked reply");
-        request->flags.chunkedReply = 1;
+        request->flags.chunkedReply = true;
         hdr->putStr(HDR_TRANSFER_ENCODING, "chunked");
     }
 
@@ -1824,7 +1824,7 @@ clientReplyContext::sendStreamError(StoreIOBuffer const &result)
     debugs(88, 5, "clientReplyContext::sendStreamError: A stream error has occured, marking as complete and sending no data.");
     StoreIOBuffer localTempBuffer;
     flags.complete = 1;
-    http->request->flags.streamError = 1;
+    http->request->flags.streamError = true;
     localTempBuffer.flags.error = result.flags.error;
     clientStreamCallback((clientStreamNode*)http->client_stream.head->data, http, NULL,
                          localTempBuffer);
@@ -2026,7 +2026,7 @@ clientReplyContext::processReplyAccessResult(const allow_t &accessAllowed)
     if (http->request->method == Http::METHOD_HEAD) {
         /* do not forward body for HEAD replies */
         body_size = 0;
-        http->flags.done_copying = 1;
+        http->flags.done_copying = true;
         flags.complete = 1;
     }
 
@@ -364,7 +364,7 @@ clientBeginRequest(const HttpRequestMethod& method, char const *url, CSCB * stre
     /* Set flags */
     /* internal requests only makes sense in an
      * accelerator today. TODO: accept flags ? */
-    http->flags.accel = 1;
+    http->flags.accel = true;
     /* allow size for url rewriting */
     url_sz = strlen(url) + Config.appendDomainLen + 5;
     http->uri = (char *)xcalloc(url_sz, 1);
@@ -392,7 +392,7 @@ clientBeginRequest(const HttpRequestMethod& method, char const *url, CSCB * stre
      */
     request->flags.accelerated = http->flags.accel;
 
-    request->flags.internalClient = 1;
+    request->flags.internalClient = true;
 
     /* this is an internally created
      * request, not subject to acceleration
@@ -537,7 +537,7 @@ clientFollowXForwardedForCheck(allow_t answer, void *data)
         conn->log_addr = request->indirect_client_addr;
     }
     request->x_forwarded_for_iterator.clean();
-    request->flags.done_follow_x_forwarded_for=true;
+    request->flags.done_follow_x_forwarded_for = true;
 
     if (answer != ACCESS_ALLOWED && answer != ACCESS_DENIED) {
         debugs(28, DBG_CRITICAL, "ERROR: Processing X-Forwarded-For. Stopping at IP address: " << request->indirect_client_addr );
@@ -568,7 +568,7 @@ ClientRequestContext::hostHeaderIpVerify(const ipcache_addrs* ia, const DnsLooku
         for (int i = 0; i < ia->count; ++i) {
             if (clientConn->local.matchIPAddr(ia->in_addrs[i]) == 0) {
                 debugs(85, 3, HERE << "validate IP " << clientConn->local << " possible from Host:");
-                http->request->flags.hostVerified = 1;
+                http->request->flags.hostVerified = true;
                 http->doCallouts();
                 return;
             }
@@ -590,9 +590,9 @@ ClientRequestContext::hostHeaderVerifyFailed(const char *A, const char *B)
 
         // NP: it is tempting to use 'flags.noCache' but that is all about READing cache data.
         // The problems here are about WRITE for new cache content, which means flags.cachable
-        http->request->flags.cachable = 0; // MUST NOT cache (for now)
+        http->request->flags.cachable = false; // MUST NOT cache (for now)
         // XXX: when we have updated the cache key to base on raw-IP + URI this cacheable limit can go.
-        http->request->flags.hierarchical = 0; // MUST NOT pass to peers (for now)
+        http->request->flags.hierarchical = false; // MUST NOT pass to peers (for now)
         // XXX: when we have sorted out the best way to relay requests properly to peers this hierarchical limit can go.
         http->doCallouts();
         return;
@@ -702,7 +702,7 @@ ClientRequestContext::hostHeaderVerify()
     } else {
         // Okay no problem.
         debugs(85, 3, HERE << "validate passed.");
-        http->request->flags.hostVerified = 1;
+        http->request->flags.hostVerified = true;
         http->doCallouts();
     }
     safe_free(hostB);
@@ -990,10 +990,10 @@ clientCheckPinning(ClientHttpRequest * http)
     if (!request->flags.connectionAuthDisabled) {
         if (Comm::IsConnOpen(http_conn->pinning.serverConnection)) {
             if (http_conn->pinning.auth) {
-                request->flags.connectionAuth = 1;
-                request->flags.auth = 1;
+                request->flags.connectionAuth = true;
+                request->flags.auth = true;
             } else {
-                request->flags.connectionProxyAuth = 1;
+                request->flags.connectionProxyAuth = true;
             }
             // These should already be linked correctly.
             assert(request->clientConnectionManager == http_conn);
@@ -1019,10 +1019,10 @@ clientCheckPinning(ClientHttpRequest * http)
                             ||
                             strncasecmp(value, "Kerberos ", 9) == 0) {
                         if (e->id == HDR_AUTHORIZATION) {
-                            request->flags.connectionAuth = 1;
+                            request->flags.connectionAuth = true;
                             may_pin = 1;
                         } else {
-                            request->flags.connectionProxyAuth = 1;
+                            request->flags.connectionProxyAuth = true;
                             may_pin = 1;
                         }
                     }
@@ -1048,7 +1048,7 @@ clientInterpretRequestHeaders(ClientHttpRequest * http)
     request->ims = req_hdr->getTime(HDR_IF_MODIFIED_SINCE);
 
     if (request->ims > 0)
-        request->flags.ims = 1;
+        request->flags.ims = true;
 
     if (!request->flags.ignoreCc) {
         if (request->cache_control) {
@@ -1090,13 +1090,13 @@ clientInterpretRequestHeaders(ClientHttpRequest * http)
 #if USE_HTTP_VIOLATIONS
 
         if (Config.onoff.reload_into_ims)
-            request->flags.nocacheHack = 1;
+            request->flags.nocacheHack = true;
         else if (refresh_nocache_hack)
-            request->flags.nocacheHack = 1;
+            request->flags.nocacheHack = true;
         else
 #endif
 
-            request->flags.noCache = 1;
+            request->flags.noCache = true;
     }
 
     /* ignore range header in non-GETs or non-HEADs */
@@ -1106,7 +1106,7 @@ clientInterpretRequestHeaders(ClientHttpRequest * http)
             request->range = req_hdr->getRange();
 
         if (request->range) {
-            request->flags.isRanged=true;
+            request->flags.isRanged = true;
             clientStreamNode *node = (clientStreamNode *)http->client_stream.tail->data;
             /* XXX: This is suboptimal. We should give the stream the range set,
              * and thereby let the top of the stream set the offset when the
@@ -1132,12 +1132,12 @@ clientInterpretRequestHeaders(ClientHttpRequest * http)
     }
 
     if (req_hdr->has(HDR_AUTHORIZATION))
-        request->flags.auth = 1;
+        request->flags.auth = true;
 
     clientCheckPinning(http);
 
     if (request->login[0] != '\0')
-        request->flags.auth = 1;
+        request->flags.auth = true;
 
     if (req_hdr->has(HDR_VIA)) {
         String s = req_hdr->getList(HDR_VIA);
@@ -1150,7 +1150,7 @@ clientInterpretRequestHeaders(ClientHttpRequest * http)
         if (strListIsSubstr(&s, ThisCache2, ',')) {
             debugObj(33, 1, "WARNING: Forwarding loop detected for:\n",
                      request, (ObjPackMethod) & httpRequestPack);
-            request->flags.loopDetected = 1;
+            request->flags.loopDetected = true;
         }
 
 #if USE_FORW_VIA_DB
@@ -1174,7 +1174,7 @@ clientInterpretRequestHeaders(ClientHttpRequest * http)
     request->flags.cachable = http->request->maybeCacheable();
 
     if (clientHierarchical(http))
-        request->flags.hierarchical = 1;
+        request->flags.hierarchical = true;
 
     debugs(85, 5, "clientInterpretRequestHeaders: REQ_NOCACHE = " <<
            (request->flags.noCache ? "SET" : "NOT SET"));
@@ -1278,7 +1278,7 @@ ClientRequestContext::clientRedirectDone(const HelperReply &reply)
                     debugs(61,2, HERE << "URL-rewriter diverts URL from " << urlCanonical(old_request) << " to " << urlCanonical(new_request));
 
                     // update the new request to flag the re-writing was done on it
-                    new_request->flags.redirected = 1;
+                    new_request->flags.redirected = true;
 
                     // unlink bodypipe from the old request. Not needed there any longer.
                     if (old_request->body_pipe != NULL) {
@@ -113,12 +113,12 @@ class ClientHttpRequest
     AccessLogEntry::Pointer al; ///< access.log entry
 
     struct {
-        unsigned int accel:1;
-        unsigned int intercepted:1;
-        unsigned int spoof_client_ip:1;
-        unsigned int internal:1;
-        unsigned int done_copying:1;
-        unsigned int purging:1;
+        bool accel;
+        //bool intercepted; //XXX: it's apparently never used.
+        //bool spoof_client_ip; //XXX: it's apparently never used.
+        bool internal;
+        bool done_copying;
+        bool purging;
     } flags;
 
     struct {
@@ -206,7 +206,7 @@ comm_empty_os_read_buffers(int fd)
     /* prevent those nasty RST packets */
     char buf[SQUID_TCP_SO_RCVBUF];
 
-    if (fd_table[fd].flags.nonblocking == 1) {
+    if (fd_table[fd].flags.nonblocking) {
         while (FD_READ_METHOD(fd, buf, SQUID_TCP_SO_RCVBUF) > 0) {};
     }
 #endif
@@ -504,7 +504,7 @@ comm_set_transparent(int fd)
         debugs(50, DBG_IMPORTANT, "comm_open: setsockopt(IP_TRANSPARENT) on FD " << fd << ": " << xstrerror());
     } else {
         /* mark the socket as having transparent options */
-        fd_table[fd].flags.transparent = 1;
+        fd_table[fd].flags.transparent = true;
     }
 #else
     debugs(50, DBG_CRITICAL, "WARNING: comm_open: setsockopt(IP_TRANSPARENT) not supported on this platform");
@@ -711,24 +711,24 @@ comm_import_opened(const Comm::ConnectionPointer &conn,
     comm_init_opened(conn, 0, 0, note, AI);
 
     if (!(conn->flags & COMM_NOCLOEXEC))
-        fd_table[conn->fd].flags.close_on_exec = 1;
+        fd_table[conn->fd].flags.close_on_exec = true;
 
     if (conn->local.GetPort() > (unsigned short) 0) {
 #if _SQUID_WINDOWS_
         if (AI->ai_socktype != SOCK_DGRAM)
 #endif
-            fd_table[conn->fd].flags.nolinger = 1;
+            fd_table[conn->fd].flags.nolinger = true;
     }
 
     if ((conn->flags & COMM_TRANSPARENT))
-        fd_table[conn->fd].flags.transparent = 1;
+        fd_table[conn->fd].flags.transparent = true;
 
     if (conn->flags & COMM_NONBLOCKING)
-        fd_table[conn->fd].flags.nonblocking = 1;
+        fd_table[conn->fd].flags.nonblocking = true;
 
 #ifdef TCP_NODELAY
     if (AI->ai_socktype == SOCK_STREAM)
-        fd_table[conn->fd].flags.nodelay = 1;
+        fd_table[conn->fd].flags.nodelay = true;
 #endif
 
     /* no fd_table[fd].flags. updates needed for these conditions:
@@ -829,7 +829,7 @@ comm_connect_addr(int sock, const Ip::Address &address)
     errno = 0;
 
     if (!F->flags.called_connect) {
-        F->flags.called_connect = 1;
+        F->flags.called_connect = true;
         ++ statCounter.syscalls.sock.connects;
 
         x = connect(sock, AI->ai_addr, AI->ai_addrlen);
@@ -1110,7 +1110,7 @@ _comm_close(int fd, char const *file, int line)
 
     PROF_start(comm_close);
 
-    F->flags.close_request = 1;
+    F->flags.close_request = true;
 
 #if USE_SSL
     if (F->ssl) {
@@ -1287,7 +1287,7 @@ commSetNoLinger(int fd)
     if (setsockopt(fd, SOL_SOCKET, SO_LINGER, (char *) &L, sizeof(L)) < 0)
         debugs(50, 0, "commSetNoLinger: FD " << fd << ": " << xstrerror());
 
-    fd_table[fd].flags.nolinger = 1;
+    fd_table[fd].flags.nolinger = true;
 }
 
 static void
@@ -1351,7 +1351,7 @@ commSetNonBlocking(int fd)
 #if _SQUID_CYGWIN_
     }
 #endif
-    fd_table[fd].flags.nonblocking = 1;
+    fd_table[fd].flags.nonblocking = true;
 
     return 0;
 }
@@ -1378,7 +1378,7 @@ commUnsetNonBlocking(int fd)
         return COMM_ERROR;
     }
 
-    fd_table[fd].flags.nonblocking = 0;
+    fd_table[fd].flags.nonblocking = false;
     return 0;
 }
 
@@ -1397,7 +1397,7 @@ commSetCloseOnExec(int fd)
     if (fcntl(fd, F_SETFD, flags | FD_CLOEXEC) < 0)
         debugs(50, 0, "FD " << fd << ": set close-on-exec failed: " << xstrerror());
 
-    fd_table[fd].flags.close_on_exec = 1;
+    fd_table[fd].flags.close_on_exec = true;
 
 #endif
 }
@@ -1411,7 +1411,7 @@ commSetTcpNoDelay(int fd)
     if (setsockopt(fd, IPPROTO_TCP, TCP_NODELAY, (char *) &on, sizeof(on)) < 0)
         debugs(50, DBG_IMPORTANT, "commSetTcpNoDelay: FD " << fd << ": " << xstrerror());
 
-    fd_table[fd].flags.nodelay = 1;
+    fd_table[fd].flags.nodelay = true;
 }
 
 #endif
@@ -33,8 +33,7 @@ Comm::ConnOpener::ConnOpener(Comm::ConnectionPointer &c, AsyncCall::Pointer &han
         callback_(handler),
         totalTries_(0),
         failRetries_(0),
-        connectTimeout_(ctimeout),
-        connectStart_(0)
+        deadline_(squid_curtime + static_cast<time_t>(ctimeout))
 {}
 
 Comm::ConnOpener::~ConnOpener()
@@ -55,36 +54,24 @@ Comm::ConnOpener::doneAll() const
         return AsyncJob::doneAll();
     }
 
+    // otherwise, we must be waiting for something
+    Must(temporaryFd_ >= 0 || calls_.sleep_);
     return false;
 }
 
 void
 Comm::ConnOpener::swanSong()
 {
-    // cancel any event watchers
-    // done here to get the "swanSong" mention in cancel debugging.
-    if (calls_.earlyAbort_ != NULL) {
-        calls_.earlyAbort_->cancel("Comm::ConnOpener::swanSong");
-        calls_.earlyAbort_ = NULL;
-    }
-    if (calls_.timeout_ != NULL) {
-        calls_.timeout_->cancel("Comm::ConnOpener::swanSong");
-        calls_.timeout_ = NULL;
-    }
-
     if (callback_ != NULL) {
-        if (callback_->canceled())
-            callback_ = NULL;
-        else
-            // inform the still-waiting caller we are dying
-            doneConnecting(COMM_ERR_CONNECT, 0);
+        // inform the still-waiting caller we are dying
+        sendAnswer(COMM_ERR_CONNECT, 0, "Comm::ConnOpener::swanSong");
     }
 
-    // rollback what we can from the job state
-    if (temporaryFd_ >= 0) {
-        // doneConnecting() handles partial FD connection cleanup
-        doneConnecting(COMM_ERR_CONNECT, 0);
-    }
+    if (temporaryFd_ >= 0)
+        closeFd();
+
+    if (calls_.sleep_)
+        cancelSleep();
 
     AsyncJob::swanSong();
 }
@@ -110,14 +97,13 @@ Comm::ConnOpener::getHost() const
 /**
  * Connection attempt are completed. One way or the other.
  * Pass the results back to the external handler.
- * NP: on errors the earlyAbort call should be cancelled first with a reason.
  */
 void
-Comm::ConnOpener::doneConnecting(comm_err_t errFlag, int xerrno)
+Comm::ConnOpener::sendAnswer(comm_err_t errFlag, int xerrno, const char *why)
 {
     // only mark the address good/bad AFTER connect is finished.
     if (host_ != NULL) {
-        if (xerrno == 0)
+        if (xerrno == 0) // XXX: should not we use errFlag instead?
             ipcacheMarkGoodAddr(host_, conn_->remote);
         else {
             ipcacheMarkBadAddr(host_, conn_->remote);
@@ -129,52 +115,147 @@ Comm::ConnOpener::doneConnecting(comm_err_t errFlag, int xerrno)
     }
 
     if (callback_ != NULL) {
-        typedef CommConnectCbParams Params;
-        Params &params = GetCommParams<Params>(callback_);
-        params.conn = conn_;
-        params.flag = errFlag;
-        params.xerrno = xerrno;
-        ScheduleCallHere(callback_);
+        // avoid scheduling cancelled callbacks, assuming they are common
+        // enough to make this extra check an optimization
+        if (callback_->canceled()) {
+            debugs(5, 4, conn_ << " not calling canceled " << *callback_ <<
+                   " [" << callback_->id << ']' );
+        } else {
+            typedef CommConnectCbParams Params;
+            Params &params = GetCommParams<Params>(callback_);
+            params.conn = conn_;
+            params.flag = errFlag;
+            params.xerrno = xerrno;
+            ScheduleCallHere(callback_);
+        }
         callback_ = NULL;
     }
 
-    if (temporaryFd_ >= 0) {
-        debugs(5, 4, HERE << conn_ << " closing temp FD " << temporaryFd_);
-        // it never reached fully open, so cleanup the FD handlers
-        // Note that comm_close() sequence does not happen for partially open FD
-        Comm::SetSelect(temporaryFd_, COMM_SELECT_WRITE, NULL, NULL, 0);
+    // The job will stop without this call because nil callback_ makes
+    // doneAll() true, but this explicit call creates nicer debugging.
+    mustStop(why);
+}
+
+/// cleans up this job I/O state without closing temporaryFd
+/// required before closing temporaryFd or keeping it in conn_
+/// leaves FD bare so must only be called via closeFd() or keepFd()
+void
+Comm::ConnOpener::cleanFd()
+{
+    debugs(5, 4, HERE << conn_ << " closing temp FD " << temporaryFd_);
+
+    Must(temporaryFd_ >= 0);
+    fde &f = fd_table[temporaryFd_];
+
+    // Our write_handler was set without using Comm::Write API, so we cannot
+    // use a cancellable Pointer-free job callback and simply cancel it here.
+    if (f.write_handler) {
+
+        /* XXX: We are about to remove write_handler, which was responsible
+         * for deleting write_data, so we have to delete write_data
+         * ourselves. Comm currently calls SetSelect handlers synchronously
+         * so if write_handler is set, we know it has not been called yet.
+         * ConnOpener converts that sync call into an async one, but only
+         * after deleting ptr, so that is not a problem.
+         */
+
+        delete static_cast<Pointer*>(f.write_data);
+        f.write_data = NULL;
+        f.write_handler = NULL;
+    }
+    // Comm::DoSelect does not do this when calling and resetting write_handler
+    // (because it expects more writes to come?). We could mimic that
+    // optimization by resetting Comm "Select" state only when the FD is
+    // actually closed.
+    Comm::SetSelect(temporaryFd_, COMM_SELECT_WRITE, NULL, NULL, 0);
+
+    if (calls_.timeout_ != NULL) {
+        calls_.timeout_->cancel("Comm::ConnOpener::cleanFd");
+        calls_.timeout_ = NULL;
+    }
+    // Comm checkTimeouts() and commCloseAllSockets() do not clear .timeout
+    // when calling timeoutHandler (XXX fix them), so we clear unconditionally.
+    f.timeoutHandler = NULL;
+    f.timeout = 0;
+
+    if (calls_.earlyAbort_ != NULL) {
+        comm_remove_close_handler(temporaryFd_, calls_.earlyAbort_);
         calls_.earlyAbort_ = NULL;
-        if (calls_.timeout_ != NULL) {
-            calls_.timeout_->cancel("Comm::ConnOpener::doneConnecting");
-            calls_.timeout_ = NULL;
-        }
-        fd_table[temporaryFd_].timeoutHandler = NULL;
-        fd_table[temporaryFd_].timeout = 0;
-        close(temporaryFd_);
-        fd_close(temporaryFd_);
-        temporaryFd_ = -1;
     }
+}
+
+/// cleans I/O state and ends I/O for temporaryFd_
+void
+Comm::ConnOpener::closeFd()
+{
+    if (temporaryFd_ < 0)
+        return;
+
+    cleanFd();
+
+    // comm_close() below uses COMMIO_FD_WRITECB(fd)->active() to clear Comm
+    // "Select" state. It will not clear ours. XXX: It should always clear
+    // because a callback may have been active but was called before comm_close
+    // Update: we now do this in cleanFd()
+    // Comm::SetSelect(temporaryFd_, COMM_SELECT_WRITE, NULL, NULL, 0);
 
-    /* ensure cleared local state, we are done. */
-    conn_ = NULL;
+    comm_close(temporaryFd_);
+    temporaryFd_ = -1;
+}
+
+/// cleans I/O state and moves temporaryFd_ to the conn_ for long-term use
+void
+Comm::ConnOpener::keepFd()
+{
+    Must(conn_ != NULL);
+    Must(temporaryFd_ >= 0);
+
+    cleanFd();
+
+    conn_->fd = temporaryFd_;
+    temporaryFd_ = -1;
 }
 
 void
 Comm::ConnOpener::start()
 {
     Must(conn_ != NULL);
 
-    /* get a socket open ready for connecting with */
+    /* outbound sockets have no need to be protocol agnostic. */
+    if (!(Ip::EnableIpv6&IPV6_SPECIAL_V4MAPPING) && conn_->remote.IsIPv4()) {
+        conn_->local.SetIPv4();
+    }
+
+    if (createFd())
+        connect();
+}
+
+/// called at the end of Comm::ConnOpener::DelayedConnectRetry event
+void
+Comm::ConnOpener::restart()
+{
+    debugs(5, 5, conn_ << " restarting after sleep");
+    calls_.sleep_ = false;
+
+    if (createFd())
+        connect();
+}
+
+/// Create a socket for the future connection or return false.
+/// If false is returned, done() is guaranteed to return true and end the job.
+bool
+Comm::ConnOpener::createFd()
+{
+    Must(temporaryFd_ < 0);
+
+    // our initators signal abort by cancelling their callbacks
+    if (callback_ == NULL || callback_->canceled())
+        return false;
+
+    temporaryFd_ = comm_openex(SOCK_STREAM, IPPROTO_TCP, conn_->local, conn_->flags, conn_->tos, conn_->nfmark, host_);
     if (temporaryFd_ < 0) {
-        /* outbound sockets have no need to be protocol agnostic. */
-        if (!(Ip::EnableIpv6&IPV6_SPECIAL_V4MAPPING) && conn_->remote.IsIPv4()) {
-            conn_->local.SetIPv4();
-        }
-        temporaryFd_ = comm_openex(SOCK_STREAM, IPPROTO_TCP, conn_->local, conn_->flags, conn_->tos, conn_->nfmark, host_);
-        if (temporaryFd_ < 0) {
-            doneConnecting(COMM_ERR_CONNECT, 0);
-            return;
-        }
+        sendAnswer(COMM_ERR_CONNECT, 0, "Comm::ConnOpener::createFd");
+        return false;
     }
 
     typedef CommCbMemFunT<Comm::ConnOpener, CommCloseCbParams> abortDialer;
@@ -183,26 +264,25 @@ Comm::ConnOpener::start()
 
     typedef CommCbMemFunT<Comm::ConnOpener, CommTimeoutCbParams> timeoutDialer;
     calls_.timeout_ = JobCallback(5, 4, timeoutDialer, this, Comm::ConnOpener::timeout);
-    debugs(5, 3, HERE << conn_ << " timeout " << connectTimeout_);
+    debugs(5, 3, conn_ << " will timeout in " << (deadline_ - squid_curtime));
 
-    // Update the fd_table directly because conn_ is not yet storing the FD
+    // Update the fd_table directly because commSetConnTimeout() needs open conn_
     assert(temporaryFd_ < Squid_MaxFD);
     assert(fd_table[temporaryFd_].flags.open);
     typedef CommTimeoutCbParams Params;
     Params &params = GetCommParams<Params>(calls_.timeout_);
     params.conn = conn_;
     fd_table[temporaryFd_].timeoutHandler = calls_.timeout_;
-    fd_table[temporaryFd_].timeout = squid_curtime + (time_t) connectTimeout_;
+    fd_table[temporaryFd_].timeout = deadline_;
 
-    connectStart_ = squid_curtime;
-    connect();
+    return true;
 }
 
 void
 Comm::ConnOpener::connected()
 {
-    conn_->fd = temporaryFd_;
-    temporaryFd_ = -1;
+    Must(temporaryFd_ >= 0);
+    keepFd();
 
     /*
      * stats.conn_open is used to account for the number of
@@ -220,64 +300,81 @@ Comm::ConnOpener::connected()
      *       Also, legacy code still depends on comm_local_port() with no access to Comm::Connection
      *       when those are done comm_local_port can become one of our member functions to do the below.
      */
-    fd_table[conn_->fd].flags.open = 1;
+    Must(fd_table[conn_->fd].flags.open);
     fd_table[conn_->fd].local_addr = conn_->local;
+
+    sendAnswer(COMM_OK, 0, "Comm::ConnOpener::connected");
 }
 
-/** Make an FD connection attempt.
- * Handles the case(s) when a partially setup connection gets closed early.
- */
+/// Make an FD connection attempt.
 void
 Comm::ConnOpener::connect()
 {
     Must(conn_ != NULL);
-
-    // our parent Jobs signal abort by cancelling their callbacks.
-    if (callback_ == NULL || callback_->canceled())
-        return;
+    Must(temporaryFd_ >= 0);
 
     ++ totalTries_;
 
     switch (comm_connect_addr(temporaryFd_, conn_->remote) ) {
 
     case COMM_INPROGRESS:
-        // check for timeout FIRST.
-        if (squid_curtime - connectStart_ > connectTimeout_) {
-            debugs(5, 5, HERE << conn_ << ": * - ERR took too long already.");
-            calls_.earlyAbort_->cancel("Comm::ConnOpener::connect timed out");
-            doneConnecting(COMM_TIMEOUT, errno);
-            return;
-        } else {
-            debugs(5, 5, HERE << conn_ << ": COMM_INPROGRESS");
-            Comm::SetSelect(temporaryFd_, COMM_SELECT_WRITE, Comm::ConnOpener::InProgressConnectRetry, new Pointer(this), 0);
-        }
+        debugs(5, 5, HERE << conn_ << ": COMM_INPROGRESS");
+        Comm::SetSelect(temporaryFd_, COMM_SELECT_WRITE, Comm::ConnOpener::InProgressConnectRetry, new Pointer(this), 0);
         break;
 
     case COMM_OK:
         debugs(5, 5, HERE << conn_ << ": COMM_OK - connected");
         connected();
-        doneConnecting(COMM_OK, 0);
         break;
 
-    default:
+    default: {
+        const int xerrno = errno;
+
         ++failRetries_;
+        debugs(5, 7, conn_ << ": failure #" << failRetries_ << " <= " <<
+               Config.connect_retries << ": " << xstrerr(xerrno));
 
-        // check for timeout FIRST.
-        if (squid_curtime - connectStart_ > connectTimeout_) {
-            debugs(5, 5, HERE << conn_ << ": * - ERR took too long to receive response.");
-            calls_.earlyAbort_->cancel("Comm::ConnOpener::connect timed out");
-            doneConnecting(COMM_TIMEOUT, errno);
-        } else if (failRetries_ < Config.connect_retries) {
+        if (failRetries_ < Config.connect_retries) {
             debugs(5, 5, HERE << conn_ << ": * - try again");
-            eventAdd("Comm::ConnOpener::DelayedConnectRetry", Comm::ConnOpener::DelayedConnectRetry, new Pointer(this), 0.05, 0, false);
+            sleep();
             return;
         } else {
             // send ERROR back to the upper layer.
             debugs(5, 5, HERE << conn_ << ": * - ERR tried too many times already.");
-            calls_.earlyAbort_->cancel("Comm::ConnOpener::connect failed");
-            doneConnecting(COMM_ERR_CONNECT, errno);
+            sendAnswer(COMM_ERR_CONNECT, xerrno, "Comm::ConnOpener::connect");
         }
     }
+    }
+}
+
+/// Close and wait a little before trying to open and connect again.
+void
+Comm::ConnOpener::sleep()
+{
+    Must(!calls_.sleep_);
+    closeFd();
+    calls_.sleep_ = true;
+    eventAdd("Comm::ConnOpener::DelayedConnectRetry",
+             Comm::ConnOpener::DelayedConnectRetry,
+             new Pointer(this), 0.05, 0, false);
+}
+
+/// cleans up this job sleep state
+void
+Comm::ConnOpener::cancelSleep()
+{
+    if (calls_.sleep_) {
+        // It would be nice to delete the sleep event, but it might be out of
+        // the event queue and in the async queue already, so (a) we do not know
+        // whether we can safely delete the call ptr here and (b) eventDelete()
+        // will assert if the event went async. Thus, we let the event run so
+        // that it deletes the call ptr [after this job is gone]. Note that we
+        // are called only when the job ends so this "hanging event" will do
+        // nothing but deleting the call ptr.  TODO: Revise eventDelete() API.
+        // eventDelete(Comm::ConnOpener::DelayedConnectRetry, calls_.sleep);
+        calls_.sleep_ = false;
+        debugs(5, 9, conn_ << " stops sleeping");
+    }
 }
 
 /**
@@ -308,7 +405,9 @@ void
 Comm::ConnOpener::earlyAbort(const CommCloseCbParams &io)
 {
     debugs(5, 3, HERE << io.conn);
-    doneConnecting(COMM_ERR_CLOSING, io.xerrno); // NP: is closing or shutdown better?
+    calls_.earlyAbort_ = NULL;
+    // NP: is closing or shutdown better?
+    sendAnswer(COMM_ERR_CLOSING, io.xerrno, "Comm::ConnOpener::earlyAbort");
 }
 
 /**
@@ -318,7 +417,9 @@ Comm::ConnOpener::earlyAbort(const CommCloseCbParams &io)
 void
 Comm::ConnOpener::timeout(const CommTimeoutCbParams &)
 {
-    connect();
+    debugs(5, 5, HERE << conn_ << ": * - ERR took too long to receive response.");
+    calls_.timeout_ = NULL;
+    sendAnswer(COMM_TIMEOUT, ETIMEDOUT, "Comm::ConnOpener::timeout");
 }
 
 /* Legacy Wrapper for the retry event after COMM_INPROGRESS
@@ -340,7 +441,7 @@ Comm::ConnOpener::InProgressConnectRetry(int fd, void *data)
 }
 
 /* Legacy Wrapper for the retry event with small delay after errors.
- * XXX: As soon as eventAdd() accepts Async calls we can use a ConnOpener::connect call
+ * XXX: As soon as eventAdd() accepts Async calls we can use a ConnOpener::restart call
  */
 void
 Comm::ConnOpener::DelayedConnectRetry(void *data)
@@ -351,7 +452,7 @@ Comm::ConnOpener::DelayedConnectRetry(void *data)
         // Ew. we are now outside the all AsyncJob protections.
         // get back inside by scheduling another call...
         typedef NullaryMemFunT<Comm::ConnOpener> Dialer;
-        AsyncCall::Pointer call = JobCallback(5, 4, Dialer, cs, Comm::ConnOpener::connect);
+        AsyncCall::Pointer call = JobCallback(5, 4, Dialer, cs, Comm::ConnOpener::restart);
         ScheduleCallHere(call);
     }
     delete ptr;
@@ -40,13 +40,23 @@ class ConnOpener : public AsyncJob
 
     void earlyAbort(const CommCloseCbParams &);
     void timeout(const CommTimeoutCbParams &);
-    void doneConnecting(comm_err_t errFlag, int xerrno);
+    void sendAnswer(comm_err_t errFlag, int xerrno, const char *why);
     static void InProgressConnectRetry(int fd, void *data);
     static void DelayedConnectRetry(void *data);
     void connect();
     void connected();
     void lookupLocalAddress();
 
+    void sleep();
+    void restart();
+
+    bool createFd();
+    void closeFd();
+    void keepFd();
+    void cleanFd();
+
+    void cancelSleep();
+
 private:
     char *host_;                         ///< domain name we are trying to connect to.
     int temporaryFd_;                    ///< the FD being opened. Do NOT set conn_->fd until it is fully open.
@@ -56,19 +66,16 @@ class ConnOpener : public AsyncJob
     int totalTries_;   ///< total number of connection attempts over all destinations so far.
     int failRetries_;  ///< number of retries current destination has been tried.
 
-    /**
-     * time at which to abandon the connection.
-     * the connection-done callback will be passed COMM_TIMEOUT
-     */
-    time_t connectTimeout_;
-
-    /// time at which this series of connection attempts was started.
-    time_t connectStart_;
+    /// if we are not done by then, we will call back with COMM_TIMEOUT
+    time_t deadline_;
 
     /// handles to calls which we may need to cancel.
     struct Calls {
         AsyncCall::Pointer earlyAbort_;
         AsyncCall::Pointer timeout_;
+        /// Whether we are idling before retrying to connect; not yet a call
+        /// [that we can cancel], but it will probably become one eventually.
+        bool sleep_;
     } calls_;
 
     CBDATA_CLASS2(ConnOpener);
@@ -502,7 +502,7 @@ Comm::DoSelect(int msec)
                 if ((hdl = F->read_handler)) {
                     PROF_start(comm_read_handler);
                     F->read_handler = NULL;
-                    F->flags.read_pending = 0;
+                    F->flags.read_pending = false;
                     hdl(fd, F->read_data);
                     PROF_stop(comm_read_handler);
                     ++ statCounter.select_fds;
@@ -125,7 +125,7 @@ file_close(int fd)
         while (!diskWriteIsComplete(fd))
             diskHandleWrite(fd, NULL);
 #else
-        F->flags.close_request = 1;
+        F->flags.close_request = true;
         debugs(6, 2, "file_close: FD " << fd << ", delaying close");
         PROF_stop(file_close);
         return;
@@ -223,7 +223,7 @@ diskHandleWrite(int fd, void *notused)
     _fde_disk *fdd = &F->disk;
     dwrite_q *q = fdd->write_q;
     int status = DISK_OK;
-    int do_close;
+    bool do_close;
 
     if (NULL == q)
         return;
@@ -232,7 +232,7 @@ diskHandleWrite(int fd, void *notused)
 
     debugs(6, 3, "diskHandleWrite: FD " << fd);
 
-    F->flags.write_daemon = 0;
+    F->flags.write_daemon = false;
 
     assert(fdd->write_q != NULL);
 
@@ -332,7 +332,7 @@ diskHandleWrite(int fd, void *notused)
         /* another block is queued */
         diskCombineWrites(fdd);
         Comm::SetSelect(fd, COMM_SELECT_WRITE, diskHandleWrite, NULL, 0);
-        F->flags.write_daemon = 1;
+        F->flags.write_daemon = true;
     }
 
     do_close = F->flags.close_request;
@@ -594,7 +594,6 @@ ErrorState::ErrorState(err_type t, http_status status, HttpRequest * req) :
 #endif
         detailCode(ERR_DETAIL_NONE)
 {
-    memset(&flags, 0, sizeof(flags));
     memset(&ftp, 0, sizeof(ftp));
 
     if (page_id >= ERR_MAX && ErrorDynamicPages.items[page_id - ERR_MAX]->page_redirect != HTTP_STATUS_NONE)
@@ -631,7 +630,7 @@ errorAppendEntry(StoreEntry * entry, ErrorState * err)
     if (err->page_id == TCP_RESET) {
         if (err->request) {
             debugs(4, 2, "RSTing this reply");
-            err->request->flags.resetTcp=true;
+            err->request->flags.resetTcp = true;
         }
     }
 
@@ -654,9 +653,6 @@ errorSend(const Comm::ConnectionPointer &conn, ErrorState * err)
     debugs(4, 3, HERE << conn << ", err=" << err);
     assert(Comm::IsConnOpen(conn));
 
-    /* moved in front of errorBuildBuf @?@ */
-    err->flags.flag_cbdata = 1;
-
     rep = err->BuildHttpReply();
 
     MemBuf *mb = rep->pack();
@@ -169,10 +169,6 @@ class ErrorState
     ERCB *callback;
     void *callback_data;
 
-    struct {
-        unsigned int flag_cbdata:1;
-    } flags;
-
     struct {
         wordlist *server_msg;
         char *request;
@@ -106,7 +106,7 @@ fd_close(int fd)
     fde *F = &fd_table[fd];
 
     assert(fd >= 0);
-    assert(F->flags.open == 1);
+    assert(F->flags.open);
 
     if (F->type == FD_FILE) {
         assert(F->read_handler == NULL);
@@ -116,7 +116,7 @@ fd_close(int fd)
     debugs(51, 3, "fd_close FD " << fd << " " << F->desc);
     Comm::SetSelect(fd, COMM_SELECT_READ, NULL, NULL, 0);
     Comm::SetSelect(fd, COMM_SELECT_WRITE, NULL, NULL, 0);
-    F->flags.open = 0;
+    F->flags.open = false;
     fdUpdateBiggest(fd, 0);
     --Number_FD;
     *F = fde();
@@ -220,7 +220,7 @@ fd_open(int fd, unsigned int type, const char *desc)
     assert(!F->flags.open);
     debugs(51, 3, "fd_open() FD " << fd << " " << desc);
     F->type = type;
-    F->flags.open = 1;
+    F->flags.open = true;
     F->epoll_state = 0;
 #if _SQUID_WINDOWS_
 
@@ -86,19 +86,19 @@ class fde
     char desc[FD_DESC_SZ];
 
     struct _fde_flags {
-        unsigned int open:1;
-        unsigned int close_request:1; // file_ or comm_close has been called
-        unsigned int write_daemon:1;
-        unsigned int socket_eof:1;
-        unsigned int nolinger:1;
-        unsigned int nonblocking:1;
-        unsigned int ipc:1;
-        unsigned int called_connect:1;
-        unsigned int nodelay:1;
-        unsigned int close_on_exec:1;
-        unsigned int read_pending:1;
-        unsigned int write_pending:1;
-        unsigned int transparent:1;
+        bool open;
+        bool close_request; ///< true if file_ or comm_close has been called
+        bool write_daemon;
+        bool socket_eof;
+        bool nolinger;
+        bool nonblocking;
+        bool ipc;
+        bool called_connect;
+        bool nodelay;
+        bool close_on_exec;
+        bool read_pending;
+        //bool write_pending; //XXX seems not to be used
+        bool transparent;
     } flags;
 
     int64_t bytes_read;
@@ -322,12 +322,12 @@ Format::Token::parse(const char *def, Quoting *quoting)
     }
 
     if (*cur == '-') {
-        left = 1;
+        left = true;
         ++cur;
     }
 
     if (*cur == '0') {
-        zero = 1;
+        zero = false;
         ++cur;
     }
 
@@ -403,7 +403,7 @@ Format::Token::parse(const char *def, Quoting *quoting)
     }
 
     if (*cur == ' ') {
-        space = 1;
+        space = true;
         ++cur;
     }
 
@@ -32,9 +32,9 @@ class Token
             widthMin(-1),
             widthMax(-1),
             quote(LOG_QUOTE_NONE),
-            left(0),
-            space(0),
-            zero(0),
+            left(false),
+            space(false),
+            zero(false),
             divisor(0),
             next(NULL)
     { data.string = NULL; }
@@ -65,9 +65,9 @@ class Token
     int widthMin; ///< minimum field width
     int widthMax; ///< maximum field width
     enum Quoting quote;
-    unsigned int left:1;
-    unsigned int space:1;
-    unsigned int zero:1;
+    bool left;
+    bool space;
+    bool zero;
     int divisor;
     Token *next;	/* todo: move from linked list to array */
 
@@ -204,12 +204,12 @@ FwdState::selectPeerForIntercepted()
 void
 FwdState::completed()
 {
-    if (flags.forward_completed == 1) {
+    if (flags.forward_completed) {
         debugs(17, DBG_IMPORTANT, HERE << "FwdState::completed called on a completed request! Bad!");
         return;
     }
 
-    flags.forward_completed = 1;
+    flags.forward_completed = true;
 
     if (EBIT_TEST(entry->flags, ENTRY_ABORTED)) {
         debugs(17, 3, HERE << "entry aborted");
@@ -1107,7 +1107,7 @@ FwdState::connectStart()
         return;
     }
 
-    request->flags.pinned = 0; // XXX: what if the ConnStateData set this to flag existing credentials?
+    request->flags.pinned = false; // XXX: what if the ConnStateData set this to flag existing credentials?
     // XXX: answer: the peer selection *should* catch it and give us only the pinned peer. so we reverse the =0 step below.
     // XXX: also, logs will now lie if pinning is broken and leads to an error message.
     if (serverDestinations[0]->peerType == PINNED) {
@@ -1125,9 +1125,9 @@ FwdState::connectStart()
                 serverConn->peerType = HIER_DIRECT;
 #endif
             ++n_tries;
-            request->flags.pinned = 1;
+            request->flags.pinned = true;
             if (pinned_connection->pinnedAuth())
-                request->flags.auth = 1;
+                request->flags.auth = true;
             comm_add_close_handler(serverConn->fd, fwdServerClosedWrapper, this);
             // the server may close the pinned connection before this request
             pconnRace = racePossible;
@@ -1323,7 +1323,7 @@ FwdState::dispatch()
             ErrorState *anErr = new ErrorState(ERR_UNSUP_REQ, HTTP_BAD_REQUEST, request);
             fail(anErr);
             // Set the dont_retry flag because this is not a transient (network) error.
-            flags.dont_retry = 1;
+            flags.dont_retry = true;
             if (Comm::IsConnOpen(serverConn)) {
                 serverConn->close();
             }
@@ -128,9 +128,9 @@ class FwdState : public RefCountable
     } calls;
 
     struct {
-        unsigned int connected_okay:1; ///< TCP link ever opened properly. This affects retry of POST,PUT,CONNECT,etc
-        unsigned int dont_retry:1;
-        unsigned int forward_completed:1;
+        bool connected_okay; ///< TCP link ever opened properly. This affects retry of POST,PUT,CONNECT,etc
+        bool dont_retry;
+        bool forward_completed;
     } flags;
 
     /** connections to open, in order, until successful */
@@ -116,8 +116,8 @@ class fqdncache_entry
     unsigned short locks;
 
     struct {
-        unsigned int negcached:1;
-        unsigned int fromhosts:1;
+        bool negcached;
+        bool fromhosts;
     } flags;
 
     int age() const; ///< time passed since request_time or -1 if unknown
@@ -428,7 +428,7 @@ fqdncacheParse(fqdncache_entry *f, const rfc1035_rr * answers, int nr, const cha
     int ttl = 0;
     const char *name = (const char *)f->hash.key;
     f->expires = squid_curtime + Config.negativeDnsTtl;
-    f->flags.negcached = 1;
+    f->flags.negcached = true;
 
     if (nr < 0) {
         debugs(35, 3, "fqdncacheParse: Lookup of '" << name << "' failed (" << error_message << ")");
@@ -485,7 +485,7 @@ fqdncacheParse(fqdncache_entry *f, const rfc1035_rr * answers, int nr, const cha
 
     f->expires = squid_curtime + ttl;
 
-    f->flags.negcached = 0;
+    f->flags.negcached = false;
 
     return f->name_count;
 }
@@ -827,7 +827,7 @@ fqdncacheAddEntryFromHosts(char *addr, wordlist * hostnames)
 
     fce->name_count = j;
     fce->names[j] = NULL;	/* it's safe */
-    fce->flags.fromhosts = 1;
+    fce->flags.fromhosts = true;
     fqdncacheAddEntry(fce);
     fqdncacheLockEntry(fce);
 }
@@ -36,8 +36,9 @@ class CossMemBuf
     char buffer[COSS_MEMBUF_SZ];
 
     struct _cossmembuf_flags {
-        unsigned int full:1;
-        unsigned int writing:1;
+        _cossmembuf_flags() : full(false), writing(false) {}
+        bool full;
+        bool writing;
     } flags;
 };
 
@@ -68,9 +69,9 @@ class CossState : public StoreIOState
     size_t requestoffset;	/* in blocks */
     int64_t reqdiskoffset;	/* in blocks */
 
-    struct {
-        unsigned int reading:1;
-        unsigned int writing:1;
+    struct CossFlags {
+        bool reading;
+        bool writing;
     } flags;
 
     CossMemBuf *locked_membuf;
@@ -176,7 +176,7 @@ CossSwapDir::readCompleted(const char *buf, int len, int errflag, RefCount<ReadR
     ssize_t rlen;
 
     debugs(79, 3, "storeCossReadDone: fileno " << sio->swap_filen << ", len " << len);
-    cstate->flags.reading = 0;
+    cstate->flags.reading = false;
 
     if (errflag) {
         ++ StoreFScoss::GetInstance().stats.read.fail;
@@ -87,7 +87,7 @@ CossSwapDir::allocate(const StoreEntry * e, int which)
          * back to the beginning
          */
         ++ StoreFScoss::GetInstance().stats.disk_overflows;
-        current_membuf->flags.full = 1;
+        current_membuf->flags.full = true;
         current_membuf->diskend = current_offset;
         current_membuf->maybeWrite(this);
         current_offset = 0;	/* wrap back to beginning */
@@ -102,7 +102,7 @@ CossSwapDir::allocate(const StoreEntry * e, int which)
          * Skip the blank space at the end of the stripe. start over.
          */
         ++ StoreFScoss::GetInstance().stats.stripe_overflows;
-        current_membuf->flags.full = 1;
+        current_membuf->flags.full = true;
         current_offset = current_membuf->diskend;
         current_membuf->maybeWrite(this);
         debugs(79, 2, "CossSwapDir::allocate: New offset - " << current_offset);
@@ -183,8 +183,8 @@ CossSwapDir::createStoreIO(StoreEntry &e, StoreIOState::STFNCB * file_callback,
     sio->callback_data = cbdataReference(callback_data);
     sio->e = &e;
 
-    cstate->flags.writing = 0;
-    cstate->flags.reading = 0;
+    cstate->flags.writing = false;
+    cstate->flags.reading = false;
     cstate->readbuffer = NULL;
     cstate->reqdiskoffset = -1;
 
@@ -220,8 +220,8 @@ CossSwapDir::openStoreIO(StoreEntry & e, StoreIOState::STFNCB * file_callback,
     cstate->st_size = e.swap_file_sz;
     sio->e = &e;
 
-    cstate->flags.writing = 0;
-    cstate->flags.reading = 0;
+    cstate->flags.writing = false;
+    cstate->flags.reading = false;
     cstate->readbuffer = NULL;
     cstate->reqdiskoffset = -1;
     p = storeCossMemPointerFromDiskOffset(storeCossFilenoToDiskOffset(f), NULL);
@@ -308,7 +308,7 @@ CossState::read_(char *buf, size_t size, off_t offset, STRCB * callback, void *c
     read.callback_data = cbdataReference(callback_data);
     debugs(79, 3, "storeCossRead: offset " << offset);
     offset_ = offset;
-    flags.reading = 1;
+    flags.reading = true;
 
     if ((offset + (off_t)size) > st_size)
         size = st_size - offset;
@@ -542,7 +542,7 @@ CossMemBuf::write(CossSwapDir * SD)
 {
     ++ StoreFScoss::GetInstance().stats.stripe_write.ops;
     debugs(79, 3, "CossMemBuf::write: offset " << diskstart << ", len " << (diskend - diskstart));
-    flags.writing = 1;
+    flags.writing = true;
     /* XXX Remember that diskstart/diskend are block offsets! */
     SD->theFile->write(new CossWrite(WriteRequest((char const *)&buffer, diskstart, diskend - diskstart, NULL), this));
 }
@@ -562,8 +562,6 @@ CossSwapDir::createMemBuf(off_t start, sfileno curfn, int *collision)
     debugs(79, 3, "CossSwapDir::createMemBuf: creating new membuf at " << newmb->diskstart);
     debugs(79, 3, "CossSwapDir::createMemBuf: at " << newmb);
     newmb->diskend = newmb->diskstart + COSS_MEMBUF_SZ;
-    newmb->flags.full = 0;
-    newmb->flags.writing = 0;
     newmb->lockcount = 0;
     newmb->SD = this;
     /* XXX This should be reversed, with the new buffer last in the chain */
@@ -63,7 +63,7 @@ Fs::Ufs::RebuildState::RebuildState(RefCount<UFSSwapDir> aSwapDir) :
      * use commonUfsDirRebuildFromDirectory() to open up each file
      * and suck in the meta data.
      */
-    int clean = 0;
+    int clean = 0; //TODO: change to bool
     int zeroLengthLog = 0;
     FILE *fp = sd->openTmpSwapLog(&clean, &zeroLengthLog);
 
@@ -78,11 +78,11 @@ Fs::Ufs::RebuildState::RebuildState(RefCount<UFSSwapDir> aSwapDir) :
 
     } else {
         fromLog = true;
-        flags.clean = (unsigned int) clean;
+        flags.clean = (clean != 0);
     }
 
     if (!clean)
-        flags.need_to_validate = 1;
+        flags.need_to_validate = true;
 
     debugs(47, DBG_IMPORTANT, "Rebuilding storage in " << sd->path << " (" <<
            (clean ? "clean log" : (LogParser ? "dirty log" : "no log")) << ")");
@@ -444,12 +444,12 @@ Fs::Ufs::RebuildState::getNextFile(sfileno * filn_p, int *size)
     while (fd < 0 && done == 0) {
         fd = -1;
 
-        if (0 == flags.init) {  /* initialize, open first file */
+        if (!flags.init) {  /* initialize, open first file */
             done = 0;
             curlvl1 = 0;
             curlvl2 = 0;
             in_dir = 0;
-            flags.init = 1;
+            flags.init = true;
             assert(Config.cacheSwap.n_configured > 0);
         }
 
@@ -62,10 +62,11 @@ class RebuildState : public RefCountable
     int curlvl1;
     int curlvl2;
 
-    struct {
-        unsigned int need_to_validate:1;
-        unsigned int clean:1;
-        unsigned int init:1;
+    struct Flags {
+        Flags() : need_to_validate(false), clean(false), init(false) {}
+        bool need_to_validate;
+        bool clean;
+        bool init;
     } flags;
     int in_dir;
     int done;
@@ -681,10 +681,17 @@ FtpStateData::ftpTimeout(const CommTimeoutCbParams &io)
     if (abortOnBadEntry("entry went bad while waiting for a timeout"))
         return;
 
-    if (SENT_PASV == state && io.conn->fd == data.conn->fd) {
-        /* stupid ftp.netscape.com */
+    if (SENT_PASV == state) {
+        /* stupid ftp.netscape.com, of FTP server behind stupid firewall rules */
         flags.pasv_supported = false;
         debugs(9, DBG_IMPORTANT, "ftpTimeout: timeout in SENT_PASV state" );
+
+        // cancel the data connection setup.
+        if (data.opener != NULL) {
+            data.opener->cancel("timeout");
+            data.opener = NULL;
+        }
+        data.close();
     }
 
     failed(ERR_READ_TIMEOUT, 0);
@@ -102,7 +102,7 @@ HelperServerBase::closePipesSafely()
     shutdown(writePipe->fd, SD_BOTH);
 #endif
 
-    flags.closing = 1;
+    flags.closing = true;
     if (readPipe->fd == writePipe->fd)
         readPipe->fd = -1;
     else
@@ -131,7 +131,7 @@ HelperServerBase::closeWritePipeSafely()
     shutdown(writePipe->fd, (readPipe->fd == writePipe->fd ? SD_BOTH : SD_SEND));
 #endif
 
-    flags.closing = 1;
+    flags.closing = true;
     if (readPipe->fd == writePipe->fd)
         readPipe->fd = -1;
     writePipe->close();
@@ -347,7 +347,7 @@ helperStatefulOpenServers(statefulhelper * hlp)
         helper_stateful_server *srv = cbdataAlloc(helper_stateful_server);
         srv->hIpc = hIpc;
         srv->pid = pid;
-        srv->flags.reserved = 0;
+        srv->flags.reserved = false;
         srv->initStats();
         srv->index = k;
         srv->addr = hlp->addr;
@@ -476,7 +476,7 @@ helperStatefulReleaseServer(helper_stateful_server * srv)
 
     ++ srv->stats.releases;
 
-    srv->flags.reserved = 0;
+    srv->flags.reserved = false;
     if (srv->parent->OnEmptyQueue != NULL && srv->data)
         srv->parent->OnEmptyQueue(srv->data);
 
@@ -622,7 +622,7 @@ helperShutdown(helper * hlp)
 
         assert(hlp->childs.n_active > 0);
         -- hlp->childs.n_active;
-        srv->flags.shutdown = 1;	/* request it to shut itself down */
+        srv->flags.shutdown = true;	/* request it to shut itself down */
 
         if (srv->flags.closing) {
             debugs(84, 3, "helperShutdown: " << hlp->id_name << " #" << srv->index + 1 << " is CLOSING.");
@@ -659,7 +659,7 @@ helperStatefulShutdown(statefulhelper * hlp)
 
         assert(hlp->childs.n_active > 0);
         -- hlp->childs.n_active;
-        srv->flags.shutdown = 1;	/* request it to shut itself down */
+        srv->flags.shutdown = true;	/* request it to shut itself down */
 
         if (srv->flags.busy) {
             debugs(84, 3, "helperStatefulShutdown: " << hlp->id_name << " #" << srv->index + 1 << " is BUSY.");
@@ -885,7 +885,7 @@ helperReturnBuffer(int request_number, helper_server * srv, helper * hlp, char *
     if (!srv->flags.shutdown) {
         helperKickQueue(hlp);
     } else if (!srv->flags.closing && !srv->stats.pending) {
-        srv->flags.closing=1;
+        srv->flags.closing=true;
         srv->writePipe->close();
     }
 }
@@ -1050,7 +1050,7 @@ helperStatefulHandleRead(const Comm::ConnectionPointer &conn, char *buf, size_t
         // only skip off the \0's _after_ passing its location in HelperReply above
         t += skip;
 
-        srv->flags.busy = 0;
+        srv->flags.busy = false;
         /**
          * BUG: the below assumes that only one response per read() was received and discards any octets remaining.
          *      Doing this prohibits concurrency support with multiple replies per read().
@@ -1291,7 +1291,7 @@ helperDispatchWriteDone(const Comm::ConnectionPointer &conn, char *buf, size_t l
     srv->writebuf->clean();
     delete srv->writebuf;
     srv->writebuf = NULL;
-    srv->flags.writing = 0;
+    srv->flags.writing = false;
 
     if (flag != COMM_OK) {
         /* Helper server has crashed */
@@ -1302,7 +1302,7 @@ helperDispatchWriteDone(const Comm::ConnectionPointer &conn, char *buf, size_t l
     if (!srv->wqueue->isNull()) {
         srv->writebuf = srv->wqueue;
         srv->wqueue = new MemBuf;
-        srv->flags.writing = 1;
+        srv->flags.writing = true;
         AsyncCall::Pointer call = commCbCall(5,5, "helperDispatchWriteDone",
                                              CommIoCbPtrFun(helperDispatchWriteDone, srv));
         Comm::Write(srv->writePipe, srv->writebuf->content(), srv->writebuf->contentSize(), call, NULL);
@@ -1345,7 +1345,7 @@ helperDispatch(helper_server * srv, helper_request * r)
         assert(NULL == srv->writebuf);
         srv->writebuf = srv->wqueue;
         srv->wqueue = new MemBuf;
-        srv->flags.writing = 1;
+        srv->flags.writing = true;
         AsyncCall::Pointer call = commCbCall(5,5, "helperDispatchWriteDone",
                                              CommIoCbPtrFun(helperDispatchWriteDone, srv));
         Comm::Write(srv->writePipe, srv->writebuf->content(), srv->writebuf->contentSize(), call, NULL);
@@ -1397,8 +1397,8 @@ helperStatefulDispatch(helper_stateful_server * srv, helper_stateful_request * r
         return;
     }
 
-    srv->flags.busy = 1;
-    srv->flags.reserved = 1;
+    srv->flags.busy = true;
+    srv->flags.reserved = true;
     srv->request = r;
     srv->dispatch_time = current_time;
     AsyncCall::Pointer call = commCbCall(5,5, "helperStatefulDispatchWriteDone",
@@ -132,11 +132,11 @@ class HelperServerBase
     dlink_node link;
 
     struct _helper_flags {
-        unsigned int busy:1;
-        unsigned int writing:1;
-        unsigned int closing:1;
-        unsigned int shutdown:1;
-        unsigned int reserved:1;
+        bool busy;
+        bool writing;
+        bool closing;
+        bool shutdown;
+        bool reserved;
     } flags;
 
     struct {
@@ -122,7 +122,7 @@ HttpStateData::HttpStateData(FwdState *theFwdState) : AsyncJob("HttpStateData"),
         _peer = cbdataReference(fwd->serverConnection()->getPeer());         /* might be NULL */
 
     if (_peer) {
-        request->flags.proxying = 1;
+        request->flags.proxying = true;
         /*
          * This NEIGHBOR_PROXY_ONLY check probably shouldn't be here.
          * We might end up getting the object from somewhere else if,
@@ -752,7 +752,7 @@ HttpStateData::processReplyHeader()
     }
 
     if (!peerSupportsConnectionPinning())
-        request->flags.connectionAuthDisabled = 1;
+        request->flags.connectionAuthDisabled = true;
 
     HttpReply *vrep = setVirginReply(newrep);
     flags.headers_parsed = true;
@@ -1442,7 +1442,7 @@ HttpStateData::processReplyBody()
 
             if (ispinned && request->clientConnectionManager.valid()) {
                 request->clientConnectionManager->pinConnection(serverConnection, request, _peer,
-                        (request->flags.connectionAuth != 0));
+                        (request->flags.connectionAuth));
             } else {
                 fwd->pconnPush(serverConnection, request->peer_host ? request->peer_host : request->GetHost());
             }
@@ -1691,11 +1691,11 @@ HttpStateData::httpBuildRequestHeader(HttpRequest * request,
      */
     if (!we_do_ranges && request->multipartRangeRequest()) {
         /* don't cache the result */
-        request->flags.cachable = 0;
+        request->flags.cachable = false;
         /* pretend it's not a range request */
         delete request->range;
         request->range = NULL;
-        request->flags.isRanged=false;
+        request->flags.isRanged = false;
     }
 
     /* append Via */
@@ -2065,9 +2065,9 @@ HttpStateData::buildRequestPrefix(MemBuf * mb)
         httpBuildRequestHeader(request, entry, fwd->al, &hdr, flags);
 
         if (request->flags.pinned && request->flags.connectionAuth)
-            request->flags.authSent = 1;
+            request->flags.authSent = true;
         else if (hdr.has(HDR_AUTHORIZATION))
-            request->flags.authSent = 1;
+            request->flags.authSent = true;
 
         packerToMemInit(&p, mb);
         hdr.packInto(&p);
@@ -1344,7 +1344,7 @@ netdbExchangeStart(void *data)
     tempBuffer.data = ex->buf;
     storeClientCopy(ex->sc, ex->e, tempBuffer,
                     netdbExchangeHandleReply, ex);
-    ex->r->flags.loopDetected = 1;	/* cheat! -- force direct */
+    ex->r->flags.loopDetected = true;	/* cheat! -- force direct */
 
     if (p->login)
         xstrncpy(ex->r->login, p->login, MAX_LOGIN_SZ);
@@ -59,6 +59,7 @@ typedef struct _IdentClient {
 typedef struct _IdentStateData {
     hash_link hash;		/* must be first */
     Comm::ConnectionPointer conn;
+    MemBuf queryMsg;  ///< the lookup message sent to IDENT server
     IdentClient *clients;
     char buf[IDENT_BUFSIZE];
 } IdentStateData;
@@ -147,14 +148,9 @@ Ident::ConnectDone(const Comm::ConnectionPointer &conn, comm_err_t status, int x
 
     comm_add_close_handler(conn->fd, Ident::Close, state);
 
-    MemBuf mb;
-    mb.init();
-    mb.Printf("%d, %d\r\n",
-              conn->remote.GetPort(),
-              conn->local.GetPort());
     AsyncCall::Pointer writeCall = commCbCall(5,4, "Ident::WriteFeedback",
                                    CommIoCbPtrFun(Ident::WriteFeedback, state));
-    Comm::Write(conn, &mb, writeCall);
+    Comm::Write(conn, &state->queryMsg, writeCall);
     AsyncCall::Pointer readCall = commCbCall(5,4, "Ident::ReadReply",
                                   CommIoCbPtrFun(Ident::ReadReply, state));
     comm_read(conn, state->buf, IDENT_BUFSIZE, readCall);
@@ -264,6 +260,10 @@ Ident::Start(const Comm::ConnectionPointer &conn, IDCB * callback, void *data)
     state->conn->local.SetPort(0);
     state->conn->remote.SetPort(IDENT_PORT);
 
+    // build our query from the original connection details
+    state->queryMsg.init();
+    state->queryMsg.Printf("%d, %d\r\n", conn->remote.GetPort(), conn->local.GetPort());
+
     ClientAdd(state, callback, data);
     hash_join(ident_hash, &state->hash);
 
@@ -321,13 +321,10 @@ ipcCreate(int type, const char *prog, const char *const args[], const char *name
     if (wfd)
         *wfd = pwfd;
 
-    fd_table[prfd].flags.ipc = 1;
-
-    fd_table[pwfd].flags.ipc = 1;
-
-    fd_table[crfd].flags.ipc = 1;
-
-    fd_table[cwfd].flags.ipc = 1;
+    fd_table[prfd].flags.ipc = true;
+    fd_table[pwfd].flags.ipc = true;
+    fd_table[crfd].flags.ipc = true;
+    fd_table[cwfd].flags.ipc = true;
 
     if (Config.sleep_after_fork) {
         /* XXX emulation of usleep() */
@@ -113,8 +113,8 @@ class ipcache_entry
     dlink_node lru;
     unsigned short locks;
     struct {
-        unsigned int negcached:1;
-        unsigned int fromhosts:1;
+        bool negcached;
+        bool fromhosts;
     } flags;
 
     int age() const; ///< time passed since request_time or -1 if unknown
@@ -473,7 +473,7 @@ ipcacheParse(ipcache_entry *i, const rfc1035_rr * answers, int nr, const char *e
     int cname_found = 0;
 
     i->expires = squid_curtime + Config.negativeDnsTtl;
-    i->flags.negcached = 1;
+    i->flags.negcached = true;
     safe_free(i->addrs.in_addrs);
     assert(i->addrs.in_addrs == NULL);
     safe_free(i->addrs.bad_mask);
@@ -585,7 +585,7 @@ ipcacheParse(ipcache_entry *i, const rfc1035_rr * answers, int nr, const char *e
 
     i->expires = squid_curtime + ttl;
 
-    i->flags.negcached = 0;
+    i->flags.negcached = false;
 
     return i->addrs.count;
 }
@@ -1218,7 +1218,7 @@ ipcacheAddEntryFromHosts(const char *name, const char *ipaddr)
     i->addrs.bad_mask = (unsigned char *)xcalloc(1, sizeof(unsigned char));
     i->addrs.in_addrs[0] = ip;
     i->addrs.bad_mask[0] = FALSE;
-    i->flags.fromhosts = 1;
+    i->flags.fromhosts = true;
     ipcacheAddEntry(i);
     ipcacheLockEntry(i);
     return 0;
@@ -113,26 +113,29 @@ logfileFreeBuffer(Logfile * lf, logfile_buffer_t * b)
 static void
 logfileHandleWrite(int fd, void *data)
 {
-    Logfile *lf = (Logfile *) data;
-    l_daemon_t *ll = (l_daemon_t *) lf->data;
-    int ret;
-    logfile_buffer_t *b;
+    Logfile *lf = static_cast<Logfile *>(data);
+    l_daemon_t *ll = static_cast<l_daemon_t *>(lf->data);
 
     /*
      * We'll try writing the first entry until its done - if we
      * get a partial write then we'll re-schedule until its completed.
      * Its naive but it'll do for now.
      */
-    b = static_cast<logfile_buffer_t*>(ll->bufs.head->data);
+    if (!ll->bufs.head) // abort if there is nothing pending right now.
+        return;
+
+    logfile_buffer_t *b = static_cast<logfile_buffer_t*>(ll->bufs.head->data);
     assert(b != NULL);
     ll->flush_pending = 0;
 
-    ret = FD_WRITE_METHOD(ll->wfd, b->buf + b->written_len, b->len - b->written_len);
-    debugs(50, 3, "logfileHandleWrite: " << lf->path << ": write returned " << ret);
+    int ret = FD_WRITE_METHOD(ll->wfd, b->buf + b->written_len, b->len - b->written_len);
+    debugs(50, 3, lf->path << ": write returned " << ret);
     if (ret < 0) {
         if (ignoreErrno(errno)) {
             /* something temporary */
-            goto reschedule;
+            Comm::SetSelect(ll->wfd, COMM_SELECT_WRITE, logfileHandleWrite, lf, 0);
+            ll->flush_pending = 1;
+            return;
         }
         debugs(50, DBG_IMPORTANT,"logfileHandleWrite: " << lf->path << ": error writing (" << xstrerror() << ")");
         /* XXX should handle this better */
@@ -153,15 +156,12 @@ logfileHandleWrite(int fd, void *data)
         b = NULL;
     }
     /* Is there more to write? */
-    if (ll->bufs.head == NULL) {
-        goto finish;
-    }
+    if (!ll->bufs.head)
+        return;
     /* there is, so schedule more */
 
-reschedule:
     Comm::SetSelect(ll->wfd, COMM_SELECT_WRITE, logfileHandleWrite, lf, 0);
     ll->flush_pending = 1;
-finish:
     return;
 }
 
@@ -455,7 +455,7 @@ MimeIcon::created (StoreEntry *newEntry)
         return;
     }
 
-    flags.cachable = 1;
+    flags.cachable = true;
     StoreEntry *e = storeCreateEntry(url,url,flags,Http::METHOD_GET);
     assert(e != NULL);
     EBIT_SET(e->flags, ENTRY_SPECIAL);
@@ -180,7 +180,7 @@ peerDigestNeeded(PeerDigest * pd)
     assert(!pd->flags.needed);
     assert(!pd->cd);
 
-    pd->flags.needed = 1;
+    pd->flags.needed = true;
     pd->times.needed = squid_curtime;
     peerDigestSetCheck(pd, 0);	/* check asap */
 }
@@ -322,7 +322,7 @@ peerDigestRequest(PeerDigest * pd)
     StoreIOBuffer tempBuffer;
 
     pd->req_result = NULL;
-    pd->flags.requested = 1;
+    pd->flags.requested = true;
 
     /* compute future request components */
 
@@ -370,10 +370,10 @@ peerDigestRequest(PeerDigest * pd)
 
     pd_last_req_time = squid_curtime;
 
-    req->flags.cachable = 1;
+    req->flags.cachable = true;
 
     /* the rest is based on clientProcessExpired() */
-    req->flags.refresh = 1;
+    req->flags.refresh = true;
 
     old_e = fetch->old_entry = Store::Root().get(key);
 
@@ -836,7 +836,7 @@ peerDigestReqFinish(DigestFetchState * fetch, char *buf,
     /* must go before peerDigestPDFinish */
 
     if (pdcb_valid) {
-        fetch->pd->flags.requested = 0;
+        fetch->pd->flags.requested = false;
         fetch->pd->req_result = reason;
     }
 
@@ -887,14 +887,14 @@ peerDigestPDFinish(DigestFetchState * fetch, int pcb_valid, int err)
             pd->cd = NULL;
         }
 
-        pd->flags.usable = 0;
+        pd->flags.usable = false;
 
         if (!pcb_valid)
             peerDigestNotePeerGone(pd);
     } else {
         assert(pcb_valid);
 
-        pd->flags.usable = 1;
+        pd->flags.usable = true;
 
         /* XXX: ugly condition, but how? */
 
@@ -293,7 +293,7 @@ refreshCheck(const StoreEntry * entry, HttpRequest * request, time_t delta)
             entry->mem_obj->getReply()->cache_control->staleIfError() < staleness) {
 
         debugs(22, 3, "refreshCheck: stale-if-error period expired.");
-        request->flags.failOnValidationError = 1;
+        request->flags.failOnValidationError = true;
     }
 
     if (EBIT_TEST(entry->flags, ENTRY_REVALIDATE) && staleness > -1
@@ -303,7 +303,7 @@ refreshCheck(const StoreEntry * entry, HttpRequest * request, time_t delta)
        ) {
         debugs(22, 3, "refreshCheck: YES: Must revalidate stale response");
         if (request)
-            request->flags.failOnValidationError = 1;
+            request->flags.failOnValidationError = true;
         return STALE_MUST_REVALIDATE;
     }
 
@@ -331,7 +331,7 @@ refreshCheck(const StoreEntry * entry, HttpRequest * request, time_t delta)
         } else {
             /* The clients no-cache header is not overridden on this request */
             debugs(22, 3, "refreshCheck: YES: client reload");
-            request->flags.noCache = 1;
+            request->flags.noCache = true;
             return STALE_FORCED_RELOAD;
         }
 
@@ -398,7 +398,7 @@ refreshCheck(const StoreEntry * entry, HttpRequest * request, time_t delta)
     if ( max_stale >= 0 && staleness > max_stale) {
         debugs(22, 3, "refreshCheck: YES: max-stale limit");
         if (request)
-            request->flags.failOnValidationError = 1;
+            request->flags.failOnValidationError = true;
         return STALE_MAX_STALE;
     }
 
@@ -705,8 +705,8 @@ static_Inst(oid * name, snint * len, mib_tree_entry * current, oid_ParseFn ** Fn
 {
     oid *instance = NULL;
     if (*len <= current->len) {
-        instance = (oid *)xmalloc(sizeof(name) * (*len + 1));
-        memcpy(instance, name, (sizeof(name) * *len));
+        instance = (oid *)xmalloc(sizeof(*name) * (*len + 1));
+        memcpy(instance, name, sizeof(*name) * (*len));
         instance[*len] = 0;
         *len += 1;
     }
@@ -722,8 +722,8 @@ time_Inst(oid * name, snint * len, mib_tree_entry * current, oid_ParseFn ** Fn)
     int index[TIME_INDEX_LEN] = {TIME_INDEX};
 
     if (*len <= current->len) {
-        instance = (oid *)xmalloc(sizeof(name) * (*len + 1));
-        memcpy(instance, name, (sizeof(name) * *len));
+        instance = (oid *)xmalloc(sizeof(*name) * (*len + 1));
+        memcpy(instance, name, sizeof(*name) * (*len));
         instance[*len] = *index;
         *len += 1;
     } else {
@@ -733,8 +733,8 @@ time_Inst(oid * name, snint * len, mib_tree_entry * current, oid_ParseFn ** Fn)
             ++loop;
 
         if (loop < (TIME_INDEX_LEN - 1)) {
-            instance = (oid *)xmalloc(sizeof(name) * (*len));
-            memcpy(instance, name, (sizeof(name) * *len));
+            instance = (oid *)xmalloc(sizeof(*name) * (*len));
+            memcpy(instance, name, sizeof(*name) * (*len));
             instance[*len - 1] = index[++loop];
         }
     }
@@ -761,8 +761,8 @@ peer_Inst(oid * name, snint * len, mib_tree_entry * current, oid_ParseFn ** Fn)
         instance = client_Inst(current->name, len, current, Fn);
     } else if (*len <= current->len) {
         debugs(49, 6, "snmp peer_Inst: *len <= current->len ???");
-        instance = (oid *)xmalloc(sizeof(name) * ( *len + 1));
-        memcpy(instance, name, (sizeof(name) * *len));
+        instance = (oid *)xmalloc(sizeof(*name) * ( *len + 1));
+        memcpy(instance, name, sizeof(*name) * (*len));
         instance[*len] = 1 ;
         *len += 1;
     } else {
@@ -773,8 +773,8 @@ peer_Inst(oid * name, snint * len, mib_tree_entry * current, oid_ParseFn ** Fn)
 
         if (peers) {
             debugs(49, 6, "snmp peer_Inst: Encode peer #" << i);
-            instance = (oid *)xmalloc(sizeof(name) * (current->len + 1 ));
-            memcpy(instance, name, (sizeof(name) * current->len ));
+            instance = (oid *)xmalloc(sizeof(*name) * (current->len + 1 ));
+            memcpy(instance, name, (sizeof(*name) * current->len ));
             instance[current->len] = no + 1 ; // i.e. the next index on cache_peeer table.
         } else {
             debugs(49, 6, "snmp peer_Inst: We have " << i << " peers. Can't find #" << no);
@@ -808,8 +808,8 @@ client_Inst(oid * name, snint * len, mib_tree_entry * current, oid_ParseFn ** Fn
 
         debugs(49, 6, HERE << "len" << *len << ", current-len" << current->len << ", addr=" << laddr << ", size=" << size);
 
-        instance = (oid *)xmalloc(sizeof(name) * (*len + size ));
-        memcpy(instance, name, (sizeof(name) * (*len)));
+        instance = (oid *)xmalloc(sizeof(*name) * (*len + size ));
+        memcpy(instance, name, (sizeof(*name) * (*len)));
 
         if ( !laddr.IsAnyAddr() ) {
             addr2oid(laddr, &instance[ *len]);  // the addr
@@ -832,8 +832,8 @@ client_Inst(oid * name, snint * len, mib_tree_entry * current, oid_ParseFn ** Fn
 
             debugs(49, 6, HERE << "len" << *len << ", current-len" << current->len << ", addr=" << laddr << ", newshift=" << newshift);
 
-            instance = (oid *)xmalloc(sizeof(name) * (current->len +  newshift));
-            memcpy(instance, name, (sizeof(name) * (current->len)));
+            instance = (oid *)xmalloc(sizeof(*name) * (current->len +  newshift));
+            memcpy(instance, name, (sizeof(*name) * (current->len)));
             addr2oid(laddr, &instance[current->len]);  // the addr.
             *len = current->len + newshift ;
         }
@@ -3,14 +3,6 @@
 
 Ssl::Config Ssl::TheConfig;
 
-Ssl::Config::Config():
-#if USE_SSL_CRTD
-        ssl_crtd(NULL),
-#endif
-        ssl_crt_validator(NULL)
-{
-}
-
 Ssl::Config::~Config()
 {
 #if USE_SSL_CRTD
@@ -16,7 +16,12 @@ class Config
 #endif
     char *ssl_crt_validator;
     HelperChildConfig ssl_crt_validator_Children;
-    Config();
+    Config():
+#if USE_SSL_CRTD
+            ssl_crtd(NULL),
+#endif
+            ssl_crt_validator(NULL) {}
+
     ~Config();
 private:
     Config(const Config &); // not implemented
@@ -249,6 +249,31 @@ std::string & Ssl::CertificateProperties::dbKey() const
     return certKey;
 }
 
+// Copy certificate extensions from cert to mimicCert.
+// Currently only extensions which are reported by the users that required are
+// mimicked. More safe to mimic extensions would be added here if users request
+// them.
+static void
+mimicExtensions(Ssl::X509_Pointer & cert, Ssl::X509_Pointer const & mimicCert)
+{
+    static int extensions[]= {
+        NID_key_usage,
+        NID_ext_key_usage,
+        NID_basic_constraints,
+        0
+    };
+
+    int nid;
+    for (int i = 0; (nid = extensions[i]) != 0; ++i) {
+        const int pos = X509_get_ext_by_NID(mimicCert.get(), nid, -1);
+        if (X509_EXTENSION *ext = X509_get_ext(mimicCert.get(), pos))
+            X509_add_ext(cert.get(), ext, -1);
+    }
+
+    // We could also restrict mimicking of the CA extension to CA:FALSE
+    // because Squid does not generate valid fake CA certificates.
+}
+
 static bool buildCertificate(Ssl::X509_Pointer & cert, Ssl::CertificateProperties const &properties)
 {
     // not an Ssl::X509_NAME_Pointer because X509_REQ_get_subject_name()
@@ -320,6 +345,8 @@ static bool buildCertificate(Ssl::X509_Pointer & cert, Ssl::CertificatePropertie
                 X509_set_version(cert.get(), 2);
             }
         }
+
+        mimicExtensions(cert, properties.mimicCert);
     }
 
     return true;
@@ -1118,9 +1118,9 @@ ssl_read_method(int fd, char *buf, int len)
 
     if (i > 0 && SSL_pending(ssl) > 0) {
         debugs(83, 2, "SSL FD " << fd << " is pending");
-        fd_table[fd].flags.read_pending = 1;
+        fd_table[fd].flags.read_pending = true;
     } else
-        fd_table[fd].flags.read_pending = 0;
+        fd_table[fd].flags.read_pending = false;
 
     return i;
 }
@@ -392,7 +392,7 @@ storeDigestRewriteStart(void *datanotused)
     debugs(71, 2, "storeDigestRewrite: start rewrite #" << sd_state.rewrite_count + 1);
     /* make new store entry */
     url = internalLocalUri("/squid-internal-periodic/", StoreDigestFileName);
-    flags.cachable = 1;
+    flags.cachable = true;
     e = storeCreateEntry(url, url, flags, Http::METHOD_GET);
     assert(e);
     sd_state.rewrite_lock = e;
@@ -262,7 +262,7 @@ storeDirSelectSwapDirLeastLoad(const StoreEntry * e)
 
     for (i = 0; i < Config.cacheSwap.n_configured; ++i) {
         SD = dynamic_cast<SwapDir *>(INDEXSD(i));
-        SD->flags.selected = 0;
+        SD->flags.selected = false;
 
         if (!SD->canStore(*e, objsize, load))
             continue;
@@ -295,7 +295,7 @@ storeDirSelectSwapDirLeastLoad(const StoreEntry * e)
     }
 
     if (dirn >= 0)
-        dynamic_cast<SwapDir *>(INDEXSD(dirn))->flags.selected = 1;
+        dynamic_cast<SwapDir *>(INDEXSD(dirn))->flags.selected = true;
 
     return dirn;
 }
@@ -1128,7 +1128,12 @@ StoreHashIndex::search(String const url, HttpRequest *)
 
 CBDATA_CLASS_INIT(StoreSearchHashIndex);
 
-StoreSearchHashIndex::StoreSearchHashIndex(RefCount<StoreHashIndex> aSwapDir) : sd(aSwapDir), _done (false), bucket (0)
+StoreSearchHashIndex::StoreSearchHashIndex(RefCount<StoreHashIndex> aSwapDir) :
+        sd(aSwapDir),
+        callback(NULL),
+        cbdata(NULL),
+        _done(false),
+        bucket(0)
 {}
 
 /* do not link
@@ -38,7 +38,7 @@
 #define STUB_API "stub_DelayId.cc"
 #include "tests/STUB.h"
 
-DelayId::DelayId() {}
+DelayId::DelayId(): pool_(0), compositeId(NULL), markedAsNoDelay(false) {}
 DelayId::~DelayId() {}
 
 void DelayId::delayRead(DeferredRead const&) STUB_NOP
@@ -4,22 +4,21 @@
 #define STUB_API "HttpReply.cc"
 #include "tests/STUB.h"
 
-HttpReply::HttpReply() : HttpMsg(hoReply)
-{
-// XXX: required by testStore
-// STUB
-}
-HttpReply::~HttpReply() STUB
-void HttpReply::setHeaders(http_status status, const char *reason, const char *ctype, int64_t clen, time_t lmt, time_t expires_) STUB
-void HttpReply::packHeadersInto(Packer * p) const STUB
-void HttpReply::reset() STUB
-void httpBodyPackInto(const HttpBody * body, Packer * p) STUB
-bool HttpReply::sanityCheckStartLine(MemBuf *buf, const size_t hdr_len, http_status *error) STUB_RETVAL(false)
-int HttpReply::httpMsgParseError() STUB_RETVAL(0)
-bool HttpReply::expectingBody(const HttpRequestMethod&, int64_t&) const STUB_RETVAL(false)
-void HttpReply::packFirstLineInto(Packer * p, bool) const STUB
-bool HttpReply::parseFirstLine(const char *start, const char *end) STUB_RETVAL(false)
-void HttpReply::hdrCacheInit() STUB
-HttpReply * HttpReply::clone() const STUB_RETVAL(NULL)
-bool HttpReply::inheritProperties(const HttpMsg *aMsg) STUB_RETVAL(false)
-int64_t HttpReply::bodySize(const HttpRequestMethod&) const STUB_RETVAL(0)
+HttpReply::HttpReply() : HttpMsg(hoReply), date (0), last_modified (0),
+        expires (0), surrogate_control (NULL), content_range (NULL), keep_alive (0),
+        protoPrefix("HTTP/"), bodySizeMax(-2)
+        STUB_NOP
+        HttpReply::~HttpReply() STUB
+        void HttpReply::setHeaders(http_status status, const char *reason, const char *ctype, int64_t clen, time_t lmt, time_t expires_) STUB
+        void HttpReply::packHeadersInto(Packer * p) const STUB
+        void HttpReply::reset() STUB
+        void httpBodyPackInto(const HttpBody * body, Packer * p) STUB
+        bool HttpReply::sanityCheckStartLine(MemBuf *buf, const size_t hdr_len, http_status *error) STUB_RETVAL(false)
+        int HttpReply::httpMsgParseError() STUB_RETVAL(0)
+        bool HttpReply::expectingBody(const HttpRequestMethod&, int64_t&) const STUB_RETVAL(false)
+        void HttpReply::packFirstLineInto(Packer * p, bool) const STUB
+        bool HttpReply::parseFirstLine(const char *start, const char *end) STUB_RETVAL(false)
+        void HttpReply::hdrCacheInit() STUB
+        HttpReply * HttpReply::clone() const STUB_RETVAL(NULL)
+        bool HttpReply::inheritProperties(const HttpMsg *aMsg) STUB_RETVAL(false)
+        int64_t HttpReply::bodySize(const HttpRequestMethod&) const STUB_RETVAL(0)
@@ -10,8 +10,7 @@
 #include "tests/STUB.h"
 
 #include "ssl/Config.h"
-Ssl::Config::Config() { printf("Ssl::Config::Config No implemented\n"); }
-Ssl::Config::~Config() { printf("Ssl::Config::Config No implemented\n"); }
+Ssl::Config::~Config() STUB_NOP
 Ssl::Config Ssl::TheConfig;
 
 #include "ssl/context_storage.h"
@@ -190,7 +190,7 @@ testCoss::testCossSearch()
     {
         /* Create "vary" base object */
         RequestFlags flags;
-        flags.cachable = 1;
+        flags.cachable = true;
         StoreEntry *pe = storeCreateEntry("dummy url", "dummy log url", flags, METHOD_GET);
         HttpReply *rep = (HttpReply *) pe->getReply();	// bypass const
         rep->setHeaders(HTTP_OK, "dummy test object", "x-squid-internal/test", -1, -1, squid_curtime + 100000);
@@ -172,7 +172,7 @@ StoreEntry *
 testRock::createEntry(const int i)
 {
     RequestFlags flags;
-    flags.cachable = 1;
+    flags.cachable = true;
     char url[64];
     snprintf(url, sizeof(url), "dummy url %i", i);
     url[sizeof(url) - 1] = '\0';
@@ -15,6 +15,7 @@ class testRock : public CPPUNIT_NS::TestFixture
     CPPUNIT_TEST_SUITE_END();
 
 public:
+    testRock() : rr(NULL) {}
     virtual void setUp();
     virtual void tearDown();
 
@@ -142,7 +142,7 @@ testUfs::testUfsSearch()
     {
         /* Create "vary" base object */
         RequestFlags flags;
-        flags.cachable = 1;
+        flags.cachable = true;
         StoreEntry *pe = storeCreateEntry("dummy url", "dummy log url", flags, Http::METHOD_GET);
         HttpReply *rep = (HttpReply *) pe->getReply();	// bypass const
         rep->setHeaders(HTTP_OK, "dummy test object", "x-squid-internal/test", -1, -1, squid_curtime + 100000);
@@ -46,6 +46,7 @@
 #include "http.h"
 #include "HttpRequest.h"
 #include "HttpStateFlags.h"
+#include "ip/QosConfig.h"
 #include "MemBuf.h"
 #include "PeerSelectState.h"
 #include "SquidConfig.h"
@@ -580,6 +581,15 @@ tunnelConnectDone(const Comm::ConnectionPointer &conn, comm_err_t status, int xe
         tunnelState->serverDestinations.shift();
         if (status != COMM_TIMEOUT && tunnelState->serverDestinations.size() > 0) {
             /* Try another IP of this destination host */
+
+            if (Ip::Qos::TheConfig.isAclTosActive()) {
+                tunnelState->serverDestinations[0]->tos = GetTosToServer(tunnelState->request);
+            }
+
+#if SO_MARK && USE_LIBCAP
+            tunnelState->serverDestinations[0]->nfmark = GetNfmarkToServer(tunnelState->request);
+#endif
+
             debugs(26, 4, HERE << "retry with : " << tunnelState->serverDestinations[0]);
             AsyncCall::Pointer call = commCbCall(26,3, "tunnelConnectDone", CommConnectCbPtrFun(tunnelConnectDone, tunnelState));
             Comm::ConnOpener *cs = new Comm::ConnOpener(tunnelState->serverDestinations[0], call, Config.Timeout.connect);
@@ -614,10 +624,10 @@ tunnelConnectDone(const Comm::ConnectionPointer &conn, comm_err_t status, int xe
     debugs(26, 4, HERE << "determine post-connect handling pathway.");
     if (conn->getPeer()) {
         tunnelState->request->peer_login = conn->getPeer()->login;
-        tunnelState->request->flags.proxying = (conn->getPeer()->options.originserver?0:1);
+        tunnelState->request->flags.proxying = !(conn->getPeer()->options.originserver);
     } else {
         tunnelState->request->peer_login = NULL;
-        tunnelState->request->flags.proxying = 0;
+        tunnelState->request->flags.proxying = false;
     }
 
     if (tunnelState->request->flags.proxying)
@@ -746,6 +756,14 @@ tunnelPeerSelectComplete(Comm::ConnectionList *peer_paths, ErrorState *err, void
     }
     delete err;
 
+    if (Ip::Qos::TheConfig.isAclTosActive()) {
+        tunnelState->serverDestinations[0]->tos = GetTosToServer(tunnelState->request);
+    }
+
+#if SO_MARK && USE_LIBCAP
+    tunnelState->serverDestinations[0]->nfmark = GetNfmarkToServer(tunnelState->request);
+#endif
+
     debugs(26, 3, HERE << "paths=" << peer_paths->size() << ", p[0]={" << (*peer_paths)[0] << "}, serverDest[0]={" <<
            tunnelState->serverDestinations[0] << "}");
 