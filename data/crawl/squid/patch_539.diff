@@ -36,8 +36,8 @@ class RequestFlags {
 public:
     RequestFlags():
         nocache(0), ims(0), auth(0), cachable(0),
-        hierarchical(0), loopdetect(0), proxy_keepalive(0), proxying(0),
-        refresh(0), redirected(false), need_validation(false),
+        hierarchical(0), loopdetect(false), proxy_keepalive(false), proxying_(false),
+        refresh_(false), redirected(false), need_validation(false),
         fail_on_validation_err(false), stale_if_hit(false), nocache_hack(false), accelerated_(false),
         ignore_cc(false), intercepted_(false), hostVerified_(false), spoof_client_ip(false),
         internal(false), internalclient(false), must_keepalive(false), connection_auth_wanted(false), connection_auth_disabled(false), connection_proxy_auth(false), pinned_(false),
@@ -53,10 +53,6 @@ class RequestFlags {
     unsigned int auth :1;
     unsigned int cachable :1; ///< whether the response to thie request may be stored in the cache
     unsigned int hierarchical :1;
-    unsigned int loopdetect :1;
-    unsigned int proxy_keepalive :1;
-    unsigned int proxying :1; /* this should be killed, also in httpstateflags */
-    unsigned int refresh :1;
 
     // When adding new flags, please update cloneAdaptationImmune() as needed.
     bool resetTCP() const;
@@ -160,7 +156,25 @@ class RequestFlags {
 
     bool isRedirected() const { return redirected; }
     void markRedirected() { redirected=true; }
+
+    bool refresh() const { return refresh_; }
+    void setRefresh() { refresh_ = true; }
+
+    bool proxying() const { return proxying_; }
+    void setProxying() { proxying_ = true; }
+    void clearProxying() { proxying_ = false; }
+
+    bool proxyKeepalive() const { return proxy_keepalive; }
+    void setProxyKeepalive() { proxy_keepalive=true;}
+    void clearProxyKeepalive() { proxy_keepalive=false; }
+
+    bool loopDetect() const { return loopdetect; }
+    void setLoopDetect() { loopdetect = 1; }
 private:
+    bool loopdetect :1;
+    bool proxy_keepalive :1;
+    bool proxying_ :1; /* this should be killed, also in httpstateflags */
+    bool refresh_ :1;
     bool redirected :1;
     bool need_validation :1;
     bool fail_on_validation_err :1; ///< whether we should fail if validation fails
@@ -287,7 +287,7 @@ Auth::Negotiate::UserRequest::HandleReply(void *data, void *lastserver, char *re
         }
         safe_free(lm_request->server_blob);
         lm_request->request->flags.setMustKeepalive();
-        if (lm_request->request->flags.proxy_keepalive) {
+        if (lm_request->request->flags.proxyKeepalive()) {
             lm_request->server_blob = xstrdup(blob);
             auth_user_request->user()->credentials(Auth::Handshake);
             auth_user_request->denyMessage("Authentication in progress");
@@ -218,7 +218,7 @@ Auth::Negotiate::Config::fixHeader(Auth::UserRequest::Pointer auth_user_request,
         return;
 
     /* Need keep-alive */
-    if (!request->flags.proxy_keepalive && request->flags.mustKeepalive())
+    if (!request->flags.proxyKeepalive() && request->flags.mustKeepalive())
         return;
 
     /* New request, no user details */
@@ -229,7 +229,7 @@ Auth::Negotiate::Config::fixHeader(Auth::UserRequest::Pointer auth_user_request,
         if (!keep_alive) {
             /* drop the connection */
             rep->header.delByName("keep-alive");
-            request->flags.proxy_keepalive = 0;
+            request->flags.clearProxyKeepalive();
         }
     } else {
         Auth::Negotiate::UserRequest *negotiate_request = dynamic_cast<Auth::Negotiate::UserRequest *>(auth_user_request.getRaw());
@@ -241,7 +241,7 @@ Auth::Negotiate::Config::fixHeader(Auth::UserRequest::Pointer auth_user_request,
             /* here it makes sense to drop the connection, as auth is
              * tied to it, even if MAYBE the client could handle it - Kinkie */
             rep->header.delByName("keep-alive");
-            request->flags.proxy_keepalive = 0;
+            request->flags.clearProxyKeepalive();
             /* fall through */
 
         case Auth::Ok:
@@ -270,7 +270,7 @@ Auth::Ntlm::UserRequest::HandleReply(void *data, void *lastserver, char *reply)
         /* we have been given a blob to send to the client */
         safe_free(lm_request->server_blob);
         lm_request->request->flags.setMustKeepalive();
-        if (lm_request->request->flags.proxy_keepalive) {
+        if (lm_request->request->flags.proxyKeepalive()) {
             lm_request->server_blob = xstrdup(blob);
             auth_user_request->user()->credentials(Auth::Handshake);
             auth_user_request->denyMessage("Authentication in progress");
@@ -205,7 +205,7 @@ Auth::Ntlm::Config::fixHeader(Auth::UserRequest::Pointer auth_user_request, Http
         return;
 
     /* Need keep-alive */
-    if (!request->flags.proxy_keepalive && request->flags.mustKeepalive())
+    if (!request->flags.proxyKeepalive() && request->flags.mustKeepalive())
         return;
 
     /* New request, no user details */
@@ -215,7 +215,7 @@ Auth::Ntlm::Config::fixHeader(Auth::UserRequest::Pointer auth_user_request, Http
 
         if (!keep_alive) {
             /* drop the connection */
-            request->flags.proxy_keepalive = 0;
+            request->flags.clearProxyKeepalive();
         }
     } else {
         Auth::Ntlm::UserRequest *ntlm_request = dynamic_cast<Auth::Ntlm::UserRequest *>(auth_user_request.getRaw());
@@ -226,7 +226,7 @@ Auth::Ntlm::Config::fixHeader(Auth::UserRequest::Pointer auth_user_request, Http
         case Auth::Failed:
             /* here it makes sense to drop the connection, as auth is
              * tied to it, even if MAYBE the client could handle it - Kinkie */
-            request->flags.proxy_keepalive = 0;
+            request->flags.clearProxyKeepalive();
             /* fall through */
 
         case Auth::Ok:
@@ -849,7 +849,10 @@ clientSetKeepaliveFlag(ClientHttpRequest * http)
            RequestMethodStr(request->method));
 
     // TODO: move to HttpRequest::hdrCacheInit, just like HttpReply.
-    request->flags.proxy_keepalive = request->persistent() ? 1 : 0;
+    if (request->persistent())
+        request->flags.setProxyKeepalive();
+    else
+        request->flags.clearProxyKeepalive();
 }
 
 static int
@@ -1739,7 +1742,7 @@ ClientSocketContext::socketState()
                 debugs(33, 5, HERE << "Range request at end of returnable " <<
                        "range sequence on " << clientConnection);
 
-                if (http->request->flags.proxy_keepalive)
+                if (http->request->flags.proxyKeepalive())
                     return STREAM_COMPLETE;
                 else
                     return STREAM_UNPLANNED_COMPLETE;
@@ -1756,7 +1759,7 @@ ClientSocketContext::socketState()
             // did we get at least what we expected, based on range specs?
 
             if (bytesSent == bytesExpected) { // got everything
-                if (http->request->flags.proxy_keepalive)
+                if (http->request->flags.proxyKeepalive())
                     return STREAM_COMPLETE;
                 else
                     return STREAM_UNPLANNED_COMPLETE;
@@ -1766,7 +1769,7 @@ ClientSocketContext::socketState()
             // expected why would persistency matter? Should not this
             // always be an error?
             if (bytesSent > bytesExpected) { // got extra
-                if (http->request->flags.proxy_keepalive)
+                if (http->request->flags.proxyKeepalive())
                     return STREAM_COMPLETE;
                 else
                     return STREAM_UNPLANNED_COMPLETE;
@@ -2472,7 +2475,7 @@ ConnStateData::quitAfterError(HttpRequest *request)
     // at the client-side, but many such errors do require closure and the
     // client-side code is bad at handling errors so we play it safe.
     if (request)
-        request->flags.proxy_keepalive = 0;
+        request->flags.clearProxyKeepalive();
     flags.readMore = false;
     debugs(33,4, HERE << "Will close after error: " << clientConnection);
 }
@@ -129,7 +129,7 @@ void clientReplyContext::setReplyToError(const HttpRequestMethod& method, ErrorS
 {
     if (errstate->httpStatus == HTTP_NOT_IMPLEMENTED && http->request)
         /* prevent confusion over whether we default to persistent or not */
-        http->request->flags.proxy_keepalive = 0;
+        http->request->flags.clearProxyKeepalive();
 
     http->al->http.code = errstate->httpStatus;
 
@@ -273,7 +273,7 @@ clientReplyContext::processExpired()
         return;
     }
 
-    http->request->flags.refresh = 1;
+    http->request->flags.setRefresh();
 #if STORE_CLIENT_LIST_DEBUG
     /* Prevent a race with the store client memory free routines
      */
@@ -651,7 +651,7 @@ clientReplyContext::processMiss()
     }
 
     /// Deny loops
-    if (r->flags.loopdetect) {
+    if (r->flags.loopDetect()) {
         http->al->http.code = HTTP_FORBIDDEN;
         err = clientBuildError(ERR_ACCESS_DENIED, HTTP_FORBIDDEN, NULL, http->getConn()->clientConnection->remote, http->request);
         createStoreEntry(r->method, RequestFlags());
@@ -1183,7 +1183,7 @@ clientReplyContext::replyStatus()
 
         const int64_t expectedBodySize =
             http->storeEntry()->getReply()->bodySize(http->request->method);
-        if (!http->request->flags.proxy_keepalive && expectedBodySize < 0) {
+        if (!http->request->flags.proxyKeepalive() && expectedBodySize < 0) {
             debugs(88, 5, "clientReplyStatus: closing, content_length < 0");
             return STREAM_FAILED;
         }
@@ -1198,7 +1198,7 @@ clientReplyContext::replyStatus()
             return STREAM_UNPLANNED_COMPLETE;
         }
 
-        if (http->request->flags.proxy_keepalive) {
+        if (http->request->flags.proxyKeepalive()) {
             debugs(88, 5, "clientReplyStatus: stream complete and can keepalive");
             return STREAM_COMPLETE;
         }
@@ -1458,31 +1458,31 @@ clientReplyContext::buildReplyHeader()
     /* Check whether we should send keep-alive */
     if (!Config.onoff.error_pconns && reply->sline.status >= 400 && !request->flags.mustKeepalive()) {
         debugs(33, 3, "clientBuildReplyHeader: Error, don't keep-alive");
-        request->flags.proxy_keepalive = 0;
+        request->flags.clearProxyKeepalive();
     } else if (!Config.onoff.client_pconns && !request->flags.mustKeepalive()) {
         debugs(33, 2, "clientBuildReplyHeader: Connection Keep-Alive not requested by admin or client");
-        request->flags.proxy_keepalive = 0;
-    } else if (request->flags.proxy_keepalive && shutting_down) {
+        request->flags.clearProxyKeepalive();
+    } else if (request->flags.proxyKeepalive() && shutting_down) {
         debugs(88, 3, "clientBuildReplyHeader: Shutting down, don't keep-alive.");
-        request->flags.proxy_keepalive = 0;
+        request->flags.clearProxyKeepalive();
     } else if (request->flags.connectionAuthWanted() && !reply->keep_alive) {
         debugs(33, 2, "clientBuildReplyHeader: Connection oriented auth but server side non-persistent");
-        request->flags.proxy_keepalive = 0;
+        request->flags.clearProxyKeepalive();
     } else if (reply->bodySize(request->method) < 0 && !maySendChunkedReply) {
         debugs(88, 3, "clientBuildReplyHeader: can't keep-alive, unknown body size" );
-        request->flags.proxy_keepalive = 0;
+        request->flags.clearProxyKeepalive();
     } else if (fdUsageHigh()&& !request->flags.mustKeepalive()) {
         debugs(88, 3, "clientBuildReplyHeader: Not many unused FDs, can't keep-alive");
-        request->flags.proxy_keepalive = 0;
+        request->flags.clearProxyKeepalive();
     } else if (request->flags.sslBumped() && !reply->persistent()) {
         // We do not really have to close, but we pretend we are a tunnel.
         debugs(88, 3, "clientBuildReplyHeader: bumped reply forces close");
-        request->flags.proxy_keepalive = 0;
+        request->flags.clearProxyKeepalive();
     }
 
     // Decide if we send chunked reply
     if (maySendChunkedReply &&
-            request->flags.proxy_keepalive &&
+            request->flags.proxyKeepalive() &&
             reply->bodySize(request->method) < 0) {
         debugs(88, 3, "clientBuildReplyHeader: chunked reply");
         request->flags.markReplyChunked();
@@ -1503,7 +1503,7 @@ clientReplyContext::buildReplyHeader()
         hdr->putStr(HDR_VIA, strVia.termedBuf());
     }
     /* Signal keep-alive or close explicitly */
-    hdr->putStr(HDR_CONNECTION, request->flags.proxy_keepalive ? "keep-alive" : "close");
+    hdr->putStr(HDR_CONNECTION, request->flags.proxyKeepalive() ? "keep-alive" : "close");
 
 #if ADD_X_REQUEST_URI
     /*
@@ -954,7 +954,7 @@ clientHierarchical(ClientHttpRequest * http)
         if (strstr(url, p->key))
             return 0;
 
-    if (request->flags.loopdetect)
+    if (request->flags.loopDetect())
         return 0;
 
     if (request->protocol == AnyP::PROTO_HTTP)
@@ -1152,7 +1152,7 @@ clientInterpretRequestHeaders(ClientHttpRequest * http)
         if (strListIsSubstr(&s, ThisCache2, ',')) {
             debugObj(33, 1, "WARNING: Forwarding loop detected for:\n",
                      request, (ObjPackMethod) & httpRequestPack);
-            request->flags.loopdetect = 1;
+            request->flags.setLoopDetect();
         }
 
 #if USE_FORW_VIA_DB
@@ -120,7 +120,7 @@ HttpStateData::HttpStateData(FwdState *theFwdState) : AsyncJob("HttpStateData"),
         _peer = cbdataReference(fwd->serverConnection()->getPeer());         /* might be NULL */
 
     if (_peer) {
-        request->flags.proxying = 1;
+        request->flags.setProxying();
         /*
          * This NEIGHBOR_PROXY_ONLY check probably shouldn't be here.
          * We might end up getting the object from somewhere else if,
@@ -1530,7 +1530,7 @@ httpFixupAuthentication(HttpRequest * request, const HttpHeader * hdr_in, HttpHe
     http_hdr_type header = flags.originpeer ? HDR_AUTHORIZATION : HDR_PROXY_AUTHORIZATION;
 
     /* Nothing to do unless we are forwarding to a peer */
-    if (!request->flags.proxying)
+    if (!request->flags.proxying())
         return;
 
     /* Needs to be explicitly enabled */
@@ -1736,7 +1736,7 @@ HttpStateData::httpBuildRequestHeader(HttpRequest * request,
 
     /* append Authorization if known in URL, not in header and going direct */
     if (!hdr_out->has(HDR_AUTHORIZATION)) {
-        if (!request->flags.proxying && request->login && *request->login) {
+        if (!request->flags.proxying() && request->login && *request->login) {
             httpHeaderPutStrf(hdr_out, HDR_AUTHORIZATION, "Basic %s",
                               old_base64_encode(request->login));
         }
@@ -1344,7 +1344,7 @@ netdbExchangeStart(void *data)
     tempBuffer.data = ex->buf;
     storeClientCopy(ex->sc, ex->e, tempBuffer,
                     netdbExchangeHandleReply, ex);
-    ex->r->flags.loopdetect = 1;	/* cheat! -- force direct */
+    ex->r->flags.setLoopDetect();	/* cheat! -- force direct */
 
     if (p->login)
         xstrncpy(ex->r->login, p->login, MAX_LOGIN_SZ);
@@ -161,16 +161,16 @@ peerAllowedToUse(const CachePeer * p, HttpRequest * request)
     if (neighborType(p, request) == PEER_SIBLING) {
 #if PEER_MULTICAST_SIBLINGS
         if (p->type == PEER_MULTICAST && p->options.mcast_siblings &&
-                (request->flags.nocache || request->flags.refresh || request->flags.loopdetect || request->flags.validationNeeded()))
+                (request->flags.nocache || request->flags.refresh() || request->flags.loopDetect() || request->flags.validationNeeded()))
             debugs(15, 2, "peerAllowedToUse(" << p->name << ", " << request->GetHost() << ") : multicast-siblings optimization match");
 #endif
         if (request->flags.nocache)
             return false;
 
-        if (request->flags.refresh)
+        if (request->flags.refresh())
             return false;
 
-        if (request->flags.loopdetect)
+        if (request->flags.loopDetect())
             return false;
 
         if (request->flags.validationNeeded())
@@ -373,7 +373,7 @@ peerDigestRequest(PeerDigest * pd)
     req->flags.cachable = 1;
 
     /* the rest is based on clientProcessExpired() */
-    req->flags.refresh = 1;
+    req->flags.setRefresh();
 
     old_e = fetch->old_entry = Store::Root().get(key);
 
@@ -429,26 +429,26 @@ peerSelectFoo(ps_state * ps)
     HttpRequest *request = ps->request;
     debugs(44, 3, "peerSelectFoo: '" << RequestMethodStr(request->method) << " " << request->GetHost() << "'");
 
-    /** If we don't know whether DIRECT is permitted ... */
+    /* If we don't know whether DIRECT is permitted ... */
     if (ps->direct == DIRECT_UNKNOWN) {
         if (ps->always_direct == ACCESS_DUNNO) {
             debugs(44, 3, "peerSelectFoo: direct = " << DirectStr[ps->direct] << " (always_direct to be checked)");
-            /** check always_direct; */
+            /* check always_direct; */
             ps->acl_checklist = new ACLFilledChecklist(Config.accessList.AlwaysDirect, request, NULL);
             ps->acl_checklist->nonBlockingCheck(peerCheckAlwaysDirectDone, ps);
             return;
         } else if (ps->never_direct == ACCESS_DUNNO) {
             debugs(44, 3, "peerSelectFoo: direct = " << DirectStr[ps->direct] << " (never_direct to be checked)");
-            /** check never_direct; */
+            /* check never_direct; */
             ps->acl_checklist = new ACLFilledChecklist(Config.accessList.NeverDirect, request, NULL);
             ps->acl_checklist->nonBlockingCheck(peerCheckNeverDirectDone, ps);
             return;
         } else if (request->flags.noDirect()) {
-            /** if we are accelerating, direct is not an option. */
+            /* if we are accelerating, direct is not an option. */
             ps->direct = DIRECT_NO;
             debugs(44, 3, "peerSelectFoo: direct = " << DirectStr[ps->direct] << " (forced non-direct)");
-        } else if (request->flags.loopdetect) {
-            /** if we are in a forwarding-loop, direct is not an option. */
+        } else if (request->flags.loopDetect()) {
+            /* if we are in a forwarding-loop, direct is not an option. */
             ps->direct = DIRECT_YES;
             debugs(44, 3, "peerSelectFoo: direct = " << DirectStr[ps->direct] << " (forwarding loop detected)");
         } else if (peerCheckNetdbDirect(ps)) {
@@ -605,13 +605,16 @@ tunnelConnectDone(const Comm::ConnectionPointer &conn, comm_err_t status, int xe
     debugs(26, 4, HERE << "determine post-connect handling pathway.");
     if (conn->getPeer()) {
         tunnelState->request->peer_login = conn->getPeer()->login;
-        tunnelState->request->flags.proxying = (conn->getPeer()->options.originserver?0:1);
+        if (conn->getPeer()->options.originserver)
+            tunnelState->request->flags.setProxying();
+        else
+            tunnelState->request->flags.clearProxying();
     } else {
         tunnelState->request->peer_login = NULL;
-        tunnelState->request->flags.proxying = 0;
+        tunnelState->request->flags.clearProxying();
     }
 
-    if (tunnelState->request->flags.proxying)
+    if (tunnelState->request->flags.proxying())
         tunnelRelayConnectRequest(conn, tunnelState);
     else {
         tunnelConnected(conn, tunnelState);
@@ -695,7 +698,7 @@ tunnelRelayConnectRequest(const Comm::ConnectionPointer &srv, void *data)
     http_state_flags flags;
     debugs(26, 3, HERE << srv << ", tunnelState=" << tunnelState);
     memset(&flags, '\0', sizeof(flags));
-    flags.proxying = tunnelState->request->flags.proxying;
+    flags.proxying = tunnelState->request->flags.proxying();
     MemBuf mb;
     mb.init();
     mb.Printf("CONNECT %s HTTP/1.1\r\n", tunnelState->url);