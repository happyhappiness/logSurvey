@@ -1,20 +1,30 @@
 Special thanks go to people who have volunteered their time, effort,
 and ideas to make this software available.
 
+    'noloader' <noloader@gmail.com>
     Adam Ciarcinski
     Adrian Chadd <adrian@squid-cache.org>
+    Alan Mizrahi <alan@mizrahi.com.ve>
     Alex Rousskov <rousskov@measurement-factory.com>
     Alexander B. Demenshin <aldem@barnet.kharkov.ua>
+    Alexander Komyagin <komyagin@altell.ru>
     Alexander Lukyanov <lav@yar.ru>
+    Alexandre Chappaz <alexandrechappaz@gmail.com>
     Alexey Veselovsky <alexey.veselovsky@eykontech.com>
+    Alexis Robert <alexis.robert@gmail.com>
     Alin Nastac <mrness@gentoo.org>
     Alter <alter@alter.org.ua>
     Amos Jeffries <amosjeffries@squid-cache.org>
     Amos Jeffries <squid3@treenet.co.nz>
+    Anatoli <me@anatoli.ws>
+    Andrea Gagliardi <andrea@netlite.it>
+    Andreas Jaeger <aj@suse.com>
     Andreas Lamprecht <Andreas.Lamprecht@siemens.at>
     Andres Kroonmaa <andre@ml.ee>
+    Andrew Beverley <andy@andybev.com>
     Andrew Hoying <andrew_hoying@blm.gov>
     Andrey Shorin <tolsty@tushino.com>
+    Anonymous <redskilldough@gmail.com>
     Ansgar Hockmann <Ansgar.Hockmann@hrz.uni-dortmund.de>
     Anthony Baxter <arb@connect.com.au>
     Arjan de Vet <Arjan.deVet@adv.IAEhv.nl>
@@ -23,7 +33,9 @@ and ideas to make this software available.
     Assar Westerlund <assar@pdc.kth.se>
     Automatic source maintenance <squidadm@squid-cache.org>
     Axel Westerhold <ml.awesterhold@dts.de>
+    Benjamin Kerensa <bkerensa@ubuntu.com>
     Benno Rice <benno@squid-cache.org>
+    Bernard <fli4l.charrier@free.fr>
     Bertrand Jacquin <beber@meleeweb.net>
     Bojan Smojver <bojan@rexursive.com>
     Brad Smith <brad@comstyle.com>
@@ -32,13 +44,17 @@ and ideas to make this software available.
     Brian Denehy <B-Denehy@adfa.oz.au>
     Bruce Murphy <pack-squid@rattus.net>
     Carson Gaspar (carson@lehman.com, carson@cs.columbia.edu)
+    Changming <me@sunchangming.com>
     Chris Hills <chaz@chaz6.com>
     Christos Tsantilas <chtsanti@users.sourceforge.net>
     Cloyce <cloyce.spradling@sun.com>
     Constantin Rack
     Cord Beermann <cord@cc.fh-lippe.de>
+    Daniel Beschorner <daniel.beschorner@evlks.de>
     Daniel O'Callaghan <danny@miriworld.its.unimelb.EDU.AU>
+    David Isaacs <david.isaacs@sbhs.nsw.edu.au>
     David Luyer <luyer@ucs.uwa.edu.au>
+    Dennis Glatting
     Dhaval Varia
     Diego Woitasen <diegows@xtech.com.ar>
     Dmitry Kurochkin
@@ -50,20 +66,26 @@ and ideas to make this software available.
     Dustin J. Mitchell
     Ed Knowles <ed@fatboy.geog.unsw.edu.au>
     Edward Moy <moy@parc.xerox.com>
+    Eliezer Croitoru <eliezer@ngtech.co.il>
+    Elmar Vonlanthen <Elmar.Vonlanthen@united-security-providers.ch>
     Emilio Casbas <ecasbas@unav.es>
     Endre Balint Nagy <bne@CareNet.hu>
+    Eray Aslan <eray.aslan@caf.com.tr>
     Eric Stern <estern@logisense.com>
     Eugene Gladchenko <eugene@donpac.ru>
     Evan Jones <ejones@uwaterloo.ca>
+    Eygene Ryabinkin <rea@freebsd.org>
     Felix Meschberger <felix.meschberger@day.com>
     Finn Thain <fthain@telegraphics.com.au>
     Flavio Pescuma <flavio@marasystems.com>
+    Francesco <kinkie@squid-cache.org>
     Francesco Chemolli <kinkie@squid-cache.org>
     Francesco Salvestrini
     Francis Daly <francis@daoine.org>
     Francois Cami <fcami@winsoft.fr>
     Frank Balluffi
     Frank Schmirler <squid@schmirler.de>
+    Frederic Bourgeois <fredbmail@free.fr>
     Geoff Keating <Geoff.Keating@anu.edu.au>
     George Michaelson <ggm@connect.com.au>
     Georgy Salnikov <sge@nmr.nioch.nsc.ru>
@@ -85,24 +107,29 @@ and ideas to make this software available.
     Igor Vinokurov <igor@cs.ibank.ru>
     Isnard <isnardjaquet@gmail.com>
     JPP <jpp1@frws.com>
+    Jakob Bohm <jb-debbugs@wisemo.com>
     Jakub Wilk <ubanus@users.sf.net>
     James Brotchie <brotchie@gmail.com>
     James R Grinter <jrg@demon.net>
     Jan Niehusmann <jan@anduin.gondor.mcs.de>
+    Jan Sievers <sievers@zedat.fu-berlin.de>
     Jean-Francois Micouleau <Jean-Francois.Micouleau@utc.fr>
     Jean-Gabriel Dick <jean-gabriel.dick@curie.fr>
+    Jean-Philippe Menil <jean-philippe.menil@univ-nantes.fr>
     Jerry Murdock <jmurdock@itraktech.com>
     Joachim Bauch <jojo@fistofbenztown.de>
     Joao Alves Neto <alves_joao@hotmail.com>
     Jochen Voss <voss@seehuhn.de>
     Joe Ramey <ramey@jello.csc.ti.com>
     John Dilley <jad@hpl.hp.com>
     John Saunders <johns@rd.scitec.com.au>
+    John Xue <xgxjohn@gmail.com>
     Johnathan Conley <johnathan.conley@gmail.com>
     Jon Thackray <jrmt@uk.gdscorp.com>
     Jonathan Larmour <JLarmour@origin-at.co.uk>
     Joshua Root <josh+squid@root.id.au>
     Kieran Whitbread <k.j.whitbread@qmul.ac.uk>
+    Kinkie <kinkie@squid-cache.org>
     Klaubert Herr <klaubert@gmail.com>
     Klaus Singvogel <kssingvo@suse.de>
     Kolics Bertold <bertold@tohotom.vein.hu>
@@ -115,15 +142,19 @@ and ideas to make this software available.
     Lutz Donnerhacke <lutz@iks-jena.de>
     Manu Garg <manugarg@gmail.com>
     Marin Stavrev <mstavrev@gmail.com>
+    Marios Makassikis <mmakassikis@gmail.com>
     Mark Bergsma <mark@nedworks.org>
     Mark Nottingham <mnot@pobox.com>
     Mark Treacy <mark@aone.com.au>
     Marko <mr_4u2@yahoo.com>
+    Marko Cupac <marko.cupac@mimar.rs>
     Markus Gyger <mgyger@itr.ch>
     Markus Moeller <huaraz@moeller.plus.com>
+    Markus Rietzler <markus.rietzler@rzf.fin-nrw.de>
     Markus Stumpf <maex@Space.NET>
     Martin Hamilton <martin@mrrl.lut.ac.uk>
     Martin Huter <m.huter@phion.com>
+    Martin Stolle <martin.stolle@ekom21.de>
     Masashi Fujita <objectx@bandit.co.jp>
     Massimo Zito <zmax.linkedin at gmail dot com>
     Matthew Morgan <atcs.matthew@gmail.com>
@@ -134,16 +165,22 @@ and ideas to make this software available.
     Michael O'Reilly <michael@metal.iinet.net.au>
     Michael Pelletier <mikep@comshare.com>
     Michael van Elst
+    Michal Luscon <mluscon@redhat.com>
     Miguel A.L. Paraz <map@iphil.net>
     Mike Groeneweg <mikeg@scorpion.murdoch.edu.au>
     Mike Mitchell <Mike.Mitchell@sas.com>
     Mikio Kishi <mkishi@104.net>
+    Ming Fu <mfu@watchguard.com>
     Miquel van Smoorenburg <miquels@cistron.nl>
     Moez Mahfoudh <moez.mahfoudh@imag.fr>
     Mukaigawa Shin'ichi <shin@nff.ncl.omron.co.jp>
+    Nathan Hoad <nathan@getoffmalawn.com>
     Neil Murray <neil@aone.com.au>
     Niall Doherty <ndoherty@eei.ericsson.se>
+    Nick Rogers <ncrogers@gmail.com>
+    Nikolai Gorchilov <niki@x3me.net>
     Oskar Pearson <oskar@is.co.za>
+    Paul Z <paulz42@gmail.com>
     Pawel Worach <pawel.worach@gmail.com>
     Pedro Lineu Orso <orso@pop.hsbcbamerindus.com.br>
     Pedro Ribeiro <pribeiro@isel.pt>
@@ -153,47 +190,72 @@ and ideas to make this software available.
     Philip Allison <philip.allison@smoothwall.net>
     Philippe Lantin <plantin@cobaltgroup.com>
     Pierangelo Masarati <ando@sys-net.it>
+    Pierre-Louis BRENAC <brenacp@esiee.fr>
     Pierre-Louis Brenac <brenacp@esiee.fr>
+    Priyanka Gupta <priyanka@icelero.com>
     Przemek Czerkas <pczerkas@mgmnet.pl>
     Rafael Martinez Torres <rmartine@fdi.ucm.es>
     Rafal Ramocki <maniac@sistbg.net>
+    Rajiv Desai <rajiv@maginatics.com>
     Ralf Wildenhues <Ralf.Wildenhues@gmx.de>
     Ralph Loader <loader@maths.ox.ac.uk>
     Regardt van de Vyver <squid@vdvyver.net>
     Reinhard Sojka <reinhard.sojka@parlament.gv.at>
     Rene Geile <rene.geile@t-online.de>
     Reuben Farrelly <reuben@reub.net>
     Richard Huveneers <Richard.Huveneers@hekkihek.hacom.nl>
+    Richard Wall <richard.wall@appliansys.com>
     Robert Collins <robertc@robertcollins.net>
     Robert Forster
+    Rodrigo Campos (rodrigo@geekbunker.org)
     Rodrigo Campos <rodrigo@geekbunker.org>
     Ron Gomes <rrg@ny.ubs.com>
     Russell Street <r.street@auckland.ac.nz>
     Russell Vincent <vincent@ucthpx.uct.ac.za>
     Ryan Troll <ryan+@andrew.cmu.edu>
     Scott Schram <scott@schram.net>
+    Sebastien Wenske <sebastien@wenske.fr>
     Sergio Rabellino <rabellino@di.unito.it>
     Shigechika Aikawa <shige@luck.imasy.or.jp>
+    Silamael <Silamael@coronamundi.de>
     Stefan Fritsch <sf@sfritsch.de>
+    Stefano Cordibella <stefano.cordibella@edalab.it>
     Stephen R. van den Berg <srb@cuci.nl>
     Steve Bennett <S.Bennett@lancaster.ac.uk>
+    Steve Hill <steve@opendium.com>
     Steve Snyder <swsnyder@snydernet.net>
     Steven Wilton <swilton@q-net.net.au>
     Stewart Forster <slf@connect.com.au>
+    Stuart Henderson <sthen@openbsd.org>
+    Susant Sahani <ssahani@redhat.com>
     Svenx <svensven@gmail.com>
     Taavi Talvik <taavi@uninet.ee>
     Taketo Kabe <kabe@shiratori.riec.tohoku.ac.jp>
+    Thomas De Schampheleire <thomas.de.schampheleire@gmail.com>
+    Thomas Hozza <thozza@redhat.com>
     Thomas Ristic <thr@bootet.net>
+    Thomas Weber <x@4t2.com>
     Thomas-Martin Seck <tmseck@netcologne.de>
+    Tianyin Xu <tixu@cs.ucsd.edu>
     Tim Starling <tstarling@wikimedia.org>
+    Tomas Hozza <thozza@redhat.com>
     Tony Lorimer <tlorimer@au.mdis.com>
     Unknown - NetBSD Project
+    Unknown FreeBSD Contributor
     Vincent Regnard
+    Vitaliy Matytsyn (main) <vm@if.bank.gov.ua>
     Vitaliy Matytsyn <vm@if.bank.gov.ua>
     Wesha <wesha@iname.com>
+    Will Roberts <squid@bigwillystyle42.com>
     Wojtek Sylwestrzak <W.Sylwestrzak@icm.edu.pl>
+    Wolfgang Breyha <wbreyha@gmx.net>
     Wolfgang Nothdurft <wolfgang@linogate.de>
+    Zhanpeng Chen <lowstz@gmail.com>
     benno@jeamland.net
     fancyrabbit <fancyrabbit@gmail.com>
+    folkert <folkert@vanheusden.com>
+    hno
+    kinkie@squid-cache.org
+    libit <sambabug.lb@gmail.com>
+    rousskov
     vollkommen <vollkommen@gmx.net>
-    Benjamin Kerensa <bkerensa@ubuntu.com>
@@ -1,3 +1,32 @@
+Changes to squid-3.4.5 (02 May 2014):
+
+	- Regression Bug 4051: inverted test on CONNECT payload existence
+	- Regression Fix: order dependency between cache_dir and maximum_object_size
+	- Fix logformat %note display
+	- Resolve 'dying from an unhandled exception: c'
+
+Changes to squid-3.4.4.2 (23 Apr 2014):
+
+	- version bump for packaging re-build with altered toolchain
+
+Changes to squid-3.4.4.1 (23 Apr 2014):
+
+	- Regression Bug 4019: Cache digest exchange segmentation fault
+	- Regression Bug 3982: EUI logging and helpers show blank MAC address
+	- Bug 4047: Support Android builds
+	- Bug 4043: Remove XMALLOC_TRACE and references to sbrk(2)
+	- Bug 4041: Missing files in compat/Makefile.am
+	- Bug 4014: Build failure with --disable-optimizations --disable-auth
+	- Bug 3986: (partial) assertion due to incorrect error page buffer size
+	- Bug 3955: Solaris EUI-48 lookup leaks FDs
+	- Bug 3371: CONNECT with data sent at once loses data
+	- C++11: Upgrade auto-detection to use the formal -std=c++11
+	- Crypto-NG: libnettle MD5 algorithm support
+	- SSL-Bump: Fix Basic auth caching on bumped connections
+	- Store-ID: Fix request URI when forwarding requests to peers
+	- ... and fix several other build errors
+	- ... and some documentation updates
+
 Changes to squid-3.4.4 (09 Mar 2014):
 
 	- Bug 4029: intercepted HTTPS requests bypass caching checks
@@ -4,7 +4,7 @@
 AUTOMAKE_OPTIONS = dist-bzip2 subdir-objects 1.5 foreign
 DIST_SUBDIRS	= compat lib libltdl scripts icons errors contrib doc helpers src test-suite tools
 SUBDIRS		= compat lib
-if USE_LOADABLE_MODULES
+if ENABLE_LOADABLE_MODULES
 SUBDIRS += libltdl
 endif
 SUBDIRS += scripts icons errors doc helpers src tools test-suite
@@ -1,107 +0,0 @@
-# ============================================================================
-#  http://www.gnu.org/software/autoconf-archive/ax_cxx_compile_stdcxx_0x.html
-# ============================================================================
-#
-# SYNOPSIS
-#
-#   AX_CXX_COMPILE_STDCXX_0X
-#
-# DESCRIPTION
-#
-#   Check for baseline language coverage in the compiler for the C++0x
-#   standard.
-#
-# LICENSE
-#
-#   Copyright (c) 2008 Benjamin Kosnik <bkoz@redhat.com>
-#
-#   Copying and distribution of this file, with or without modification, are
-#   permitted in any medium without royalty provided the copyright notice
-#   and this notice are preserved. This file is offered as-is, without any
-#   warranty.
-
-#serial 7
-
-AU_ALIAS([AC_CXX_COMPILE_STDCXX_0X], [AX_CXX_COMPILE_STDCXX_0X])
-AC_DEFUN([AX_CXX_COMPILE_STDCXX_0X], [
-  AC_CACHE_CHECK(if g++ supports C++0x features without additional flags,
-  ax_cv_cxx_compile_cxx0x_native,
-  [AC_LANG_SAVE
-  AC_LANG_CPLUSPLUS
-  AC_TRY_COMPILE([
-  template <typename T>
-    struct check
-    {
-      static_assert(sizeof(int) <= sizeof(T), "not big enough");
-    };
-
-    typedef check<check<bool>> right_angle_brackets;
-
-    int a;
-    decltype(a) b;
-
-    typedef check<int> check_type;
-    check_type c;
-    check_type&& cr = static_cast<check_type&&>(c);],,
-  ax_cv_cxx_compile_cxx0x_native=yes, ax_cv_cxx_compile_cxx0x_native=no)
-  AC_LANG_RESTORE
-  ])
-
-  AC_CACHE_CHECK(if g++ supports C++0x features with -std=c++0x,
-  ax_cv_cxx_compile_cxx0x_cxx,
-  [AC_LANG_SAVE
-  AC_LANG_CPLUSPLUS
-  ac_save_CXXFLAGS="$CXXFLAGS"
-  CXXFLAGS="$CXXFLAGS -std=c++0x"
-  AC_TRY_COMPILE([
-  template <typename T>
-    struct check
-    {
-      static_assert(sizeof(int) <= sizeof(T), "not big enough");
-    };
-
-    typedef check<check<bool>> right_angle_brackets;
-
-    int a;
-    decltype(a) b;
-
-    typedef check<int> check_type;
-    check_type c;
-    check_type&& cr = static_cast<check_type&&>(c);],,
-  ax_cv_cxx_compile_cxx0x_cxx=yes, ax_cv_cxx_compile_cxx0x_cxx=no)
-  CXXFLAGS="$ac_save_CXXFLAGS"
-  AC_LANG_RESTORE
-  ])
-
-  AC_CACHE_CHECK(if g++ supports C++0x features with -std=gnu++0x,
-  ax_cv_cxx_compile_cxx0x_gxx,
-  [AC_LANG_SAVE
-  AC_LANG_CPLUSPLUS
-  ac_save_CXXFLAGS="$CXXFLAGS"
-  CXXFLAGS="$CXXFLAGS -std=gnu++0x"
-  AC_TRY_COMPILE([
-  template <typename T>
-    struct check
-    {
-      static_assert(sizeof(int) <= sizeof(T), "not big enough");
-    };
-
-    typedef check<check<bool>> right_angle_brackets;
-
-    int a;
-    decltype(a) b;
-
-    typedef check<int> check_type;
-    check_type c;
-    check_type&& cr = static_cast<check_type&&>(c);],,
-  ax_cv_cxx_compile_cxx0x_gxx=yes, ax_cv_cxx_compile_cxx0x_gxx=no)
-  CXXFLAGS="$ac_save_CXXFLAGS"
-  AC_LANG_RESTORE
-  ])
-
-  if test "$ax_cv_cxx_compile_cxx0x_native" = yes ||
-     test "$ax_cv_cxx_compile_cxx0x_cxx" = yes ||
-     test "$ax_cv_cxx_compile_cxx0x_gxx" = yes; then
-    AC_DEFINE(HAVE_STDCXX_0X,,[Define if g++ supports C++0x features. ])
-  fi
-])
@@ -0,0 +1,142 @@
+# ============================================================================
+#  http://www.gnu.org/software/autoconf-archive/ax_cxx_compile_stdcxx_11.html
+# ============================================================================
+#
+# SYNOPSIS
+#
+#   AX_CXX_COMPILE_STDCXX_11([ext|noext],[mandatory|optional])
+#
+# DESCRIPTION
+#
+#   Check for baseline language coverage in the compiler for the C++11
+#   standard; if necessary, add switches to CXXFLAGS to enable support.
+#
+#   The first argument, if specified, indicates whether you insist on an
+#   extended mode (e.g. -std=gnu++11) or a strict conformance mode (e.g.
+#   -std=c++11).  If neither is specified, you get whatever works, with
+#   preference for an extended mode.
+#
+#   The second argument, if specified 'mandatory' or if left unspecified,
+#   indicates that baseline C++11 support is required and that the macro
+#   should error out if no mode with that support is found.  If specified
+#   'optional', then configuration proceeds regardless, after defining
+#   HAVE_CXX11 if and only if a supporting mode is found.
+#
+# LICENSE
+#
+#   Copyright (c) 2008 Benjamin Kosnik <bkoz@redhat.com>
+#   Copyright (c) 2012 Zack Weinberg <zackw@panix.com>
+#   Copyright (c) 2013 Roy Stogner <roystgnr@ices.utexas.edu>
+#   Copyright (c) 2014 Alexey Sokolov <sokolov@google.com>
+#
+#   Copying and distribution of this file, with or without modification, are
+#   permitted in any medium without royalty provided the copyright notice
+#   and this notice are preserved. This file is offered as-is, without any
+#   warranty.
+
+#serial 4
+
+m4_define([_AX_CXX_COMPILE_STDCXX_11_testbody], [[
+  template <typename T>
+    struct check
+    {
+      static_assert(sizeof(int) <= sizeof(T), "not big enough");
+    };
+
+    struct Base {
+    virtual void f() {}
+    };
+    struct Child : public Base {
+    virtual void f() override {}
+    };
+
+    typedef check<check<bool>> right_angle_brackets;
+
+    int a;
+    decltype(a) b;
+
+    typedef check<int> check_type;
+    check_type c;
+    check_type&& cr = static_cast<check_type&&>(c);
+
+    auto d = a;
+    auto l = [](){};
+]])
+
+AC_DEFUN([AX_CXX_COMPILE_STDCXX_11], [dnl
+  m4_if([$1], [], [],
+        [$1], [ext], [],
+        [$1], [noext], [],
+        [m4_fatal([invalid argument `$1' to AX_CXX_COMPILE_STDCXX_11])])dnl
+  m4_if([$2], [], [ax_cxx_compile_cxx11_required=true],
+        [$2], [mandatory], [ax_cxx_compile_cxx11_required=true],
+        [$2], [optional], [ax_cxx_compile_cxx11_required=false],
+        [m4_fatal([invalid second argument `$2' to AX_CXX_COMPILE_STDCXX_11])])
+  AC_LANG_PUSH([C++])dnl
+  ac_success=no
+  AC_CACHE_CHECK(whether $CXX supports C++11 features by default,
+  ax_cv_cxx_compile_cxx11,
+  [AC_COMPILE_IFELSE([AC_LANG_SOURCE([_AX_CXX_COMPILE_STDCXX_11_testbody])],
+    [ax_cv_cxx_compile_cxx11=yes],
+    [ax_cv_cxx_compile_cxx11=no])])
+  if test x$ax_cv_cxx_compile_cxx11 = xyes; then
+    ac_success=yes
+  fi
+
+  m4_if([$1], [noext], [], [dnl
+  if test x$ac_success = xno; then
+    for switch in -std=gnu++11 -std=gnu++0x; do
+      cachevar=AS_TR_SH([ax_cv_cxx_compile_cxx11_$switch])
+      AC_CACHE_CHECK(whether $CXX supports C++11 features with $switch,
+                     $cachevar,
+        [ac_save_CXXFLAGS="$CXXFLAGS"
+         CXXFLAGS="$CXXFLAGS $switch"
+         AC_COMPILE_IFELSE([AC_LANG_SOURCE([_AX_CXX_COMPILE_STDCXX_11_testbody])],
+          [eval $cachevar=yes],
+          [eval $cachevar=no])
+         CXXFLAGS="$ac_save_CXXFLAGS"])
+      if eval test x\$$cachevar = xyes; then
+        CXXFLAGS="$CXXFLAGS $switch"
+        ac_success=yes
+        break
+      fi
+    done
+  fi])
+
+  m4_if([$1], [ext], [], [dnl
+  if test x$ac_success = xno; then
+    for switch in -std=c++11 -std=c++0x; do
+      cachevar=AS_TR_SH([ax_cv_cxx_compile_cxx11_$switch])
+      AC_CACHE_CHECK(whether $CXX supports C++11 features with $switch,
+                     $cachevar,
+        [ac_save_CXXFLAGS="$CXXFLAGS"
+         CXXFLAGS="$CXXFLAGS $switch"
+         AC_COMPILE_IFELSE([AC_LANG_SOURCE([_AX_CXX_COMPILE_STDCXX_11_testbody])],
+          [eval $cachevar=yes],
+          [eval $cachevar=no])
+         CXXFLAGS="$ac_save_CXXFLAGS"])
+      if eval test x\$$cachevar = xyes; then
+        CXXFLAGS="$CXXFLAGS $switch"
+        ac_success=yes
+        break
+      fi
+    done
+  fi])
+  AC_LANG_POP([C++])
+  if test x$ax_cxx_compile_cxx11_required = xtrue; then
+    if test x$ac_success = xno; then
+      AC_MSG_ERROR([*** A compiler with support for C++11 language features is required.])
+    fi
+  else
+    if test x$ac_success = xno; then
+      HAVE_CXX11=0
+      AC_MSG_NOTICE([No compiler with C++11 support was found])
+    else
+      HAVE_CXX11=1
+      AC_DEFINE(HAVE_CXX11,1,
+                [define if the compiler supports basic C++11 syntax])
+    fi
+
+    AC_SUBST(HAVE_CXX11)
+  fi
+])
@@ -35,12 +35,18 @@ AC_DEFUN([SQUID_DEFAULT_INCLUDES],[[
 dnl *BSD net headers
 AC_DEFUN([SQUID_BSDNET_INCLUDES],[
 SQUID_DEFAULT_INCLUDES
+#if HAVE_SYS_PARAM_H
+#include <sys/param.h>
+#endif
 #if HAVE_SYS_TIME_H
 #include <sys/time.h>
 #endif
 #if HAVE_SYS_SOCKET_H
 #include <sys/socket.h>
 #endif
+#if HAVE_NET_IF_H
+#include <net/if.h>
+#endif
 #if HAVE_NETINET_IN_H
 #include <netinet/in.h>
 #endif
@@ -50,15 +56,9 @@ SQUID_DEFAULT_INCLUDES
 #if HAVE_NETINET_IP_COMPAT_H
 #include <netinet/ip_compat.h>
 #endif
-#if HAVE_NET_IF_H
-#include <net/if.h>
-#endif
 #if HAVE_NETINET_IP_FIL_H
 #include <netinet/ip_fil.h>
 #endif
-#if HAVE_SYS_PARAM_H
-#include <sys/param.h>
-#endif
 ])
 
 dnl ===========================================================================
@@ -197,26 +197,6 @@ AC_DEFUN([SQUID_CHECK_UNIX_SOCKET],[
 ])
 
 
-dnl checks that the system provides struct mallinfo and mallinfo.mxfast.
-dnl AC_DEFINEs HAVE_STRUCT_MALLINFO  and HAVE_STRUCT_MALLINFO_MXFAST if so
-
-AC_DEFUN([SQUID_HAVE_STRUCT_MALLINFO],[
-AC_CHECK_TYPE(struct mallinfo,AC_DEFINE(HAVE_STRUCT_MALLINFO,1,[The system provides struct mallinfo]),,[
-#if HAVE_SYS_TYPES_H
-#include <sys/types.h>
-#endif
-#if HAVE_MALLOC_H
-#include <malloc.h>
-#endif])
-AC_CHECK_MEMBERS([struct mallinfo.mxfast],,,[
-#if HAVE_SYS_TYPES_H
-#include <sys/types.h>
-#endif
-#if HAVE_MALLOC_H
-#include <malloc.h>
-#endif])
-])
-
 dnl check the default FD_SETSIZE size.
 dnl not cached, people are likely to tune this
 dnl defines DEFAULT_FD_SETSIZE
@@ -56,6 +56,7 @@ libcompat_squid_la_SOURCES = \
 	xstrto.h \
 	\
 	os/aix.h \
+	os/android.h \
 	os/dragonfly.h \
 	os/freebsd.h \
 	os/hpux.h \
@@ -73,7 +74,7 @@ libcompat_squid_la_SOURCES = \
 	os/solaris.h \
 	os/sunos.h
 
-libcompat_squid_la_LIBADD= $(LIBOBJS)
+libcompat_squid_la_LIBADD= $(LTLIBOBJS)
 
 check_PROGRAMS += testPreCompiler
 TESTS += testPreCompiler
@@ -56,6 +56,7 @@
 /*****************************************************/
 
 #include "compat/os/aix.h"
+#include "compat/os/android.h"
 #include "compat/os/dragonfly.h"
 #include "compat/os/freebsd.h"
 #include "compat/os/hpux.h"
@@ -0,0 +1,13 @@
+#ifndef SQUID_OS_ANDROID_H
+#define SQUID_OS_ANDROID_H
+
+#if defined(__ANDROID__)
+/****************************************************************************
+ *--------------------------------------------------------------------------*
+ * DO *NOT* MAKE ANY CHANGES below here unless you know what you're doing...*
+ *--------------------------------------------------------------------------*
+ ****************************************************************************/
+#define _SQUID_ANDROID_ 1
+
+#endif /* _SQUID_ANDROID_ */
+#endif /* SQUID_OS_ANDROID_H */
@@ -148,33 +148,76 @@ SQUIDCEXTERN int WIN32_truncate(const char *pathname, off_t length);
 #define umask _umask
 #define unlink _unlink
 
+#ifndef O_RDONLY
 #define O_RDONLY        _O_RDONLY
+#endif
+#ifndef O_WRONLY
 #define O_WRONLY        _O_WRONLY
+#endif
+#ifndef O_RDWR
 #define O_RDWR          _O_RDWR
+#endif
+#ifndef O_APPEND
 #define O_APPEND        _O_APPEND
-
+#endif
+#ifndef O_CREAT
 #define O_CREAT         _O_CREAT
+#endif
+#ifndef O_TRUNC
 #define O_TRUNC         _O_TRUNC
+#endif
+#ifndef O_EXCL
 #define O_EXCL          _O_EXCL
-
+#endif
+#ifndef O_TEXT
 #define O_TEXT          _O_TEXT
+#endif
+#ifndef O_BINARY
 #define O_BINARY        _O_BINARY
+#endif
+#ifndef O_RAW
 #define O_RAW           _O_BINARY
+#endif
+#ifndef O_TEMPORARY
 #define O_TEMPORARY     _O_TEMPORARY
+#endif
+#ifndef O_NOINHERIT
 #define O_NOINHERIT     _O_NOINHERIT
+#endif
+#ifndef O_SEQUENTIAL
 #define O_SEQUENTIAL    _O_SEQUENTIAL
+#endif
+#ifndef O_RANDOM
 #define O_RANDOM        _O_RANDOM
+#endif
+#ifndef O_NDELAY
 #define O_NDELAY	0
+#endif
 
+#ifndef S_IFMT
 #define S_IFMT   _S_IFMT
+#endif
+#ifndef S_IFDIR
 #define S_IFDIR  _S_IFDIR
+#endif
+#ifndef S_IFCHR
 #define S_IFCHR  _S_IFCHR
+#endif
+#ifndef S_IFREG
 #define S_IFREG  _S_IFREG
+#endif
+#ifndef S_IREAD
 #define S_IREAD  _S_IREAD
+#endif
+#ifndef S_IWRITE
 #define S_IWRITE _S_IWRITE
+#endif
+#ifndef S_IEXEC
 #define S_IEXEC  _S_IEXEC
-
+#endif
+#ifndef S_IRWXO
 #define S_IRWXO 007
+#endif
 
 #if defined(_MSC_VER)
 #define	S_ISDIR(m) (((m) & _S_IFDIR) == _S_IFDIR)
@@ -5,7 +5,7 @@
 #include "squid.h"
 #include "psignal.h"
 
-#if _SQUID_AIX_ || _SQUID_MINGW_
+#if _SQUID_AIX_ || _SQUID_ANDROID_ || _SQUID_MINGW_
 extern const char* const sys_siglist[];
 #define _sys_nsig 64
 #define _sys_siglist sys_siglist
@@ -49,7 +49,7 @@
 #define INT64_MIN LONG_MIN
 #else
 /* 32 bit system */
-#define INT64_MIN       -9223372036854775807L-1L
+#define INT64_MIN       (-9223372036854775807LL-1LL)
 #endif
 #endif
 
@@ -59,7 +59,7 @@
 #define INT64_MAX LONG_MAX
 #else
 /* 32 bit system */
-#define INT64_MAX       9223372036854775807L
+#define INT64_MAX       9223372036854775807LL
 #endif
 #endif
 
@@ -86,19 +86,9 @@ xcalloc(size_t n, size_t sz)
         exit(1);
     }
 
-#if XMALLOC_DEBUG
-    check_malloc(p, sz * n);
-#endif
 #if XMALLOC_STATISTICS
     malloc_stat(sz * n);
 #endif
-#if XMALLOC_TRACE
-    xmalloc_show_trace(p, 1);
-#endif
-#if MEM_GEN_TRACE
-    if (tracefp)
-        fprintf(tracefp, "c:%u:%u:%p\n", (unsigned int) n, (unsigned int) sz, p);
-#endif
 
     PROF_stop(xcalloc);
     return p;
@@ -127,19 +117,9 @@ xmalloc(size_t sz)
         exit(1);
     }
 
-#if XMALLOC_DEBUG
-    check_malloc(p, sz);
-#endif
 #if XMALLOC_STATISTICS
     malloc_stat(sz);
 #endif
-#if XMALLOC_TRACE
-    xmalloc_show_trace(p, 1);
-#endif
-#if MEM_GEN_TRACE
-    if (tracefp)
-        fprintf(tracefp, "m:%d:%p\n", sz, p);
-#endif
 
     PROF_stop(xmalloc);
     return (p);
@@ -149,17 +129,10 @@ void *
 xrealloc(void *s, size_t sz)
 {
     PROF_start(xrealloc);
-#if XMALLOC_TRACE
-    xmalloc_show_trace(s, -1);
-#endif
 
     if (sz < 1)
         sz = 1;
 
-#if XMALLOC_DEBUG
-    if (s != NULL)
-        check_free(s);
-#endif
     PROF_start(realloc);
     void *p= realloc(s, sz);
     PROF_stop(realloc);
@@ -176,19 +149,10 @@ xrealloc(void *s, size_t sz)
         exit(1);
     }
 
-#if XMALLOC_DEBUG
-    check_malloc(p, sz);
-#endif
 #if XMALLOC_STATISTICS
     malloc_stat(sz);
 #endif
-#if XMALLOC_TRACE
-    xmalloc_show_trace(p, 1);
-#endif
-#if MEM_GEN_TRACE
-    if (tracefp)                /* new ptr, old ptr, new size */
-        fprintf(tracefp, "r:%p:%p:%d\n", p, s, sz);
-#endif
+
     PROF_stop(xrealloc);
     return (p);
 }
@@ -199,21 +163,8 @@ free_const(const void *s_const)
     void *s = const_cast<void *>(s_const);
 
     PROF_start(free_const);
-#if XMALLOC_TRACE
-    xmalloc_show_trace(s, -1);
-#endif
-
-#if XMALLOC_DEBUG
-    check_free(s);
-#endif
-
     PROF_start(free);
     free(s);
     PROF_stop(free);
-
-#if MEM_GEN_TRACE
-    if (tracefp)
-        fprintf(tracefp, "f:%p\n", s);
-#endif
     PROF_stop(free_const);
 }
@@ -2,9 +2,7 @@
 #include "compat/xalloc.h"
 #include "compat/xstring.h"
 
-#if HAVE_ERRNO_H
-#include <errno.h>
-#endif
+#include <cerrno>
 
 char *
 xstrdup(const char *s)
@@ -47,9 +47,7 @@
  *      Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.
  */
 
-#if HAVE_ERRNO_H
-#include <errno.h>
-#endif
+#include <cerrno>
 
 bool
 xstrtoul(const char *s, char **end, unsigned long *value,
@@ -16,7 +16,7 @@ m4_include([acinclude/krb5.m4])
 m4_include([acinclude/pam.m4])
 m4_include([acinclude/pkg.m4])
 m4_include([acinclude/lib-checks.m4])
-m4_include([acinclude/ax_cxx_compile_stdcxx_0x.m4])
+m4_include([acinclude/ax_cxx_compile_stdcxx_11.m4])
 m4_include([acinclude/ax_cxx_0x_types.m4])
 
 PRESET_CFLAGS="$CFLAGS"
@@ -53,17 +53,19 @@ if test "x${enable_arch_native}" != "xno"; then
 fi
 
 # might be cross-compiling.
-if test "x$HOSTCXX" = "x"; then
-  HOSTCXX="$CXX"
+# NP: BUILDCXXFLAGS defined at the end of configure after CXXFLAGS fully known.
+AC_ARG_VAR([BUILDCXX],[path to compiler for building compile-time tools. e.g. cf_gen])
+if test "x$HOSTCXX" != "x" -a "x$BUILDCXX" = "x"; then
+  AC_MSG_WARN([Cross-compiling with HOSTCXX is deprecated. Uses BUILDCXX instead.])
+  BUILDCXX="$HOSTCXX"
+fi
+if test "x$BUILDCXX" = "x"; then
+  BUILDCXX="$CXX"
   if test "x$squid_cv_check_marchnative" = "xyes"; then
     CXXFLAGS="$CXXFLAGS -march=native"
   fi
 fi
-if test "x$squid_cv_check_marchnative" = "xyes"; then
-  # always valid for the Host compiler.
-  HOSTCXX="$HOSTCXX -march=native"
-fi
-AC_SUBST(HOSTCXX)
+AC_SUBST(BUILDCXX)
 
 AC_MSG_CHECKING([simplified host os])
 simple_host_os=`echo $host_os|sed 's/[0-9].*//g;s/-.*//g'`
@@ -82,16 +84,15 @@ if test "x$squid_host_os" = "solaris" -a "x$GCC" != "x" ; then
 	AC_USE_SYSTEM_EXTENSIONS
 fi
 
-# Check for C++0x compiler support
-AX_CXX_COMPILE_STDCXX_0X
-if test "x$ax_cv_cxx_compile_cxx0x_cxx" = "xyes" -a \
-  "x$squid_host_os" != "xmingw" ; then
+# Check for C++11 compiler support
+if test "x$squid_host_os" != "xmingw" ; then
     #BUG 3613: when clang -std=c++0x is used, it activates a "strict mode"
     # in the system libraries, which makes some c99 methods unavailable
     # (e.g. strtoll), yet configure detects them as avilable.
     case "$CXX" in
       *clang++*) ;; #do nothing
-      *) CXXFLAGS="$CXXFLAGS -std=c++0x" ;;
+      *)
+      AX_CXX_COMPILE_STDCXX_11([noext],[optional])
     esac
 fi
 
@@ -151,7 +152,7 @@ AC_ARG_ENABLE(loadable-modules,
   SQUID_YESNO([$enableval],
     [Unrecognized argument to --disable-loadable-modules: $enableval])
 ])
-AM_CONDITIONAL(USE_LOADABLE_MODULES, test "x${enable_loadable_modules:=yes}" = "xyes")
+AM_CONDITIONAL(ENABLE_LOADABLE_MODULES, test "x${enable_loadable_modules:=yes}" = "xyes")
 AC_MSG_RESULT([$enable_loadable_modules])
 
 if test "x$enable_loadable_modules" = "xyes";
@@ -207,7 +208,7 @@ AC_SUBST(CGIEXT)
 
 AM_CONDITIONAL(ENABLE_WIN32SPECIFIC,
                [test "x$squid_host_os" = "xmingw" -o "x$squid_host_os" = "xcygwin"])
-AM_CONDITIONAL(USE_IPC_WIN32,[test "x$squid_host_os" = "xmingw"])
+AM_CONDITIONAL(ENABLE_WIN32_IPC,[test "x$squid_host_os" = "xmingw"])
 
 case "$squid_host_os" in
 mingw)
@@ -449,28 +450,6 @@ dnl Nasty hack to get autoconf 2.64 on Linux to run.
 dnl all other uses of RUN_IFELSE are wrapped inside CACHE_CHECK which breaks on 2.64
 AC_RUN_IFELSE([AC_LANG_SOURCE([[ int main(int argc, char **argv) { return 0; } ]])],[],[],[:])
 
-dnl This is a developer only option.. developers know how to set defines
-dnl
-dnl AC_ARG_ENABLE(xmalloc-debug,
-dnl [  --enable-xmalloc-debug  Do some simple malloc debugging],
-dnl [ if test "$enableval" = "yes" ; then
-dnl     AC_MSG_NOTICE([malloc debugging enabled])
-dnl     AC_DEFINE(XMALLOC_DEBUG,1,[Define to do simple malloc debugging])
-dnl   fi
-dnl ])
-
-dnl This is a developer only option.. developers know how to set defines
-dnl
-dnl AC_ARG_ENABLE(xmalloc-debug-trace,
-dnl [  --enable-xmalloc-debug-trace
-dnl                           Detailed trace of memory allocations],
-dnl [ if test "$enableval" = "yes" ; then
-dnl     AC_MSG_NOTICE([malloc debug trace enabled])
-dnl     AC_DEFINE(XMALLOC_TRACE,1,[Define to have a detailed trace of memory allocations])
-dnl     AC_DEFINE(XMALLOC_DEBUG,1)
-dnl   fi
-dnl ])
-
 AH_TEMPLATE(XMALLOC_STATISTICS,[Define to have malloc statistics])
 AC_ARG_ENABLE(xmalloc-statistics,
   AS_HELP_STRING([--enable-xmalloc-statistics],
@@ -559,7 +538,7 @@ AC_ARG_WITH(pthreads,AS_HELP_STRING([--without-pthreads],[Disable POSIX Threads]
 AC_ARG_WITH(aio, AS_HELP_STRING([--without-aio],[Do not use POSIX AIO. Default: auto-detect]))
 AH_TEMPLATE(USE_DISKIO_AIO, [Whether POSIX AIO support is needed. Automatic])
 AH_TEMPLATE(USE_DISKIO_DISKTHREADS, [Whether pthreads support is needed. Automatic])
-USE_AIOPS_WIN32=0
+ENABLE_WIN32_AIOPS=0
 squid_opt_use_aio=
 squid_opt_use_diskthreads=
 AIOLIB=
@@ -602,7 +581,7 @@ for module in $squid_disk_module_candidates none; do
       dnl REF: http://autoconf-archive.cryp.to/acx_pthread.html
         case "$squid_host_os" in
           mingw)
-            USE_AIOPS_WIN32=1
+            ENABLE_WIN32_AIOPS=1
             AC_MSG_NOTICE([Windows threads support automatically enabled])
             ;;
           freebsd)
@@ -714,7 +693,7 @@ for module in $squid_disk_module_candidates none; do
         DISK_LINKOBJS="$DISK_LINKOBJS DiskIO/AIO/AIODiskIOModule.o"
         case "$squid_host_os" in
           mingw)
-            USE_AIO_WIN32=1
+            ENABLE_WIN32_AIO=1
             AC_MSG_NOTICE([Replacing AIO DiskIO module with: Windows overlapped I/O support])
             ;;
           *)
@@ -773,8 +752,8 @@ AC_SUBST(DISK_LIBS)
 AC_SUBST(DISK_PROGRAMS)
 AC_SUBST(DISK_LINKOBJS)
 AC_SUBST(DISK_OS_LIBS)
-AM_CONDITIONAL([USE_AIOPS_WIN32], [test "$USE_AIOPS_WIN32" = "1"])
-AM_CONDITIONAL([USE_AIO_WIN32], [test "$USE_AIO_WIN32" = "1"])
+AM_CONDITIONAL([ENABLE_WIN32_AIOPS], [test "$ENABLE_WIN32_AIOPS" = "1"])
+AM_CONDITIONAL([ENABLE_WIN32_AIO], [test "$ENABLE_WIN32_AIO" = "1"])
 
 
 dnl Check what Storage formats are wanted.
@@ -997,13 +976,12 @@ AC_SUBST(XMLLIB)
 
 # icap argument handling
 AC_ARG_ENABLE(icap-client,
-  AS_HELP_STRING([--enable-icap-client],[Enable the ICAP client.]),
-    [squid_opt_use_icap_client=$enableval],
-    [squid_opt_use_icap_client=no])
-SQUID_DEFINE_BOOL(ICAP_CLIENT,$squid_opt_use_icap_client,
-     [Enable ICAP client features in Squid])
-AM_CONDITIONAL(USE_ICAP_CLIENT, [test "x$squid_opt_use_icap_client" = "xyes" ])
-if test "x$squid_opt_use_icap_client" = "xyes" ; then
+  AS_HELP_STRING([--disable-icap-client],[Disable the ICAP client.]),[
+  SQUID_YESNO([$enableval],[Unrecognized argument to --disable-icap-client: $enableval])
+])
+SQUID_DEFINE_BOOL(ICAP_CLIENT,${enable_icap_client:=yes}, [Enable ICAP client features in Squid])
+AM_CONDITIONAL(USE_ICAP_CLIENT, [test "x$enable_icap_client" != "xno" ])
+if test "x$enable_icap_client" != "xno" ; then
   ICAP_LIBS="icap/libicap.la"
   squid_opt_use_adaptation=yes
 else
@@ -1075,18 +1053,6 @@ else
 fi
 AC_SUBST(ADAPTATION_LIBS)
 
-
-dnl This is a developer only option. Developers know how to set defines
-dnl
-dnl AC_ARG_ENABLE(mem-gen-trace,
-dnl [  --enable-mem-gen-trace  Do trace of memory stuff],
-dnl [ if test "$enableval" = "yes" ; then
-dnl     AC_MSG_NOTICE([Memory trace (to file) enabled])
-dnl     AC_DEFINE(MEM_GEN_TRACE,1,[Define for log file trace of mem alloc/free])
-dnl   fi
-dnl ])
-
-
 test "x$squid_host_os" = "xmingw" && enable_wccp=no
 AC_ARG_ENABLE(wccp,
   AS_HELP_STRING([--disable-wccp],[Disable Web Cache Coordination Protocol]), [
@@ -1214,32 +1180,88 @@ SQUID_DEFINE_BOOL(USE_HTCP,${enable_htcp:=yes},
 AM_CONDITIONAL(ENABLE_HTCP, [test "x$enable_htcp" = "xyes"])
 AC_MSG_NOTICE([HTCP support enabled: $enable_htcp])
 
+# Cryptograhic libraries
+AC_ARG_WITH(nettle,
+  AS_HELP_STRING([--without-nettle],[Compile without the Nettle crypto library.]),[
+case "$with_nettle" in
+  yes|no)
+    : # Nothing special to do here
+    ;;
+  *)
+    if test ! -d "$withval" ; then
+      AC_MSG_ERROR([--with-nettle path does not point to a directory])
+    fi
+    NETTLELIBDIR="-L$with_nettle/lib"
+    CPPFLAGS="-I$with_nettle/include $CPPFLAGS"
+    with_nettle=yes
+  esac
+])
+if test "x$with_nettle" != "xno" ; then
+  AC_CHECK_LIB(nettle, nettle_md5_init,[
+    NETTLELIB="$NETTLELIBDIR -lnettle"
+    AC_CHECK_HEADERS(nettle/md5.h)
+  ],[with_nettle=no])
+fi
+AC_MSG_NOTICE([Using Nettle cryptographic library: ${with_nettle:=yes}])
+AC_SUBST(NETTLELIB)
 
-# SSL is not enabled by default.
-# Default is to use OpenSSL when available
-AC_ARG_ENABLE(ssl,
-  AS_HELP_STRING([--enable-ssl],
-                 [Enable ssl gatewaying support using OpenSSL]), [
-SQUID_YESNO([$enableval],
-            [unrecognized argument to --enable-ssl: $enableval])
+dnl Check for libcrypt
+CRYPTLIB=
+dnl Some of our helpers use crypt(3) which may be in libc, or in
+dnl libcrypt (eg FreeBSD)
+AC_CHECK_LIB(crypt, crypt, [CRYPTLIB="-lcrypt"])
+dnl Solaris10 provides MD5 natively through libmd5
+AC_CHECK_LIB(md5, MD5Init, [CRYPTLIB="$CRYPTLIB -lmd5"])
+AC_SUBST(CRYPTLIB)
+
+SSLLIB=""
+
+dnl User may want to disable GnuTLS
+AC_ARG_WITH(gnutls,
+  AS_HELP_STRING([--without-gnutls],
+                 [Do not use GnuTLS for SSL. Default: auto-detect]), [ 
+case "$with_gnutls" in
+  yes|no)
+    : # Nothing special to do here
+    ;;
+  *)
+    if test ! -d "$withval" ; then
+      AC_MSG_ERROR([--with-gnutls path does not point to a directory])
+    fi
+    LIBGNUTLS_PATH="-L$with_gnutls/lib"
+    CPPFLAGS="-I$with_gnutls/include $CPPFLAGS"
+  esac
 ])
-# USE_OPENSSL is AC_DEFINED later
-# default for ssl is set here
-if test "x${enable_ssl:=no}" = "xyes" ; then
-  if test "x$squid_host_os" = "xmingw" ; then
-    SSLLIB='-lssleay32 -leay32 -lgdi32'
-  else
-    SSLLIB='-lssl -lcrypto'
-  fi
-  if test "x$with_openssl" = "x"; then
-    with_openssl=yes
+AH_TEMPLATE(USE_GNUTLS,[GnuTLS support is available])
+if test "x$with_gnutls" != "xno"; then
+  AC_CHECK_HEADERS(gnutls/gnutls.h gnutls/x509.h)
+
+  # User may have provided a custom location for GnuTLS. Otherwise...
+  SQUID_STATE_SAVE(squid_gnutls_state)
+  LIBS="$LIBS $LIBGNUTLS_PATH"
+
+  # auto-detect using pkg-config
+  PKG_CHECK_MODULES([LIBGNUTLS],[gnutls >= 3.1.5],,[
+    ## find the package without pkg-config
+    ## check that the library is actually new enough.
+    ## by testing for a 3.1.5+ function which we use
+    AC_CHECK_LIB(gnutls,gnutls_certificate_verify_peers3,[LIBGNUTLS_LIBS="-lgnutls"])
+  ])
+
+  SQUID_STATE_ROLLBACK(squid_gnutls_state) #de-pollute LIBS
+
+  if test "x$with_gnutls" = "xyes" -a "x$LIBGNUTLS_LIBS" = "x"; then
+    AC_MSG_ERROR([Required GnuTLS library not found])
   fi
-  if test "x$with_openssl" = "x"; then
-    with_openssl=yes
+  if test "x$LIBGNUTLS_LIBS" != "x" ; then
+    CXXFLAGS="$LIBGNUTLS_CFLAGS $CXXFLAGS"
+    SSLLIB="$LIBGNUTLS_PATH $LIBGNUTLS_LIBS $SSLLIB"
+    AC_DEFINE(USE_GNUTLS,1,[GnuTLS support is available])
+  else
+    with_gnutls=no
   fi
 fi
-AM_CONDITIONAL(ENABLE_SSL,[ test "x$enable_ssl" = "xyes" ])
-AC_MSG_NOTICE([SSL gatewaying support enabled: $enable_ssl])
+AC_MSG_NOTICE([GnuTLS library support: ${with_gnutls:=auto} ${LIBGNUTLS_PATH} ${LIBGNUTLS_LIBS}])
 
 dnl User may specify OpenSSL is needed from a non-standard location
 AC_ARG_WITH(openssl,
@@ -1256,37 +1278,72 @@ case "$with_openssl" in
     if test ! -d "$withval" ; then
       AC_MSG_ERROR([--with-openssl path does not point to a directory])
     fi
-    SSLLIBDIR="$with_openssl/lib"
+    LIBOPENSSL_PATH="-L$with_openssl/lib"
     CPPFLAGS="-I$with_openssl/include $CPPFLAGS"
     with_openssl=yes
   esac
 ])
-SQUID_DEFINE_BOOL(USE_SSL,$enable_ssl,
-   [Define this to include code for SSL gatewaying support])
-AC_MSG_NOTICE([Using OpenSSL MD5 implementation: ${with_openssl:=no}])
-SQUID_DEFINE_BOOL(USE_OPENSSL,${with_openssl},
-   [Define this to make use of the OpenSSL libraries for MD5 calculation rather than Squid-supplied MD5 implementation or if building with SSL encryption])
-if test "x$enable_ssl" = "xyes"; then
-  if test "x$SSLLIB" = "x"; then
-    SSLLIB="-lcrypto" # for MD5 routines
-  fi
+AH_TEMPLATE(USE_OPENSSL,[OpenSSL support is available])
+## OpenSSL is default disable due to licensing issues on some OS
+if test "x$with_openssl" = "xyes"; then
+  AC_CHECK_HEADERS( \
+    openssl/err.h \
+    openssl/md5.h \
+    openssl/opensslv.h \
+    openssl/ssl.h \
+    openssl/x509v3.h \
+    openssl/engine.h \
+    openssl/txt_db.h \
+  )
+
+  # User may have provided a custom location for OpenSSL. Otherwise...
+  SQUID_STATE_SAVE(squid_openssl_state)
+  LIBS="$LIBS $LIBOPENSSL_PATH"
+
+  # auto-detect using pkg-config
+  PKG_CHECK_MODULES([LIBOPENSSL],[openssl],,[
+    ## For some OS pkg-config is broken or unavailable.
+    ## Detect libraries the hard way.
+
+    # Windows MinGW has some special libraries ...
+    if test "x$squid_host_os" = "xmingw" ; then
+      LIBOPENSSL_LIBS='-lssleay32 -leay32 -lgdi32 $LIBOPENSSL_LIBS'
+      AC_MSG_NOTICE([Windows OpenSSL library support: yes -lssleay32 -leay32 -lgdi32])
+    fi
+
+    AC_CHECK_LIB(crypto,[CRYPTO_new_ex_data],[LIBOPENSSL_LIBS="-lcrypto $LIBOPENSSL_LIBS"],[
+      AC_MSG_ERROR([library 'crypto' is required for OpenSSL])
+    ])
+    AC_CHECK_LIB(ssl,[SSL_library_init],[LIBOPENSSL_LIBS="-lssl $LIBOPENSSL_LIBS"],[
+      AC_MSG_ERROR([library 'ssl' is required for OpenSSL])
+    ])
+  ])
+
   # This is a workaround for RedHat 9 brain damage..
-  if test -d /usr/kerberos/include -a "x$SSLLIBDIR" = "x" -a -f /usr/include/openssl/kssl.h; then
+  if test -d /usr/kerberos/include -a -f /usr/include/openssl/kssl.h; then
     AC_MSG_NOTICE([OpenSSL depends on Kerberos])
-    SSLLIBDIR="/usr/kerberos/lib"
+    LIBOPENSSL_LIBS="-L/usr/kerberos/lib $LIBOPENSSL_LIBS"
     CPPFLAGS="$CPPFLAGS -I/usr/kerberos/include"
   fi
-fi
-if test "x$SSLLIBDIR" != "x" ; then
-  SSLLIB="-L$SSLLIBDIR $SSLLIB"
-fi
-AC_SUBST(SSLLIB)
+  SQUID_STATE_ROLLBACK(squid_openssl_state) #de-pollute LIBS
 
-if test "x$with_openssl" = "xyes"; then
-SQUID_CHECK_OPENSSL_GETCERTIFICATE_WORKS
-SQUID_CHECK_OPENSSL_CONST_SSL_METHOD
-SQUID_CHECK_OPENSSL_TXTDB
+  if test "x$LIBOPENSSL_LIBS" != "x"; then
+    CXXFLAGS="$LIBOPENSSL_CFLAGS $CXXFLAGS"
+    SSLLIB="$LIBOPENSSL_PATH $LIBOPENSSL_LIBS $SSLLIB"
+    AC_DEFINE(USE_OPENSSL,1,[OpenSSL support is available])
+
+    # check for other specific broken implementations
+    SQUID_CHECK_OPENSSL_GETCERTIFICATE_WORKS
+    SQUID_CHECK_OPENSSL_CONST_SSL_METHOD
+    SQUID_CHECK_OPENSSL_TXTDB
+  fi
+  if test "x$SSLLIB" = "x"; then
+    AC_MSG_ERROR([Required OpenSSL library not found])
+  fi
 fi
+AC_MSG_NOTICE([OpenSSL library support: ${with_openssl:=no} ${LIBOPENSSL_PATH} ${LIBOPENSSL_LIBS}])
+AM_CONDITIONAL(ENABLE_SSL,[ test "x$with_openssl" = "xyes" ])
+AC_SUBST(SSLLIB)
 
 AC_ARG_ENABLE(forw-via-db,
   AS_HELP_STRING([--enable-forw-via-db],[Enable Forw/Via database]), [
@@ -1676,8 +1733,8 @@ AC_ARG_ENABLE(ssl-crtd,
   [unrecogized argument to --enable-ssl-crtd: $enableval])
 ])
 
-if test "x$enable_ssl_crtd" = "xyes" -a "x$enable_ssl" = "xno" ; then
-   AC_MSG_ERROR([You need to enable ssl gatewaying support to use ssl_crtd feature. Try to use --enable-ssl. ])
+if test "x$enable_ssl_crtd" = "xyes" -a "x$with_openssl" = "xno" ; then
+   AC_MSG_ERROR([You need to enable ssl gatewaying support to use ssl_crtd feature. Try to use --with-openssl. ])
 fi
 SQUID_DEFINE_BOOL(USE_SSL_CRTD, ${enable_ssl_crtd:=no},[Use ssl_crtd daemon])
 AM_CONDITIONAL(USE_SSL_CRTD, [test "x$enable_ssl_crtd" = "xyes"])
@@ -2195,18 +2252,10 @@ AC_CHECK_HEADERS( \
   netinet/in.h \
   netinet/in_systm.h \
   netinet/ip_fil_compat.h \
-  openssl/err.h \
-  openssl/md5.h \
-  openssl/opensslv.h \
-  openssl/ssl.h \
-  openssl/x509v3.h \
   netinet/tcp.h \
-  openssl/engine.h \
-  openssl/txt_db.h \
   paths.h \
   poll.h \
   pwd.h \
-  shadow.h \
   regex.h \
   sched.h \
   siginfo.h \
@@ -2307,8 +2356,6 @@ AC_CHECK_MEMBERS([struct tm.tm_gmtoff],,,[
 #endif
 ])
 
-SQUID_HAVE_STRUCT_MALLINFO
-
 dnl Override rusage() detect on MinGW because is emulated in source code
 case "$squid_host_os" in
   mingw)
@@ -2483,7 +2530,6 @@ SQUID_DEFINE_BOOL(HAVE_UNIXSOCKET,$squid_cv_unixsocket,[System supports unix soc
 AC_CHECK_LIB(gnumalloc, malloc)
 if test "x$ac_cv_lib_gnumalloc_malloc" = "xyes"; then
   AC_MSG_NOTICE([Disabling extended malloc functions when using bundled gnumalloc])
-  ac_cv_func_mallinfo=no
   ac_cv_func_mallocblksize=no
   ac_cv_func_mallopt=no
 else
@@ -2574,22 +2620,6 @@ SQUID_CHECK_SS_LEN_IN_SOCKADDR_STORAGE
 SQUID_CHECK_SIN_LEN_IN_SOCKADDR_IN
 
 
-dnl Check for libcrypt
-CRYPTLIB=
-dnl Some of our helpers use crypt(3) which may be in libc, or in
-dnl libcrypt (eg FreeBSD)
-AC_CHECK_LIB(crypt, crypt, [CRYPTLIB="-lcrypt"])
-dnl Solaris10 provides MD5 natively through libmd5
-AC_CHECK_LIB(md5, MD5Init, [CRYPTLIB="$CRYPTLIB -lmd5"])
-AC_SUBST(CRYPTLIB)
-
-# check for crypt, may require -lcrypt
-SAVED_LIBS="$LIBS"
-LIBS="$LIBS $CRYPTLIB"
-AC_CHECK_FUNCS(crypt)
-LIBS="$SAVED_LIBS"
-
-
 dnl Check for libdl, used by auth_modules/PAM
 if test "x$with_dl" = "xyes"; then
     AC_CHECK_LIB(dl, dlopen)
@@ -2940,16 +2970,6 @@ if test "x$GCC" = "xyes"; then
 	esac
 fi
 
-# Recommended by Balint Nagy Endre <bne@CareNet.hu>
-case "$host" in
-  *-univel-sysv4.2MP)
-    if test `uname -v` = "2.03"; then
-      AC_MSG_NOTICE([disabling mallinfo for $host])
-      ac_cv_func_mallinfo=no
-    fi
-    ;;
-esac
-
 dnl This has to be before AC_CHECK_FUNCS
 # Disable poll() on certain platforms. Override by setting ac_cv_func_poll
 # when running configure.
@@ -3010,7 +3030,6 @@ AC_CHECK_FUNCS(\
 	htobe16 \
 	htole16 \
 	lrand48 \
-	mallinfo \
 	mallocblksize \
 	mallopt \
 	memcpy \
@@ -3033,7 +3052,6 @@ AC_CHECK_FUNCS(\
 	res_init \
 	__res_init \
 	rint \
-	sbrk \
 	sched_getaffinity \
 	sched_setaffinity \
 	select \
@@ -3147,6 +3165,9 @@ AC_CHECK_TYPE(struct iovec,AC_DEFINE(HAVE_IOVEC,1,[The system provides struct io
   #if HAVE_WINSOCK2_H
   #include <winsock2.h>
   #endif
+  #if HAVE_SYS_UIO_H
+  #include <sys/uio.h>
+  #endif
 ])
 
 AC_CHECK_TYPE(struct msghdr,AC_DEFINE(HAVE_MSGHDR,1,[The system provides struct msghdr]),,[
@@ -3397,6 +3418,18 @@ AC_SUBST(XTRA_LIBS)
 AC_SUBST(SQUID_CFLAGS)
 AC_SUBST(SQUID_CXXFLAGS)
 
+AC_ARG_VAR([BUILDCXXFLAGS],[C++ compiler flags for building compile-time tools. e.g. cf_gen])
+if test "x$BUILDCXXFLAGS" = "x"; then
+  # if we are NOT cross-compiling, use the default build flags for cf_gen and friends
+  # otherwise rely on the user-provided value
+  if test "x$squid_cv_check_marchnative" = "xyes"; then
+    # always valid for the Build compiler.
+    BUILDCXXFLAGS="-march=native"
+  fi
+  BUILDCXXFLAGS="$BUILDCXXFLAGS $CXXFLAGS"
+fi
+AC_SUBST(BUILDCXXFLAGS)
+
 AC_MSG_NOTICE([BUILD LIBRARIES: $LIBS])
 AC_MSG_NOTICE([BUILD EXTRA LIBRARIES: $XTRA_LIBS])
 AC_MSG_NOTICE([BUILD OBJECTS: $OBJS])
@@ -3405,6 +3438,7 @@ AC_MSG_NOTICE([BUILD C FLAGS: $CFLAGS])
 AC_MSG_NOTICE([BUILD EXTRA C FLAGS: $SQUID_CFLAGS])
 AC_MSG_NOTICE([BUILD C++ FLAGS: $CXXFLAGS])
 AC_MSG_NOTICE([BUILD EXTRA C++ FLAGS: $SQUID_CXXFLAGS])
+AC_MSG_NOTICE([BUILD Tools C++ FLAGS: $BUILDCXXFLAGS])
 
 dnl Clean up after OSF/1 core dump bug
 rm -f core 
@@ -3447,6 +3481,7 @@ AC_CONFIG_FILES([
 	src/ipc/Makefile
 	src/ssl/Makefile
 	src/mgr/Makefile
+	src/parser/Makefile
 	src/snmp/Makefile
 	contrib/Makefile
 	icons/Makefile
@@ -3484,6 +3519,7 @@ AC_CONFIG_FILES([
 	helpers/negotiate_auth/wrapper/Makefile
 	helpers/external_acl/Makefile
 	helpers/external_acl/AD_group/Makefile
+	helpers/external_acl/delayer/Makefile
 	helpers/external_acl/eDirectory_userip/Makefile
 	helpers/external_acl/file_userip/Makefile
 	helpers/external_acl/kerberos_ldap_group/Makefile
@@ -1,6 +1,6 @@
 <!doctype linuxdoc system>
 <article>
-<title>Squid 3.4.4 release notes</title>
+<title>Squid 3.4.5 release notes</title>
 <author>Squid Developers</author>
 
 <abstract>
@@ -13,7 +13,7 @@ for Applied Network Research and members of the Web Caching community.
 
 <sect>Notice
 <p>
-The Squid Team are pleased to announce the release of Squid-3.4.4 for testing.
+The Squid Team are pleased to announce the release of Squid-3.4.5 for testing.
 
 This new release is available for download from <url url="http://www.squid-cache.org/Versions/v3/3.4/"> or the
  <url url="http://www.squid-cache.org/Mirrors/http-mirrors.html" name="mirrors">.
@@ -40,6 +40,9 @@ The 3.5 change history can be <url url="http://www.squid-cache.org/Versions/v3/3
 <itemize>
 	<item>Support libecap v1.0
 	<item>Authentication helper query extensions
+	<item>Support named services
+	<item>Upgraded squidclient tool
+	<item>Helper support for concurrency channels
 </itemize>
 
 Most user-facing changes are reflected in squid.conf (see below).
@@ -71,6 +74,95 @@ Most user-facing changes are reflected in squid.conf (see below).
   will send any meaningful detail.
 
 
+<sect1>Support named services
+<p>Details at <url url="http://wiki.squid-cache.org/MultipleInstances">.
+<p>Terminology details at <url url="http://wiki.squid-cache.org/Features/SmpScale#Terminology">.
+
+<p>The command line option <em>-n</em> assigns a name to the Squid service
+   instance to be used as a unique identifier for all SMP processes run as
+   part of that instance. This allows multiple instances of Squid service to
+   be run on a single machine without background SMP systems such as shared
+   memory and inter-process communication becoming confused or requiring
+   additional configuration.
+
+<p>A service name is always used. When the <em>-n</em> option is missing
+   from the command line the default service name is <em>squid</em>.
+
+<p>When multiple instances are being run the <em>-n</em> service name is
+   required to target all other options such as <em>-z</em> or <em>-k</em>
+   commands at the correct service.
+
+<p>The squid.conf macro ${service_name} is added to provide the service name
+   of the process parsing the config.
+
+
+<sect1>Upgraded squidclient tool
+<p>The <em>squidclient</em> has begun the process of upgrading to support
+   protocols other than HTTP.
+
+<sect2>Debug levels
+<p>The tool displays the server response message on STDOUT unless the <em>-q</em>
+   command line option is used. Error messages will be output to STDERR.
+   All other possible output is considered debug and output to STDERR using
+   a range of debug verbosity levels (currently 1, 2 and 3).
+
+<p>When the <em>-v</em> command line option is used debugging is enabled.
+   The level of debug display is raised for each repetition of the option.
+
+<sect2>PING
+<p>When <em>--ping</em> is given the tool will send its message repeatedly
+   using whichever protocol that message has been formatted for.
+   Optional parameters to limit the number of pings and their frequency are
+   available.
+
+<p>Older tool versions also provide this feature but require the loop count
+   parameter to be set to enable use of the feature.
+
+<sect2>HTTPS
+<p>When Squid is built with the GnuTLS encryption library the tool is able
+   to open TLS (or SSL/3.0) connections to servers.
+
+<p>The <em>--https</em> option enables TLS using default values.
+
+<p>The <em>--cert</em> option specifies a file containing X.509 client
+   certificate and private key in PEM format to be loaded for use. Multiple
+   certificates are supported and the option may be used multiple times to
+   load certificates.
+   The default is not to use a client certificate.
+
+<p>The <em>--params</em> option specifies a library specific set of parameters
+   to be sent to the library for configuring the security context.
+   See <url url="http://gnutls.org/manual/html_node/Priority-Strings.html"> for
+   available GnuTLS parameters.
+
+<p>The <em>--trusted-ca</em> option specifies a file in PEM format containing
+   one or more Certificate Authority (CA) certificates used to verify the
+   remote server. This option may be used multiple times to load additional
+   CA certificate lists.
+   The default is not to use any CA, nor trust any server.
+
+<p>Anonymous TLS (using non-authenticated Diffi-Hellman or Elliptic Curve
+   encryption) is available with the <em>--anonymous-tls</em> option.
+   The default is to use X.509 certificate encryption instead.
+
+<p>When performing TLS/SSL server certificates are always verified, the
+   results shown at debug level 3. The encrypted type is displayed at debug
+   level 2 and the connection is used to send and receive the messages
+   regardless of verification results.
+
+
+<sect1>Helper support for concurrency channels
+<p>Helper concurrency greatly reduces the communication lag between Squid
+   and its helpers allowing faster transaction speeds even on sequential
+   helpers.
+
+<p>The Digest authentication, Store-ID, and URL-rewrite helpers packaged
+   with Squid have been updated to support concurrency channels. They will
+   auto-detect the <em>channel-ID</em> field and will produce the appropriate
+   response format.
+   With these helpers concurrency may now be set to 0 or any higher number as desired.
+
+
 <sect>Changes to squid.conf since Squid-3.4
 <p>
 There have been changes to Squid's configuration file since Squid-3.4.
@@ -81,6 +173,9 @@ There have been changes to Squid's configuration file since Squid-3.4.
     acl whitelist dstdomain parameters("/etc/squid/whitelist.txt")
 </verb>
 
+<p>The squid.conf macro ${service_name} is added to provide the service name
+   of the process parsing the config.
+
 <p>There have also been changes to individual directives in the config file.
 
 This section gives a thorough account of those changes in three categories:
@@ -104,10 +199,35 @@ This section gives a thorough account of those changes in three categories:
 	   based on ACL selection. ACL can be based on client request or cached
 	   response details.
 
+	<tag>sslproxy_session_cache_size</tag>
+	<p>New directive which sets the cache size to use for TLS/SSL sessions cache.
+
+	<tag>sslproxy_session_ttl</tag>
+	<p>New directive to specify the time in seconds the TLS/SSL session is valid.
+
+	<tag>store_id_extras</tag>
+	<p>New directive to send additional lookup parameters to the configured
+	   Store-ID helper program. It takes a string which may contain logformat %macros.
+	<p>The Store-ID helper input format is now:
+	<verb>
+         [channel-ID] url [extras]
+	</verb>
+	<p>The default value for extras is: "%&gt;a/%>A %un %>rm myip=%la myport=%lp"
+
 	<tag>store_miss</tag>
 	<p>New configuration directive to enable/disable caching of MISS responses.
 	   ACL can be based on any request or response details.
 
+	<tag>url_rewrite_extras</tag>
+	<p>New directive to send additional lookup parameters to the configured
+	   URL-rewriter/redirector helper program. It takes a string which may
+	   contain logformat %macros.
+	<p>The url rewrite and redirector helper input format is now:
+	<verb>
+         [channel-ID] url [extras]
+	</verb>
+	<p>The default value for extras is: "%>a/%>A %un %>rm myip=%la myport=%lp"
+
 </descrip>
 
 <sect1>Changes to existing tags<label id="modifiedtags">
@@ -123,15 +243,44 @@ This section gives a thorough account of those changes in three categories:
 	<p>New parameter <em>key_extras</em> to send additional parameters to
 	   the authentication helper.
 
+	<tag>cache_dir</tag>
+	<p>New support for larger than 32KB objects in both <em>rock</em> type
+	   cache and shared memory cache.
+	<p>New <em>slot-size=N</em> option for rock cache to specify the database
+	   slot/page size when small slot sizes are desired. The default and
+	   maximum slot size is 32KB.
+	<p>Removal of old rock cache dir followed by <em>squid -z</em> is required
+	   when upgrading from earlier versions of Squid.
+
+	<tag>cache_peer</tag>
+	<p>New <em>standby=N</em> option to retain a set of N open and unused
+	   connections to the peer at virtually all times to reduce TCP handshake
+	   delays.
+	<p>These connections differ from HTTP persistent connections in that they
+	   have not been used for HTTP messaging (and may never be). They may be
+	   turned into persistent connections after their first use subject to the
+	   same keep-alive critera any HTTP connection is checked for.
+
 	<tag>forward_max_tries</tag>
-	<p>Default value increased to <em>25 destinations/em> to allow better
+	<p>Default value increased to <em>25 destinations</em> to allow better
 	   contact and IPv4 failover with domains using long lists of IPv6
 	   addresses.
 
+	<tag>ftp_epsv</tag>
+	<p>Converted into an Access List with allow/deny value driven by ACLs
+	   using Squid standard first line wins matching basis.
+	<p>The old values of <em>on</em> and <em>off</em> imply <em>allow all</em>
+	    and <em>deny all</em> respectively and are now deprecated.
+	   Do not combine use of on/off values with ACL configuration.
+
 	<tag>http_port</tag>
 	<p><em>protocol=</em> option altered to accept protocol version details.
 	   Currently supported values are: HTTP, HTTP/1.1, HTTPS, HTTPS/1.1
 
+	<tag>https_port</tag>
+	<p><em>protocol=</em> option altered to accept protocol version details.
+	   Currently supported values are: HTTP, HTTP/1.1, HTTPS, HTTPS/1.1
+
 	<tag>logformat</tag>
 	<p>New format code <em>%credentials</em> to log the client credentials
 	   token.
@@ -146,13 +295,19 @@ This section gives a thorough account of those changes in three categories:
 <p>
 <descrip>
 	<tag>cache_dir</tag>
-	<p><em>COSS</em> storage type is formally replaced by Rosk storage type.
+	<p><em>COSS</em> storage type is formally replaced by Rock storage type.
 
 	<tag>cache_dns_program</tag>
 	<p>DNS external helper interface has been removed. It was no longer
 	   able to provide high performance service and the internal DNS
 	   client library with multicast DNS cover all modern use-cases.
 
+	<tag>cache_peer</tag>
+	<p><em>idle=</em> replaced by <em>standby=</em>.
+	<p>NOTE that standby connections are started earlier and available in
+	   more circumstances than squid-2 idle connections were. They are
+	   also spread over all IPs of the peer.
+
 	<tag>dns_children</tag>
 	<p>DNS external helper interface has been removed.
 
@@ -177,26 +332,48 @@ This section gives an account of those changes in three categories:
 <descrip>
 	<p><em>There are no new ./configure options in Squid-3.5.</em>
 
+	<tag>BUILDCXX=</tag>
+	<p>Used when cross-compiling Squid.
+	<p>The path and name of a compiler for building cf_gen and related
+	   tools used in the compile process.
+
+	<tag>BUILDCXXFLAGS=</tag>
+	<p>Used when cross-compiling Squid.
+	<p>C++ compiler flags used for building cf_gen and related
+	   tools used in the compile process.
+
+	<tag>--without-gnutls</tag>
+	<p>New option to explicitly disable use of GnuTLS encryption library.
+	   Use of this library is auto-enabled if v3.1.5 or later is available.
+	<p>It is currently only used by the squidclient tool.
+
 </descrip>
 
 <sect1>Changes to existing options<label id="modifiedoptions">
 <p>
 <descrip>
-	<p><em>There are no changes to existing ./configure options in Squid-3.5.</em>
+	<tag>--enable-icap-client</tag>
+	<p>Deprecated. ICAP client is now auto-enabled.
+	   Use --disable-icap-client to disable if you need to.
 
 </descrip>
 </p>
 
 <sect1>Removed options<label id="removedoptions">
 <p>
 <descrip>
-	<p><em>There are no removed ./configure options in Squid-3.5.</em>
-
 	<tag>--disable-internal-dns</tag>
 	<p>DNS external helper interface has been removed. It was no longer
 	   able to provide high performance service and the internal DNS
 	   client library with multicast DNS cover all modern use-cases.
 
+	<tag>--enable-ssl</tag>
+	<p>Removed. Use <em>--with-openssl</em> to enable OpenSSL library support.
+
+	<tag>--with-coss-membuf-size</tag>
+	<p>The COSS cache type has been removed.
+	   It has been replaced by <em>rock</em> cache type.
+
 </descrip>
 
 
@@ -213,7 +390,6 @@ This section gives an account of those changes in three categories:
 	<p>Not yet ported from 2.6
 
 	<tag>cache_peer</tag>
-	<p><em>idle=</em> not yet ported from 2.7
 	<p><em>monitorinterval=</em> not yet ported from 2.6
 	<p><em>monitorsize=</em> not yet ported from 2.6
 	<p><em>monitortimeout=</em> not yet ported from 2.6
@@ -69,9 +69,6 @@ rfc4918.txt
 	HTTP Extensions for Distributed Authoring -- WEBDAV
 	Numerous extension methods to HTTP
 
-rfc2616.txt
-	Hypertext Transfer Protocol -- HTTP/1.1
-
 rfc2617.txt
 	HTTP/1.1 Basic and Digest authentication
 
@@ -166,3 +163,41 @@ rfc6762.txt
 	Multicast DNS
 	Details the DNS requirements on the Squid internal DNS client
 	for resolving URLs in the .local domain.
+
+rfc7230.txt
+	Hypertext Transfer Protocol (HTTP/1.1): Message Syntax and Routing
+	Details the message 'frame' delimiters, first-line, and URL
+	syntax, generic parsing rules, connection management, routing,
+	and transfer encoding.
+
+rfc7231.txt
+	Hypertext Transfer Protocol (HTTP/1.1): Semantics and Content
+	Details the basic HTTP methods, headers and status code values
+	and behaviour requirements imposed by each.
+
+rfc7232.txt
+	Hypertext Transfer Protocol (HTTP/1.1): Conditional Requests
+	Last-Modified and Etag validator headers,
+	If-* conditional headers,
+	304 and 412 status codes.
+
+rfc7233.txt
+	Hypertext Transfer Protocol (HTTP/1.1): Range Requests
+	Defines range requests and the rules for constructing and
+	combining responses to those requests.
+
+rfc7234.txt
+	Hypertext Transfer Protocol (HTTP/1.1): Caching
+	Defines HTTP caches and the associated header fields that
+	control cache behavior or indicate cacheable response messages.
+
+rfc7235.txt
+	Hypertext Transfer Protocol (HTTP/1.1): Authentication
+
+rfc7238.txt
+	The Hypertext Transfer Protocol Status Code 308 (Permanent Redirect)
+
+rfc7239.txt
+	Forwarded HTTP Extension
+	Details the Forwarded: header replacement for X-Forwarded-For
+	and other X-Forwarded-* variants
@@ -0,0 +1,1571 @@
+
+
+
+
+
+
+Internet Engineering Task Force (IETF)                  R. Fielding, Ed.
+Request for Comments: 7232                                         Adobe
+Obsoletes: 2616                                          J. Reschke, Ed.
+Category: Standards Track                                     greenbytes
+ISSN: 2070-1721                                                June 2014
+
+
+      Hypertext Transfer Protocol (HTTP/1.1): Conditional Requests
+
+Abstract
+
+   The Hypertext Transfer Protocol (HTTP) is a stateless application-
+   level protocol for distributed, collaborative, hypertext information
+   systems.  This document defines HTTP/1.1 conditional requests,
+   including metadata header fields for indicating state changes,
+   request header fields for making preconditions on such state, and
+   rules for constructing the responses to a conditional request when
+   one or more preconditions evaluate to false.
+
+Status of This Memo
+
+   This is an Internet Standards Track document.
+
+   This document is a product of the Internet Engineering Task Force
+   (IETF).  It represents the consensus of the IETF community.  It has
+   received public review and has been approved for publication by the
+   Internet Engineering Steering Group (IESG).  Further information on
+   Internet Standards is available in Section 2 of RFC 5741.
+
+   Information about the current status of this document, any errata,
+   and how to provide feedback on it may be obtained at
+   http://www.rfc-editor.org/info/rfc7232.
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+Fielding & Reschke           Standards Track                    [Page 1]
+
+RFC 7232              HTTP/1.1 Conditional Requests            June 2014
+
+
+Copyright Notice
+
+   Copyright (c) 2014 IETF Trust and the persons identified as the
+   document authors.  All rights reserved.
+
+   This document is subject to BCP 78 and the IETF Trust's Legal
+   Provisions Relating to IETF Documents
+   (http://trustee.ietf.org/license-info) in effect on the date of
+   publication of this document.  Please review these documents
+   carefully, as they describe your rights and restrictions with respect
+   to this document.  Code Components extracted from this document must
+   include Simplified BSD License text as described in Section 4.e of
+   the Trust Legal Provisions and are provided without warranty as
+   described in the Simplified BSD License.
+
+   This document may contain material from IETF Documents or IETF
+   Contributions published or made publicly available before November
+   10, 2008.  The person(s) controlling the copyright in some of this
+   material may not have granted the IETF Trust the right to allow
+   modifications of such material outside the IETF Standards Process.
+   Without obtaining an adequate license from the person(s) controlling
+   the copyright in such materials, this document may not be modified
+   outside the IETF Standards Process, and derivative works of it may
+   not be created outside the IETF Standards Process, except to format
+   it for publication as an RFC or to translate it into languages other
+   than English.
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+Fielding & Reschke           Standards Track                    [Page 2]
+
+RFC 7232              HTTP/1.1 Conditional Requests            June 2014
+
+
+Table of Contents
+
+   1. Introduction ....................................................4
+      1.1. Conformance and Error Handling .............................4
+      1.2. Syntax Notation ............................................4
+   2. Validators ......................................................5
+      2.1. Weak versus Strong .........................................5
+      2.2. Last-Modified ..............................................7
+           2.2.1. Generation ..........................................7
+           2.2.2. Comparison ..........................................8
+      2.3. ETag .......................................................9
+           2.3.1. Generation .........................................10
+           2.3.2. Comparison .........................................10
+           2.3.3. Example: Entity-Tags Varying on
+                  Content-Negotiated Resources .......................11
+      2.4. When to Use Entity-Tags and Last-Modified Dates ...........12
+   3. Precondition Header Fields .....................................13
+      3.1. If-Match ..................................................13
+      3.2. If-None-Match .............................................14
+      3.3. If-Modified-Since .........................................16
+      3.4. If-Unmodified-Since .......................................17
+      3.5. If-Range ..................................................18
+   4. Status Code Definitions ........................................18
+      4.1. 304 Not Modified ..........................................18
+      4.2. 412 Precondition Failed ...................................19
+   5. Evaluation .....................................................19
+   6. Precedence .....................................................20
+   7. IANA Considerations ............................................22
+      7.1. Status Code Registration ..................................22
+      7.2. Header Field Registration .................................22
+   8. Security Considerations ........................................22
+   9. Acknowledgments ................................................23
+   10. References ....................................................24
+      10.1. Normative References .....................................24
+      10.2. Informative References ...................................24
+   Appendix A. Changes from RFC 2616 .................................25
+   Appendix B. Imported ABNF .........................................25
+   Appendix C. Collected ABNF ........................................26
+   Index .............................................................27
+
+
+
+
+
+
+
+
+
+
+
+
+Fielding & Reschke           Standards Track                    [Page 3]
+
+RFC 7232              HTTP/1.1 Conditional Requests            June 2014
+
+
+1.  Introduction
+
+   Conditional requests are HTTP requests [RFC7231] that include one or
+   more header fields indicating a precondition to be tested before
+   applying the method semantics to the target resource.  This document
+   defines the HTTP/1.1 conditional request mechanisms in terms of the
+   architecture, syntax notation, and conformance criteria defined in
+   [RFC7230].
+
+   Conditional GET requests are the most efficient mechanism for HTTP
+   cache updates [RFC7234].  Conditionals can also be applied to
+   state-changing methods, such as PUT and DELETE, to prevent the "lost
+   update" problem: one client accidentally overwriting the work of
+   another client that has been acting in parallel.
+
+   Conditional request preconditions are based on the state of the
+   target resource as a whole (its current value set) or the state as
+   observed in a previously obtained representation (one value in that
+   set).  A resource might have multiple current representations, each
+   with its own observable state.  The conditional request mechanisms
+   assume that the mapping of requests to a "selected representation"
+   (Section 3 of [RFC7231]) will be consistent over time if the server
+   intends to take advantage of conditionals.  Regardless, if the
+   mapping is inconsistent and the server is unable to select the
+   appropriate representation, then no harm will result when the
+   precondition evaluates to false.
+
+   The conditional request preconditions defined by this specification
+   (Section 3) are evaluated when applicable to the recipient
+   (Section 5) according to their order of precedence (Section 6).
+
+1.1.  Conformance and Error Handling
+
+   The key words "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT",
+   "SHOULD", "SHOULD NOT", "RECOMMENDED", "MAY", and "OPTIONAL" in this
+   document are to be interpreted as described in [RFC2119].
+
+   Conformance criteria and considerations regarding error handling are
+   defined in Section 2.5 of [RFC7230].
+
+1.2.  Syntax Notation
+
+   This specification uses the Augmented Backus-Naur Form (ABNF)
+   notation of [RFC5234] with a list extension, defined in Section 7 of
+   [RFC7230], that allows for compact definition of comma-separated
+   lists using a '#' operator (similar to how the '*' operator indicates
+
+
+
+
+
+Fielding & Reschke           Standards Track                    [Page 4]
+
+RFC 7232              HTTP/1.1 Conditional Requests            June 2014
+
+
+   repetition).  Appendix B describes rules imported from other
+   documents.  Appendix C shows the collected grammar with all list
+   operators expanded to standard ABNF notation.
+
+2.  Validators
+
+   This specification defines two forms of metadata that are commonly
+   used to observe resource state and test for preconditions:
+   modification dates (Section 2.2) and opaque entity tags
+   (Section 2.3).  Additional metadata that reflects resource state has
+   been defined by various extensions of HTTP, such as Web Distributed
+   Authoring and Versioning (WebDAV, [RFC4918]), that are beyond the
+   scope of this specification.  A resource metadata value is referred
+   to as a "validator" when it is used within a precondition.
+
+2.1.  Weak versus Strong
+
+   Validators come in two flavors: strong or weak.  Weak validators are
+   easy to generate but are far less useful for comparisons.  Strong
+   validators are ideal for comparisons but can be very difficult (and
+   occasionally impossible) to generate efficiently.  Rather than impose
+   that all forms of resource adhere to the same strength of validator,
+   HTTP exposes the type of validator in use and imposes restrictions on
+   when weak validators can be used as preconditions.
+
+   A "strong validator" is representation metadata that changes value
+   whenever a change occurs to the representation data that would be
+   observable in the payload body of a 200 (OK) response to GET.
+
+   A strong validator might change for reasons other than a change to
+   the representation data, such as when a semantically significant part
+   of the representation metadata is changed (e.g., Content-Type), but
+   it is in the best interests of the origin server to only change the
+   value when it is necessary to invalidate the stored responses held by
+   remote caches and authoring tools.
+
+   Cache entries might persist for arbitrarily long periods, regardless
+   of expiration times.  Thus, a cache might attempt to validate an
+   entry using a validator that it obtained in the distant past.  A
+   strong validator is unique across all versions of all representations
+   associated with a particular resource over time.  However, there is
+   no implication of uniqueness across representations of different
+   resources (i.e., the same strong validator might be in use for
+   representations of multiple resources at the same time and does not
+   imply that those representations are equivalent).
+
+
+
+
+
+
+Fielding & Reschke           Standards Track                    [Page 5]
+
+RFC 7232              HTTP/1.1 Conditional Requests            June 2014
+
+
+   There are a variety of strong validators used in practice.  The best
+   are based on strict revision control, wherein each change to a
+   representation always results in a unique node name and revision
+   identifier being assigned before the representation is made
+   accessible to GET.  A collision-resistant hash function applied to
+   the representation data is also sufficient if the data is available
+   prior to the response header fields being sent and the digest does
+   not need to be recalculated every time a validation request is
+   received.  However, if a resource has distinct representations that
+   differ only in their metadata, such as might occur with content
+   negotiation over media types that happen to share the same data
+   format, then the origin server needs to incorporate additional
+   information in the validator to distinguish those representations.
+
+   In contrast, a "weak validator" is representation metadata that might
+   not change for every change to the representation data.  This
+   weakness might be due to limitations in how the value is calculated,
+   such as clock resolution, an inability to ensure uniqueness for all
+   possible representations of the resource, or a desire of the resource
+   owner to group representations by some self-determined set of
+   equivalency rather than unique sequences of data.  An origin server
+   SHOULD change a weak entity-tag whenever it considers prior
+   representations to be unacceptable as a substitute for the current
+   representation.  In other words, a weak entity-tag ought to change
+   whenever the origin server wants caches to invalidate old responses.
+
+   For example, the representation of a weather report that changes in
+   content every second, based on dynamic measurements, might be grouped
+   into sets of equivalent representations (from the origin server's
+   perspective) with the same weak validator in order to allow cached
+   representations to be valid for a reasonable period of time (perhaps
+   adjusted dynamically based on server load or weather quality).
+   Likewise, a representation's modification time, if defined with only
+   one-second resolution, might be a weak validator if it is possible
+   for the representation to be modified twice during a single second
+   and retrieved between those modifications.
+
+   Likewise, a validator is weak if it is shared by two or more
+   representations of a given resource at the same time, unless those
+   representations have identical representation data.  For example, if
+   the origin server sends the same validator for a representation with
+   a gzip content coding applied as it does for a representation with no
+   content coding, then that validator is weak.  However, two
+   simultaneous representations might share the same strong validator if
+   they differ only in the representation metadata, such as when two
+   different media types are available for the same representation data.
+
+
+
+
+
+Fielding & Reschke           Standards Track                    [Page 6]
+
+RFC 7232              HTTP/1.1 Conditional Requests            June 2014
+
+
+   Strong validators are usable for all conditional requests, including
+   cache validation, partial content ranges, and "lost update"
+   avoidance.  Weak validators are only usable when the client does not
+   require exact equality with previously obtained representation data,
+   such as when validating a cache entry or limiting a web traversal to
+   recent changes.
+
+2.2.  Last-Modified
+
+   The "Last-Modified" header field in a response provides a timestamp
+   indicating the date and time at which the origin server believes the
+   selected representation was last modified, as determined at the
+   conclusion of handling the request.
+
+     Last-Modified = HTTP-date
+
+   An example of its use is
+
+     Last-Modified: Tue, 15 Nov 1994 12:45:26 GMT
+
+2.2.1.  Generation
+
+   An origin server SHOULD send Last-Modified for any selected
+   representation for which a last modification date can be reasonably
+   and consistently determined, since its use in conditional requests
+   and evaluating cache freshness ([RFC7234]) results in a substantial
+   reduction of HTTP traffic on the Internet and can be a significant
+   factor in improving service scalability and reliability.
+
+   A representation is typically the sum of many parts behind the
+   resource interface.  The last-modified time would usually be the most
+   recent time that any of those parts were changed.  How that value is
+   determined for any given resource is an implementation detail beyond
+   the scope of this specification.  What matters to HTTP is how
+   recipients of the Last-Modified header field can use its value to
+   make conditional requests and test the validity of locally cached
+   responses.
+
+   An origin server SHOULD obtain the Last-Modified value of the
+   representation as close as possible to the time that it generates the
+   Date field value for its response.  This allows a recipient to make
+   an accurate assessment of the representation's modification time,
+   especially if the representation changes near the time that the
+   response is generated.
+
+   An origin server with a clock MUST NOT send a Last-Modified date that
+   is later than the server's time of message origination (Date).  If
+   the last modification time is derived from implementation-specific
+
+
+
+Fielding & Reschke           Standards Track                    [Page 7]
+
+RFC 7232              HTTP/1.1 Conditional Requests            June 2014
+
+
+   metadata that evaluates to some time in the future, according to the
+   origin server's clock, then the origin server MUST replace that value
+   with the message origination date.  This prevents a future
+   modification date from having an adverse impact on cache validation.
+
+   An origin server without a clock MUST NOT assign Last-Modified values
+   to a response unless these values were associated with the resource
+   by some other system or user with a reliable clock.
+
+2.2.2.  Comparison
+
+   A Last-Modified time, when used as a validator in a request, is
+   implicitly weak unless it is possible to deduce that it is strong,
+   using the following rules:
+
+   o  The validator is being compared by an origin server to the actual
+      current validator for the representation and,
+
+   o  That origin server reliably knows that the associated
+      representation did not change twice during the second covered by
+      the presented validator.
+
+   or
+
+   o  The validator is about to be used by a client in an
+      If-Modified-Since, If-Unmodified-Since, or If-Range header field,
+      because the client has a cache entry for the associated
+      representation, and
+
+   o  That cache entry includes a Date value, which gives the time when
+      the origin server sent the original response, and
+
+   o  The presented Last-Modified time is at least 60 seconds before the
+      Date value.
+
+   or
+
+   o  The validator is being compared by an intermediate cache to the
+      validator stored in its cache entry for the representation, and
+
+   o  That cache entry includes a Date value, which gives the time when
+      the origin server sent the original response, and
+
+   o  The presented Last-Modified time is at least 60 seconds before the
+      Date value.
+
+
+
+
+
+
+Fielding & Reschke           Standards Track                    [Page 8]
+
+RFC 7232              HTTP/1.1 Conditional Requests            June 2014
+
+
+   This method relies on the fact that if two different responses were
+   sent by the origin server during the same second, but both had the
+   same Last-Modified time, then at least one of those responses would
+   have a Date value equal to its Last-Modified time.  The arbitrary
+   60-second limit guards against the possibility that the Date and
+   Last-Modified values are generated from different clocks or at
+   somewhat different times during the preparation of the response.  An
+   implementation MAY use a value larger than 60 seconds, if it is
+   believed that 60 seconds is too short.
+
+2.3.  ETag
+
+   The "ETag" header field in a response provides the current entity-tag
+   for the selected representation, as determined at the conclusion of
+   handling the request.  An entity-tag is an opaque validator for
+   differentiating between multiple representations of the same
+   resource, regardless of whether those multiple representations are
+   due to resource state changes over time, content negotiation
+   resulting in multiple representations being valid at the same time,
+   or both.  An entity-tag consists of an opaque quoted string, possibly
+   prefixed by a weakness indicator.
+
+     ETag       = entity-tag
+
+     entity-tag = [ weak ] opaque-tag
+     weak       = %x57.2F ; "W/", case-sensitive
+     opaque-tag = DQUOTE *etagc DQUOTE
+     etagc      = %x21 / %x23-7E / obs-text
+                ; VCHAR except double quotes, plus obs-text
+
+      Note: Previously, opaque-tag was defined to be a quoted-string
+      ([RFC2616], Section 3.11); thus, some recipients might perform
+      backslash unescaping.  Servers therefore ought to avoid backslash
+      characters in entity tags.
+
+   An entity-tag can be more reliable for validation than a modification
+   date in situations where it is inconvenient to store modification
+   dates, where the one-second resolution of HTTP date values is not
+   sufficient, or where modification dates are not consistently
+   maintained.
+
+   Examples:
+
+     ETag: "xyzzy"
+     ETag: W/"xyzzy"
+     ETag: ""
+
+
+
+
+
+Fielding & Reschke           Standards Track                    [Page 9]
+
+RFC 7232              HTTP/1.1 Conditional Requests            June 2014
+
+
+   An entity-tag can be either a weak or strong validator, with strong
+   being the default.  If an origin server provides an entity-tag for a
+   representation and the generation of that entity-tag does not satisfy
+   all of the characteristics of a strong validator (Section 2.1), then
+   the origin server MUST mark the entity-tag as weak by prefixing its
+   opaque value with "W/" (case-sensitive).
+
+2.3.1.  Generation
+
+   The principle behind entity-tags is that only the service author
+   knows the implementation of a resource well enough to select the most
+   accurate and efficient validation mechanism for that resource, and
+   that any such mechanism can be mapped to a simple sequence of octets
+   for easy comparison.  Since the value is opaque, there is no need for
+   the client to be aware of how each entity-tag is constructed.
+
+   For example, a resource that has implementation-specific versioning
+   applied to all changes might use an internal revision number, perhaps
+   combined with a variance identifier for content negotiation, to
+   accurately differentiate between representations.  Other
+   implementations might use a collision-resistant hash of
+   representation content, a combination of various file attributes, or
+   a modification timestamp that has sub-second resolution.
+
+   An origin server SHOULD send an ETag for any selected representation
+   for which detection of changes can be reasonably and consistently
+   determined, since the entity-tag's use in conditional requests and
+   evaluating cache freshness ([RFC7234]) can result in a substantial
+   reduction of HTTP network traffic and can be a significant factor in
+   improving service scalability and reliability.
+
+2.3.2.  Comparison
+
+   There are two entity-tag comparison functions, depending on whether
+   or not the comparison context allows the use of weak validators:
+
+   o  Strong comparison: two entity-tags are equivalent if both are not
+      weak and their opaque-tags match character-by-character.
+
+   o  Weak comparison: two entity-tags are equivalent if their
+      opaque-tags match character-by-character, regardless of either or
+      both being tagged as "weak".
+
+
+
+
+
+
+
+
+
+Fielding & Reschke           Standards Track                   [Page 10]
+
+RFC 7232              HTTP/1.1 Conditional Requests            June 2014
+
+
+   The example below shows the results for a set of entity-tag pairs and
+   both the weak and strong comparison function results:
+
+   +--------+--------+-------------------+-----------------+
+   | ETag 1 | ETag 2 | Strong Comparison | Weak Comparison |
+   +--------+--------+-------------------+-----------------+
+   | W/"1"  | W/"1"  | no match          | match           |
+   | W/"1"  | W/"2"  | no match          | no match        |
+   | W/"1"  | "1"    | no match          | match           |
+   | "1"    | "1"    | match             | match           |
+   +--------+--------+-------------------+-----------------+
+
+2.3.3.  Example: Entity-Tags Varying on Content-Negotiated Resources
+
+   Consider a resource that is subject to content negotiation (Section
+   3.4 of [RFC7231]), and where the representations sent in response to
+   a GET request vary based on the Accept-Encoding request header field
+   (Section 5.3.4 of [RFC7231]):
+
+   >> Request:
+
+     GET /index HTTP/1.1
+     Host: www.example.com
+     Accept-Encoding: gzip
+
+
+   In this case, the response might or might not use the gzip content
+   coding.  If it does not, the response might look like:
+
+   >> Response:
+
+     HTTP/1.1 200 OK
+     Date: Fri, 26 Mar 2010 00:05:00 GMT
+     ETag: "123-a"
+     Content-Length: 70
+     Vary: Accept-Encoding
+     Content-Type: text/plain
+
+     Hello World!
+     Hello World!
+     Hello World!
+     Hello World!
+     Hello World!
+
+
+
+
+
+
+
+
+Fielding & Reschke           Standards Track                   [Page 11]
+
+RFC 7232              HTTP/1.1 Conditional Requests            June 2014
+
+
+   An alternative representation that does use gzip content coding would
+   be:
+
+   >> Response:
+
+     HTTP/1.1 200 OK
+     Date: Fri, 26 Mar 2010 00:05:00 GMT
+     ETag: "123-b"
+     Content-Length: 43
+     Vary: Accept-Encoding
+     Content-Type: text/plain
+     Content-Encoding: gzip
+
+     ...binary data...
+
+      Note: Content codings are a property of the representation data,
+      so a strong entity-tag for a content-encoded representation has to
+      be distinct from the entity tag of an unencoded representation to
+      prevent potential conflicts during cache updates and range
+      requests.  In contrast, transfer codings (Section 4 of [RFC7230])
+      apply only during message transfer and do not result in distinct
+      entity-tags.
+
+2.4.  When to Use Entity-Tags and Last-Modified Dates
+
+   In 200 (OK) responses to GET or HEAD, an origin server:
+
+   o  SHOULD send an entity-tag validator unless it is not feasible to
+      generate one.
+
+   o  MAY send a weak entity-tag instead of a strong entity-tag, if
+      performance considerations support the use of weak entity-tags, or
+      if it is unfeasible to send a strong entity-tag.
+
+   o  SHOULD send a Last-Modified value if it is feasible to send one.
+
+   In other words, the preferred behavior for an origin server is to
+   send both a strong entity-tag and a Last-Modified value in successful
+   responses to a retrieval request.
+
+   A client:
+
+   o  MUST send that entity-tag in any cache validation request (using
+      If-Match or If-None-Match) if an entity-tag has been provided by
+      the origin server.
+
+
+
+
+
+
+Fielding & Reschke           Standards Track                   [Page 12]
+
+RFC 7232              HTTP/1.1 Conditional Requests            June 2014
+
+
+   o  SHOULD send the Last-Modified value in non-subrange cache
+      validation requests (using If-Modified-Since) if only a
+      Last-Modified value has been provided by the origin server.
+
+   o  MAY send the Last-Modified value in subrange cache validation
+      requests (using If-Unmodified-Since) if only a Last-Modified value
+      has been provided by an HTTP/1.0 origin server.  The user agent
+      SHOULD provide a way to disable this, in case of difficulty.
+
+   o  SHOULD send both validators in cache validation requests if both
+      an entity-tag and a Last-Modified value have been provided by the
+      origin server.  This allows both HTTP/1.0 and HTTP/1.1 caches to
+      respond appropriately.
+
+3.  Precondition Header Fields
+
+   This section defines the syntax and semantics of HTTP/1.1 header
+   fields for applying preconditions on requests.  Section 5 defines
+   when the preconditions are applied.  Section 6 defines the order of
+   evaluation when more than one precondition is present.
+
+3.1.  If-Match
+
+   The "If-Match" header field makes the request method conditional on
+   the recipient origin server either having at least one current
+   representation of the target resource, when the field-value is "*",
+   or having a current representation of the target resource that has an
+   entity-tag matching a member of the list of entity-tags provided in
+   the field-value.
+
+   An origin server MUST use the strong comparison function when
+   comparing entity-tags for If-Match (Section 2.3.2), since the client
+   intends this precondition to prevent the method from being applied if
+   there have been any changes to the representation data.
+
+     If-Match = "*" / 1#entity-tag
+
+   Examples:
+
+     If-Match: "xyzzy"
+     If-Match: "xyzzy", "r2d2xxxx", "c3piozzzz"
+     If-Match: *
+
+   If-Match is most often used with state-changing methods (e.g., POST,
+   PUT, DELETE) to prevent accidental overwrites when multiple user
+   agents might be acting in parallel on the same resource (i.e., to
+
+
+
+
+
+Fielding & Reschke           Standards Track                   [Page 13]
+
+RFC 7232              HTTP/1.1 Conditional Requests            June 2014
+
+
+   prevent the "lost update" problem).  It can also be used with safe
+   methods to abort a request if the selected representation does not
+   match one already stored (or partially stored) from a prior request.
+
+   An origin server that receives an If-Match header field MUST evaluate
+   the condition prior to performing the method (Section 5).  If the
+   field-value is "*", the condition is false if the origin server does
+   not have a current representation for the target resource.  If the
+   field-value is a list of entity-tags, the condition is false if none
+   of the listed tags match the entity-tag of the selected
+   representation.
+
+   An origin server MUST NOT perform the requested method if a received
+   If-Match condition evaluates to false; instead, the origin server
+   MUST respond with either a) the 412 (Precondition Failed) status code
+   or b) one of the 2xx (Successful) status codes if the origin server
+   has verified that a state change is being requested and the final
+   state is already reflected in the current state of the target
+   resource (i.e., the change requested by the user agent has already
+   succeeded, but the user agent might not be aware of it, perhaps
+   because the prior response was lost or a compatible change was made
+   by some other user agent).  In the latter case, the origin server
+   MUST NOT send a validator header field in the response unless it can
+   verify that the request is a duplicate of an immediately prior change
+   made by the same user agent.
+
+   The If-Match header field can be ignored by caches and intermediaries
+   because it is not applicable to a stored response.
+
+3.2.  If-None-Match
+
+   The "If-None-Match" header field makes the request method conditional
+   on a recipient cache or origin server either not having any current
+   representation of the target resource, when the field-value is "*",
+   or having a selected representation with an entity-tag that does not
+   match any of those listed in the field-value.
+
+   A recipient MUST use the weak comparison function when comparing
+   entity-tags for If-None-Match (Section 2.3.2), since weak entity-tags
+   can be used for cache validation even if there have been changes to
+   the representation data.
+
+     If-None-Match = "*" / 1#entity-tag
+
+
+
+
+
+
+
+
+Fielding & Reschke           Standards Track                   [Page 14]
+
+RFC 7232              HTTP/1.1 Conditional Requests            June 2014
+
+
+   Examples:
+
+     If-None-Match: "xyzzy"
+     If-None-Match: W/"xyzzy"
+     If-None-Match: "xyzzy", "r2d2xxxx", "c3piozzzz"
+     If-None-Match: W/"xyzzy", W/"r2d2xxxx", W/"c3piozzzz"
+     If-None-Match: *
+
+   If-None-Match is primarily used in conditional GET requests to enable
+   efficient updates of cached information with a minimum amount of
+   transaction overhead.  When a client desires to update one or more
+   stored responses that have entity-tags, the client SHOULD generate an
+   If-None-Match header field containing a list of those entity-tags
+   when making a GET request; this allows recipient servers to send a
+   304 (Not Modified) response to indicate when one of those stored
+   responses matches the selected representation.
+
+   If-None-Match can also be used with a value of "*" to prevent an
+   unsafe request method (e.g., PUT) from inadvertently modifying an
+   existing representation of the target resource when the client
+   believes that the resource does not have a current representation
+   (Section 4.2.1 of [RFC7231]).  This is a variation on the "lost
+   update" problem that might arise if more than one client attempts to
+   create an initial representation for the target resource.
+
+   An origin server that receives an If-None-Match header field MUST
+   evaluate the condition prior to performing the method (Section 5).
+   If the field-value is "*", the condition is false if the origin
+   server has a current representation for the target resource.  If the
+   field-value is a list of entity-tags, the condition is false if one
+   of the listed tags match the entity-tag of the selected
+   representation.
+
+   An origin server MUST NOT perform the requested method if the
+   condition evaluates to false; instead, the origin server MUST respond
+   with either a) the 304 (Not Modified) status code if the request
+   method is GET or HEAD or b) the 412 (Precondition Failed) status code
+   for all other request methods.
+
+   Requirements on cache handling of a received If-None-Match header
+   field are defined in Section 4.3.2 of [RFC7234].
+
+
+
+
+
+
+
+
+
+
+Fielding & Reschke           Standards Track                   [Page 15]
+
+RFC 7232              HTTP/1.1 Conditional Requests            June 2014
+
+
+3.3.  If-Modified-Since
+
+   The "If-Modified-Since" header field makes a GET or HEAD request
+   method conditional on the selected representation's modification date
+   being more recent than the date provided in the field-value.
+   Transfer of the selected representation's data is avoided if that
+   data has not changed.
+
+     If-Modified-Since = HTTP-date
+
+   An example of the field is:
+
+     If-Modified-Since: Sat, 29 Oct 1994 19:43:31 GMT
+
+   A recipient MUST ignore If-Modified-Since if the request contains an
+   If-None-Match header field; the condition in If-None-Match is
+   considered to be a more accurate replacement for the condition in
+   If-Modified-Since, and the two are only combined for the sake of
+   interoperating with older intermediaries that might not implement
+   If-None-Match.
+
+   A recipient MUST ignore the If-Modified-Since header field if the
+   received field-value is not a valid HTTP-date, or if the request
+   method is neither GET nor HEAD.
+
+   A recipient MUST interpret an If-Modified-Since field-value's
+   timestamp in terms of the origin server's clock.
+
+   If-Modified-Since is typically used for two distinct purposes: 1) to
+   allow efficient updates of a cached representation that does not have
+   an entity-tag and 2) to limit the scope of a web traversal to
+   resources that have recently changed.
+
+   When used for cache updates, a cache will typically use the value of
+   the cached message's Last-Modified field to generate the field value
+   of If-Modified-Since.  This behavior is most interoperable for cases
+   where clocks are poorly synchronized or when the server has chosen to
+   only honor exact timestamp matches (due to a problem with
+   Last-Modified dates that appear to go "back in time" when the origin
+   server's clock is corrected or a representation is restored from an
+   archived backup).  However, caches occasionally generate the field
+   value based on other data, such as the Date header field of the
+   cached message or the local clock time that the message was received,
+   particularly when the cached message does not contain a Last-Modified
+   field.
+
+
+
+
+
+
+Fielding & Reschke           Standards Track                   [Page 16]
+
+RFC 7232              HTTP/1.1 Conditional Requests            June 2014
+
+
+   When used for limiting the scope of retrieval to a recent time
+   window, a user agent will generate an If-Modified-Since field value
+   based on either its own local clock or a Date header field received
+   from the server in a prior response.  Origin servers that choose an
+   exact timestamp match based on the selected representation's
+   Last-Modified field will not be able to help the user agent limit its
+   data transfers to only those changed during the specified window.
+
+   An origin server that receives an If-Modified-Since header field
+   SHOULD evaluate the condition prior to performing the method
+   (Section 5).  The origin server SHOULD NOT perform the requested
+   method if the selected representation's last modification date is
+   earlier than or equal to the date provided in the field-value;
+   instead, the origin server SHOULD generate a 304 (Not Modified)
+   response, including only those metadata that are useful for
+   identifying or updating a previously cached response.
+
+   Requirements on cache handling of a received If-Modified-Since header
+   field are defined in Section 4.3.2 of [RFC7234].
+
+3.4.  If-Unmodified-Since
+
+   The "If-Unmodified-Since" header field makes the request method
+   conditional on the selected representation's last modification date
+   being earlier than or equal to the date provided in the field-value.
+   This field accomplishes the same purpose as If-Match for cases where
+   the user agent does not have an entity-tag for the representation.
+
+     If-Unmodified-Since = HTTP-date
+
+   An example of the field is:
+
+     If-Unmodified-Since: Sat, 29 Oct 1994 19:43:31 GMT
+
+   A recipient MUST ignore If-Unmodified-Since if the request contains
+   an If-Match header field; the condition in If-Match is considered to
+   be a more accurate replacement for the condition in
+   If-Unmodified-Since, and the two are only combined for the sake of
+   interoperating with older intermediaries that might not implement
+   If-Match.
+
+   A recipient MUST ignore the If-Unmodified-Since header field if the
+   received field-value is not a valid HTTP-date.
+
+   A recipient MUST interpret an If-Unmodified-Since field-value's
+   timestamp in terms of the origin server's clock.
+
+
+
+
+
+Fielding & Reschke           Standards Track                   [Page 17]
+
+RFC 7232              HTTP/1.1 Conditional Requests            June 2014
+
+
+   If-Unmodified-Since is most often used with state-changing methods
+   (e.g., POST, PUT, DELETE) to prevent accidental overwrites when
+   multiple user agents might be acting in parallel on a resource that
+   does not supply entity-tags with its representations (i.e., to
+   prevent the "lost update" problem).  It can also be used with safe
+   methods to abort a request if the selected representation does not
+   match one already stored (or partially stored) from a prior request.
+
+   An origin server that receives an If-Unmodified-Since header field
+   MUST evaluate the condition prior to performing the method
+   (Section 5).  The origin server MUST NOT perform the requested method
+   if the selected representation's last modification date is more
+   recent than the date provided in the field-value; instead the origin
+   server MUST respond with either a) the 412 (Precondition Failed)
+   status code or b) one of the 2xx (Successful) status codes if the
+   origin server has verified that a state change is being requested and
+   the final state is already reflected in the current state of the
+   target resource (i.e., the change requested by the user agent has
+   already succeeded, but the user agent might not be aware of that
+   because the prior response message was lost or a compatible change
+   was made by some other user agent).  In the latter case, the origin
+   server MUST NOT send a validator header field in the response unless
+   it can verify that the request is a duplicate of an immediately prior
+   change made by the same user agent.
+
+   The If-Unmodified-Since header field can be ignored by caches and
+   intermediaries because it is not applicable to a stored response.
+
+3.5.  If-Range
+
+   The "If-Range" header field provides a special conditional request
+   mechanism that is similar to the If-Match and If-Unmodified-Since
+   header fields but that instructs the recipient to ignore the Range
+   header field if the validator doesn't match, resulting in transfer of
+   the new selected representation instead of a 412 (Precondition
+   Failed) response.  If-Range is defined in Section 3.2 of [RFC7233].
+
+4.  Status Code Definitions
+
+4.1.  304 Not Modified
+
+   The 304 (Not Modified) status code indicates that a conditional GET
+   or HEAD request has been received and would have resulted in a 200
+   (OK) response if it were not for the fact that the condition
+   evaluated to false.  In other words, there is no need for the server
+   to transfer a representation of the target resource because the
+   request indicates that the client, which made the request
+
+
+
+
+Fielding & Reschke           Standards Track                   [Page 18]
+
+RFC 7232              HTTP/1.1 Conditional Requests            June 2014
+
+
+   conditional, already has a valid representation; the server is
+   therefore redirecting the client to make use of that stored
+   representation as if it were the payload of a 200 (OK) response.
+
+   The server generating a 304 response MUST generate any of the
+   following header fields that would have been sent in a 200 (OK)
+   response to the same request: Cache-Control, Content-Location, Date,
+   ETag, Expires, and Vary.
+
+   Since the goal of a 304 response is to minimize information transfer
+   when the recipient already has one or more cached representations, a
+   sender SHOULD NOT generate representation metadata other than the
+   above listed fields unless said metadata exists for the purpose of
+   guiding cache updates (e.g., Last-Modified might be useful if the
+   response does not have an ETag field).
+
+   Requirements on a cache that receives a 304 response are defined in
+   Section 4.3.4 of [RFC7234].  If the conditional request originated
+   with an outbound client, such as a user agent with its own cache
+   sending a conditional GET to a shared proxy, then the proxy SHOULD
+   forward the 304 response to that client.
+
+   A 304 response cannot contain a message-body; it is always terminated
+   by the first empty line after the header fields.
+
+4.2.  412 Precondition Failed
+
+   The 412 (Precondition Failed) status code indicates that one or more
+   conditions given in the request header fields evaluated to false when
+   tested on the server.  This response code allows the client to place
+   preconditions on the current resource state (its current
+   representations and metadata) and, thus, prevent the request method
+   from being applied if the target resource is in an unexpected state.
+
+5.  Evaluation
+
+   Except when excluded below, a recipient cache or origin server MUST
+   evaluate received request preconditions after it has successfully
+   performed its normal request checks and just before it would perform
+   the action associated with the request method.  A server MUST ignore
+   all received preconditions if its response to the same request
+   without those conditions would have been a status code other than a
+   2xx (Successful) or 412 (Precondition Failed).  In other words,
+   redirects and failures take precedence over the evaluation of
+   preconditions in conditional requests.
+
+
+
+
+
+
+Fielding & Reschke           Standards Track                   [Page 19]
+
+RFC 7232              HTTP/1.1 Conditional Requests            June 2014
+
+
+   A server that is not the origin server for the target resource and
+   cannot act as a cache for requests on the target resource MUST NOT
+   evaluate the conditional request header fields defined by this
+   specification, and it MUST forward them if the request is forwarded,
+   since the generating client intends that they be evaluated by a
+   server that can provide a current representation.  Likewise, a server
+   MUST ignore the conditional request header fields defined by this
+   specification when received with a request method that does not
+   involve the selection or modification of a selected representation,
+   such as CONNECT, OPTIONS, or TRACE.
+
+   Conditional request header fields that are defined by extensions to
+   HTTP might place conditions on all recipients, on the state of the
+   target resource in general, or on a group of resources.  For
+   instance, the "If" header field in WebDAV can make a request
+   conditional on various aspects of multiple resources, such as locks,
+   if the recipient understands and implements that field ([RFC4918],
+   Section 10.4).
+
+   Although conditional request header fields are defined as being
+   usable with the HEAD method (to keep HEAD's semantics consistent with
+   those of GET), there is no point in sending a conditional HEAD
+   because a successful response is around the same size as a 304 (Not
+   Modified) response and more useful than a 412 (Precondition Failed)
+   response.
+
+6.  Precedence
+
+   When more than one conditional request header field is present in a
+   request, the order in which the fields are evaluated becomes
+   important.  In practice, the fields defined in this document are
+   consistently implemented in a single, logical order, since "lost
+   update" preconditions have more strict requirements than cache
+   validation, a validated cache is more efficient than a partial
+   response, and entity tags are presumed to be more accurate than date
+   validators.
+
+   A recipient cache or origin server MUST evaluate the request
+   preconditions defined by this specification in the following order:
+
+   1.  When recipient is the origin server and If-Match is present,
+       evaluate the If-Match precondition:
+
+       *  if true, continue to step 3
+
+       *  if false, respond 412 (Precondition Failed) unless it can be
+          determined that the state-changing request has already
+          succeeded (see Section 3.1)
+
+
+
+Fielding & Reschke           Standards Track                   [Page 20]
+
+RFC 7232              HTTP/1.1 Conditional Requests            June 2014
+
+
+   2.  When recipient is the origin server, If-Match is not present, and
+       If-Unmodified-Since is present, evaluate the If-Unmodified-Since
+       precondition:
+
+       *  if true, continue to step 3
+
+       *  if false, respond 412 (Precondition Failed) unless it can be
+          determined that the state-changing request has already
+          succeeded (see Section 3.4)
+
+   3.  When If-None-Match is present, evaluate the If-None-Match
+       precondition:
+
+       *  if true, continue to step 5
+
+       *  if false for GET/HEAD, respond 304 (Not Modified)
+
+       *  if false for other methods, respond 412 (Precondition Failed)
+
+   4.  When the method is GET or HEAD, If-None-Match is not present, and
+       If-Modified-Since is present, evaluate the If-Modified-Since
+       precondition:
+
+       *  if true, continue to step 5
+
+       *  if false, respond 304 (Not Modified)
+
+   5.  When the method is GET and both Range and If-Range are present,
+       evaluate the If-Range precondition:
+
+       *  if the validator matches and the Range specification is
+          applicable to the selected representation, respond 206
+          (Partial Content) [RFC7233]
+
+   6.  Otherwise,
+
+       *  all conditions are met, so perform the requested action and
+          respond according to its success or failure.
+
+   Any extension to HTTP/1.1 that defines additional conditional request
+   header fields ought to define its own expectations regarding the
+   order for evaluating such fields in relation to those defined in this
+   document and other conditionals that might be found in practice.
+
+
+
+
+
+
+
+
+Fielding & Reschke           Standards Track                   [Page 21]
+
+RFC 7232              HTTP/1.1 Conditional Requests            June 2014
+
+
+7.  IANA Considerations
+
+7.1.  Status Code Registration
+
+   The "Hypertext Transfer Protocol (HTTP) Status Code Registry" located
+   at <http://www.iana.org/assignments/http-status-codes> has been
+   updated with the registrations below:
+
+   +-------+---------------------+-------------+
+   | Value | Description         | Reference   |
+   +-------+---------------------+-------------+
+   | 304   | Not Modified        | Section 4.1 |
+   | 412   | Precondition Failed | Section 4.2 |
+   +-------+---------------------+-------------+
+
+7.2.  Header Field Registration
+
+   HTTP header fields are registered within the "Message Headers"
+   registry maintained at
+   <http://www.iana.org/assignments/message-headers/>.
+
+   This document defines the following HTTP header fields, so their
+   associated registry entries have been updated according to the
+   permanent registrations below (see [BCP90]):
+
+   +---------------------+----------+----------+-------------+
+   | Header Field Name   | Protocol | Status   | Reference   |
+   +---------------------+----------+----------+-------------+
+   | ETag                | http     | standard | Section 2.3 |
+   | If-Match            | http     | standard | Section 3.1 |
+   | If-Modified-Since   | http     | standard | Section 3.3 |
+   | If-None-Match       | http     | standard | Section 3.2 |
+   | If-Unmodified-Since | http     | standard | Section 3.4 |
+   | Last-Modified       | http     | standard | Section 2.2 |
+   +---------------------+----------+----------+-------------+
+
+   The change controller is: "IETF (iesg@ietf.org) - Internet
+   Engineering Task Force".
+
+8.  Security Considerations
+
+   This section is meant to inform developers, information providers,
+   and users of known security concerns specific to the HTTP conditional
+   request mechanisms.  More general security considerations are
+   addressed in HTTP "Message Syntax and Routing" [RFC7230] and
+   "Semantics and Content" [RFC7231].
+
+
+
+
+
+Fielding & Reschke           Standards Track                   [Page 22]
+
+RFC 7232              HTTP/1.1 Conditional Requests            June 2014
+
+
+   The validators defined by this specification are not intended to
+   ensure the validity of a representation, guard against malicious
+   changes, or detect man-in-the-middle attacks.  At best, they enable
+   more efficient cache updates and optimistic concurrent writes when
+   all participants are behaving nicely.  At worst, the conditions will
+   fail and the client will receive a response that is no more harmful
+   than an HTTP exchange without conditional requests.
+
+   An entity-tag can be abused in ways that create privacy risks.  For
+   example, a site might deliberately construct a semantically invalid
+   entity-tag that is unique to the user or user agent, send it in a
+   cacheable response with a long freshness time, and then read that
+   entity-tag in later conditional requests as a means of re-identifying
+   that user or user agent.  Such an identifying tag would become a
+   persistent identifier for as long as the user agent retained the
+   original cache entry.  User agents that cache representations ought
+   to ensure that the cache is cleared or replaced whenever the user
+   performs privacy-maintaining actions, such as clearing stored cookies
+   or changing to a private browsing mode.
+
+9.  Acknowledgments
+
+   See Section 10 of [RFC7230].
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+Fielding & Reschke           Standards Track                   [Page 23]
+
+RFC 7232              HTTP/1.1 Conditional Requests            June 2014
+
+
+10.  References
+
+10.1.  Normative References
+
+   [RFC2119]  Bradner, S., "Key words for use in RFCs to Indicate
+              Requirement Levels", BCP 14, RFC 2119, March 1997.
+
+   [RFC5234]  Crocker, D., Ed. and P. Overell, "Augmented BNF for Syntax
+              Specifications: ABNF", STD 68, RFC 5234, January 2008.
+
+   [RFC7230]  Fielding, R., Ed. and J. Reschke, Ed., "Hypertext Transfer
+              Protocol (HTTP/1.1): Message Syntax and Routing",
+              RFC 7230, June 2014.
+
+   [RFC7231]  Fielding, R., Ed. and J. Reschke, Ed., "Hypertext Transfer
+              Protocol (HTTP/1.1): Semantics and Content", RFC 7231,
+              June 2014.
+
+   [RFC7233]  Fielding, R., Ed., Lafon, Y., Ed., and J. Reschke, Ed.,
+              "Hypertext Transfer Protocol (HTTP/1.1): Range Requests",
+              RFC 7233, June 2014.
+
+   [RFC7234]  Fielding, R., Ed., Nottingham, M., Ed., and J. Reschke,
+              Ed., "Hypertext Transfer Protocol (HTTP/1.1): Caching",
+              RFC 7234, June 2014.
+
+10.2.  Informative References
+
+   [BCP90]    Klyne, G., Nottingham, M., and J. Mogul, "Registration
+              Procedures for Message Header Fields", BCP 90, RFC 3864,
+              September 2004.
+
+   [RFC2616]  Fielding, R., Gettys, J., Mogul, J., Frystyk, H.,
+              Masinter, L., Leach, P., and T. Berners-Lee, "Hypertext
+              Transfer Protocol -- HTTP/1.1", RFC 2616, June 1999.
+
+   [RFC4918]  Dusseault, L., Ed., "HTTP Extensions for Web Distributed
+              Authoring and Versioning (WebDAV)", RFC 4918, June 2007.
+
+
+
+
+
+
+
+
+
+
+
+
+
+Fielding & Reschke           Standards Track                   [Page 24]
+
+RFC 7232              HTTP/1.1 Conditional Requests            June 2014
+
+
+Appendix A.  Changes from RFC 2616
+
+   The definition of validator weakness has been expanded and clarified.
+   (Section 2.1)
+
+   Weak entity-tags are now allowed in all requests except range
+   requests.  (Sections 2.1 and 3.2)
+
+   The ETag header field ABNF has been changed to not use quoted-string,
+   thus avoiding escaping issues.  (Section 2.3)
+
+   ETag is defined to provide an entity tag for the selected
+   representation, thereby clarifying what it applies to in various
+   situations (such as a PUT response).  (Section 2.3)
+
+   The precedence for evaluation of conditional requests has been
+   defined.  (Section 6)
+
+Appendix B.  Imported ABNF
+
+   The following core rules are included by reference, as defined in
+   Appendix B.1 of [RFC5234]: ALPHA (letters), CR (carriage return),
+   CRLF (CR LF), CTL (controls), DIGIT (decimal 0-9), DQUOTE (double
+   quote), HEXDIG (hexadecimal 0-9/A-F/a-f), LF (line feed), OCTET (any
+   8-bit sequence of data), SP (space), and VCHAR (any visible US-ASCII
+   character).
+
+   The rules below are defined in [RFC7230]:
+
+     OWS           = <OWS, see [RFC7230], Section 3.2.3>
+     obs-text      = <obs-text, see [RFC7230], Section 3.2.6>
+
+   The rules below are defined in other parts:
+
+     HTTP-date     = <HTTP-date, see [RFC7231], Section 7.1.1.1>
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+Fielding & Reschke           Standards Track                   [Page 25]
+
+RFC 7232              HTTP/1.1 Conditional Requests            June 2014
+
+
+Appendix C.  Collected ABNF
+
+   In the collected ABNF below, list rules are expanded as per Section
+   1.2 of [RFC7230].
+
+   ETag = entity-tag
+
+   HTTP-date = <HTTP-date, see [RFC7231], Section 7.1.1.1>
+
+   If-Match = "*" / ( *( "," OWS ) entity-tag *( OWS "," [ OWS
+    entity-tag ] ) )
+   If-Modified-Since = HTTP-date
+   If-None-Match = "*" / ( *( "," OWS ) entity-tag *( OWS "," [ OWS
+    entity-tag ] ) )
+   If-Unmodified-Since = HTTP-date
+
+   Last-Modified = HTTP-date
+
+   OWS = <OWS, see [RFC7230], Section 3.2.3>
+
+   entity-tag = [ weak ] opaque-tag
+   etagc = "!" / %x23-7E ; '#'-'~'
+    / obs-text
+
+   obs-text = <obs-text, see [RFC7230], Section 3.2.6>
+   opaque-tag = DQUOTE *etagc DQUOTE
+
+   weak = %x57.2F ; W/
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+Fielding & Reschke           Standards Track                   [Page 26]
+
+RFC 7232              HTTP/1.1 Conditional Requests            June 2014
+
+
+Index
+
+   3
+      304 Not Modified (status code)  19
+
+   4
+      412 Precondition Failed (status code)  18
+
+   E
+      ETag header field  9
+
+   G
+      Grammar
+         entity-tag  9
+         ETag  9
+         etagc  9
+         If-Match  13
+         If-Modified-Since  15
+         If-None-Match  14
+         If-Unmodified-Since  17
+         Last-Modified  7
+         opaque-tag  9
+         weak  9
+
+   I
+      If-Match header field  13
+      If-Modified-Since header field  16
+      If-None-Match header field  14
+      If-Unmodified-Since header field  17
+
+   L
+      Last-Modified header field  7
+
+   M
+      metadata  5
+
+   S
+      selected representation  4
+
+   V
+      validator  5
+         strong  5
+         weak  5
+
+
+
+
+
+
+
+
+Fielding & Reschke           Standards Track                   [Page 27]
+
+RFC 7232              HTTP/1.1 Conditional Requests            June 2014
+
+
+Authors' Addresses
+
+   Roy T. Fielding (editor)
+   Adobe Systems Incorporated
+   345 Park Ave
+   San Jose, CA  95110
+   USA
+
+   EMail: fielding@gbiv.com
+   URI:   http://roy.gbiv.com/
+
+
+   Julian F. Reschke (editor)
+   greenbytes GmbH
+   Hafenweg 16
+   Muenster, NW  48155
+   Germany
+
+   EMail: julian.reschke@greenbytes.de
+   URI:   http://greenbytes.de/tech/webdav/
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+Fielding & Reschke           Standards Track                   [Page 28]
+
@@ -0,0 +1,1403 @@
+
+
+
+
+
+
+Internet Engineering Task Force (IETF)                  R. Fielding, Ed.
+Request for Comments: 7233                                         Adobe
+Obsoletes: 2616                                            Y. Lafon, Ed.
+Category: Standards Track                                            W3C
+ISSN: 2070-1721                                          J. Reschke, Ed.
+                                                              greenbytes
+                                                              June 2014
+
+
+         Hypertext Transfer Protocol (HTTP/1.1): Range Requests
+
+Abstract
+
+   The Hypertext Transfer Protocol (HTTP) is a stateless application-
+   level protocol for distributed, collaborative, hypertext information
+   systems.  This document defines range requests and the rules for
+   constructing and combining responses to those requests.
+
+Status of This Memo
+
+   This is an Internet Standards Track document.
+
+   This document is a product of the Internet Engineering Task Force
+   (IETF).  It represents the consensus of the IETF community.  It has
+   received public review and has been approved for publication by the
+   Internet Engineering Steering Group (IESG).  Further information on
+   Internet Standards is available in Section 2 of RFC 5741.
+
+   Information about the current status of this document, any errata,
+   and how to provide feedback on it may be obtained at
+   http://www.rfc-editor.org/info/rfc7233.
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+Fielding, et al.             Standards Track                    [Page 1]
+
+RFC 7233                 HTTP/1.1 Range Requests               June 2014
+
+
+Copyright Notice
+
+   Copyright (c) 2014 IETF Trust and the persons identified as the
+   document authors.  All rights reserved.
+
+   This document is subject to BCP 78 and the IETF Trust's Legal
+   Provisions Relating to IETF Documents
+   (http://trustee.ietf.org/license-info) in effect on the date of
+   publication of this document.  Please review these documents
+   carefully, as they describe your rights and restrictions with respect
+   to this document.  Code Components extracted from this document must
+   include Simplified BSD License text as described in Section 4.e of
+   the Trust Legal Provisions and are provided without warranty as
+   described in the Simplified BSD License.
+
+   This document may contain material from IETF Documents or IETF
+   Contributions published or made publicly available before November
+   10, 2008.  The person(s) controlling the copyright in some of this
+   material may not have granted the IETF Trust the right to allow
+   modifications of such material outside the IETF Standards Process.
+   Without obtaining an adequate license from the person(s) controlling
+   the copyright in such materials, this document may not be modified
+   outside the IETF Standards Process, and derivative works of it may
+   not be created outside the IETF Standards Process, except to format
+   it for publication as an RFC or to translate it into languages other
+   than English.
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+Fielding, et al.             Standards Track                    [Page 2]
+
+RFC 7233                 HTTP/1.1 Range Requests               June 2014
+
+
+Table of Contents
+
+   1. Introduction ....................................................4
+      1.1. Conformance and Error Handling .............................4
+      1.2. Syntax Notation ............................................4
+   2. Range Units .....................................................5
+      2.1. Byte Ranges ................................................5
+      2.2. Other Range Units ..........................................7
+      2.3. Accept-Ranges ..............................................7
+   3. Range Requests ..................................................8
+      3.1. Range ......................................................8
+      3.2. If-Range ...................................................9
+   4. Responses to a Range Request ...................................10
+      4.1. 206 Partial Content .......................................10
+      4.2. Content-Range .............................................12
+      4.3. Combining Ranges ..........................................14
+      4.4. 416 Range Not Satisfiable .................................15
+   5. IANA Considerations ............................................16
+      5.1. Range Unit Registry .......................................16
+           5.1.1. Procedure ..........................................16
+           5.1.2. Registrations ......................................16
+      5.2. Status Code Registration ..................................17
+      5.3. Header Field Registration .................................17
+      5.4. Internet Media Type Registration ..........................17
+           5.4.1. Internet Media Type multipart/byteranges ...........18
+   6. Security Considerations ........................................19
+      6.1. Denial-of-Service Attacks Using Range .....................19
+   7. Acknowledgments ................................................19
+   8. References .....................................................20
+      8.1. Normative References ......................................20
+      8.2. Informative References ....................................20
+   Appendix A. Internet Media Type multipart/byteranges ..............21
+   Appendix B. Changes from RFC 2616 .................................22
+   Appendix C. Imported ABNF .........................................22
+   Appendix D. Collected ABNF ........................................23
+   Index .............................................................24
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+Fielding, et al.             Standards Track                    [Page 3]
+
+RFC 7233                 HTTP/1.1 Range Requests               June 2014
+
+
+1.  Introduction
+
+   Hypertext Transfer Protocol (HTTP) clients often encounter
+   interrupted data transfers as a result of canceled requests or
+   dropped connections.  When a client has stored a partial
+   representation, it is desirable to request the remainder of that
+   representation in a subsequent request rather than transfer the
+   entire representation.  Likewise, devices with limited local storage
+   might benefit from being able to request only a subset of a larger
+   representation, such as a single page of a very large document, or
+   the dimensions of an embedded image.
+
+   This document defines HTTP/1.1 range requests, partial responses, and
+   the multipart/byteranges media type.  Range requests are an OPTIONAL
+   feature of HTTP, designed so that recipients not implementing this
+   feature (or not supporting it for the target resource) can respond as
+   if it is a normal GET request without impacting interoperability.
+   Partial responses are indicated by a distinct status code to not be
+   mistaken for full responses by caches that might not implement the
+   feature.
+
+   Although the range request mechanism is designed to allow for
+   extensible range types, this specification only defines requests for
+   byte ranges.
+
+1.1.  Conformance and Error Handling
+
+   The key words "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT",
+   "SHOULD", "SHOULD NOT", "RECOMMENDED", "MAY", and "OPTIONAL" in this
+   document are to be interpreted as described in [RFC2119].
+
+   Conformance criteria and considerations regarding error handling are
+   defined in Section 2.5 of [RFC7230].
+
+1.2.  Syntax Notation
+
+   This specification uses the Augmented Backus-Naur Form (ABNF)
+   notation of [RFC5234] with a list extension, defined in Section 7 of
+   [RFC7230], that allows for compact definition of comma-separated
+   lists using a '#' operator (similar to how the '*' operator indicates
+   repetition).  Appendix C describes rules imported from other
+   documents.  Appendix D shows the collected grammar with all list
+   operators expanded to standard ABNF notation.
+
+
+
+
+
+
+
+
+Fielding, et al.             Standards Track                    [Page 4]
+
+RFC 7233                 HTTP/1.1 Range Requests               June 2014
+
+
+2.  Range Units
+
+   A representation can be partitioned into subranges according to
+   various structural units, depending on the structure inherent in the
+   representation's media type.  This "range unit" is used in the
+   Accept-Ranges (Section 2.3) response header field to advertise
+   support for range requests, the Range (Section 3.1) request header
+   field to delineate the parts of a representation that are requested,
+   and the Content-Range (Section 4.2) payload header field to describe
+   which part of a representation is being transferred.
+
+     range-unit       = bytes-unit / other-range-unit
+
+2.1.  Byte Ranges
+
+   Since representation data is transferred in payloads as a sequence of
+   octets, a byte range is a meaningful substructure for any
+   representation transferable over HTTP (Section 3 of [RFC7231]).  The
+   "bytes" range unit is defined for expressing subranges of the data's
+   octet sequence.
+
+     bytes-unit       = "bytes"
+
+   A byte-range request can specify a single range of bytes or a set of
+   ranges within a single representation.
+
+     byte-ranges-specifier = bytes-unit "=" byte-range-set
+     byte-range-set  = 1#( byte-range-spec / suffix-byte-range-spec )
+     byte-range-spec = first-byte-pos "-" [ last-byte-pos ]
+     first-byte-pos  = 1*DIGIT
+     last-byte-pos   = 1*DIGIT
+
+   The first-byte-pos value in a byte-range-spec gives the byte-offset
+   of the first byte in a range.  The last-byte-pos value gives the
+   byte-offset of the last byte in the range; that is, the byte
+   positions specified are inclusive.  Byte offsets start at zero.
+
+   Examples of byte-ranges-specifier values:
+
+   o  The first 500 bytes (byte offsets 0-499, inclusive):
+
+        bytes=0-499
+
+   o  The second 500 bytes (byte offsets 500-999, inclusive):
+
+        bytes=500-999
+
+
+
+
+
+Fielding, et al.             Standards Track                    [Page 5]
+
+RFC 7233                 HTTP/1.1 Range Requests               June 2014
+
+
+   A byte-range-spec is invalid if the last-byte-pos value is present
+   and less than the first-byte-pos.
+
+   A client can limit the number of bytes requested without knowing the
+   size of the selected representation.  If the last-byte-pos value is
+   absent, or if the value is greater than or equal to the current
+   length of the representation data, the byte range is interpreted as
+   the remainder of the representation (i.e., the server replaces the
+   value of last-byte-pos with a value that is one less than the current
+   length of the selected representation).
+
+   A client can request the last N bytes of the selected representation
+   using a suffix-byte-range-spec.
+
+     suffix-byte-range-spec = "-" suffix-length
+     suffix-length = 1*DIGIT
+
+   If the selected representation is shorter than the specified
+   suffix-length, the entire representation is used.
+
+   Additional examples, assuming a representation of length 10000:
+
+   o  The final 500 bytes (byte offsets 9500-9999, inclusive):
+
+        bytes=-500
+
+   Or:
+
+        bytes=9500-
+
+   o  The first and last bytes only (bytes 0 and 9999):
+
+        bytes=0-0,-1
+
+   o  Other valid (but not canonical) specifications of the second 500
+      bytes (byte offsets 500-999, inclusive):
+
+        bytes=500-600,601-999
+        bytes=500-700,601-999
+
+   If a valid byte-range-set includes at least one byte-range-spec with
+   a first-byte-pos that is less than the current length of the
+   representation, or at least one suffix-byte-range-spec with a
+   non-zero suffix-length, then the byte-range-set is satisfiable.
+   Otherwise, the byte-range-set is unsatisfiable.
+
+
+
+
+
+
+Fielding, et al.             Standards Track                    [Page 6]
+
+RFC 7233                 HTTP/1.1 Range Requests               June 2014
+
+
+   In the byte-range syntax, first-byte-pos, last-byte-pos, and
+   suffix-length are expressed as decimal number of octets.  Since there
+   is no predefined limit to the length of a payload, recipients MUST
+   anticipate potentially large decimal numerals and prevent parsing
+   errors due to integer conversion overflows.
+
+2.2.  Other Range Units
+
+   Range units are intended to be extensible.  New range units ought to
+   be registered with IANA, as defined in Section 5.1.
+
+     other-range-unit = token
+
+2.3.  Accept-Ranges
+
+   The "Accept-Ranges" header field allows a server to indicate that it
+   supports range requests for the target resource.
+
+     Accept-Ranges     = acceptable-ranges
+     acceptable-ranges = 1#range-unit / "none"
+
+   An origin server that supports byte-range requests for a given target
+   resource MAY send
+
+     Accept-Ranges: bytes
+
+   to indicate what range units are supported.  A client MAY generate
+   range requests without having received this header field for the
+   resource involved.  Range units are defined in Section 2.
+
+   A server that does not support any kind of range request for the
+   target resource MAY send
+
+     Accept-Ranges: none
+
+   to advise the client not to attempt a range request.
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+Fielding, et al.             Standards Track                    [Page 7]
+
+RFC 7233                 HTTP/1.1 Range Requests               June 2014
+
+
+3.  Range Requests
+
+3.1.  Range
+
+   The "Range" header field on a GET request modifies the method
+   semantics to request transfer of only one or more subranges of the
+   selected representation data, rather than the entire selected
+   representation data.
+
+     Range = byte-ranges-specifier / other-ranges-specifier
+     other-ranges-specifier = other-range-unit "=" other-range-set
+     other-range-set = 1*VCHAR
+
+   A server MAY ignore the Range header field.  However, origin servers
+   and intermediate caches ought to support byte ranges when possible,
+   since Range supports efficient recovery from partially failed
+   transfers and partial retrieval of large representations.  A server
+   MUST ignore a Range header field received with a request method other
+   than GET.
+
+   An origin server MUST ignore a Range header field that contains a
+   range unit it does not understand.  A proxy MAY discard a Range
+   header field that contains a range unit it does not understand.
+
+   A server that supports range requests MAY ignore or reject a Range
+   header field that consists of more than two overlapping ranges, or a
+   set of many small ranges that are not listed in ascending order,
+   since both are indications of either a broken client or a deliberate
+   denial-of-service attack (Section 6.1).  A client SHOULD NOT request
+   multiple ranges that are inherently less efficient to process and
+   transfer than a single range that encompasses the same data.
+
+   A client that is requesting multiple ranges SHOULD list those ranges
+   in ascending order (the order in which they would typically be
+   received in a complete representation) unless there is a specific
+   need to request a later part earlier.  For example, a user agent
+   processing a large representation with an internal catalog of parts
+   might need to request later parts first, particularly if the
+   representation consists of pages stored in reverse order and the user
+   agent wishes to transfer one page at a time.
+
+   The Range header field is evaluated after evaluating the precondition
+   header fields defined in [RFC7232], and only if the result in absence
+   of the Range header field would be a 200 (OK) response.  In other
+   words, Range is ignored when a conditional GET would result in a 304
+   (Not Modified) response.
+
+
+
+
+
+Fielding, et al.             Standards Track                    [Page 8]
+
+RFC 7233                 HTTP/1.1 Range Requests               June 2014
+
+
+   The If-Range header field (Section 3.2) can be used as a precondition
+   to applying the Range header field.
+
+   If all of the preconditions are true, the server supports the Range
+   header field for the target resource, and the specified range(s) are
+   valid and satisfiable (as defined in Section 2.1), the server SHOULD
+   send a 206 (Partial Content) response with a payload containing one
+   or more partial representations that correspond to the satisfiable
+   ranges requested, as defined in Section 4.
+
+   If all of the preconditions are true, the server supports the Range
+   header field for the target resource, and the specified range(s) are
+   invalid or unsatisfiable, the server SHOULD send a 416 (Range Not
+   Satisfiable) response.
+
+3.2.  If-Range
+
+   If a client has a partial copy of a representation and wishes to have
+   an up-to-date copy of the entire representation, it could use the
+   Range header field with a conditional GET (using either or both of
+   If-Unmodified-Since and If-Match.)  However, if the precondition
+   fails because the representation has been modified, the client would
+   then have to make a second request to obtain the entire current
+   representation.
+
+   The "If-Range" header field allows a client to "short-circuit" the
+   second request.  Informally, its meaning is as follows: if the
+   representation is unchanged, send me the part(s) that I am requesting
+   in Range; otherwise, send me the entire representation.
+
+     If-Range = entity-tag / HTTP-date
+
+   A client MUST NOT generate an If-Range header field in a request that
+   does not contain a Range header field.  A server MUST ignore an
+   If-Range header field received in a request that does not contain a
+   Range header field.  An origin server MUST ignore an If-Range header
+   field received in a request for a target resource that does not
+   support Range requests.
+
+   A client MUST NOT generate an If-Range header field containing an
+   entity-tag that is marked as weak.  A client MUST NOT generate an
+   If-Range header field containing an HTTP-date unless the client has
+   no entity-tag for the corresponding representation and the date is a
+   strong validator in the sense defined by Section 2.2.2 of [RFC7232].
+
+   A server that evaluates an If-Range precondition MUST use the strong
+   comparison function when comparing entity-tags (Section 2.3.2 of
+   [RFC7232]) and MUST evaluate the condition as false if an HTTP-date
+
+
+
+Fielding, et al.             Standards Track                    [Page 9]
+
+RFC 7233                 HTTP/1.1 Range Requests               June 2014
+
+
+   validator is provided that is not a strong validator in the sense
+   defined by Section 2.2.2 of [RFC7232].  A valid entity-tag can be
+   distinguished from a valid HTTP-date by examining the first two
+   characters for a DQUOTE.
+
+   If the validator given in the If-Range header field matches the
+   current validator for the selected representation of the target
+   resource, then the server SHOULD process the Range header field as
+   requested.  If the validator does not match, the server MUST ignore
+   the Range header field.  Note that this comparison by exact match,
+   including when the validator is an HTTP-date, differs from the
+   "earlier than or equal to" comparison used when evaluating an
+   If-Unmodified-Since conditional.
+
+4.  Responses to a Range Request
+
+4.1.  206 Partial Content
+
+   The 206 (Partial Content) status code indicates that the server is
+   successfully fulfilling a range request for the target resource by
+   transferring one or more parts of the selected representation that
+   correspond to the satisfiable ranges found in the request's Range
+   header field (Section 3.1).
+
+   If a single part is being transferred, the server generating the 206
+   response MUST generate a Content-Range header field, describing what
+   range of the selected representation is enclosed, and a payload
+   consisting of the range.  For example:
+
+     HTTP/1.1 206 Partial Content
+     Date: Wed, 15 Nov 1995 06:25:24 GMT
+     Last-Modified: Wed, 15 Nov 1995 04:58:08 GMT
+     Content-Range: bytes 21010-47021/47022
+     Content-Length: 26012
+     Content-Type: image/gif
+
+     ... 26012 bytes of partial image data ...
+
+   If multiple parts are being transferred, the server generating the
+   206 response MUST generate a "multipart/byteranges" payload, as
+   defined in Appendix A, and a Content-Type header field containing the
+   multipart/byteranges media type and its required boundary parameter.
+   To avoid confusion with single-part responses, a server MUST NOT
+   generate a Content-Range header field in the HTTP header section of a
+   multiple part response (this field will be sent in each part
+   instead).
+
+
+
+
+
+Fielding, et al.             Standards Track                   [Page 10]
+
+RFC 7233                 HTTP/1.1 Range Requests               June 2014
+
+
+   Within the header area of each body part in the multipart payload,
+   the server MUST generate a Content-Range header field corresponding
+   to the range being enclosed in that body part.  If the selected
+   representation would have had a Content-Type header field in a 200
+   (OK) response, the server SHOULD generate that same Content-Type
+   field in the header area of each body part.  For example:
+
+     HTTP/1.1 206 Partial Content
+     Date: Wed, 15 Nov 1995 06:25:24 GMT
+     Last-Modified: Wed, 15 Nov 1995 04:58:08 GMT
+     Content-Length: 1741
+     Content-Type: multipart/byteranges; boundary=THIS_STRING_SEPARATES
+
+     --THIS_STRING_SEPARATES
+     Content-Type: application/pdf
+     Content-Range: bytes 500-999/8000
+
+     ...the first range...
+     --THIS_STRING_SEPARATES
+     Content-Type: application/pdf
+     Content-Range: bytes 7000-7999/8000
+
+     ...the second range
+     --THIS_STRING_SEPARATES--
+
+   When multiple ranges are requested, a server MAY coalesce any of the
+   ranges that overlap, or that are separated by a gap that is smaller
+   than the overhead of sending multiple parts, regardless of the order
+   in which the corresponding byte-range-spec appeared in the received
+   Range header field.  Since the typical overhead between parts of a
+   multipart/byteranges payload is around 80 bytes, depending on the
+   selected representation's media type and the chosen boundary
+   parameter length, it can be less efficient to transfer many small
+   disjoint parts than it is to transfer the entire selected
+   representation.
+
+   A server MUST NOT generate a multipart response to a request for a
+   single range, since a client that does not request multiple parts
+   might not support multipart responses.  However, a server MAY
+   generate a multipart/byteranges payload with only a single body part
+   if multiple ranges were requested and only one range was found to be
+   satisfiable or only one range remained after coalescing.  A client
+   that cannot process a multipart/byteranges response MUST NOT generate
+   a request that asks for multiple ranges.
+
+   When a multipart response payload is generated, the server SHOULD
+   send the parts in the same order that the corresponding
+   byte-range-spec appeared in the received Range header field,
+
+
+
+Fielding, et al.             Standards Track                   [Page 11]
+
+RFC 7233                 HTTP/1.1 Range Requests               June 2014
+
+
+   excluding those ranges that were deemed unsatisfiable or that were
+   coalesced into other ranges.  A client that receives a multipart
+   response MUST inspect the Content-Range header field present in each
+   body part in order to determine which range is contained in that body
+   part; a client cannot rely on receiving the same ranges that it
+   requested, nor the same order that it requested.
+
+   When a 206 response is generated, the server MUST generate the
+   following header fields, in addition to those required above, if the
+   field would have been sent in a 200 (OK) response to the same
+   request: Date, Cache-Control, ETag, Expires, Content-Location, and
+   Vary.
+
+   If a 206 is generated in response to a request with an If-Range
+   header field, the sender SHOULD NOT generate other representation
+   header fields beyond those required above, because the client is
+   understood to already have a prior response containing those header
+   fields.  Otherwise, the sender MUST generate all of the
+   representation header fields that would have been sent in a 200 (OK)
+   response to the same request.
+
+   A 206 response is cacheable by default; i.e., unless otherwise
+   indicated by explicit cache controls (see Section 4.2.2 of
+   [RFC7234]).
+
+4.2.  Content-Range
+
+   The "Content-Range" header field is sent in a single part 206
+   (Partial Content) response to indicate the partial range of the
+   selected representation enclosed as the message payload, sent in each
+   part of a multipart 206 response to indicate the range enclosed
+   within each body part, and sent in 416 (Range Not Satisfiable)
+   responses to provide information about the selected representation.
+
+     Content-Range       = byte-content-range
+                         / other-content-range
+
+     byte-content-range  = bytes-unit SP
+                           ( byte-range-resp / unsatisfied-range )
+
+     byte-range-resp     = byte-range "/" ( complete-length / "*" )
+     byte-range          = first-byte-pos "-" last-byte-pos
+     unsatisfied-range   = "*/" complete-length
+
+     complete-length     = 1*DIGIT
+
+     other-content-range = other-range-unit SP other-range-resp
+     other-range-resp    = *CHAR
+
+
+
+Fielding, et al.             Standards Track                   [Page 12]
+
+RFC 7233                 HTTP/1.1 Range Requests               June 2014
+
+
+   If a 206 (Partial Content) response contains a Content-Range header
+   field with a range unit (Section 2) that the recipient does not
+   understand, the recipient MUST NOT attempt to recombine it with a
+   stored representation.  A proxy that receives such a message SHOULD
+   forward it downstream.
+
+   For byte ranges, a sender SHOULD indicate the complete length of the
+   representation from which the range has been extracted, unless the
+   complete length is unknown or difficult to determine.  An asterisk
+   character ("*") in place of the complete-length indicates that the
+   representation length was unknown when the header field was
+   generated.
+
+   The following example illustrates when the complete length of the
+   selected representation is known by the sender to be 1234 bytes:
+
+     Content-Range: bytes 42-1233/1234
+
+   and this second example illustrates when the complete length is
+   unknown:
+
+     Content-Range: bytes 42-1233/*
+
+   A Content-Range field value is invalid if it contains a
+   byte-range-resp that has a last-byte-pos value less than its
+   first-byte-pos value, or a complete-length value less than or equal
+   to its last-byte-pos value.  The recipient of an invalid
+   Content-Range MUST NOT attempt to recombine the received content with
+   a stored representation.
+
+   A server generating a 416 (Range Not Satisfiable) response to a
+   byte-range request SHOULD send a Content-Range header field with an
+   unsatisfied-range value, as in the following example:
+
+     Content-Range: bytes */1234
+
+   The complete-length in a 416 response indicates the current length of
+   the selected representation.
+
+   The Content-Range header field has no meaning for status codes that
+   do not explicitly describe its semantic.  For this specification,
+   only the 206 (Partial Content) and 416 (Range Not Satisfiable) status
+   codes describe a meaning for Content-Range.
+
+
+
+
+
+
+
+
+Fielding, et al.             Standards Track                   [Page 13]
+
+RFC 7233                 HTTP/1.1 Range Requests               June 2014
+
+
+   The following are examples of Content-Range values in which the
+   selected representation contains a total of 1234 bytes:
+
+   o  The first 500 bytes:
+
+        Content-Range: bytes 0-499/1234
+
+   o  The second 500 bytes:
+
+        Content-Range: bytes 500-999/1234
+
+   o  All except for the first 500 bytes:
+
+        Content-Range: bytes 500-1233/1234
+
+   o  The last 500 bytes:
+
+        Content-Range: bytes 734-1233/1234
+
+4.3.  Combining Ranges
+
+   A response might transfer only a subrange of a representation if the
+   connection closed prematurely or if the request used one or more
+   Range specifications.  After several such transfers, a client might
+   have received several ranges of the same representation.  These
+   ranges can only be safely combined if they all have in common the
+   same strong validator (Section 2.1 of [RFC7232]).
+
+   A client that has received multiple partial responses to GET requests
+   on a target resource MAY combine those responses into a larger
+   continuous range if they share the same strong validator.
+
+   If the most recent response is an incomplete 200 (OK) response, then
+   the header fields of that response are used for any combined response
+   and replace those of the matching stored responses.
+
+   If the most recent response is a 206 (Partial Content) response and
+   at least one of the matching stored responses is a 200 (OK), then the
+   combined response header fields consist of the most recent 200
+   response's header fields.  If all of the matching stored responses
+   are 206 responses, then the stored response with the most recent
+   header fields is used as the source of header fields for the combined
+   response, except that the client MUST use other header fields
+   provided in the new response, aside from Content-Range, to replace
+   all instances of the corresponding header fields in the stored
+   response.
+
+
+
+
+
+Fielding, et al.             Standards Track                   [Page 14]
+
+RFC 7233                 HTTP/1.1 Range Requests               June 2014
+
+
+   The combined response message body consists of the union of partial
+   content ranges in the new response and each of the selected
+   responses.  If the union consists of the entire range of the
+   representation, then the client MUST process the combined response as
+   if it were a complete 200 (OK) response, including a Content-Length
+   header field that reflects the complete length.  Otherwise, the
+   client MUST process the set of continuous ranges as one of the
+   following: an incomplete 200 (OK) response if the combined response
+   is a prefix of the representation, a single 206 (Partial Content)
+   response containing a multipart/byteranges body, or multiple 206
+   (Partial Content) responses, each with one continuous range that is
+   indicated by a Content-Range header field.
+
+4.4.  416 Range Not Satisfiable
+
+   The 416 (Range Not Satisfiable) status code indicates that none of
+   the ranges in the request's Range header field (Section 3.1) overlap
+   the current extent of the selected resource or that the set of ranges
+   requested has been rejected due to invalid ranges or an excessive
+   request of small or overlapping ranges.
+
+   For byte ranges, failing to overlap the current extent means that the
+   first-byte-pos of all of the byte-range-spec values were greater than
+   the current length of the selected representation.  When this status
+   code is generated in response to a byte-range request, the sender
+   SHOULD generate a Content-Range header field specifying the current
+   length of the selected representation (Section 4.2).
+
+   For example:
+
+     HTTP/1.1 416 Range Not Satisfiable
+     Date: Fri, 20 Jan 2012 15:41:54 GMT
+     Content-Range: bytes */47022
+
+      Note: Because servers are free to ignore Range, many
+      implementations will simply respond with the entire selected
+      representation in a 200 (OK) response.  That is partly because
+      most clients are prepared to receive a 200 (OK) to complete the
+      task (albeit less efficiently) and partly because clients might
+      not stop making an invalid partial request until they have
+      received a complete representation.  Thus, clients cannot depend
+      on receiving a 416 (Range Not Satisfiable) response even when it
+      is most appropriate.
+
+
+
+
+
+
+
+
+Fielding, et al.             Standards Track                   [Page 15]
+
+RFC 7233                 HTTP/1.1 Range Requests               June 2014
+
+
+5.  IANA Considerations
+
+5.1.  Range Unit Registry
+
+   The "HTTP Range Unit Registry" defines the namespace for the range
+   unit names and refers to their corresponding specifications.  The
+   registry has been created and is now maintained at
+   <http://www.iana.org/assignments/http-parameters>.
+
+5.1.1.  Procedure
+
+   Registration of an HTTP Range Unit MUST include the following fields:
+
+   o  Name
+
+   o  Description
+
+   o  Pointer to specification text
+
+   Values to be added to this namespace require IETF Review (see
+   [RFC5226], Section 4.1).
+
+5.1.2.  Registrations
+
+   The initial range unit registry contains the registrations below:
+
+   +-------------+---------------------------------------+-------------+
+   | Range Unit  | Description                           | Reference   |
+   | Name        |                                       |             |
+   +-------------+---------------------------------------+-------------+
+   | bytes       | a range of octets                     | Section 2.1 |
+   | none        | reserved as keyword, indicating no    | Section 2.3 |
+   |             | ranges are supported                  |             |
+   +-------------+---------------------------------------+-------------+
+
+   The change controller is: "IETF (iesg@ietf.org) - Internet
+   Engineering Task Force".
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+Fielding, et al.             Standards Track                   [Page 16]
+
+RFC 7233                 HTTP/1.1 Range Requests               June 2014
+
+
+5.2.  Status Code Registration
+
+   The "Hypertext Transfer Protocol (HTTP) Status Code Registry" located
+   at <http://www.iana.org/assignments/http-status-codes> has been
+   updated to include the registrations below:
+
+   +-------+-----------------------+-------------+
+   | Value | Description           | Reference   |
+   +-------+-----------------------+-------------+
+   | 206   | Partial Content       | Section 4.1 |
+   | 416   | Range Not Satisfiable | Section 4.4 |
+   +-------+-----------------------+-------------+
+
+5.3.  Header Field Registration
+
+   HTTP header fields are registered within the "Message Headers"
+   registry maintained at
+   <http://www.iana.org/assignments/message-headers/>.
+
+   This document defines the following HTTP header fields, so their
+   associated registry entries have been updated according to the
+   permanent registrations below (see [BCP90]):
+
+   +-------------------+----------+----------+-------------+
+   | Header Field Name | Protocol | Status   | Reference   |
+   +-------------------+----------+----------+-------------+
+   | Accept-Ranges     | http     | standard | Section 2.3 |
+   | Content-Range     | http     | standard | Section 4.2 |
+   | If-Range          | http     | standard | Section 3.2 |
+   | Range             | http     | standard | Section 3.1 |
+   +-------------------+----------+----------+-------------+
+
+   The change controller is: "IETF (iesg@ietf.org) - Internet
+   Engineering Task Force".
+
+5.4.  Internet Media Type Registration
+
+   IANA maintains the registry of Internet media types [BCP13] at
+   <http://www.iana.org/assignments/media-types>.
+
+   This document serves as the specification for the Internet media type
+   "multipart/byteranges".  The following has been registered with IANA.
+
+
+
+
+
+
+
+
+
+Fielding, et al.             Standards Track                   [Page 17]
+
+RFC 7233                 HTTP/1.1 Range Requests               June 2014
+
+
+5.4.1.  Internet Media Type multipart/byteranges
+
+   Type name:  multipart
+
+   Subtype name:  byteranges
+
+   Required parameters:  boundary
+
+   Optional parameters:  N/A
+
+   Encoding considerations:  only "7bit", "8bit", or "binary" are
+      permitted
+
+   Security considerations:  see Section 6
+
+   Interoperability considerations:  N/A
+
+   Published specification:  This specification (see Appendix A).
+
+   Applications that use this media type:  HTTP components supporting
+      multiple ranges in a single request.
+
+   Fragment identifier considerations:  N/A
+
+   Additional information:
+
+      Deprecated alias names for this type:  N/A
+
+      Magic number(s):  N/A
+
+      File extension(s):  N/A
+
+      Macintosh file type code(s):  N/A
+
+   Person and email address to contact for further information:  See
+      Authors' Addresses section.
+
+   Intended usage:  COMMON
+
+   Restrictions on usage:  N/A
+
+   Author:  See Authors' Addresses section.
+
+   Change controller:  IESG
+
+
+
+
+
+
+
+Fielding, et al.             Standards Track                   [Page 18]
+
+RFC 7233                 HTTP/1.1 Range Requests               June 2014
+
+
+6.  Security Considerations
+
+   This section is meant to inform developers, information providers,
+   and users of known security concerns specific to the HTTP range
+   request mechanisms.  More general security considerations are
+   addressed in HTTP messaging [RFC7230] and semantics [RFC7231].
+
+6.1.  Denial-of-Service Attacks Using Range
+
+   Unconstrained multiple range requests are susceptible to denial-of-
+   service attacks because the effort required to request many
+   overlapping ranges of the same data is tiny compared to the time,
+   memory, and bandwidth consumed by attempting to serve the requested
+   data in many parts.  Servers ought to ignore, coalesce, or reject
+   egregious range requests, such as requests for more than two
+   overlapping ranges or for many small ranges in a single set,
+   particularly when the ranges are requested out of order for no
+   apparent reason.  Multipart range requests are not designed to
+   support random access.
+
+7.  Acknowledgments
+
+   See Section 10 of [RFC7230].
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+Fielding, et al.             Standards Track                   [Page 19]
+
+RFC 7233                 HTTP/1.1 Range Requests               June 2014
+
+
+8.  References
+
+8.1.  Normative References
+
+   [RFC2046]  Freed, N. and N. Borenstein, "Multipurpose Internet Mail
+              Extensions (MIME) Part Two: Media Types", RFC 2046,
+              November 1996.
+
+   [RFC2119]  Bradner, S., "Key words for use in RFCs to Indicate
+              Requirement Levels", BCP 14, RFC 2119, March 1997.
+
+   [RFC5234]  Crocker, D., Ed. and P. Overell, "Augmented BNF for Syntax
+              Specifications: ABNF", STD 68, RFC 5234, January 2008.
+
+   [RFC7230]  Fielding, R., Ed. and J. Reschke, Ed., "Hypertext Transfer
+              Protocol (HTTP/1.1): Message Syntax and Routing",
+              RFC 7230, June 2014.
+
+   [RFC7231]  Fielding, R., Ed. and J. Reschke, Ed., "Hypertext Transfer
+              Protocol (HTTP/1.1): Semantics and Content", RFC 7231,
+              June 2014.
+
+   [RFC7232]  Fielding, R., Ed. and J. Reschke, Ed., "Hypertext Transfer
+              Protocol (HTTP/1.1): Conditional Requests", RFC 7232,
+              June 2014.
+
+   [RFC7234]  Fielding, R., Ed., Nottingham, M., Ed., and J. Reschke,
+              Ed., "Hypertext Transfer Protocol (HTTP/1.1): Caching",
+              RFC 7234, June 2014.
+
+8.2.  Informative References
+
+   [BCP13]    Freed, N., Klensin, J., and T. Hansen, "Media Type
+              Specifications and Registration Procedures", BCP 13,
+              RFC 6838, January 2013.
+
+   [BCP90]    Klyne, G., Nottingham, M., and J. Mogul, "Registration
+              Procedures for Message Header Fields", BCP 90, RFC 3864,
+              September 2004.
+
+   [RFC2616]  Fielding, R., Gettys, J., Mogul, J., Frystyk, H.,
+              Masinter, L., Leach, P., and T. Berners-Lee, "Hypertext
+              Transfer Protocol -- HTTP/1.1", RFC 2616, June 1999.
+
+   [RFC5226]  Narten, T. and H. Alvestrand, "Guidelines for Writing an
+              IANA Considerations Section in RFCs", BCP 26, RFC 5226,
+              May 2008.
+
+
+
+
+Fielding, et al.             Standards Track                   [Page 20]
+
+RFC 7233                 HTTP/1.1 Range Requests               June 2014
+
+
+Appendix A.  Internet Media Type multipart/byteranges
+
+   When a 206 (Partial Content) response message includes the content of
+   multiple ranges, they are transmitted as body parts in a multipart
+   message body ([RFC2046], Section 5.1) with the media type of
+   "multipart/byteranges".
+
+   The multipart/byteranges media type includes one or more body parts,
+   each with its own Content-Type and Content-Range fields.  The
+   required boundary parameter specifies the boundary string used to
+   separate each body part.
+
+   Implementation Notes:
+
+   1.  Additional CRLFs might precede the first boundary string in the
+       body.
+
+   2.  Although [RFC2046] permits the boundary string to be quoted, some
+       existing implementations handle a quoted boundary string
+       incorrectly.
+
+   3.  A number of clients and servers were coded to an early draft of
+       the byteranges specification that used a media type of multipart/
+       x-byteranges, which is almost (but not quite) compatible with
+       this type.
+
+   Despite the name, the "multipart/byteranges" media type is not
+   limited to byte ranges.  The following example uses an "exampleunit"
+   range unit:
+
+     HTTP/1.1 206 Partial Content
+     Date: Tue, 14 Nov 1995 06:25:24 GMT
+     Last-Modified: Tue, 14 July 04:58:08 GMT
+     Content-Length: 2331785
+     Content-Type: multipart/byteranges; boundary=THIS_STRING_SEPARATES
+
+     --THIS_STRING_SEPARATES
+     Content-Type: video/example
+     Content-Range: exampleunit 1.2-4.3/25
+
+     ...the first range...
+     --THIS_STRING_SEPARATES
+     Content-Type: video/example
+     Content-Range: exampleunit 11.2-14.3/25
+
+     ...the second range
+     --THIS_STRING_SEPARATES--
+
+
+
+
+Fielding, et al.             Standards Track                   [Page 21]
+
+RFC 7233                 HTTP/1.1 Range Requests               June 2014
+
+
+Appendix B.  Changes from RFC 2616
+
+   Servers are given more leeway in how they respond to a range request,
+   in order to mitigate abuse by malicious (or just greedy) clients.
+   (Section 3.1)
+
+   A weak validator cannot be used in a 206 response.  (Section 4.1)
+
+   The Content-Range header field only has meaning when the status code
+   explicitly defines its use.  (Section 4.2)
+
+   This specification introduces a Range Unit Registry.  (Section 5.1)
+
+   multipart/byteranges can consist of a single part.  (Appendix A)
+
+Appendix C.  Imported ABNF
+
+   The following core rules are included by reference, as defined in
+   Appendix B.1 of [RFC5234]: ALPHA (letters), CR (carriage return),
+   CRLF (CR LF), CTL (controls), DIGIT (decimal 0-9), DQUOTE (double
+   quote), HEXDIG (hexadecimal 0-9/A-F/a-f), LF (line feed), OCTET (any
+   8-bit sequence of data), SP (space), and VCHAR (any visible US-ASCII
+   character).
+
+   Note that all rules derived from token are to be compared
+   case-insensitively, like range-unit and acceptable-ranges.
+
+   The rules below are defined in [RFC7230]:
+
+     OWS        = <OWS, see [RFC7230], Section 3.2.3>
+     token      = <token, see [RFC7230], Section 3.2.6>
+
+   The rules below are defined in other parts:
+
+     HTTP-date  = <HTTP-date, see [RFC7231], Section 7.1.1.1>
+     entity-tag = <entity-tag, see [RFC7232], Section 2.3>
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+Fielding, et al.             Standards Track                   [Page 22]
+
+RFC 7233                 HTTP/1.1 Range Requests               June 2014
+
+
+Appendix D.  Collected ABNF
+
+   In the collected ABNF below, list rules are expanded as per Section
+   1.2 of [RFC7230].
+
+   Accept-Ranges = acceptable-ranges
+
+   Content-Range = byte-content-range / other-content-range
+
+   HTTP-date = <HTTP-date, see [RFC7231], Section 7.1.1.1>
+
+   If-Range = entity-tag / HTTP-date
+
+   OWS = <OWS, see [RFC7230], Section 3.2.3>
+
+   Range = byte-ranges-specifier / other-ranges-specifier
+
+   acceptable-ranges = ( *( "," OWS ) range-unit *( OWS "," [ OWS
+    range-unit ] ) ) / "none"
+
+   byte-content-range = bytes-unit SP ( byte-range-resp /
+    unsatisfied-range )
+   byte-range = first-byte-pos "-" last-byte-pos
+   byte-range-resp = byte-range "/" ( complete-length / "*" )
+   byte-range-set = *( "," OWS ) ( byte-range-spec /
+    suffix-byte-range-spec ) *( OWS "," [ OWS ( byte-range-spec /
+    suffix-byte-range-spec ) ] )
+   byte-range-spec = first-byte-pos "-" [ last-byte-pos ]
+   byte-ranges-specifier = bytes-unit "=" byte-range-set
+   bytes-unit = "bytes"
+
+   complete-length = 1*DIGIT
+
+   entity-tag = <entity-tag, see [RFC7232], Section 2.3>
+
+   first-byte-pos = 1*DIGIT
+
+   last-byte-pos = 1*DIGIT
+
+   other-content-range = other-range-unit SP other-range-resp
+   other-range-resp = *CHAR
+   other-range-set = 1*VCHAR
+   other-range-unit = token
+   other-ranges-specifier = other-range-unit "=" other-range-set
+
+   range-unit = bytes-unit / other-range-unit
+
+   suffix-byte-range-spec = "-" suffix-length
+
+
+
+Fielding, et al.             Standards Track                   [Page 23]
+
+RFC 7233                 HTTP/1.1 Range Requests               June 2014
+
+
+   suffix-length = 1*DIGIT
+
+   token = <token, see [RFC7230], Section 3.2.6>
+
+   unsatisfied-range = "*/" complete-length
+
+Index
+
+   2
+      206 Partial Content (status code)  10
+
+   4
+      416 Range Not Satisfiable (status code)  15
+
+   A
+      Accept-Ranges header field  7
+
+   C
+      Content-Range header field  12
+
+   G
+      Grammar
+         Accept-Ranges  7
+         acceptable-ranges  7
+         byte-content-range  12
+         byte-range  12
+         byte-range-resp  12
+         byte-range-set  5
+         byte-range-spec  5
+         byte-ranges-specifier  5
+         bytes-unit  5
+         complete-length  12
+         Content-Range  12
+         first-byte-pos  5
+         If-Range  9
+         last-byte-pos  5
+         other-content-range  12
+         other-range-resp  12
+         other-range-unit  5, 7
+         Range  8
+         range-unit  5
+         ranges-specifier  5
+         suffix-byte-range-spec  6
+         suffix-length  6
+         unsatisfied-range  12
+
+
+
+
+
+
+Fielding, et al.             Standards Track                   [Page 24]
+
+RFC 7233                 HTTP/1.1 Range Requests               June 2014
+
+
+   I
+      If-Range header field  9
+
+   M
+      Media Type
+         multipart/byteranges  18, 21
+         multipart/x-byteranges  19
+      multipart/byteranges Media Type  18, 21
+      multipart/x-byteranges Media Type  21
+
+   R
+      Range header field  8
+
+Authors' Addresses
+
+   Roy T. Fielding (editor)
+   Adobe Systems Incorporated
+   345 Park Ave
+   San Jose, CA  95110
+   USA
+
+   EMail: fielding@gbiv.com
+   URI:   http://roy.gbiv.com/
+
+
+   Yves Lafon (editor)
+   World Wide Web Consortium
+   W3C / ERCIM
+   2004, rte des Lucioles
+   Sophia-Antipolis, AM  06902
+   France
+
+   EMail: ylafon@w3.org
+   URI:   http://www.raubacapeu.net/people/yves/
+
+
+   Julian F. Reschke (editor)
+   greenbytes GmbH
+   Hafenweg 16
+   Muenster, NW  48155
+   Germany
+
+   EMail: julian.reschke@greenbytes.de
+   URI:   http://greenbytes.de/tech/webdav/
+
+
+
+
+
+
+
+Fielding, et al.             Standards Track                   [Page 25]
+
@@ -0,0 +1,2411 @@
+
+
+
+
+
+
+Internet Engineering Task Force (IETF)                  R. Fielding, Ed.
+Request for Comments: 7234                                         Adobe
+Obsoletes: 2616                                       M. Nottingham, Ed.
+Category: Standards Track                                         Akamai
+ISSN: 2070-1721                                          J. Reschke, Ed.
+                                                              greenbytes
+                                                               June 2014
+
+
+            Hypertext Transfer Protocol (HTTP/1.1): Caching
+
+Abstract
+
+   The Hypertext Transfer Protocol (HTTP) is a stateless application-
+   level protocol for distributed, collaborative, hypertext information
+   systems.  This document defines HTTP caches and the associated header
+   fields that control cache behavior or indicate cacheable response
+   messages.
+
+Status of This Memo
+
+   This is an Internet Standards Track document.
+
+   This document is a product of the Internet Engineering Task Force
+   (IETF).  It represents the consensus of the IETF community.  It has
+   received public review and has been approved for publication by the
+   Internet Engineering Steering Group (IESG).  Further information on
+   Internet Standards is available in Section 2 of RFC 5741.
+
+   Information about the current status of this document, any errata,
+   and how to provide feedback on it may be obtained at
+   http://www.rfc-editor.org/info/rfc7234.
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+Fielding, et al.             Standards Track                    [Page 1]
+
+RFC 7234                    HTTP/1.1 Caching                   June 2014
+
+
+Copyright Notice
+
+   Copyright (c) 2014 IETF Trust and the persons identified as the
+   document authors.  All rights reserved.
+
+   This document is subject to BCP 78 and the IETF Trust's Legal
+   Provisions Relating to IETF Documents
+   (http://trustee.ietf.org/license-info) in effect on the date of
+   publication of this document.  Please review these documents
+   carefully, as they describe your rights and restrictions with respect
+   to this document.  Code Components extracted from this document must
+   include Simplified BSD License text as described in Section 4.e of
+   the Trust Legal Provisions and are provided without warranty as
+   described in the Simplified BSD License.
+
+   This document may contain material from IETF Documents or IETF
+   Contributions published or made publicly available before November
+   10, 2008.  The person(s) controlling the copyright in some of this
+   material may not have granted the IETF Trust the right to allow
+   modifications of such material outside the IETF Standards Process.
+   Without obtaining an adequate license from the person(s) controlling
+   the copyright in such materials, this document may not be modified
+   outside the IETF Standards Process, and derivative works of it may
+   not be created outside the IETF Standards Process, except to format
+   it for publication as an RFC or to translate it into languages other
+   than English.
+
+Table of Contents
+
+   1. Introduction ....................................................4
+      1.1. Conformance and Error Handling .............................4
+      1.2. Syntax Notation ............................................4
+           1.2.1. Delta Seconds .......................................5
+   2. Overview of Cache Operation .....................................5
+   3. Storing Responses in Caches .....................................6
+      3.1. Storing Incomplete Responses ...............................7
+      3.2. Storing Responses to Authenticated Requests ................7
+      3.3. Combining Partial Content ..................................8
+   4. Constructing Responses from Caches ..............................8
+      4.1. Calculating Secondary Keys with Vary .......................9
+      4.2. Freshness .................................................11
+           4.2.1. Calculating Freshness Lifetime .....................12
+           4.2.2. Calculating Heuristic Freshness ....................13
+           4.2.3. Calculating Age ....................................13
+           4.2.4. Serving Stale Responses ............................15
+      4.3. Validation ................................................16
+           4.3.1. Sending a Validation Request .......................16
+           4.3.2. Handling a Received Validation Request .............16
+
+
+
+Fielding, et al.             Standards Track                    [Page 2]
+
+RFC 7234                    HTTP/1.1 Caching                   June 2014
+
+
+           4.3.3. Handling a Validation Response .....................18
+           4.3.4. Freshening Stored Responses upon Validation ........18
+           4.3.5. Freshening Responses via HEAD ......................19
+      4.4. Invalidation ..............................................20
+   5. Header Field Definitions .......................................21
+      5.1. Age .......................................................21
+      5.2. Cache-Control .............................................21
+           5.2.1. Request Cache-Control Directives ...................22
+           5.2.2. Response Cache-Control Directives ..................24
+           5.2.3. Cache Control Extensions ...........................27
+      5.3. Expires ...................................................28
+      5.4. Pragma ....................................................29
+      5.5. Warning ...................................................29
+           5.5.1. Warning: 110 - "Response is Stale" .................31
+           5.5.2. Warning: 111 - "Revalidation Failed" ...............31
+           5.5.3. Warning: 112 - "Disconnected Operation" ............31
+           5.5.4. Warning: 113 - "Heuristic Expiration" ..............31
+           5.5.5. Warning: 199 - "Miscellaneous Warning" .............32
+           5.5.6. Warning: 214 - "Transformation Applied" ............32
+           5.5.7. Warning: 299 - "Miscellaneous Persistent Warning" ..32
+   6. History Lists ..................................................32
+   7. IANA Considerations ............................................32
+      7.1. Cache Directive Registry ..................................32
+           7.1.1. Procedure ..........................................32
+           7.1.2. Considerations for New Cache Control Directives ....33
+           7.1.3. Registrations ......................................33
+      7.2. Warn Code Registry ........................................34
+           7.2.1. Procedure ..........................................34
+           7.2.2. Registrations ......................................34
+      7.3. Header Field Registration .................................34
+   8. Security Considerations ........................................35
+   9. Acknowledgments ................................................36
+   10. References ....................................................36
+      10.1. Normative References .....................................36
+      10.2. Informative References ...................................37
+   Appendix A. Changes from RFC 2616 .................................38
+   Appendix B. Imported ABNF .........................................39
+   Appendix C. Collected ABNF ........................................39
+   Index .............................................................41
+
+
+
+
+
+
+
+
+
+
+
+
+Fielding, et al.             Standards Track                    [Page 3]
+
+RFC 7234                    HTTP/1.1 Caching                   June 2014
+
+
+1.  Introduction
+
+   HTTP is typically used for distributed information systems, where
+   performance can be improved by the use of response caches.  This
+   document defines aspects of HTTP/1.1 related to caching and reusing
+   response messages.
+
+   An HTTP cache is a local store of response messages and the subsystem
+   that controls storage, retrieval, and deletion of messages in it.  A
+   cache stores cacheable responses in order to reduce the response time
+   and network bandwidth consumption on future, equivalent requests.
+   Any client or server MAY employ a cache, though a cache cannot be
+   used by a server that is acting as a tunnel.
+
+   A shared cache is a cache that stores responses to be reused by more
+   than one user; shared caches are usually (but not always) deployed as
+   a part of an intermediary.  A private cache, in contrast, is
+   dedicated to a single user; often, they are deployed as a component
+   of a user agent.
+
+   The goal of caching in HTTP/1.1 is to significantly improve
+   performance by reusing a prior response message to satisfy a current
+   request.  A stored response is considered "fresh", as defined in
+   Section 4.2, if the response can be reused without "validation"
+   (checking with the origin server to see if the cached response
+   remains valid for this request).  A fresh response can therefore
+   reduce both latency and network overhead each time it is reused.
+   When a cached response is not fresh, it might still be reusable if it
+   can be freshened by validation (Section 4.3) or if the origin is
+   unavailable (Section 4.2.4).
+
+1.1.  Conformance and Error Handling
+
+   The key words "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT",
+   "SHOULD", "SHOULD NOT", "RECOMMENDED", "MAY", and "OPTIONAL" in this
+   document are to be interpreted as described in [RFC2119].
+
+   Conformance criteria and considerations regarding error handling are
+   defined in Section 2.5 of [RFC7230].
+
+1.2.  Syntax Notation
+
+   This specification uses the Augmented Backus-Naur Form (ABNF)
+   notation of [RFC5234] with a list extension, defined in Section 7 of
+   [RFC7230], that allows for compact definition of comma-separated
+   lists using a '#' operator (similar to how the '*' operator indicates
+
+
+
+
+
+Fielding, et al.             Standards Track                    [Page 4]
+
+RFC 7234                    HTTP/1.1 Caching                   June 2014
+
+
+   repetition).  Appendix B describes rules imported from other
+   documents.  Appendix C shows the collected grammar with all list
+   operators expanded to standard ABNF notation.
+
+1.2.1.  Delta Seconds
+
+   The delta-seconds rule specifies a non-negative integer, representing
+   time in seconds.
+
+     delta-seconds  = 1*DIGIT
+
+   A recipient parsing a delta-seconds value and converting it to binary
+   form ought to use an arithmetic type of at least 31 bits of
+   non-negative integer range.  If a cache receives a delta-seconds
+   value greater than the greatest integer it can represent, or if any
+   of its subsequent calculations overflows, the cache MUST consider the
+   value to be either 2147483648 (2^31) or the greatest positive integer
+   it can conveniently represent.
+
+      Note: The value 2147483648 is here for historical reasons,
+      effectively represents infinity (over 68 years), and does not need
+      to be stored in binary form; an implementation could produce it as
+      a canned string if any overflow occurs, even if the calculations
+      are performed with an arithmetic type incapable of directly
+      representing that number.  What matters here is that an overflow
+      be detected and not treated as a negative value in later
+      calculations.
+
+2.  Overview of Cache Operation
+
+   Proper cache operation preserves the semantics of HTTP transfers
+   ([RFC7231]) while eliminating the transfer of information already
+   held in the cache.  Although caching is an entirely OPTIONAL feature
+   of HTTP, it can be assumed that reusing a cached response is
+   desirable and that such reuse is the default behavior when no
+   requirement or local configuration prevents it.  Therefore, HTTP
+   cache requirements are focused on preventing a cache from either
+   storing a non-reusable response or reusing a stored response
+   inappropriately, rather than mandating that caches always store and
+   reuse particular responses.
+
+   Each cache entry consists of a cache key and one or more HTTP
+   responses corresponding to prior requests that used the same key.
+   The most common form of cache entry is a successful result of a
+   retrieval request: i.e., a 200 (OK) response to a GET request, which
+   contains a representation of the resource identified by the request
+   target (Section 4.3.1 of [RFC7231]).  However, it is also possible to
+   cache permanent redirects, negative results (e.g., 404 (Not Found)),
+
+
+
+Fielding, et al.             Standards Track                    [Page 5]
+
+RFC 7234                    HTTP/1.1 Caching                   June 2014
+
+
+   incomplete results (e.g., 206 (Partial Content)), and responses to
+   methods other than GET if the method's definition allows such caching
+   and defines something suitable for use as a cache key.
+
+   The primary cache key consists of the request method and target URI.
+   However, since HTTP caches in common use today are typically limited
+   to caching responses to GET, many caches simply decline other methods
+   and use only the URI as the primary cache key.
+
+   If a request target is subject to content negotiation, its cache
+   entry might consist of multiple stored responses, each differentiated
+   by a secondary key for the values of the original request's selecting
+   header fields (Section 4.1).
+
+3.  Storing Responses in Caches
+
+   A cache MUST NOT store a response to any request, unless:
+
+   o  The request method is understood by the cache and defined as being
+      cacheable, and
+
+   o  the response status code is understood by the cache, and
+
+   o  the "no-store" cache directive (see Section 5.2) does not appear
+      in request or response header fields, and
+
+   o  the "private" response directive (see Section 5.2.2.6) does not
+      appear in the response, if the cache is shared, and
+
+   o  the Authorization header field (see Section 4.2 of [RFC7235]) does
+      not appear in the request, if the cache is shared, unless the
+      response explicitly allows it (see Section 3.2), and
+
+   o  the response either:
+
+      *  contains an Expires header field (see Section 5.3), or
+
+      *  contains a max-age response directive (see Section 5.2.2.8), or
+
+      *  contains a s-maxage response directive (see Section 5.2.2.9)
+         and the cache is shared, or
+
+      *  contains a Cache Control Extension (see Section 5.2.3) that
+         allows it to be cached, or
+
+      *  has a status code that is defined as cacheable by default (see
+         Section 4.2.2), or
+
+
+
+
+Fielding, et al.             Standards Track                    [Page 6]
+
+RFC 7234                    HTTP/1.1 Caching                   June 2014
+
+
+      *  contains a public response directive (see Section 5.2.2.5).
+
+   Note that any of the requirements listed above can be overridden by a
+   cache-control extension; see Section 5.2.3.
+
+   In this context, a cache has "understood" a request method or a
+   response status code if it recognizes it and implements all specified
+   caching-related behavior.
+
+   Note that, in normal operation, some caches will not store a response
+   that has neither a cache validator nor an explicit expiration time,
+   as such responses are not usually useful to store.  However, caches
+   are not prohibited from storing such responses.
+
+3.1.  Storing Incomplete Responses
+
+   A response message is considered complete when all of the octets
+   indicated by the message framing ([RFC7230]) are received prior to
+   the connection being closed.  If the request method is GET, the
+   response status code is 200 (OK), and the entire response header
+   section has been received, a cache MAY store an incomplete response
+   message body if the cache entry is recorded as incomplete.  Likewise,
+   a 206 (Partial Content) response MAY be stored as if it were an
+   incomplete 200 (OK) cache entry.  However, a cache MUST NOT store
+   incomplete or partial-content responses if it does not support the
+   Range and Content-Range header fields or if it does not understand
+   the range units used in those fields.
+
+   A cache MAY complete a stored incomplete response by making a
+   subsequent range request ([RFC7233]) and combining the successful
+   response with the stored entry, as defined in Section 3.3.  A cache
+   MUST NOT use an incomplete response to answer requests unless the
+   response has been made complete or the request is partial and
+   specifies a range that is wholly within the incomplete response.  A
+   cache MUST NOT send a partial response to a client without explicitly
+   marking it as such using the 206 (Partial Content) status code.
+
+3.2.  Storing Responses to Authenticated Requests
+
+   A shared cache MUST NOT use a cached response to a request with an
+   Authorization header field (Section 4.2 of [RFC7235]) to satisfy any
+   subsequent request unless a cache directive that allows such
+   responses to be stored is present in the response.
+
+   In this specification, the following Cache-Control response
+   directives (Section 5.2.2) have such an effect: must-revalidate,
+   public, and s-maxage.
+
+
+
+
+Fielding, et al.             Standards Track                    [Page 7]
+
+RFC 7234                    HTTP/1.1 Caching                   June 2014
+
+
+   Note that cached responses that contain the "must-revalidate" and/or
+   "s-maxage" response directives are not allowed to be served stale
+   (Section 4.2.4) by shared caches.  In particular, a response with
+   either "max-age=0, must-revalidate" or "s-maxage=0" cannot be used to
+   satisfy a subsequent request without revalidating it on the origin
+   server.
+
+3.3.  Combining Partial Content
+
+   A response might transfer only a partial representation if the
+   connection closed prematurely or if the request used one or more
+   Range specifiers ([RFC7233]).  After several such transfers, a cache
+   might have received several ranges of the same representation.  A
+   cache MAY combine these ranges into a single stored response, and
+   reuse that response to satisfy later requests, if they all share the
+   same strong validator and the cache complies with the client
+   requirements in Section 4.3 of [RFC7233].
+
+   When combining the new response with one or more stored responses, a
+   cache MUST:
+
+   o  delete any Warning header fields in the stored response with
+      warn-code 1xx (see Section 5.5);
+
+   o  retain any Warning header fields in the stored response with
+      warn-code 2xx; and,
+
+   o  use other header fields provided in the new response, aside from
+      Content-Range, to replace all instances of the corresponding
+      header fields in the stored response.
+
+4.  Constructing Responses from Caches
+
+   When presented with a request, a cache MUST NOT reuse a stored
+   response, unless:
+
+   o  The presented effective request URI (Section 5.5 of [RFC7230]) and
+      that of the stored response match, and
+
+   o  the request method associated with the stored response allows it
+      to be used for the presented request, and
+
+   o  selecting header fields nominated by the stored response (if any)
+      match those presented (see Section 4.1), and
+
+
+
+
+
+
+
+Fielding, et al.             Standards Track                    [Page 8]
+
+RFC 7234                    HTTP/1.1 Caching                   June 2014
+
+
+   o  the presented request does not contain the no-cache pragma
+      (Section 5.4), nor the no-cache cache directive (Section 5.2.1),
+      unless the stored response is successfully validated
+      (Section 4.3), and
+
+   o  the stored response does not contain the no-cache cache directive
+      (Section 5.2.2.2), unless it is successfully validated
+      (Section 4.3), and
+
+   o  the stored response is either:
+
+      *  fresh (see Section 4.2), or
+
+      *  allowed to be served stale (see Section 4.2.4), or
+
+      *  successfully validated (see Section 4.3).
+
+   Note that any of the requirements listed above can be overridden by a
+   cache-control extension; see Section 5.2.3.
+
+   When a stored response is used to satisfy a request without
+   validation, a cache MUST generate an Age header field (Section 5.1),
+   replacing any present in the response with a value equal to the
+   stored response's current_age; see Section 4.2.3.
+
+   A cache MUST write through requests with methods that are unsafe
+   (Section 4.2.1 of [RFC7231]) to the origin server; i.e., a cache is
+   not allowed to generate a reply to such a request before having
+   forwarded the request and having received a corresponding response.
+
+   Also, note that unsafe requests might invalidate already-stored
+   responses; see Section 4.4.
+
+   When more than one suitable response is stored, a cache MUST use the
+   most recent response (as determined by the Date header field).  It
+   can also forward the request with "Cache-Control: max-age=0" or
+   "Cache-Control: no-cache" to disambiguate which response to use.
+
+   A cache that does not have a clock available MUST NOT use stored
+   responses without revalidating them upon every use.
+
+4.1.  Calculating Secondary Keys with Vary
+
+   When a cache receives a request that can be satisfied by a stored
+   response that has a Vary header field (Section 7.1.4 of [RFC7231]),
+   it MUST NOT use that response unless all of the selecting header
+
+
+
+
+
+Fielding, et al.             Standards Track                    [Page 9]
+
+RFC 7234                    HTTP/1.1 Caching                   June 2014
+
+
+   fields nominated by the Vary header field match in both the original
+   request (i.e., that associated with the stored response), and the
+   presented request.
+
+   The selecting header fields from two requests are defined to match if
+   and only if those in the first request can be transformed to those in
+   the second request by applying any of the following:
+
+   o  adding or removing whitespace, where allowed in the header field's
+      syntax
+
+   o  combining multiple header fields with the same field name (see
+      Section 3.2 of [RFC7230])
+
+   o  normalizing both header field values in a way that is known to
+      have identical semantics, according to the header field's
+      specification (e.g., reordering field values when order is not
+      significant; case-normalization, where values are defined to be
+      case-insensitive)
+
+   If (after any normalization that might take place) a header field is
+   absent from a request, it can only match another request if it is
+   also absent there.
+
+   A Vary header field-value of "*" always fails to match.
+
+   The stored response with matching selecting header fields is known as
+   the selected response.
+
+   If multiple selected responses are available (potentially including
+   responses without a Vary header field), the cache will need to choose
+   one to use.  When a selecting header field has a known mechanism for
+   doing so (e.g., qvalues on Accept and similar request header fields),
+   that mechanism MAY be used to select preferred responses; of the
+   remainder, the most recent response (as determined by the Date header
+   field) is used, as per Section 4.
+
+   If no selected response is available, the cache cannot satisfy the
+   presented request.  Typically, it is forwarded to the origin server
+   in a (possibly conditional; see Section 4.3) request.
+
+
+
+
+
+
+
+
+
+
+
+Fielding, et al.             Standards Track                   [Page 10]
+
+RFC 7234                    HTTP/1.1 Caching                   June 2014
+
+
+4.2.  Freshness
+
+   A fresh response is one whose age has not yet exceeded its freshness
+   lifetime.  Conversely, a stale response is one where it has.
+
+   A response's freshness lifetime is the length of time between its
+   generation by the origin server and its expiration time.  An explicit
+   expiration time is the time at which the origin server intends that a
+   stored response can no longer be used by a cache without further
+   validation, whereas a heuristic expiration time is assigned by a
+   cache when no explicit expiration time is available.
+
+   A response's age is the time that has passed since it was generated
+   by, or successfully validated with, the origin server.
+
+   When a response is "fresh" in the cache, it can be used to satisfy
+   subsequent requests without contacting the origin server, thereby
+   improving efficiency.
+
+   The primary mechanism for determining freshness is for an origin
+   server to provide an explicit expiration time in the future, using
+   either the Expires header field (Section 5.3) or the max-age response
+   directive (Section 5.2.2.8).  Generally, origin servers will assign
+   future explicit expiration times to responses in the belief that the
+   representation is not likely to change in a semantically significant
+   way before the expiration time is reached.
+
+   If an origin server wishes to force a cache to validate every
+   request, it can assign an explicit expiration time in the past to
+   indicate that the response is already stale.  Compliant caches will
+   normally validate a stale cached response before reusing it for
+   subsequent requests (see Section 4.2.4).
+
+   Since origin servers do not always provide explicit expiration times,
+   caches are also allowed to use a heuristic to determine an expiration
+   time under certain circumstances (see Section 4.2.2).
+
+   The calculation to determine if a response is fresh is:
+
+      response_is_fresh = (freshness_lifetime > current_age)
+
+   freshness_lifetime is defined in Section 4.2.1; current_age is
+   defined in Section 4.2.3.
+
+   Clients can send the max-age or min-fresh cache directives in a
+   request to constrain or relax freshness calculations for the
+   corresponding response (Section 5.2.1).
+
+
+
+
+Fielding, et al.             Standards Track                   [Page 11]
+
+RFC 7234                    HTTP/1.1 Caching                   June 2014
+
+
+   When calculating freshness, to avoid common problems in date parsing:
+
+   o  Although all date formats are specified to be case-sensitive, a
+      cache recipient SHOULD match day, week, and time-zone names
+      case-insensitively.
+
+   o  If a cache recipient's internal implementation of time has less
+      resolution than the value of an HTTP-date, the recipient MUST
+      internally represent a parsed Expires date as the nearest time
+      equal to or earlier than the received value.
+
+   o  A cache recipient MUST NOT allow local time zones to influence the
+      calculation or comparison of an age or expiration time.
+
+   o  A cache recipient SHOULD consider a date with a zone abbreviation
+      other than GMT or UTC to be invalid for calculating expiration.
+
+   Note that freshness applies only to cache operation; it cannot be
+   used to force a user agent to refresh its display or reload a
+   resource.  See Section 6 for an explanation of the difference between
+   caches and history mechanisms.
+
+4.2.1.  Calculating Freshness Lifetime
+
+   A cache can calculate the freshness lifetime (denoted as
+   freshness_lifetime) of a response by using the first match of the
+   following:
+
+   o  If the cache is shared and the s-maxage response directive
+      (Section 5.2.2.9) is present, use its value, or
+
+   o  If the max-age response directive (Section 5.2.2.8) is present,
+      use its value, or
+
+   o  If the Expires response header field (Section 5.3) is present, use
+      its value minus the value of the Date response header field, or
+
+   o  Otherwise, no explicit expiration time is present in the response.
+      A heuristic freshness lifetime might be applicable; see
+      Section 4.2.2.
+
+   Note that this calculation is not vulnerable to clock skew, since all
+   of the information comes from the origin server.
+
+
+
+
+
+
+
+
+Fielding, et al.             Standards Track                   [Page 12]
+
+RFC 7234                    HTTP/1.1 Caching                   June 2014
+
+
+   When there is more than one value present for a given directive
+   (e.g., two Expires header fields, multiple Cache-Control: max-age
+   directives), the directive's value is considered invalid.  Caches are
+   encouraged to consider responses that have invalid freshness
+   information to be stale.
+
+4.2.2.  Calculating Heuristic Freshness
+
+   Since origin servers do not always provide explicit expiration times,
+   a cache MAY assign a heuristic expiration time when an explicit time
+   is not specified, employing algorithms that use other header field
+   values (such as the Last-Modified time) to estimate a plausible
+   expiration time.  This specification does not provide specific
+   algorithms, but does impose worst-case constraints on their results.
+
+   A cache MUST NOT use heuristics to determine freshness when an
+   explicit expiration time is present in the stored response.  Because
+   of the requirements in Section 3, this means that, effectively,
+   heuristics can only be used on responses without explicit freshness
+   whose status codes are defined as cacheable by default (see Section
+   6.1 of [RFC7231]), and those responses without explicit freshness
+   that have been marked as explicitly cacheable (e.g., with a "public"
+   response directive).
+
+   If the response has a Last-Modified header field (Section 2.2 of
+   [RFC7232]), caches are encouraged to use a heuristic expiration value
+   that is no more than some fraction of the interval since that time.
+   A typical setting of this fraction might be 10%.
+
+   When a heuristic is used to calculate freshness lifetime, a cache
+   SHOULD generate a Warning header field with a 113 warn-code (see
+   Section 5.5.4) in the response if its current_age is more than 24
+   hours and such a warning is not already present.
+
+      Note: Section 13.9 of [RFC2616] prohibited caches from calculating
+      heuristic freshness for URIs with query components (i.e., those
+      containing '?').  In practice, this has not been widely
+      implemented.  Therefore, origin servers are encouraged to send
+      explicit directives (e.g., Cache-Control: no-cache) if they wish
+      to preclude caching.
+
+4.2.3.  Calculating Age
+
+   The Age header field is used to convey an estimated age of the
+   response message when obtained from a cache.  The Age field value is
+   the cache's estimate of the number of seconds since the response was
+   generated or validated by the origin server.  In essence, the Age
+
+
+
+
+Fielding, et al.             Standards Track                   [Page 13]
+
+RFC 7234                    HTTP/1.1 Caching                   June 2014
+
+
+   value is the sum of the time that the response has been resident in
+   each of the caches along the path from the origin server, plus the
+   amount of time it has been in transit along network paths.
+
+   The following data is used for the age calculation:
+
+   age_value
+
+      The term "age_value" denotes the value of the Age header field
+      (Section 5.1), in a form appropriate for arithmetic operation; or
+      0, if not available.
+
+   date_value
+
+      The term "date_value" denotes the value of the Date header field,
+      in a form appropriate for arithmetic operations.  See Section
+      7.1.1.2 of [RFC7231] for the definition of the Date header field,
+      and for requirements regarding responses without it.
+
+   now
+
+      The term "now" means "the current value of the clock at the host
+      performing the calculation".  A host ought to use NTP ([RFC5905])
+      or some similar protocol to synchronize its clocks to Coordinated
+      Universal Time.
+
+   request_time
+
+      The current value of the clock at the host at the time the request
+      resulting in the stored response was made.
+
+   response_time
+
+      The current value of the clock at the host at the time the
+      response was received.
+
+   A response's age can be calculated in two entirely independent ways:
+
+   1.  the "apparent_age": response_time minus date_value, if the local
+       clock is reasonably well synchronized to the origin server's
+       clock.  If the result is negative, the result is replaced by
+       zero.
+
+   2.  the "corrected_age_value", if all of the caches along the
+       response path implement HTTP/1.1.  A cache MUST interpret this
+       value relative to the time the request was initiated, not the
+       time that the response was received.
+
+
+
+
+Fielding, et al.             Standards Track                   [Page 14]
+
+RFC 7234                    HTTP/1.1 Caching                   June 2014
+
+
+     apparent_age = max(0, response_time - date_value);
+
+     response_delay = response_time - request_time;
+     corrected_age_value = age_value + response_delay;
+
+   These are combined as
+
+     corrected_initial_age = max(apparent_age, corrected_age_value);
+
+   unless the cache is confident in the value of the Age header field
+   (e.g., because there are no HTTP/1.0 hops in the Via header field),
+   in which case the corrected_age_value MAY be used as the
+   corrected_initial_age.
+
+   The current_age of a stored response can then be calculated by adding
+   the amount of time (in seconds) since the stored response was last
+   validated by the origin server to the corrected_initial_age.
+
+     resident_time = now - response_time;
+     current_age = corrected_initial_age + resident_time;
+
+4.2.4.  Serving Stale Responses
+
+   A "stale" response is one that either has explicit expiry information
+   or is allowed to have heuristic expiry calculated, but is not fresh
+   according to the calculations in Section 4.2.
+
+   A cache MUST NOT generate a stale response if it is prohibited by an
+   explicit in-protocol directive (e.g., by a "no-store" or "no-cache"
+   cache directive, a "must-revalidate" cache-response-directive, or an
+   applicable "s-maxage" or "proxy-revalidate" cache-response-directive;
+   see Section 5.2.2).
+
+   A cache MUST NOT send stale responses unless it is disconnected
+   (i.e., it cannot contact the origin server or otherwise find a
+   forward path) or doing so is explicitly allowed (e.g., by the
+   max-stale request directive; see Section 5.2.1).
+
+   A cache SHOULD generate a Warning header field with the 110 warn-code
+   (see Section 5.5.1) in stale responses.  Likewise, a cache SHOULD
+   generate a 112 warn-code (see Section 5.5.3) in stale responses if
+   the cache is disconnected.
+
+   A cache SHOULD NOT generate a new Warning header field when
+   forwarding a response that does not have an Age header field, even if
+   the response is already stale.  A cache need not validate a response
+   that merely became stale in transit.
+
+
+
+
+Fielding, et al.             Standards Track                   [Page 15]
+
+RFC 7234                    HTTP/1.1 Caching                   June 2014
+
+
+4.3.  Validation
+
+   When a cache has one or more stored responses for a requested URI,
+   but cannot serve any of them (e.g., because they are not fresh, or
+   one cannot be selected; see Section 4.1), it can use the conditional
+   request mechanism [RFC7232] in the forwarded request to give the next
+   inbound server an opportunity to select a valid stored response to
+   use, updating the stored metadata in the process, or to replace the
+   stored response(s) with a new response.  This process is known as
+   "validating" or "revalidating" the stored response.
+
+4.3.1.  Sending a Validation Request
+
+   When sending a conditional request for cache validation, a cache
+   sends one or more precondition header fields containing validator
+   metadata from its stored response(s), which is then compared by
+   recipients to determine whether a stored response is equivalent to a
+   current representation of the resource.
+
+   One such validator is the timestamp given in a Last-Modified header
+   field (Section 2.2 of [RFC7232]), which can be used in an
+   If-Modified-Since header field for response validation, or in an
+   If-Unmodified-Since or If-Range header field for representation
+   selection (i.e., the client is referring specifically to a previously
+   obtained representation with that timestamp).
+
+   Another validator is the entity-tag given in an ETag header field
+   (Section 2.3 of [RFC7232]).  One or more entity-tags, indicating one
+   or more stored responses, can be used in an If-None-Match header
+   field for response validation, or in an If-Match or If-Range header
+   field for representation selection (i.e., the client is referring
+   specifically to one or more previously obtained representations with
+   the listed entity-tags).
+
+4.3.2.  Handling a Received Validation Request
+
+   Each client in the request chain may have its own cache, so it is
+   common for a cache at an intermediary to receive conditional requests
+   from other (outbound) caches.  Likewise, some user agents make use of
+   conditional requests to limit data transfers to recently modified
+   representations or to complete the transfer of a partially retrieved
+   representation.
+
+   If a cache receives a request that can be satisfied by reusing one of
+   its stored 200 (OK) or 206 (Partial Content) responses, the cache
+   SHOULD evaluate any applicable conditional header field preconditions
+   received in that request with respect to the corresponding validators
+   contained within the selected response.  A cache MUST NOT evaluate
+
+
+
+Fielding, et al.             Standards Track                   [Page 16]
+
+RFC 7234                    HTTP/1.1 Caching                   June 2014
+
+
+   conditional header fields that are only applicable to an origin
+   server, found in a request with semantics that cannot be satisfied
+   with a cached response, or applied to a target resource for which it
+   has no stored responses; such preconditions are likely intended for
+   some other (inbound) server.
+
+   The proper evaluation of conditional requests by a cache depends on
+   the received precondition header fields and their precedence, as
+   defined in Section 6 of [RFC7232].  The If-Match and
+   If-Unmodified-Since conditional header fields are not applicable to a
+   cache.
+
+   A request containing an If-None-Match header field (Section 3.2 of
+   [RFC7232]) indicates that the client wants to validate one or more of
+   its own stored responses in comparison to whichever stored response
+   is selected by the cache.  If the field-value is "*", or if the
+   field-value is a list of entity-tags and at least one of them matches
+   the entity-tag of the selected stored response, a cache recipient
+   SHOULD generate a 304 (Not Modified) response (using the metadata of
+   the selected stored response) instead of sending that stored
+   response.
+
+   When a cache decides to revalidate its own stored responses for a
+   request that contains an If-None-Match list of entity-tags, the cache
+   MAY combine the received list with a list of entity-tags from its own
+   stored set of responses (fresh or stale) and send the union of the
+   two lists as a replacement If-None-Match header field value in the
+   forwarded request.  If a stored response contains only partial
+   content, the cache MUST NOT include its entity-tag in the union
+   unless the request is for a range that would be fully satisfied by
+   that partial stored response.  If the response to the forwarded
+   request is 304 (Not Modified) and has an ETag header field value with
+   an entity-tag that is not in the client's list, the cache MUST
+   generate a 200 (OK) response for the client by reusing its
+   corresponding stored response, as updated by the 304 response
+   metadata (Section 4.3.4).
+
+   If an If-None-Match header field is not present, a request containing
+   an If-Modified-Since header field (Section 3.3 of [RFC7232])
+   indicates that the client wants to validate one or more of its own
+   stored responses by modification date.  A cache recipient SHOULD
+   generate a 304 (Not Modified) response (using the metadata of the
+   selected stored response) if one of the following cases is true: 1)
+   the selected stored response has a Last-Modified field-value that is
+   earlier than or equal to the conditional timestamp; 2) no
+   Last-Modified field is present in the selected stored response, but
+   it has a Date field-value that is earlier than or equal to the
+   conditional timestamp; or, 3) neither Last-Modified nor Date is
+
+
+
+Fielding, et al.             Standards Track                   [Page 17]
+
+RFC 7234                    HTTP/1.1 Caching                   June 2014
+
+
+   present in the selected stored response, but the cache recorded it as
+   having been received at a time earlier than or equal to the
+   conditional timestamp.
+
+   A cache that implements partial responses to range requests, as
+   defined in [RFC7233], also needs to evaluate a received If-Range
+   header field (Section 3.2 of [RFC7233]) with respect to its selected
+   stored response.
+
+4.3.3.  Handling a Validation Response
+
+   Cache handling of a response to a conditional request is dependent
+   upon its status code:
+
+   o  A 304 (Not Modified) response status code indicates that the
+      stored response can be updated and reused; see Section 4.3.4.
+
+   o  A full response (i.e., one with a payload body) indicates that
+      none of the stored responses nominated in the conditional request
+      is suitable.  Instead, the cache MUST use the full response to
+      satisfy the request and MAY replace the stored response(s).
+
+   o  However, if a cache receives a 5xx (Server Error) response while
+      attempting to validate a response, it can either forward this
+      response to the requesting client, or act as if the server failed
+      to respond.  In the latter case, the cache MAY send a previously
+      stored response (see Section 4.2.4).
+
+4.3.4.  Freshening Stored Responses upon Validation
+
+   When a cache receives a 304 (Not Modified) response and already has
+   one or more stored 200 (OK) responses for the same cache key, the
+   cache needs to identify which of the stored responses are updated by
+   this new response and then update the stored response(s) with the new
+   information provided in the 304 response.
+
+   The stored response to update is identified by using the first match
+   (if any) of the following:
+
+   o  If the new response contains a strong validator (see Section 2.1
+      of [RFC7232]), then that strong validator identifies the selected
+      representation for update.  All of the stored responses with the
+      same strong validator are selected.  If none of the stored
+      responses contain the same strong validator, then the cache MUST
+      NOT use the new response to update any stored responses.
+
+
+
+
+
+
+Fielding, et al.             Standards Track                   [Page 18]
+
+RFC 7234                    HTTP/1.1 Caching                   June 2014
+
+
+   o  If the new response contains a weak validator and that validator
+      corresponds to one of the cache's stored responses, then the most
+      recent of those matching stored responses is selected for update.
+
+   o  If the new response does not include any form of validator (such
+      as in the case where a client generates an If-Modified-Since
+      request from a source other than the Last-Modified response header
+      field), and there is only one stored response, and that stored
+      response also lacks a validator, then that stored response is
+      selected for update.
+
+   If a stored response is selected for update, the cache MUST:
+
+   o  delete any Warning header fields in the stored response with
+      warn-code 1xx (see Section 5.5);
+
+   o  retain any Warning header fields in the stored response with
+      warn-code 2xx; and,
+
+   o  use other header fields provided in the 304 (Not Modified)
+      response to replace all instances of the corresponding header
+      fields in the stored response.
+
+4.3.5.  Freshening Responses via HEAD
+
+   A response to the HEAD method is identical to what an equivalent
+   request made with a GET would have been, except it lacks a body.
+   This property of HEAD responses can be used to invalidate or update a
+   cached GET response if the more efficient conditional GET request
+   mechanism is not available (due to no validators being present in the
+   stored response) or if transmission of the representation body is not
+   desired even if it has changed.
+
+   When a cache makes an inbound HEAD request for a given request target
+   and receives a 200 (OK) response, the cache SHOULD update or
+   invalidate each of its stored GET responses that could have been
+   selected for that request (see Section 4.1).
+
+   For each of the stored responses that could have been selected, if
+   the stored response and HEAD response have matching values for any
+   received validator fields (ETag and Last-Modified) and, if the HEAD
+   response has a Content-Length header field, the value of
+   Content-Length matches that of the stored response, the cache SHOULD
+   update the stored response as described below; otherwise, the cache
+   SHOULD consider the stored response to be stale.
+
+
+
+
+
+
+Fielding, et al.             Standards Track                   [Page 19]
+
+RFC 7234                    HTTP/1.1 Caching                   June 2014
+
+
+   If a cache updates a stored response with the metadata provided in a
+   HEAD response, the cache MUST:
+
+   o  delete any Warning header fields in the stored response with
+      warn-code 1xx (see Section 5.5);
+
+   o  retain any Warning header fields in the stored response with
+      warn-code 2xx; and,
+
+   o  use other header fields provided in the HEAD response to replace
+      all instances of the corresponding header fields in the stored
+      response and append new header fields to the stored response's
+      header section unless otherwise restricted by the Cache-Control
+      header field.
+
+4.4.  Invalidation
+
+   Because unsafe request methods (Section 4.2.1 of [RFC7231]) such as
+   PUT, POST or DELETE have the potential for changing state on the
+   origin server, intervening caches can use them to keep their contents
+   up to date.
+
+   A cache MUST invalidate the effective Request URI (Section 5.5 of
+   [RFC7230]) as well as the URI(s) in the Location and Content-Location
+   response header fields (if present) when a non-error status code is
+   received in response to an unsafe request method.
+
+   However, a cache MUST NOT invalidate a URI from a Location or
+   Content-Location response header field if the host part of that URI
+   differs from the host part in the effective request URI (Section 5.5
+   of [RFC7230]).  This helps prevent denial-of-service attacks.
+
+   A cache MUST invalidate the effective request URI (Section 5.5 of
+   [RFC7230]) when it receives a non-error response to a request with a
+   method whose safety is unknown.
+
+   Here, a "non-error response" is one with a 2xx (Successful) or 3xx
+   (Redirection) status code.  "Invalidate" means that the cache will
+   either remove all stored responses related to the effective request
+   URI or will mark these as "invalid" and in need of a mandatory
+   validation before they can be sent in response to a subsequent
+   request.
+
+   Note that this does not guarantee that all appropriate responses are
+   invalidated.  For example, a state-changing request might invalidate
+   responses in the caches it travels through, but relevant responses
+   still might be stored in other caches that it has not.
+
+
+
+
+Fielding, et al.             Standards Track                   [Page 20]
+
+RFC 7234                    HTTP/1.1 Caching                   June 2014
+
+
+5.  Header Field Definitions
+
+   This section defines the syntax and semantics of HTTP/1.1 header
+   fields related to caching.
+
+5.1.  Age
+
+   The "Age" header field conveys the sender's estimate of the amount of
+   time since the response was generated or successfully validated at
+   the origin server.  Age values are calculated as specified in
+   Section 4.2.3.
+
+     Age = delta-seconds
+
+   The Age field-value is a non-negative integer, representing time in
+   seconds (see Section 1.2.1).
+
+   The presence of an Age header field implies that the response was not
+   generated or validated by the origin server for this request.
+   However, lack of an Age header field does not imply the origin was
+   contacted, since the response might have been received from an
+   HTTP/1.0 cache that does not implement Age.
+
+5.2.  Cache-Control
+
+   The "Cache-Control" header field is used to specify directives for
+   caches along the request/response chain.  Such cache directives are
+   unidirectional in that the presence of a directive in a request does
+   not imply that the same directive is to be given in the response.
+
+   A cache MUST obey the requirements of the Cache-Control directives
+   defined in this section.  See Section 5.2.3 for information about how
+   Cache-Control directives defined elsewhere are handled.
+
+      Note: Some HTTP/1.0 caches might not implement Cache-Control.
+
+   A proxy, whether or not it implements a cache, MUST pass cache
+   directives through in forwarded messages, regardless of their
+   significance to that application, since the directives might be
+   applicable to all recipients along the request/response chain.  It is
+   not possible to target a directive to a specific cache.
+
+   Cache directives are identified by a token, to be compared
+   case-insensitively, and have an optional argument, that can use both
+   token and quoted-string syntax.  For the directives defined below
+   that define arguments, recipients ought to accept both forms, even if
+   one is documented to be preferred.  For any directive not defined by
+   this specification, a recipient MUST accept both forms.
+
+
+
+Fielding, et al.             Standards Track                   [Page 21]
+
+RFC 7234                    HTTP/1.1 Caching                   June 2014
+
+
+     Cache-Control   = 1#cache-directive
+
+     cache-directive = token [ "=" ( token / quoted-string ) ]
+
+   For the cache directives defined below, no argument is defined (nor
+   allowed) unless stated otherwise.
+
+5.2.1.  Request Cache-Control Directives
+
+5.2.1.1.  max-age
+
+   Argument syntax:
+
+      delta-seconds (see Section 1.2.1)
+
+   The "max-age" request directive indicates that the client is
+   unwilling to accept a response whose age is greater than the
+   specified number of seconds.  Unless the max-stale request directive
+   is also present, the client is not willing to accept a stale
+   response.
+
+   This directive uses the token form of the argument syntax: e.g.,
+   'max-age=5' not 'max-age="5"'.  A sender SHOULD NOT generate the
+   quoted-string form.
+
+5.2.1.2.  max-stale
+
+   Argument syntax:
+
+      delta-seconds (see Section 1.2.1)
+
+   The "max-stale" request directive indicates that the client is
+   willing to accept a response that has exceeded its freshness
+   lifetime.  If max-stale is assigned a value, then the client is
+   willing to accept a response that has exceeded its freshness lifetime
+   by no more than the specified number of seconds.  If no value is
+   assigned to max-stale, then the client is willing to accept a stale
+   response of any age.
+
+   This directive uses the token form of the argument syntax: e.g.,
+   'max-stale=10' not 'max-stale="10"'.  A sender SHOULD NOT generate
+   the quoted-string form.
+
+5.2.1.3.  min-fresh
+
+   Argument syntax:
+
+      delta-seconds (see Section 1.2.1)
+
+
+
+Fielding, et al.             Standards Track                   [Page 22]
+
+RFC 7234                    HTTP/1.1 Caching                   June 2014
+
+
+   The "min-fresh" request directive indicates that the client is
+   willing to accept a response whose freshness lifetime is no less than
+   its current age plus the specified time in seconds.  That is, the
+   client wants a response that will still be fresh for at least the
+   specified number of seconds.
+
+   This directive uses the token form of the argument syntax: e.g.,
+   'min-fresh=20' not 'min-fresh="20"'.  A sender SHOULD NOT generate
+   the quoted-string form.
+
+5.2.1.4.  no-cache
+
+   The "no-cache" request directive indicates that a cache MUST NOT use
+   a stored response to satisfy the request without successful
+   validation on the origin server.
+
+5.2.1.5.  no-store
+
+   The "no-store" request directive indicates that a cache MUST NOT
+   store any part of either this request or any response to it.  This
+   directive applies to both private and shared caches.  "MUST NOT
+   store" in this context means that the cache MUST NOT intentionally
+   store the information in non-volatile storage, and MUST make a
+   best-effort attempt to remove the information from volatile storage
+   as promptly as possible after forwarding it.
+
+   This directive is NOT a reliable or sufficient mechanism for ensuring
+   privacy.  In particular, malicious or compromised caches might not
+   recognize or obey this directive, and communications networks might
+   be vulnerable to eavesdropping.
+
+   Note that if a request containing this directive is satisfied from a
+   cache, the no-store request directive does not apply to the already
+   stored response.
+
+5.2.1.6.  no-transform
+
+   The "no-transform" request directive indicates that an intermediary
+   (whether or not it implements a cache) MUST NOT transform the
+   payload, as defined in Section 5.7.2 of [RFC7230].
+
+5.2.1.7.  only-if-cached
+
+   The "only-if-cached" request directive indicates that the client only
+   wishes to obtain a stored response.  If it receives this directive, a
+   cache SHOULD either respond using a stored response that is
+   consistent with the other constraints of the request, or respond with
+
+
+
+
+Fielding, et al.             Standards Track                   [Page 23]
+
+RFC 7234                    HTTP/1.1 Caching                   June 2014
+
+
+   a 504 (Gateway Timeout) status code.  If a group of caches is being
+   operated as a unified system with good internal connectivity, a
+   member cache MAY forward such a request within that group of caches.
+
+5.2.2.  Response Cache-Control Directives
+
+5.2.2.1.  must-revalidate
+
+   The "must-revalidate" response directive indicates that once it has
+   become stale, a cache MUST NOT use the response to satisfy subsequent
+   requests without successful validation on the origin server.
+
+   The must-revalidate directive is necessary to support reliable
+   operation for certain protocol features.  In all circumstances a
+   cache MUST obey the must-revalidate directive; in particular, if a
+   cache cannot reach the origin server for any reason, it MUST generate
+   a 504 (Gateway Timeout) response.
+
+   The must-revalidate directive ought to be used by servers if and only
+   if failure to validate a request on the representation could result
+   in incorrect operation, such as a silently unexecuted financial
+   transaction.
+
+5.2.2.2.  no-cache
+
+   Argument syntax:
+
+      #field-name
+
+   The "no-cache" response directive indicates that the response MUST
+   NOT be used to satisfy a subsequent request without successful
+   validation on the origin server.  This allows an origin server to
+   prevent a cache from using it to satisfy a request without contacting
+   it, even by caches that have been configured to send stale responses.
+
+   If the no-cache response directive specifies one or more field-names,
+   then a cache MAY use the response to satisfy a subsequent request,
+   subject to any other restrictions on caching.  However, any header
+   fields in the response that have the field-name(s) listed MUST NOT be
+   sent in the response to a subsequent request without successful
+   revalidation with the origin server.  This allows an origin server to
+   prevent the re-use of certain header fields in a response, while
+   still allowing caching of the rest of the response.
+
+   The field-names given are not limited to the set of header fields
+   defined by this specification.  Field names are case-insensitive.
+
+
+
+
+
+Fielding, et al.             Standards Track                   [Page 24]
+
+RFC 7234                    HTTP/1.1 Caching                   June 2014
+
+
+   This directive uses the quoted-string form of the argument syntax.  A
+   sender SHOULD NOT generate the token form (even if quoting appears
+   not to be needed for single-entry lists).
+
+   Note: Although it has been back-ported to many implementations, some
+   HTTP/1.0 caches will not recognize or obey this directive.  Also,
+   no-cache response directives with field-names are often handled by
+   caches as if an unqualified no-cache directive was received; i.e.,
+   the special handling for the qualified form is not widely
+   implemented.
+
+5.2.2.3.  no-store
+
+   The "no-store" response directive indicates that a cache MUST NOT
+   store any part of either the immediate request or response.  This
+   directive applies to both private and shared caches.  "MUST NOT
+   store" in this context means that the cache MUST NOT intentionally
+   store the information in non-volatile storage, and MUST make a
+   best-effort attempt to remove the information from volatile storage
+   as promptly as possible after forwarding it.
+
+   This directive is NOT a reliable or sufficient mechanism for ensuring
+   privacy.  In particular, malicious or compromised caches might not
+   recognize or obey this directive, and communications networks might
+   be vulnerable to eavesdropping.
+
+5.2.2.4.  no-transform
+
+   The "no-transform" response directive indicates that an intermediary
+   (regardless of whether it implements a cache) MUST NOT transform the
+   payload, as defined in Section 5.7.2 of [RFC7230].
+
+5.2.2.5.  public
+
+   The "public" response directive indicates that any cache MAY store
+   the response, even if the response would normally be non-cacheable or
+   cacheable only within a private cache.  (See Section 3.2 for
+   additional details related to the use of public in response to a
+   request containing Authorization, and Section 3 for details of how
+   public affects responses that would normally not be stored, due to
+   their status codes not being defined as cacheable by default; see
+   Section 4.2.2.)
+
+5.2.2.6.  private
+
+   Argument syntax:
+
+      #field-name
+
+
+
+Fielding, et al.             Standards Track                   [Page 25]
+
+RFC 7234                    HTTP/1.1 Caching                   June 2014
+
+
+   The "private" response directive indicates that the response message
+   is intended for a single user and MUST NOT be stored by a shared
+   cache.  A private cache MAY store the response and reuse it for later
+   requests, even if the response would normally be non-cacheable.
+
+   If the private response directive specifies one or more field-names,
+   this requirement is limited to the field-values associated with the
+   listed response header fields.  That is, a shared cache MUST NOT
+   store the specified field-names(s), whereas it MAY store the
+   remainder of the response message.
+
+   The field-names given are not limited to the set of header fields
+   defined by this specification.  Field names are case-insensitive.
+
+   This directive uses the quoted-string form of the argument syntax.  A
+   sender SHOULD NOT generate the token form (even if quoting appears
+   not to be needed for single-entry lists).
+
+   Note: This usage of the word "private" only controls where the
+   response can be stored; it cannot ensure the privacy of the message
+   content.  Also, private response directives with field-names are
+   often handled by caches as if an unqualified private directive was
+   received; i.e., the special handling for the qualified form is not
+   widely implemented.
+
+5.2.2.7.  proxy-revalidate
+
+   The "proxy-revalidate" response directive has the same meaning as the
+   must-revalidate response directive, except that it does not apply to
+   private caches.
+
+5.2.2.8.  max-age
+
+   Argument syntax:
+
+      delta-seconds (see Section 1.2.1)
+
+   The "max-age" response directive indicates that the response is to be
+   considered stale after its age is greater than the specified number
+   of seconds.
+
+   This directive uses the token form of the argument syntax: e.g.,
+   'max-age=5' not 'max-age="5"'.  A sender SHOULD NOT generate the
+   quoted-string form.
+
+
+
+
+
+
+
+Fielding, et al.             Standards Track                   [Page 26]
+
+RFC 7234                    HTTP/1.1 Caching                   June 2014
+
+
+5.2.2.9.  s-maxage
+
+   Argument syntax:
+
+      delta-seconds (see Section 1.2.1)
+
+   The "s-maxage" response directive indicates that, in shared caches,
+   the maximum age specified by this directive overrides the maximum age
+   specified by either the max-age directive or the Expires header
+   field.  The s-maxage directive also implies the semantics of the
+   proxy-revalidate response directive.
+
+   This directive uses the token form of the argument syntax: e.g.,
+   's-maxage=10' not 's-maxage="10"'.  A sender SHOULD NOT generate the
+   quoted-string form.
+
+5.2.3.  Cache Control Extensions
+
+   The Cache-Control header field can be extended through the use of one
+   or more cache-extension tokens, each with an optional value.  A cache
+   MUST ignore unrecognized cache directives.
+
+   Informational extensions (those that do not require a change in cache
+   behavior) can be added without changing the semantics of other
+   directives.
+
+   Behavioral extensions are designed to work by acting as modifiers to
+   the existing base of cache directives.  Both the new directive and
+   the old directive are supplied, such that applications that do not
+   understand the new directive will default to the behavior specified
+   by the old directive, and those that understand the new directive
+   will recognize it as modifying the requirements associated with the
+   old directive.  In this way, extensions to the existing cache-control
+   directives can be made without breaking deployed caches.
+
+   For example, consider a hypothetical new response directive called
+   "community" that acts as a modifier to the private directive: in
+   addition to private caches, any cache that is shared only by members
+   of the named community is allowed to cache the response.  An origin
+   server wishing to allow the UCI community to use an otherwise private
+   response in their shared cache(s) could do so by including
+
+     Cache-Control: private, community="UCI"
+
+   A cache that recognizes such a community cache-extension could
+   broaden its behavior in accordance with that extension.  A cache that
+   does not recognize the community cache-extension would ignore it and
+   adhere to the private directive.
+
+
+
+Fielding, et al.             Standards Track                   [Page 27]
+
+RFC 7234                    HTTP/1.1 Caching                   June 2014
+
+
+5.3.  Expires
+
+   The "Expires" header field gives the date/time after which the
+   response is considered stale.  See Section 4.2 for further discussion
+   of the freshness model.
+
+   The presence of an Expires field does not imply that the original
+   resource will change or cease to exist at, before, or after that
+   time.
+
+   The Expires value is an HTTP-date timestamp, as defined in Section
+   7.1.1.1 of [RFC7231].
+
+     Expires = HTTP-date
+
+   For example
+
+     Expires: Thu, 01 Dec 1994 16:00:00 GMT
+
+   A cache recipient MUST interpret invalid date formats, especially the
+   value "0", as representing a time in the past (i.e., "already
+   expired").
+
+   If a response includes a Cache-Control field with the max-age
+   directive (Section 5.2.2.8), a recipient MUST ignore the Expires
+   field.  Likewise, if a response includes the s-maxage directive
+   (Section 5.2.2.9), a shared cache recipient MUST ignore the Expires
+   field.  In both these cases, the value in Expires is only intended
+   for recipients that have not yet implemented the Cache-Control field.
+
+   An origin server without a clock MUST NOT generate an Expires field
+   unless its value represents a fixed time in the past (always expired)
+   or its value has been associated with the resource by a system or
+   user with a reliable clock.
+
+   Historically, HTTP required the Expires field-value to be no more
+   than a year in the future.  While longer freshness lifetimes are no
+   longer prohibited, extremely large values have been demonstrated to
+   cause problems (e.g., clock overflows due to use of 32-bit integers
+   for time values), and many caches will evict a response far sooner
+   than that.
+
+
+
+
+
+
+
+
+
+
+Fielding, et al.             Standards Track                   [Page 28]
+
+RFC 7234                    HTTP/1.1 Caching                   June 2014
+
+
+5.4.  Pragma
+
+   The "Pragma" header field allows backwards compatibility with
+   HTTP/1.0 caches, so that clients can specify a "no-cache" request
+   that they will understand (as Cache-Control was not defined until
+   HTTP/1.1).  When the Cache-Control header field is also present and
+   understood in a request, Pragma is ignored.
+
+   In HTTP/1.0, Pragma was defined as an extensible field for
+   implementation-specified directives for recipients.  This
+   specification deprecates such extensions to improve interoperability.
+
+     Pragma           = 1#pragma-directive
+     pragma-directive = "no-cache" / extension-pragma
+     extension-pragma = token [ "=" ( token / quoted-string ) ]
+
+   When the Cache-Control header field is not present in a request,
+   caches MUST consider the no-cache request pragma-directive as having
+   the same effect as if "Cache-Control: no-cache" were present (see
+   Section 5.2.1).
+
+   When sending a no-cache request, a client ought to include both the
+   pragma and cache-control directives, unless Cache-Control: no-cache
+   is purposefully omitted to target other Cache-Control response
+   directives at HTTP/1.1 caches.  For example:
+
+     GET / HTTP/1.1
+     Host: www.example.com
+     Cache-Control: max-age=30
+     Pragma: no-cache
+
+   will constrain HTTP/1.1 caches to serve a response no older than 30
+   seconds, while precluding implementations that do not understand
+   Cache-Control from serving a cached response.
+
+      Note: Because the meaning of "Pragma: no-cache" in responses is
+      not specified, it does not provide a reliable replacement for
+      "Cache-Control: no-cache" in them.
+
+5.5.  Warning
+
+   The "Warning" header field is used to carry additional information
+   about the status or transformation of a message that might not be
+   reflected in the status code.  This information is typically used to
+   warn about possible incorrectness introduced by caching operations or
+   transformations applied to the payload of the message.
+
+
+
+
+
+Fielding, et al.             Standards Track                   [Page 29]
+
+RFC 7234                    HTTP/1.1 Caching                   June 2014
+
+
+   Warnings can be used for other purposes, both cache-related and
+   otherwise.  The use of a warning, rather than an error status code,
+   distinguishes these responses from true failures.
+
+   Warning header fields can in general be applied to any message,
+   however some warn-codes are specific to caches and can only be
+   applied to response messages.
+
+     Warning       = 1#warning-value
+
+     warning-value = warn-code SP warn-agent SP warn-text
+                                           [ SP warn-date ]
+
+     warn-code  = 3DIGIT
+     warn-agent = ( uri-host [ ":" port ] ) / pseudonym
+                     ; the name or pseudonym of the server adding
+                     ; the Warning header field, for use in debugging
+                     ; a single "-" is recommended when agent unknown
+     warn-text  = quoted-string
+     warn-date  = DQUOTE HTTP-date DQUOTE
+
+   Multiple warnings can be generated in a response (either by the
+   origin server or by a cache), including multiple warnings with the
+   same warn-code number that only differ in warn-text.
+
+   A user agent that receives one or more Warning header fields SHOULD
+   inform the user of as many of them as possible, in the order that
+   they appear in the response.  Senders that generate multiple Warning
+   header fields are encouraged to order them with this user agent
+   behavior in mind.  A sender that generates new Warning header fields
+   MUST append them after any existing Warning header fields.
+
+   Warnings are assigned three digit warn-codes.  The first digit
+   indicates whether the Warning is required to be deleted from a stored
+   response after validation:
+
+   o  1xx warn-codes describe the freshness or validation status of the
+      response, and so they MUST be deleted by a cache after validation.
+      They can only be generated by a cache when validating a cached
+      entry, and MUST NOT be generated in any other situation.
+
+   o  2xx warn-codes describe some aspect of the representation that is
+      not rectified by a validation (for example, a lossy compression of
+      the representation) and they MUST NOT be deleted by a cache after
+      validation, unless a full response is sent, in which case they
+      MUST be.
+
+
+
+
+
+Fielding, et al.             Standards Track                   [Page 30]
+
+RFC 7234                    HTTP/1.1 Caching                   June 2014
+
+
+   If a sender generates one or more 1xx warn-codes in a message to be
+   sent to a recipient known to implement only HTTP/1.0, the sender MUST
+   include in each corresponding warning-value a warn-date that matches
+   the Date header field in the message.  For example:
+
+     HTTP/1.1 200 OK
+     Date: Sat, 25 Aug 2012 23:34:45 GMT
+     Warning: 112 - "network down" "Sat, 25 Aug 2012 23:34:45 GMT"
+
+
+   Warnings have accompanying warn-text that describes the error, e.g.,
+   for logging.  It is advisory only, and its content does not affect
+   interpretation of the warn-code.
+
+   If a recipient that uses, evaluates, or displays Warning header
+   fields receives a warn-date that is different from the Date value in
+   the same message, the recipient MUST exclude the warning-value
+   containing that warn-date before storing, forwarding, or using the
+   message.  This allows recipients to exclude warning-values that were
+   improperly retained after a cache validation.  If all of the
+   warning-values are excluded, the recipient MUST exclude the Warning
+   header field as well.
+
+   The following warn-codes are defined by this specification, each with
+   a recommended warn-text in English, and a description of its meaning.
+   The procedure for defining additional warn codes is described in
+   Section 7.2.1.
+
+5.5.1.  Warning: 110 - "Response is Stale"
+
+   A cache SHOULD generate this whenever the sent response is stale.
+
+5.5.2.  Warning: 111 - "Revalidation Failed"
+
+   A cache SHOULD generate this when sending a stale response because an
+   attempt to validate the response failed, due to an inability to reach
+   the server.
+
+5.5.3.  Warning: 112 - "Disconnected Operation"
+
+   A cache SHOULD generate this if it is intentionally disconnected from
+   the rest of the network for a period of time.
+
+5.5.4.  Warning: 113 - "Heuristic Expiration"
+
+   A cache SHOULD generate this if it heuristically chose a freshness
+   lifetime greater than 24 hours and the response's age is greater than
+   24 hours.
+
+
+
+Fielding, et al.             Standards Track                   [Page 31]
+
+RFC 7234                    HTTP/1.1 Caching                   June 2014
+
+
+5.5.5.  Warning: 199 - "Miscellaneous Warning"
+
+   The warning text can include arbitrary information to be presented to
+   a human user or logged.  A system receiving this warning MUST NOT
+   take any automated action, besides presenting the warning to the
+   user.
+
+5.5.6.  Warning: 214 - "Transformation Applied"
+
+   This Warning code MUST be added by a proxy if it applies any
+   transformation to the representation, such as changing the
+   content-coding, media-type, or modifying the representation data,
+   unless this Warning code already appears in the response.
+
+5.5.7.  Warning: 299 - "Miscellaneous Persistent Warning"
+
+   The warning text can include arbitrary information to be presented to
+   a human user or logged.  A system receiving this warning MUST NOT
+   take any automated action.
+
+6.  History Lists
+
+   User agents often have history mechanisms, such as "Back" buttons and
+   history lists, that can be used to redisplay a representation
+   retrieved earlier in a session.
+
+   The freshness model (Section 4.2) does not necessarily apply to
+   history mechanisms.  That is, a history mechanism can display a
+   previous representation even if it has expired.
+
+   This does not prohibit the history mechanism from telling the user
+   that a view might be stale or from honoring cache directives (e.g.,
+   Cache-Control: no-store).
+
+7.  IANA Considerations
+
+7.1.  Cache Directive Registry
+
+   The "Hypertext Transfer Protocol (HTTP) Cache Directive Registry"
+   defines the namespace for the cache directives.  It has been created
+   and is now maintained at
+   <http://www.iana.org/assignments/http-cache-directives>.
+
+7.1.1.  Procedure
+
+   A registration MUST include the following fields:
+
+   o  Cache Directive Name
+
+
+
+Fielding, et al.             Standards Track                   [Page 32]
+
+RFC 7234                    HTTP/1.1 Caching                   June 2014
+
+
+   o  Pointer to specification text
+
+   Values to be added to this namespace require IETF Review (see
+   [RFC5226], Section 4.1).
+
+7.1.2.  Considerations for New Cache Control Directives
+
+   New extension directives ought to consider defining:
+
+   o  What it means for a directive to be specified multiple times,
+
+   o  When the directive does not take an argument, what it means when
+      an argument is present,
+
+   o  When the directive requires an argument, what it means when it is
+      missing,
+
+   o  Whether the directive is specific to requests, responses, or able
+      to be used in either.
+
+   See also Section 5.2.3.
+
+7.1.3.  Registrations
+
+   The registry has been populated with the registrations below:
+
+   +------------------------+----------------------------------+
+   | Cache Directive        | Reference                        |
+   +------------------------+----------------------------------+
+   | max-age                | Section 5.2.1.1, Section 5.2.2.8 |
+   | max-stale              | Section 5.2.1.2                  |
+   | min-fresh              | Section 5.2.1.3                  |
+   | must-revalidate        | Section 5.2.2.1                  |
+   | no-cache               | Section 5.2.1.4, Section 5.2.2.2 |
+   | no-store               | Section 5.2.1.5, Section 5.2.2.3 |
+   | no-transform           | Section 5.2.1.6, Section 5.2.2.4 |
+   | only-if-cached         | Section 5.2.1.7                  |
+   | private                | Section 5.2.2.6                  |
+   | proxy-revalidate       | Section 5.2.2.7                  |
+   | public                 | Section 5.2.2.5                  |
+   | s-maxage               | Section 5.2.2.9                  |
+   | stale-if-error         | [RFC5861], Section 4             |
+   | stale-while-revalidate | [RFC5861], Section 3             |
+   +------------------------+----------------------------------+
+
+
+
+
+
+
+
+Fielding, et al.             Standards Track                   [Page 33]
+
+RFC 7234                    HTTP/1.1 Caching                   June 2014
+
+
+7.2.  Warn Code Registry
+
+   The "Hypertext Transfer Protocol (HTTP) Warn Codes" registry defines
+   the namespace for warn codes.  It has been created and is now
+   maintained at <http://www.iana.org/assignments/http-warn-codes>.
+
+7.2.1.  Procedure
+
+   A registration MUST include the following fields:
+
+   o  Warn Code (3 digits)
+
+   o  Short Description
+
+   o  Pointer to specification text
+
+   Values to be added to this namespace require IETF Review (see
+   [RFC5226], Section 4.1).
+
+7.2.2.  Registrations
+
+   The registry has been populated with the registrations below:
+
+   +-----------+----------------------------------+---------------+
+   | Warn Code | Short Description                | Reference     |
+   +-----------+----------------------------------+---------------+
+   | 110       | Response is Stale                | Section 5.5.1 |
+   | 111       | Revalidation Failed              | Section 5.5.2 |
+   | 112       | Disconnected Operation           | Section 5.5.3 |
+   | 113       | Heuristic Expiration             | Section 5.5.4 |
+   | 199       | Miscellaneous Warning            | Section 5.5.5 |
+   | 214       | Transformation Applied           | Section 5.5.6 |
+   | 299       | Miscellaneous Persistent Warning | Section 5.5.7 |
+   +-----------+----------------------------------+---------------+
+
+7.3.  Header Field Registration
+
+   HTTP header fields are registered within the "Message Headers"
+   registry maintained at
+   <http://www.iana.org/assignments/message-headers/>.
+
+
+
+
+
+
+
+
+
+
+
+Fielding, et al.             Standards Track                   [Page 34]
+
+RFC 7234                    HTTP/1.1 Caching                   June 2014
+
+
+   This document defines the following HTTP header fields, so the
+   "Permanent Message Header Field Names" registry has been updated
+   accordingly (see [BCP90]).
+
+   +-------------------+----------+----------+-------------+
+   | Header Field Name | Protocol | Status   | Reference   |
+   +-------------------+----------+----------+-------------+
+   | Age               | http     | standard | Section 5.1 |
+   | Cache-Control     | http     | standard | Section 5.2 |
+   | Expires           | http     | standard | Section 5.3 |
+   | Pragma            | http     | standard | Section 5.4 |
+   | Warning           | http     | standard | Section 5.5 |
+   +-------------------+----------+----------+-------------+
+
+   The change controller is: "IETF (iesg@ietf.org) - Internet
+   Engineering Task Force".
+
+8.  Security Considerations
+
+   This section is meant to inform developers, information providers,
+   and users of known security concerns specific to HTTP caching.  More
+   general security considerations are addressed in HTTP messaging
+   [RFC7230] and semantics [RFC7231].
+
+   Caches expose additional potential vulnerabilities, since the
+   contents of the cache represent an attractive target for malicious
+   exploitation.  Because cache contents persist after an HTTP request
+   is complete, an attack on the cache can reveal information long after
+   a user believes that the information has been removed from the
+   network.  Therefore, cache contents need to be protected as sensitive
+   information.
+
+   In particular, various attacks might be amplified by being stored in
+   a shared cache; such "cache poisoning" attacks use the cache to
+   distribute a malicious payload to many clients, and are especially
+   effective when an attacker can use implementation flaws, elevated
+   privileges, or other techniques to insert such a response into a
+   cache.  One common attack vector for cache poisoning is to exploit
+   differences in message parsing on proxies and in user agents; see
+   Section 3.3.3 of [RFC7230] for the relevant requirements.
+
+   Likewise, implementation flaws (as well as misunderstanding of cache
+   operation) might lead to caching of sensitive information (e.g.,
+   authentication credentials) that is thought to be private, exposing
+   it to unauthorized parties.
+
+
+
+
+
+
+Fielding, et al.             Standards Track                   [Page 35]
+
+RFC 7234                    HTTP/1.1 Caching                   June 2014
+
+
+   Furthermore, the very use of a cache can bring about privacy
+   concerns.  For example, if two users share a cache, and the first one
+   browses to a site, the second may be able to detect that the other
+   has been to that site, because the resources from it load more
+   quickly, thanks to the cache.
+
+   Note that the Set-Cookie response header field [RFC6265] does not
+   inhibit caching; a cacheable response with a Set-Cookie header field
+   can be (and often is) used to satisfy subsequent requests to caches.
+   Servers who wish to control caching of these responses are encouraged
+   to emit appropriate Cache-Control response header fields.
+
+9.  Acknowledgments
+
+   See Section 10 of [RFC7230].
+
+10.  References
+
+10.1.  Normative References
+
+   [RFC2119]  Bradner, S., "Key words for use in RFCs to Indicate
+              Requirement Levels", BCP 14, RFC 2119, March 1997.
+
+   [RFC5234]  Crocker, D., Ed. and P. Overell, "Augmented BNF for Syntax
+              Specifications: ABNF", STD 68, RFC 5234, January 2008.
+
+   [RFC7230]  Fielding, R., Ed. and J. Reschke, Ed., "Hypertext Transfer
+              Protocol (HTTP/1.1): Message Syntax and Routing",
+              RFC 7230, June 2014.
+
+   [RFC7231]  Fielding, R., Ed. and J. Reschke, Ed., "Hypertext Transfer
+              Protocol (HTTP/1.1): Semantics and Content", RFC 7231,
+              June 2014.
+
+   [RFC7232]  Fielding, R., Ed. and J. Reschke, Ed., "Hypertext Transfer
+              Protocol (HTTP/1.1): Conditional Requests", RFC 7232,
+              June 2014.
+
+   [RFC7233]  Fielding, R., Ed., Lafon, Y., Ed., and J. Reschke, Ed.,
+              "Hypertext Transfer Protocol (HTTP/1.1): Range Requests",
+              RFC 7233, June 2014.
+
+   [RFC7235]  Fielding, R., Ed. and J. Reschke, Ed., "Hypertext Transfer
+              Protocol (HTTP/1.1): Authentication", RFC 7235, June 2014.
+
+
+
+
+
+
+
+Fielding, et al.             Standards Track                   [Page 36]
+
+RFC 7234                    HTTP/1.1 Caching                   June 2014
+
+
+10.2.  Informative References
+
+   [BCP90]    Klyne, G., Nottingham, M., and J. Mogul, "Registration
+              Procedures for Message Header Fields", BCP 90, RFC 3864,
+              September 2004.
+
+   [RFC2616]  Fielding, R., Gettys, J., Mogul, J., Frystyk, H.,
+              Masinter, L., Leach, P., and T. Berners-Lee, "Hypertext
+              Transfer Protocol -- HTTP/1.1", RFC 2616, June 1999.
+
+   [RFC5226]  Narten, T. and H. Alvestrand, "Guidelines for Writing an
+              IANA Considerations Section in RFCs", BCP 26, RFC 5226,
+              May 2008.
+
+   [RFC5861]  Nottingham, M., "HTTP Cache-Control Extensions for Stale
+              Content", RFC 5861, April 2010.
+
+   [RFC5905]  Mills, D., Martin, J., Ed., Burbank, J., and W. Kasch,
+              "Network Time Protocol Version 4: Protocol and Algorithms
+              Specification", RFC 5905, June 2010.
+
+   [RFC6265]  Barth, A., "HTTP State Management Mechanism", RFC 6265,
+              April 2011.
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+Fielding, et al.             Standards Track                   [Page 37]
+
+RFC 7234                    HTTP/1.1 Caching                   June 2014
+
+
+Appendix A.  Changes from RFC 2616
+
+   The specification has been substantially rewritten for clarity.
+
+   The conditions under which an authenticated response can be cached
+   have been clarified.  (Section 3.2)
+
+   New status codes can now define that caches are allowed to use
+   heuristic freshness with them.  Caches are now allowed to calculate
+   heuristic freshness for URIs with query components.  (Section 4.2.2)
+
+   The algorithm for calculating age is now less conservative.  Caches
+   are now required to handle dates with time zones as if they're
+   invalid, because it's not possible to accurately guess.
+   (Section 4.2.3)
+
+   The Content-Location response header field is no longer used to
+   determine the appropriate response to use when validating.
+   (Section 4.3)
+
+   The algorithm for selecting a cached negotiated response to use has
+   been clarified in several ways.  In particular, it now explicitly
+   allows header-specific canonicalization when processing selecting
+   header fields.  (Section 4.1)
+
+   Requirements regarding denial-of-service attack avoidance when
+   performing invalidation have been clarified.  (Section 4.4)
+
+   Cache invalidation only occurs when a successful response is
+   received.  (Section 4.4)
+
+   Cache directives are explicitly defined to be case-insensitive.
+   Handling of multiple instances of cache directives when only one is
+   expected is now defined.  (Section 5.2)
+
+   The "no-store" request directive doesn't apply to responses; i.e., a
+   cache can satisfy a request with no-store on it and does not
+   invalidate it.  (Section 5.2.1.5)
+
+   The qualified forms of the private and no-cache cache directives are
+   noted to not be widely implemented; for example, "private=foo" is
+   interpreted by many caches as simply "private".  Additionally, the
+   meaning of the qualified form of no-cache has been clarified.
+   (Section 5.2.2)
+
+   The "no-cache" response directive's meaning has been clarified.
+   (Section 5.2.2.2)
+
+
+
+
+Fielding, et al.             Standards Track                   [Page 38]
+
+RFC 7234                    HTTP/1.1 Caching                   June 2014
+
+
+   The one-year limit on Expires header field values has been removed;
+   instead, the reasoning for using a sensible value is given.
+   (Section 5.3)
+
+   The Pragma header field is now only defined for backwards
+   compatibility; future pragmas are deprecated.  (Section 5.4)
+
+   Some requirements regarding production and processing of the Warning
+   header fields have been relaxed, as it is not widely implemented.
+   Furthermore, the Warning header field no longer uses RFC 2047
+   encoding, nor does it allow multiple languages, as these aspects were
+   not implemented.  (Section 5.5)
+
+   This specification introduces the Cache Directive and Warn Code
+   Registries, and defines considerations for new cache directives.
+   (Section 7.1 and Section 7.2)
+
+Appendix B.  Imported ABNF
+
+   The following core rules are included by reference, as defined in
+   Appendix B.1 of [RFC5234]: ALPHA (letters), CR (carriage return),
+   CRLF (CR LF), CTL (controls), DIGIT (decimal 0-9), DQUOTE (double
+   quote), HEXDIG (hexadecimal 0-9/A-F/a-f), LF (line feed), OCTET (any
+   8-bit sequence of data), SP (space), and VCHAR (any visible US-ASCII
+   character).
+
+   The rules below are defined in [RFC7230]:
+
+     OWS           = <OWS, see [RFC7230], Section 3.2.3>
+     field-name    = <field-name, see [RFC7230], Section 3.2>
+     quoted-string = <quoted-string, see [RFC7230], Section 3.2.6>
+     token         = <token, see [RFC7230], Section 3.2.6>
+
+     port          = <port, see [RFC7230], Section 2.7>
+     pseudonym     = <pseudonym, see [RFC7230], Section 5.7.1>
+     uri-host      = <uri-host, see [RFC7230], Section 2.7>
+
+   The rules below are defined in other parts:
+
+     HTTP-date     = <HTTP-date, see [RFC7231], Section 7.1.1.1>
+
+
+
+
+
+
+
+
+
+
+
+Fielding, et al.             Standards Track                   [Page 39]
+
+RFC 7234                    HTTP/1.1 Caching                   June 2014
+
+
+Appendix C.  Collected ABNF
+
+   In the collected ABNF below, list rules are expanded as per Section
+   1.2 of [RFC7230].
+
+   Age = delta-seconds
+
+   Cache-Control = *( "," OWS ) cache-directive *( OWS "," [ OWS
+    cache-directive ] )
+
+   Expires = HTTP-date
+
+   HTTP-date = <HTTP-date, see [RFC7231], Section 7.1.1.1>
+
+   OWS = <OWS, see [RFC7230], Section 3.2.3>
+
+   Pragma = *( "," OWS ) pragma-directive *( OWS "," [ OWS
+    pragma-directive ] )
+
+   Warning = *( "," OWS ) warning-value *( OWS "," [ OWS warning-value ]
+    )
+
+   cache-directive = token [ "=" ( token / quoted-string ) ]
+
+   delta-seconds = 1*DIGIT
+
+   extension-pragma = token [ "=" ( token / quoted-string ) ]
+
+   field-name = <field-name, see [RFC7230], Section 3.2>
+
+   port = <port, see [RFC7230], Section 2.7>
+   pragma-directive = "no-cache" / extension-pragma
+   pseudonym = <pseudonym, see [RFC7230], Section 5.7.1>
+
+   quoted-string = <quoted-string, see [RFC7230], Section 3.2.6>
+
+   token = <token, see [RFC7230], Section 3.2.6>
+
+   uri-host = <uri-host, see [RFC7230], Section 2.7>
+
+   warn-agent = ( uri-host [ ":" port ] ) / pseudonym
+   warn-code = 3DIGIT
+   warn-date = DQUOTE HTTP-date DQUOTE
+   warn-text = quoted-string
+   warning-value = warn-code SP warn-agent SP warn-text [ SP warn-date
+    ]
+
+
+
+
+
+Fielding, et al.             Standards Track                   [Page 40]
+
+RFC 7234                    HTTP/1.1 Caching                   June 2014
+
+
+Index
+
+   1
+      110 (warn-code)  31
+      111 (warn-code)  31
+      112 (warn-code)  31
+      113 (warn-code)  31
+      199 (warn-code)  32
+
+   2
+      214 (warn-code)  32
+      299 (warn-code)  32
+
+   A
+      age  11
+      Age header field  21
+
+   C
+      cache  4
+      cache entry  5
+      cache key  5-6
+      Cache-Control header field  21
+
+   D
+      Disconnected Operation (warn-text)  31
+
+   E
+      Expires header field  28
+      explicit expiration time  11
+
+   F
+      fresh  11
+      freshness lifetime  11
+
+   G
+      Grammar
+         Age  21
+         Cache-Control  22
+         cache-directive  22
+         delta-seconds  5
+         Expires  28
+         extension-pragma  29
+         Pragma  29
+         pragma-directive  29
+         warn-agent  29
+         warn-code  29
+         warn-date  29
+         warn-text  29
+
+
+
+Fielding, et al.             Standards Track                   [Page 41]
+
+RFC 7234                    HTTP/1.1 Caching                   June 2014
+
+
+         Warning  29
+         warning-value  29
+
+   H
+      Heuristic Expiration (warn-text)  31
+      heuristic expiration time  11
+   M
+      max-age (cache directive)  22, 26
+      max-stale (cache directive)  22
+      min-fresh (cache directive)  22
+      Miscellaneous Persistent Warning (warn-text)  32
+      Miscellaneous Warning (warn-text)  32
+      must-revalidate (cache directive)  24
+
+   N
+      no-cache (cache directive)  23, 25
+      no-store (cache directive)  23, 24
+      no-transform (cache directive)  23, 25
+
+   O
+      only-if-cached (cache directive)  23
+
+   P
+      Pragma header field  29
+      private (cache directive)  25
+      private cache  4
+      proxy-revalidate (cache directive)  26
+      public (cache directive)  25
+
+   R
+      Response is Stale (warn-text)  30
+      Revalidation Failed (warn-text)  31
+
+   S
+      s-maxage (cache directive)  27
+      shared cache  4
+      stale  11
+      strong validator  18
+
+   T
+      Transformation Applied (warn-text)  32
+
+   V
+      validator  16
+
+   W
+      Warning header field  29
+
+
+
+
+Fielding, et al.             Standards Track                   [Page 42]
+
+RFC 7234                    HTTP/1.1 Caching                   June 2014
+
+
+Authors' Addresses
+
+   Roy T. Fielding (editor)
+   Adobe Systems Incorporated
+   345 Park Ave
+   San Jose, CA  95110
+   USA
+
+   EMail: fielding@gbiv.com
+   URI:   http://roy.gbiv.com/
+
+
+   Mark Nottingham (editor)
+   Akamai
+
+   EMail: mnot@mnot.net
+   URI:   http://www.mnot.net/
+
+
+   Julian F. Reschke (editor)
+   greenbytes GmbH
+   Hafenweg 16
+   Muenster, NW  48155
+   Germany
+
+   EMail: julian.reschke@greenbytes.de
+   URI:   http://greenbytes.de/tech/webdav/
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+Fielding, et al.             Standards Track                   [Page 43]
+
@@ -0,0 +1,1067 @@
+
+
+
+
+
+
+Internet Engineering Task Force (IETF)                  R. Fielding, Ed.
+Request for Comments: 7235                                         Adobe
+Obsoletes: 2616                                          J. Reschke, Ed.
+Updates: 2617                                                 greenbytes
+Category: Standards Track                                      June 2014
+ISSN: 2070-1721
+
+
+         Hypertext Transfer Protocol (HTTP/1.1): Authentication
+
+Abstract
+
+   The Hypertext Transfer Protocol (HTTP) is a stateless application-
+   level protocol for distributed, collaborative, hypermedia information
+   systems.  This document defines the HTTP Authentication framework.
+
+Status of This Memo
+
+   This is an Internet Standards Track document.
+
+   This document is a product of the Internet Engineering Task Force
+   (IETF).  It represents the consensus of the IETF community.  It has
+   received public review and has been approved for publication by the
+   Internet Engineering Steering Group (IESG).  Further information on
+   Internet Standards is available in Section 2 of RFC 5741.
+
+   Information about the current status of this document, any errata,
+   and how to provide feedback on it may be obtained at
+   http://www.rfc-editor.org/info/rfc7235.
+
+Copyright Notice
+
+   Copyright (c) 2014 IETF Trust and the persons identified as the
+   document authors.  All rights reserved.
+
+   This document is subject to BCP 78 and the IETF Trust's Legal
+   Provisions Relating to IETF Documents
+   (http://trustee.ietf.org/license-info) in effect on the date of
+   publication of this document.  Please review these documents
+   carefully, as they describe your rights and restrictions with respect
+   to this document.  Code Components extracted from this document must
+   include Simplified BSD License text as described in Section 4.e of
+   the Trust Legal Provisions and are provided without warranty as
+   described in the Simplified BSD License.
+
+   This document may contain material from IETF Documents or IETF
+   Contributions published or made publicly available before November
+   10, 2008.  The person(s) controlling the copyright in some of this
+
+
+
+Fielding & Reschke           Standards Track                    [Page 1]
+
+RFC 7235                 HTTP/1.1 Authentication               June 2014
+
+
+   material may not have granted the IETF Trust the right to allow
+   modifications of such material outside the IETF Standards Process.
+   Without obtaining an adequate license from the person(s) controlling
+   the copyright in such materials, this document may not be modified
+   outside the IETF Standards Process, and derivative works of it may
+   not be created outside the IETF Standards Process, except to format
+   it for publication as an RFC or to translate it into languages other
+   than English.
+
+Table of Contents
+
+   1. Introduction ....................................................3
+      1.1. Conformance and Error Handling .............................3
+      1.2. Syntax Notation ............................................3
+   2. Access Authentication Framework .................................3
+      2.1. Challenge and Response .....................................3
+      2.2. Protection Space (Realm) ...................................5
+   3. Status Code Definitions .........................................6
+      3.1. 401 Unauthorized ...........................................6
+      3.2. 407 Proxy Authentication Required ..........................6
+   4. Header Field Definitions ........................................7
+      4.1. WWW-Authenticate ...........................................7
+      4.2. Authorization ..............................................8
+      4.3. Proxy-Authenticate .........................................8
+      4.4. Proxy-Authorization ........................................9
+   5. IANA Considerations .............................................9
+      5.1. Authentication Scheme Registry .............................9
+           5.1.1. Procedure ...........................................9
+           5.1.2. Considerations for New Authentication Schemes ......10
+      5.2. Status Code Registration ..................................11
+      5.3. Header Field Registration .................................11
+   6. Security Considerations ........................................12
+      6.1. Confidentiality of Credentials ............................12
+      6.2. Authentication Credentials and Idle Clients ...............12
+      6.3. Protection Spaces .........................................13
+   7. Acknowledgments ................................................14
+   8. References .....................................................14
+      8.1. Normative References ......................................14
+      8.2. Informative References ....................................14
+   Appendix A. Changes from RFCs 2616 and 2617 .......................16
+   Appendix B. Imported ABNF .........................................16
+   Appendix C. Collected ABNF ........................................17
+   Index .............................................................18
+
+
+
+
+
+
+
+
+Fielding & Reschke           Standards Track                    [Page 2]
+
+RFC 7235                 HTTP/1.1 Authentication               June 2014
+
+
+1.  Introduction
+
+   HTTP provides a general framework for access control and
+   authentication, via an extensible set of challenge-response
+   authentication schemes, which can be used by a server to challenge a
+   client request and by a client to provide authentication information.
+   This document defines HTTP/1.1 authentication in terms of the
+   architecture defined in "Hypertext Transfer Protocol (HTTP/1.1):
+   Message Syntax and Routing" [RFC7230], including the general
+   framework previously described in "HTTP Authentication: Basic and
+   Digest Access Authentication" [RFC2617] and the related fields and
+   status codes previously defined in "Hypertext Transfer Protocol --
+   HTTP/1.1" [RFC2616].
+
+   The IANA Authentication Scheme Registry (Section 5.1) lists
+   registered authentication schemes and their corresponding
+   specifications, including the "basic" and "digest" authentication
+   schemes previously defined by RFC 2617.
+
+1.1.  Conformance and Error Handling
+
+   The key words "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT",
+   "SHOULD", "SHOULD NOT", "RECOMMENDED", "MAY", and "OPTIONAL" in this
+   document are to be interpreted as described in [RFC2119].
+
+   Conformance criteria and considerations regarding error handling are
+   defined in Section 2.5 of [RFC7230].
+
+1.2.  Syntax Notation
+
+   This specification uses the Augmented Backus-Naur Form (ABNF)
+   notation of [RFC5234] with a list extension, defined in Section 7 of
+   [RFC7230], that allows for compact definition of comma-separated
+   lists using a '#' operator (similar to how the '*' operator indicates
+   repetition).  Appendix B describes rules imported from other
+   documents.  Appendix C shows the collected grammar with all list
+   operators expanded to standard ABNF notation.
+
+2.  Access Authentication Framework
+
+2.1.  Challenge and Response
+
+   HTTP provides a simple challenge-response authentication framework
+   that can be used by a server to challenge a client request and by a
+   client to provide authentication information.  It uses a case-
+   insensitive token as a means to identify the authentication scheme,
+   followed by additional information necessary for achieving
+
+
+
+
+Fielding & Reschke           Standards Track                    [Page 3]
+
+RFC 7235                 HTTP/1.1 Authentication               June 2014
+
+
+   authentication via that scheme.  The latter can be either a comma-
+   separated list of parameters or a single sequence of characters
+   capable of holding base64-encoded information.
+
+   Authentication parameters are name=value pairs, where the name token
+   is matched case-insensitively, and each parameter name MUST only
+   occur once per challenge.
+
+     auth-scheme    = token
+
+     auth-param     = token BWS "=" BWS ( token / quoted-string )
+
+     token68        = 1*( ALPHA / DIGIT /
+                          "-" / "." / "_" / "~" / "+" / "/" ) *"="
+
+   The token68 syntax allows the 66 unreserved URI characters
+   ([RFC3986]), plus a few others, so that it can hold a base64,
+   base64url (URL and filename safe alphabet), base32, or base16 (hex)
+   encoding, with or without padding, but excluding whitespace
+   ([RFC4648]).
+
+   A 401 (Unauthorized) response message is used by an origin server to
+   challenge the authorization of a user agent, including a
+   WWW-Authenticate header field containing at least one challenge
+   applicable to the requested resource.
+
+   A 407 (Proxy Authentication Required) response message is used by a
+   proxy to challenge the authorization of a client, including a
+   Proxy-Authenticate header field containing at least one challenge
+   applicable to the proxy for the requested resource.
+
+     challenge   = auth-scheme [ 1*SP ( token68 / #auth-param ) ]
+
+      Note: Many clients fail to parse a challenge that contains an
+      unknown scheme.  A workaround for this problem is to list well-
+      supported schemes (such as "basic") first.
+
+   A user agent that wishes to authenticate itself with an origin server
+   -- usually, but not necessarily, after receiving a 401 (Unauthorized)
+   -- can do so by including an Authorization header field with the
+   request.
+
+   A client that wishes to authenticate itself with a proxy -- usually,
+   but not necessarily, after receiving a 407 (Proxy Authentication
+   Required) -- can do so by including a Proxy-Authorization header
+   field with the request.
+
+
+
+
+
+Fielding & Reschke           Standards Track                    [Page 4]
+
+RFC 7235                 HTTP/1.1 Authentication               June 2014
+
+
+   Both the Authorization field value and the Proxy-Authorization field
+   value contain the client's credentials for the realm of the resource
+   being requested, based upon a challenge received in a response
+   (possibly at some point in the past).  When creating their values,
+   the user agent ought to do so by selecting the challenge with what it
+   considers to be the most secure auth-scheme that it understands,
+   obtaining credentials from the user as appropriate.  Transmission of
+   credentials within header field values implies significant security
+   considerations regarding the confidentiality of the underlying
+   connection, as described in Section 6.1.
+
+     credentials = auth-scheme [ 1*SP ( token68 / #auth-param ) ]
+
+   Upon receipt of a request for a protected resource that omits
+   credentials, contains invalid credentials (e.g., a bad password) or
+   partial credentials (e.g., when the authentication scheme requires
+   more than one round trip), an origin server SHOULD send a 401
+   (Unauthorized) response that contains a WWW-Authenticate header field
+   with at least one (possibly new) challenge applicable to the
+   requested resource.
+
+   Likewise, upon receipt of a request that omits proxy credentials or
+   contains invalid or partial proxy credentials, a proxy that requires
+   authentication SHOULD generate a 407 (Proxy Authentication Required)
+   response that contains a Proxy-Authenticate header field with at
+   least one (possibly new) challenge applicable to the proxy.
+
+   A server that receives valid credentials that are not adequate to
+   gain access ought to respond with the 403 (Forbidden) status code
+   (Section 6.5.3 of [RFC7231]).
+
+   HTTP does not restrict applications to this simple challenge-response
+   framework for access authentication.  Additional mechanisms can be
+   used, such as authentication at the transport level or via message
+   encapsulation, and with additional header fields specifying
+   authentication information.  However, such additional mechanisms are
+   not defined by this specification.
+
+2.2.  Protection Space (Realm)
+
+   The "realm" authentication parameter is reserved for use by
+   authentication schemes that wish to indicate a scope of protection.
+
+   A protection space is defined by the canonical root URI (the scheme
+   and authority components of the effective request URI; see Section
+   5.5 of [RFC7230]) of the server being accessed, in combination with
+   the realm value if present.  These realms allow the protected
+   resources on a server to be partitioned into a set of protection
+
+
+
+Fielding & Reschke           Standards Track                    [Page 5]
+
+RFC 7235                 HTTP/1.1 Authentication               June 2014
+
+
+   spaces, each with its own authentication scheme and/or authorization
+   database.  The realm value is a string, generally assigned by the
+   origin server, that can have additional semantics specific to the
+   authentication scheme.  Note that a response can have multiple
+   challenges with the same auth-scheme but with different realms.
+
+   The protection space determines the domain over which credentials can
+   be automatically applied.  If a prior request has been authorized,
+   the user agent MAY reuse the same credentials for all other requests
+   within that protection space for a period of time determined by the
+   authentication scheme, parameters, and/or user preferences (such as a
+   configurable inactivity timeout).  Unless specifically allowed by the
+   authentication scheme, a single protection space cannot extend
+   outside the scope of its server.
+
+   For historical reasons, a sender MUST only generate the quoted-string
+   syntax.  Recipients might have to support both token and
+   quoted-string syntax for maximum interoperability with existing
+   clients that have been accepting both notations for a long time.
+
+3.  Status Code Definitions
+
+3.1.  401 Unauthorized
+
+   The 401 (Unauthorized) status code indicates that the request has not
+   been applied because it lacks valid authentication credentials for
+   the target resource.  The server generating a 401 response MUST send
+   a WWW-Authenticate header field (Section 4.1) containing at least one
+   challenge applicable to the target resource.
+
+   If the request included authentication credentials, then the 401
+   response indicates that authorization has been refused for those
+   credentials.  The user agent MAY repeat the request with a new or
+   replaced Authorization header field (Section 4.2).  If the 401
+   response contains the same challenge as the prior response, and the
+   user agent has already attempted authentication at least once, then
+   the user agent SHOULD present the enclosed representation to the
+   user, since it usually contains relevant diagnostic information.
+
+3.2.  407 Proxy Authentication Required
+
+   The 407 (Proxy Authentication Required) status code is similar to 401
+   (Unauthorized), but it indicates that the client needs to
+   authenticate itself in order to use a proxy.  The proxy MUST send a
+   Proxy-Authenticate header field (Section 4.3) containing a challenge
+   applicable to that proxy for the target resource.  The client MAY
+   repeat the request with a new or replaced Proxy-Authorization header
+   field (Section 4.4).
+
+
+
+Fielding & Reschke           Standards Track                    [Page 6]
+
+RFC 7235                 HTTP/1.1 Authentication               June 2014
+
+
+4.  Header Field Definitions
+
+   This section defines the syntax and semantics of header fields
+   related to the HTTP authentication framework.
+
+4.1.  WWW-Authenticate
+
+   The "WWW-Authenticate" header field indicates the authentication
+   scheme(s) and parameters applicable to the target resource.
+
+     WWW-Authenticate = 1#challenge
+
+   A server generating a 401 (Unauthorized) response MUST send a
+   WWW-Authenticate header field containing at least one challenge.  A
+   server MAY generate a WWW-Authenticate header field in other response
+   messages to indicate that supplying credentials (or different
+   credentials) might affect the response.
+
+   A proxy forwarding a response MUST NOT modify any WWW-Authenticate
+   fields in that response.
+
+   User agents are advised to take special care in parsing the field
+   value, as it might contain more than one challenge, and each
+   challenge can contain a comma-separated list of authentication
+   parameters.  Furthermore, the header field itself can occur multiple
+   times.
+
+   For instance:
+
+     WWW-Authenticate: Newauth realm="apps", type=1,
+                       title="Login to \"apps\"", Basic realm="simple"
+
+   This header field contains two challenges; one for the "Newauth"
+   scheme with a realm value of "apps", and two additional parameters
+   "type" and "title", and another one for the "Basic" scheme with a
+   realm value of "simple".
+
+      Note: The challenge grammar production uses the list syntax as
+      well.  Therefore, a sequence of comma, whitespace, and comma can
+      be considered either as applying to the preceding challenge, or to
+      be an empty entry in the list of challenges.  In practice, this
+      ambiguity does not affect the semantics of the header field value
+      and thus is harmless.
+
+
+
+
+
+
+
+
+Fielding & Reschke           Standards Track                    [Page 7]
+
+RFC 7235                 HTTP/1.1 Authentication               June 2014
+
+
+4.2.  Authorization
+
+   The "Authorization" header field allows a user agent to authenticate
+   itself with an origin server -- usually, but not necessarily, after
+   receiving a 401 (Unauthorized) response.  Its value consists of
+   credentials containing the authentication information of the user
+   agent for the realm of the resource being requested.
+
+     Authorization = credentials
+
+   If a request is authenticated and a realm specified, the same
+   credentials are presumed to be valid for all other requests within
+   this realm (assuming that the authentication scheme itself does not
+   require otherwise, such as credentials that vary according to a
+   challenge value or using synchronized clocks).
+
+   A proxy forwarding a request MUST NOT modify any Authorization fields
+   in that request.  See Section 3.2 of [RFC7234] for details of and
+   requirements pertaining to handling of the Authorization field by
+   HTTP caches.
+
+4.3.  Proxy-Authenticate
+
+   The "Proxy-Authenticate" header field consists of at least one
+   challenge that indicates the authentication scheme(s) and parameters
+   applicable to the proxy for this effective request URI (Section 5.5
+   of [RFC7230]).  A proxy MUST send at least one Proxy-Authenticate
+   header field in each 407 (Proxy Authentication Required) response
+   that it generates.
+
+     Proxy-Authenticate = 1#challenge
+
+   Unlike WWW-Authenticate, the Proxy-Authenticate header field applies
+   only to the next outbound client on the response chain.  This is
+   because only the client that chose a given proxy is likely to have
+   the credentials necessary for authentication.  However, when multiple
+   proxies are used within the same administrative domain, such as
+   office and regional caching proxies within a large corporate network,
+   it is common for credentials to be generated by the user agent and
+   passed through the hierarchy until consumed.  Hence, in such a
+   configuration, it will appear as if Proxy-Authenticate is being
+   forwarded because each proxy will send the same challenge set.
+
+   Note that the parsing considerations for WWW-Authenticate apply to
+   this header field as well; see Section 4.1 for details.
+
+
+
+
+
+
+Fielding & Reschke           Standards Track                    [Page 8]
+
+RFC 7235                 HTTP/1.1 Authentication               June 2014
+
+
+4.4.  Proxy-Authorization
+
+   The "Proxy-Authorization" header field allows the client to identify
+   itself (or its user) to a proxy that requires authentication.  Its
+   value consists of credentials containing the authentication
+   information of the client for the proxy and/or realm of the resource
+   being requested.
+
+     Proxy-Authorization = credentials
+
+   Unlike Authorization, the Proxy-Authorization header field applies
+   only to the next inbound proxy that demanded authentication using the
+   Proxy-Authenticate field.  When multiple proxies are used in a chain,
+   the Proxy-Authorization header field is consumed by the first inbound
+   proxy that was expecting to receive credentials.  A proxy MAY relay
+   the credentials from the client request to the next proxy if that is
+   the mechanism by which the proxies cooperatively authenticate a given
+   request.
+
+5.  IANA Considerations
+
+5.1.  Authentication Scheme Registry
+
+   The "Hypertext Transfer Protocol (HTTP) Authentication Scheme
+   Registry" defines the namespace for the authentication schemes in
+   challenges and credentials.  It has been created and is now
+   maintained at <http://www.iana.org/assignments/http-authschemes>.
+
+5.1.1.  Procedure
+
+   Registrations MUST include the following fields:
+
+   o  Authentication Scheme Name
+
+   o  Pointer to specification text
+
+   o  Notes (optional)
+
+   Values to be added to this namespace require IETF Review (see
+   [RFC5226], Section 4.1).
+
+
+
+
+
+
+
+
+
+
+
+Fielding & Reschke           Standards Track                    [Page 9]
+
+RFC 7235                 HTTP/1.1 Authentication               June 2014
+
+
+5.1.2.  Considerations for New Authentication Schemes
+
+   There are certain aspects of the HTTP Authentication Framework that
+   put constraints on how new authentication schemes can work:
+
+   o  HTTP authentication is presumed to be stateless: all of the
+      information necessary to authenticate a request MUST be provided
+      in the request, rather than be dependent on the server remembering
+      prior requests.  Authentication based on, or bound to, the
+      underlying connection is outside the scope of this specification
+      and inherently flawed unless steps are taken to ensure that the
+      connection cannot be used by any party other than the
+      authenticated user (see Section 2.3 of [RFC7230]).
+
+   o  The authentication parameter "realm" is reserved for defining
+      protection spaces as described in Section 2.2.  New schemes MUST
+      NOT use it in a way incompatible with that definition.
+
+   o  The "token68" notation was introduced for compatibility with
+      existing authentication schemes and can only be used once per
+      challenge or credential.  Thus, new schemes ought to use the
+      auth-param syntax instead, because otherwise future extensions
+      will be impossible.
+
+   o  The parsing of challenges and credentials is defined by this
+      specification and cannot be modified by new authentication
+      schemes.  When the auth-param syntax is used, all parameters ought
+      to support both token and quoted-string syntax, and syntactical
+      constraints ought to be defined on the field value after parsing
+      (i.e., quoted-string processing).  This is necessary so that
+      recipients can use a generic parser that applies to all
+      authentication schemes.
+
+      Note: The fact that the value syntax for the "realm" parameter is
+      restricted to quoted-string was a bad design choice not to be
+      repeated for new parameters.
+
+   o  Definitions of new schemes ought to define the treatment of
+      unknown extension parameters.  In general, a "must-ignore" rule is
+      preferable to a "must-understand" rule, because otherwise it will
+      be hard to introduce new parameters in the presence of legacy
+      recipients.  Furthermore, it's good to describe the policy for
+      defining new parameters (such as "update the specification" or
+      "use this registry").
+
+   o  Authentication schemes need to document whether they are usable in
+      origin-server authentication (i.e., using WWW-Authenticate),
+      and/or proxy authentication (i.e., using Proxy-Authenticate).
+
+
+
+Fielding & Reschke           Standards Track                   [Page 10]
+
+RFC 7235                 HTTP/1.1 Authentication               June 2014
+
+
+   o  The credentials carried in an Authorization header field are
+      specific to the user agent and, therefore, have the same effect on
+      HTTP caches as the "private" Cache-Control response directive
+      (Section 5.2.2.6 of [RFC7234]), within the scope of the request in
+      which they appear.
+
+      Therefore, new authentication schemes that choose not to carry
+      credentials in the Authorization header field (e.g., using a newly
+      defined header field) will need to explicitly disallow caching, by
+      mandating the use of either Cache-Control request directives
+      (e.g., "no-store", Section 5.2.1.5 of [RFC7234]) or response
+      directives (e.g., "private").
+
+5.2.  Status Code Registration
+
+   The "Hypertext Transfer Protocol (HTTP) Status Code Registry" located
+   at <http://www.iana.org/assignments/http-status-codes> has been
+   updated with the registrations below:
+
+   +-------+-------------------------------+-------------+
+   | Value | Description                   | Reference   |
+   +-------+-------------------------------+-------------+
+   | 401   | Unauthorized                  | Section 3.1 |
+   | 407   | Proxy Authentication Required | Section 3.2 |
+   +-------+-------------------------------+-------------+
+
+5.3.  Header Field Registration
+
+   HTTP header fields are registered within the "Message Headers"
+   registry maintained at
+   <http://www.iana.org/assignments/message-headers/>.
+
+   This document defines the following HTTP header fields, so the
+   "Permanent Message Header Field Names" registry has been updated
+   accordingly (see [BCP90]).
+
+   +---------------------+----------+----------+-------------+
+   | Header Field Name   | Protocol | Status   | Reference   |
+   +---------------------+----------+----------+-------------+
+   | Authorization       | http     | standard | Section 4.2 |
+   | Proxy-Authenticate  | http     | standard | Section 4.3 |
+   | Proxy-Authorization | http     | standard | Section 4.4 |
+   | WWW-Authenticate    | http     | standard | Section 4.1 |
+   +---------------------+----------+----------+-------------+
+
+   The change controller is: "IETF (iesg@ietf.org) - Internet
+   Engineering Task Force".
+
+
+
+
+Fielding & Reschke           Standards Track                   [Page 11]
+
+RFC 7235                 HTTP/1.1 Authentication               June 2014
+
+
+6.  Security Considerations
+
+   This section is meant to inform developers, information providers,
+   and users of known security concerns specific to HTTP authentication.
+   More general security considerations are addressed in HTTP messaging
+   [RFC7230] and semantics [RFC7231].
+
+   Everything about the topic of HTTP authentication is a security
+   consideration, so the list of considerations below is not exhaustive.
+   Furthermore, it is limited to security considerations regarding the
+   authentication framework, in general, rather than discussing all of
+   the potential considerations for specific authentication schemes
+   (which ought to be documented in the specifications that define those
+   schemes).  Various organizations maintain topical information and
+   links to current research on Web application security (e.g.,
+   [OWASP]), including common pitfalls for implementing and using the
+   authentication schemes found in practice.
+
+6.1.  Confidentiality of Credentials
+
+   The HTTP authentication framework does not define a single mechanism
+   for maintaining the confidentiality of credentials; instead, each
+   authentication scheme defines how the credentials are encoded prior
+   to transmission.  While this provides flexibility for the development
+   of future authentication schemes, it is inadequate for the protection
+   of existing schemes that provide no confidentiality on their own, or
+   that do not sufficiently protect against replay attacks.
+   Furthermore, if the server expects credentials that are specific to
+   each individual user, the exchange of those credentials will have the
+   effect of identifying that user even if the content within
+   credentials remains confidential.
+
+   HTTP depends on the security properties of the underlying transport-
+   or session-level connection to provide confidential transmission of
+   header fields.  In other words, if a server limits access to
+   authenticated users using this framework, the server needs to ensure
+   that the connection is properly secured in accordance with the nature
+   of the authentication scheme used.  For example, services that depend
+   on individual user authentication often require a connection to be
+   secured with TLS ("Transport Layer Security", [RFC5246]) prior to
+   exchanging any credentials.
+
+6.2.  Authentication Credentials and Idle Clients
+
+   Existing HTTP clients and user agents typically retain authentication
+   information indefinitely.  HTTP does not provide a mechanism for the
+   origin server to direct clients to discard these cached credentials,
+   since the protocol has no awareness of how credentials are obtained
+
+
+
+Fielding & Reschke           Standards Track                   [Page 12]
+
+RFC 7235                 HTTP/1.1 Authentication               June 2014
+
+
+   or managed by the user agent.  The mechanisms for expiring or
+   revoking credentials can be specified as part of an authentication
+   scheme definition.
+
+   Circumstances under which credential caching can interfere with the
+   application's security model include but are not limited to:
+
+   o  Clients that have been idle for an extended period, following
+      which the server might wish to cause the client to re-prompt the
+      user for credentials.
+
+   o  Applications that include a session termination indication (such
+      as a "logout" or "commit" button on a page) after which the server
+      side of the application "knows" that there is no further reason
+      for the client to retain the credentials.
+
+   User agents that cache credentials are encouraged to provide a
+   readily accessible mechanism for discarding cached credentials under
+   user control.
+
+6.3.  Protection Spaces
+
+   Authentication schemes that solely rely on the "realm" mechanism for
+   establishing a protection space will expose credentials to all
+   resources on an origin server.  Clients that have successfully made
+   authenticated requests with a resource can use the same
+   authentication credentials for other resources on the same origin
+   server.  This makes it possible for a different resource to harvest
+   authentication credentials for other resources.
+
+   This is of particular concern when an origin server hosts resources
+   for multiple parties under the same canonical root URI (Section 2.2).
+   Possible mitigation strategies include restricting direct access to
+   authentication credentials (i.e., not making the content of the
+   Authorization request header field available), and separating
+   protection spaces by using a different host name (or port number) for
+   each party.
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+Fielding & Reschke           Standards Track                   [Page 13]
+
+RFC 7235                 HTTP/1.1 Authentication               June 2014
+
+
+7.  Acknowledgments
+
+   This specification takes over the definition of the HTTP
+   Authentication Framework, previously defined in RFC 2617.  We thank
+   John Franks, Phillip M. Hallam-Baker, Jeffery L. Hostetler, Scott D.
+   Lawrence, Paul J. Leach, Ari Luotonen, and Lawrence C. Stewart for
+   their work on that specification.  See Section 6 of [RFC2617] for
+   further acknowledgements.
+
+   See Section 10 of [RFC7230] for the Acknowledgments related to this
+   document revision.
+
+8.  References
+
+8.1.  Normative References
+
+   [RFC2119]  Bradner, S., "Key words for use in RFCs to Indicate
+              Requirement Levels", BCP 14, RFC 2119, March 1997.
+
+   [RFC5234]  Crocker, D., Ed. and P. Overell, "Augmented BNF for Syntax
+              Specifications: ABNF", STD 68, RFC 5234, January 2008.
+
+   [RFC7230]  Fielding, R., Ed. and J. Reschke, Ed., "Hypertext Transfer
+              Protocol (HTTP/1.1): Message Syntax and Routing",
+              RFC 7230, June 2014.
+
+   [RFC7231]  Fielding, R., Ed. and J. Reschke, Ed., "Hypertext Transfer
+              Protocol (HTTP/1.1): Semantics and Content", RFC 7231,
+              June 2014.
+
+   [RFC7234]  Fielding, R., Ed., Nottingham, M., Ed., and J. Reschke,
+              Ed., "Hypertext Transfer Protocol (HTTP/1.1): Caching",
+              RFC 7234, June 2014.
+
+8.2.  Informative References
+
+   [BCP90]    Klyne, G., Nottingham, M., and J. Mogul, "Registration
+              Procedures for Message Header Fields", BCP 90, RFC 3864,
+              September 2004.
+
+   [OWASP]    van der Stock, A., Ed., "A Guide to Building Secure Web
+              Applications and Web Services", The Open Web Application
+              Security Project (OWASP) 2.0.1, July 2005,
+              <https://www.owasp.org/>.
+
+   [RFC2616]  Fielding, R., Gettys, J., Mogul, J., Frystyk, H.,
+              Masinter, L., Leach, P., and T. Berners-Lee, "Hypertext
+              Transfer Protocol -- HTTP/1.1", RFC 2616, June 1999.
+
+
+
+Fielding & Reschke           Standards Track                   [Page 14]
+
+RFC 7235                 HTTP/1.1 Authentication               June 2014
+
+
+   [RFC2617]  Franks, J., Hallam-Baker, P., Hostetler, J., Lawrence, S.,
+              Leach, P., Luotonen, A., and L. Stewart, "HTTP
+              Authentication: Basic and Digest Access Authentication",
+              RFC 2617, June 1999.
+
+   [RFC3986]  Berners-Lee, T., Fielding, R., and L. Masinter, "Uniform
+              Resource Identifier (URI): Generic Syntax", STD 66,
+              RFC 3986, January 2005.
+
+   [RFC4648]  Josefsson, S., "The Base16, Base32, and Base64 Data
+              Encodings", RFC 4648, October 2006.
+
+   [RFC5226]  Narten, T. and H. Alvestrand, "Guidelines for Writing an
+              IANA Considerations Section in RFCs", BCP 26, RFC 5226,
+              May 2008.
+
+   [RFC5246]  Dierks, T. and E. Rescorla, "The Transport Layer Security
+              (TLS) Protocol Version 1.2", RFC 5246, August 2008.
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+Fielding & Reschke           Standards Track                   [Page 15]
+
+RFC 7235                 HTTP/1.1 Authentication               June 2014
+
+
+Appendix A.  Changes from RFCs 2616 and 2617
+
+   The framework for HTTP Authentication is now defined by this
+   document, rather than RFC 2617.
+
+   The "realm" parameter is no longer always required on challenges;
+   consequently, the ABNF allows challenges without any auth parameters.
+   (Section 2)
+
+   The "token68" alternative to auth-param lists has been added for
+   consistency with legacy authentication schemes such as "Basic".
+   (Section 2)
+
+   This specification introduces the Authentication Scheme Registry,
+   along with considerations for new authentication schemes.
+   (Section 5.1)
+
+Appendix B.  Imported ABNF
+
+   The following core rules are included by reference, as defined in
+   Appendix B.1 of [RFC5234]: ALPHA (letters), CR (carriage return),
+   CRLF (CR LF), CTL (controls), DIGIT (decimal 0-9), DQUOTE (double
+   quote), HEXDIG (hexadecimal 0-9/A-F/a-f), LF (line feed), OCTET (any
+   8-bit sequence of data), SP (space), and VCHAR (any visible US-ASCII
+   character).
+
+   The rules below are defined in [RFC7230]:
+
+     BWS           = <BWS, see [RFC7230], Section 3.2.3>
+     OWS           = <OWS, see [RFC7230], Section 3.2.3>
+     quoted-string = <quoted-string, see [RFC7230], Section 3.2.6>
+     token         = <token, see [RFC7230], Section 3.2.6>
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+Fielding & Reschke           Standards Track                   [Page 16]
+
+RFC 7235                 HTTP/1.1 Authentication               June 2014
+
+
+Appendix C.  Collected ABNF
+
+   In the collected ABNF below, list rules are expanded as per Section
+   1.2 of [RFC7230].
+
+   Authorization = credentials
+
+   BWS = <BWS, see [RFC7230], Section 3.2.3>
+
+   OWS = <OWS, see [RFC7230], Section 3.2.3>
+
+   Proxy-Authenticate = *( "," OWS ) challenge *( OWS "," [ OWS
+    challenge ] )
+   Proxy-Authorization = credentials
+
+   WWW-Authenticate = *( "," OWS ) challenge *( OWS "," [ OWS challenge
+    ] )
+
+   auth-param = token BWS "=" BWS ( token / quoted-string )
+   auth-scheme = token
+
+   challenge = auth-scheme [ 1*SP ( token68 / [ ( "," / auth-param ) *(
+    OWS "," [ OWS auth-param ] ) ] ) ]
+   credentials = auth-scheme [ 1*SP ( token68 / [ ( "," / auth-param )
+    *( OWS "," [ OWS auth-param ] ) ] ) ]
+
+   quoted-string = <quoted-string, see [RFC7230], Section 3.2.6>
+
+   token = <token, see [RFC7230], Section 3.2.6>
+   token68 = 1*( ALPHA / DIGIT / "-" / "." / "_" / "~" / "+" / "/" )
+    *"="
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+Fielding & Reschke           Standards Track                   [Page 17]
+
+RFC 7235                 HTTP/1.1 Authentication               June 2014
+
+
+Index
+
+   4
+      401 Unauthorized (status code)  6
+      407 Proxy Authentication Required (status code)  6
+
+   A
+      Authorization header field  8
+
+   C
+      Canonical Root URI  5
+
+   G
+      Grammar
+         auth-param  4
+         auth-scheme  4
+         Authorization  8
+         challenge  4
+         credentials  5
+         Proxy-Authenticate  8
+         Proxy-Authorization  9
+         token68  4
+         WWW-Authenticate  7
+
+   P
+      Protection Space  5
+      Proxy-Authenticate header field  8
+      Proxy-Authorization header field  9
+
+   R
+      Realm  5
+
+   W
+      WWW-Authenticate header field  7
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+Fielding & Reschke           Standards Track                   [Page 18]
+
+RFC 7235                 HTTP/1.1 Authentication               June 2014
+
+
+Authors' Addresses
+
+   Roy T. Fielding (editor)
+   Adobe Systems Incorporated
+   345 Park Ave
+   San Jose, CA  95110
+   USA
+
+   EMail: fielding@gbiv.com
+   URI:   http://roy.gbiv.com/
+
+
+   Julian F. Reschke (editor)
+   greenbytes GmbH
+   Hafenweg 16
+   Muenster, NW  48155
+   Germany
+
+   EMail: julian.reschke@greenbytes.de
+   URI:   http://greenbytes.de/tech/webdav/
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+Fielding & Reschke           Standards Track                   [Page 19]
+
@@ -0,0 +1,339 @@
+
+
+
+
+
+
+Internet Engineering Task Force (IETF)                        J. Reschke
+Request for Comments: 7238                                    greenbytes
+Category: Experimental                                         June 2014
+ISSN: 2070-1721
+
+
+  The Hypertext Transfer Protocol Status Code 308 (Permanent Redirect)
+
+Abstract
+
+   This document specifies the additional Hypertext Transfer Protocol
+   (HTTP) status code 308 (Permanent Redirect).
+
+Status of This Memo
+
+   This document is not an Internet Standards Track specification; it is
+   published for examination, experimental implementation, and
+   evaluation.
+
+   This document defines an Experimental Protocol for the Internet
+   community.  This document is a product of the Internet Engineering
+   Task Force (IETF).  It represents the consensus of the IETF
+   community.  It has received public review and has been approved for
+   publication by the Internet Engineering Steering Group (IESG).  Not
+   all documents approved by the IESG are a candidate for any level of
+   Internet Standard; see Section 2 of RFC 5741.
+
+   Information about the current status of this document, any errata,
+   and how to provide feedback on it may be obtained at
+   http://www.rfc-editor.org/info/rfc7238.
+
+Copyright Notice
+
+   Copyright (c) 2014 IETF Trust and the persons identified as the
+   document authors.  All rights reserved.
+
+   This document is subject to BCP 78 and the IETF Trust's Legal
+   Provisions Relating to IETF Documents
+   (http://trustee.ietf.org/license-info) in effect on the date of
+   publication of this document.  Please review these documents
+   carefully, as they describe your rights and restrictions with respect
+   to this document.  Code Components extracted from this document must
+   include Simplified BSD License text as described in Section 4.e of
+   the Trust Legal Provisions and are provided without warranty as
+   described in the Simplified BSD License.
+
+
+
+
+
+
+Reschke                       Experimental                      [Page 1]
+
+RFC 7238                  HTTP Status Code 308                 June 2014
+
+
+Table of Contents
+
+   1.  Introduction  . . . . . . . . . . . . . . . . . . . . . . . . . 2
+   2.  Notational Conventions  . . . . . . . . . . . . . . . . . . . . 2
+   3.  308 Permanent Redirect  . . . . . . . . . . . . . . . . . . . . 2
+   4.  Deployment Considerations . . . . . . . . . . . . . . . . . . . 3
+   5.  Security Considerations . . . . . . . . . . . . . . . . . . . . 4
+   6.  IANA Considerations . . . . . . . . . . . . . . . . . . . . . . 4
+   7.  Acknowledgements  . . . . . . . . . . . . . . . . . . . . . . . 5
+   8.  References  . . . . . . . . . . . . . . . . . . . . . . . . . . 5
+     8.1.  Normative References  . . . . . . . . . . . . . . . . . . . 5
+     8.2.  Informative References  . . . . . . . . . . . . . . . . . . 5
+
+1.  Introduction
+
+   HTTP defines a set of status codes for the purpose of redirecting a
+   request to a different URI ([RFC3986]).  The history of these status
+   codes is summarized in Section 6.4 of [RFC7231], which also
+   classifies the existing status codes into four categories.
+
+   The first of these categories contains the status codes 301 (Moved
+   Permanently), 302 (Found), and 307 (Temporary Redirect), which can be
+   classified as below:
+
+   +-------------------------------------------+-----------+-----------+
+   |                                           | Permanent | Temporary |
+   +-------------------------------------------+-----------+-----------+
+   | Allows changing the request method from   | 301       | 302       |
+   | POST to GET                               |           |           |
+   | Does not allow changing the request       | -         | 307       |
+   | method from POST to GET                   |           |           |
+   +-------------------------------------------+-----------+-----------+
+
+   Section 6.4.7 of [RFC7231] states that HTTP does not define a
+   permanent variant of status code 307; this specification adds the
+   status code 308, defining this missing variant (Section 3).
+
+2.  Notational Conventions
+
+   The key words "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT",
+   "SHOULD", "SHOULD NOT", "RECOMMENDED", "MAY", and "OPTIONAL" in this
+   document are to be interpreted as described in [RFC2119].
+
+3.  308 Permanent Redirect
+
+   The 308 (Permanent Redirect) status code indicates that the target
+   resource has been assigned a new permanent URI and any future
+   references to this resource ought to use one of the enclosed URIs.
+
+
+
+Reschke                       Experimental                      [Page 2]
+
+RFC 7238                  HTTP Status Code 308                 June 2014
+
+
+   Clients with link editing capabilities ought to automatically re-link
+   references to the effective request URI (Section 5.5 of [RFC7230]) to
+   one or more of the new references sent by the server, where possible.
+
+   The server SHOULD generate a Location header field ([RFC7231],
+   Section 7.1.2) in the response containing a preferred URI reference
+   for the new permanent URI.  The user agent MAY use the Location field
+   value for automatic redirection.  The server's response payload
+   usually contains a short hypertext note with a hyperlink to the new
+   URI(s).
+
+   A 308 response is cacheable by default; i.e., unless otherwise
+   indicated by the method definition or explicit cache controls (see
+   [RFC7234], Section 4.2.2).
+
+      Note: This status code is similar to 301 (Moved Permanently)
+      ([RFC7231], Section 6.4.2), except that it does not allow changing
+      the request method from POST to GET.
+
+4.  Deployment Considerations
+
+   Section 6 of [RFC7231] requires recipients to treat unknown 3xx
+   status codes the same way as status code 300 Multiple Choices
+   ([RFC7231], Section 6.4.1).  Thus, servers will not be able to rely
+   on automatic redirection happening similar to status codes 301, 302,
+   or 307.
+
+   Therefore, initial use of status code 308 will be restricted to cases
+   where the server has sufficient confidence in the client's
+   understanding the new code or when a fallback to the semantics of
+   status code 300 is not problematic.  Server implementers are advised
+   not to vary the status code based on characteristics of the request,
+   such as the User-Agent header field ("User-Agent Sniffing") -- doing
+   so usually results in code that is both hard to maintain and hard to
+   debug and would also require special attention to caching (i.e.,
+   setting a "Vary" response header field, as defined in Section 7.1.4
+   of [RFC7231]).
+
+   Note that many existing HTML-based user agents will emulate a refresh
+   when encountering an HTML <meta> refresh directive ([HTML]).  This
+   can be used as another fallback.  For example:
+
+   Client request:
+
+     GET / HTTP/1.1
+     Host: example.com
+
+
+
+
+
+Reschke                       Experimental                      [Page 3]
+
+RFC 7238                  HTTP Status Code 308                 June 2014
+
+
+   Server response:
+
+     HTTP/1.1 308 Permanent Redirect
+     Content-Type: text/html; charset=UTF-8
+     Location: http://example.com/new
+     Content-Length: 454
+
+     <!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
+                           "http://www.w3.org/TR/html4/strict.dtd">
+     <html>
+        <head>
+           <title>Permanent Redirect</title>
+           <meta http-equiv="refresh"
+                 content="0; url=http://example.com/new">
+        </head>
+        <body>
+           <p>
+              The document has been moved to
+              <a href="http://example.com/new"
+              >http://example.com/new</a>.
+           </p>
+        </body>
+     </html>
+
+5.  Security Considerations
+
+   All security considerations that apply to HTTP redirects apply to the
+   308 status code as well (see Section 9 of [RFC7231]).
+
+6.  IANA Considerations
+
+   The registration below has been added to the "Hypertext Transfer
+   Protocol (HTTP) Status Code Registry" (defined in Section 8.2 of
+   [RFC7231] and located at
+   <http://www.iana.org/assignments/http-status-codes>):
+
+   +-------+--------------------+---------------------------------+
+   | Value | Description        | Reference                       |
+   +-------+--------------------+---------------------------------+
+   | 308   | Permanent Redirect | Section 3 of this specification |
+   +-------+--------------------+---------------------------------+
+
+
+
+
+
+
+
+
+
+
+Reschke                       Experimental                      [Page 4]
+
+RFC 7238                  HTTP Status Code 308                 June 2014
+
+
+7.  Acknowledgements
+
+   The definition for the new status code 308 reuses text from the
+   HTTP/1.1 definitions of status codes 301 and 307.
+
+   Furthermore, thanks to Ben Campbell, Cyrus Daboo, Eran Hammer-Lahav,
+   Bjoern Hoehrmann, Subramanian Moonesamy, Peter Saint-Andre, and
+   Robert Sparks for feedback on this document.
+
+8.  References
+
+8.1.  Normative References
+
+   [RFC2119]  Bradner, S., "Key words for use in RFCs to Indicate
+              Requirement Levels", BCP 14, RFC 2119, March 1997.
+
+   [RFC3986]  Berners-Lee, T., Fielding, R., and L. Masinter, "Uniform
+              Resource Identifier (URI): Generic Syntax", STD 66,
+              RFC 3986, January 2005.
+
+   [RFC7230]  Fielding, R., Ed. and J. Reschke, Ed., "Hypertext Transfer
+              Protocol (HTTP/1.1): Message Syntax and Routing",
+              RFC 7230, June 2014.
+
+   [RFC7231]  Fielding, R., Ed. and J. Reschke, Ed., "Hypertext Transfer
+              Protocol (HTTP/1.1): Semantics and Content", RFC 7231,
+              June 2014.
+
+   [RFC7234]  Fielding, R., Ed., Nottingham, M., Ed., and J. Reschke,
+              Ed., "Hypertext Transfer Protocol (HTTP/1.1): Caching",
+              RFC 7234, June 2014.
+
+8.2.  Informative References
+
+   [HTML]     Raggett, D., Le Hors, A., and I. Jacobs, "HTML 4.01
+              Specification", W3C Recommendation REC-html401-19991224,
+              December 1999,
+              <http://www.w3.org/TR/1999/REC-html401-19991224>.
+
+              Latest version available at
+              <http://www.w3.org/TR/html401>.
+
+
+
+
+
+
+
+
+
+
+Reschke                       Experimental                      [Page 5]
+
+RFC 7238                  HTTP Status Code 308                 June 2014
+
+
+Author's Address
+
+   Julian F. Reschke
+   greenbytes GmbH
+   Hafenweg 16
+   Muenster, NW  48155
+   Germany
+
+   EMail: julian.reschke@greenbytes.de
+   URI:   http://greenbytes.de/tech/webdav/
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+Reschke                       Experimental                      [Page 6]
+
@@ -0,0 +1,899 @@
+
+
+
+
+
+
+Internet Engineering Task Force (IETF)                      A. Petersson
+Request for Comments: 7239                                    M. Nilsson
+Category: Standards Track                                 Opera Software
+ISSN: 2070-1721                                                June 2014
+
+
+                        Forwarded HTTP Extension
+
+Abstract
+
+   This document defines an HTTP extension header field that allows
+   proxy components to disclose information lost in the proxying
+   process, for example, the originating IP address of a request or IP
+   address of the proxy on the user-agent-facing interface.  In a path
+   of proxying components, this makes it possible to arrange it so that
+   each subsequent component will have access to, for example, all IP
+   addresses used in the chain of proxied HTTP requests.
+
+   This document also specifies guidelines for a proxy administrator to
+   anonymize the origin of a request.
+
+Status of This Memo
+
+   This is an Internet Standards Track document.
+
+   This document is a product of the Internet Engineering Task Force
+   (IETF).  It represents the consensus of the IETF community.  It has
+   received public review and has been approved for publication by the
+   Internet Engineering Steering Group (IESG).  Further information on
+   Internet Standards is available in Section 2 of RFC 5741.
+
+   Information about the current status of this document, any errata,
+   and how to provide feedback on it may be obtained at
+   http://www.rfc-editor.org/info/rfc7239.
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+Petersson & Nilsson          Standards Track                    [Page 1]
+
+RFC 7239                Forwarded HTTP Extension               June 2014
+
+
+Copyright Notice
+
+   Copyright (c) 2014 IETF Trust and the persons identified as the
+   document authors.  All rights reserved.
+
+   This document is subject to BCP 78 and the IETF Trust's Legal
+   Provisions Relating to IETF Documents
+   (http://trustee.ietf.org/license-info) in effect on the date of
+   publication of this document.  Please review these documents
+   carefully, as they describe your rights and restrictions with respect
+   to this document.  Code Components extracted from this document must
+   include Simplified BSD License text as described in Section 4.e of
+   the Trust Legal Provisions and are provided without warranty as
+   described in the Simplified BSD License.
+
+Table of Contents
+
+   1. Introduction ....................................................3
+   2. Notational Conventions ..........................................4
+   3. Syntax Notations ................................................4
+   4. Forwarded HTTP Header Field .....................................4
+   5. Parameters ......................................................6
+      5.1. Forwarded By ...............................................6
+      5.2. Forwarded For ..............................................6
+      5.3. Forwarded Host .............................................7
+      5.4. Forwarded Proto ............................................7
+      5.5. Extensions .................................................7
+   6. Node Identifiers ................................................8
+      6.1. IPv4 and IPv6 Identifiers ..................................9
+      6.2. The "unknown" Identifier ...................................9
+      6.3. Obfuscated Identifier ......................................9
+   7. Implementation Considerations ..................................10
+      7.1. HTTP Lists ................................................10
+      7.2. Header Field Preservation .................................10
+      7.3. Relation to Via ...........................................10
+      7.4. Transition ................................................11
+      7.5. Example Usage .............................................11
+   8. Security Considerations ........................................12
+      8.1. Header Validity and Integrity .............................12
+      8.2. Information Leak ..........................................12
+      8.3. Privacy Considerations ....................................12
+   9. IANA Considerations ............................................14
+   10. References ....................................................14
+      10.1. Normative References .....................................14
+      10.2. Informative References ...................................15
+   Appendix A. Acknowledgments .......................................16
+
+
+
+
+
+Petersson & Nilsson          Standards Track                    [Page 2]
+
+RFC 7239                Forwarded HTTP Extension               June 2014
+
+
+1.  Introduction
+
+   In today's HTTP landscape, there are a multitude of different
+   applications that act as proxies for the user agents.  In many cases,
+   these proxies exists without the action or knowledge of the end-user.
+   These cases occur, for example, when the proxy exists as a part of
+   the infrastructure within the organization running the web server.
+   Such proxies may be used for features such as load balancing or
+   crypto offload.  Another example is when the proxy is used within the
+   same organization as the user, and the proxy is used to cache
+   resources.  However, these proxies make the requests appear as if
+   they originated from the proxy's IP address, and they may change
+   other information in the original request.  This represents a loss of
+   information from the original request.
+
+   This loss of information can cause problems for a web server that has
+   a specific use for the clients' IP addresses that will not be met by
+   using the address of the proxy or other information changed by the
+   proxy.  The main uses of this information are for diagnostics, access
+   control, and abuse management.  Diagnostic functions can include
+   event logging, troubleshooting, and statistics gathering, and the
+   information collected is usually only stored for short periods of
+   time and only gathered in response to a particular problem or a
+   complaint from the client.  Access control can be operated by
+   configuring a list of client IP addresses from which access is
+   permitted, but this approach will not work if a proxy is used, unless
+   the proxy is trusted and is, itself, configured with a list of
+   allowed client addresses for the server.  Cases of abuse require
+   identification of the abuser and this uses many of the same features
+   identified for diagnostics.
+
+   Most of the time that a proxy is used, this loss of information is
+   not the primary purpose, or even a desired effect, of using the
+   proxy.  Thus, to restore the desired functionality when a proxy is in
+   use, a way of disclosing the original information at the HTTP level
+   is needed.  Clearly, however, when the purpose of using a proxy is to
+   provide client anonymity, the proxy will not use the feature defined
+   in this document.
+
+   It should be noted that the use of a reverse proxy also hides
+   information.  Again, where the loss of information is not a
+   deliberate function of the use of the reverse proxy, it can be
+   desirable to find a way to encode the information within the HTTP
+   messages so that the consumer can see it.
+
+   A common way to disclose this information is by using the non-
+   standard header fields such as X-Forwarded-For, X-Forwarded-By, and
+   X-Forwarded-Proto.  There are many benefits to using a standardized
+
+
+
+Petersson & Nilsson          Standards Track                    [Page 3]
+
+RFC 7239                Forwarded HTTP Extension               June 2014
+
+
+   approach to commonly desired protocol function: not least is
+   interoperability between implementations.  This document standardizes
+   a header field called "Forwarded" and provides the syntax and
+   semantics for disclosing such information.  "Forwarded" also combines
+   all the information within one single header field, making it
+   possible to correlate that information.  With the header field format
+   described in this document, it is possible to know what information
+   belongs together, as long as the proxies are trusted.  Such
+   conclusions are not possible to make with the X-Forwarded class of
+   header fields.  The header field defined in this document is optional
+   such that implementations of proxies that are intended to provide
+   privacy are not required to operate or implement the header field.
+
+   Note that similar issues to those described for proxies also arise
+   with use of NATs.  This is discussed further in [RFC6269].
+
+2.  Notational Conventions
+
+   The key words "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT",
+   "SHOULD", "SHOULD NOT", "RECOMMENDED", "MAY", and "OPTIONAL" in this
+   document are to be interpreted as described in [RFC2119].
+
+3.  Syntax Notations
+
+   This specification uses the Augmented Backus-Naur Form (ABNF)
+   notation of [RFC5234] with the list rule extension defined in Section
+   7 of [RFC7230].
+
+4.  Forwarded HTTP Header Field
+
+   The "Forwarded" HTTP header field is an OPTIONAL header field that,
+   when used, contains a list of parameter-identifier pairs that
+   disclose information that is altered or lost when a proxy is involved
+   in the path of the request.  Due to the sensitive nature of the data
+   passed in this header field (see Sections 8.2 and 8.3), this header
+   field should be turned off by default.  Further, each parameter
+   should be configured individually.  "Forwarded" is only for use in
+   HTTP requests and is not to be used in HTTP responses.  This applies
+   to forwarding proxies, as well as reverse proxies.  Information
+   passed in this header field can be, for example, the source IP
+   address of the request, the IP address of the incoming interface on
+   the proxy, or whether HTTP or HTTPS was used.  If the request is
+   passing through several proxies, each proxy can add a set of
+   parameters; it can also remove previously added "Forwarded" header
+   fields.
+
+
+
+
+
+
+Petersson & Nilsson          Standards Track                    [Page 4]
+
+RFC 7239                Forwarded HTTP Extension               June 2014
+
+
+   The top-level list is represented as a list of HTTP header
+   field-values as defined in Section 3.2 of [RFC7230].  The first
+   element in this list holds information added by the first proxy that
+   implements and uses this header field, and each subsequent element
+   holds information added by each subsequent proxy.  Because this
+   header field is optional, any proxy in the chain may choose not to
+   update this header field.  Each field-value is a semicolon-separated
+   list; this sublist consists of parameter-identifier pairs.
+   Parameter-identifier pairs are grouped together by an equals sign.
+   Each parameter MUST NOT occur more than once per field-value.  The
+   parameter names are case-insensitive.  The header field value can be
+   defined in ABNF syntax as:
+
+       Forwarded   = 1#forwarded-element
+
+       forwarded-element =
+           [ forwarded-pair ] *( ";" [ forwarded-pair ] )
+
+       forwarded-pair = token "=" value
+       value          = token / quoted-string
+
+       token = <Defined in [RFC7230], Section 3.2.6>
+       quoted-string = <Defined in [RFC7230], Section 3.2.6>
+
+   Examples:
+
+       Forwarded: for="_gazonk"
+       Forwarded: For="[2001:db8:cafe::17]:4711"
+       Forwarded: for=192.0.2.60;proto=http;by=203.0.113.43
+       Forwarded: for=192.0.2.43, for=198.51.100.17
+
+   Note that as ":" and "[]" are not valid characters in "token", IPv6
+   addresses are written as "quoted-string".
+
+   A proxy server that wants to add a new "Forwarded" header field value
+   can either append it to the last existing "Forwarded" header field
+   after a comma separator or add a new field at the end of the header
+   block.  A proxy MAY remove all "Forwarded" header fields from a
+   request.  It MUST, however, ensure that the correct header field is
+   updated in case of multiple "Forwarded" header fields.
+
+
+
+
+
+
+
+
+
+
+
+Petersson & Nilsson          Standards Track                    [Page 5]
+
+RFC 7239                Forwarded HTTP Extension               June 2014
+
+
+5.  Parameters
+
+   This document specifies a number of parameters and valid values for
+   each of them:
+
+   o  "by" identifies the user-agent facing interface of the proxy.
+
+   o  "for" identifies the node making the request to the proxy.
+
+   o  "host" is the host request header field as received by the proxy.
+
+   o  "proto" indicates what protocol was used to make the request.
+
+5.1.  Forwarded By
+
+   The "by" parameter is used to disclose the interface where the
+   request came in to the proxy server.  When proxies choose to use the
+   "by" parameter, its default configuration SHOULD contain an
+   obfuscated identifier as described in Section 6.3.  If the server
+   receiving proxied requests requires some address-based functionality,
+   this parameter MAY instead contain an IP address (and, potentially, a
+   port number).  A third option is the "unknown" identifier described
+   in Section 6.2.
+
+   The syntax of a "by" value, after potential quoted-string unescaping,
+   conforms to the "node" ABNF described in Section 6.
+
+   This is primarily added by reverse proxies that wish to forward this
+   information to the backend server.  It can also be interesting in a
+   multihomed environment to signal to backend servers from which the
+   request came.
+
+5.2.  Forwarded For
+
+   The "for" parameter is used to disclose information about the client
+   that initiated the request and subsequent proxies in a chain of
+   proxies.  When proxies choose to use the "for" parameter, its default
+   configuration SHOULD contain an obfuscated identifier as described in
+   Section 6.3.  If the server receiving proxied requests requires some
+   address-based functionality, this parameter MAY instead contain an IP
+   address (and, potentially, a port number).  A third option is the
+   "unknown" identifier described in Section 6.2.
+
+   The syntax of a "for" value, after potential quoted-string
+   unescaping, conforms to the "node" ABNF described in Section 6.
+
+
+
+
+
+
+Petersson & Nilsson          Standards Track                    [Page 6]
+
+RFC 7239                Forwarded HTTP Extension               June 2014
+
+
+   In a chain of proxy servers where this is fully utilized, the first
+   "for" parameter will disclose the client where the request was first
+   made, followed by any subsequent proxy identifiers.  The last proxy
+   in the chain is not part of the list of "for" parameters.  The last
+   proxy's IP address, and optionally a port number, are, however,
+   readily available as the remote IP address at the transport layer.
+   It can, however, be more relevant to read information about the last
+   proxy from preceding "Forwarded" header field's "by" parameter, if
+   present.
+
+5.3.  Forwarded Host
+
+   The "host" parameter is used to forward the original value of the
+   "Host" header field.  This can be used, for example, by the origin
+   server if a reverse proxy is rewriting the "Host" header field to
+   some internal host name.
+
+   The syntax for a "host" value, after potential quoted-string
+   unescaping, MUST conform to the Host ABNF described in Section 5.4 of
+   [RFC7230].
+
+5.4.  Forwarded Proto
+
+   The "proto" parameter has the value of the used protocol type.  The
+   syntax of a "proto" value, after potential quoted-string unescaping,
+   MUST conform to the URI scheme name as defined in Section 3.1 in
+   [RFC3986] and registered with IANA according to [RFC4395].  Typical
+   values are "http" or "https".
+
+   For example, in an environment where a reverse proxy is also used as
+   a crypto offloader, this allows the origin server to rewrite URLs in
+   a document to match the type of connection as the user agent
+   requested, even though all connections to the origin server are
+   unencrypted HTTP.
+
+5.5.  Extensions
+
+   Extensions allow for additional parameters and values.  Extensions
+   can be particularly useful in reverse proxy environments.  All
+   extension parameters SHOULD be registered in the "HTTP Forwarded
+   Parameter" registry.  If certain extensions are expected to have
+   widespread deployment, they SHOULD also be standardized.  This is
+   further discussed in Section 9.
+
+
+
+
+
+
+
+
+Petersson & Nilsson          Standards Track                    [Page 7]
+
+RFC 7239                Forwarded HTTP Extension               June 2014
+
+
+6.  Node Identifiers
+
+   The node identifier is one of the following:
+
+   o  The client's IP address, with an optional port number
+
+   o  A token indicating that the IP address of the client is not known
+      to the proxy server
+
+   o  A generated token, allowing for tracing and debugging, while
+      allowing the internal structure or sensitive information to be
+      hidden
+
+   The node identifier is defined by the ABNF syntax as:
+
+       node     = nodename [ ":" node-port ]
+       nodename = IPv4address / "[" IPv6address "]" /
+                   "unknown" / obfnode
+
+       IPv4address = <Defined in [RFC3986], Section 3.2.2>
+       IPv6address = <Defined in [RFC3986], Section 3.2.2>
+       obfnode = "_" 1*( ALPHA / DIGIT / "." / "_" / "-")
+
+       node-port     = port / obfport
+       port          = 1*5DIGIT
+       obfport       = "_" 1*(ALPHA / DIGIT / "." / "_" / "-")
+
+       DIGIT = <Defined in [RFC5234], Section 3.4>
+       ALPHA = <Defined in [RFC5234], Section B.1>
+
+   Each of the identifiers may optionally have the port identifier, for
+   example, allowing the identification of the endpoint in a NATed
+   environment.  The "node-port" can be identified either by its port
+   number or by a generated token obfuscating the real port number.  An
+   obfuscated port may be used in situations where the possessor of the
+   proxy wants the ability to trace requests -- for example, in debug
+   purposes -- but does not want to reveal internal information.
+
+   Note that the ABNF above also allows port numbers to be appended to
+   the "unknown" identifier.  Interpretation of such notation is,
+   however, left to the possessor of a proxy adding such a value to the
+   header field.  To distinguish an "obfport" from a port, the "obfport"
+   MUST have a leading underscore.  Further, it MUST also consist of
+   only "ALPHA", "DIGIT", and the characters ".", "_", and "-".
+
+   It is important to note that an IPv6 address and any nodename with
+   node-port specified MUST be quoted, since ":" is not an allowed
+   character in "token".
+
+
+
+Petersson & Nilsson          Standards Track                    [Page 8]
+
+RFC 7239                Forwarded HTTP Extension               June 2014
+
+
+   Examples:
+
+             "192.0.2.43:47011"
+             "[2001:db8:cafe::17]:47011"
+
+6.1.  IPv4 and IPv6 Identifiers
+
+   The ABNF rules for "IPv6address" and "IPv4address" are defined in
+   [RFC3986].  The "IPv6address" SHOULD comply with textual
+   representation recommendations [RFC5952] (for example, lowercase,
+   compression of zeros).
+
+   Note that the IP address may be one from the internal nets, as
+   defined in [RFC1918] and [RFC4193].  Also, note that an IPv6 address
+   is always enclosed in square brackets.
+
+6.2.  The "unknown" Identifier
+
+   The "unknown" identifier is used when the identity of the preceding
+   entity is not known, but the proxy server still wants to signal that
+   a forwarding of the request was made.  One example would be a proxy
+   server process generating an outgoing request without direct access
+   to the incoming request TCP socket.
+
+6.3.  Obfuscated Identifier
+
+   A generated identifier may be used where there is a wish to keep the
+   internal IP addresses secret, while still allowing the "Forwarded"
+   header field to be used for tracing and debugging.  This can also be
+   useful if the proxy uses some sort of interface labels and there is a
+   desire to pass them rather than an IP address.  Unless static
+   assignment of identifiers is necessary for the server's use of the
+   identifiers, obfuscated identifiers SHOULD be randomly generated for
+   each request.  If the server requires that identifiers persist across
+   requests, they SHOULD NOT persist longer than client IP addresses.
+   To distinguish the obfuscated identifier from other identifiers, it
+   MUST have a leading underscore "_".  Furthermore, it MUST also
+   consist of only "ALPHA", "DIGIT", and the characters ".", "_", and
+   "-".
+   Example:
+
+       Forwarded: for=_hidden, for=_SEVKISEK
+
+
+
+
+
+
+
+
+
+Petersson & Nilsson          Standards Track                    [Page 9]
+
+RFC 7239                Forwarded HTTP Extension               June 2014
+
+
+7.  Implementation Considerations
+
+7.1.  HTTP Lists
+
+   Note that an HTTP list allows white spaces to occur between the
+   identifiers, and the list may be split over multiple header fields.
+   As an example, the header field
+
+       Forwarded: for=192.0.2.43,for="[2001:db8:cafe::17]",for=unknown
+
+   is equivalent to the header field
+
+       Forwarded: for=192.0.2.43, for="[2001:db8:cafe::17]", for=unknown
+
+   which is equivalent to the header fields
+
+       Forwarded: for=192.0.2.43
+       Forwarded: for="[2001:db8:cafe::17]", for=unknown
+
+7.2.  Header Field Preservation
+
+   There are some cases when this header field should be kept and some
+   cases where it should not be kept.  A directly forwarded request
+   should preserve and possibly extend it.  If a single incoming request
+   causes the proxy to make multiple outbound requests, special care
+   must be taken to decide whether or not the header field should be
+   preserved.  In many cases, the header field should be preserved, but
+   if the outbound request is not a direct consequence of the incoming
+   request, the header field should not be preserved.  Consider also the
+   case when a proxy has detected a content mismatch in a 304 response
+   and is following the instructions in [RFC7232], Section 4.1 to repeat
+   the request unconditionally, in which case the new request is still
+   basically a direct consequence of the origin request, and the header
+   field should probably be kept.
+
+7.3.  Relation to Via
+
+   The "Via" header field (see [RFC7230], Section 5.7.1) is a header
+   field with a similar use case as this header field.  The "Via" header
+   field, however, only provides information about the proxy itself, and
+   thereby leaves out the information about the client connecting to the
+   proxy server.  The "Forwarded" header field, on the other hand, has
+   relaying information from the client-facing side of the proxy server
+   as its main purpose.  As "Via" is already widely deployed, its format
+   cannot be changed to address the problems that "Forwarded" addresses.
+
+
+
+
+
+
+Petersson & Nilsson          Standards Track                   [Page 10]
+
+RFC 7239                Forwarded HTTP Extension               June 2014
+
+
+   Note that it is not possible to combine information from this header
+   field with the information from the Via header field.  Some proxies
+   will not update the "Forwarded" header field, some proxies will not
+   update the Via header field, and some proxies will update both.
+
+7.4.  Transition
+
+   If a proxy gets incoming requests with X-Forwarded-* header fields
+   present, it is encouraged to convert these into the header field
+   described in this document, if it can be done in a sensible way.  If
+   the request only contains one type -- for example, X-Forwarded-For --
+   this can be translated to "Forwarded", by prepending each element
+   with "for=".  Note that IPv6 addresses may not be quoted in
+   X-Forwarded-For and may not be enclosed by square brackets, but they
+   are quoted and enclosed in square brackets in "Forwarded".
+
+       X-Forwarded-For: 192.0.2.43, 2001:db8:cafe::17
+
+   becomes:
+
+       Forwarded: for=192.0.2.43, for="[2001:db8:cafe::17]"
+
+   However, special care must be taken if, for example, both
+   X-Forwarded-For and X-Forwarded-By exist.  In such cases, it may not
+   be possible to do a conversion, since it is not possible to know in
+   which order the already existing fields were added.  Also, note that
+   removing the X-Forwarded-For header field may cause issues for
+   parties that have not yet implemented support for this new header
+   field.
+
+7.5.  Example Usage
+
+   A request from a client with IP address 192.0.2.43 passes through a
+   proxy with IP address 198.51.100.17, then through another proxy with
+   IP address 203.0.113.60 before reaching an origin server.  This
+   could, for example, be an office client behind a corporate malware
+   filter talking to a origin server through a reverse proxy.
+
+   o  The HTTP request between the client and the first proxy has no
+      "Forwarded" header field.
+
+   o  The HTTP request between the first and second proxy has a
+      "Forwarded: for=192.0.2.43" header field.
+
+   o  The HTTP request between the second proxy and the origin server
+      has a "Forwarded: for=192.0.2.43,
+      for=198.51.100.17;by=203.0.113.60;proto=http;host=example.com"
+      header field.
+
+
+
+Petersson & Nilsson          Standards Track                   [Page 11]
+
+RFC 7239                Forwarded HTTP Extension               June 2014
+
+
+   Note that, at some points in a connection chain, the information
+   might not be updated in the "Forwarded" header field, either because
+   of lack of support of this HTTP extension or because of a policy
+   decision not to disclose information about this network component.
+
+8.  Security Considerations
+
+8.1.  Header Validity and Integrity
+
+   The "Forwarded" HTTP header field cannot be relied upon to be
+   correct, as it may be modified, whether mistakenly or for malicious
+   reasons, by every node on the way to the server, including the client
+   making the request.
+
+   One approach to ensure that the "Forwarded" HTTP header field is
+   correct is to verify the correctness of proxies and to whitelist them
+   as trusted.  This approach has at least two weaknesses.  First, the
+   chain of IP addresses listed before the request came to the proxy
+   cannot be trusted.  Second, unless the communication between proxies
+   and the endpoint is secured, the data can be modified by an attacker
+   with access to the network.
+
+8.2.  Information Leak
+
+   The "Forwarded" HTTP header field can reveal internal structures of
+   the network setup behind the NAT or proxy setup, which may be
+   undesired.  This can be addressed either by using obfuscated
+   elements, by preventing the internal nodes from updating the HTTP
+   header field, or by having an egress proxy remove entries that reveal
+   internal network information.
+
+   This header field should never be copied into response messages by
+   origin servers or intermediaries, as it can reveal the whole proxy
+   chain to the client.  As a side effect, special care must be taken in
+   hosting environments not to allow the TRACE request where the
+   "Forwarded" field is used, as it would appear in the body of the
+   response message.
+
+8.3.  Privacy Considerations
+
+   In recent years, there have been growing concerns about privacy.
+   There is a trade-off between ensuring privacy for users versus
+   disclosing information that is useful, for example, for debugging,
+   statistics, and generating location-dependent content.  The
+   "Forwarded" HTTP header field, by design, exposes information that
+   some users consider privacy sensitive, in order to allow for such
+   uses.  For any proxy, if the HTTP request contains header fields that
+
+
+
+
+Petersson & Nilsson          Standards Track                   [Page 12]
+
+RFC 7239                Forwarded HTTP Extension               June 2014
+
+
+   specifically request privacy semantics, the proxy SHOULD NOT use the
+   "Forwarded" header field, nor in any other manner pass private
+   information, such as IP addresses, on to the next hop.
+
+   The client's IP address, that may be forwarded in the "for" parameter
+   of this header field, is considered to be privacy sensitive by many
+   people, as the IP address may be able to uniquely identify a client,
+   what operator the user is using, and possibly a rough estimation of
+   where the user is geographically located.
+
+   Proxies using this extension will preserve the information of a
+   direct connection.  This has an end-user privacy impact regardless of
+   whether the end-user or deployer knows or expects that this is the
+   case.
+
+   Implementers and deployers of such proxies need to consider whether,
+   and how, deploying this extension affects user privacy.
+
+   The default configuration for both the "by" and "for" parameters
+   SHOULD contain obfuscated identifiers.  These identifiers SHOULD be
+   randomly generated per request.  If identifiers that persist across
+   requests are required, their lifetimes SHOULD be limited and they
+   SHOULD NOT persist longer than client IP addresses.  When generating
+   obfuscated identifiers, care must be taken not to include potentially
+   sensitive information in them.
+
+   Note that users' IP addresses may already be forwarded by proxies
+   using the header field X-Forwarded-For, which is widely used.  It
+   should also be noted that if the user were doing the connection
+   directly without passing the proxy, the client's IP address would be
+   sent to the web server.  Users that do not actively choose an
+   anonymizing proxy cannot rely on having their IP address shielded.
+   These users who want to minimize the risk of being tracked must also
+   note that there are other ways information may leak, for example, by
+   browser header field fingerprinting.  The Forwarded header field
+   itself, even when used without a uniquely identifying client
+   identifier, may make fingerprinting more feasible by revealing the
+   chain of proxies traversed by the client's request.
+
+
+
+
+
+
+
+
+
+
+
+
+
+Petersson & Nilsson          Standards Track                   [Page 13]
+
+RFC 7239                Forwarded HTTP Extension               June 2014
+
+
+9.  IANA Considerations
+
+   This document specifies the HTTP header field listed below, which has
+   been added to the "Permanent Message Header Field Names" registry
+   defined in [RFC3864].
+
+   Header field: Forwarded
+   Applicable protocol: http
+   Status: standard
+   Author/Change controller:
+       IETF (iesg@ietf.org)
+       Internet Engineering Task Force
+   Specification document(s): this specification (Section 4)
+   Related information: None
+
+   The "Forwarded" header field contains parameters for which IANA has
+   created and now maintains a new registry entitled "HTTP Forwarded
+   Parameters".  Initial registrations are given below.  For future
+   assignments, the registration procedure is IETF Review [RFC5226].
+   The security and privacy implications of all new parameters should be
+   thoroughly documented.  New parameters and their values MUST conform
+   with the forwarded-pair as defined in ABNF in Section 4.  Further, a
+   short description should be provided in the registration.
+
+   +-------------+---------------------------------------+-------------+
+   | Parameter   | Description                           | Reference   |
+   | name        |                                       |             |
+   +-------------+---------------------------------------+-------------+
+   | by          | IP address of incoming interface of a | Section 5.1 |
+   |             | proxy                                 |             |
+   | for         | IP address of client making a request | Section 5.2 |
+   |             | through a proxy                       |             |
+   | host        | Host header field of the incoming     | Section 5.3 |
+   |             | request                               |             |
+   | proto       | Application protocol used for         | Section 5.4 |
+   |             | incoming request                      |             |
+   +-------------+---------------------------------------+-------------+
+
+                       Table 1: Initial Assignments
+
+10.  References
+
+10.1.  Normative References
+
+   [RFC1918]  Rekhter, Y., Moskowitz, R., Karrenberg, D., Groot, G., and
+              E. Lear, "Address Allocation for Private Internets",
+              BCP 5, RFC 1918, February 1996.
+
+
+
+
+Petersson & Nilsson          Standards Track                   [Page 14]
+
+RFC 7239                Forwarded HTTP Extension               June 2014
+
+
+   [RFC2119]  Bradner, S., "Key words for use in RFCs to Indicate
+              Requirement Levels", BCP 14, RFC 2119, March 1997.
+
+   [RFC3864]  Klyne, G., Nottingham, M., and J. Mogul, "Registration
+              Procedures for Message Header Fields", BCP 90, RFC 3864,
+              September 2004.
+
+   [RFC3986]  Berners-Lee, T., Fielding, R., and L. Masinter, "Uniform
+              Resource Identifier (URI): Generic Syntax", STD 66,
+              RFC 3986, January 2005.
+
+   [RFC4193]  Hinden, R. and B. Haberman, "Unique Local IPv6 Unicast
+              Addresses", RFC 4193, October 2005.
+
+   [RFC4395]  Hansen, T., Hardie, T., and L. Masinter, "Guidelines and
+              Registration Procedures for New URI Schemes", BCP 35,
+              RFC 4395, February 2006.
+
+   [RFC5226]  Narten, T. and H. Alvestrand, "Guidelines for Writing an
+              IANA Considerations Section in RFCs", BCP 26, RFC 5226,
+              May 2008.
+
+   [RFC5234]  Crocker, D. and P. Overell, "Augmented BNF for Syntax
+              Specifications: ABNF", STD 68, RFC 5234, January 2008.
+
+   [RFC5952]  Kawamura, S. and M. Kawashima, "A Recommendation for IPv6
+              Address Text Representation", RFC 5952, August 2010.
+
+   [RFC7230]  Fielding, R., Ed. and J. Reschke, Ed., "Hypertext Transfer
+              Protocol (HTTP/1.1): Message Syntax and Routing",
+              RFC 7230, June 2014.
+
+   [RFC7232]  Fielding, R., Ed. and J. Reschke, Ed., "Hypertext Transfer
+              Protocol (HTTP/1.1): Conditional Requests", RFC 7232,
+              June 2014.
+
+10.2.  Informative References
+
+   [RFC6269]  Ford, M., Boucadair, M., Durand, A., Levis, P., and P.
+              Roberts, "Issues with IP Address Sharing", RFC 6269,
+              June 2011.
+
+
+
+
+
+
+
+
+
+
+Petersson & Nilsson          Standards Track                   [Page 15]
+
+RFC 7239                Forwarded HTTP Extension               June 2014
+
+
+Appendix A.  Acknowledgments
+
+   Thanks to Per Cederqvist, Alissa Cooper, Adrian Farrel, Stephen
+   Farrell, Ned Freed, Per Hedbor, Amos Jeffries, Poul-Henning Kamp,
+   Murray S. Kucherawy, Barry Leiba, Salvatore Loreto, Alexey Melnikov,
+   S. Moonesamy, Susan Nichols, Mark Nottingham, Julian Reschke, John
+   Sullivan, Willy Tarreau, and Dan Wing for their feedback.
+
+Authors' Addresses
+
+   Andreas Petersson
+   Opera Software
+
+   EMail: andreas@sbin.se
+
+
+   Martin Nilsson
+   Opera Software
+   S:t Larsgatan 12
+   Linkoping  SE-582 24
+
+   EMail: nilsson@opera.com
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+Petersson & Nilsson          Standards Track                   [Page 16]
+
@@ -20,6 +20,7 @@ TRANSLATE_LANGUAGES= \
     id.lang \
     it.lang \
     ja.lang \
+    ka.lang \
     ko.lang \
     lt.lang \
     lv.lang \
@@ -8,6 +8,7 @@ LDADD = \
 	$(top_builddir)/lib/libmisccontainers.la \
 	$(top_builddir)/lib/libmiscencoding.la \
 	$(COMPAT_LIB) \
+	$(NETTLELIB) \
 	$(CRYPTLIB) \
 	$(SSLLIB) \
 	$(XTRA_LIBS)
@@ -1 +1,7 @@
 BUILD_HELPER="NCSA"
+
+# check for optional crypt(3), may require -lcrypt
+SQUID_STATE_SAVE(ncsa_helper)
+LIBS="$LIBS $CRYPTLIB"
+AC_CHECK_FUNCS(crypt)
+SQUID_STATE_ROLLBACK(ncsa_helper)
@@ -65,12 +65,19 @@ main(int argc, char **argv)
         if (!nispasswd) {
             /* User does not exist */
             printf("ERR No such user\n");
+#if HAVE_CRYPT
         } else if (strcmp(nispasswd, (char *) crypt(passwd, nispasswd)) == 0) {
             /* All ok !, thanks... */
             printf("OK\n");
         } else {
             /* Password incorrect */
             printf("ERR Wrong password\n");
+#else
+        }
+        else {
+            /* Password incorrect */
+            printf("BH message=\"Missing crypto capability\"\n");
+#endif
         }
     }
     exit(0);
@@ -20,8 +20,9 @@
 #define BOOL_DEFINED
 #endif
 
+#if HAVE_RPCSVC_YPCLNT_H
 #include <rpcsvc/ypclnt.h>
-
+#endif
 #if HAVE_RPCSVC_YP_PROT_H
 #include <rpcsvc/yp_prot.h>
 #endif
@@ -1,4 +1,5 @@
-AC_CHECK_HEADERS([sys/types.h rpc/rpc.h rpcsvc/yp_prot.h],[BUILD_HELPER="NIS"],,AC_INCLUDES_DEFAULT([
+BUILD_HELPER="NIS"
+AC_CHECK_HEADERS([sys/types.h rpc/rpc.h rpcsvc/ypclnt.h rpcsvc/yp_prot.h crypt.h],[],[BUILD_HELPER=""],AC_INCLUDES_DEFAULT([
 #if HAVE_RPC_RPC_H
 #include <rpc/rpc.h>
 #endif
@@ -15,5 +15,6 @@ basic_radius_auth_SOURCES = \
 basic_radius_auth_LDADD = \
 	$(top_builddir)/lib/libmiscencoding.la \
 	$(COMPAT_LIB) \
+	$(NETTLELIB) \
 	$(SSLLIB) \
 	$(XTRA_LIBS)
@@ -1 +1,14 @@
-AC_CHECK_HEADERS([pwd.h],[BUILD_HELPER="getpwnam"])
+AC_CHECK_HEADERS([pwd.h],[
+  # check for crypt(3), may require -lcrypt
+  SQUID_STATE_SAVE(getpwnam_helper)
+  LIBS="$LIBS $CRYPTLIB"
+  AC_CHECK_FUNCS(crypt)
+  SQUID_STATE_ROLLBACK(getpwnam_helper)
+
+  # unconditionally requires crypt(3), for now
+  if test "x$ac_cv_func_crypt" != "x"; then
+    AC_CHECK_HEADERS(unistd.h crypt.h shadow.h)
+
+    BUILD_HELPER="getpwnam"
+  fi
+])
@@ -14,6 +14,7 @@ digest_ldap_auth_LDADD = \
 	$(COMPAT_LIB) \
 	$(LDAPLIB) \
 	$(LBERLIB) \
+	$(NETTLELIB) \
 	$(CRYPTLIB) \
 	$(SSLLIB) \
 	$(XTRA_LIBS)
@@ -32,6 +32,7 @@
 #include "util.h"
 
 typedef struct _request_data {
+    int channelId;
     char *user;
     char *realm;
     char *password;
@@ -49,6 +49,14 @@ ParseBuffer(char *buf, RequestData * requestData)
     requestData->parsed = 0;
     if ((p = strchr(buf, '\n')) != NULL)
         *p = '\0';		/* strip \n */
+
+    p = NULL;
+    requestData->channelId = strtoll(buf, &p, 10);
+    if (*p != ' ') // not a channel-ID
+        requestData->channelId = -1;
+    else
+        buf = ++p;
+
     if ((requestData->user = strtok(buf, "\"")) == NULL)
         return;
     if ((requestData->realm = strtok(NULL, "\"")) == NULL)
@@ -63,6 +71,8 @@ OutputHHA1(RequestData * requestData)
 {
     requestData->error = 0;
     GetHHA1(requestData);
+    if (requestData->channelId >= 0)
+        printf("%u ", requestData->channelId);
     if (requestData->error) {
         SEND_ERR("message=\"No such user\"");
         return;
@@ -76,6 +86,8 @@ DoOneRequest(char *buf)
     RequestData requestData;
     ParseBuffer(buf, &requestData);
     if (!requestData.parsed) {
+        if (requestData.channelId >= 0)
+            printf("%u ", requestData.channelId);
         SEND_BH("message=\"Invalid line received\"");
         return;
     }
@@ -35,6 +35,7 @@
 #include "util.h"
 
 typedef struct _request_data {
+    int channelId;
     char *user;
     char *realm;
     char *password;
@@ -49,6 +49,14 @@ ParseBuffer(char *buf, RequestData * requestData)
     requestData->parsed = 0;
     if ((p = strchr(buf, '\n')) != NULL)
         *p = '\0';		/* strip \n */
+
+    p = NULL;
+    requestData->channelId = strtoll(buf, &p, 10);
+    if (*p != ' ') // not a channel-ID
+        requestData->channelId = -1;
+    else
+        buf = ++p;
+
     if ((requestData->user = strtok(buf, "\"")) == NULL)
         return;
     if ((requestData->realm = strtok(NULL, "\"")) == NULL)
@@ -63,6 +71,8 @@ OutputHHA1(RequestData * requestData)
 {
     requestData->error = 0;
     GetHHA1(requestData);
+    if (requestData->channelId >= 0)
+        printf("%u ", requestData->channelId);
     if (requestData->error) {
         SEND_ERR("message=\"No such user\"");
         return;
@@ -76,6 +86,8 @@ DoOneRequest(char *buf)
     RequestData requestData;
     ParseBuffer(buf, &requestData);
     if (!requestData.parsed) {
+        if (requestData.channelId >= 0)
+            printf("%u ", requestData.channelId);
         SEND_BH("message=\"Invalid line received\"");
         return;
     }
@@ -14,6 +14,7 @@ LDADD = \
 	$(top_builddir)/lib/libmisccontainers.la \
 	$(top_builddir)/lib/libmiscencoding.la \
 	$(COMPAT_LIB) \
+	$(NETTLELIB) \
 	$(CRYPTLIB) \
 	$(SSLLIB) \
 	$(XTRA_LIBS)
@@ -27,6 +27,7 @@
 #endif
 
 typedef struct _request_data {
+    int channelId;
     char *user;
     char *realm;
     char *password;
@@ -5,7 +5,7 @@
 .if !'po4a'hide' \-
 File based digest authentication helper for Squid.
 .PP
-Version 1.0
+Version 1.1
 .
 .SH SYNOPSIS
 .if !'po4a'hide' .B digest_file_auth
@@ -17,6 +17,9 @@ file
 is an installed binary authentication program for Squid. It handles digest 
 authentication protocol and authenticates against a text file backend.
 .
+This program will automatically detect the existence of a concurrecy channel-ID and adjust appropriately.
+It may be used with any value 0 or above for the auth_param children concurrency= parameter.
+.
 .SH OPTIONS
 .if !'po4a'hide' .TP 12
 .if !'po4a'hide' .B \-c
@@ -51,6 +51,14 @@ ParseBuffer(char *buf, RequestData * requestData)
     requestData->parsed = 0;
     if ((p = strchr(buf, '\n')) != NULL)
         *p = '\0';		/* strip \n */
+
+    p = NULL;
+    requestData->channelId = strtoll(buf, &p, 10);
+    if (*p != ' ') // not a channel-ID
+        requestData->channelId = -1;
+    else
+        buf = ++p;
+
     if ((requestData->user = strtok(buf, "\"")) == NULL)
         return;
     if ((requestData->realm = strtok(NULL, "\"")) == NULL)
@@ -65,6 +73,8 @@ OutputHHA1(RequestData * requestData)
 {
     requestData->error = 0;
     GetHHA1(requestData);
+    if (requestData->channelId >= 0)
+        printf("%u ", requestData->channelId);
     if (requestData->error) {
         SEND_ERR("message=\"No such user\"");
         return;
@@ -78,6 +88,8 @@ DoOneRequest(char *buf)
     RequestData requestData;
     ParseBuffer(buf, &requestData);
     if (!requestData.parsed) {
+        if (requestData.channelId >= 0)
+            printf("%u ", requestData.channelId);
         SEND_BH("message=\"Invalid line received\"");
         return;
     }
@@ -1,5 +1,6 @@
 DIST_SUBDIRS= \
 	AD_group \
+	delayer \
 	eDirectory_userip \
 	file_userip \
 	kerberos_ldap_group \
@@ -0,0 +1,12 @@
+include $(top_srcdir)/src/Common.am
+
+libexec_SCRIPTS = ext_delayer_acl
+CLEANFILES += ext_delayer_acl ext_delayer_acl.8
+man_MANS = ext_delayer_acl.8
+EXTRA_DIST = ext_delayer_acl.pl.in ext_delayer_acl.8 required.m4
+
+ext_delayer_acl.8: ext_delayer_acl
+	pod2man ext_delayer_acl ext_delayer_acl.8
+
+ext_delayer_acl: ext_delayer_acl.pl.in
+	$(subst_perlshell)
@@ -0,0 +1,257 @@
+#!@PERL@
+=pod
+
+=head1 NAME
+
+delayer - Squid external acl helper adding artificial delay to requests
+
+=head1 SYNOPSIS
+
+delayer [--help] [--debug] [--log file] [--wait msec]
+
+=head1 OPTIONS
+
+=over 8
+
+=item B<--help> or B<-h>
+
+Print help message to stdout
+
+=item B<--debug> or B<-d>
+
+Emit debugging output to STDERR and ultimately cache.log
+
+=item B<--log /path/to/file> or B<-l /path/to/file>
+
+Emit debugging output to specified file instead of STDERR. Also turns on debugging
+
+=item B<--wait msec> or B<-w msec>
+
+Delay each request by the specified amount of msec.
+Unless this option is specified, by default each submitted request
+will be delayed by half a second (500 msec).
+
+=back
+
+=head1 DESCRIPTION
+
+Squid external acl helper; causes squid to delay responding to HTTP requests.
+
+By carefully crafting the ACLs of a Squid setup it is possible to
+selectively delay requests received by a proxy. After the configured amount
+of time, it will always return "true".
+
+=head1 CONFIGURATION
+
+To engage it, this snippet of configuration template can be used in squid.conf:
+
+ external_acl_type delayer concurrency=100000 children-max=2 children-startup=1 children-idle=1 cache=10 %URI /path/to/delayer -w 200
+ acl delay external delayer
+ http_access allow acl1 acl2 acl3 delay !all
+
+It is important that the acl referencing the delayer be the penultimate clause in the
+http_access line. It will cause delay to all requests that match all the
+preceding acls in the line. The !all clause at the end of the line will make it
+so that no traffic is authorized by this ACL, only the delay to evaluate
+the delay clause will be inserted before evaluating following http_access lines.
+It is also important to place the http_access line carefully in the sequence
+of all http_access_lines; it should be near the beginning, but be careful
+not to insert unwanted slow acls (especially proxy_auth).
+
+It is possible to customize how delay is calculated for each request by
+modifying the "calc_delay" PERL function in the script, documentation on this
+is embedded in the source code comments.
+
+=head1 AUTHOR
+
+This software is written by Francesco Chemolli <kinkie@squid-cache.org>
+
+=head1 COPYRIGHT
+
+(C) 2014 Francesco Chemolli <kinkie@squid-cache.org>
+
+This program is free software. You may redistribute copies of it under the
+terms of the GNU General Public License version 2, or (at your opinion) any
+later version.
+
+=head1 QUESTIONS
+
+Questions on this code are best addressed on the Squid-users mailing list
+<squid-users@squid-cache.org>
+
+=head1 REPORTING BUGS
+
+Bug reports need to be made in English.
+See http://wiki.squid-cache.org/SquidFaq/BugReporting for details of what you
+need to include with your bug report.
+Report bugs or bug fixes using http://bugs.squid-cache.org/
+
+=head1 SEE ALSO
+
+B<squid>(8), B<GPL>(7), B<Squid Wiki> http://wiki.squid-cache.org/ ,
+B<Squid Configuration Manual> http://www.squid-cache.org/Doc/config/
+
+=cut
+
+use strict;
+use warnings;
+use Getopt::Long qw(:config auto_version auto_help);
+use Data::Dumper;
+use Time::HiRes qw(gettimeofday tv_interval);
+
+# options handling
+my %opts = (); #for getopt
+my $debug = 0; #debug
+my $logfile = *STDERR; #filehandle to logfile
+my $logfilename;
+my $delay = 500; #in milliseconds. Configurable with the -w option.
+#for custom delay algorithms, you can customize the dispatch_request function
+
+#calculate the delay for the request.
+# Gets as input the verbatim full line received from squid
+# (channel number and all, as configured in squid.conf) and returns
+# a floating point number >= 0 which is the delay to be applied to the request
+# in seconds.
+# Notice that in order to have efficient data structures, the delay is
+# assumed to be monotonously growing. In other words, a long-delay
+# item will stall the queue until completed. Supporting generic delays
+# requires transforming @queue from a FIFO to a priority queue.
+sub calc_delay {
+  return $delay;
+}
+
+GetOptions("debug|d" => \$debug,
+           "wait|w=i" => \$delay,
+           "log|l=s" => \$logfilename)
+or die("Error in parsing command line arguments");
+if (defined $opts{h}) {
+  HELP_MESSAGE();
+  exit 0;
+}
+$delay /= 1000.0; # transform msec into sec
+if ($logfilename) {
+  open ($logfile,">>", "$opts{l}");
+  $debug=1;
+} 
+
+my @p=split(/[\\\/]/,$0);
+my $prg_basename=pop @p;
+$prg_basename .= "[$$]";
+undef @p;
+my $reqid=0; #sequence number for requests
+
+# variables initialization for select
+my $rvec = '';
+vec($rvec,0,1) = 1; #stdin
+my ($nfound, $rd, $nread, $req);
+
+#requests queue
+my @queue = (); # array of references to hashes, with keys chan, when, req, reqid
+
+# signal handlers
+$SIG{HUP} = \&dump_state;
+
+#disable IO buffering
+$| = 1;
+my $fh=select($logfile); $|=1; select($fh); undef($fh);
+
+# takes a result from a gettimeofday call and turns it into a
+# floating-point number suitable for approximate time calculations and select
+sub fract_time {
+  return $_[0]+$_[1]/1000000;
+}
+
+sub dispatch_request {
+  my $r = $_[0];
+  chomp $r;
+  &debug("got request: '$r'");
+  my %evt = ();
+  my @fields;
+  @fields = split (/\s+/, $r);
+  $evt{when} = &calc_delay($r)+fract_time(gettimeofday());
+  $evt{reqid}=$reqid++;
+  $evt{req} = $r;
+  $evt{chan} = $fields[0];
+  &debug("Dispatching: reqid $evt{reqid}, chan $evt{chan}, when $evt{when}, raw {$evt{req}}");
+  push @queue,\%evt;
+}
+
+sub next_event {
+  my $now = fract_time(gettimeofday());
+  if (@queue) {
+    my $when = $queue[0]->{when} - $now;
+    &debug("Next event is in $when seconds");
+    return $when;
+  }
+  &debug("No events in queue");
+  return undef;
+}
+
+sub handle_events {
+  my $now = fract_time(gettimeofday());
+  while ( @queue ) {
+    &debug("Queue length is $#queue");
+    last if ($queue[0]->{when} > $now);
+    my %evt = %{shift @queue};
+    &debug("Event: reqid $evt{reqid}, chan $evt{chan}, when $evt{when}, raw {$evt{req}}");
+    print $evt{chan} , " OK\n";
+  }
+}
+
+# main loop
+while(1) {
+  &debug("selecting");
+  $nfound = select($rd = $rvec,undef,undef,&next_event());
+  &debug("found $nfound bits set");
+  if ($nfound == -1 ) {
+    next if ($!{ERESTART} || $!{EAGAIN} || $!{EINTR});
+    &debug("error in select: $!");
+    exit 1;
+  }
+  if (vec($rd,0,1)==1) { #got stuff from stdin
+    my $d; #data
+    $nread = sysread(STDIN,$d,40960); # read 40kb
+    # clear the signal-bit, stdin is special
+    vec($rd,0,1) = 0;
+    if ($nread==0) {
+      &debug("nothing read from stdin, exiting");
+      exit 0;
+    }
+    my $i;
+    while ($i = index($d,"\n")) { #BUG: assumption of no spill-over
+      last if ($i == -1);
+      &dispatch_request(substr($d,0,$i));
+      $d=substr($d,$i+1);
+    }
+  }
+  &handle_events();
+}
+
+my $doc = <<_EOF;
+delay-adding external acl helper
+authorizes all requests, adding a delay before doing so.
+supports multiplexed helper protocol.
+Options:
+  -h, --help: this help message
+  -d, --debug: enable debug output
+  -l <file>, --log <file>: log output to named file instead of stderr (implies debug)
+  -w <num>, --wait <num> delay each request by this number milliseconds
+
+AUTHOR: Francesco Chemolli <kinkie\@squid-cache.org>
+Licensed under the terms of the GNU GPL v2 or later (see source for details)
+_EOF
+our $VERSION = "1.0";
+
+sub HELP_MESSAGE {
+  print STDERR $doc;
+}
+
+sub dump_state {
+  $SIG{HUP} = \&dump_state;
+  print STDERR "Queue:\n",Dumper(\@queue),"\n";
+}
+
+sub debug {
+  return unless ($debug);
+  print $logfile $prg_basename , ": ", @_, "\n";
+}
@@ -0,0 +1,3 @@
+if test "x$PERL" != "x" -a "x$POD2MAN" != "x"; then
+  BUILD_HELPER="delayer"
+fi
@@ -28,9 +28,7 @@
 #ifdef HAVE_LDAP
 
 #include "support.h"
-#ifdef HAVE_ERRNO_H
-#include <errno.h>
-#endif
+#include <cerrno>
 
 char *convert_domain_to_bind_path(char *domain);
 char *escape_filter(char *filter);
@@ -28,9 +28,7 @@
 #ifdef HAVE_LDAP
 
 #include "support.h"
-#ifdef HAVE_ERRNO_H
-#include <errno.h>
-#endif
+#include <cerrno>
 #ifdef HAVE_NETDB_H
 #include <netdb.h>
 #endif
@@ -27,6 +27,9 @@ if test "x$enable_external_acl_helpers" != "xno" ; then
       elif test "x$helper" = "xLM_group" ; then
         m4_include([helpers/external_acl/LM_group/required.m4])
 
+      elif test "x$helper" = "xdelayer" ; then
+        m4_include([helpers/external_acl/delayer/required.m4])
+
       elif test "x$helper" = "xSQL_session" ; then
         m4_include([helpers/external_acl/SQL_session/required.m4])
 
@@ -12,6 +12,7 @@ negotiate_kerberos_auth_LDFLAGS =
 negotiate_kerberos_auth_LDADD = \
 	$(top_builddir)/lib/libmiscencoding.la \
 	$(COMPAT_LIB) \
+	$(NETTLELIB) \
 	$(KRB5LIBS) \
 	$(XTRA_LIBS)
 
@@ -20,6 +21,7 @@ negotiate_kerberos_auth_test_LDFLAGS =
 negotiate_kerberos_auth_test_LDADD = \
 	$(top_builddir)/lib/libmiscencoding.la \
 	$(COMPAT_LIB) \
+	$(NETTLELIB) \
 	$(KRB5LIBS) \
 	$(XTRA_LIBS)
 
@@ -8,4 +8,5 @@ negotiate_wrapper_auth_SOURCES = negotiate_wrapper.cc
 negotiate_wrapper_auth_LDADD = \
 	$(top_builddir)/lib/libmiscencoding.la \
 	$(COMPAT_LIB) \
+	$(NETTLELIB) \
 	$(XTRA_LIBS)
@@ -7,6 +7,7 @@ ntlm_fake_auth_LDADD = \
 	$(top_builddir)/lib/ntlmauth/libntlmauth.la \
 	$(top_builddir)/lib/libmiscencoding.la \
 	$(COMPAT_LIB) \
+	$(NETTLELIB) \
 	$(CRYPTLIB) \
 	$(XTRA_LIBS)
 
@@ -9,6 +9,7 @@ ntlm_smb_lm_auth_LDADD = \
 	$(top_builddir)/lib/ntlmauth/libntlmauth.la \
 	$(top_builddir)/lib/libmiscencoding.la \
 	$(COMPAT_LIB) \
+	$(NETTLELIB) \
 	$(CRYPTLIB) \
 	$(XTRA_LIBS)
 
@@ -13,7 +13,7 @@ storeid_file_rewrite - File based Store-ID helper for Squid
 
 storeid_file_rewrite filepath
 
-=head1 DESCRIPTOIN
+=head1 DESCRIPTION
 
 This program acts as a store_id helper program, rewriting URLs passed
 by Squid into storage-ids that can be used to achieve better caching
@@ -28,6 +28,9 @@ Eg:
 Rewrite rules are matched in the same order as they appear in the rules file.
 So for best performance, sort it in order of frequency of occurrence.
 
+This program will automatically detect the existence of a concurrecy channel-ID and adjust appropriately.
+It may be used with any value 0 or above for the store_id_children concurrency= parameter.
+
 For more information please see http://wiki.squid-cache.org/Features/StoreID
 
 =cut
@@ -53,19 +56,24 @@ close RULES;
 URL: while (<STDIN>) {
 	chomp;
 	last if $_ eq 'quit';
-	
+
+  my $channel = "";
+  if (s/^(\d+\s+)//o) {
+    $channel = $1;
+  }
+
 	foreach my $rule (@rules) {
 		if (my @match = /$rule->[0]/) {
 			$_ = $rule->[1];
 			
 			for (my $i=1; $i<=scalar(@match); $i++) {
 				s/\$$i/$match[$i-1]/g;
 			}
-			print "OK store-id=$_\n";
+			print $channel, "OK store-id=$_\n";
 			next URL;
 		}
 	}
-	print "ERR\n";
+	print $channel, "ERR\n";
 }
 
 =pod
@@ -109,9 +109,16 @@ main(int argc, char *argv[])
 
         debug("Got %d bytes '%s' from Squid\n", buflen, buf);
 
-        /* send 'no-change' result back to Squid */
-        fprintf(stdout,"\n");
+        p = NULL;
+        int64_t channelId = strtoll(buf, &p, 10);
+        if (*p != ' ') {
+            /* send 'no-change' result back to Squid in non-concurrent format */
+            fprintf(stdout,"ERR\n");
+        } else {
+            /* send 'no-change' result back to Squid in concurrent format */
+            fprintf(stdout, "%" PRId64 " ERR\n", channelId);
+        }
     }
     debug("%s build " __DATE__ ", " __TIME__ " shutting down...\n", my_program_name);
-    exit(0);
+    return 0;
 }
@@ -1,6 +1,18 @@
 #ifndef SQUID_MD5_H
 #define SQUID_MD5_H
 
+#if HAVE_NETTLE_MD5_H
+#include <nettle/md5.h>
+
+typedef struct md5_ctx SquidMD5_CTX;
+
+#define SquidMD5Init(c)       md5_init((c))
+#define SquidMD5Update(c,b,l) md5_update((c), (l), (const uint8_t *)(b))
+#define SquidMD5Final(d,c)    md5_digest((c), MD5_DIGEST_SIZE, (uint8_t *)(d))
+
+#define SQUID_MD5_DIGEST_LENGTH MD5_DIGEST_SIZE
+
+#else
 /*
  * This is the header file for the MD5 message-digest algorithm.
  * The algorithm is due to Ron Rivest.  This code was
@@ -45,4 +57,6 @@ SQUIDCEXTERN void SquidMD5Transform(uint32_t buf[4], uint32_t const in[16]);
 
 #define SQUID_MD5_DIGEST_LENGTH         16
 
+#endif /* HAVE_NETTLE_MD5_H */
+
 #endif /* SQUID_MD5_H */
@@ -103,11 +103,7 @@
 /*
  * Determine if this is a leak check build or standard
  */
-#if PURIFY
-#define LEAK_CHECK_MODE 1
-#elif WITH_VALGRIND
-#define LEAK_CHECK_MODE 1
-#elif XMALLOC_TRACE
+#if PURIFY || WITH_VALGRIND
 #define LEAK_CHECK_MODE 1
 #endif
 
@@ -60,20 +60,6 @@ SQUIDCEXTERN void Tolower(char *);
 #include "SquidNew.h"
 #endif
 
-#if XMALLOC_TRACE
-#define xmalloc(size) (xmalloc_func="xmalloc",xmalloc_line=__LINE__,xmalloc_file=__FILE__,xmalloc(size))
-#define xfree(ptr) (xmalloc_func="xfree",xmalloc_line=__LINE__,xmalloc_file=__FILE__,xfree(ptr))
-#define xrealloc(ptr,size) (xmalloc_func="xrealloc",xmalloc_line=__LINE__,xmalloc_file=__FILE__,xrealloc(ptr,size))
-#define xcalloc(n,size) (xmalloc_func="xcalloc",xmalloc_line=__LINE__,xmalloc_file=__FILE__,xcalloc(n,size))
-#define xstrdup(ptr) (xmalloc_func="xstrdup",xmalloc_line=__LINE__,xmalloc_file=__FILE__,xstrdup(ptr))
-extern int xmalloc_line;
-extern char *xmalloc_file;
-extern char *xmalloc_func;
-extern int xmalloc_trace;
-extern size_t xmalloc_total;
-extern void xmalloc_find_leaks(void);
-#endif
-
 SQUIDCEXTERN time_t parse_iso3307_time(const char *buf);
 
 SQUIDCEXTERN double xpercent(double part, double whole);
@@ -58,7 +58,6 @@ libmisccontainers_la_SOURCES = \
 	hash.cc
 
 libmiscutil_la_SOURCES = \
-	malloc_trace.cc \
 	MemPool.cc \
 	MemPoolChunked.cc \
 	MemPoolMalloc.cc \
@@ -1,410 +0,0 @@
-/*
- * DEBUG:
- * AUTHOR: Harvest Derived
- *
- * SQUID Web Proxy Cache          http://www.squid-cache.org/
- * ----------------------------------------------------------
- *
- *  Squid is the result of efforts by numerous individuals from
- *  the Internet community; see the CONTRIBUTORS file for full
- *  details.   Many organizations have provided support for Squid's
- *  development; see the SPONSORS file for full details.  Squid is
- *  Copyrighted (C) 2001 by the Regents of the University of
- *  California; see the COPYRIGHT file for full details.  Squid
- *  incorporates software developed and/or copyrighted by other
- *  sources; see the CREDITS file for full details.
- *
- *  This program is free software; you can redistribute it and/or modify
- *  it under the terms of the GNU General Public License as published by
- *  the Free Software Foundation; either version 2 of the License, or
- *  (at your option) any later version.
- *
- *  This program is distributed in the hope that it will be useful,
- *  but WITHOUT ANY WARRANTY; without even the implied warranty of
- *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
- *  GNU General Public License for more details.
- *
- *  You should have received a copy of the GNU General Public License
- *  along with this program; if not, write to the Free Software
- *  Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111, USA.
- *
- */
-
-#define _etext etext
-
-#include "squid.h"
-#include "profiler/Profiler.h"
-#include "util.h"
-
-#include <cassert>
-#include <cctype>
-#include <cerrno>
-#include <cmath>
-#include <cstring>
-#if HAVE_UNISTD_H
-#include <unistd.h>
-#endif
-#if HAVE_GNUMALLLOC_H
-#include <gnumalloc.h>
-#elif HAVE_MALLOC_H
-#include <malloc.h>
-#endif
-
-#if MEM_GEN_TRACE
-
-static FILE *tracefp = NULL;
-
-void
-log_trace_init(char *fn)
-{
-    tracefp = fopen(fn, "a+");
-
-    if (!tracefp) {
-        perror("log_trace_init");
-        exit(1);
-    }
-}
-
-void
-log_trace_done()
-{
-    fclose(tracefp);
-    tracefp = NULL;
-}
-
-#endif
-
-#if XMALLOC_TRACE
-char *xmalloc_file = "";
-int xmalloc_line = 0;
-char *xmalloc_func = "";
-static int xmalloc_count = 0;
-int xmalloc_trace = 0;		/* Enable with -m option */
-size_t xmalloc_total = 0;
-#undef xmalloc
-#undef xfree
-#undef xrealloc
-#undef xcalloc
-#undef xstrdup
-#endif
-
-#if XMALLOC_DEBUG
-#define DBG_ARRY_SZ (1<<11)
-#define DBG_ARRY_BKTS (1<<8)
-static void *(*malloc_ptrs)[DBG_ARRY_SZ];
-static int malloc_size[DBG_ARRY_BKTS][DBG_ARRY_SZ];
-#if XMALLOC_TRACE
-static char *malloc_file[DBG_ARRY_BKTS][DBG_ARRY_SZ];
-static short malloc_line[DBG_ARRY_BKTS][DBG_ARRY_SZ];
-static int malloc_count[DBG_ARRY_BKTS][DBG_ARRY_SZ];
-#endif
-static int dbg_initd = 0;
-
-#define DBG_HASH_BUCKET(ptr)   (((((int)ptr)>>4)+(((int)ptr)>>12)+(((int)ptr)>>20))&0xFF)
-
-static void
-check_init(void)
-{
-    int B = 0, I = 0;
-    /* calloc the ptrs so that we don't see them when hunting lost memory */
-    malloc_ptrs = calloc(DBG_ARRY_BKTS, sizeof(*malloc_ptrs));
-
-    for (B = 0; B < DBG_ARRY_BKTS; ++B) {
-        for (I = 0; I < DBG_ARRY_SZ; ++I) {
-            malloc_ptrs[B][I] = NULL;
-            malloc_size[B][I] = 0;
-#if XMALLOC_TRACE
-
-            malloc_file[B][I] = NULL;
-            malloc_line[B][I] = 0;
-            malloc_count[B][I] = 0;
-#endif
-
-        }
-    }
-
-    dbg_initd = 1;
-}
-
-static void
-check_free(void *s)
-{
-    int B, I;
-    B = DBG_HASH_BUCKET(s);
-
-    for (I = 0; I < DBG_ARRY_SZ; ++I) {
-        if (malloc_ptrs[B][I] != s)
-            continue;
-
-        malloc_ptrs[B][I] = NULL;
-
-        malloc_size[B][I] = 0;
-
-#if XMALLOC_TRACE
-
-        malloc_file[B][I] = NULL;
-
-        malloc_line[B][I] = 0;
-
-        malloc_count[B][I] = 0;
-
-#endif
-
-        break;
-    }
-
-    if (I == DBG_ARRY_SZ) {
-        static char msg[128];
-        snprintf(msg, 128, "xfree: ERROR: s=%p not found!", s);
-        if (failure_notify)
-            (*failure_notify) (msg);
-        else
-            perror(msg);
-    }
-}
-
-static void
-check_malloc(void *p, size_t sz)
-{
-    void *P, *Q;
-    int B, I;
-
-    if (!dbg_initd)
-        check_init();
-
-    B = DBG_HASH_BUCKET(p);
-
-    for (I = 0; I < DBG_ARRY_SZ; ++I) {
-        if (!(P = malloc_ptrs[B][I]))
-            continue;
-
-        Q = P + malloc_size[B][I];
-
-        if (P <= p && p < Q) {
-            static char msg[128];
-            snprintf(msg, 128, "xmalloc: ERROR: p=%p falls in P=%p+%d",
-                     p, P, malloc_size[B][I]);
-            if (failure_notify)
-                (*failure_notify) (msg);
-            else
-                perror(msg);
-        }
-    }
-
-    for (I = 0; I < DBG_ARRY_SZ; ++I) {
-        if (malloc_ptrs[B][I])
-            continue;
-
-        malloc_ptrs[B][I] = p;
-
-        malloc_size[B][I] = (int) sz;
-
-#if XMALLOC_TRACE
-
-        malloc_file[B][I] = xmalloc_file;
-
-        malloc_line[B][I] = xmalloc_line;
-
-        malloc_count[B][I] = xmalloc_count;
-
-#endif
-
-        break;
-    }
-
-    if (I == DBG_ARRY_SZ) {
-        if (failure_notify)
-            (*failure_notify) ("xmalloc: debug out of array space!");
-        else
-            perror("xmalloc: debug out of array space!");
-    }
-}
-
-#endif
-
-#if XMALLOC_TRACE && !HAVE_MALLOCBLKSIZE
-size_t
-xmallocblksize(void *p)
-{
-    int B, I;
-    B = DBG_HASH_BUCKET(p);
-
-    for (I = 0; I < DBG_ARRY_SZ; ++I) {
-        if (malloc_ptrs[B][I] == p)
-            return malloc_size[B][I];
-    }
-
-    return 0;
-}
-
-#endif
-
-#ifdef XMALLOC_TRACE
-static char *
-malloc_file_name(void *p)
-{
-    int B, I;
-    B = DBG_HASH_BUCKET(p);
-
-    for (I = 0; I < DBG_ARRY_SZ; ++I) {
-        if (malloc_ptrs[B][I] == p)
-            return malloc_file[B][I];
-    }
-
-    return 0;
-}
-
-int
-malloc_line_number(void *p)
-{
-    int B, I;
-    B = DBG_HASH_BUCKET(p);
-
-    for (I = 0; I < DBG_ARRY_SZ; ++I) {
-        if (malloc_ptrs[B][I] == p)
-            return malloc_line[B][I];
-    }
-
-    return 0;
-}
-
-int
-malloc_number(void *p)
-{
-    int B, I;
-    B = DBG_HASH_BUCKET(p);
-
-    for (I = 0; I < DBG_ARRY_SZ; ++I) {
-        if (malloc_ptrs[B][I] == p)
-            return malloc_count[B][I];
-    }
-
-    return 0;
-}
-
-static void
-xmalloc_show_trace(void *p, int sign)
-{
-    int statMemoryAccounted();
-    static size_t last_total = 0, last_accounted = 0, last_mallinfo = 0;
-    size_t accounted = statMemoryAccounted();
-    size_t mi = 0;
-    size_t sz;
-#if HAVE_MALLINFO
-
-    struct mallinfo mp = mallinfo();
-    mi = mp.uordblks + mp.usmblks + mp.hblkhd;
-#endif
-
-    sz = xmallocblksize(p) * sign;
-    xmalloc_total += sz;
-    xmalloc_count += sign > 0;
-
-    if (xmalloc_trace) {
-        fprintf(stderr, "%c%8p size=%5d/%d acc=%5d/%d mallinfo=%5d/%d %s:%d %s",
-                sign > 0 ? '+' : '-', p,
-                (int) xmalloc_total - last_total, (int) xmalloc_total,
-                (int) accounted - last_accounted, (int) accounted,
-                (int) mi - last_mallinfo, (int) mi,
-                xmalloc_file, xmalloc_line, xmalloc_func);
-
-        if (sign < 0)
-            fprintf(stderr, " (%d %s:%d)\n", malloc_number(p), malloc_file_name(p), malloc_line_number(p));
-        else
-            fprintf(stderr, " %d\n", xmalloc_count);
-    }
-
-    last_total = xmalloc_total;
-    last_accounted = accounted;
-    last_mallinfo = mi;
-}
-
-short malloc_refs[DBG_ARRY_BKTS][DBG_ARRY_SZ];
-#define XMALLOC_LEAK_ALIGN (4)
-static void
-xmalloc_scan_region(void *start, int size, int depth)
-{
-    int B, I;
-    char *ptr = start;
-    char *end = ptr + size - XMALLOC_LEAK_ALIGN;
-    static int sum = 0;
-
-    while (ptr <= end) {
-        void *p = *(void **) ptr;
-
-        if (p && p != start) {
-            B = DBG_HASH_BUCKET(p);
-
-            for (I = 0; I < DBG_ARRY_SZ; ++I) {
-                if (malloc_ptrs[B][I] == p) {
-                    if (!malloc_refs[B][I]++) {
-                        /* A new reference */
-                        fprintf(stderr, "%*s%p %s:%d size %d allocation %d\n",
-                                depth, "",
-                                malloc_ptrs[B][I], malloc_file[B][I],
-                                malloc_line[B][I], malloc_size[B][I],
-                                malloc_count[B][I]);
-                        sum += malloc_size[B][I];
-                        xmalloc_scan_region(malloc_ptrs[B][I], malloc_size[B][I], depth + 1);
-
-                        if (depth == 0) {
-                            if (sum != malloc_size[B][I])
-                                fprintf(stderr, "=== %d bytes\n", sum);
-
-                            sum = 0;
-                        }
-
-#if XMALLOC_SHOW_ALL_REFERENCES
-
-                    } else {
-                        /* We have already scanned this pointer... */
-                        fprintf(stderr, "%*s%p %s:%d size %d allocation %d ... (%d)\n",
-                                depth * 2, "",
-                                malloc_ptrs[B][I], malloc_file[B][I],
-                                malloc_line[B][I], malloc_size[B][I],
-                                malloc_count[B][I], malloc_refs[B][I]);
-#endif
-
-                    }
-                }
-            }
-        }
-
-        ptr += XMALLOC_LEAK_ALIGN;
-    }
-}
-
-void
-xmalloc_find_leaks(void)
-{
-    int B, I;
-    int leak_sum = 0;
-
-    extern void _etext;
-    fprintf(stderr, "----- Memory map ----\n");
-    xmalloc_scan_region(&_etext, (void *) sbrk(0) - (void *) &_etext, 0);
-
-    for (B = 0; B < DBG_ARRY_BKTS; ++B) {
-        for (I = 0; I < DBG_ARRY_SZ; ++I) {
-            if (malloc_ptrs[B][I] && malloc_refs[B][I] == 0) {
-                /* Found a leak... */
-                fprintf(stderr, "Leak found: %p", malloc_ptrs[B][I]);
-                fprintf(stderr, " %s", malloc_file[B][I]);
-                fprintf(stderr, ":%d", malloc_line[B][I]);
-                fprintf(stderr, " size %d", malloc_size[B][I]);
-                fprintf(stderr, " allocation %d\n", malloc_count[B][I]);
-                leak_sum += malloc_size[B][I];
-            }
-        }
-    }
-
-    if (leak_sum) {
-        fprintf(stderr, "Total leaked memory: %d\n", leak_sum);
-    } else {
-        fprintf(stderr, "No memory leaks detected\n");
-    }
-
-    fprintf(stderr, "----------------------\n");
-}
-
-#endif /* XMALLOC_TRACE */
@@ -32,6 +32,8 @@
 #include "squid.h"
 #include "md5.h"
 
+#if !HAVE_NETTLE_MD5_H
+
 #if HAVE_STRING_H
 #include <string.h>		/* for memcpy() */
 #endif
@@ -252,3 +254,4 @@ SquidMD5Transform(uint32_t buf[4], uint32_t const in[16])
 }
 
 #endif /* !ASM_MD5 */
+#endif /* HAVE_ETTLE_MD5_H */
@@ -109,17 +109,15 @@ ntlm_validate_packet(const ntlmhdr * hdr, const int32_t type)
 lstring
 ntlm_fetch_string(const ntlmhdr *packet, const int32_t packet_size, const strhdr * str, const uint32_t flags)
 {
-    int16_t l;			/* length */
-    int32_t o;			/* offset */
     static char buf[NTLM_MAX_FIELD_LENGTH];
     lstring rv;
     char *d;
 
     rv.str = NULL;
     rv.l = -1;
 
-    l = le16toh(str->len);
-    o = le32toh(str->offset);
+    int16_t l = le16toh(str->len);
+    int32_t o = le32toh(str->offset);
     // debug("ntlm_fetch_string(plength=%d,l=%d,o=%d)\n",packet_size,l,o);
 
     if (l < 0 || l > NTLM_MAX_FIELD_LENGTH || o + l > packet_size || o == 0) {
@@ -133,13 +131,13 @@ ntlm_fetch_string(const ntlmhdr *packet, const int32_t packet_size, const strhdr
         unsigned short *s = (unsigned short *)rv.str;
         rv.str = d = buf;
 
-        for (l >>= 1; l; ++s, --l) {
-            unsigned short c = le16toh(*s);
+        for (uint32_t len = (l>>1); len; ++s, --len) {
+            uint16_t c = le16toh(*s);
             if (c > 254 || c == '\0') {
                 fprintf(stderr, "ntlmssp: bad unicode: %04x\n", c);
                 return rv;
             }
-            *d = c;
+            *d = static_cast<char>(c&0xFF);
             ++d;
             ++rv.l;
         }
@@ -171,14 +169,15 @@ ntlm_add_to_payload(const ntlmhdr *packet_hdr,
                     int *payload_length,
                     strhdr * hdr,
                     const char *toadd,
-                    const int toadd_length)
+                    const uint16_t toadd_length)
 {
     int l = (*payload_length);
     memcpy(payload + l, toadd, toadd_length);
 
     hdr->len = htole16(toadd_length);
     hdr->maxlen = htole16(toadd_length);
-    hdr->offset = htole32(l + payload - (char*)packet_hdr);
+    const off_t o = l + reinterpret_cast<const ntlmhdr *>(payload) - packet_hdr;
+    hdr->offset = htole32(o & 0xFFFFFFFF);
     (*payload_length) += toadd_length;
 }
 
@@ -200,12 +199,11 @@ void
 ntlm_make_nonce(char *nonce)
 {
     static unsigned hash;
-    int i;
-    int r = (int) rand();
+    uint32_t r = static_cast<uint32_t>(rand());
     r = (hash ^ r) + r;
 
-    for (i = 0; i < NTLM_NONCE_LEN; ++i) {
-        nonce[i] = r;
+    for (int i = 0; i < NTLM_NONCE_LEN; ++i) {
+        nonce[i] = static_cast<char>(r & 0xFF);
         r = (r >> 2) ^ r;
     }
     hash = r;
@@ -226,7 +224,10 @@ ntlm_make_challenge(ntlm_challenge *ch,
     memcpy(ch->hdr.signature, "NTLMSSP", 8);		/* set the signature */
     ch->hdr.type = htole32(NTLM_CHALLENGE);	/* this is a challenge */
     if (domain != NULL) {
-        ntlm_add_to_payload(&ch->hdr, ch->payload, &pl, &ch->target, domain, strlen(domain));
+        // silently truncate the domain if it exceeds 2^16-1 bytes.
+        // NTLM packets normally expect 2^8 bytes of domain.
+        const uint16_t dlen = strlen(domain) & 0xFFFF;
+        ntlm_add_to_payload(&ch->hdr, ch->payload, &pl, &ch->target, domain, dlen);
     }
     ch->flags = htole32(flags);
     ch->context_low = 0;		/* check this out */
@@ -139,7 +139,7 @@ extern "C" {
                              int *payload_length,
                              strhdr * hdr,
                              const char *toadd,
-                             const int toadd_length);
+                             const uint16_t toadd_length);
 
     /* ************************************************************************* */
     /* Negotiate Packet structures and functions */
@@ -197,7 +197,9 @@ extern "C" {
     /** Generate a challenge request nonce. */
     void ntlm_make_nonce(char *nonce);
 
-    /** Generate a challenge request Blob to be sent to the client. */
+    /** Generate a challenge request Blob to be sent to the client.
+     * Will silently truncate the domain value at 2^16-1 bytes if larger.
+     */
     void ntlm_make_challenge(ntlm_challenge *ch,
                              const char *domain,
                              const char *domain_controller,
@@ -116,7 +116,7 @@ if (groff --help >/dev/null); then
 	if [ ! -d ${tmpdir}/doc/manuals ] ; then
 		mkdir -p ${tmpdir}/doc/manuals
 	fi
-	for f in `ls -1 ${tmpdir}/helpers/*/*/*.8 ${tmpdir}/src/*.8 ${tmpdir}/src/*/*.8 ${tmpdir}/tools/*.1 ${tmpdir}/tools/*.8 ./helpers/*/*/*.8 2>/dev/null` ; do
+	for f in `ls -1 ${tmpdir}/helpers/*/*/*.8 ${tmpdir}/src/*.8 ${tmpdir}/src/*/*.8 ${tmpdir}/tools/squidclient/*.1 ${tmpdir}/tools/*.8 ./helpers/*/*/*.8 2>/dev/null` ; do
 		cp $f ${tmpdir}/doc/manuals/
 	done
 	for f in `ls -1 ${tmpdir}/doc/manuals/*.1  ${tmpdir}/doc/manuals/*.8 2>/dev/null` ; do
@@ -1282,7 +1282,7 @@ PREDEFINED             = __cplusplus \
                          USE_SELECT \
                          USE_SELECT_WIN32 \
                          USE_SQUID_ESI \
-                         USE_SSL \
+                         USE_OPENSSL \
                          USE_LINUX_TPROXY2 \
                          USE_LINUX_TPROXY4 \
                          USE_UNLINKD \
@@ -4,13 +4,13 @@
 #include "HttpRequest.h"
 #include "SquidConfig.h"
 
-#if USE_SSL
+#if USE_OPENSSL
 #include "ssl/support.h"
 
 AccessLogEntry::SslDetails::SslDetails(): user(NULL), bumpMode(::Ssl::bumpEnd)
 {
 }
-#endif /* USE_SSL */
+#endif /* USE_OPENSSL */
 
 void
 AccessLogEntry::getLogClientIp(char *buf, size_t bufsz) const
@@ -45,7 +45,7 @@
 #if ICAP_CLIENT
 #include "adaptation/icap/Elements.h"
 #endif
-#if USE_SSL
+#if USE_OPENSSL
 #include "ssl/gadgets.h"
 #endif
 
@@ -137,7 +137,7 @@ class AccessLogEntry: public RefCountable
         const char *opcode;
     } htcp;
 
-#if USE_SSL
+#if USE_OPENSSL
     /// logging information specific to the SSL protocol
     class SslDetails
     {
@@ -165,7 +165,7 @@ class AccessLogEntry: public RefCountable
                 msec(0),
                 rfc931 (NULL),
                 extuser(NULL),
-#if USE_SSL
+#if USE_OPENSSL
                 ssluser(NULL),
 #endif
                 port(NULL) {
@@ -180,7 +180,7 @@ class AccessLogEntry: public RefCountable
         int msec;
         const char *rfc931;
         const char *extuser;
-#if USE_SSL
+#if USE_OPENSSL
 
         const char *ssluser;
         Ssl::X509_Pointer sslClientCert; ///< cert received from the client
@@ -223,8 +223,7 @@ class AccessLogEntry: public RefCountable
 #endif
 
     // Why is this a sub-class and not a set of real "private:" fields?
-    // It looks like its duplicating HTTPRequestMethod anyway!
-    // TODO: shuffle this to the relevant protocol section OR replace with request->method
+    // TODO: shuffle this to the relevant ICP/HTCP protocol section
     class Private
     {
 
@@ -57,7 +57,7 @@
 #include "acl/SourceAsn.h"
 #include "acl/SourceDomain.h"
 #include "acl/SourceIp.h"
-#if USE_SSL
+#if USE_OPENSSL
 #include "acl/Certificate.h"
 #include "acl/CertificateData.h"
 #include "acl/SslError.h"
@@ -66,7 +66,7 @@
 #include "acl/Strategised.h"
 #include "acl/Strategy.h"
 #include "acl/StringData.h"
-#if USE_SSL
+#if USE_OPENSSL
 #include "acl/ServerCertificate.h"
 #endif
 #include "acl/Tag.h"
@@ -151,7 +151,7 @@ ACLStrategised<char const *> ACLUrlPath::RegistryEntry_(new ACLRegexData, ACLUrl
 ACL::Prototype ACLUrlPort::RegistryProtoype(&ACLUrlPort::RegistryEntry_, "port");
 ACLStrategised<int> ACLUrlPort::RegistryEntry_(new ACLIntRange, ACLUrlPortStrategy::Instance(), "port");
 
-#if USE_SSL
+#if USE_OPENSSL
 ACL::Prototype ACLSslError::RegistryProtoype(&ACLSslError::RegistryEntry_, "ssl_error");
 ACLStrategised<const Ssl::CertErrors *> ACLSslError::RegistryEntry_(new ACLSslErrorData, ACLSslErrorStrategy::Instance(), "ssl_error");
 ACL::Prototype ACLCertificate::UserRegistryProtoype(&ACLCertificate::UserRegistryEntry_, "user_cert");
@@ -30,20 +30,23 @@
  */
 
 #include "acl/forward.h"
+#include "base/CbcPointer.h"
 #include "enums.h"
 #include "icp_opcode.h"
 #include "ip/Address.h"
 
 //TODO: remove, it is unconditionally defined and always used.
 #define PEER_MULTICAST_SIBLINGS 1
 
-#if USE_SSL
+#if HAVE_OPENSSL_SSL_H
 #include <openssl/ssl.h>
 #endif
 
 class CachePeerDomainList;
 class NeighborTypeDomainList;
+class PconnPool;
 class PeerDigest;
+class PeerPoolMgr;
 
 // currently a POD
 class CachePeer
@@ -186,8 +189,14 @@ class CachePeer
     time_t connect_timeout;
     int connect_fail_limit;
     int max_conn;
+    struct {
+        PconnPool *pool; ///< idle connection pool for this peer
+        CbcPointer<PeerPoolMgr> mgr; ///< pool manager
+        int limit; ///< the limit itself
+        bool waitingForClose; ///< a conn must close before we open a standby conn
+    } standby; ///< optional "cache_peer standby=limit" feature
     char *domain;       /* Forced domain */
-#if USE_SSL
+#if USE_OPENSSL
 
     int use_ssl;
     char *sslcert;
@@ -40,7 +40,7 @@ class ClientRequestContext : public RefCountable
 
     void adaptationAccessCheck();
 #endif
-#if USE_SSL
+#if USE_OPENSSL
     /**
      * Initiates and start the acl checklist to check if the a CONNECT
      * request must be bumped.
@@ -77,7 +77,7 @@ class ClientRequestContext : public RefCountable
     bool interpreted_req_hdrs;
     bool tosToClientDone;
     bool nfmarkToClientDone;
-#if USE_SSL
+#if USE_OPENSSL
     bool sslBumpCheckDone;
 #endif
     ErrorState *error; ///< saved error page for centralized/delayed processing
@@ -102,8 +102,8 @@
 
   \par
   The read, write, and accept notifications (scheduled in step #2
-  above) carry the COMM_ERR_CLOSING error flag. When handling
-  COMM_ERR_CLOSING event, the user code should limit
+  above) carry the Comm::ERR_CLOSING error flag. When handling
+  Comm::ERR_CLOSING event, the user code should limit
   descriptor-related processing, especially Comm calls, because
   supported Comm functionality is very limited when the descriptor is
   closing. New code should use the close handlers instead (scheduled
@@ -121,7 +121,7 @@
   Since all notifications are asynchronous, it is possible for a read
   or write notification that was scheduled before comm_close() was
   called to arrive at its destination after comm_close() was called.
-  Such notification will arrive with COMM_ERR_CLOSING flag even though
+  Such notification will arrive with Comm::ERR_CLOSING flag even though
   that flag was not set at the time of the I/O (and the I/O may have
   been successful). This behavior may change.
 
@@ -140,12 +140,12 @@
   instead.
 
   \par
-  COMM_ERR_CLOSING interface will be removed. The read, write, and
+  Comm::ERR_CLOSING interface will be removed. The read, write, and
   accept notifications will not be scheduled after comm_close() is
   called.  New user code should register close handlers instead.
 
   \par
-  When COMM_ERR_CLOSING interface is removed, pending notifications
+  When Comm::ERR_CLOSING interface is removed, pending notifications
   (if any) will be canceled after comm_close() is called. However, the
   cancellation may be removed later if Comm is modified to provide safe
   access to closing descriptors and their fragile state. New user code
@@ -7,7 +7,7 @@
 /* CommCommonCbParams */
 
 CommCommonCbParams::CommCommonCbParams(void *aData):
-        data(cbdataReference(aData)), conn(), flag(COMM_OK), xerrno(0), fd(-1)
+        data(cbdataReference(aData)), conn(), flag(Comm::OK), xerrno(0), fd(-1)
 {
 }
 
@@ -31,7 +31,7 @@ CommCommonCbParams::print(std::ostream &os) const
 
     if (xerrno)
         os << ", errno=" << xerrno;
-    if (flag != COMM_OK)
+    if (flag != Comm::OK)
         os << ", flag=" << flag;
     if (data)
         os << ", data=" << data;
@@ -84,9 +84,9 @@ CommIoCbParams::syncWithComm()
 {
     // change parameters if the call was scheduled before comm_close but
     // is being fired after comm_close
-    if ((conn->fd < 0 || fd_table[conn->fd].closing()) && flag != COMM_ERR_CLOSING) {
-        debugs(5, 3, HERE << "converting late call to COMM_ERR_CLOSING: " << conn);
-        flag = COMM_ERR_CLOSING;
+    if ((conn->fd < 0 || fd_table[conn->fd].closing()) && flag != Comm::ERR_CLOSING) {
+        debugs(5, 3, HERE << "converting late call to Comm::ERR_CLOSING: " << conn);
+        flag = Comm::ERR_CLOSING;
     }
     return true; // now we are in sync and can handle the call
 }
@@ -3,8 +3,8 @@
 
 #include "base/AsyncCall.h"
 #include "base/AsyncJobCalls.h"
+#include "comm/Flag.h"
 #include "comm/forward.h"
-#include "comm_err_t.h"
 #include "MasterXaction.h"
 
 /* CommCalls implement AsyncCall interface for comm_* callbacks.
@@ -24,8 +24,8 @@
 class CommAcceptCbParams;
 typedef void IOACB(const CommAcceptCbParams &params);
 
-typedef void CNCB(const Comm::ConnectionPointer &conn, comm_err_t status, int xerrno, void *data);
-typedef void IOCB(const Comm::ConnectionPointer &conn, char *, size_t size, comm_err_t flag, int xerrno, void *data);
+typedef void CNCB(const Comm::ConnectionPointer &conn, Comm::Flag status, int xerrno, void *data);
+typedef void IOCB(const Comm::ConnectionPointer &conn, char *, size_t size, Comm::Flag flag, int xerrno, void *data);
 
 class CommTimeoutCbParams;
 typedef void CTCB(const CommTimeoutCbParams &params);
@@ -72,12 +72,12 @@ class CommCommonCbParams
      *  - On read calls this is the connection just read from.
      *  - On close calls this describes the connection which is now closed.
      *  - On timeouts this is the connection whose operation timed out.
-     *   + NP: timeouts might also return to the connect/read/write handler with COMM_ERR_TIMEOUT.
+     *   + NP: timeouts might also return to the connect/read/write handler with Comm::TIMEOUT.
      */
     Comm::ConnectionPointer conn;
 
-    comm_err_t flag;  ///< comm layer result status.
-    int xerrno;      ///< The last errno to occur. non-zero if flag is COMM_ERR.
+    Comm::Flag flag;  ///< comm layer result status.
+    int xerrno;      ///< The last errno to occur. non-zero if flag is Comm::COMM_ERROR.
 
     int fd; ///< FD which the call was about. Set by the async call creator.
 private:
@@ -27,7 +27,7 @@ INCLUDES += $(KRB5INCS)
 
 ## Loadable Modules requires LTDL include paths.
 ## Because we need this to use the libray linking headers...
-if USE_LOADABLE_MODULES
+if ENABLE_LOADABLE_MODULES
 INCLUDES += $(INCLTDL)
 endif
 
@@ -53,9 +53,7 @@
 #include "DiskIO/WriteRequest.h"
 #include "globals.h"
 
-#if HAVE_ERRNO_H
-#include <errno.h>
-#endif
+#include <cerrno>
 
 CBDATA_CLASS_INIT(AIODiskFile);
 
@@ -38,9 +38,7 @@
 #include "StatCounters.h"
 #include "win32.h"
 
-#if HAVE_ERRNO_H
-#include <errno.h>
-#endif
+#include <cerrno>
 
 #if _SQUID_WINDOWS_
 VOID CALLBACK IoCompletionRoutine(DWORD dwErrorCode,
@@ -40,9 +40,7 @@
 #include "DiskIO/WriteRequest.h"
 #include "globals.h"
 
-#if HAVE_ERRNO_H
-#include <errno.h>
-#endif
+#include <cerrno>
 
 CBDATA_CLASS_INIT(BlockingFile);
 
@@ -46,6 +46,7 @@
 #include "Store.h"
 #include "unlinkd.h"
 
+#include <cerrno>
 #if HAVE_SYS_IPC_H
 #include <sys/ipc.h>
 #endif
@@ -55,9 +56,6 @@
 #if HAVE_SYS_SHM_H
 #include <sys/shm.h>
 #endif
-#if HAVE_ERRNO_H
-#include <errno.h>
-#endif
 
 diskd_stats_t diskd_stats;
 
@@ -106,20 +106,20 @@ int aioQueueSize(void);
 class DiskThreadsIOStrategy;
 
 struct AIOCounts {
-    int open_start;
-    int open_finish;
-    int close_start;
-    int close_finish;
-    int cancel;
-    int write_start;
-    int write_finish;
-    int read_start;
-    int read_finish;
-    int stat_start;
-    int stat_finish;
-    int unlink_start;
-    int unlink_finish;
-    int check_callback;
+    uint64_t open_start;
+    uint64_t open_finish;
+    uint64_t close_start;
+    uint64_t close_finish;
+    uint64_t cancel;
+    uint64_t write_start;
+    uint64_t write_finish;
+    uint64_t read_start;
+    uint64_t read_finish;
+    uint64_t stat_start;
+    uint64_t stat_finish;
+    uint64_t unlink_start;
+    uint64_t unlink_finish;
+    uint64_t check_callback;
 };
 
 extern AIOCounts squidaio_counts;
@@ -43,9 +43,7 @@
 #include "StatCounters.h"
 #include "Store.h"
 
-#if HAVE_ERRNO_H
-#include <errno.h>
-#endif
+#include <cerrno>
 
 /* === PUBLIC =========================================================== */
 
@@ -196,16 +196,16 @@ void
 DiskThreadsIOStrategy::aioStats(StoreEntry * sentry)
 {
     storeAppendPrintf(sentry, "ASYNC IO Counters:\n");
-    storeAppendPrintf(sentry, "Operation\t# Requests\tNumber serviced\n");
-    storeAppendPrintf(sentry, "open\t%d\t%d\n", squidaio_counts.open_start, squidaio_counts.open_finish);
-    storeAppendPrintf(sentry, "close\t%d\t%d\n", squidaio_counts.close_start, squidaio_counts.close_finish);
-    storeAppendPrintf(sentry, "cancel\t%d\t-\n", squidaio_counts.cancel);
-    storeAppendPrintf(sentry, "write\t%d\t%d\n", squidaio_counts.write_start, squidaio_counts.write_finish);
-    storeAppendPrintf(sentry, "read\t%d\t%d\n", squidaio_counts.read_start, squidaio_counts.read_finish);
-    storeAppendPrintf(sentry, "stat\t%d\t%d\n", squidaio_counts.stat_start, squidaio_counts.stat_finish);
-    storeAppendPrintf(sentry, "unlink\t%d\t%d\n", squidaio_counts.unlink_start, squidaio_counts.unlink_finish);
-    storeAppendPrintf(sentry, "check_callback\t%d\t-\n", squidaio_counts.check_callback);
-    storeAppendPrintf(sentry, "queue\t%d\t-\n", squidaio_get_queue_len());
+    storeAppendPrintf(sentry, "  Operation\t# Requests\tNumber serviced\n");
+    storeAppendPrintf(sentry, "  open\t%" PRIu64 "\t%" PRIu64 "\n", squidaio_counts.open_start, squidaio_counts.open_finish);
+    storeAppendPrintf(sentry, "  close\t%" PRIu64 "\t%" PRIu64 "\n", squidaio_counts.close_start, squidaio_counts.close_finish);
+    storeAppendPrintf(sentry, "  cancel\t%" PRIu64 "\t-\n", squidaio_counts.cancel);
+    storeAppendPrintf(sentry, "  write\t%" PRIu64 "\t%" PRIu64 "\n", squidaio_counts.write_start, squidaio_counts.write_finish);
+    storeAppendPrintf(sentry, "  read\t%" PRIu64 "\t%" PRIu64 "\n", squidaio_counts.read_start, squidaio_counts.read_finish);
+    storeAppendPrintf(sentry, "  stat\t%" PRIu64 "\t%" PRIu64 "\n", squidaio_counts.stat_start, squidaio_counts.stat_finish);
+    storeAppendPrintf(sentry, "  unlink\t%" PRIu64 "\t%" PRIu64 "\n", squidaio_counts.unlink_start, squidaio_counts.unlink_finish);
+    storeAppendPrintf(sentry, "  check_callback\t%" PRIu64 "\t-\n", squidaio_counts.check_callback);
+    storeAppendPrintf(sentry, "  queue\t%d\t-\n", squidaio_get_queue_len());
     squidaio_stats(sentry);
 }
 
@@ -41,11 +41,11 @@
 #include "SquidTime.h"
 #include "Store.h"
 
+#include <cerrno>
 #include <csignal>
 #include <sys/stat.h>
 #include <fcntl.h>
 #include <pthread.h>
-#include <errno.h>
 #include <dirent.h>
 #if HAVE_SCHED_H
 #include <sched.h>
@@ -40,10 +40,10 @@
 #include "SquidTime.h"
 #include "Store.h"
 
+#include <cerrno>
 #include <csignal>
 #include <sys/stat.h>
 #include <fcntl.h>
-#include <errno.h>
 #include <dirent.h>
 
 #define RIDICULOUS_LENGTH	4096
@@ -24,9 +24,8 @@
 #include "StatCounters.h"
 #include "tools.h"
 
-#if HAVE_ERRNO_H
-#include <errno.h>
-#endif
+#include <cerrno>
+
 CBDATA_CLASS_INIT(IpcIoFile);
 
 /// shared memory segment path to use for IpcIoFile maps
@@ -11,15 +11,13 @@
 #include "DiskIO/WriteRequest.h"
 #include "globals.h"
 
+#include <cerrno>
 #if HAVE_SYS_MMAN_H
 #include <sys/mman.h>
 #endif
 #if HAVE_SYS_STAT_H
 #include <sys/stat.h>
 #endif
-#if HAVE_ERRNO_H
-#include <errno.h>
-#endif
 
 // Some systems such as Hurd provide mmap() API but do not support MAP_NORESERVE
 #ifndef MAP_NORESERVE
@@ -80,7 +80,7 @@ class ACLExternal : public ACL
     /* when requiresRequest is made dynamic, review this too */
     //    virtual bool requiresReply() const {return true;}
     virtual bool isProxyAuth() const;
-    virtual wordlist *dump() const;
+    virtual SBufList dump() const;
     virtual bool valid () const;
     virtual bool empty () const;
 
@@ -64,58 +64,88 @@
 #include "mgr/Registration.h"
 #include "neighbors.h"
 #include "pconn.h"
+#include "PeerPoolMgr.h"
 #include "PeerSelectState.h"
 #include "SquidConfig.h"
 #include "SquidTime.h"
 #include "Store.h"
 #include "StoreClient.h"
 #include "urn.h"
 #include "whois.h"
-#if USE_SSL
+#if USE_OPENSSL
 #include "ssl/cert_validate_message.h"
 #include "ssl/Config.h"
 #include "ssl/ErrorDetail.h"
 #include "ssl/helper.h"
+#include "ssl/PeerConnector.h"
 #include "ssl/ServerBump.h"
 #include "ssl/support.h"
 #endif
-#if HAVE_ERRNO_H
-#include <errno.h>
-#endif
+
+#include <cerrno>
 
 static PSC fwdPeerSelectionCompleteWrapper;
 static CLCB fwdServerClosedWrapper;
-#if USE_SSL
-static PF fwdNegotiateSSLWrapper;
-#endif
 static CNCB fwdConnectDoneWrapper;
 
 static OBJH fwdStats;
 
 #define MAX_FWD_STATS_IDX 9
 static int FwdReplyCodes[MAX_FWD_STATS_IDX + 1][Http::scInvalidHeader + 1];
 
-static PconnPool *fwdPconnPool = new PconnPool("server-side");
+static PconnPool *fwdPconnPool = new PconnPool("server-side", NULL);
 CBDATA_CLASS_INIT(FwdState);
 
+#if USE_OPENSSL
+class FwdStatePeerAnswerDialer: public CallDialer, public Ssl::PeerConnector::CbDialer
+{
+public:
+    typedef void (FwdState::*Method)(Ssl::PeerConnectorAnswer &);
+
+    FwdStatePeerAnswerDialer(Method method, FwdState *fwd):
+            method_(method), fwd_(fwd), answer_() {}
+
+    /* CallDialer API */
+    virtual bool canDial(AsyncCall &call) { return fwd_.valid(); }
+    void dial(AsyncCall &call) { ((&(*fwd_))->*method_)(answer_); }
+    virtual void print(std::ostream &os) const {
+        os << '(' << fwd_.get() << ", " << answer_ << ')';
+    }
+
+    /* Ssl::PeerConnector::CbDialer API */
+    virtual Ssl::PeerConnectorAnswer &answer() { return answer_; }
+
+private:
+    Method method_;
+    CbcPointer<FwdState> fwd_;
+    Ssl::PeerConnectorAnswer answer_;
+};
+#endif
+
 void
 FwdState::abort(void* d)
 {
     FwdState* fwd = (FwdState*)d;
     Pointer tmp = fwd; // Grab a temporary pointer to keep the object alive during our scope.
 
     if (Comm::IsConnOpen(fwd->serverConnection())) {
-        comm_remove_close_handler(fwd->serverConnection()->fd, fwdServerClosedWrapper, fwd);
-        debugs(17, 3, HERE << "store entry aborted; closing " <<
-               fwd->serverConnection());
-        fwd->serverConnection()->close();
+        fwd->closeServerConnection("store entry aborted");
     } else {
         debugs(17, 7, HERE << "store entry aborted; no connection to close");
     }
     fwd->serverDestinations.clear();
     fwd->self = NULL;
 }
 
+void
+FwdState::closeServerConnection(const char *reason)
+{
+    debugs(17, 3, "because " << reason << "; " << serverConn);
+    comm_remove_close_handler(serverConn->fd, fwdServerClosedWrapper, this);
+    fwdPconnPool->noteUses(fd_table[serverConn->fd].pconn.uses);
+    serverConn->close();
+}
+
 /**** PUBLIC INTERFACE ********************************************************/
 
 FwdState::FwdState(const Comm::ConnectionPointer &client, StoreEntry * e, HttpRequest * r, const AccessLogEntryPointer &alp):
@@ -229,7 +259,7 @@ FwdState::completed()
             assert(err);
             errorAppendEntry(entry, err);
             err = NULL;
-#if USE_SSL
+#if USE_OPENSSL
             if (request->flags.sslPeek && request->clientConnectionManager.valid()) {
                 CallJobHere1(17, 4, request->clientConnectionManager, ConnStateData,
                              ConnStateData::httpsPeeked, Comm::ConnectionPointer(NULL));
@@ -271,11 +301,8 @@ FwdState::~FwdState()
         calls.connector = NULL;
     }
 
-    if (Comm::IsConnOpen(serverConn)) {
-        comm_remove_close_handler(serverConnection()->fd, fwdServerClosedWrapper, this);
-        debugs(17, 3, HERE << "closing FD " << serverConnection()->fd);
-        serverConn->close();
-    }
+    if (Comm::IsConnOpen(serverConn))
+        closeServerConnection("~FwdState");
 
     serverDestinations.clear();
 
@@ -297,7 +324,7 @@ FwdState::Start(const Comm::ConnectionPointer &clientConn, StoreEntry *entry, Ht
      */
 
     if ( Config.accessList.miss && !request->client_addr.isNoAddr() &&
-            request->protocol != AnyP::PROTO_INTERNAL && request->protocol != AnyP::PROTO_CACHE_OBJECT) {
+            !request->flags.internal && request->url.getScheme() != AnyP::PROTO_CACHE_OBJECT) {
         /**
          * Check if this host is allowed to fetch MISSES from us (miss_access).
          * Intentionally replace the src_addr automatically selected by the checklist code
@@ -337,13 +364,16 @@ FwdState::Start(const Comm::ConnectionPointer &clientConn, StoreEntry *entry, Ht
         return;
     }
 
-    switch (request->protocol) {
-
-    case AnyP::PROTO_INTERNAL:
+    if (request->flags.internal) {
+        debugs(17, 2, "calling internalStart() due to request flag");
         internalStart(clientConn, request, entry);
         return;
+    }
+
+    switch (request->url.getScheme()) {
 
     case AnyP::PROTO_CACHE_OBJECT:
+        debugs(17, 2, "calling CacheManager due to request scheme " << request->url.getScheme());
         CacheManager::GetInstance()->Start(clientConn, request, entry);
         return;
 
@@ -508,18 +538,8 @@ fwdServerClosedWrapper(const CommCloseCbParams &params)
     fwd->serverClosed(params.fd);
 }
 
-#if USE_SSL
-static void
-fwdNegotiateSSLWrapper(int fd, void *data)
-{
-    FwdState *fwd = (FwdState *) data;
-    fwd->negotiateSSL(fd);
-}
-
-#endif
-
 void
-fwdConnectDoneWrapper(const Comm::ConnectionPointer &conn, comm_err_t status, int xerrno, void *data)
+fwdConnectDoneWrapper(const Comm::ConnectionPointer &conn, Comm::Flag status, int xerrno, void *data)
 {
     FwdState *fwd = (FwdState *) data;
     fwd->connectDone(conn, status, xerrno);
@@ -598,7 +618,11 @@ FwdState::checkRetriable()
 void
 FwdState::serverClosed(int fd)
 {
-    debugs(17, 2, HERE << "FD " << fd << " " << entry->url());
+    // XXX: fd is often -1 here
+    debugs(17, 2, "FD " << fd << " " << entry->url() << " after " <<
+           (fd >= 0 ? fd_table[fd].pconn.uses : -1) << " requests");
+    if (fd >= 0 && serverConnection()->fd == fd)
+        fwdPconnPool->noteUses(fd_table[fd].pconn.uses);
     retryOrBail();
 }
 
@@ -646,367 +670,10 @@ FwdState::handleUnregisteredServerEnd()
     retryOrBail();
 }
 
-#if USE_SSL
-void
-FwdState::negotiateSSL(int fd)
-{
-    unsigned long ssl_lib_error = SSL_ERROR_NONE;
-    SSL *ssl = fd_table[fd].ssl;
-    int ret;
-
-    if ((ret = SSL_connect(ssl)) <= 0) {
-        int ssl_error = SSL_get_error(ssl, ret);
-#ifdef EPROTO
-        int sysErrNo = EPROTO;
-#else
-        int sysErrNo = EACCES;
-#endif
-
-        switch (ssl_error) {
-
-        case SSL_ERROR_WANT_READ:
-            Comm::SetSelect(fd, COMM_SELECT_READ, fwdNegotiateSSLWrapper, this, 0);
-            return;
-
-        case SSL_ERROR_WANT_WRITE:
-            Comm::SetSelect(fd, COMM_SELECT_WRITE, fwdNegotiateSSLWrapper, this, 0);
-            return;
-
-        case SSL_ERROR_SSL:
-        case SSL_ERROR_SYSCALL:
-            ssl_lib_error = ERR_get_error();
-            debugs(81, DBG_IMPORTANT, "fwdNegotiateSSL: Error negotiating SSL connection on FD " << fd <<
-                   ": " << ERR_error_string(ssl_lib_error, NULL) << " (" << ssl_error <<
-                   "/" << ret << "/" << errno << ")");
-
-            // store/report errno when ssl_error is SSL_ERROR_SYSCALL, ssl_lib_error is 0, and ret is -1
-            if (ssl_error == SSL_ERROR_SYSCALL && ret == -1 && ssl_lib_error == 0)
-                sysErrNo = errno;
-
-            // falling through to complete error handling
-
-        default:
-            // TODO: move into a method before merge
-            Ssl::ErrorDetail *errDetails;
-            Ssl::ErrorDetail *errFromFailure = (Ssl::ErrorDetail *)SSL_get_ex_data(ssl, ssl_ex_index_ssl_error_detail);
-            if (errFromFailure != NULL) {
-                // The errFromFailure is attached to the ssl object
-                // and will be released when ssl object destroyed.
-                // Copy errFromFailure to a new Ssl::ErrorDetail object.
-                errDetails = new Ssl::ErrorDetail(*errFromFailure);
-            } else {
-                // server_cert can be NULL here
-                X509 *server_cert = SSL_get_peer_certificate(ssl);
-                errDetails = new Ssl::ErrorDetail(SQUID_ERR_SSL_HANDSHAKE, server_cert, NULL);
-                X509_free(server_cert);
-            }
-
-            if (ssl_lib_error != SSL_ERROR_NONE)
-                errDetails->setLibError(ssl_lib_error);
-
-            if (request->clientConnectionManager.valid()) {
-                // remember the server certificate from the ErrorDetail object
-                if (Ssl::ServerBump *serverBump = request->clientConnectionManager->serverBump()) {
-                    serverBump->serverCert.resetAndLock(errDetails->peerCert());
-
-                    // remember validation errors, if any
-                    if (Ssl::CertErrors *errs = static_cast<Ssl::CertErrors*>(SSL_get_ex_data(ssl, ssl_ex_index_ssl_errors)))
-                        serverBump->sslErrors = cbdataReference(errs);
-                }
-
-                // For intercepted connections, set the host name to the server
-                // certificate CN. Otherwise, we just hope that CONNECT is using
-                // a user-entered address (a host name or a user-entered IP).
-                const bool isConnectRequest = !request->clientConnectionManager->port->flags.isIntercepted();
-                if (request->flags.sslPeek && !isConnectRequest) {
-                    if (X509 *srvX509 = errDetails->peerCert()) {
-                        if (const char *name = Ssl::CommonHostName(srvX509)) {
-                            request->SetHost(name);
-                            debugs(83, 3, HERE << "reset request host: " << name);
-                        }
-                    }
-                }
-            }
-
-            ErrorState *const anErr = makeConnectingError(ERR_SECURE_CONNECT_FAIL);
-            anErr->xerrno = sysErrNo;
-            anErr->detail = errDetails;
-            fail(anErr);
-
-            if (serverConnection()->getPeer()) {
-                peerConnectFailed(serverConnection()->getPeer());
-            }
-
-            serverConn->close();
-            return;
-        }
-    }
-
-    if (request->clientConnectionManager.valid()) {
-        // remember the server certificate from the ErrorDetail object
-        if (Ssl::ServerBump *serverBump = request->clientConnectionManager->serverBump()) {
-            serverBump->serverCert.reset(SSL_get_peer_certificate(ssl));
-
-            // remember validation errors, if any
-            if (Ssl::CertErrors *errs = static_cast<Ssl::CertErrors *>(SSL_get_ex_data(ssl, ssl_ex_index_ssl_errors)))
-                serverBump->sslErrors = cbdataReference(errs);
-        }
-    }
-
-    if (serverConnection()->getPeer() && !SSL_session_reused(ssl)) {
-        if (serverConnection()->getPeer()->sslSession)
-            SSL_SESSION_free(serverConnection()->getPeer()->sslSession);
-
-        serverConnection()->getPeer()->sslSession = SSL_get1_session(ssl);
-    }
-
-    if (Ssl::TheConfig.ssl_crt_validator) {
-        Ssl::CertValidationRequest validationRequest;
-        // WARNING: Currently we do not use any locking for any of the
-        // members of the Ssl::CertValidationRequest class. In this code the
-        // Ssl::CertValidationRequest object used only to pass data to
-        // Ssl::CertValidationHelper::submit method.
-        validationRequest.ssl = ssl;
-        validationRequest.domainName = request->GetHost();
-        if (Ssl::CertErrors *errs = static_cast<Ssl::CertErrors *>(SSL_get_ex_data(ssl, ssl_ex_index_ssl_errors)))
-            // validationRequest disappears on return so no need to cbdataReference
-            validationRequest.errors = errs;
-        else
-            validationRequest.errors = NULL;
-        try {
-            debugs(83, 5, "Sending SSL certificate for validation to ssl_crtvd.");
-            Ssl::CertValidationHelper::GetInstance()->sslSubmit(validationRequest, sslCrtvdHandleReplyWrapper, this);
-            return;
-        } catch (const std::exception &e) {
-            debugs(33, DBG_IMPORTANT, "ERROR: Failed to compose ssl_crtvd " <<
-                   "request for " << validationRequest.domainName <<
-                   " certificate: " << e.what() << "; will now block to " <<
-                   "validate that certificate.");
-            // fall through to do blocking in-process generation.
-            ErrorState *anErr = new ErrorState(ERR_GATEWAY_FAILURE, Http::scInternalServerError, request);
-            fail(anErr);
-            if (serverConnection()->getPeer()) {
-                peerConnectFailed(serverConnection()->getPeer());
-            }
-            serverConn->close();
-            self = NULL;
-            return;
-        }
-    }
-
-    dispatch();
-}
-
-void
-FwdState::sslCrtvdHandleReplyWrapper(void *data, Ssl::CertValidationResponse const &validationResponse)
-{
-    FwdState * fwd = (FwdState *)(data);
-    fwd->sslCrtvdHandleReply(validationResponse);
-}
-
-void
-FwdState::sslCrtvdHandleReply(Ssl::CertValidationResponse const &validationResponse)
-{
-    Ssl::CertErrors *errs = NULL;
-    Ssl::ErrorDetail *errDetails = NULL;
-    bool validatorFailed = false;
-    if (!Comm::IsConnOpen(serverConnection())) {
-        return;
-    }
-
-    debugs(83,5, request->GetHost() << " cert validation result: " << validationResponse.resultCode);
-
-    if (validationResponse.resultCode == HelperReply::Error)
-        errs = sslCrtvdCheckForErrors(validationResponse, errDetails);
-    else if (validationResponse.resultCode != HelperReply::Okay)
-        validatorFailed = true;
-
-    if (!errDetails && !validatorFailed) {
-        dispatch();
-        return;
-    }
-
-    ErrorState *anErr = NULL;
-    if (validatorFailed) {
-        anErr = new ErrorState(ERR_GATEWAY_FAILURE, Http::scInternalServerError, request);
-    }  else {
-
-        // Check the list error with
-        if (errDetails && request->clientConnectionManager.valid()) {
-            // remember the server certificate from the ErrorDetail object
-            if (Ssl::ServerBump *serverBump = request->clientConnectionManager->serverBump()) {
-                // remember validation errors, if any
-                if (errs) {
-                    if (serverBump->sslErrors)
-                        cbdataReferenceDone(serverBump->sslErrors);
-                    serverBump->sslErrors = cbdataReference(errs);
-                }
-            }
-        }
-
-        anErr = makeConnectingError(ERR_SECURE_CONNECT_FAIL);
-        anErr->detail = errDetails;
-        /*anErr->xerrno= Should preserved*/
-    }
-
-    fail(anErr);
-    if (serverConnection()->getPeer()) {
-        peerConnectFailed(serverConnection()->getPeer());
-    }
-    serverConn->close();
-    self = NULL;
-    return;
-}
-
-/// Checks errors in the cert. validator response against sslproxy_cert_error.
-/// The first honored error, if any, is returned via errDetails parameter.
-/// The method returns all seen errors except SSL_ERROR_NONE as Ssl::CertErrors.
-Ssl::CertErrors *
-FwdState::sslCrtvdCheckForErrors(Ssl::CertValidationResponse const &resp, Ssl::ErrorDetail *& errDetails)
-{
-    Ssl::CertErrors *errs = NULL;
-
-    ACLFilledChecklist *check = NULL;
-    if (acl_access *acl = Config.ssl_client.cert_error)
-        check = new ACLFilledChecklist(acl, request, dash_str);
-
-    SSL *ssl = fd_table[serverConnection()->fd].ssl;
-    typedef Ssl::CertValidationResponse::RecvdErrors::const_iterator SVCRECI;
-    for (SVCRECI i = resp.errors.begin(); i != resp.errors.end(); ++i) {
-        debugs(83, 7, "Error item: " << i->error_no << " " << i->error_reason);
-
-        assert(i->error_no != SSL_ERROR_NONE);
-
-        if (!errDetails) {
-            bool allowed = false;
-            if (check) {
-                check->sslErrors = new Ssl::CertErrors(Ssl::CertError(i->error_no, i->cert.get()));
-                if (check->fastCheck() == ACCESS_ALLOWED)
-                    allowed = true;
-            }
-            // else the Config.ssl_client.cert_error access list is not defined
-            // and the first error will cause the error page
-
-            if (allowed) {
-                debugs(83, 3, "bypassing SSL error " << i->error_no << " in " << "buffer");
-            } else {
-                debugs(83, 5, "confirming SSL error " << i->error_no);
-                X509 *brokenCert = i->cert.get();
-                Ssl::X509_Pointer peerCert(SSL_get_peer_certificate(ssl));
-                const char *aReason = i->error_reason.empty() ? NULL : i->error_reason.c_str();
-                errDetails = new Ssl::ErrorDetail(i->error_no, peerCert.get(), brokenCert, aReason);
-            }
-            if (check) {
-                delete check->sslErrors;
-                check->sslErrors = NULL;
-            }
-        }
-
-        if (!errs)
-            errs = new Ssl::CertErrors(Ssl::CertError(i->error_no, i->cert.get()));
-        else
-            errs->push_back_unique(Ssl::CertError(i->error_no, i->cert.get()));
-    }
-    if (check)
-        delete check;
-
-    return errs;
-}
-
-void
-FwdState::initiateSSL()
-{
-    SSL *ssl;
-    SSL_CTX *sslContext = NULL;
-    const CachePeer *peer = serverConnection()->getPeer();
-    int fd = serverConnection()->fd;
-
-    if (peer) {
-        assert(peer->use_ssl);
-        sslContext = peer->sslContext;
-    } else {
-        sslContext = Config.ssl_client.sslContext;
-    }
-
-    assert(sslContext);
-
-    if ((ssl = SSL_new(sslContext)) == NULL) {
-        debugs(83, DBG_IMPORTANT, "fwdInitiateSSL: Error allocating handle: " << ERR_error_string(ERR_get_error(), NULL)  );
-        ErrorState *anErr = new ErrorState(ERR_SOCKET_FAILURE, Http::scInternalServerError, request);
-        // TODO: create Ssl::ErrorDetail with OpenSSL-supplied error code
-        fail(anErr);
-        self = NULL;		// refcounted
-        return;
-    }
-
-    SSL_set_fd(ssl, fd);
-
-    if (peer) {
-        if (peer->ssldomain)
-            SSL_set_ex_data(ssl, ssl_ex_index_server, peer->ssldomain);
-
-#if NOT_YET
-
-        else if (peer->name)
-            SSL_set_ex_data(ssl, ssl_ex_index_server, peer->name);
-
-#endif
-
-        else
-            SSL_set_ex_data(ssl, ssl_ex_index_server, peer->host);
-
-        if (peer->sslSession)
-            SSL_set_session(ssl, peer->sslSession);
-
-    } else {
-        // While we are peeking at the certificate, we may not know the server
-        // name that the client will request (after interception or CONNECT)
-        // unless it was the CONNECT request with a user-typed address.
-        const char *hostname = request->GetHost();
-        const bool hostnameIsIp = request->GetHostIsNumeric();
-        const bool isConnectRequest = request->clientConnectionManager.valid() &&
-                                      !request->clientConnectionManager->port->flags.isIntercepted();
-        if (!request->flags.sslPeek || isConnectRequest)
-            SSL_set_ex_data(ssl, ssl_ex_index_server, (void*)hostname);
-
-        // Use SNI TLS extension only when we connect directly
-        // to the origin server and we know the server host name.
-        if (!hostnameIsIp)
-            Ssl::setClientSNI(ssl, hostname);
-    }
-
-    // If CertValidation Helper used do not lookup checklist for errors,
-    // but keep a list of errors to send it to CertValidator
-    if (!Ssl::TheConfig.ssl_crt_validator) {
-        // Create the ACL check list now, while we have access to more info.
-        // The list is used in ssl_verify_cb() and is freed in ssl_free().
-        if (acl_access *acl = Config.ssl_client.cert_error) {
-            ACLFilledChecklist *check = new ACLFilledChecklist(acl, request, dash_str);
-            SSL_set_ex_data(ssl, ssl_ex_index_cert_error_check, check);
-        }
-    }
-
-    // store peeked cert to check SQUID_X509_V_ERR_CERT_CHANGE
-    X509 *peeked_cert;
-    if (request->clientConnectionManager.valid() &&
-            request->clientConnectionManager->serverBump() &&
-            (peeked_cert = request->clientConnectionManager->serverBump()->serverCert.get())) {
-        CRYPTO_add(&(peeked_cert->references),1,CRYPTO_LOCK_X509);
-        SSL_set_ex_data(ssl, ssl_ex_index_ssl_peeked_cert, peeked_cert);
-    }
-
-    fd_table[fd].ssl = ssl;
-    fd_table[fd].read_method = &ssl_read_method;
-    fd_table[fd].write_method = &ssl_write_method;
-    negotiateSSL(fd);
-}
-
-#endif
-
 void
-FwdState::connectDone(const Comm::ConnectionPointer &conn, comm_err_t status, int xerrno)
+FwdState::connectDone(const Comm::ConnectionPointer &conn, Comm::Flag status, int xerrno)
 {
-    if (status != COMM_OK) {
+    if (status != Comm::OK) {
         ErrorState *const anErr = makeConnectingError(ERR_CONNECT_FAIL);
         anErr->xerrno = xerrno;
         fail(anErr);
@@ -1032,12 +699,19 @@ FwdState::connectDone(const Comm::ConnectionPointer &conn, comm_err_t status, in
     if (serverConnection()->getPeer())
         peerConnectSucceded(serverConnection()->getPeer());
 
-#if USE_SSL
+#if USE_OPENSSL
     if (!request->flags.pinned) {
         if ((serverConnection()->getPeer() && serverConnection()->getPeer()->use_ssl) ||
-                (!serverConnection()->getPeer() && request->protocol == AnyP::PROTO_HTTPS) ||
+                (!serverConnection()->getPeer() && request->url.getScheme() == AnyP::PROTO_HTTPS) ||
                 request->flags.sslPeek) {
-            initiateSSL();
+
+            HttpRequest::Pointer requestPointer = request;
+            AsyncCall::Pointer callback = asyncCall(17,4,
+                                                    "FwdState::ConnectedToPeer",
+                                                    FwdStatePeerAnswerDialer(&FwdState::connectedToPeer, this));
+            Ssl::PeerConnector *connector =
+                new Ssl::PeerConnector(requestPointer, serverConnection(), callback);
+            AsyncJob::Start(connector); // will call our callback
             return;
         }
     }
@@ -1046,6 +720,21 @@ FwdState::connectDone(const Comm::ConnectionPointer &conn, comm_err_t status, in
     dispatch();
 }
 
+#if USE_OPENSSL
+void
+FwdState::connectedToPeer(Ssl::PeerConnectorAnswer &answer)
+{
+    if (ErrorState *error = answer.error.get()) {
+        fail(error);
+        answer.error.clear(); // preserve error for errorSendComplete()
+        self = NULL;
+        return;
+    }
+
+    dispatch();
+}
+#endif
+
 void
 FwdState::connectTimeout(int fd)
 {
@@ -1054,7 +743,7 @@ FwdState::connectTimeout(int fd)
     assert(fd == serverDestinations[0]->fd);
 
     if (entry->isEmpty()) {
-        ErrorState *anErr = new ErrorState(ERR_CONNECT_FAIL, Http::scGateway_Timeout, request);
+        ErrorState *anErr = new ErrorState(ERR_CONNECT_FAIL, Http::scGatewayTimeout, request);
         anErr->xerrno = ETIMEDOUT;
         fail(anErr);
 
@@ -1151,7 +840,7 @@ FwdState::connectStart()
     // This does not increase the total number of connections because we just
     // closed the connection that failed the race. And re-pinning assumes this.
     if (pconnRace != raceHappened)
-        temp = fwdPconnPool->pop(serverDestinations[0], host, checkRetriable());
+        temp = pconnPop(serverDestinations[0], host);
 
     const bool openedPconn = Comm::IsConnOpen(temp);
     pconnRace = openedPconn ? racePossible : raceImpossible;
@@ -1191,18 +880,7 @@ FwdState::connectStart()
     entry->mem_obj->checkUrlChecksum();
 #endif
 
-    /* Get the server side TOS and Netfilter mark to be set on the connection. */
-    if (Ip::Qos::TheConfig.isAclTosActive()) {
-        serverDestinations[0]->tos = GetTosToServer(request);
-    }
-#if SO_MARK && USE_LIBCAP
-    serverDestinations[0]->nfmark = GetNfmarkToServer(request);
-    debugs(17, 3, "fwdConnectStart: got outgoing addr " << serverDestinations[0]->local << ", tos " << int(serverDestinations[0]->tos)
-           << ", netfilter mark " << serverDestinations[0]->nfmark);
-#else
-    serverDestinations[0]->nfmark = 0;
-    debugs(17, 3, "fwdConnectStart: got outgoing addr " << serverDestinations[0]->local << ", tos " << int(serverDestinations[0]->tos));
-#endif
+    GetMarkingsToServer(request, *serverDestinations[0]);
 
     calls.connector = commCbCall(17,3, "fwdConnectDoneWrapper", CommConnectCbPtrFun(fwdConnectDoneWrapper, this));
     Comm::ConnOpener *cs = new Comm::ConnOpener(serverDestinations[0], calls.connector, ctimeout);
@@ -1214,7 +892,7 @@ FwdState::connectStart()
 void
 FwdState::dispatch()
 {
-    debugs(17, 3, HERE << clientConn << ": Fetching '" << RequestMethodStr(request->method) << " " << entry->url() << "'");
+    debugs(17, 3, clientConn << ": Fetching " << request->method << ' ' << entry->url());
     /*
      * Assert that server_fd is set.  This is to guarantee that fwdState
      * is attached to something and will be deallocated when server_fd
@@ -1224,7 +902,7 @@ FwdState::dispatch()
 
     fd_note(serverConnection()->fd, entry->url());
 
-    fd_table[serverConnection()->fd].noteUse(fwdPconnPool);
+    fd_table[serverConnection()->fd].noteUse();
 
     /*assert(!EBIT_TEST(entry->flags, ENTRY_DISPATCHED)); */
     assert(entry->ping_status != PING_WAITING);
@@ -1258,7 +936,7 @@ FwdState::dispatch()
     }
 #endif
 
-#if USE_SSL
+#if USE_OPENSSL
     if (request->flags.sslPeek) {
         CallJobHere1(17, 4, request->clientConnectionManager, ConnStateData,
                      ConnStateData::httpsPeeked, serverConnection());
@@ -1278,8 +956,8 @@ FwdState::dispatch()
         request->peer_login = NULL;
         request->peer_domain = NULL;
 
-        switch (request->protocol) {
-#if USE_SSL
+        switch (request->url.getScheme()) {
+#if USE_OPENSSL
 
         case AnyP::PROTO_HTTPS:
             httpStart(this);
@@ -1300,8 +978,6 @@ FwdState::dispatch()
 
         case AnyP::PROTO_CACHE_OBJECT:
 
-        case AnyP::PROTO_INTERNAL:
-
         case AnyP::PROTO_URN:
             fatal_dump("Should never get here");
             break;
@@ -1385,7 +1061,7 @@ ErrorState *
 FwdState::makeConnectingError(const err_type type) const
 {
     return new ErrorState(type, request->flags.needValidation ?
-                          Http::scGateway_Timeout : Http::scServiceUnavailable, request);
+                          Http::scGatewayTimeout : Http::scServiceUnavailable, request);
 }
 
 static void
@@ -1424,7 +1100,7 @@ FwdState::reforwardableStatus(const Http::StatusCode s) const
 
     case Http::scBadGateway:
 
-    case Http::scGateway_Timeout:
+    case Http::scGatewayTimeout:
         return true;
 
     case Http::scForbidden:
@@ -1459,6 +1135,22 @@ FwdState::pconnPush(Comm::ConnectionPointer &conn, const char *domain)
     }
 }
 
+Comm::ConnectionPointer
+FwdState::pconnPop(const Comm::ConnectionPointer &dest, const char *domain)
+{
+    // always call shared pool first because we need to close an idle
+    // connection there if we have to use a standby connection.
+    Comm::ConnectionPointer conn = fwdPconnPool->pop(dest, domain, checkRetriable());
+    if (!Comm::IsConnOpen(conn)) {
+        // either there was no pconn to pop or this is not a retriable xaction
+        if (CachePeer *peer = dest->getPeer()) {
+            if (peer->standby.pool)
+                conn = peer->standby.pool->pop(dest, domain, true);
+        }
+    }
+    return conn; // open, closed, or nil
+}
+
 void
 FwdState::initModule()
 {
@@ -1584,3 +1276,20 @@ GetNfmarkToServer(HttpRequest * request)
     ACLFilledChecklist ch(NULL, request, NULL);
     return aclMapNfmark(Ip::Qos::TheConfig.nfmarkToServer, &ch);
 }
+
+void
+GetMarkingsToServer(HttpRequest * request, Comm::Connection &conn)
+{
+    // Get the server side TOS and Netfilter mark to be set on the connection.
+    if (Ip::Qos::TheConfig.isAclTosActive()) {
+        conn.tos = GetTosToServer(request);
+        debugs(17, 3, "from " << conn.local << " tos " << int(conn.tos));
+    }
+
+#if SO_MARK && USE_LIBCAP
+    conn.nfmark = GetNfmarkToServer(request);
+    debugs(17, 3, "from " << conn.local << " netfilter mark " << conn.nfmark);
+#else
+    conn.nfmark = 0;
+#endif
+}
@@ -8,22 +8,25 @@
 #include "fde.h"
 #include "http/StatusCode.h"
 #include "ip/Address.h"
-#if USE_SSL
+#if USE_OPENSSL
 #include "ssl/support.h"
 #endif
 
 /* forward decls */
 
 class AccessLogEntry;
 typedef RefCount<AccessLogEntry> AccessLogEntryPointer;
+class PconnPool;
+typedef RefCount<PconnPool> PconnPoolPointer;
 class ErrorState;
 class HttpRequest;
 
-#if USE_SSL
+#if USE_OPENSSL
 namespace Ssl
 {
 class ErrorDetail;
 class CertValidationResponse;
+class PeerConnectorAnswer;
 };
 #endif
 
@@ -39,6 +42,9 @@ tos_t GetTosToServer(HttpRequest * request);
  */
 nfmark_t GetNfmarkToServer(HttpRequest * request);
 
+/// Sets initial TOS value and Netfilter for the future outgoing connection.
+void GetMarkingsToServer(HttpRequest * request, Comm::Connection &conn);
+
 class HelperReply;
 
 class FwdState : public RefCountable
@@ -67,13 +73,14 @@ class FwdState : public RefCountable
     bool reforwardableStatus(const Http::StatusCode s) const;
     void serverClosed(int fd);
     void connectStart();
-    void connectDone(const Comm::ConnectionPointer & conn, comm_err_t status, int xerrno);
+    void connectDone(const Comm::ConnectionPointer & conn, Comm::Flag status, int xerrno);
     void connectTimeout(int fd);
-    void initiateSSL();
-    void negotiateSSL(int fd);
     bool checkRetry();
     bool checkRetriable();
     void dispatch();
+    /// Pops a connection from connection pool if available. If not
+    /// checks the peer stand-by connection pool for available connection.
+    Comm::ConnectionPointer pconnPop(const Comm::ConnectionPointer &dest, const char *domain);
     void pconnPush(Comm::ConnectionPointer & conn, const char *domain);
 
     bool dontRetry() { return flags.dont_retry; }
@@ -83,14 +90,6 @@ class FwdState : public RefCountable
     /** return a ConnectionPointer to the current server connection (may or may not be open) */
     Comm::ConnectionPointer const & serverConnection() const { return serverConn; };
 
-#if USE_SSL
-    /// Callback function called when squid receive message from cert validator helper
-    static void sslCrtvdHandleReplyWrapper(void *data, Ssl::CertValidationResponse const &);
-    /// Process response from cert validator helper
-    void sslCrtvdHandleReply(Ssl::CertValidationResponse const &);
-    /// Check SSL errors returned from cert validator against sslproxy_cert_error access list
-    Ssl::CertErrors *sslCrtvdCheckForErrors(Ssl::CertValidationResponse const &, Ssl::ErrorDetail *&);
-#endif
 private:
     // hidden for safer management of self; use static fwdStart
     FwdState(const Comm::ConnectionPointer &client, StoreEntry *, HttpRequest *, const AccessLogEntryPointer &alp);
@@ -104,8 +103,14 @@ class FwdState : public RefCountable
     void completed();
     void retryOrBail();
     ErrorState *makeConnectingError(const err_type type) const;
+#if USE_OPENSSL
+    void connectedToPeer(Ssl::PeerConnectorAnswer &answer);
+#endif
     static void RegisterWithCacheManager(void);
 
+    /// stops monitoring server connection for closure and updates pconn stats
+    void closeServerConnection(const char *reason);
+
 public:
     StoreEntry *entry;
     HttpRequest *request;
@@ -111,6 +111,7 @@ static const HttpHeaderFieldAttrs HeadersAttrs[] = {
     {"ETag", HDR_ETAG, ftETag},
     {"Expect", HDR_EXPECT, ftStr},
     {"Expires", HDR_EXPIRES, ftDate_1123},
+    {"Forwarded", HDR_FORWARDED, ftStr},
     {"From", HDR_FROM, ftStr},
     {"Host", HDR_HOST, ftStr},
     {"HTTP2-Settings", HDR_HTTP2_SETTINGS, ftStr}, /* for now */
@@ -216,6 +217,7 @@ static http_hdr_type ListHeadersArr[] = {
 #endif
     HDR_SURROGATE_CAPABILITY,
     HDR_SURROGATE_CONTROL,
+    HDR_FORWARDED,
     HDR_X_FORWARDED_FOR
 };
 
@@ -267,7 +269,7 @@ static http_hdr_type RequestHeadersArr[] = {
     HDR_ORIGIN,
     HDR_PROXY_CONNECTION,
     HDR_PROXY_AUTHORIZATION, HDR_RANGE, HDR_REFERER, HDR_REQUEST_RANGE,
-    HDR_USER_AGENT, HDR_X_FORWARDED_FOR, HDR_SURROGATE_CAPABILITY
+    HDR_USER_AGENT, HDR_FORWARDED, HDR_X_FORWARDED_FOR, HDR_SURROGATE_CAPABILITY
 };
 
 static HttpHeaderMask HopByHopHeadersMask;
@@ -83,6 +83,7 @@ typedef enum {
     HDR_ETAG,                           /**< RFC 2608, 2616 */
     HDR_EXPECT,                         /**< RFC 2616, 2616 */
     HDR_EXPIRES,                        /**< RFC 2608, 2616 */
+    HDR_FORWARDED,                      /**< RFC 7239 */
     HDR_FROM,                           /**< RFC 2608, 2616 */
     HDR_HOST,                           /**< RFC 2608, 2616 */
     HDR_HTTP2_SETTINGS,                 /**< HTTP/2.0 upgrade header. see draft-ietf-httpbis-http2-04 */
@@ -137,7 +138,7 @@ typedef enum {
     HDR_AUTHENTICATION_INFO,            /**< RFC 2617 */
     HDR_X_CACHE,                        /**< Squid custom header */
     HDR_X_CACHE_LOOKUP,	                /**< Squid custom header. temporary hack that became de-facto. TODO remove */
-    HDR_X_FORWARDED_FOR,                /**< Squid custom header */
+    HDR_X_FORWARDED_FOR,                /**< obsolete Squid custom header */
     HDR_X_REQUEST_URI,                  /**< Squid custom header appended if ADD_X_REQUEST_URI is defined */
     HDR_X_SQUID_ERROR,                  /**< Squid custom header on generated error responses */
 #if X_ACCELERATOR_VARY
@@ -176,7 +177,7 @@ typedef enum {
 #endif
     hoRequest,
     hoReply,
-#if USE_SSL
+#if USE_OPENSSL
     hoErrorDetail,
 #endif
     hoEnd
@@ -50,15 +50,13 @@
 #include "Store.h"
 #include "StrList.h"
 
-#if USE_SSL
+#if USE_OPENSSL
 #include "ssl/support.h"
 #endif
 
 #include <algorithm>
+#include <cerrno>
 #include <string>
-#if HAVE_ERRNO_H
-#include <errno.h>
-#endif
 
 static void httpHeaderPutStrvf(HttpHeader * hdr, http_hdr_type id, const char *fmt, va_list vargs);
 
@@ -41,7 +41,7 @@
 #include "SquidConfig.h"
 
 HttpMsg::HttpMsg(http_hdr_owner_type owner): header(owner),
-        cache_control(NULL), hdr_sz(0), content_length(0), protocol(AnyP::PROTO_NONE),
+        cache_control(NULL), hdr_sz(0), content_length(0),
         pstate(psReadyToParseStartLine)
 {}
 
@@ -67,6 +67,8 @@ class HttpMsg : public RefCountable
     bool persistent() const;
 
 public:
+    /// HTTP-Version field in the first line of the message.
+    /// see RFC 7230 section 3.1
     Http::ProtocolVersion http_ver;
 
     HttpHeader header;
@@ -80,8 +82,6 @@ class HttpMsg : public RefCountable
 
     int64_t content_length;
 
-    AnyP::ProtocolType protocol;
-
     HttpMsgParseState pstate;   /* the current parsing state */
 
     BodyPipe::Pointer body_pipe; // optional pipeline to receive message body
@@ -604,7 +604,6 @@ HttpReply::clone() const
     rep->pstate = pstate;
     rep->body_pipe = body_pipe;
 
-    rep->protocol = protocol;
     // keep_alive is handled in hdrCacheInit()
     return rep;
 }
@@ -82,15 +82,15 @@ void
 HttpRequest::initHTTP(const HttpRequestMethod& aMethod, AnyP::ProtocolType aProtocol, const char *aUrlpath)
 {
     method = aMethod;
-    protocol = aProtocol;
+    url.setScheme(aProtocol);
     urlpath = aUrlpath;
 }
 
 void
 HttpRequest::init()
 {
     method = Http::METHOD_NONE;
-    protocol = AnyP::PROTO_NONE;
+    url.clear();
     urlpath = NULL;
     login[0] = '\0';
     host[0] = '\0';
@@ -150,6 +150,7 @@ HttpRequest::clean()
 
     safe_free(vary_headers);
 
+    url.clear();
     urlpath.clean();
 
     header.clean();
@@ -197,7 +198,7 @@ HttpRequest::reset()
 HttpRequest *
 HttpRequest::clone() const
 {
-    HttpRequest *copy = new HttpRequest(method, protocol, urlpath.termedBuf());
+    HttpRequest *copy = new HttpRequest(method, url.getScheme(), urlpath.termedBuf());
     // TODO: move common cloning clone to Msg::copyTo() or copy ctor
     copy->header.append(&header);
     copy->hdrCacheInit();
@@ -391,8 +392,8 @@ HttpRequest::pack(Packer * p)
 {
     assert(p);
     /* pack request-line */
-    packerPrintf(p, "%s " SQUIDSTRINGPH " HTTP/%d.%d\r\n",
-                 RequestMethodStr(method), SQUIDSTRINGPRINT(urlpath),
+    packerPrintf(p, SQUIDSBUFPH " " SQUIDSTRINGPH " HTTP/%d.%d\r\n",
+                 SQUIDSBUFPRINT(method.image()), SQUIDSTRINGPRINT(urlpath),
                  http_ver.major, http_ver.minor);
     /* headers */
     header.packInto(p);
@@ -414,7 +415,7 @@ httpRequestPack(void *obj, Packer *p)
 int
 HttpRequest::prefixLen()
 {
-    return strlen(RequestMethodStr(method)) + 1 +
+    return method.image().length() + 1 +
            urlpath.size() + 1 +
            4 + 1 + 3 + 2 +
            header.len + 2;
@@ -524,8 +525,8 @@ const char *HttpRequest::packableURI(bool full_uri) const
 void HttpRequest::packFirstLineInto(Packer * p, bool full_uri) const
 {
     // form HTTP request-line
-    packerPrintf(p, "%s %s HTTP/%d.%d\r\n",
-                 RequestMethodStr(method),
+    packerPrintf(p, SQUIDSBUFPH " %s HTTP/%d.%d\r\n",
+                 SQUIDSBUFPRINT(method.image()),
                  packableURI(full_uri),
                  http_ver.major, http_ver.minor);
 }
@@ -594,7 +595,7 @@ HttpRequest::maybeCacheable()
     if (!flags.hostVerified && (flags.intercepted || flags.interceptTproxy))
         return false;
 
-    switch (protocol) {
+    switch (url.getScheme()) {
     case AnyP::PROTO_HTTP:
     case AnyP::PROTO_HTTPS:
         if (!method.respMaybeCacheable())
@@ -39,6 +39,7 @@
 #include "HttpRequestMethod.h"
 #include "Notes.h"
 #include "RequestFlags.h"
+#include "URL.h"
 
 #if USE_AUTH
 #include "auth/UserRequest.h"
@@ -136,6 +137,9 @@ class HttpRequest: public HttpMsg
 public:
     HttpRequestMethod method;
 
+    // TODO expand to include all URI parts
+    URL url; ///< the request URI (scheme only)
+
     char login[MAX_LOGIN_SZ];
 
 private:
@@ -20,20 +20,11 @@ operator++ (Http::MethodType &aMethod)
  * or from a range of chars, * such as "GET" from "GETFOOBARBAZ"
  * (pass in pointer to G and pointer to F.)
  */
-HttpRequestMethod::HttpRequestMethod(char const *begin, char const *end) : theMethod (Http::METHOD_NONE)
+HttpRequestMethod::HttpRequestMethod(char const *begin, char const *end) : theMethod(Http::METHOD_NONE)
 {
     if (begin == NULL)
         return;
 
-    /*
-     * This check for '%' makes sure that we don't
-     * match one of the extension method placeholders,
-     * which have the form %EXT[0-9][0-9]
-     */
-
-    if (*begin == '%')
-        return;
-
     /*
      * if e is NULL, b must be NULL terminated and we
      * make e point to the first whitespace character
@@ -42,40 +33,40 @@ HttpRequestMethod::HttpRequestMethod(char const *begin, char const *end) : theMe
     if (NULL == end)
         end = begin + strcspn(begin, w_space);
 
-    if (end == begin) {
-        theMethod = Http::METHOD_NONE;
+    if (end == begin)
         return;
-    }
 
+    // TODO: Optimize this linear search.
     for (++theMethod; theMethod < Http::METHOD_ENUM_END; ++theMethod) {
         // RFC 2616 section 5.1.1 - Method names are case-sensitive
         // NP: this is not a HTTP_VIOLATIONS case since there is no MUST/SHOULD involved.
-        if (0 == strncasecmp(begin, Http::MethodType_str[theMethod], end-begin)) {
+        if (0 == image().caseCmp(begin, end-begin)) {
 
             // relaxed parser allows mixed-case and corrects them on output
             if (Config.onoff.relaxed_header_parser)
                 return;
 
-            if (0 == strncmp(begin, Http::MethodType_str[theMethod], end-begin))
+            if (0 == image().cmp(begin, end-begin))
                 return;
         }
     }
 
     // if method not found and method string is not null then it is other method
     theMethod = Http::METHOD_OTHER;
-    theImage.limitInit(begin,end-begin);
+    theImage.assign(begin, end-begin);
 }
 
-char const*
+const SBuf &
 HttpRequestMethod::image() const
 {
+    static const SBuf methodOther("METHOD_OTHER");
     if (Http::METHOD_OTHER != theMethod) {
-        return Http::MethodType_str[theMethod];
+        return Http::MethodType_sb[theMethod];
     } else {
-        if (theImage.size()>0) {
-            return theImage.termedBuf();
+        if (!theImage.isEmpty()) {
+            return theImage;
         } else {
-            return "METHOD_OTHER";
+            return methodOther;
         }
     }
 }
@@ -2,8 +2,7 @@
 #define SQUID_HTTPREQUESTMETHOD_H
 
 #include "http/MethodType.h"
-#include "SquidString.h"
-#include "SquidString.h"
+#include "SBuf.h"
 
 class SquidConfig;
 
@@ -41,7 +40,7 @@ class HttpRequestMethod
 
     HttpRequestMethod & operator = (Http::MethodType const aMethod) {
         theMethod = aMethod;
-        theImage.clean();
+        theImage.clear();
         return *this;
     }
 
@@ -73,8 +72,8 @@ class HttpRequestMethod
      */
     Http::MethodType id() const { return theMethod; }
 
-    /** Get a char string representation of the method. */
-    char const * image() const;
+    /** Get a string representation of the method. */
+    const SBuf &image() const;
 
     /// Whether this method is defined as a "safe" in HTTP/1.1
     /// see RFC 2616 section 9.1.1
@@ -112,10 +111,8 @@ class HttpRequestMethod
     bool purgesOthers() const;
 
 private:
-    static const char *RequestMethodStr[];
-
     Http::MethodType theMethod; ///< Method type
-    String theImage;     ///< Used for storing the Http::METHOD_OTHER only. A copy of the parsed method text.
+    SBuf theImage;     ///< Used for storing the Http::METHOD_OTHER only. A copy of the parsed method text.
 };
 
 inline std::ostream &
@@ -125,16 +122,4 @@ operator << (std::ostream &os, HttpRequestMethod const &method)
     return os;
 }
 
-inline const char*
-RequestMethodStr(const Http::MethodType m)
-{
-    return HttpRequestMethod(m).image();
-}
-
-inline const char*
-RequestMethodStr(const HttpRequestMethod& m)
-{
-    return m.image();
-}
-
 #endif /* SQUID_HTTPREQUESTMETHOD_H */
@@ -26,6 +26,7 @@ typedef enum {
     LOG_TCP_DENIED_REPLY,
     LOG_TCP_OFFLINE_HIT,
     LOG_TCP_REDIRECT,
+    LOG_TCP_TUNNEL,             // a binary tunnel was established for this transaction
     LOG_UDP_HIT,
     LOG_UDP_MISS,
     LOG_UDP_DENIED,
@@ -46,8 +46,8 @@ LOADABLE_MODULES_SOURCES = \
 	LoadableModules.h \
 	LoadableModules.cc
 
-SUBDIRS	= base anyp comm eui acl format fs repl
-DIST_SUBDIRS = base anyp comm eui acl format fs repl
+SUBDIRS	= base anyp parser comm eui acl format fs repl
+DIST_SUBDIRS = base anyp parser comm eui acl format fs repl
 
 if ENABLE_AUTH
 SUBDIRS += auth
@@ -173,7 +173,7 @@ WIN32_SOURCE =
 WINSVC_SOURCE =
 endif
 
-if USE_IPC_WIN32
+if ENABLE_WIN32_IPC
 IPC_SOURCE = SquidIpc.h ipc_win32.cc
 else
 IPC_SOURCE = SquidIpc.h ipc.cc
@@ -182,13 +182,13 @@ endif
 AIO_WIN32_ALL_SOURCES = \
 	DiskIO/AIO/aio_win32.cc \
 	DiskIO/AIO/aio_win32.h
-if USE_AIO_WIN32
+if ENABLE_WIN32_AIO
 AIO_WIN32_SOURCES = $(AIO_WIN32_ALL_SOURCES)
 else
 AIO_WIN32_SOURCES =
 endif
 
-if USE_AIOPS_WIN32
+if ENABLE_WIN32_AIOPS
 AIOPS_SOURCE = DiskIO/DiskThreads/aiops_win32.cc \
 	DiskIO/DiskThreads/CommIO.cc \
 	DiskIO/DiskThreads/CommIO.h
@@ -264,7 +264,6 @@ DiskIO/DiskIOModules_gen.cc: Makefile
 libsquid_la_SOURCES = \
 	comm.cc \
 	comm.h \
-	comm_err_t.h \
 	CommCalls.cc \
 	CommCalls.h \
 	DescriptorSet.cc \
@@ -472,6 +471,8 @@ squid_SOURCES = \
 	peer_sourcehash.cc \
 	peer_userhash.h \
 	peer_userhash.cc \
+	PeerPoolMgr.h \
+	PeerPoolMgr.cc \
 	PeerSelectState.h \
 	PingData.h \
 	protos.h \
@@ -639,11 +640,13 @@ squid_LDADD = \
 	$(DISK_LINKOBJS) \
 	$(REPL_OBJS) \
 	$(DISK_OS_LIBS) \
+	$(NETTLELIB) \
 	$(CRYPTLIB) \
 	$(REGEXLIB) \
 	$(ADAPTATION_LIBS) \
 	$(ESI_LIBS) \
 	$(SNMP_LIBS) \
+	parser/libsquid-parser.la \
 	$(top_builddir)/lib/libmisccontainers.la \
 	$(top_builddir)/lib/libmiscencoding.la \
 	$(top_builddir)/lib/libmiscutil.la \
@@ -675,7 +678,7 @@ squid_DEPENDENCIES = \
 	ipc/libipc.la \
 	mgr/libmgr.la
 
-if USE_LOADABLE_MODULES
+if ENABLE_LOADABLE_MODULES
 squid_SOURCES += $(LOADABLE_MODULES_SOURCES)
 squid_LDADD += -L$(top_builddir) $(LIBLTDL)
 squid_LDFLAGS = -export-dynamic -dlopen force
@@ -760,6 +763,7 @@ ufsdump_LDADD = \
 	mgr/libmgr.la \
 	$(XTRA_OBJS) \
 	$(REPL_OBJS) \
+	$(NETTLELIB) \
 	$(CRYPTLIB) \
 	$(REGEXLIB) \
 	$(SSLLIB) \
@@ -965,7 +969,7 @@ cache_cf.o: cf_parser.cci
 
 # cf_gen builds the configuration files.
 cf_gen$(EXEEXT): $(cf_gen_SOURCES) $(cf_gen_DEPENDENCIES) cf_gen_defines.cci
-	$(HOSTCXX) -o $@ $(srcdir)/cf_gen.cc -I$(srcdir) -I$(top_builddir)/include/ -I$(top_builddir)/src
+	$(BUILDCXX) $(BUILDCXXFLAGS) -o $@ $(srcdir)/cf_gen.cc -I$(srcdir) -I$(top_builddir)/include/ -I$(top_builddir)/src
 
 # squid.conf.default is built by cf_gen when making cf_parser.cci
 squid.conf.default squid.conf.documented: cf_parser.cci
@@ -1209,6 +1213,7 @@ tests_testHttpReply_LDADD=\
 	$(top_builddir)/lib/libmiscutil.la \
 	$(SQUID_CPPUNIT_LIBS) \
 	$(SQUID_CPPUNIT_LA) \
+	$(NETTLELIB) \
 	$(SSLLIB) \
 	$(COMPAT_LIB) \
 	$(XTRA_LIBS)
@@ -1348,6 +1353,7 @@ tests_testACLMaxUserIP_LDADD= \
 	$(top_builddir)/lib/libmiscencoding.la \
 	$(top_builddir)/lib/libmiscutil.la \
 	$(DISK_OS_LIBS) \
+	$(NETTLELIB) \
 	$(REGEXLIB) \
 	$(SQUID_CPPUNIT_LIBS) \
 	$(SSLLIB) \
@@ -1514,6 +1520,8 @@ tests_testCacheManager_SOURCES = \
 	peer_sourcehash.cc \
 	peer_userhash.h \
 	peer_userhash.cc \
+	PeerPoolMgr.h \
+	PeerPoolMgr.cc \
 	redirect.h \
 	tests/stub_redirect.cc \
 	refresh.h \
@@ -1610,6 +1618,7 @@ tests_testCacheManager_LDADD = \
 	$(top_builddir)/lib/libmisccontainers.la \
 	$(top_builddir)/lib/libmiscencoding.la \
 	$(top_builddir)/lib/libmiscutil.la \
+	$(NETTLELIB) \
 	$(REGEXLIB) \
 	$(SQUID_CPPUNIT_LIBS) \
 	$(SQUID_CPPUNIT_LA) \
@@ -1739,6 +1748,7 @@ tests_testDiskIO_SOURCES = \
 	tests/stub_MemStore.cc \
 	mime.h \
 	tests/stub_mime.cc \
+	tests/stub_neighbors.cc \
 	tests/stub_pconn.cc \
 	tests/stub_Port.cc \
 	tests/stub_stat.cc \
@@ -1791,6 +1801,7 @@ tests_testDiskIO_LDADD = \
 	$(top_builddir)/lib/libmisccontainers.la \
 	$(top_builddir)/lib/libmiscencoding.la \
 	$(top_builddir)/lib/libmiscutil.la \
+	$(NETTLELIB) \
 	$(REGEXLIB) \
 	$(SQUID_CPPUNIT_LIBS) \
 	$(SSLLIB) \
@@ -1893,6 +1904,8 @@ tests_testEvent_SOURCES = \
 	HttpParser.cc \
 	HttpParser.h \
 	HttpReply.cc \
+	PeerPoolMgr.h \
+	PeerPoolMgr.cc \
 	RequestFlags.h \
 	RequestFlags.cc \
 	HttpRequest.cc \
@@ -2038,6 +2051,7 @@ tests_testEvent_LDADD = \
 	ipc/libipc.la \
 	mgr/libmgr.la \
 	$(SNMP_LIBS) \
+	$(NETTLELIB) \
 	$(REGEXLIB) \
 	$(SQUID_CPPUNIT_LIBS) \
 	$(SQUID_CPPUNIT_LA) \
@@ -2140,6 +2154,8 @@ tests_testEventLoop_SOURCES = \
 	HttpParser.cc \
 	HttpParser.h \
 	HttpReply.cc \
+	PeerPoolMgr.h \
+	PeerPoolMgr.cc \
 	RequestFlags.h \
 	RequestFlags.cc \
 	HttpRequest.cc \
@@ -2285,6 +2301,7 @@ tests_testEventLoop_LDADD = \
 	ipc/libipc.la \
 	mgr/libmgr.la \
 	$(SNMP_LIBS) \
+	$(NETTLELIB) \
 	$(REGEXLIB) \
 	$(SQUID_CPPUNIT_LIBS) \
 	$(SQUID_CPPUNIT_LA) \
@@ -2383,6 +2400,8 @@ tests_test_http_range_SOURCES = \
 	HttpParser.cc \
 	HttpParser.h \
 	HttpReply.cc \
+	PeerPoolMgr.h \
+	PeerPoolMgr.cc \
 	RequestFlags.h \
 	RequestFlags.cc \
 	HttpRequest.cc \
@@ -2525,6 +2544,7 @@ tests_test_http_range_LDADD = \
 	$(top_builddir)/lib/libmisccontainers.la \
 	$(top_builddir)/lib/libmiscencoding.la \
 	$(top_builddir)/lib/libmiscutil.la \
+	$(NETTLELIB) \
 	$(REGEXLIB) \
 	$(SQUID_CPPUNIT_LIBS) \
 	$(SQUID_CPPUNIT_LA) \
@@ -2722,6 +2742,8 @@ tests_testHttpRequest_SOURCES = \
 	peer_sourcehash.cc \
 	peer_userhash.h \
 	peer_userhash.cc \
+	PeerPoolMgr.h \
+	PeerPoolMgr.cc \
 	redirect.h \
 	tests/stub_libauth_acls.cc \
 	tests/stub_redirect.cc \
@@ -2813,6 +2835,7 @@ tests_testHttpRequest_LDADD = \
 	$(top_builddir)/lib/libmiscencoding.la \
 	$(top_builddir)/lib/libmiscutil.la \
 	$(DISK_OS_LIBS) \
+	$(NETTLELIB) \
 	$(REGEXLIB) \
 	$(SQUID_CPPUNIT_LIBS) \
 	$(SQUID_CPPUNIT_LA) \
@@ -2987,6 +3010,7 @@ tests_testStore_LDADD= \
 	$(top_builddir)/lib/libmisccontainers.la \
 	$(top_builddir)/lib/libmiscencoding.la \
 	$(top_builddir)/lib/libmiscutil.la \
+	$(NETTLELIB) \
 	$(REGEXLIB) \
 	$(SQUID_CPPUNIT_LIBS) \
 	$(SSLLIB) \
@@ -3070,6 +3094,7 @@ tests_testUfs_SOURCES = \
 	tests/stub_libeui.cc \
 	tests/stub_libicmp.cc \
 	tests/stub_MemStore.cc \
+	tests/stub_neighbors.cc \
 	tests/stub_pconn.cc \
 	tests/stub_Port.cc \
 	tests/stub_UdsOp.cc \
@@ -3225,6 +3250,7 @@ tests_testUfs_LDADD = \
 	$(top_builddir)/lib/libmisccontainers.la \
 	$(top_builddir)/lib/libmiscencoding.la \
 	$(top_builddir)/lib/libmiscutil.la \
+	$(NETTLELIB) \
 	$(REGEXLIB) \
 	$(SQUID_CPPUNIT_LIBS) \
 	$(SSLLIB) \
@@ -3361,6 +3387,7 @@ tests_testRock_SOURCES = \
 	tests/stub_MemStore.cc \
 	mime.h \
 	tests/stub_mime.cc \
+	tests/stub_neighbors.cc \
 	tests/stub_Port.cc \
 	tests/stub_pconn.cc \
 	tests/stub_store_client.cc \
@@ -3403,6 +3430,7 @@ tests_testRock_LDADD = \
 	$(top_builddir)/lib/libmisccontainers.la \
 	$(top_builddir)/lib/libmiscencoding.la \
 	$(top_builddir)/lib/libmiscutil.la \
+	$(NETTLELIB) \
 	$(REGEXLIB) \
 	$(SQUID_CPPUNIT_LIBS) \
 	$(SSLLIB) \
@@ -3500,6 +3528,8 @@ tests_testURL_SOURCES = \
 	HttpParser.cc \
 	HttpParser.h \
 	HttpReply.cc \
+	PeerPoolMgr.h \
+	PeerPoolMgr.cc \
 	RequestFlags.h \
 	RequestFlags.cc \
 	HttpRequest.cc \
@@ -3648,6 +3678,7 @@ tests_testURL_LDADD = \
 	$(top_builddir)/lib/libmisccontainers.la \
 	$(top_builddir)/lib/libmiscencoding.la \
 	$(top_builddir)/lib/libmiscutil.la \
+	$(NETTLELIB) \
 	$(COMPAT_LIB) \
 	$(SQUID_CPPUNIT_LIBS) \
 	$(SQUID_CPPUNIT_LA) \
@@ -3790,6 +3821,9 @@ tests_testStatHist_SOURCES = \
 	fatal.h \
 	tests/stub_fatal.cc \
 	tests/stub_MemBuf.cc \
+	$(SBUF_SOURCE) \
+	SBufDetailedStats.h \
+	tests/stub_SBufDetailedStats.cc \
 	StatHist.cc \
 	StatHist.h \
 	String.cc \
@@ -3808,6 +3842,7 @@ tests_testStatHist_SOURCES = \
 	repl_modules.h \
 	tests/stub_store.cc \
 	tests/stub_store_stats.cc \
+	time.cc \
 	tools.h \
 	tests/stub_tools.cc \
 	tests/testMain.cc \
@@ -95,7 +95,7 @@ MemBlob::~MemBlob()
         memFreeString(capacity,mem);
     Stats.liveBytes -= capacity;
     --Stats.live;
-    recordMemBlobSizeAtDestruct(size);
+    recordMemBlobSizeAtDestruct(capacity);
 
     debugs(MEMBLOB_DEBUGSECTION,9, HERE << "destructed, this="
            << static_cast<void*>(this) << " id=" << id
@@ -137,6 +137,7 @@ MemBuf::init(mb_size_t szInit, mb_size_t szMax)
     capacity = 0;
     stolen = 0;
     grow(szInit);
+    terminate();
 }
 
 /**
@@ -243,8 +243,7 @@ struct StoreClientStats : public unary_function<store_client, void> {
 void
 MemObject::stat(MemBuf * mb) const
 {
-    mb->Printf("\t%s %s\n",
-               RequestMethodStr(method), logUri());
+    mb->Printf("\t" SQUIDSBUFPH " %s\n", SQUIDSBUFPRINT(method.image()), logUri());
     if (vary_headers)
         mb->Printf("\tvary_headers: %s\n", vary_headers);
     mb->Printf("\tinmem_lo: %" PRId64 "\n", inmem_lo);
@@ -158,15 +158,15 @@ NotePairs::~NotePairs()
 }
 
 const char *
-NotePairs::find(const char *noteKey) const
+NotePairs::find(const char *noteKey, const char *sep) const
 {
     static String value;
     value.clean();
     for (std::vector<NotePairs::Entry *>::const_iterator  i = entries.begin(); i != entries.end(); ++i) {
         if ((*i)->name.cmp(noteKey) == 0) {
             if (value.size())
-                value.append(", ");
-            value.append(ConfigParser::QuoteString((*i)->value));
+                value.append(sep);
+            value.append((*i)->value);
         }
     }
     return value.size() ? value.termedBuf() : NULL;
@@ -180,7 +180,7 @@ NotePairs::toString(const char *sep) const
     for (std::vector<NotePairs::Entry *>::const_iterator  i = entries.begin(); i != entries.end(); ++i) {
         value.append((*i)->name);
         value.append(": ");
-        value.append(ConfigParser::QuoteString((*i)->value));
+        value.append((*i)->value);
         value.append(sep);
     }
     return value.size() ? value.termedBuf() : NULL;
@@ -145,7 +145,7 @@ class NotePairs: public RefCountable
      * Returns a comma separated list of notes with key 'noteKey'.
      * Use findFirst instead when a unique kv-pair is needed.
      */
-    const char *find(const char *noteKey) const;
+    const char *find(const char *noteKey, const char *sep = ",") const;
 
     /**
      * Returns the first note value for this key or an empty string.
@@ -0,0 +1,284 @@
+#include "squid.h"
+#include "base/AsyncJobCalls.h"
+#include "base/RunnersRegistry.h"
+#include "CachePeer.h"
+#include "comm/Connection.h"
+#include "comm/ConnOpener.h"
+#include "Debug.h"
+#include "fd.h"
+#include "FwdState.h"
+#include "globals.h"
+#include "HttpRequest.h"
+#include "neighbors.h"
+#include "pconn.h"
+#include "PeerPoolMgr.h"
+#include "SquidConfig.h"
+#if USE_OPENSSL
+#include "ssl/PeerConnector.h"
+#endif
+
+CBDATA_CLASS_INIT(PeerPoolMgr);
+
+#if USE_OPENSSL
+/// Gives Ssl::PeerConnector access to Answer in the PeerPoolMgr callback dialer.
+class MyAnswerDialer: public UnaryMemFunT<PeerPoolMgr, Ssl::PeerConnectorAnswer, Ssl::PeerConnectorAnswer&>,
+        public Ssl::PeerConnector::CbDialer
+{
+public:
+    MyAnswerDialer(const JobPointer &aJob, Method aMethod):
+            UnaryMemFunT<PeerPoolMgr, Ssl::PeerConnectorAnswer, Ssl::PeerConnectorAnswer&>(aJob, aMethod, Ssl::PeerConnectorAnswer()) {}
+
+    /* Ssl::PeerConnector::CbDialer API */
+    virtual Ssl::PeerConnectorAnswer &answer() { return arg1; }
+};
+#endif
+
+PeerPoolMgr::PeerPoolMgr(CachePeer *aPeer): AsyncJob("PeerPoolMgr"),
+        peer(cbdataReference(aPeer)),
+        request(),
+        opener(),
+        securer(),
+        closer(),
+        addrUsed(0)
+{
+}
+
+PeerPoolMgr::~PeerPoolMgr()
+{
+    cbdataReferenceDone(peer);
+}
+
+void
+PeerPoolMgr::start()
+{
+    AsyncJob::start();
+
+    // ErrorState, getOutgoingAddress(), and other APIs may require a request.
+    // We fake one. TODO: Optionally send this request to peers?
+    request = new HttpRequest(Http::METHOD_OPTIONS, AnyP::PROTO_HTTP, "*");
+    request->SetHost(peer->host);
+
+    checkpoint("peer initialized");
+}
+
+void
+PeerPoolMgr::swanSong()
+{
+    AsyncJob::swanSong();
+}
+
+bool
+PeerPoolMgr::validPeer() const
+{
+    return peer && cbdataReferenceValid(peer) && peer->standby.pool;
+}
+
+bool
+PeerPoolMgr::doneAll() const
+{
+    return !(validPeer() && peer->standby.limit) && AsyncJob::doneAll();
+}
+
+void
+PeerPoolMgr::handleOpenedConnection(const CommConnectCbParams &params)
+{
+    opener = NULL;
+
+    if (!validPeer()) {
+        debugs(48, 3, "peer gone");
+        if (params.conn != NULL)
+            params.conn->close();
+        return;
+    }
+
+    if (params.flag != Comm::OK) {
+        /* it might have been a timeout with a partially open link */
+        if (params.conn != NULL)
+            params.conn->close();
+        peerConnectFailed(peer);
+        checkpoint("conn opening failure"); // may retry
+        return;
+    }
+
+    Must(params.conn != NULL);
+
+#if USE_OPENSSL
+    // Handle SSL peers.
+    if (peer->use_ssl) {
+        typedef CommCbMemFunT<PeerPoolMgr, CommCloseCbParams> CloserDialer;
+        closer = JobCallback(48, 3, CloserDialer, this,
+                             PeerPoolMgr::handleSecureClosure);
+        comm_add_close_handler(params.conn->fd, closer);
+
+        securer = asyncCall(48, 4, "PeerPoolMgr::handleSecuredPeer",
+                            MyAnswerDialer(this, &PeerPoolMgr::handleSecuredPeer));
+        Ssl::PeerConnector *connector =
+            new Ssl::PeerConnector(request, params.conn, securer);
+        AsyncJob::Start(connector); // will call our callback
+        return;
+    }
+#endif
+
+    pushNewConnection(params.conn);
+}
+
+void
+PeerPoolMgr::pushNewConnection(const Comm::ConnectionPointer &conn)
+{
+    Must(validPeer());
+    Must(Comm::IsConnOpen(conn));
+    peer->standby.pool->push(conn, NULL /* domain */);
+    // push() will trigger a checkpoint()
+}
+
+#if USE_OPENSSL
+void
+PeerPoolMgr::handleSecuredPeer(Ssl::PeerConnectorAnswer &answer)
+{
+    Must(securer != NULL);
+    securer = NULL;
+
+    if (closer != NULL) {
+        if (answer.conn != NULL)
+            comm_remove_close_handler(answer.conn->fd, closer);
+        else
+            closer->cancel("securing completed");
+        closer = NULL;
+    }
+
+    if (!validPeer()) {
+        debugs(48, 3, "peer gone");
+        if (answer.conn != NULL)
+            answer.conn->close();
+        return;
+    }
+
+    if (answer.error.get()) {
+        if (answer.conn != NULL)
+            answer.conn->close();
+        // PeerConnector calls peerConnectFailed() for us;
+        checkpoint("conn securing failure"); // may retry
+        return;
+    }
+
+    pushNewConnection(answer.conn);
+}
+
+void
+PeerPoolMgr::handleSecureClosure(const CommCloseCbParams &params)
+{
+    Must(closer != NULL);
+    Must(securer != NULL);
+    securer->cancel("conn closed by a 3rd party");
+    securer = NULL;
+    closer = NULL;
+    // allow the closing connection to fully close before we check again
+    Checkpoint(this, "conn closure while securing");
+}
+#endif
+
+void
+PeerPoolMgr::openNewConnection()
+{
+    // KISS: Do nothing else when we are already doing something.
+    if (opener != NULL || securer != NULL || shutting_down) {
+        debugs(48, 7, "busy: " << opener << '|' << securer << '|' << shutting_down);
+        return; // there will be another checkpoint when we are done opening/securing
+    }
+
+    // Do not talk to a peer until it is ready.
+    if (!neighborUp(peer)) // provides debugging
+        return; // there will be another checkpoint when peer is up
+
+    // Do not violate peer limits.
+    if (!peerCanOpenMore(peer)) { // provides debugging
+        peer->standby.waitingForClose = true; // may already be true
+        return; // there will be another checkpoint when a peer conn closes
+    }
+
+    // Do not violate global restrictions.
+    if (fdUsageHigh()) {
+        debugs(48, 7, "overwhelmed");
+        peer->standby.waitingForClose = true; // may already be true
+        // There will be another checkpoint when a peer conn closes OR when
+        // a future pop() fails due to an empty pool. See PconnPool::pop().
+        return;
+    }
+
+    peer->standby.waitingForClose = false;
+
+    Comm::ConnectionPointer conn = new Comm::Connection;
+    Must(peer->n_addresses); // guaranteed by neighborUp() above
+    // cycle through all available IP addresses
+    conn->remote = peer->addresses[addrUsed++ % peer->n_addresses];
+    conn->remote.port(peer->http_port);
+    conn->peerType = STANDBY_POOL; // should be reset by peerSelect()
+    conn->setPeer(peer);
+    getOutgoingAddress(request.getRaw(), conn);
+    GetMarkingsToServer(request.getRaw(), *conn);
+
+    const int ctimeout = peer->connect_timeout > 0 ?
+                         peer->connect_timeout : Config.Timeout.peer_connect;
+    typedef CommCbMemFunT<PeerPoolMgr, CommConnectCbParams> Dialer;
+    opener = JobCallback(48, 5, Dialer, this, PeerPoolMgr::handleOpenedConnection);
+    Comm::ConnOpener *cs = new Comm::ConnOpener(conn, opener, ctimeout);
+    AsyncJob::Start(cs);
+}
+
+void
+PeerPoolMgr::closeOldConnections(const int howMany)
+{
+    debugs(48, 8, howMany);
+    peer->standby.pool->closeN(howMany);
+}
+
+void
+PeerPoolMgr::checkpoint(const char *reason)
+{
+    if (!validPeer()) {
+        debugs(48, 3, reason << " and peer gone");
+        return; // nothing to do after our owner dies; the job will quit
+    }
+
+    const int count = peer->standby.pool->count();
+    const int limit = peer->standby.limit;
+    debugs(48, 7, reason << " with " << count << " ? " << limit);
+
+    if (count < limit)
+        openNewConnection();
+    else if (count > limit)
+        closeOldConnections(count - limit);
+}
+
+void
+PeerPoolMgr::Checkpoint(const Pointer &mgr, const char *reason)
+{
+    CallJobHere1(48, 5, mgr, PeerPoolMgr, checkpoint, reason);
+}
+
+/// launches PeerPoolMgrs for peers configured with standby.limit
+class PeerPoolMgrsRr: public RegisteredRunner
+{
+public:
+    /* RegisteredRunner API */
+    virtual void useConfig() { syncConfig(); }
+    virtual void syncConfig();
+};
+
+RunnerRegistrationEntry(PeerPoolMgrsRr);
+
+void
+PeerPoolMgrsRr::syncConfig()
+{
+    for (CachePeer *p = Config.peers; p; p = p->next) {
+        // On reconfigure, Squid deletes the old config (and old peers in it),
+        // so should always be dealing with a brand new configuration.
+        assert(!p->standby.mgr);
+        assert(!p->standby.pool);
+        if (p->standby.limit) {
+            p->standby.mgr = new PeerPoolMgr(p);
+            p->standby.pool = new PconnPool(p->name, p->standby.mgr);
+            AsyncJob::Start(p->standby.mgr.get());
+        }
+    }
+}
@@ -0,0 +1,69 @@
+#ifndef SQUID_PEERPOOLMGR_H
+#define SQUID_PEERPOOLMGR_H
+
+#include "base/AsyncJob.h"
+#include "comm/forward.h"
+
+class HttpRequest;
+class CachePeer;
+class CommConnectCbParams;
+
+#if USE_OPENSSL
+namespace Ssl
+{
+class PeerConnectorAnswer;
+}
+#endif
+
+/// Maintains an fixed-size "standby" PconnPool for a single CachePeer.
+class PeerPoolMgr: public AsyncJob
+{
+public:
+    typedef CbcPointer<PeerPoolMgr> Pointer;
+
+    // syncs mgr state whenever connection-related peer or pool state changes
+    static void Checkpoint(const Pointer &mgr, const char *reason);
+
+    explicit PeerPoolMgr(CachePeer *aPeer);
+    virtual ~PeerPoolMgr();
+
+protected:
+    /* AsyncJob API */
+    virtual void start();
+    virtual void swanSong();
+    virtual bool doneAll() const;
+
+    /// whether the peer is still out there and in a valid state we can safely use
+    bool validPeer() const;
+
+    /// Starts new connection, or closes the excess connections
+    /// according pool configuration
+    void checkpoint(const char *reason);
+    /// starts the process of opening a new standby connection (if possible)
+    void openNewConnection();
+    /// closes 'howMany' standby connections
+    void closeOldConnections(const int howMany);
+
+    /// Comm::ConnOpener calls this when done opening a connection for us
+    void handleOpenedConnection(const CommConnectCbParams &params);
+#if USE_OPENSSL
+    /// Ssl::PeerConnector callback
+    void handleSecuredPeer(Ssl::PeerConnectorAnswer &answer);
+    /// called when the connection we are trying to secure is closed by a 3rd party
+    void handleSecureClosure(const CommCloseCbParams &params);
+#endif
+    /// the final step in connection opening (and, optionally, securing) sequence
+    void pushNewConnection(const Comm::ConnectionPointer &conn);
+
+private:
+    CachePeer *peer; ///< the owner of the pool we manage
+    RefCount<HttpRequest> request; ///< fake HTTP request for conn opening code
+    AsyncCall::Pointer opener; ///< whether we are opening a connection
+    AsyncCall::Pointer securer; ///< whether we are securing a connection
+    AsyncCall::Pointer closer; ///< monitors conn while we are securing it
+    unsigned int addrUsed; ///< counter for cycling through peer addresses
+
+    CBDATA_CLASS2(PeerPoolMgr);
+};
+
+#endif /* SQUID_PEERPOOLMGR_H */
@@ -59,7 +59,7 @@ SBufStats::SBufStats()
         : alloc(0), allocCopy(0), allocFromString(0), allocFromCString(0),
         assignFast(0), clear(0), append(0), toStream(0), setChar(0),
         getChar(0), compareSlow(0), compareFast(0), copyOut(0),
-        rawAccess(0), chop(0), trim(0), find(0), scanf(0),
+        rawAccess(0), nulTerminate(0), chop(0), trim(0), find(0), scanf(0),
         caseChange(0), cowFast(0), cowSlow(0), live(0)
 {}
 
@@ -80,6 +80,7 @@ SBufStats::operator +=(const SBufStats& ss)
     compareFast += ss.compareFast;
     copyOut += ss.copyOut;
     rawAccess += ss.rawAccess;
+    nulTerminate += ss.nulTerminate;
     chop += ss.chop;
     trim += ss.trim;
     find += ss.find;
@@ -376,12 +377,12 @@ memcasecmp(const char *b1, const char *b2, SBuf::size_type len)
 }
 
 int
-SBuf::compare(const SBuf &S, SBufCaseSensitive isCaseSensitive, size_type n) const
+SBuf::compare(const SBuf &S, const SBufCaseSensitive isCaseSensitive, const size_type n) const
 {
     if (n != npos)
         return substr(0,n).compare(S.substr(0,n),isCaseSensitive);
 
-    size_type byteCompareLen = min(S.length(), length());
+    const size_type byteCompareLen = min(S.length(), length());
     ++stats.compareSlow;
     int rv = 0;
     if (isCaseSensitive == caseSensitive) {
@@ -398,8 +399,61 @@ SBuf::compare(const SBuf &S, SBufCaseSensitive isCaseSensitive, size_type n) con
     return -1;
 }
 
+int
+SBuf::compare(const char *s, const SBufCaseSensitive isCaseSensitive, const size_type n) const
+{
+    // 0-length comparison is always true regardless of buffer states
+    if (!n) {
+        ++stats.compareFast;
+        return 0;
+    }
+
+    // N-length compare MUST provide a non-NULL C-string pointer
+    assert(s);
+
+    // when this is a 0-length string, no need for any complexity.
+    if (!length()) {
+        ++stats.compareFast;
+        return '\0' - *s;
+    }
+
+    // brute-force scan in order to avoid ever needing strlen() on a c-string.
+    ++stats.compareSlow;
+    const char *left = buf();
+    const char *right = s;
+    int rv = 0;
+    // what area to scan.
+    // n may be npos, but we treat that as a huge positive value
+    size_type byteCount = min(length(), n);
+
+    // loop until we find a difference, a '\0', or reach the end of area to scan
+    if (isCaseSensitive == caseSensitive) {
+        while ((rv = *left - *right++) == 0) {
+            if (*left++ == '\0' || --byteCount == 0)
+                break;
+        }
+    } else {
+        while ((rv = tolower(*left) - tolower(*right++)) == 0) {
+            if (*left++ == '\0' || --byteCount == 0)
+                break;
+        }
+    }
+
+    // If we stopped scanning because we reached the end
+    //  of buf() before we reached the end of s,
+    // pretend we have a 0-terminator there to compare.
+    // NP: the loop already incremented "right" ready for this comparison
+    if (!byteCount && length() < n)
+        return '\0' - *right;
+
+    // If we found a difference within the scan area,
+    // or we found a '\0',
+    // or all n characters were identical (and none was \0).
+    return rv;
+}
+
 bool
-SBuf::startsWith(const SBuf &S, SBufCaseSensitive isCaseSensitive) const
+SBuf::startsWith(const SBuf &S, const SBufCaseSensitive isCaseSensitive) const
 {
     debugs(24, 8, id << " startsWith " << S.id << ", caseSensitive: " <<
            isCaseSensitive);
@@ -444,6 +498,7 @@ SBuf::consume(size_type n)
         n = length();
     else
         n = min(n, length());
+    debugs(24, 8, "consume " << n);
     SBuf rv(substr(0, n));
     chop(n);
     return rv;
@@ -491,6 +546,7 @@ SBuf::c_str()
     *rawSpace(1) = '\0';
     ++store_->size;
     ++stats.setChar;
+    ++stats.nulTerminate;
     return buf();
 }
 
@@ -764,6 +820,7 @@ SBufStats::dump(std::ostream& os) const
     "\ncomparisons not requiring data-scan: " << compareFast <<
     "\ncopy-out ops: " << copyOut <<
     "\nraw access to memory: " << rawAccess <<
+    "\nNULL terminate C string: " << nulTerminate <<
     "\nchop operations: " << chop <<
     "\ntrim operations: " << trim <<
     "\nfind: " << find <<
@@ -77,6 +77,7 @@ class SBufStats
     uint64_t compareFast; ///<number of comparison operations not requiring data scan
     uint64_t copyOut; ///<number of data-copies to other forms of buffers
     uint64_t rawAccess; ///<number of accesses to raw contents
+    uint64_t nulTerminate; ///<number of c_str() terminations
     uint64_t chop;  ///<number of chop operations
     uint64_t trim;  ///<number of trim operations
     uint64_t find;  ///<number of find operations
@@ -254,15 +255,28 @@ class SBuf
      * \retval <0 argument of the call is smaller than called SBuf
      * \retval 0  argument of the call has the same contents of called SBuf
      */
-    int compare(const SBuf &S, SBufCaseSensitive isCaseSensitive, size_type n = npos) const;
+    int compare(const SBuf &S, const SBufCaseSensitive isCaseSensitive, const size_type n = npos) const;
 
-    /// shorthand version for compare
-    inline int cmp(const SBuf &S, size_type n = npos) const {
+    /// shorthand version for compare()
+    inline int cmp(const SBuf &S, const size_type n = npos) const {
         return compare(S,caseSensitive,n);
     }
 
-    /// shorthand version for case-insensitive comparison
-    inline int caseCmp(const SBuf &S, size_type n = npos) const {
+    /// shorthand version for case-insensitive compare()
+    inline int caseCmp(const SBuf &S, const size_type n = npos) const {
+        return compare(S,caseInsensitive,n);
+    }
+
+    /// Comparison with a C-string.
+    int compare(const char *s, const SBufCaseSensitive isCaseSensitive, const size_type n = npos) const;
+
+    /// Shorthand version for C-string compare().
+    inline int cmp(const char *S, const size_type n = npos) const {
+        return compare(S,caseSensitive,n);
+    }
+
+    /// Shorthand version for case-insensitive C-string compare().
+    inline int caseCmp(const char *S, const size_type n = npos) const {
         return compare(S,caseInsensitive,n);
     }
 
@@ -271,7 +285,7 @@ class SBuf
      *  \param isCaseSensitive one of caseSensitive or caseInsensitive
      *  \retval true argument is a prefix of the SBuf
      */
-    bool startsWith(const SBuf &S, SBufCaseSensitive isCaseSensitive = caseSensitive) const;
+    bool startsWith(const SBuf &S, const SBufCaseSensitive isCaseSensitive = caseSensitive) const;
 
     bool operator ==(const SBuf & S) const;
     bool operator !=(const SBuf & S) const;
@@ -15,8 +15,8 @@ namespace SBufDetailedStatsHistInitializer
 // run the post-instantiation initialization methods for StatHist objects
 struct Initializer {
     Initializer() {
-        sbufDestructTimeStats.logInit(300,30.0,128000.0);
-        memblobDestructTimeStats.logInit(300,30.0,128000.0);
+        sbufDestructTimeStats.logInit(100,30.0,128000.0);
+        memblobDestructTimeStats.logInit(100,30.0,128000.0);
     }
 };
 Initializer initializer;
@@ -62,6 +62,14 @@ SBufStatsAction::collect()
     mbsizesatdestruct = *collectMemBlobDestructTimeStats();
 }
 
+static void
+statHistSBufDumper(StoreEntry * sentry, int idx, double val, double size, int count)
+{
+    if (count == 0)
+        return;
+    storeAppendPrintf(sentry, "\t%d-%d\t%d\n", static_cast<int>(val), static_cast<int>(val+size), count);
+}
+
 void
 SBufStatsAction::dump(StoreEntry* entry)
 {
@@ -73,9 +81,9 @@ SBufStatsAction::dump(StoreEntry* entry)
     mbdata.dump(ses);
     ses << "\n";
     ses << "SBuf size distribution at destruct time:\n";
-    sbsizesatdestruct.dump(entry,NULL);
-    ses << "MemBlob size distribution at destruct time:\n";
-    mbsizesatdestruct.dump(entry,NULL);
+    sbsizesatdestruct.dump(entry,statHistSBufDumper);
+    ses << "MemBlob capacity distribution at destruct time:\n";
+    mbsizesatdestruct.dump(entry,statHistSBufDumper);
 }
 
 void
@@ -376,7 +376,7 @@ ServerStateData::sentRequestBody(const CommIoCbParams &io)
         // kids should increment their counters
     }
 
-    if (io.flag == COMM_ERR_CLOSING)
+    if (io.flag == Comm::ERR_CLOSING)
         return;
 
     if (!requestBodySource) {
@@ -517,7 +517,7 @@ ServerStateData::maybePurgeOthers()
 
     // XXX: should we use originalRequest() here?
     const char *reqUrl = urlCanonical(request);
-    debugs(88, 5, "maybe purging due to " << RequestMethodStr(request->method) << ' ' << reqUrl);
+    debugs(88, 5, "maybe purging due to " << request->method << ' ' << reqUrl);
     purgeEntriesByUrl(request, reqUrl);
     purgeEntriesByHeader(request, reqUrl, theFinalReply, HDR_LOCATION);
     purgeEntriesByHeader(request, reqUrl, theFinalReply, HDR_CONTENT_LOCATION);
@@ -40,8 +40,11 @@
 #include "Notes.h"
 #include "YesNoNone.h"
 
-#if USE_SSL
+#if USE_OPENSSL
+#if HAVE_OPENSSL_SSL_H
 #include <openssl/ssl.h>
+#endif
+
 class sslproxy_cert_sign;
 class sslproxy_cert_adapt;
 #endif
@@ -135,7 +138,7 @@ class SquidConfig
 
     struct {
         AnyP::PortCfg *http;
-#if USE_SSL
+#if USE_OPENSSL
         AnyP::PortCfg *https;
 #endif
     } Sockaddr;
@@ -199,7 +202,7 @@ class SquidConfig
 #endif
 
         char *diskd;
-#if USE_SSL
+#if USE_OPENSSL
 
         char *ssl_password;
 #endif
@@ -385,7 +388,7 @@ class SquidConfig
         acl_access *htcp_clr;
 #endif
 
-#if USE_SSL
+#if USE_OPENSSL
         acl_access *ssl_bump;
 #endif
 #if FOLLOW_X_FORWARDED_FOR
@@ -395,6 +398,8 @@ class SquidConfig
         /// spoof_client_ip squid.conf acl.
         /// nil unless configured
         acl_access* spoof_client_ip;
+
+        acl_access *ftp_epsv;
     } accessList;
     AclDenyInfoList *denyInfoList;
 
@@ -487,7 +492,7 @@ class SquidConfig
         int rebuild_chunk_percentage;
     } digest;
 #endif
-#if USE_SSL
+#if USE_OPENSSL
 
     struct {
         int unclean_shutdown;
@@ -509,7 +514,7 @@ class SquidConfig
     time_t minimum_expiry_time; /* seconds */
     external_acl *externalAclHelperList;
 
-#if USE_SSL
+#if USE_OPENSSL
 
     struct {
         char *cert;
@@ -45,8 +45,16 @@ class URL
     MEMPROXY_CLASS(URL);
     URL() : scheme_() {}
     URL(AnyP::UriScheme const &aScheme) : scheme_(aScheme) {}
+
+    void clear() {
+        scheme_=AnyP::PROTO_NONE;
+    }
+
     AnyP::UriScheme const & getScheme() const {return scheme_;}
 
+    /// convert the URL scheme to that given
+    void setScheme(const AnyP::ProtocolType &p) {scheme_=p;}
+
 private:
     /**
      \par
@@ -68,7 +76,7 @@ class URL
      * In order to make taking any of these routes easy, scheme is private
      * and immutable, only settable at construction time,
      */
-    AnyP::UriScheme const scheme_;
+    AnyP::UriScheme scheme_;
 };
 
 MEMPROXY_CLASS_INLINE(URL);
@@ -38,6 +38,7 @@
 #include "defines.h"
 #include "dlink.h"
 #include "MemPool.h"
+#include "SBufList.h"
 
 #include <ostream>
 #include <string>
@@ -121,7 +122,7 @@ class ACL
     virtual void parse() = 0;
     virtual char const *typeString() const = 0;
     virtual bool isProxyAuth() const;
-    virtual wordlist *dump() const = 0;
+    virtual SBufList dump() const = 0;
     virtual bool empty() const = 0;
     virtual bool valid() const;
 
@@ -9,7 +9,6 @@
 #include "cache_cf.h"
 #include "ConfigParser.h"
 #include "Debug.h"
-#include "wordlist.h"
 
 void
 ACLAdaptationServiceData::parse()
@@ -17,10 +17,10 @@ Acl::AllOf::clone() const
     return new AllOf;
 }
 
-wordlist*
+SBufList
 Acl::AllOf::dump() const
 {
-    return empty() ? NULL : nodes.front()->dump();
+    return empty() ? SBufList() : nodes.front()->dump();
 }
 
 int
@@ -18,7 +18,7 @@ class AllOf: public Acl::InnerNode
     virtual char const *typeString() const;
     virtual ACL *clone() const;
     virtual void parse();
-    virtual wordlist *dump() const;
+    virtual SBufList dump() const;
 
 private:
     /* Acl::InnerNode API */
@@ -41,8 +41,8 @@
 #include "cache_cf.h"
 #include "Debug.h"
 #include "eui/Eui48.h"
+#include "globals.h"
 #include "ip/Address.h"
-#include "wordlist.h"
 
 static void aclParseArpList(SplayNode<Eui::Eui48 *> **curlist);
 static int aclMatchArp(SplayNode<Eui::Eui48 *> **dataptr, Ip::Address &c);
@@ -203,15 +203,15 @@ aclDumpArpListWalkee(Eui::Eui48 * const &node, void *state)
 {
     static char buf[48];
     node->encode(buf, 48);
-    wordlistAdd((wordlist **)state, buf);
+    static_cast<SBufList *>(state)->push_back(SBuf(buf));
 }
 
-wordlist *
+SBufList
 ACLARP::dump() const
 {
-    wordlist *w = NULL;
-    data->walk(aclDumpArpListWalkee, &w);
-    return w;
+    SBufList sl;
+    data->walk(aclDumpArpListWalkee, &sl);
+    return sl;
 }
 
 /* ==== END ARP ACL SUPPORT =============================================== */
@@ -58,7 +58,7 @@ class ACLARP : public ACL
     virtual char const *typeString() const;
     virtual void parse();
     virtual int match(ACLChecklist *checklist);
-    virtual wordlist *dump() const;
+    virtual SBufList dump() const;
     virtual bool empty () const;
 
 protected:
@@ -50,7 +50,6 @@
 #include "Store.h"
 #include "StoreClient.h"
 #include "StoreClient.h"
-#include "wordlist.h"
 
 #define WHOIS_PORT 43
 #define	AS_REQBUF_SZ	4096
@@ -551,20 +550,21 @@ ACLASN::match(Ip::Address toMatch)
     return asnMatchIp(data, toMatch);
 }
 
-wordlist *
-ACLASN::dump()
+SBufList
+ACLASN::dump() const
 {
-    wordlist *W = NULL;
-    char buf[32];
+    SBufList sl;
+
     CbDataList<int> *ldata = data;
 
     while (ldata != NULL) {
-        snprintf(buf, sizeof(buf), "%d", ldata->element);
-        wordlistAdd(&W, buf);
+        SBuf s;
+        s.Printf("%d", ldata->element);
+        sl.push_back(s);
         ldata = ldata->next;
     }
 
-    return W;
+    return sl;
 }
 
 bool
@@ -56,7 +56,7 @@ class ACLASN : public ACLData<Ip::Address>
     virtual ~ACLASN();
 
     virtual bool match(Ip::Address);
-    virtual wordlist *dump();
+    virtual SBufList dump() const;
     virtual void parse();
     bool empty() const;
     virtual ACLData<Ip::Address> *clone() const;
@@ -2,7 +2,6 @@
 #include "acl/BoolOps.h"
 #include "acl/Checklist.h"
 #include "Debug.h"
-#include "wordlist.h"
 
 /* Acl::NotNode */
 
@@ -52,11 +51,11 @@ Acl::NotNode::clone() const
     return NULL;
 }
 
-wordlist*
+SBufList
 Acl::NotNode::dump() const
 {
-    wordlist *text = NULL;
-    wordlistAdd(&text, name);
+    SBufList text;
+    text.push_back(SBuf(name));
     return text;
 }
 
@@ -23,7 +23,7 @@ class NotNode: public InnerNode
     virtual char const *typeString() const;
     virtual ACL *clone() const;
     virtual void parse();
-    virtual wordlist *dump() const;
+    virtual SBufList dump() const;
 
     /* Acl::InnerNode API */
     virtual int doMatch(ACLChecklist *checklist, Nodes::const_iterator start) const;
@@ -37,7 +37,7 @@
 /* MS Visual Studio Projects are monolithic, so we need the following
  * #if to exclude the SSL code from compile process when not needed.
  */
-#if USE_SSL
+#if USE_OPENSSL
 
 #include "acl/Certificate.h"
 #include "acl/CertificateData.h"
@@ -67,4 +67,4 @@ ACLCertificateStrategy::Instance()
 
 ACLCertificateStrategy ACLCertificateStrategy::Instance_;
 
-#endif /* USE_SSL */
+#endif /* USE_OPENSSL */
@@ -98,23 +98,23 @@ ACLCertificateData::match(X509 *cert)
 static void
 aclDumpAttributeListWalkee(char * const & node_data, void *outlist)
 {
-    /* outlist is really a wordlist ** */
-    wordlistAdd((wordlist **)outlist, node_data);
+    /* outlist is really a SBufList * */
+    static_cast<SBufList *>(outlist)->push_back(SBuf(node_data));
 }
 
-wordlist *
-ACLCertificateData::dump()
+SBufList
+ACLCertificateData::dump() const
 {
-    wordlist *wl = NULL;
+    SBufList sl;
     if (validAttributesStr)
-        wordlistAdd(&wl, attribute);
+        sl.push_back(SBuf(attribute));
     /* damn this is VERY inefficient for long ACL lists... filling
      * a wordlist this way costs Sum(1,N) iterations. For instance
      * a 1000-elements list will be filled in 499500 iterations.
      */
     /* XXX FIXME: don't break abstraction */
-    values.values->walk(aclDumpAttributeListWalkee, &wl);
-    return wl;
+    values.values->walk(aclDumpAttributeListWalkee, &sl);
+    return sl;
 }
 
 void
@@ -53,7 +53,7 @@ class ACLCertificateData : public ACLData<X509 *>
     ACLCertificateData &operator= (ACLCertificateData const &);
     virtual ~ACLCertificateData();
     bool match(X509 *);
-    wordlist *dump();
+    virtual SBufList dump() const;
     void parse();
     bool empty() const;
     virtual ACLData<X509 *> *clone() const;
@@ -32,7 +32,7 @@
 #ifndef SQUID_ACLDATA_H
 #define SQUID_ACLDATA_H
 
-class wordlist;
+#include "SBufList.h"
 
 /// \ingroup ACLAPI
 template <class M>
@@ -44,7 +44,7 @@ class ACLData
     virtual ~ACLData() {}
 
     virtual bool match(M) =0;
-    virtual wordlist *dump() =0;
+    virtual SBufList dump() const =0;
     virtual void parse() =0;
     virtual ACLData *clone() const =0;
     virtual void prepareForUse() {}
@@ -38,7 +38,6 @@
 #include "cache_cf.h"
 #include "Debug.h"
 #include "src/URL.h"
-#include "wordlist.h"
 
 template<class T>
 inline void
@@ -140,20 +139,20 @@ ACLDomainData::match(char const *host)
 static void
 aclDumpDomainListWalkee(char * const & node_data, void *outlist)
 {
-    /* outlist is really a wordlist ** */
-    wordlistAdd((wordlist **)outlist, (char const *)node_data);
+    /* outlist is really a SBufList ** */
+    static_cast<SBufList *>(outlist)->push_back(SBuf(node_data));
 }
 
-wordlist *
-ACLDomainData::dump()
+SBufList
+ACLDomainData::dump() const
 {
-    wordlist *wl = NULL;
+    SBufList sl;
     /* damn this is VERY inefficient for long ACL lists... filling
      * a wordlist this way costs Sum(1,N) iterations. For instance
      * a 1000-elements list will be filled in 499500 iterations.
      */
-    domains->walk(aclDumpDomainListWalkee, &wl);
-    return wl;
+    domains->walk(aclDumpDomainListWalkee, &sl);
+    return sl;
 }
 
 void
@@ -46,7 +46,7 @@ class ACLDomainData : public ACLData<char const *>
 
     virtual ~ACLDomainData();
     bool match(char const *);
-    wordlist *dump();
+    virtual SBufList dump() const;
     void parse();
     bool empty() const;
     virtual ACLData<char const *> *clone() const;
@@ -41,8 +41,8 @@
 #include "cache_cf.h"
 #include "Debug.h"
 #include "eui/Eui64.h"
+#include "globals.h"
 #include "ip/Address.h"
-#include "wordlist.h"
 
 static void aclParseEuiList(SplayNode<Eui::Eui64 *> **curlist);
 static int aclMatchEui(SplayNode<Eui::Eui64 *> **dataptr, Ip::Address &c);
@@ -177,13 +177,13 @@ aclDumpEuiListWalkee(Eui::Eui64 * const &node, void *state)
 {
     static char buf[48];
     node->encode(buf, 48);
-    wordlistAdd((wordlist **)state, buf);
+    static_cast<SBufList *>(state)->push_back(SBuf(buf));
 }
 
-wordlist *
+SBufList
 ACLEui64::dump() const
 {
-    wordlist *w = NULL;
+    SBufList w;
     data->walk(aclDumpEuiListWalkee, &w);
     return w;
 }
@@ -57,7 +57,7 @@ class ACLEui64 : public ACL
     virtual char const *typeString() const;
     virtual void parse();
     virtual int match(ACLChecklist *checklist);
-    virtual wordlist *dump() const;
+    virtual SBufList dump() const;
     virtual bool empty () const;
 
 protected:
@@ -85,7 +85,7 @@ ACLExtUser::match(ACLChecklist *cl)
     }
 }
 
-wordlist *
+SBufList
 ACLExtUser::dump() const
 {
     return data->dump();
@@ -55,7 +55,7 @@ class ACLExtUser : public ACL
     virtual void parse();
 
     virtual int match(ACLChecklist *checklist);
-    virtual wordlist *dump() const;
+    virtual SBufList dump() const;
     virtual bool empty () const;
     virtual ACL *clone()const;
 
@@ -24,7 +24,7 @@ ACLFilledChecklist::ACLFilledChecklist() :
 #if SQUID_SNMP
         snmp_community(NULL),
 #endif
-#if USE_SSL
+#if USE_OPENSSL
         sslErrors(NULL),
 #endif
         extacl_entry (NULL),
@@ -54,7 +54,7 @@ ACLFilledChecklist::~ACLFilledChecklist()
 
     cbdataReferenceDone(conn_);
 
-#if USE_SSL
+#if USE_OPENSSL
     cbdataReferenceDone(sslErrors);
 #endif
 
@@ -140,7 +140,7 @@ ACLFilledChecklist::ACLFilledChecklist(const acl_access *A, HttpRequest *http_re
 #if SQUID_SNMP
         snmp_community(NULL),
 #endif
-#if USE_SSL
+#if USE_OPENSSL
         sslErrors(NULL),
 #endif
         extacl_entry (NULL),
@@ -8,7 +8,7 @@
 #if USE_AUTH
 #include "auth/UserRequest.h"
 #endif
-#if USE_SSL
+#if USE_OPENSSL
 #include "ssl/support.h"
 #endif
 
@@ -69,7 +69,7 @@ class ACLFilledChecklist: public ACLChecklist
     char *snmp_community;
 #endif
 
-#if USE_SSL
+#if USE_OPENSSL
     /// SSL [certificate validation] errors, in undefined order
     Ssl::CertErrors *sslErrors;
     /// The peer certificate
@@ -262,26 +262,38 @@ aclRegister(ACL *acl)
     }
 }
 
+/// remove registered acl from the centralized deletion set
+static
+void
+aclDeregister(ACL *acl)
+{
+    if (acl->registered) {
+        if (RegisteredAcls)
+            RegisteredAcls->erase(acl);
+        acl->registered = false;
+    }
+}
+
 /*********************/
 /* Destroy functions */
 /*********************/
 
-/// helper for RegisteredAcls cleanup
-static void
-aclDeleteOne(ACL *acl)
-{
-    delete acl;
-}
-
 /// called to delete ALL Acls.
 void
 aclDestroyAcls(ACL ** head)
 {
     *head = NULL; // Config.aclList
     if (AclSet *acls = RegisteredAcls) {
         debugs(28, 8, "deleting all " << acls->size() << " ACLs");
-        std::for_each(acls->begin(), acls->end(), &aclDeleteOne);
-        acls->clear();
+        while (!acls->empty()) {
+            ACL *acl = *acls->begin();
+            // We use centralized deletion (this function) so ~ACL should not
+            // delete other ACLs, but we still deregister first to prevent any
+            // accesses to the being-deleted ACL via RegisteredAcls.
+            assert(acl->registered); // make sure we are making progress
+            aclDeregister(acl);
+            delete acl;
+        }
     }
 }
 
@@ -290,7 +302,8 @@ aclDestroyAclList(ACLList **list)
 {
     debugs(28, 8, "aclDestroyAclList: invoked");
     assert(list);
-    cbdataFree(*list);
+    delete *list;
+    *list = NULL;
 }
 
 void
@@ -299,7 +312,8 @@ aclDestroyAccessList(acl_access ** list)
     assert(list);
     if (*list)
         debugs(28, 3, "destroying: " << *list << ' ' << (*list)->name);
-    cbdataFree(*list);
+    delete *list;
+    *list = NULL;
 }
 
 /* maex@space.net (06.09.1996)
@@ -3,7 +3,6 @@
 #include "acl/HierCodeData.h"
 #include "cache_cf.h"
 #include "hier_code.h"
-#include "wordlist.h"
 
 ACLHierCodeData::ACLHierCodeData()
 {
@@ -25,17 +24,17 @@ ACLHierCodeData::match(hier_code toFind)
     return values[toFind];
 }
 
-wordlist *
-ACLHierCodeData::dump()
+SBufList
+ACLHierCodeData::dump() const
 {
-    wordlist *W = NULL;
+    SBufList sl;
 
     for (hier_code iter=HIER_NONE; iter<HIER_MAX; ++iter) {
         if (!values[iter]) continue;
-        wordlistAdd(&W, hier_code_str[iter]);
+        sl.push_back(SBuf(hier_code_str[iter]));
     }
 
-    return W;
+    return sl;
 }
 
 void
@@ -18,7 +18,7 @@ class ACLHierCodeData : public ACLData<hier_code>
     ACLHierCodeData &operator= (ACLHierCodeData const &);
     virtual ~ACLHierCodeData();
     bool match(hier_code);
-    wordlist *dump();
+    virtual SBufList dump() const;
     void parse();
     bool empty() const;
     virtual ACLData<hier_code> *clone() const;
@@ -42,7 +42,6 @@
 #include "Debug.h"
 #include "HttpHeaderTools.h"
 #include "SBuf.h"
-#include "wordlist.h"
 
 /* Construct an ACLHTTPHeaderData that uses an ACLRegex rule with the value of the
  * selected header from a given request.
@@ -80,15 +79,15 @@ ACLHTTPHeaderData::match(HttpHeader* hdr)
     return regex_rule->match(cvalue.c_str());
 }
 
-wordlist *
-ACLHTTPHeaderData::dump()
+SBufList
+ACLHTTPHeaderData::dump() const
 {
-    wordlist *W = NULL;
-    wordlistAdd(&W, hdrName.termedBuf());
-    wordlist * regex_dump = regex_rule->dump();
-    wordlistAddWl(&W, regex_dump);
-    wordlistDestroy(&regex_dump);
-    return W;
+    SBufList sl;
+    sl.push_back(SBuf(hdrName));
+    // temp is needed until c++11 move-constructor
+    SBufList temp = regex_rule->dump();
+    sl.splice(sl.end(), temp);
+    return sl;
 }
 
 void
@@ -54,7 +54,7 @@ class ACLHTTPHeaderData : public ACLData<HttpHeader*>
     ACLHTTPHeaderData();
     virtual ~ACLHTTPHeaderData();
     virtual bool match(HttpHeader* hdr);
-    virtual wordlist *dump();
+    virtual SBufList dump() const;
     virtual void parse();
     virtual bool empty() const;
     virtual ACLData<HttpHeader*> *clone() const;
@@ -38,7 +38,6 @@
 #include "cache_cf.h"
 #include "Debug.h"
 #include "HttpReply.h"
-#include "wordlist.h"
 
 #include <climits>
 
@@ -50,14 +49,17 @@ acl_httpstatus_data::acl_httpstatus_data(int x) : status1(x), status2(x) { ; }
 
 acl_httpstatus_data::acl_httpstatus_data(int x, int y) : status1(x), status2(y) { ; }
 
-void acl_httpstatus_data::toStr(char* buf, int len) const
+SBuf
+acl_httpstatus_data::toStr() const
 {
+    SBuf rv;
     if (status2 == INT_MAX)
-        snprintf(buf, len, "%d-", status1);
+        rv.Printf("%d-", status1);
     else if (status1 == status2)
-        snprintf(buf, len, "%d", status1);
+        rv.Printf("%d", status1);
     else
-        snprintf(buf, len, "%d-%d", status1, status2);
+        rv.Printf("%d-%d", status1, status2);
+    return rv;
 }
 
 int acl_httpstatus_data::compare(acl_httpstatus_data* const& a, acl_httpstatus_data* const& b)
@@ -69,13 +71,11 @@ int acl_httpstatus_data::compare(acl_httpstatus_data* const& a, acl_httpstatus_d
         ret = aclHTTPStatusCompare(a, b);
 
     if (ret == 0) {
-        char bufa[8];
-        char bufb[8];
-        a->toStr(bufa, sizeof(bufa));
-        b->toStr(bufb, sizeof(bufb));
-        debugs(28, DBG_CRITICAL, "WARNING: '" << bufa << "' is a subrange of '" << bufb << "'");
-        debugs(28, DBG_CRITICAL, "WARNING: because of this '" << bufa << "' is ignored to keep splay tree searching predictable");
-        debugs(28, DBG_CRITICAL, "WARNING: You should probably remove '" << bufb << "' from the ACL named '" << AclMatchedName << "'");
+        const SBuf sa = a->toStr();
+        const SBuf sb = b->toStr();
+        debugs(28, DBG_CRITICAL, "WARNING: '" << sa << "' is a subrange of '" << sb << "'");
+        debugs(28, DBG_CRITICAL, "WARNING: because of this '" << sa << "' is ignored to keep splay tree searching predictable");
+        debugs(28, DBG_CRITICAL, "WARNING: You should probably remove '" << sb << "' from the ACL named '" << AclMatchedName << "'");
     }
 
     return ret;
@@ -184,15 +184,14 @@ aclHTTPStatusCompare(acl_httpstatus_data * const &a, acl_httpstatus_data * const
 static void
 aclDumpHTTPStatusListWalkee(acl_httpstatus_data * const &node, void *state)
 {
-    static char buf[8];
-    node->toStr(buf, sizeof(buf));
-    wordlistAdd((wordlist **)state, buf);
+    // state is a SBufList*
+    static_cast<SBufList *>(state)->push_back(node->toStr());
 }
 
-wordlist *
+SBufList
 ACLHTTPStatus::dump() const
 {
-    wordlist *w = NULL;
+    SBufList w;
     data->walk(aclDumpHTTPStatusListWalkee, &w);
     return w;
 }
@@ -42,7 +42,7 @@ struct acl_httpstatus_data {
     int status1, status2;
     acl_httpstatus_data(int);
     acl_httpstatus_data(int, int);
-    void toStr(char* buf, int len) const;
+    SBuf toStr() const; // was toStr
 
     static int compare(acl_httpstatus_data* const& a, acl_httpstatus_data* const& b);
 };
@@ -63,7 +63,7 @@ class ACLHTTPStatus : public ACL
     virtual char const *typeString() const;
     virtual void parse();
     virtual int match(ACLChecklist *checklist);
-    virtual wordlist *dump() const;
+    virtual SBufList dump() const;
     virtual bool empty () const;
     virtual bool requiresReply() const { return true; }
 
@@ -2,12 +2,12 @@
 #include "acl/Acl.h"
 #include "acl/BoolOps.h"
 #include "acl/Checklist.h"
+#include "acl/Gadgets.h"
 #include "acl/InnerNode.h"
 #include "cache_cf.h"
 #include "ConfigParser.h"
 #include "Debug.h"
 #include "globals.h"
-#include "wordlist.h"
 #include <algorithm>
 
 void
@@ -27,6 +27,7 @@ Acl::InnerNode::add(ACL *node)
 {
     assert(node != NULL);
     nodes.push_back(node);
+    aclRegister(node);
 }
 
 // one call parses one "acl name acltype name1 name2 ..." line
@@ -64,13 +65,13 @@ Acl::InnerNode::lineParse()
     return;
 }
 
-wordlist*
+SBufList
 Acl::InnerNode::dump() const
 {
-    wordlist *values = NULL;
+    SBufList rv;
     for (Nodes::const_iterator i = nodes.begin(); i != nodes.end(); ++i)
-        wordlistAdd(&values, (*i)->name);
-    return values;
+        rv.push_back(SBuf((*i)->name));
+    return rv;
 }
 
 int
@@ -24,7 +24,7 @@ class InnerNode: public ACL
     /* ACL API */
     virtual void prepareForUse();
     virtual bool empty() const;
-    virtual wordlist *dump() const;
+    virtual SBufList dump() const;
 
     /// parses one "acl name type acl1 acl2..." line, appending to nodes
     void lineParse();
@@ -37,7 +37,6 @@
 #include "cache_cf.h"
 #include "Debug.h"
 #include "Parsing.h"
-#include "wordlist.h"
 
 /* explicit instantiation required for some systems */
 /** \cond AUTODOCS_IGNORE */
@@ -109,27 +108,27 @@ ACLIntRange::clone() const
     return new ACLIntRange (*this);
 }
 
-ACLIntRange::~ACLIntRange ()
+ACLIntRange::~ACLIntRange()
 {}
 
-wordlist *
-ACLIntRange::dump ()
+SBufList
+ACLIntRange::dump() const
 {
-    wordlist *W = NULL;
-    char buf[32];
+    SBufList sl;
     CbDataListIterator<RangeType> iter(ranges);
 
     while (!iter.end()) {
+        SBuf sb;
         const RangeType & element = iter.next();
 
         if (element.size() == 1)
-            snprintf(buf, sizeof(buf), "%d", element.start);
+            sb.Printf("%d", element.start);
         else
-            snprintf(buf, sizeof(buf), "%d-%d", element.start, element.end-1);
+            sb.Printf("%d-%d", element.start, element.end-1);
 
-        wordlistAdd(&W, buf);
+        sl.push_back(sb);
     }
 
-    return W;
+    return sl;
 }
 
@@ -46,7 +46,7 @@ class ACLIntRange : public ACLData<int>
 
     virtual ~ACLIntRange();
     virtual bool match(int);
-    virtual wordlist *dump();
+    virtual SBufList dump() const;
     virtual void parse();
     virtual bool empty() const;
     virtual ACLData<int> *clone() const;
@@ -62,20 +62,7 @@ ACLIP::operator delete (void *address)
 void
 ACLIP::DumpIpListWalkee(acl_ip_data * const & ip, void *state)
 {
-    char tmpbuf[ ((MAX_IPSTRLEN*2)+6) ]; // space for 2 IPs and a CIDR mask(3) and seperators(3).
-    MemBuf mb;
-    wordlist **W = static_cast<wordlist **>(state);
-    tmpbuf[0] = '\0';
-
-    mb.init();
-    assert(mb.max_capacity > 0 && 1==1 );
-
-    ip->toStr(tmpbuf, sizeof(tmpbuf) );
-    assert(mb.max_capacity > 0 && 2==2 );
-    mb.append(tmpbuf, strlen(tmpbuf) );
-    assert(mb.max_capacity > 0 && 3==3);
-    wordlistAdd(W, mb.buf);
-    mb.clean();
+    static_cast<SBufList *>(state)->push_back(ip->toSBuf());
 }
 
 /**
@@ -115,6 +102,15 @@ acl_ip_data::toStr(char *buf, int len) const
         b3[0] = '\0';
 }
 
+SBuf
+acl_ip_data::toSBuf() const
+{
+    const int bufsz = MAX_IPSTRLEN*2+6;
+    static char tmpbuf[ bufsz ];
+    toStr(tmpbuf,bufsz);
+    return SBuf(tmpbuf);
+}
+
 /*
  * aclIpAddrNetworkCompare - The guts of the comparison for IP ACLs
  * matching checks.  The first argument (p) is a "host" address,
@@ -528,16 +524,16 @@ ACLIP::~ACLIP()
         data->destroy(IPSplay::DefaultFree);
 }
 
-wordlist *
+SBufList
 ACLIP::dump() const
 {
-    wordlist *w = NULL;
-    data->walk (DumpIpListWalkee, &w);
-    return w;
+    SBufList sl;
+    data->walk(DumpIpListWalkee, &sl);
+    return sl;
 }
 
 bool
-ACLIP::empty () const
+ACLIP::empty() const
 {
     return data->empty();
 }
@@ -561,6 +557,6 @@ ACLIP::match(Ip::Address &clientip)
     return !splayLastResult;
 }
 
-acl_ip_data::acl_ip_data () :addr1(), addr2(), mask(), next (NULL) {}
+acl_ip_data::acl_ip_data() :addr1(), addr2(), mask(), next (NULL) {}
 
-acl_ip_data::acl_ip_data (Ip::Address const &anAddress1, Ip::Address const &anAddress2, Ip::Address const &aMask, acl_ip_data *aNext) : addr1(anAddress1), addr2(anAddress2), mask(aMask), next(aNext) {}
+acl_ip_data::acl_ip_data(Ip::Address const &anAddress1, Ip::Address const &anAddress2, Ip::Address const &aMask, acl_ip_data *aNext) : addr1(anAddress1), addr2(anAddress2), mask(aMask), next(aNext) {}
@@ -50,6 +50,7 @@ class acl_ip_data
 
     acl_ip_data (Ip::Address const &, Ip::Address const &, Ip::Address const &, acl_ip_data *);
     void toStr(char *buf, int len) const;
+    SBuf toSBuf() const;
 
     Ip::Address addr1;
 
@@ -85,7 +86,7 @@ class ACLIP : public ACL
     virtual void parse();
     //    virtual bool isProxyAuth() const {return true;}
     virtual int match(ACLChecklist *checklist) = 0;
-    virtual wordlist *dump() const;
+    virtual SBufList dump() const;
     virtual bool empty () const;
 
 protected:
@@ -39,7 +39,6 @@
 #include "client_db.h"
 #include "Debug.h"
 #include "SquidConfig.h"
-#include "wordlist.h"
 
 ACL *
 ACLMaxConnection::clone() const
@@ -104,21 +103,17 @@ ACLMaxConnection::match(ACLChecklist *checklist)
     return clientdbEstablished(Filled(checklist)->src_addr, 0) > limit ? 1 : 0;
 }
 
-wordlist *
+SBufList
 ACLMaxConnection::dump() const
 {
+    SBufList sl;
     if (!limit)
-        return NULL;
+        return sl;
 
-    wordlist *W = NULL;
-
-    char buf[32];
-
-    snprintf(buf, sizeof(buf), "%d", limit);
-
-    wordlistAdd(&W, buf);
-
-    return W;
+    SBuf s;
+    s.Printf("%d", limit);
+    sl.push_back(s);
+    return sl;
 }
 
 void
@@ -52,7 +52,7 @@ class ACLMaxConnection : public ACL
     virtual char const *typeString() const;
     virtual void parse();
     virtual int match(ACLChecklist *checklist);
-    virtual wordlist *dump() const;
+    virtual SBufList dump() const;
     virtual bool empty () const;
     virtual bool valid () const;
     virtual void prepareForUse();
@@ -37,7 +37,6 @@
 #include "acl/MethodData.h"
 #include "cache_cf.h"
 #include "HttpRequestMethod.h"
-#include "wordlist.h"
 
 int ACLMethodData::ThePurgeCount = 0;
 
@@ -68,18 +67,18 @@ ACLMethodData::match(HttpRequestMethod toFind)
 template cbdata_type CbDataList<HttpRequestMethod>::CBDATA_CbDataList;
 /// \endcond
 
-wordlist *
-ACLMethodData::dump()
+SBufList
+ACLMethodData::dump() const
 {
-    wordlist *W = NULL;
+    SBufList sl;
     CbDataList<HttpRequestMethod> *data = values;
 
     while (data != NULL) {
-        wordlistAdd(&W, RequestMethodStr(data->element));
+        sl.push_back(data->element.image());
         data = data->next;
     }
 
-    return W;
+    return sl;
 }
 
 void
@@ -90,9 +89,9 @@ ACLMethodData::parse()
 
     for (Tail = &values; *Tail; Tail = &((*Tail)->next));
     while ((t = strtokFile())) {
-        if (strcmp(t, "PURGE") == 0)
-            ++ThePurgeCount; // configuration code wants to know
         CbDataList<HttpRequestMethod> *q = new CbDataList<HttpRequestMethod> (HttpRequestMethod(t, NULL));
+        if (q->element == Http::METHOD_PURGE)
+            ++ThePurgeCount; // configuration code wants to know
         *(Tail) = q;
         Tail = &q->next;
     }
@@ -50,7 +50,7 @@ class ACLMethodData : public ACLData<HttpRequestMethod>
     ACLMethodData &operator= (ACLMethodData const &);
     virtual ~ACLMethodData();
     bool match(HttpRequestMethod);
-    wordlist *dump();
+    virtual SBufList dump() const;
     void parse();
     bool empty() const;
     virtual ACLData<HttpRequestMethod> *clone() const;
@@ -51,15 +51,15 @@ ACLNoteData::match(HttpRequest *request)
     return false;
 }
 
-wordlist *
-ACLNoteData::dump()
+SBufList
+ACLNoteData::dump() const
 {
-    wordlist *W = NULL;
-    wordlistAdd(&W, name.termedBuf());
-    wordlist * dumpR = values->dump();
-    wordlistAddWl(&W, dumpR);
-    wordlistDestroy(&dumpR);
-    return W;
+    SBufList sl;
+    sl.push_back(SBuf(name));
+    // temp is needed until c++11 move constructor
+    SBufList temp = values->dump();
+    sl.splice(sl.end(), temp);
+    return sl;
 }
 
 void
@@ -17,7 +17,7 @@ class ACLNoteData : public ACLData<HttpRequest *>
     ACLNoteData();
     virtual ~ACLNoteData();
     virtual bool match(HttpRequest* request);
-    virtual wordlist *dump();
+    virtual SBufList dump() const;
     virtual void parse();
     virtual bool empty() const;
     virtual ACLData<HttpRequest *> *clone() const;
@@ -42,9 +42,9 @@
 template class ACLStrategised<AnyP::ProtocolType>;
 
 int
-ACLProtocolStrategy::match (ACLData<MatchType> * &data, ACLFilledChecklist *checklist, ACLFlags &)
+ACLProtocolStrategy::match(ACLData<MatchType> * &data, ACLFilledChecklist *checklist, ACLFlags &)
 {
-    return data->match (checklist->request->protocol);
+    return data->match(checklist->request->url.getScheme());
 }
 
 ACLProtocolStrategy *
@@ -65,18 +65,18 @@ ACLProtocolData::match(AnyP::ProtocolType toFind)
 template cbdata_type CbDataList<AnyP::ProtocolType>::CBDATA_CbDataList;
 /// \endcond
 
-wordlist *
-ACLProtocolData::dump()
+SBufList
+ACLProtocolData::dump() const
 {
-    wordlist *W = NULL;
+    SBufList sl;
     CbDataList<AnyP::ProtocolType> *data = values;
 
     while (data != NULL) {
-        wordlistAdd(&W, AnyP::ProtocolType_str[data->element]);
+        sl.push_back(SBuf(AnyP::ProtocolType_str[data->element]));
         data = data->next;
     }
 
-    return W;
+    return sl;
 }
 
 void
@@ -50,7 +50,7 @@ class ACLProtocolData : public ACLData<AnyP::ProtocolType>
     ACLProtocolData &operator= (ACLProtocolData const &);
     virtual ~ACLProtocolData();
     bool match(AnyP::ProtocolType);
-    wordlist *dump();
+    virtual SBufList dump() const;
     void parse();
     bool empty() const;
     virtual ACLData<AnyP::ProtocolType> *clone() const;
@@ -135,10 +135,10 @@ ACLRandom::match(ACLChecklist *cl)
     return (data > random)?1:0;
 }
 
-wordlist *
+SBufList
 ACLRandom::dump() const
 {
-    wordlist *w = NULL;
-    wordlistAdd(&w, pattern);
-    return w;
+    SBufList sl;
+    sl.push_back(SBuf(pattern));
+    return sl;
 }
@@ -51,7 +51,7 @@ class ACLRandom : public ACL
     virtual char const *typeString() const;
     virtual void parse();
     virtual int match(ACLChecklist *checklist);
-    virtual wordlist *dump() const;
+    virtual SBufList dump() const;
     virtual bool empty () const;
     virtual bool valid() const;
 
@@ -101,28 +101,28 @@ ACLRegexData::match(char const *word)
     return 0;
 }
 
-wordlist *
-ACLRegexData::dump()
+SBufList
+ACLRegexData::dump() const
 {
-    wordlist *W = NULL;
+    SBufList sl;
     RegexList *temp = data;
     int flags = REG_EXTENDED | REG_NOSUB;
 
     while (temp != NULL) {
         if (temp->flags != flags) {
             if ((temp->flags&REG_ICASE) != 0) {
-                wordlistAdd(&W, "-i");
+                sl.push_back(SBuf("-i"));
             } else {
-                wordlistAdd(&W, "+i");
+                sl.push_back(SBuf("+i"));
             }
             flags = temp->flags;
         }
 
-        wordlistAdd(&W, temp->pattern);
+        sl.push_back(SBuf(temp->pattern));
         temp = temp->next;
     }
 
-    return W;
+    return sl;
 }
 
 static const char *
@@ -45,7 +45,7 @@ class ACLRegexData : public ACLData<char const *>
 
     virtual ~ACLRegexData();
     virtual bool match(char const *user);
-    virtual wordlist *dump();
+    virtual SBufList dump() const;
     virtual void parse();
     virtual bool empty() const;
     virtual ACLData<char const *> *clone() const;
@@ -3,7 +3,7 @@
 
 #include "squid.h"
 
-#if USE_SSL
+#if USE_OPENSSL
 
 #include "acl/CertificateData.h"
 #include "acl/Checklist.h"
@@ -35,4 +35,4 @@ ACLServerCertificateStrategy::Instance()
 
 ACLServerCertificateStrategy ACLServerCertificateStrategy::Instance_;
 
-#endif /* USE_SSL */
+#endif /* USE_OPENSSL */
@@ -67,18 +67,16 @@ ACLSslErrorData::match(const Ssl::CertErrors *toFind)
 // template cbdata_type Ssl::Errors::CBDATA_CbDataList;
 /** \endcond */
 
-wordlist *
-ACLSslErrorData::dump()
+SBufList
+ACLSslErrorData::dump() const
 {
-    wordlist *W = NULL;
+    SBufList sl;
     Ssl::Errors *data = values;
-
     while (data != NULL) {
-        wordlistAdd(&W, Ssl::GetErrorName(data->element));
+        sl.push_back(SBuf(Ssl::GetErrorName(data->element)));
         data = data->next;
     }
-
-    return W;
+    return sl;
 }
 
 void
@@ -18,7 +18,7 @@ class ACLSslErrorData : public ACLData<const Ssl::CertErrors *>
     ACLSslErrorData &operator= (ACLSslErrorData const &);
     virtual ~ACLSslErrorData();
     bool match(const Ssl::CertErrors *);
-    wordlist *dump();
+    virtual SBufList dump() const;
     void parse();
     bool empty() const;
     virtual  ACLSslErrorData *clone() const;
@@ -63,7 +63,7 @@ class ACLStrategised : public ACL
     virtual void parse();
     virtual int match(ACLChecklist *checklist);
     virtual int match (M const &);
-    virtual wordlist *dump() const;
+    virtual SBufList dump() const;
     virtual bool empty () const;
     virtual bool valid () const;
     virtual ACL *clone()const;
@@ -161,7 +161,7 @@ ACLStrategised<MatchType>::match(MatchType const &toFind)
 }
 
 template <class MatchType>
-wordlist *
+SBufList
 ACLStrategised<MatchType>::dump() const
 {
     return data->dump();
@@ -37,7 +37,6 @@
 #include "acl/StringData.h"
 #include "cache_cf.h"
 #include "Debug.h"
-#include "wordlist.h"
 
 ACLStringData::ACLStringData() : values (NULL)
 {}
@@ -90,20 +89,20 @@ ACLStringData::match(char const *toFind)
 static void
 aclDumpStringWalkee(char * const & node_data, void *outlist)
 {
-    /* outlist is really a wordlist ** */
-    wordlistAdd((wordlist **)outlist, node_data);
+    /* outlist is really a SBufList* */
+    static_cast<SBufList*>(outlist)->push_back(SBuf(node_data));
 }
 
-wordlist *
-ACLStringData::dump()
+SBufList
+ACLStringData::dump() const
 {
-    wordlist *wl = NULL;
+    SBufList sl;
     /* damn this is VERY inefficient for long ACL lists... filling
-     * a wordlist this way costs Sum(1,N) iterations. For instance
+     * a SBufList this way costs Sum(1,N) iterations. For instance
      * a 1000-elements list will be filled in 499500 iterations.
      */
-    values->walk(aclDumpStringWalkee, &wl);
-    return wl;
+    values->walk(aclDumpStringWalkee, &sl);
+    return sl;
 }
 
 void
@@ -48,7 +48,7 @@ class ACLStringData : public ACLData<char const *>
     ACLStringData &operator= (ACLStringData const &);
     virtual ~ACLStringData();
     bool match(char const *);
-    wordlist *dump();
+    virtual SBufList dump() const;
     virtual void parse();
     bool empty() const;
     virtual ACLData<char const *> *clone() const;
@@ -97,15 +97,15 @@ ACLTimeData::match(time_t when)
     return 0;
 }
 
-wordlist *
-ACLTimeData::dump()
+SBufList
+ACLTimeData::dump() const
 {
-    wordlist *W = NULL;
-    char buf[128];
-    ACLTimeData *t = this;
+    SBufList sl;
+    const ACLTimeData *t = this;
 
     while (t != NULL) {
-        snprintf(buf, sizeof(buf), "%c%c%c%c%c%c%c %02d:%02d-%02d:%02d",
+        SBuf s;
+        s.Printf("%c%c%c%c%c%c%c %02d:%02d-%02d:%02d",
                  t->weekbits & ACL_SUNDAY ? 'S' : '-',
                  t->weekbits & ACL_MONDAY ? 'M' : '-',
                  t->weekbits & ACL_TUESDAY ? 'T' : '-',
@@ -114,11 +114,11 @@ ACLTimeData::dump()
                  t->weekbits & ACL_FRIDAY ? 'F' : '-',
                  t->weekbits & ACL_SATURDAY ? 'A' : '-',
                  t->start / 60, t->start % 60, t->stop / 60, t->stop % 60);
-        wordlistAdd(&W, buf);
+        sl.push_back(s);
         t = t->next;
     }
 
-    return W;
+    return sl;
 }
 
 void
@@ -48,7 +48,7 @@ class ACLTimeData : public ACLData<time_t>
     ACLTimeData&operator=(ACLTimeData const &);
     virtual ~ACLTimeData();
     bool match(time_t);
-    wordlist *dump();
+    virtual SBufList dump() const;
     void parse();
     bool empty() const;
     virtual ACLData<time_t> *clone() const;
@@ -48,28 +48,27 @@ Acl::Tree::add(ACL *rule)
     InnerNode::add(rule);
 }
 
-wordlist*
+SBufList
 Acl::Tree::treeDump(const char *prefix, const ActionToString &convert) const
 {
-    wordlist *text = NULL;
+    SBufList text;
     Actions::const_iterator action = actions.begin();
     typedef Nodes::const_iterator NCI;
     for (NCI node = nodes.begin(); node != nodes.end(); ++node) {
 
-        wordlistAdd(&text, prefix);
+        text.push_back(SBuf(prefix));
 
         if (action != actions.end()) {
             const char *act = convert ? convert[action->kind] :
                               (*action == ACCESS_ALLOWED ? "allow" : "deny");
-            wordlistAdd(&text, act ? act : "???");
+            text.push_back(act?SBuf(act):SBuf("???"));
             ++action;
         }
 
-        wordlist *rule = (*node)->dump();
-        wordlistAddWl(&text, rule);
-        wordlistDestroy(&rule);
-
-        wordlistAdd(&text, "\n");
+        // temp is needed until c++11 move constructor
+        SBufList temp = (*node)->dump();
+        text.splice(text.end(), temp);
+        text.push_back(SBuf("\n"));
     }
     return text;
 }
@@ -2,6 +2,7 @@
 #define SQUID_ACL_TREE_H
 
 #include "acl/BoolOps.h"
+#include "SBufList.h"
 
 namespace Acl
 {
@@ -14,7 +15,7 @@ class Tree: public OrNode
     /// dumps <name, action, rule, new line> tuples
     /// action.kind is mapped to a string using the supplied conversion table
     typedef const char **ActionToString;
-    wordlist* treeDump(const char *name, const ActionToString &convert) const;
+    SBufList treeDump(const char *name, const ActionToString &convert) const;
 
     /// Returns the corresponding action after a successful tree match.
     allow_t winningAction() const;
@@ -37,7 +37,6 @@
 #include "acl/UserData.h"
 #include "ConfigParser.h"
 #include "Debug.h"
-#include "wordlist.h"
 
 template<class T>
 inline void
@@ -97,28 +96,28 @@ ACLUserData::match(char const *user)
 static void
 aclDumpUserListWalkee(char * const & node_data, void *outlist)
 {
-    /* outlist is really a wordlist ** */
-    wordlistAdd((wordlist **)outlist, (char const *)node_data);
+    /* outlist is really a SBufList* */
+    static_cast<SBufList *>(outlist)->push_back(SBuf(node_data));
 }
 
-wordlist *
-ACLUserData::dump()
+SBufList
+ACLUserData::dump() const
 {
-    wordlist *wl = NULL;
+    SBufList sl;
 
     if (flags.case_insensitive)
-        wordlistAdd(&wl, "-i");
+        sl.push_back(SBuf("-i"));
 
     /* damn this is VERY inefficient for long ACL lists... filling
-     * a wordlist this way costs Sum(1,N) iterations. For instance
+     * a SBufList this way costs Sum(1,N) iterations. For instance
      * a 1000-elements list will be filled in 499500 iterations.
      */
     if (flags.required)
-        wordlistAdd(&wl, "REQUIRED");
+        sl.push_back(SBuf("REQUIRED"));
     else if (names)
-        names->walk(aclDumpUserListWalkee, &wl);
+        names->walk(aclDumpUserListWalkee, &sl);
 
-    return wl;
+    return sl;
 }
 
 void
@@ -45,7 +45,7 @@ class ACLUserData : public ACLData<char const *>
 
     virtual ~ACLUserData();
     bool match(char const *user);
-    wordlist *dump();
+    virtual SBufList dump() const;
     void parse();
     bool empty() const;
     virtual ACLData<char const *> *clone() const;
@@ -1,5 +1,6 @@
 #include "squid.h"
 #include "acl/Gadgets.h"
+#include "acl/Tree.h"
 #include "adaptation/AccessRule.h"
 #include "adaptation/Service.h"
 #include "adaptation/ServiceGroups.h"
@@ -14,7 +15,7 @@ Adaptation::AccessRule::AccessRule(const String &aGroupId): id(++LastId), groupI
 
 Adaptation::AccessRule::~AccessRule()
 {
-    // XXX: leaking acls here?
+    delete acl;
 }
 
 void
@@ -51,8 +52,8 @@ Adaptation::AccessRule::group()
 Adaptation::AccessRules &
 Adaptation::AllRules()
 {
-    static AccessRules TheRules;
-    return TheRules;
+    static AccessRules *TheRules = new AccessRules;
+    return *TheRules;
 }
 
 // TODO: make AccessRules::find work
@@ -54,8 +54,8 @@ Adaptation::Service::wants(const ServiceFilter &filter) const
 Adaptation::Services &
 Adaptation::AllServices()
 {
-    static Services TheServices;
-    return TheServices;
+    static Services *TheServices = new Services;
+    return *TheServices;
 }
 
 Adaptation::ServicePointer
@@ -315,8 +315,8 @@ Adaptation::ServicePlan::print(std::ostream &os) const
 Adaptation::Groups &
 Adaptation::AllGroups()
 {
-    static Groups TheGroups;
-    return TheGroups;
+    static Groups *TheGroups = new Groups;
+    return *TheGroups;
 }
 
 Adaptation::ServiceGroupPointer
@@ -45,7 +45,6 @@ Adaptation::Ecap::Host::Host()
     libecap::protocolWais.assignHostId(AnyP::PROTO_WAIS);
     libecap::protocolUrn.assignHostId(AnyP::PROTO_URN);
     libecap::protocolWhois.assignHostId(AnyP::PROTO_WHOIS);
-    protocolInternal.assignHostId(AnyP::PROTO_INTERNAL);
     protocolCacheObj.assignHostId(AnyP::PROTO_CACHE_OBJECT);
     protocolIcp.assignHostId(AnyP::PROTO_ICP);
 #if USE_HTCP
@@ -135,7 +135,7 @@ libecap::Name
 Adaptation::Ecap::FirstLineRep::protocol() const
 {
     // TODO: optimize?
-    switch (theMessage.protocol) {
+    switch (theMessage.http_ver.protocol) {
     case AnyP::PROTO_HTTP:
         return libecap::protocolHttp;
     case AnyP::PROTO_HTTPS:
@@ -158,8 +158,6 @@ Adaptation::Ecap::FirstLineRep::protocol() const
 #endif
     case AnyP::PROTO_CACHE_OBJECT:
         return protocolCacheObj;
-    case AnyP::PROTO_INTERNAL:
-        return protocolInternal;
     case AnyP::PROTO_ICY:
         return protocolIcy;
     case AnyP::PROTO_COAP:
@@ -181,7 +179,7 @@ void
 Adaptation::Ecap::FirstLineRep::protocol(const Name &p)
 {
     // TODO: what happens if we fail to translate some protocol?
-    theMessage.protocol = TranslateProtocolId(p);
+    theMessage.http_ver.protocol = TranslateProtocolId(p);
 }
 
 AnyP::ProtocolType
@@ -254,7 +252,7 @@ Adaptation::Ecap::RequestLineRep::method() const
     case Http::METHOD_TRACE:
         return libecap::methodTrace;
     default:
-        return Name(theMessage.method.image());
+        return Name(theMessage.method.image().toStdString());
     }
 }
 
@@ -101,7 +101,7 @@ int
 Adaptation::Ecap::Engine::checkEvents(int)
 {
     // Start with the default I/O loop timeout, convert from milliseconds.
-    static const struct timeval maxTimeout {
+    static const struct timeval maxTimeout = {
         EVENT_LOOP_TIMEOUT/1000, // seconds
         (EVENT_LOOP_TIMEOUT % 1000)*1000
     }; // microseconds
@@ -28,7 +28,7 @@ class History: public RefCountable
     int processingTime() const;
 
     String rfc931; ///< the username from ident
-#if USE_SSL
+#if USE_OPENSSL
     String ssluser; ///< the username from SSL
 #endif
     LogTags logType; ///< the squid request status (TCP_MISS etc)
@@ -1285,7 +1285,7 @@ void Adaptation::Icap::ModXact::finalizeLogInfo()
     if (h->rfc931.size())
         al.cache.rfc931 = h->rfc931.termedBuf();
 
-#if USE_SSL
+#if USE_OPENSSL
     if (h->ssluser.size())
         al.cache.ssluser = h->ssluser.termedBuf();
 #endif
@@ -147,7 +147,7 @@ void Adaptation::Icap::ServiceRep::putConnection(const Comm::ConnectionPointer &
 void Adaptation::Icap::ServiceRep::noteConnectionUse(const Comm::ConnectionPointer &conn)
 {
     Must(Comm::IsConnOpen(conn));
-    fd_table[conn->fd].noteUse(NULL); // pconn re-use but not via PconnPool API
+    fd_table[conn->fd].noteUse(); // pconn re-use, albeit not via PconnPool API
 }
 
 void Adaptation::Icap::ServiceRep::noteConnectionFailed(const char *comment)
@@ -10,6 +10,7 @@
 #include "comm.h"
 #include "comm/Connection.h"
 #include "comm/ConnOpener.h"
+#include "comm/Read.h"
 #include "comm/Write.h"
 #include "CommCalls.h"
 #include "err_detail_type.h"
@@ -120,7 +121,7 @@ Adaptation::Icap::Xaction::openConnection()
         CbcPointer<Xaction> self(this);
         Dialer dialer(self, &Adaptation::Icap::Xaction::noteCommConnected);
         dialer.params.conn = connection;
-        dialer.params.flag = COMM_OK;
+        dialer.params.flag = Comm::OK;
         // fake other parameters by copying from the existing connection
         connector = asyncCall(93,3, "Adaptation::Icap::Xaction::noteCommConnected", dialer);
         ScheduleCallHere(connector);
@@ -152,7 +153,7 @@ Adaptation::Icap::Xaction::dnsLookupDone(const ipcache_addrs *ia)
         CbcPointer<Xaction> self(this);
         Dialer dialer(self, &Adaptation::Icap::Xaction::noteCommConnected);
         dialer.params.conn = connection;
-        dialer.params.flag = COMM_ERROR;
+        dialer.params.flag = Comm::COMM_ERROR;
         // fake other parameters by copying from the existing connection
         connector = asyncCall(93,3, "Adaptation::Icap::Xaction::noteCommConnected", dialer);
         ScheduleCallHere(connector);
@@ -185,7 +186,7 @@ Adaptation::Icap::Xaction::reusedConnection(void *data)
 {
     debugs(93, 5, HERE << "reused connection");
     Adaptation::Icap::Xaction *x = (Adaptation::Icap::Xaction*)data;
-    x->noteCommConnected(COMM_OK);
+    x->noteCommConnected(Comm::OK);
 }
 #endif
 
@@ -227,15 +228,15 @@ void Adaptation::Icap::Xaction::noteCommConnected(const CommConnectCbParams &io)
 {
     cs = NULL;
 
-    if (io.flag == COMM_TIMEOUT) {
+    if (io.flag == Comm::TIMEOUT) {
         handleCommTimedout();
         return;
     }
 
     Must(connector != NULL);
     connector = NULL;
 
-    if (io.flag != COMM_OK)
+    if (io.flag != Comm::OK)
         dieOnConnectionFailure(); // throws
 
     typedef CommCbMemFunT<Adaptation::Icap::Xaction, CommTimeoutCbParams> TimeoutDialer;
@@ -286,7 +287,7 @@ void Adaptation::Icap::Xaction::noteCommWrote(const CommIoCbParams &io)
         ignoreLastWrite = false;
         debugs(93, 7, HERE << "ignoring last write; status: " << io.flag);
     } else {
-        Must(io.flag == COMM_OK);
+        Must(io.flag == Comm::OK);
         al.icap.bytesSent += io.size;
         updateTimeout();
         handleCommWrote(io.size);
@@ -392,7 +393,7 @@ void Adaptation::Icap::Xaction::noteCommRead(const CommIoCbParams &io)
     Must(reader != NULL);
     reader = NULL;
 
-    Must(io.flag == COMM_OK);
+    Must(io.flag == Comm::OK);
 
     if (!io.size) {
         commEof = true;
@@ -428,7 +429,7 @@ void Adaptation::Icap::Xaction::cancelRead()
 {
     if (reader != NULL) {
         Must(haveConnection());
-        comm_read_cancel(connection->fd, reader);
+        Comm::ReadCancel(connection->fd, reader);
         reader = NULL;
     }
 }
@@ -41,12 +41,6 @@
 #include "ipcache.h"
 #include "MemBuf.h"
 
-class CommConnectCbParams;
-namespace Comm
-{
-class ConnOpener;
-}
-
 namespace Adaptation
 {
 namespace Icap
@@ -2,7 +2,7 @@
 #include "anyp/PortCfg.h"
 #include "comm.h"
 #include "fatal.h"
-#if USE_SSL
+#if USE_OPENSSL
 #include "ssl/support.h"
 #endif
 
@@ -29,7 +29,7 @@ AnyP::PortCfg::PortCfg() :
         vport(0),
         disable_pmtu_discovery(0),
         listenConn()
-#if USE_SSL
+#if USE_OPENSSL
         ,cert(NULL),
         key(NULL),
         version(0),
@@ -71,7 +71,7 @@ AnyP::PortCfg::~PortCfg()
     safe_free(name);
     safe_free(defaultsite);
 
-#if USE_SSL
+#if USE_OPENSSL
     safe_free(cert);
     safe_free(key);
     safe_free(options);
@@ -106,7 +106,7 @@ AnyP::PortCfg::clone() const
 #if 0
     // TODO: AYJ: 2009-07-18: for now SSL does not clone. Configure separate ports with IPs and SSL settings
 
-#if USE_SSL
+#if USE_OPENSSL
     char *cert;
     char *key;
     int version;
@@ -127,7 +127,7 @@ AnyP::PortCfg::clone() const
     return b;
 }
 
-#if USE_SSL
+#if USE_OPENSSL
 void
 AnyP::PortCfg::configureSslServerContext()
 {
@@ -187,10 +187,10 @@ AnyP::PortCfg::setTransport(const char *aProtocol)
     // HTTP/1.0 not supported because we are version 1.1 which contains a superset of 1.0
     // and RFC 2616 requires us to upgrade 1.0 to 1.1
 
-    if (strcasecmp("http", aProtocol) != 0 || strcmp("HTTP/1.1", aProtocol) != 0)
+    if (strcasecmp("http", aProtocol) == 0 || strcmp("HTTP/1.1", aProtocol) == 0)
         transport = AnyP::ProtocolVersion(AnyP::PROTO_HTTP, 1,1);
 
-    else if (strcasecmp("https", aProtocol) != 0 || strcmp("HTTPS/1.1", aProtocol) != 0)
+    else if (strcasecmp("https", aProtocol) == 0 || strcmp("HTTPS/1.1", aProtocol) == 0)
         transport = AnyP::ProtocolVersion(AnyP::PROTO_HTTPS, 1,1);
 
     else
@@ -6,7 +6,7 @@
 #include "anyp/TrafficMode.h"
 #include "comm/Connection.h"
 
-#if USE_SSL
+#if USE_OPENSSL
 #include "ssl/gadgets.h"
 #endif
 
@@ -19,7 +19,7 @@ class PortCfg
     PortCfg();
     ~PortCfg();
     AnyP::PortCfg *clone() const;
-#if USE_SSL
+#if USE_OPENSSL
     /// creates, configures, and validates SSL context and related port options
     void configureSslServerContext();
 #endif
@@ -64,7 +64,7 @@ class PortCfg
      */
     Comm::ConnectionPointer listenConn;
 
-#if USE_SSL
+#if USE_OPENSSL
     char *cert;
     char *key;
     int version;
@@ -27,7 +27,6 @@ typedef enum {
 #endif
     PROTO_URN,
     PROTO_WHOIS,
-    PROTO_INTERNAL,
     PROTO_ICY,
     PROTO_UNKNOWN,
     PROTO_MAX
@@ -146,19 +146,14 @@ ACLMaxUserIP::match(ACLChecklist *cl)
     }
 }
 
-wordlist *
+SBufList
 ACLMaxUserIP::dump() const
 {
+    SBufList sl;
     if (!maximum)
-        return NULL;
-
-    wordlist *W = NULL;
-
-    char buf[128];
-
-    snprintf(buf, sizeof(buf), "%lu", (unsigned long int) maximum);
-
-    wordlistAdd(&W, buf);
-
-    return W;
+        return sl;
+    SBuf s;
+    s.Printf("%d", maximum);
+    sl.push_back(s);
+    return sl;
 }
@@ -54,7 +54,7 @@ class ACLMaxUserIP : public ACL
     virtual char const *typeString() const;
     virtual void parse();
     virtual int match(ACLChecklist *cl);
-    virtual wordlist *dump() const;
+    virtual SBufList dump() const;
     virtual bool empty() const;
     virtual bool valid() const;
     virtual bool requiresRequest() const {return true;}
@@ -99,7 +99,7 @@ ACLProxyAuth::match(ACLChecklist *checklist)
     }
 }
 
-wordlist *
+SBufList
 ACLProxyAuth::dump() const
 {
     return data->dump();
@@ -189,6 +189,8 @@ int
 ACLProxyAuth::matchProxyAuth(ACLChecklist *cl)
 {
     ACLFilledChecklist *checklist = Filled(cl);
+    if (checklist->request->flags.sslBumped)
+        return 1; // AuthenticateAcl() already handled this bumped request
     if (!authenticateUserAuthenticated(Filled(checklist)->auth_user_request)) {
         return 0;
     }
@@ -65,7 +65,7 @@ class ACLProxyAuth : public ACL
     virtual bool isProxyAuth() const {return true;}
 
     virtual int match(ACLChecklist *checklist);
-    virtual wordlist *dump() const;
+    virtual SBufList dump() const;
     virtual bool valid() const;
     virtual bool empty() const;
     virtual bool requiresRequest() const {return true;}
@@ -40,6 +40,7 @@
 #include "format/Format.h"
 #include "globals.h"
 #include "Store.h"
+#include "wordlist.h"
 
 Auth::ConfigVector Auth::TheConfig;
 
@@ -94,7 +95,34 @@ Auth::Config::registerWithCacheManager(void)
 void
 Auth::Config::parse(Auth::Config * scheme, int n_configured, char *param_str)
 {
-    if (strcmp(param_str, "key_extras") == 0) {
+    if (strcmp(param_str, "program") == 0) {
+        if (authenticateProgram)
+            wordlistDestroy(&authenticateProgram);
+
+        parse_wordlist(&authenticateProgram);
+
+        requirePathnameExists("Authentication helper program", authenticateProgram->key);
+
+    } else if (strcmp(param_str, "realm") == 0) {
+        realm.clear();
+
+        char *token = ConfigParser::NextQuotedOrToEol();
+
+        while (*token && xisspace(*token))
+            ++token;
+
+        if (!token || !*token) {
+            debugs(29, DBG_PARSE_NOTE(DBG_IMPORTANT), "ERROR: Missing auth_param " << scheme->type() << " realm");
+            self_destruct();
+            return;
+        }
+
+        realm = token;
+
+    } else if (strcmp(param_str, "children") == 0) {
+        authenticateChildren.parseConfig();
+
+    } else if (strcmp(param_str, "key_extras") == 0) {
         keyExtrasLine = ConfigParser::NextQuotedToken();
         Format::Format *nlf =  new ::Format::Format(scheme->type());
         if (!nlf->parse(keyExtrasLine.termedBuf())) {
@@ -116,11 +144,31 @@ Auth::Config::parse(Auth::Config * scheme, int n_configured, char *param_str)
     }
 }
 
-void
-Auth::Config::dump(StoreEntry *entry, const char *name, Auth::Config *scheme)
+bool
+Auth::Config::dump(StoreEntry *entry, const char *name, Auth::Config *scheme) const
 {
+    if (!authenticateProgram)
+        return false; // not configured
+
+    wordlist *list = authenticateProgram;
+    storeAppendPrintf(entry, "%s %s", name, scheme->type());
+    while (list != NULL) {
+        storeAppendPrintf(entry, " %s", list->key);
+        list = list->next;
+    }
+    storeAppendPrintf(entry, "\n");
+
+    storeAppendPrintf(entry, "%s %s realm " SQUIDSBUFPH "\n", name, scheme->type(), SQUIDSBUFPRINT(realm));
+
+    storeAppendPrintf(entry, "%s %s children %d startup=%d idle=%d concurrency=%d\n",
+                      name, scheme->type(),
+                      authenticateChildren.n_max, authenticateChildren.n_startup,
+                      authenticateChildren.n_idle, authenticateChildren.concurrency);
+
     if (keyExtrasLine.size() > 0)
         storeAppendPrintf(entry, "%s %s key_extras \"%s\"\n", name, scheme->type(), keyExtrasLine.termedBuf());
+
+    return true;
 }
 
 void
@@ -122,8 +122,9 @@ class Config
     /**
      * Responsible for writing to the StoreEntry the configuration parameters that a user
      * would put in a config file to recreate the running configuration.
+     * Returns whether the scheme is configured.
      */
-    virtual void dump(StoreEntry *, const char *, Config *);
+    virtual bool dump(StoreEntry *, const char *, Config *) const;
 
     /** add headers as needed when challenging for auth */
     virtual void fixHeader(UserRequest::Pointer, HttpReply *, http_hdr_type, HttpRequest *) = 0;
@@ -148,6 +149,10 @@ class Config
     wordlist *authenticateProgram; ///< Helper program to run, includes all parameters
     String keyExtrasLine;  ///< The format of the request to the auth helper
     Format::Format *keyExtras; ///< The compiled request format
+
+protected:
+    /// RFC 7235 section 2.2 - Protection Space (Realm)
+    SBuf realm;
 };
 
 typedef std::vector<Config *> ConfigVector;
@@ -59,7 +59,6 @@ Auth::User::User(Auth::Config *aConfig, const char *aRequestRealm) :
         username_(NULL),
         requestRealm_(aRequestRealm)
 {
-    proxy_auth_list.head = proxy_auth_list.tail = NULL;
     proxy_match_cache.head = proxy_match_cache.tail = NULL;
     ip_list.head = ip_list.tail = NULL;
     debugs(29, 5, HERE << "Initialised auth_user '" << this << "'.");
@@ -91,7 +90,6 @@ Auth::User::absorb(Auth::User::Pointer from)
 {
     /*
      * XXX Incomplete: it should merge in hash references too and ask the module to merge in scheme data
-     *  dlink_list proxy_auth_list;
      *  dlink_list proxy_match_cache;
      */
 
@@ -71,8 +71,6 @@ class User : public RefCountable
     Auth::Type auth_type;
     /** the config for this user */
     Auth::Config *config;
-    /** we may have many proxy-authenticate strings that decode to the same user */
-    dlink_list proxy_auth_list;
     dlink_list proxy_match_cache;
     size_t ipcount;
     long expiretime;
@@ -65,8 +65,8 @@ Auth::UserRequest::start(HttpRequest *request, AccessLogEntry::Pointer &al, AUTH
 {
     assert(handler);
     assert(data);
-    debugs(29, 9, HERE << "auth_user_request '" << this << "'");
-    module_start(request, al, handler, data);
+    debugs(29, 9, this);
+    startHelperLookup(request, al, handler, data);
 }
 
 bool
@@ -158,15 +158,6 @@ class UserRequest : public RefCountable
 
     virtual void releaseAuthServer();
 
-    /**
-     * Called when squid is ready to put the request on hold and wait for a callback from the auth module
-     * when the auth module has performed it's external activities.
-     *
-     * \param handler	Handler to process the callback when its run
-     * \param data	CBDATA for handler
-     */
-    virtual void module_start(HttpRequest *request, AccessLogEntry::Pointer &al, AUTHCB *handler, void *data) = 0;
-
     // User credentials object this UserRequest is managing
     virtual User::Pointer user() {return _auth_user;}
     virtual const User::Pointer user() const {return _auth_user;}
@@ -195,7 +186,18 @@ class UserRequest : public RefCountable
     /// Add the appropriate [Proxy-]Authenticate header to the given reply
     static void addReplyAuthHeader(HttpReply * rep, UserRequest::Pointer auth_user_request, HttpRequest * request, int accelerated, int internal);
 
+    /** Start an asynchronous helper lookup to verify the user credentials
+     *
+     * Uses startHelperLookup() for scheme-specific actions.
+     *
+     * The given callback will be called when the auth module has performed
+     * it's external activities.
+     *
+     * \param handler	Handler to process the callback when its run
+     * \param data	CBDATA for handler
+     */
     void start(HttpRequest *request, AccessLogEntry::Pointer &al, AUTHCB *handler, void *data);
+
     char const * denyMessage(char const * const default_message = NULL);
 
     /** Possibly overrideable in future */
@@ -224,6 +226,15 @@ class UserRequest : public RefCountable
     virtual const char *credentialsStr() = 0;
 
     const char *helperRequestKeyExtras(HttpRequest *, AccessLogEntry::Pointer &al);
+
+protected:
+    /**
+     * The scheme-specific actions to be performed when sending helper lookup.
+     *
+     * \see void start(HttpRequest *, AccessLogEntry::Pointer &, AUTHCB *, void *);
+     */
+    virtual void startHelperLookup(HttpRequest *request, AccessLogEntry::Pointer &al, AUTHCB *handler, void *data) = 0;
+
 private:
 
     static AuthAclState authenticate(UserRequest::Pointer * auth_user_request, http_hdr_type headertype, HttpRequest * request, ConnStateData * conn, Ip::Address &src_addr, AccessLogEntry::Pointer &al);
@@ -93,7 +93,7 @@ Auth::Basic::UserRequest::module_direction()
 
 /* send the initial data to a basic authenticator module */
 void
-Auth::Basic::UserRequest::module_start(HttpRequest *request, AccessLogEntry::Pointer &al, AUTHCB * handler, void *data)
+Auth::Basic::UserRequest::startHelperLookup(HttpRequest *request, AccessLogEntry::Pointer &al, AUTHCB * handler, void *data)
 {
     assert(user()->auth_type == Auth::AUTH_BASIC);
     Auth::Basic::User *basic_auth = dynamic_cast<Auth::Basic::User *>(user().getRaw());
@@ -26,7 +26,7 @@ class UserRequest : public Auth::UserRequest
     virtual int authenticated() const;
     virtual void authenticate(HttpRequest * request, ConnStateData *conn, http_hdr_type type);
     virtual Auth::Direction module_direction();
-    virtual void module_start(HttpRequest * request, AccessLogEntry::Pointer &al, AUTHCB *, void *);
+    virtual void startHelperLookup(HttpRequest * request, AccessLogEntry::Pointer &al, AUTHCB *, void *);
     virtual const char *credentialsStr();
 
 private:
@@ -76,8 +76,7 @@ Auth::Basic::Config::active() const
 bool
 Auth::Basic::Config::configured() const
 {
-    if ((authenticateProgram != NULL) && (authenticateChildren.n_max != 0) &&
-            (basicAuthRealm != NULL)) {
+    if ((authenticateProgram != NULL) && (authenticateChildren.n_max != 0) && !realm.isEmpty()) {
         debugs(29, 9, HERE << "returning configured");
         return true;
     }
@@ -96,8 +95,8 @@ void
 Auth::Basic::Config::fixHeader(Auth::UserRequest::Pointer auth_user_request, HttpReply *rep, http_hdr_type hdrType, HttpRequest * request)
 {
     if (authenticateProgram) {
-        debugs(29, 9, HERE << "Sending type:" << hdrType << " header: 'Basic realm=\"" << basicAuthRealm << "\"'");
-        httpHeaderPutStrf(&rep->header, hdrType, "Basic realm=\"%s\"", basicAuthRealm);
+        debugs(29, 9, "Sending type:" << hdrType << " header: 'Basic realm=\"" << realm << "\"'");
+        httpHeaderPutStrf(&rep->header, hdrType, "Basic realm=\"" SQUIDSBUFPH "\"", SQUIDSBUFPRINT(realm));
     }
 }
 
@@ -129,59 +128,33 @@ Auth::Basic::Config::done()
 
     if (authenticateProgram)
         wordlistDestroy(&authenticateProgram);
-
-    if (basicAuthRealm)
-        safe_free(basicAuthRealm);
 }
 
-void
-Auth::Basic::Config::dump(StoreEntry * entry, const char *name, Auth::Config * scheme)
+bool
+Auth::Basic::Config::dump(StoreEntry * entry, const char *name, Auth::Config * scheme) const
 {
-    wordlist *list = authenticateProgram;
-    storeAppendPrintf(entry, "%s %s", name, "basic");
-
-    while (list != NULL) {
-        storeAppendPrintf(entry, " %s", list->key);
-        list = list->next;
-    }
+    if (!Auth::Config::dump(entry, name, scheme))
+        return false; // not configured
 
-    storeAppendPrintf(entry, "\n");
-
-    storeAppendPrintf(entry, "%s basic realm %s\n", name, basicAuthRealm);
-    storeAppendPrintf(entry, "%s basic children %d startup=%d idle=%d concurrency=%d\n", name, authenticateChildren.n_max, authenticateChildren.n_startup, authenticateChildren.n_idle, authenticateChildren.concurrency);
     storeAppendPrintf(entry, "%s basic credentialsttl %d seconds\n", name, (int) credentialsTTL);
     storeAppendPrintf(entry, "%s basic casesensitive %s\n", name, casesensitive ? "on" : "off");
-    Auth::Config::dump(entry, name, scheme);
+    storeAppendPrintf(entry, "%s basic utf8 %s\n", name, utf8 ? "on" : "off");
+    return true;
 }
 
 Auth::Basic::Config::Config() :
         credentialsTTL( 2*60*60 ),
         casesensitive(0),
         utf8(0)
 {
-    basicAuthRealm = xstrdup("Squid proxy-caching web server");
-}
-
-Auth::Basic::Config::~Config()
-{
-    safe_free(basicAuthRealm);
+    static const SBuf defaultRealm("Squid proxy-caching web server");
+    realm = defaultRealm;
 }
 
 void
 Auth::Basic::Config::parse(Auth::Config * scheme, int n_configured, char *param_str)
 {
-    if (strcmp(param_str, "program") == 0) {
-        if (authenticateProgram)
-            wordlistDestroy(&authenticateProgram);
-
-        parse_wordlist(&authenticateProgram);
-
-        requirePathnameExists("auth_param basic program", authenticateProgram->key);
-    } else if (strcmp(param_str, "children") == 0) {
-        authenticateChildren.parseConfig();
-    } else if (strcmp(param_str, "realm") == 0) {
-        parse_eol(&basicAuthRealm);
-    } else if (strcmp(param_str, "credentialsttl") == 0) {
+    if (strcmp(param_str, "credentialsttl") == 0) {
         parse_time_t(&credentialsTTL);
     } else if (strcmp(param_str, "casesensitive") == 0) {
         parse_onoff(&casesensitive);
@@ -23,13 +23,12 @@ class Config : public Auth::Config
 {
 public:
     Config();
-    ~Config();
     virtual bool active() const;
     virtual bool configured() const;
     virtual Auth::UserRequest::Pointer decode(char const *proxy_auth, const char *requestRealm);
     virtual void done();
     virtual void rotateHelpers();
-    virtual void dump(StoreEntry *, const char *, Auth::Config *);
+    virtual bool dump(StoreEntry *, const char *, Auth::Config *) const;
     virtual void fixHeader(Auth::UserRequest::Pointer, HttpReply *, http_hdr_type, HttpRequest *);
     virtual void init(Auth::Config *);
     virtual void parse(Auth::Config *, int, char *);
@@ -38,7 +37,6 @@ class Config : public Auth::Config
     virtual const char * type() const;
 
 public:
-    char *basicAuthRealm;
     time_t credentialsTTL;
     int casesensitive;
     int utf8;
@@ -102,9 +102,10 @@ Auth::Digest::UserRequest::authenticate(HttpRequest * request, ConnStateData * c
                   authenticateDigestNonceNonceb64(digest_request->nonce),
                   digest_request->cnonce,
                   digest_user->HA1, SESSIONKEY);
+    SBuf sTmp = request->method.image();
     DigestCalcResponse(SESSIONKEY, authenticateDigestNonceNonceb64(digest_request->nonce),
                        digest_request->nc, digest_request->cnonce, digest_request->qop,
-                       RequestMethodStr(request->method), digest_request->uri, HA2, Response);
+                       sTmp.c_str(), digest_request->uri, HA2, Response);
 
     debugs(29, 9, "\nResponse = '" << digest_request->response << "'\nsquid is = '" << Response << "'");
 
@@ -123,9 +124,10 @@ Auth::Digest::UserRequest::authenticate(HttpRequest * request, ConnStateData * c
              * widespread and such broken browsers no longer are commonly
              * used.
              */
+            sTmp = HttpRequestMethod(Http::METHOD_GET).image();
             DigestCalcResponse(SESSIONKEY, authenticateDigestNonceNonceb64(digest_request->nonce),
                                digest_request->nc, digest_request->cnonce, digest_request->qop,
-                               RequestMethodStr(Http::METHOD_GET), digest_request->uri, HA2, Response);
+                               sTmp.c_str(), digest_request->uri, HA2, Response);
 
             if (strcasecmp(digest_request->response, Response)) {
                 auth_user->credentials(Auth::Failed);
@@ -270,7 +272,7 @@ Auth::Digest::UserRequest::addAuthenticationInfoTrailer(HttpReply * rep, int acc
 
 /* send the initial data to a digest authenticator module */
 void
-Auth::Digest::UserRequest::module_start(HttpRequest *request, AccessLogEntry::Pointer &al, AUTHCB * handler, void *data)
+Auth::Digest::UserRequest::startHelperLookup(HttpRequest *request, AccessLogEntry::Pointer &al, AUTHCB * handler, void *data)
 {
     char buf[8192];
 
@@ -34,7 +34,7 @@ class UserRequest : public Auth::UserRequest
     virtual void addAuthenticationInfoTrailer(HttpReply * rep, int accel);
 #endif
 
-    virtual void module_start(HttpRequest *request, AccessLogEntry::Pointer &al, AUTHCB *, void *);
+    virtual void startHelperLookup(HttpRequest *request, AccessLogEntry::Pointer &al, AUTHCB *, void *);
     virtual const char *credentialsStr();
 
     char *nonceb64;             /* "dcd98b7102dd2f0e8b11d0f600bfb0c093" */
@@ -487,25 +487,18 @@ Auth::Digest::Config::rotateHelpers()
     /* NP: dynamic helper restart will ensure they start up again as needed. */
 }
 
-void
-Auth::Digest::Config::dump(StoreEntry * entry, const char *name, Auth::Config * scheme)
+bool
+Auth::Digest::Config::dump(StoreEntry * entry, const char *name, Auth::Config * scheme) const
 {
-    wordlist *list = authenticateProgram;
-    debugs(29, 9, "Dumping configuration");
-    storeAppendPrintf(entry, "%s %s", name, "digest");
+    if (!Auth::Config::dump(entry, name, scheme))
+        return false;
 
-    while (list != NULL) {
-        storeAppendPrintf(entry, " %s", list->key);
-        list = list->next;
-    }
-
-    storeAppendPrintf(entry, "\n%s %s realm %s\n%s %s children %d startup=%d idle=%d concurrency=%d\n%s %s nonce_max_count %d\n%s %s nonce_max_duration %d seconds\n%s %s nonce_garbage_interval %d seconds\n",
-                      name, "digest", digestAuthRealm,
-                      name, "digest", authenticateChildren.n_max, authenticateChildren.n_startup, authenticateChildren.n_idle, authenticateChildren.concurrency,
+    storeAppendPrintf(entry, "%s %s nonce_max_count %d\n%s %s nonce_max_duration %d seconds\n%s %s nonce_garbage_interval %d seconds\n",
                       name, "digest", noncemaxuses,
                       name, "digest", (int) noncemaxduration,
                       name, "digest", (int) nonceGCInterval);
-    Auth::Config::dump(entry, name, scheme);
+    storeAppendPrintf(entry, "%s digest utf8 %s\n", name, utf8 ? "on" : "off");
+    return true;
 }
 
 bool
@@ -519,7 +512,7 @@ Auth::Digest::Config::configured() const
 {
     if ((authenticateProgram != NULL) &&
             (authenticateChildren.n_max != 0) &&
-            (digestAuthRealm != NULL) && (noncemaxduration > -1))
+            !realm.isEmpty() && (noncemaxduration > -1))
         return true;
 
     return false;
@@ -551,12 +544,13 @@ Auth::Digest::Config::fixHeader(Auth::UserRequest::Pointer auth_user_request, Ht
     }
 
     debugs(29, 9, "Sending type:" << hdrType <<
-           " header: 'Digest realm=\"" << digestAuthRealm << "\", nonce=\"" <<
+           " header: 'Digest realm=\"" << realm << "\", nonce=\"" <<
            authenticateDigestNonceNonceb64(nonce) << "\", qop=\"" << QOP_AUTH <<
            "\", stale=" << (stale ? "true" : "false"));
 
     /* in the future, for WWW auth we may want to support the domain entry */
-    httpHeaderPutStrf(&rep->header, hdrType, "Digest realm=\"%s\", nonce=\"%s\", qop=\"%s\", stale=%s", digestAuthRealm, authenticateDigestNonceNonceb64(nonce), QOP_AUTH, stale ? "true" : "false");
+    httpHeaderPutStrf(&rep->header, hdrType, "Digest realm=\"" SQUIDSBUFPH "\", nonce=\"%s\", qop=\"%s\", stale=%s",
+                      SQUIDSBUFPRINT(realm), authenticateDigestNonceNonceb64(nonce), QOP_AUTH, stale ? "true" : "false");
 }
 
 /* Initialize helpers and the like for this auth scheme. Called AFTER parsing the
@@ -614,12 +608,9 @@ Auth::Digest::Config::done()
 
     if (authenticateProgram)
         wordlistDestroy(&authenticateProgram);
-
-    safe_free(digestAuthRealm);
 }
 
 Auth::Digest::Config::Config() :
-        digestAuthRealm(NULL),
         nonceGCInterval(5*60),
         noncemaxduration(30*60),
         noncemaxuses(50),
@@ -639,10 +630,6 @@ Auth::Digest::Config::parse(Auth::Config * scheme, int n_configured, char *param
         parse_wordlist(&authenticateProgram);
 
         requirePathnameExists("auth_param digest program", authenticateProgram->key);
-    } else if (strcmp(param_str, "children") == 0) {
-        authenticateChildren.parseConfig();
-    } else if (strcmp(param_str, "realm") == 0) {
-        parse_eol(&digestAuthRealm);
     } else if (strcmp(param_str, "nonce_garbage_interval") == 0) {
         parse_time_t(&nonceGCInterval);
     } else if (strcmp(param_str, "nonce_max_duration") == 0) {
@@ -75,15 +75,14 @@ class Config : public Auth::Config
     virtual Auth::UserRequest::Pointer decode(char const *proxy_auth, const char *requestRealm);
     virtual void done();
     virtual void rotateHelpers();
-    virtual void dump(StoreEntry *, const char *, Auth::Config *);
+    virtual bool dump(StoreEntry *, const char *, Auth::Config *) const;
     virtual void fixHeader(Auth::UserRequest::Pointer, HttpReply *, http_hdr_type, HttpRequest *);
     virtual void init(Auth::Config *);
     virtual void parse(Auth::Config *, int, char *);
     virtual void registerWithCacheManager(void);
     virtual const char * type() const;
 
 public:
-    char *digestAuthRealm;
     time_t nonceGCInterval;
     time_t noncemaxduration;
     unsigned int noncemaxuses;
@@ -6,7 +6,6 @@
 Auth::Negotiate::User::User(Auth::Config *aConfig, const char *aRequestRealm) :
         Auth::User(aConfig, aRequestRealm)
 {
-    proxy_auth_list.head = proxy_auth_list.tail = NULL;
 }
 
 Auth::Negotiate::User::~User()
@@ -97,7 +97,7 @@ Auth::Negotiate::UserRequest::module_direction()
 }
 
 void
-Auth::Negotiate::UserRequest::module_start(HttpRequest *req, AccessLogEntry::Pointer &al, AUTHCB * handler, void *data)
+Auth::Negotiate::UserRequest::startHelperLookup(HttpRequest *req, AccessLogEntry::Pointer &al, AUTHCB * handler, void *data)
 {
     static char buf[MAX_AUTHTOKEN_LEN];
 
@@ -26,7 +26,7 @@ class UserRequest : public Auth::UserRequest
     virtual int authenticated() const;
     virtual void authenticate(HttpRequest * request, ConnStateData * conn, http_hdr_type type);
     virtual Direction module_direction();
-    virtual void module_start(HttpRequest *request, AccessLogEntry::Pointer &al, AUTHCB *, void *);
+    virtual void startHelperLookup(HttpRequest *request, AccessLogEntry::Pointer &al, AUTHCB *, void *);
     virtual const char *credentialsStr();
 
     virtual void addAuthenticationInfoHeader(HttpReply * rep, int accel);
@@ -108,21 +108,14 @@ Auth::Negotiate::Config::done()
     debugs(29, DBG_IMPORTANT, "Reconfigure: Negotiate authentication configuration cleared.");
 }
 
-void
-Auth::Negotiate::Config::dump(StoreEntry * entry, const char *name, Auth::Config * scheme)
+bool
+Auth::Negotiate::Config::dump(StoreEntry * entry, const char *name, Auth::Config * scheme) const
 {
-    wordlist *list = authenticateProgram;
-    storeAppendPrintf(entry, "%s %s", name, "negotiate");
-
-    while (list != NULL) {
-        storeAppendPrintf(entry, " %s", list->key);
-        list = list->next;
-    }
+    if (!Auth::Config::dump(entry, name, scheme))
+        return false;
 
-    storeAppendPrintf(entry, "\n%s negotiate children %d startup=%d idle=%d concurrency=%d\n",
-                      name, authenticateChildren.n_max, authenticateChildren.n_startup, authenticateChildren.n_idle, authenticateChildren.concurrency);
-    storeAppendPrintf(entry, "%s %s keep_alive %s\n", name, "negotiate", keep_alive ? "on" : "off");
-    Auth::Config::dump(entry, name, scheme);
+    storeAppendPrintf(entry, "%s negotiate keep_alive %s\n", name, keep_alive ? "on" : "off");
+    return true;
 }
 
 Auth::Negotiate::Config::Config() : keep_alive(1)
@@ -138,8 +131,6 @@ Auth::Negotiate::Config::parse(Auth::Config * scheme, int n_configured, char *pa
         parse_wordlist(&authenticateProgram);
 
         requirePathnameExists("auth_param negotiate program", authenticateProgram->key);
-    } else if (strcmp(param_str, "children") == 0) {
-        authenticateChildren.parseConfig();
     } else if (strcmp(param_str, "keep_alive") == 0) {
         parse_onoff(&keep_alive);
     } else
@@ -34,7 +34,7 @@ class Config : public Auth::Config
     virtual Auth::UserRequest::Pointer decode(char const *proxy_auth, const char *requestRealm);
     virtual void done();
     virtual void rotateHelpers();
-    virtual void dump(StoreEntry *, const char *, Auth::Config *);
+    virtual bool dump(StoreEntry *, const char *, Auth::Config *) const;
     virtual void fixHeader(Auth::UserRequest::Pointer, HttpReply *, http_hdr_type, HttpRequest *);
     virtual void init(Auth::Config *);
     virtual void parse(Auth::Config *, int, char *);
@@ -6,7 +6,6 @@
 Auth::Ntlm::User::User(Auth::Config *aConfig, const char *aRequestRealm) :
         Auth::User(aConfig, aRequestRealm)
 {
-    proxy_auth_list.head = proxy_auth_list.tail = NULL;
 }
 
 Auth::Ntlm::User::~User()
@@ -95,7 +95,7 @@ Auth::Ntlm::UserRequest::module_direction()
 }
 
 void
-Auth::Ntlm::UserRequest::module_start(HttpRequest *req, AccessLogEntry::Pointer &al, AUTHCB * handler, void *data)
+Auth::Ntlm::UserRequest::startHelperLookup(HttpRequest *req, AccessLogEntry::Pointer &al, AUTHCB * handler, void *data)
 {
     static char buf[MAX_AUTHTOKEN_LEN];
 
@@ -26,7 +26,7 @@ class UserRequest : public Auth::UserRequest
     virtual int authenticated() const;
     virtual void authenticate(HttpRequest * request, ConnStateData * conn, http_hdr_type type);
     virtual Auth::Direction module_direction();
-    virtual void module_start(HttpRequest *req, AccessLogEntry::Pointer &al, AUTHCB *, void *);
+    virtual void startHelperLookup(HttpRequest *req, AccessLogEntry::Pointer &al, AUTHCB *, void *);
     virtual const char *credentialsStr();
 
     virtual const char * connLastHeader();
@@ -100,21 +100,14 @@ Auth::Ntlm::Config::done()
     debugs(29, DBG_IMPORTANT, "Reconfigure: NTLM authentication configuration cleared.");
 }
 
-void
-Auth::Ntlm::Config::dump(StoreEntry * entry, const char *name, Auth::Config * scheme)
+bool
+Auth::Ntlm::Config::dump(StoreEntry * entry, const char *name, Auth::Config * scheme) const
 {
-    wordlist *list = authenticateProgram;
-    storeAppendPrintf(entry, "%s %s", name, "ntlm");
-
-    while (list != NULL) {
-        storeAppendPrintf(entry, " %s", list->key);
-        list = list->next;
-    }
+    if (!Auth::Config::dump(entry, name, scheme))
+        return false;
 
-    storeAppendPrintf(entry, "\n%s ntlm children %d startup=%d idle=%d concurrency=%d\n",
-                      name, authenticateChildren.n_max, authenticateChildren.n_startup, authenticateChildren.n_idle, authenticateChildren.concurrency);
-    storeAppendPrintf(entry, "%s %s keep_alive %s\n", name, "ntlm", keep_alive ? "on" : "off");
-    Auth::Config::dump(entry, name, scheme);
+    storeAppendPrintf(entry, "%s ntlm keep_alive %s\n", name, keep_alive ? "on" : "off");
+    return true;
 }
 
 Auth::Ntlm::Config::Config() : keep_alive(1)
@@ -130,8 +123,6 @@ Auth::Ntlm::Config::parse(Auth::Config * scheme, int n_configured, char *param_s
         parse_wordlist(&authenticateProgram);
 
         requirePathnameExists("auth_param ntlm program", authenticateProgram->key);
-    } else if (strcmp(param_str, "children") == 0) {
-        authenticateChildren.parseConfig();
     } else if (strcmp(param_str, "keep_alive") == 0) {
         parse_onoff(&keep_alive);
     } else
@@ -30,7 +30,7 @@ class Config : public Auth::Config
     virtual Auth::UserRequest::Pointer decode(char const *proxy_auth, const char *requestRealm);
     virtual void done();
     virtual void rotateHelpers();
-    virtual void dump(StoreEntry *, const char *, Auth::Config *);
+    virtual bool dump(StoreEntry *, const char *, Auth::Config *) const;
     virtual void fixHeader(Auth::UserRequest::Pointer, HttpReply *, http_hdr_type, HttpRequest *);
     virtual void init(Auth::Config *);
     virtual void parse(Auth::Config *, int, char *);
@@ -53,7 +53,7 @@ be dialed is irrelevant here.
 handle the call back, then it must cancel it.  Whether that Call will be
 scheduled is irrelevant here. If the Recipient has an AsyncCall pointer,
 calling AsyncCall::cancel is sufficient, but the code should use
-call-specific APIs when possible (e.g., comm_read_cancel or comm_close).
+call-specific APIs when possible (e.g., Comm::ReadCancel or comm_close).
 
 - Processed calls should be forgotten: If you scheduled, received, or
 cancel the call, set its pointer to NULL. The Caller should forget the
@@ -135,7 +135,7 @@ Cbc &
 CbcPointer<Cbc>::operator *() const
 {
     Cbc *c = get();
-    Must(c);
+    assert(c);
     return *c;
 }
 
@@ -144,7 +144,7 @@ Cbc *
 CbcPointer<Cbc>::operator ->() const
 {
     Cbc *c = get();
-    Must(c);
+    assert(c);
     return c;
 }
 
@@ -34,10 +34,13 @@ CharacterSet::add(const unsigned char c)
 CharacterSet &
 CharacterSet::addRange(unsigned char low, unsigned char high)
 {
-    while (low <= high) {
+    //manual loop splitting is needed to cover case where high is 255
+    // otherwise low will wrap, resulting in infinite loop
+    while (low < high) {
         chars_[static_cast<uint8_t>(low)] = 1;
         ++low;
     }
+    chars_[static_cast<uint8_t>(high)] = 1;
     return *this;
 }
 
@@ -58,20 +61,35 @@ CharacterSet::CharacterSet(const char *label, unsigned char low, unsigned char h
 }
 
 const CharacterSet
+// RFC 5234
 CharacterSet::ALPHA("ALPHA", "abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ"),
 CharacterSet::BIT("BIT","01"),
 CharacterSet::CR("CR","\r"),
-CharacterSet::LF("LF","\n"),
+#if __cplusplus == 201103L
+//CharacterSet::CTL("CTL",{{0x01,0x1f},{0x7f,0x7f}}),
+#endif
 CharacterSet::DIGIT("DIGIT","0123456789"),
 CharacterSet::DQUOTE("DQUOTE","\""),
-CharacterSet::HTAB("HTAB","\t"),
 CharacterSet::HEXDIG("HEXDIG","0123456789aAbBcCdDeEfF"),
+CharacterSet::HTAB("HTAB","\t"),
+CharacterSet::LF("LF","\n"),
 CharacterSet::SP("SP"," "),
 CharacterSet::VCHAR("VCHAR", 0x21, 0x7e),
+// RFC 7230
 CharacterSet::WSP("WSP"," \t"),
+#if __cplusplus == 201103L
+//CharacterSet::CTEXT("ctext",{{0x09,0x09},{0x20,0x20},{0x2a,0x5b},{0x5d,0x7e},{0x80,0xff}}),
+#endif
 CharacterSet::TCHAR("TCHAR","!#$%&'*+-.^_`|~0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ"),
-CharacterSet::SPECIAL("SPECIAL","()<>@,;:\\\"/[]?={}")
-// QDTEXT and OBSTEXT are omitted for now as they require c++11 constructors
-//,CharacterSet::QDTEXT("QDTEXT",{{9,9},{0x20,0x21},{0x23,0x5b},{0x5d,0x7e},{0x80,0xff}})
-//,CharacterSet::OBSTEXT("OBSTEXT",0x80,0xff)
+CharacterSet::SPECIAL("SPECIAL","()<>@,;:\\\"/[]?={}"),
+#if __cplusplus == 201103L
+//CharacterSet::QDTEXT("QDTEXT",{{0x09,0x09},{0x20,0x21},{0x23,0x5b},{0x5d,0x7e},{0x80,0xff}}),
+#endif
+CharacterSet::OBSTEXT("OBSTEXT",0x80,0xff),
+// RFC 7232
+#if __cplusplus == 201103L
+//CharacterSet::ETAGC("ETAGC",{{0x21,0x21},{0x23,0x7e},{0x80,0xff}}),
+#endif
+// RFC 7235
+CharacterSet::TOKEN68C("TOKEN68C","-._~+/0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ")
 ;
@@ -36,38 +36,64 @@ class CharacterSet
     /// optional set label for debugging (default: "anonymous")
     const char * name;
 
-    // common character sets, insipired to RFC5234
+    // common character sets, RFC 5234
     // A-Za-z
     static const CharacterSet ALPHA;
     // 0-1
     static const CharacterSet BIT;
     // carriage return
     static const CharacterSet CR;
-    // line feed
-    static const CharacterSet LF;
-    // double quote
-    static const CharacterSet DQUOTE;
+    // controls
+#if __cplusplus == 201103L
+    // ready but disabled as needs C++11 constructor
+    //static const CharacterSet CTL;
+#endif
     // 0-9
     static const CharacterSet DIGIT;
+    // double quote
+    static const CharacterSet DQUOTE;
     // 0-9aAbBcCdDeEfF
     static const CharacterSet HEXDIG;
     // horizontal tab
     static const CharacterSet HTAB;
+    // line feed
+    static const CharacterSet LF;
     // white space
     static const CharacterSet SP;
     // visible (printable) characters
     static const CharacterSet VCHAR;
     // <space><tab>
     static const CharacterSet WSP;
-    // character sets from draft httpbis
+
+    // HTTP character sets, RFC 7230
+    // ctext
+#if __cplusplus == 201103L
+    // ready but disabled as needs C++11 constructor
+    //static const CharacterSet CTEXT;
+#endif
+    // XXX: maybe field-vchar = VCHAR / obs-text
     // any VCHAR except for SPECIAL
     static const CharacterSet TCHAR;
     // special VCHARs
     static const CharacterSet SPECIAL;
-    // qdtext (ready but not enabled as it requires a c++11 constructor)
+    // qdtext
+#if __cplusplus == 201103L
+    // ready but disabled as needs C++11 constructor
     //static const CharacterSet QDTEXT;
-    // obs-text (ready but not enabled as it requires a c++11 constructor)
-    //static const CharacterSet OBSTEXT;
+#endif
+    // obs-text
+    static const CharacterSet OBSTEXT;
+
+    // HTTP character sets, RFC 7232
+    // etagc
+#if __cplusplus == 201103L
+    // ready but disabled as needs C++11 constructor
+    //static const CharacterSet ETAGC;
+#endif
+
+    // HTTP character sets, RFC 7235
+    // token68 (internal charaters only, excludes '=' terminator)
+    static const CharacterSet TOKEN68C;
 
 private:
     /** index of characters in this set
@@ -140,6 +140,10 @@ LruMap<EntryValue, EntryCost>::add(const char *key, EntryValue *t)
 
     del(key);
     trim();
+
+    if (memLimit() == 0)
+        return false;
+
     index.push_front(new Entry(key, t));
     storage.insert(MapPair(key, index.begin()));
 
@@ -185,7 +189,7 @@ template <class EntryValue, size_t EntryCost>
 void
 LruMap<EntryValue, EntryCost>::trim()
 {
-    while (memLimit() > 0 && size() >= memLimit()) {
+    while (size() >= memLimit()) {
         QueueIterator i = index.end();
         --i;
         if (i != index.end()) {
@@ -60,7 +60,7 @@ class RegisteredRunner
     /// Meant for cleanup and state saving that may require other modules.
     virtual void startShutdown() {}
 
-    /// Called after stopping the main loop.
+    /// Called after stopping the main loop and before releasing memory.
     /// Meant for quick/basic cleanup that does not require any other modules.
     virtual ~RegisteredRunner() {}
     /// exists to simplify caller interface; override the destructor instead
@@ -69,9 +69,12 @@
 #include "neighbors.h"
 #include "NeighborTypeDomainList.h"
 #include "Parsing.h"
+#include "pconn.h"
 #include "PeerDigest.h"
+#include "PeerPoolMgr.h"
 #include "RefreshPattern.h"
 #include "rfc1738.h"
+#include "SBufList.h"
 #include "SquidConfig.h"
 #include "SquidString.h"
 #include "ssl/ProxyCerts.h"
@@ -91,7 +94,7 @@
 #if USE_ECAP
 #include "adaptation/ecap/Config.h"
 #endif
-#if USE_SSL
+#if USE_OPENSSL
 #include "ssl/Config.h"
 #include "ssl/support.h"
 #endif
@@ -121,7 +124,7 @@
 #include <sys/stat.h>
 #endif
 
-#if USE_SSL
+#if USE_OPENSSL
 #include "ssl/gadgets.h"
 #endif
 
@@ -189,7 +192,7 @@ static void defaults_postscriptum(void);
 static int parse_line(char *);
 static void parse_obsolete(const char *);
 static void parseBytesLine(size_t * bptr, const char *units);
-#if USE_SSL
+#if USE_OPENSSL
 static void parseBytesOptionValue(size_t * bptr, const char *units, char const * value);
 #endif
 static void parseBytesLineSigned(ssize_t * bptr, const char *units);
@@ -230,7 +233,7 @@ static void parsePortCfg(AnyP::PortCfg **, const char *protocol);
 static void dump_PortCfg(StoreEntry *, const char *, const AnyP::PortCfg *);
 static void free_PortCfg(AnyP::PortCfg **);
 
-#if USE_SSL
+#if USE_OPENSSL
 static void parse_sslproxy_cert_sign(sslproxy_cert_sign **cert_sign);
 static void dump_sslproxy_cert_sign(StoreEntry *entry, const char *name, sslproxy_cert_sign *cert_sign);
 static void free_sslproxy_cert_sign(sslproxy_cert_sign **cert_sign);
@@ -240,7 +243,11 @@ static void free_sslproxy_cert_adapt(sslproxy_cert_adapt **cert_adapt);
 static void parse_sslproxy_ssl_bump(acl_access **ssl_bump);
 static void dump_sslproxy_ssl_bump(StoreEntry *entry, const char *name, acl_access *ssl_bump);
 static void free_sslproxy_ssl_bump(acl_access **ssl_bump);
-#endif /* USE_SSL */
+#endif /* USE_OPENSSL */
+
+static void parse_ftp_epsv(acl_access **ftp_epsv);
+static void dump_ftp_epsv(StoreEntry *entry, const char *name, acl_access *ftp_epsv);
+static void free_ftp_epsv(acl_access **ftp_epsv);
 
 static void parse_b_size_t(size_t * var);
 static void parse_b_int64_t(int64_t * var);
@@ -860,16 +867,18 @@ configDoConfigure(void)
             Config2.effectiveGroupID = pwd->pw_gid;
 
 #if HAVE_PUTENV
-
             if (pwd->pw_dir && *pwd->pw_dir) {
-                int len;
-                char *env_str = (char *)xcalloc((len = strlen(pwd->pw_dir) + 6), 1);
-                snprintf(env_str, len, "HOME=%s", pwd->pw_dir);
-                putenv(env_str);
+                // putenv() leaks by design; avoid leaks when nothing changes
+                static SBuf lastDir;
+                if (lastDir.isEmpty() || !lastDir.cmp(pwd->pw_dir)) {
+                    lastDir = pwd->pw_dir;
+                    int len = strlen(pwd->pw_dir) + 6;
+                    char *env_str = (char *)xcalloc(len, 1);
+                    snprintf(env_str, len, "HOME=%s", pwd->pw_dir);
+                    putenv(env_str);
+                }
             }
-
 #endif
-
         }
     } else {
         Config2.effectiveUserID = geteuid();
@@ -889,7 +898,7 @@ configDoConfigure(void)
         Config2.effectiveGroupID = grp->gr_gid;
     }
 
-#if USE_SSL
+#if USE_OPENSSL
 
     debugs(3, DBG_IMPORTANT, "Initializing https proxy context");
 
@@ -1259,15 +1268,13 @@ parseBytesUnits(const char *unit)
     return 0;
 }
 
-/*****************************************************************************
- * Max
- *****************************************************************************/
-
 static void
-dump_wordlist(StoreEntry * entry, wordlist *words)
+dump_SBufList(StoreEntry * entry, const SBufList &words)
 {
-    for (wordlist *word = words; word; word = word->next)
-        storeAppendPrintf(entry, "%s ", word->key);
+    for (SBufList::const_iterator i = words.begin(); i != words.end(); ++i) {
+        entry->append(i->rawContent(), i->length());
+        entry->append(" ",1);
+    }
 }
 
 static void
@@ -1280,11 +1287,7 @@ dump_acl(StoreEntry * entry, const char *name, ACL * ae)
                           ae->name,
                           ae->typeString(),
                           ae->flags.flagsStr());
-        wordlist *w = ae->dump();
-        dump_wordlist(entry, w);
-
-        storeAppendPrintf(entry, "\n");
-        wordlistDestroy(&w);
+        dump_SBufList(entry, ae->dump());
         ae = ae->next;
     }
 }
@@ -1304,19 +1307,14 @@ free_acl(ACL ** ae)
 void
 dump_acl_list(StoreEntry * entry, ACLList * head)
 {
-    wordlist *values = head->dump();
-    dump_wordlist(entry, values);
-    wordlistDestroy(&values);
+    dump_SBufList(entry, head->dump());
 }
 
 void
 dump_acl_access(StoreEntry * entry, const char *name, acl_access * head)
 {
-    if (head) {
-        wordlist *lines = head->treeDump(name, NULL);
-        dump_wordlist(entry, lines);
-        wordlistDestroy(&lines);
-    }
+    if (head)
+        dump_SBufList(entry, head->treeDump(name,NULL));
 }
 
 static void
@@ -2242,6 +2240,8 @@ parse_peer(CachePeer ** head)
             p->options.allow_miss = true;
         } else if (!strncmp(token, "max-conn=", 9)) {
             p->max_conn = xatoi(token + 9);
+        } else if (!strncmp(token, "standby=", 8)) {
+            p->standby.limit = xatoi(token + 8);
         } else if (!strcmp(token, "originserver")) {
             p->options.originserver = true;
         } else if (!strncmp(token, "name=", 5)) {
@@ -2255,7 +2255,7 @@ parse_peer(CachePeer ** head)
             if (token[13])
                 p->domain = xstrdup(token + 13);
 
-#if USE_SSL
+#if USE_OPENSSL
 
         } else if (strcmp(token, "ssl") == 0) {
             p->use_ssl = 1;
@@ -2315,6 +2315,9 @@ parse_peer(CachePeer ** head)
     if (peerFindByName(p->name))
         fatalf("ERROR: cache_peer %s specified twice\n", p->name);
 
+    if (p->max_conn > 0 && p->max_conn < p->standby.limit)
+        fatalf("ERROR: cache_peer %s max-conn=%d is lower than its standby=%d\n", p->host, p->max_conn, p->standby.limit);
+
     if (p->weight < 1)
         p->weight = 1;
 
@@ -2359,6 +2362,9 @@ free_peer(CachePeer ** P)
         cbdataReferenceDone(p->digest);
 #endif
 
+        // the mgr job will notice that its owner is gone and stop
+        PeerPoolMgr::Checkpoint(p->standby.mgr, "peer gone");
+        delete p->standby.pool;
         cbdataFree(p);
     }
 
@@ -3687,7 +3693,7 @@ parse_port_option(AnyP::PortCfg * s, char *token)
             ++t;
             s->tcp_keepalive.timeout = xatoui(t);
         }
-#if USE_SSL
+#if USE_OPENSSL
     } else if (strcmp(token, "sslBump") == 0) {
         debugs(3, DBG_CRITICAL, "WARNING: '" << token << "' is deprecated " <<
                "in http_port. Use 'ssl-bump' instead.");
@@ -3789,7 +3795,7 @@ parsePortCfg(AnyP::PortCfg ** head, const char *optionName)
         parse_port_option(s, token);
     }
 
-#if USE_SSL
+#if USE_OPENSSL
     if (s->transport.protocol == AnyP::PROTO_HTTPS) {
         /* ssl-bump on https_port configuration requires either tproxy or intercept, and vice versa */
         const bool hijacked = s->flags.isIntercepted();
@@ -3896,7 +3902,7 @@ dump_generic_port(StoreEntry * e, const char *n, const AnyP::PortCfg * s)
         }
     }
 
-#if USE_SSL
+#if USE_OPENSSL
     if (s->flags.tunnelSslBumping)
         storeAppendPrintf(e, " ssl-bump");
 
@@ -3966,7 +3972,7 @@ void
 configFreeMemory(void)
 {
     free_all();
-#if USE_SSL
+#if USE_OPENSSL
     SSL_CTX_free(Config.ssl_client.sslContext);
 #endif
 }
@@ -4449,7 +4455,7 @@ static void free_icap_service_failure_limit(Adaptation::Icap::Config *cfg)
 }
 #endif
 
-#if USE_SSL
+#if USE_OPENSSL
 static void parse_sslproxy_cert_adapt(sslproxy_cert_adapt **cert_adapt)
 {
     char *al;
@@ -4693,11 +4699,8 @@ static void parse_sslproxy_ssl_bump(acl_access **ssl_bump)
 
 static void dump_sslproxy_ssl_bump(StoreEntry *entry, const char *name, acl_access *ssl_bump)
 {
-    if (ssl_bump) {
-        wordlist *lines = ssl_bump->treeDump(name, Ssl::BumpModeStr);
-        dump_wordlist(entry, lines);
-        wordlistDestroy(&lines);
-    }
+    if (ssl_bump)
+        dump_SBufList(entry, ssl_bump->treeDump(name, Ssl::BumpModeStr));
 }
 
 static void free_sslproxy_ssl_bump(acl_access **ssl_bump)
@@ -4789,6 +4792,73 @@ static void free_note(Notes *notes)
     notes->clean();
 }
 
+static bool FtpEspvDeprecated = false;
+static void parse_ftp_epsv(acl_access **ftp_epsv)
+{
+    allow_t ftpEpsvDeprecatedAction;
+    bool ftpEpsvIsDeprecatedRule = false;
+
+    char *t = ConfigParser::PeekAtToken();
+    if (!t) {
+        self_destruct();
+        return;
+    }
+
+    if (!strcmp(t, "off")) {
+        (void)ConfigParser::NextToken();
+        ftpEpsvIsDeprecatedRule = true;
+        ftpEpsvDeprecatedAction = allow_t(ACCESS_DENIED);
+    } else if (!strcmp(t, "on")) {
+        (void)ConfigParser::NextToken();
+        ftpEpsvIsDeprecatedRule = true;
+        ftpEpsvDeprecatedAction = allow_t(ACCESS_ALLOWED);
+    }
+
+    // Check for mixing "ftp_epsv on|off" and "ftp_epsv allow|deny .." rules:
+    //   1) if this line is "ftp_epsv allow|deny ..." and already exist rules of "ftp_epsv on|off"
+    //   2) if this line is "ftp_epsv on|off" and already exist rules of "ftp_epsv allow|deny ..."
+    // then abort
+    if ((!ftpEpsvIsDeprecatedRule && FtpEspvDeprecated) ||
+            (ftpEpsvIsDeprecatedRule && !FtpEspvDeprecated && *ftp_epsv != NULL)) {
+        debugs(3, DBG_CRITICAL, "FATAL: do not mix \"ftp_epsv on|off\" cfg lines with \"ftp_epsv allow|deny ...\" cfg lines. Update your ftp_epsv rules.");
+        self_destruct();
+    }
+
+    if (ftpEpsvIsDeprecatedRule) {
+        // overwrite previous ftp_epsv lines
+        delete *ftp_epsv;
+        if (ftpEpsvDeprecatedAction == allow_t(ACCESS_DENIED)) {
+            Acl::AndNode *ftpEpsvRule = new Acl::AndNode;
+            ftpEpsvRule->context("(ftp_epsv rule)", config_input_line);
+            ACL *a = ACL::FindByName("all");
+            if (!a) {
+                self_destruct();
+                return;
+            }
+            ftpEpsvRule->add(a);
+            *ftp_epsv = new Acl::Tree;
+            (*ftp_epsv)->context("(ftp_epsv rules)", config_input_line);
+            (*ftp_epsv)->add(ftpEpsvRule, ftpEpsvDeprecatedAction);
+        } else
+            *ftp_epsv = NULL;
+        FtpEspvDeprecated = true;
+    } else {
+        aclParseAccessLine(cfg_directive, LegacyParser, ftp_epsv);
+    }
+}
+
+static void dump_ftp_epsv(StoreEntry *entry, const char *name, acl_access *ftp_epsv)
+{
+    if (ftp_epsv)
+        dump_SBufList(entry, ftp_epsv->treeDump(name, NULL));
+}
+
+static void free_ftp_epsv(acl_access **ftp_epsv)
+{
+    free_acl_access(ftp_epsv);
+    FtpEspvDeprecated = false;
+}
+
 static void
 parse_configuration_includes_quoted_values(bool *recognizeQuotedValues)
 {
@@ -37,10 +37,7 @@
  */
 
 #include "squid.h"
-
-#if HAVE_ERRNO_H
-#include <errno.h>
-#endif
+#include <cerrno>
 
 typedef struct {
     const char *name;
@@ -59,18 +56,6 @@ typedef struct _CacheEntry {
     unsigned char key_arr[SQUID_MD5_DIGEST_LENGTH];
 } CacheEntry;
 
-/* copied from url.c */
-const char *RequestMethodStr[] = {
-    "NONE",
-    "GET",
-    "POST",
-    "PUT",
-    "HEAD",
-    "CONNECT",
-    "TRACE",
-    "PURGE"
-};
-
 static int cacheIndexScan(CacheIndex * idx, const char *fname, FILE * file);
 
 static CacheEntry *
@@ -82,7 +82,7 @@ void
 CacheManager::registerProfile(const Mgr::ActionProfile::Pointer &profile)
 {
     Must(profile != NULL);
-    if (std::find(menu_.begin(), menu_.end(), profile) == menu_.end()) {
+    if (!CacheManager::findAction(profile->name)) {
         menu_.push_back(profile);
         debugs(16, 3, HERE << "registered profile: " << *profile);
     } else {
@@ -185,16 +185,14 @@ carpSelectParent(HttpRequest * request)
 
     /* select CachePeer */
     for (k = 0; k < n_carp_peers; ++k) {
-        String key;
+        SBuf key;
         tp = carp_peers[k];
         if (tp->options.carp_key.set) {
             //this code follows urlCanonical's pattern.
             //   corner cases should use the canonical URL
             if (tp->options.carp_key.scheme) {
-                // temporary, until bug 1961 URL handling is fixed.
-                const AnyP::UriScheme sch(request->protocol);
-                key.append(sch.c_str());
-                if (key.size()) //if the scheme is not empty
+                key.append(request->url.getScheme().c_str());
+                if (key.length()) //if the scheme is not empty
                     key.append("://");
             }
             if (tp->options.carp_key.host) {
@@ -208,24 +206,24 @@ carpSelectParent(HttpRequest * request)
             if (tp->options.carp_key.path) {
                 String::size_type pos;
                 if ((pos=request->urlpath.find('?'))!=String::npos)
-                    key.append(request->urlpath.substr(0,pos));
+                    key.append(SBuf(request->urlpath.substr(0,pos)));
                 else
-                    key.append(request->urlpath);
+                    key.append(SBuf(request->urlpath));
             }
             if (tp->options.carp_key.params) {
                 String::size_type pos;
                 if ((pos=request->urlpath.find('?'))!=String::npos)
-                    key.append(request->urlpath.substr(pos,request->urlpath.size()));
+                    key.append(SBuf(request->urlpath.substr(pos,request->urlpath.size())));
             }
         }
         // if the url-based key is empty, e.g. because the user is
         // asking to balance on the path but the request doesn't supply any,
         // then fall back to canonical URL
 
-        if (key.size()==0)
-            key=urlCanonical(request);
+        if (key.isEmpty())
+            key=SBuf(urlCanonical(request));
 
-        for (const char *c = key.rawBuf(), *e=key.rawBuf()+key.size(); c < e; ++c)
+        for (const char *c = key.rawContent(), *e=key.rawContent()+key.length(); c < e; ++c)
             user_hash += ROTATE_LEFT(user_hash, 19) + *c;
         combined_hash = (user_hash ^ tp->carp.hash);
         combined_hash += combined_hash * 0x62531965;
@@ -48,9 +48,9 @@
 
 #include "squid.h"
 #include "cbdata.h"
+#include "Generic.h"
 #include "mgr/Registration.h"
 #include "Store.h"
-#include "Generic.h"
 
 #include <climits>
 #if USE_CBDATA_DEBUG
@@ -75,3 +75,4 @@ wordlist
 sslproxy_ssl_bump	acl
 sslproxy_cert_sign	acl
 sslproxy_cert_adapt	acl
+ftp_epsv                acl
@@ -64,6 +64,17 @@ COMMENT_START
   from causing Squid entering an infinite loop whilst trying to load
   configuration files.
 
+  Values with byte units
+
+	Squid accepts size units on some size related directives. All
+	such directives are documented with a default value displaying
+	a unit.
+
+	Units accepted by Squid are:
+		bytes - byte
+		KB - Kilobyte (1024 bytes)
+		MB - Megabyte
+		GB - Gigabyte
 
   Values with spaces, quotes, and other special characters
 
@@ -283,7 +294,7 @@ DOC_START
 	This is used to define parameters for the various authentication
 	schemes supported by Squid.
 
-	format: auth_param scheme parameter [setting]
+		format: auth_param scheme parameter [setting]
 
 	The order in which authentication schemes are presented to the client is
 	dependent on the order the scheme first appears in config file. IE
@@ -320,307 +331,188 @@ DOC_START
 	=== Parameters common to all schemes. ===
 
 	"program" cmdline
-	Specifies the command for the external authenticator.  Such a program
-	runs a loop that, on every iteration, reads a request line from
-	the standard and responds with a scheme-specific answer. The loop
-	stops when all input is exchausted (EOF). See scheme-specific
-	"program" descriptions below for details.
+		Specifies the command for the external authenticator.
 
-	"key_extras" format
-	Specifies a string to be append to request line format for the
-	authentication helper. "Quoted" format values may contain spaces and
-	logformat %macros. In theory, any logformat %macro can be used.
-	In practice, a %macro expands as a dash (-) if the helper request is
-	sent before the required macro information is available to Squid.
-	By default, Squid uses request formats provided in scheme-specific
-	examples below (search for %credentials).
-	The expanded key_extras value is added to the Squid credentials
-	cache and, hence, will affect authentication. It can be used to
-	autenticate different users with identical user names (e.g., when user
-	authentication depends on http_port).
-	Avoid adding frequently changing information to key_extras. For
-	example, if you add user source IP, and it changes frequently
-	in your environment, then max_user_ip ACL is going to treat every
-	user+IP combination as a unique "user", breaking the ACL and
-	wasting a lot of memory on those user records. It will also force
-	users to authenticate from scratch whenever their IP changes.
-
-	=== Parameters for the basic scheme follow. ===
+		By default, each authentication scheme is not used unless a
+		program is specified.
 
-	"program" cmdline
-	Specify the command for the external authenticator.  Such a program
-	reads a request_format line ("username password" by default) and
-	replies with one of three results:
+		See http://wiki.squid-cache.org/Features/AddonHelpers for
+		more details on helper operations and creating your own.
 
-	  OK
-		the user exists.
+	"key_extras" format
+		Specifies a string to be append to request line format for
+		the authentication helper. "Quoted" format values may contain
+		spaces and logformat %macros. In theory, any logformat %macro
+		can be used. In practice, a %macro expands as a dash (-) if
+		the helper request is sent before the required macro
+		information is available to Squid.
+
+		By default, Squid uses request formats provided in
+		scheme-specific examples below (search for %credentials).
+
+		The expanded key_extras value is added to the Squid credentials
+		cache and, hence, will affect authentication. It can be used to
+		autenticate different users with identical user names (e.g.,
+		when user authentication depends on http_port).
+
+		Avoid adding frequently changing information to key_extras. For
+		example, if you add user source IP, and it changes frequently
+		in your environment, then max_user_ip ACL is going to treat
+		every user+IP combination as a unique "user", breaking the ACL
+		and wasting a lot of memory on those user records. It will also
+		force users to authenticate from scratch whenever their IP
+		changes.
+
+	"realm" string
+		Specifies the protection scope (aka realm name) which is to be
+		reported to the client for the authentication scheme. It is
+		commonly part of the text the user will see when prompted for
+		their username and password.
+
+		For Basic the default is "Squid proxy-caching web server".
+		For Digest there is no default, this parameter is mandatory.
+		For NTLM and Negotiate this parameter is ignored.
 
-	  ERR
-		the user does not exist.
+	"children" numberofchildren [startup=N] [idle=N] [concurrency=N]
 
-	  BH
-		An internal error occurred in the helper, preventing
-		a result being identified.
+		The maximum number of authenticator processes to spawn. If
+		you start too few Squid will have to wait for them to process
+		a backlog of credential verifications, slowing it down. When
+		password verifications are done via a (slow) network you are
+		likely to need lots of authenticator processes.
 
-	"ERR" and "BH" results may optionally be followed by message="..."
-	containing a description available as %m in the returned error page.
+		The startup= and idle= options permit some skew in the exact
+		amount run. A minimum of startup=N will begin during startup
+		and reconfigure. Squid will start more in groups of up to
+		idle=N in an attempt to meet traffic needs and to keep idle=N
+		free above those traffic needs up to the maximum.
 
-	If you use an authenticator, make sure you have 1 acl of type
-	proxy_auth.
+		The concurrency= option sets the number of concurrent requests
+		the helper can process.  The default of 0 is used for helpers
+		who only supports one request at a time. Setting this to a
+		number greater than 0 changes the protocol used to include a
+		channel ID field first on the request/response line, allowing
+		multiple requests to be sent to the same helper in parallel
+		without waiting for the response.
 
-	By default, the basic authentication scheme is not used unless a
-	program is specified.
+		Concurrency must not be set unless it's known the helper
+		supports the input format with channel-ID fields.
 
-	If you want to use the traditional NCSA proxy authentication, set
-	this line to something like
+		NOTE: NTLM and Negotiate schemes do not support concurrency
+			in the Squid code module even though some helpers can.
 
-	auth_param basic program @DEFAULT_PREFIX@/libexec/basic_ncsa_auth @DEFAULT_PREFIX@/etc/passwd
 
-	"utf8" on|off
-	HTTP uses iso-latin-1 as character set, while some authentication
-	backends such as LDAP expects UTF-8. If this is set to on Squid will
-	translate the HTTP iso-latin-1 charset to UTF-8 before sending the
-	username & password to the helper.
+IF HAVE_AUTH_MODULE_BASIC
+	=== Basic authentication parameters ===
 
-	"children" numberofchildren [startup=N] [idle=N] [concurrency=N]
-	The maximum number of authenticator processes to spawn. If you start too few
-	Squid will have to wait for them to process a backlog of credential
-	verifications, slowing it down. When password verifications are
-	done via a (slow) network you are likely to need lots of
-	authenticator processes.
-
-	The startup= and idle= options permit some skew in the exact amount
-	run. A minimum of startup=N will begin during startup and reconfigure.
-	Squid will start more in groups of up to idle=N in an attempt to meet
-	traffic needs and to keep idle=N free above those traffic needs up to
-	the maximum.
-
-	The concurrency= option sets the number of concurrent requests the
-	helper can process.  The default of 0 is used for helpers who only
-	supports one request at a time. Setting this to a number greater than
-	0 changes the protocol used to include a channel number first on the
-	request/response line, allowing multiple requests to be sent to the
-	same helper in parallel without waiting for the response.
-	Must not be set unless it's known the helper supports this.
-
-	auth_param basic children 20 startup=0 idle=1
-
-	"realm" realmstring
-	Specifies the realm name which is to be reported to the
-	client for the basic proxy authentication scheme (part of
-	the text the user will see when prompted their username and
-	password). There is no default.
-	auth_param basic realm Squid proxy-caching web server
+	"utf8" on|off
+		HTTP uses iso-latin-1 as character set, while some
+		authentication backends such as LDAP expects UTF-8. If this is
+		set to on Squid will translate the HTTP iso-latin-1 charset to
+		UTF-8 before sending the username and password to the helper.
 
 	"credentialsttl" timetolive
-	Specifies how long squid assumes an externally validated
-	username:password pair is valid for - in other words how
-	often the helper program is called for that user. Set this
-	low to force revalidation with short lived passwords.  Note
-	setting this high does not impact your susceptibility
-	to replay attacks unless you are using an one-time password
-	system (such as SecureID).  If you are using such a system,
-	you will be vulnerable to replay attacks unless you also
-	use the max_user_ip ACL in an http_access rule.
-
-	"casesensitive" on|off
-	Specifies if usernames are case sensitive. Most user databases are
-	case insensitive allowing the same username to be spelled using both
-	lower and upper case letters, but some are case sensitive. This
-	makes a big difference for user_max_ip ACL processing and similar.
-	auth_param basic casesensitive off
-
-	=== Parameters for the digest scheme follow ===
-
-	"program" cmdline
-	Specify the command for the external authenticator.  Such a program
-	reads a request_format line ("username":"realm" by default) and
-	replies with one of three results:
-
-	  OK ha1="..."
-		the user exists. The ha1= key is mandatory and
-		contains the appropriate H(A1) value, hex encoded.
-		See rfc 2616 for the definition of H(A1).
+		Specifies how long squid assumes an externally validated
+		username:password pair is valid for - in other words how
+		often the helper program is called for that user. Set this
+		low to force revalidation with short lived passwords.
 
-	  ERR
-		the user does not exist.
-
-	  BH
-		An internal error occurred in the helper, preventing
-		a result being identified.
-
-	"ERR" and "BH" results may optionally be followed by message="..."
-	containing a description available as %m in the returned error page.
+		NOTE: setting this high does not impact your susceptibility
+		to replay attacks unless you are using an one-time password
+		system (such as SecureID). If you are using such a system,
+		you will be vulnerable to replay attacks unless you also
+		use the max_user_ip ACL in an http_access rule.
 
-	By default, the digest authentication scheme is not used unless a
-	program is specified.
-
-	If you want to use a digest authenticator, set this line to
-	something like
+	"casesensitive" on|off
+		Specifies if usernames are case sensitive. Most user databases
+		are case insensitive allowing the same username to be spelled
+		using both lower and upper case letters, but some are case
+		sensitive. This makes a big difference for user_max_ip ACL
+		processing and similar.
 
-	auth_param digest program @DEFAULT_PREFIX@/bin/digest_pw_auth @DEFAULT_PREFIX@/etc/digpass
+ENDIF
+IF HAVE_AUTH_MODULE_DIGEST
+	=== Digest authentication parameters ===
 
 	"utf8" on|off
-	HTTP uses iso-latin-1 as character set, while some authentication
-	backends such as LDAP expects UTF-8. If this is set to on Squid will
-	translate the HTTP iso-latin-1 charset to UTF-8 before sending the
-	username & password to the helper.
-
-	"children" numberofchildren [startup=N] [idle=N] [concurrency=N]
-	The maximum number of authenticator processes to spawn (default 5).
-	If you start too few Squid will have to wait for them to
-	process a backlog of H(A1) calculations, slowing it down.
-	When the H(A1) calculations are done via a (slow) network
-	you are likely to need lots of authenticator processes.
-
-	The startup= and idle= options permit some skew in the exact amount
-	run. A minimum of startup=N will begin during startup and reconfigure.
-	Squid will start more in groups of up to idle=N in an attempt to meet
-	traffic needs and to keep idle=N free above those traffic needs up to
-	the maximum.
-
-	The concurrency= option sets the number of concurrent requests the
-	helper can process.  The default of 0 is used for helpers who only
-	supports one request at a time. Setting this to a number greater than
-	0 changes the protocol used to include a channel number first on the
-	request/response line, allowing multiple requests to be sent to the
-	same helper in parallel without waiting for the response.
-	Must not be set unless it's known the helper supports this.
-
-	auth_param digest children 20 startup=0 idle=1
-
-	"realm" realmstring
-	Specifies the realm name which is to be reported to the
-	client for the digest proxy authentication scheme (part of
-	the text the user will see when prompted their username and
-	password). There is no default.
-	auth_param digest realm Squid proxy-caching web server
+		HTTP uses iso-latin-1 as character set, while some
+		authentication backends such as LDAP expects UTF-8. If this is
+		set to on Squid will translate the HTTP iso-latin-1 charset to
+		UTF-8 before sending the username and password to the helper.
 
 	"nonce_garbage_interval" timeinterval
-	Specifies the interval that nonces that have been issued
-	to client_agent's are checked for validity.
+		Specifies the interval that nonces that have been issued
+		to client_agent's are checked for validity.
 
 	"nonce_max_duration" timeinterval
-	Specifies the maximum length of time a given nonce will be
-	valid for.
+		Specifies the maximum length of time a given nonce will be
+		valid for.
 
 	"nonce_max_count" number
-	Specifies the maximum number of times a given nonce can be
-	used.
+		Specifies the maximum number of times a given nonce can be
+		used.
 
 	"nonce_strictness" on|off
-	Determines if squid requires strict increment-by-1 behavior
-	for nonce counts, or just incrementing (off - for use when
-	user agents generate nonce counts that occasionally miss 1
-	(ie, 1,2,4,6)). Default off.
+		Determines if squid requires strict increment-by-1 behavior
+		for nonce counts, or just incrementing (off - for use when
+		user agents generate nonce counts that occasionally miss 1
+		(ie, 1,2,4,6)). Default off.
 
 	"check_nonce_count" on|off
-	This directive if set to off can disable the nonce count check
-	completely to work around buggy digest qop implementations in
-	certain mainstream browser versions. Default on to check the
-	nonce count to protect from authentication replay attacks.
+		This directive if set to off can disable the nonce count check
+		completely to work around buggy digest qop implementations in
+		certain mainstream browser versions. Default on to check the
+		nonce count to protect from authentication replay attacks.
 
 	"post_workaround" on|off
-	This is a workaround to certain buggy browsers who sends
-	an incorrect request digest in POST requests when reusing
-	the same nonce as acquired earlier on a GET request.
+		This is a workaround to certain buggy browsers who send an
+		incorrect request digest in POST requests when reusing the
+		same nonce as acquired earlier on a GET request.
 
-	=== NTLM scheme options follow ===
-
-	"program" cmdline
-	Specify the command for the external NTLM authenticator.
-	Such a program reads exchanged NTLMSSP packets with
-	the browser via Squid until authentication is completed.
-	If you use an NTLM authenticator, make sure you have 1 acl
-	of type proxy_auth.  By default, the NTLM authenticator program
-	is not used.
-
-	auth_param ntlm program /usr/bin/ntlm_auth
-
-	"children" numberofchildren [startup=N] [idle=N]
-	The maximum number of authenticator processes to spawn (default 5).
-	If you start too few Squid will have to wait for them to
-	process a backlog of credential verifications, slowing it
-	down. When credential verifications are done via a (slow)
-	network you are likely to need lots of authenticator
-	processes.
-
-	The startup= and idle= options permit some skew in the exact amount
-	run. A minimum of startup=N will begin during startup and reconfigure.
-	Squid will start more in groups of up to idle=N in an attempt to meet
-	traffic needs and to keep idle=N free above those traffic needs up to
-	the maximum.
-
-	auth_param ntlm children 20 startup=0 idle=1
+ENDIF
+IF HAVE_AUTH_MODULE_NEGOTIATE
+	=== Negotiate authentication parameters ===
 
 	"keep_alive" on|off
-	If you experience problems with PUT/POST requests when using the
-	Negotiate authentication scheme then you can try setting this to
-	off. This will cause Squid to forcibly close the connection on
-	the initial requests where the browser asks which schemes are
-	supported by the proxy.
-
-	auth_param ntlm keep_alive on
+		If you experience problems with PUT/POST requests when using
+		the this authentication scheme then you can try setting this
+		to off. This will cause Squid to forcibly close the connection
+		on the initial request where the browser asks which schemes
+		are supported by the proxy.
 
-	=== Options for configuring the NEGOTIATE auth-scheme follow ===
-
-	"program" cmdline
-	Specify the command for the external Negotiate authenticator.
-	This protocol is used in Microsoft Active-Directory enabled setups with
-	the Microsoft Internet Explorer or Mozilla Firefox browsers.
-	Its main purpose is to exchange credentials with the Squid proxy
-	using the Kerberos mechanisms.
-	If you use a Negotiate authenticator, make sure you have at least
-	one acl of type proxy_auth active. By default, the negotiate
-	authenticator program is not used.
-	The only supported program for this role is the ntlm_auth
-	program distributed as part of Samba, version 4 or later.
-
-	auth_param negotiate program /usr/bin/ntlm_auth --helper-protocol=gss-spnego
-
-	"children" numberofchildren [startup=N] [idle=N]
-	The maximum number of authenticator processes to spawn (default 5).
-	If you start too few Squid will have to wait for them to
-	process a backlog of credential verifications, slowing it
-	down. When credential verifications are done via a (slow)
-	network you are likely to need lots of authenticator
-	processes.
-
-	The startup= and idle= options permit some skew in the exact amount
-	run. A minimum of startup=N will begin during startup and reconfigure.
-	Squid will start more in groups of up to idle=N in an attempt to meet
-	traffic needs and to keep idle=N free above those traffic needs up to
-	the maximum.
-
-	auth_param negotiate children 20 startup=0 idle=1
+ENDIF
+IF HAVE_AUTH_MODULE_NTLM
+	=== NTLM authentication parameters ===
 
 	"keep_alive" on|off
-	If you experience problems with PUT/POST requests when using the
-	Negotiate authentication scheme then you can try setting this to
-	off. This will cause Squid to forcibly close the connection on
-	the initial requests where the browser asks which schemes are
-	supported by the proxy.
+		If you experience problems with PUT/POST requests when using
+		the this authentication scheme then you can try setting this
+		to off. This will cause Squid to forcibly close the connection
+		on the initial request where the browser asks which schemes
+		are supported by the proxy.
+ENDIF
 
-	auth_param negotiate keep_alive on
-	
-	Examples:
+	=== Example Configuration ===
+
+	This configuration displays the recommended authentication scheme
+	order from most to least secure with recommended minimum configuration
+	settings for each scheme:
 
-#Recommended minimum configuration per scheme:
 #auth_param negotiate program <uncomment and complete this line to activate>
 #auth_param negotiate children 20 startup=0 idle=1
 #auth_param negotiate keep_alive on
 #
-#auth_param ntlm program <uncomment and complete this line to activate>
-#auth_param ntlm children 20 startup=0 idle=1
-#auth_param ntlm keep_alive on
-#
-#auth_param digest program <uncomment and complete this line>
+#auth_param digest program <uncomment and complete this line to activate>
 #auth_param digest children 20 startup=0 idle=1
 #auth_param digest realm Squid proxy-caching web server
 #auth_param digest nonce_garbage_interval 5 minutes
 #auth_param digest nonce_max_duration 30 minutes
 #auth_param digest nonce_max_count 50
 #
+#auth_param ntlm program <uncomment and complete this line to activate>
+#auth_param ntlm children 20 startup=0 idle=1
+#auth_param ntlm keep_alive on
+#
 #auth_param basic program <uncomment and complete this line>
 #auth_param basic children 5 startup=5 idle=1
 #auth_param basic realm Squid proxy-caching web server
@@ -699,7 +591,7 @@ DOC_START
 			Up to the value of children-max. (default 1)
 	  concurrency=n	concurrency level per process. Only used with helpers
 			capable of processing more than one query at a time.
-	  cache=n	limit the result cache size, default is unbounded.
+	  cache=n	limit the result cache size, default is 262144.
 	  grace=n	Percentage remaining of TTL where a refresh of a
 			cached entry should be initiated without needing to
 			wait for a new reply. (default is for no grace period)
@@ -718,7 +610,7 @@ DOC_START
 	  %SRCPORT	Client source port
 	  %URI		Requested URI
 	  %DST		Requested host
-	  %PROTO	Requested protocol
+	  %PROTO	Requested URL scheme
 	  %PORT		Requested port
 	  %PATH		Requested URL path
 	  %METHOD	Request method
@@ -842,7 +734,7 @@ DOC_END
 NAME: acl
 TYPE: acl
 LOC: Config.aclList
-IF USE_SSL
+IF USE_OPENSSL
 DEFAULT: ssl::certHasExpired ssl_error X509_V_ERR_CERT_HAS_EXPIRED
 DEFAULT: ssl::certNotYetValid ssl_error X509_V_ERR_CERT_NOT_YET_VALID
 DEFAULT: ssl::certDomainMismatch ssl_error SQUID_X509_V_ERR_DOMAIN_MISMATCH
@@ -1107,7 +999,7 @@ DOC_START
 	  # adaptation_meta because it starts matching immediately after
 	  # the service has been selected for adaptation.
 
-IF USE_SSL
+IF USE_OPENSSL
 	acl aclname ssl_error errorname
 	  # match against SSL certificate validation error [fast]
 	  #
@@ -1838,7 +1730,7 @@ NOCOMMENT_END
 DOC_END
 
 NAME: https_port
-IFDEF: USE_SSL
+IFDEF: USE_OPENSSL
 TYPE: PortCfg
 DEFAULT: none
 LOC: Config.Sockaddr.https
@@ -2071,10 +1963,19 @@ DEFAULT: none
 LOC: Ip::Qos::TheConfig
 DOC_START
 	Allows you to select a TOS/DSCP value to mark outgoing
-	connections with, based on where the reply was sourced.	For
-	platforms using netfilter, allows you to set a netfilter mark
+	connections to the client, based on where the reply was sourced.
+	For platforms using netfilter, allows you to set a netfilter mark
 	value instead of, or in addition to, a TOS value.
 
+	By default this functionality is disabled. To enable it with the default
+	settings simply use "qos_flows mark" or "qos_flows tos". Default
+	settings will result in the netfilter mark or TOS value being copied
+	from the upstream connection to the client. Note that it is the connection
+	CONNMARK value not the packet MARK value that is copied.
+
+	It is not currently possible to copy the mark or TOS value from the
+	client to the upstream connection request.
+
 	TOS values really only have local significance - so you should
 	know what you're specifying. For more information, see RFC2474,
 	RFC2475, and RFC3260.
@@ -2273,7 +2174,7 @@ COMMENT_START
 COMMENT_END
 
 NAME: ssl_unclean_shutdown
-IFDEF: USE_SSL
+IFDEF: USE_OPENSSL
 TYPE: onoff
 DEFAULT: off
 LOC: Config.SSL.unclean_shutdown
@@ -2283,7 +2184,7 @@ DOC_START
 DOC_END
 
 NAME: ssl_engine
-IFDEF: USE_SSL
+IFDEF: USE_OPENSSL
 TYPE: string
 LOC: Config.SSL.ssl_engine
 DEFAULT: none
@@ -2293,7 +2194,7 @@ DOC_START
 DOC_END
 
 NAME: sslproxy_client_certificate
-IFDEF: USE_SSL
+IFDEF: USE_OPENSSL
 DEFAULT: none
 LOC: Config.ssl_client.cert
 TYPE: string
@@ -2302,7 +2203,7 @@ DOC_START
 DOC_END
 
 NAME: sslproxy_client_key
-IFDEF: USE_SSL
+IFDEF: USE_OPENSSL
 DEFAULT: none
 LOC: Config.ssl_client.key
 TYPE: string
@@ -2311,7 +2212,7 @@ DOC_START
 DOC_END
 
 NAME: sslproxy_version
-IFDEF: USE_SSL
+IFDEF: USE_OPENSSL
 DEFAULT: 1
 DEFAULT_DOC: automatic SSL/TLS version negotiation
 LOC: Config.ssl_client.version
@@ -2330,7 +2231,7 @@ DOC_START
 DOC_END
 
 NAME: sslproxy_options
-IFDEF: USE_SSL
+IFDEF: USE_OPENSSL
 DEFAULT: none
 LOC: Config.ssl_client.options
 TYPE: string
@@ -2360,7 +2261,7 @@ DOC_START
 DOC_END
 
 NAME: sslproxy_cipher
-IFDEF: USE_SSL
+IFDEF: USE_OPENSSL
 DEFAULT: none
 LOC: Config.ssl_client.cipher
 TYPE: string
@@ -2371,7 +2272,7 @@ DOC_START
 DOC_END
 
 NAME: sslproxy_cafile
-IFDEF: USE_SSL
+IFDEF: USE_OPENSSL
 DEFAULT: none
 LOC: Config.ssl_client.cafile
 TYPE: string
@@ -2381,7 +2282,7 @@ DOC_START
 DOC_END
 
 NAME: sslproxy_capath
-IFDEF: USE_SSL
+IFDEF: USE_OPENSSL
 DEFAULT: none
 LOC: Config.ssl_client.capath
 TYPE: string
@@ -2391,7 +2292,7 @@ DOC_START
 DOC_END
 
 NAME: sslproxy_session_ttl
-IFDEF: USE_SSL
+IFDEF: USE_OPENSSL
 DEFAULT: 300
 LOC: Config.SSL.session_ttl
 TYPE: int
@@ -2400,7 +2301,7 @@ DOC_START
 DOC_END
 
 NAME: sslproxy_session_cache_size
-IFDEF: USE_SSL
+IFDEF: USE_OPENSSL
 DEFAULT: 2 MB
 LOC: Config.SSL.sessionCacheSize
 TYPE: b_size_t
@@ -2409,7 +2310,7 @@ DOC_START
 DOC_END
 
 NAME: ssl_bump
-IFDEF: USE_SSL
+IFDEF: USE_OPENSSL
 TYPE: sslproxy_ssl_bump
 LOC: Config.accessList.ssl_bump
 DEFAULT_DOC: Does not bump unless rules are present in squid.conf
@@ -2468,7 +2369,7 @@ DOC_START
 DOC_END
 
 NAME: sslproxy_flags
-IFDEF: USE_SSL
+IFDEF: USE_OPENSSL
 DEFAULT: none
 LOC: Config.ssl_client.flags
 TYPE: string
@@ -2481,7 +2382,7 @@ DOC_START
 DOC_END
 
 NAME: sslproxy_cert_error
-IFDEF: USE_SSL
+IFDEF: USE_OPENSSL
 DEFAULT: none
 DEFAULT_DOC: Server certificate errors terminate the transaction.
 LOC: Config.ssl_client.cert_error
@@ -2516,7 +2417,7 @@ DOC_START
 DOC_END
 
 NAME: sslproxy_cert_sign
-IFDEF: USE_SSL
+IFDEF: USE_OPENSSL
 DEFAULT: none
 POSTSCRIPTUM: signUntrusted ssl::certUntrusted
 POSTSCRIPTUM: signSelf ssl::certSelfSigned
@@ -2562,7 +2463,7 @@ DOC_START
 DOC_END
 
 NAME: sslproxy_cert_adapt
-IFDEF: USE_SSL
+IFDEF: USE_OPENSSL
 DEFAULT: none
 TYPE: sslproxy_cert_adapt
 LOC: Config.ssl_client.cert_adapt
@@ -2605,7 +2506,7 @@ DOC_START
 DOC_END
 
 NAME: sslpassword_program
-IFDEF: USE_SSL
+IFDEF: USE_OPENSSL
 DEFAULT: none
 LOC: Config.Program.ssl_password
 TYPE: string
@@ -2670,7 +2571,7 @@ DOC_END
 
 NAME: sslcrtvalidator_program
 TYPE: eol
-IFDEF: USE_SSL
+IFDEF: USE_OPENSSL
 DEFAULT: none
 LOC: Ssl::TheConfig.ssl_crt_validator
 DOC_START
@@ -2686,7 +2587,7 @@ DOC_END
 
 NAME: sslcrtvalidator_children
 TYPE: HelperChildConfig
-IFDEF: USE_SSL
+IFDEF: USE_OPENSSL
 DEFAULT: 32 startup=5 idle=1 concurrency=1
 LOC: Ssl::TheConfig.ssl_crt_validator_Children
 DOC_START
@@ -3066,7 +2967,8 @@ DOC_START
 	
 	connect-fail-limit=N
 			How many times connecting to a peer must fail before
-			it is marked as down. Default is 10.
+			it is marked as down. Standby connection failures
+			count towards this limit. Default is 10.
 	
 	allow-miss	Disable Squid's use of only-if-cached when forwarding
 			requests to siblings. This is primarily useful when
@@ -3076,8 +2978,50 @@ DOC_START
 			For example to deny peer usage on requests from peer
 			by denying cache_peer_access if the source is a peer.
 	
-	max-conn=N	Limit the amount of connections Squid may open to this
-			peer. see also 
+	max-conn=N 	Limit the number of concurrent connections the Squid
+			may open to this peer, including already opened idle
+			and standby connections. There is no peer-specific
+			connection limit by default.
+	
+			A peer exceeding the limit is not used for new
+			requests unless a standby connection is available.
+	
+			max-conn currently works poorly with idle persistent
+			connections: When a peer reaches its max-conn limit,
+			and there are idle persistent connections to the peer,
+			the peer may not be selected because the limiting code
+			does not know whether Squid can reuse those idle
+			connections.
+	
+	standby=N	Maintain a pool of N "hot standby" connections to an
+			UP peer, available for requests when no idle
+			persistent connection is available (or safe) to use.
+			By default and with zero N, no such pool is maintained.
+			N must not exceed the max-conn limit (if any).
+	
+			At start or after reconfiguration, Squid opens new TCP
+			standby connections until there are N connections
+			available and then replenishes the standby pool as
+			opened connections are used up for requests. A used
+			connection never goes back to the standby pool, but
+			may go to the regular idle persistent connection pool
+			shared by all peers and origin servers.
+	
+			Squid never opens multiple new standby connections
+			concurrently.  This one-at-a-time approach minimizes
+			flooding-like effect on peers. Furthermore, just a few
+			standby connections should be sufficient in most cases
+			to supply most new requests with a ready-to-use
+			connection.
+	
+			Standby connections obey server_idle_pconn_timeout.
+			For the feature to work as intended, the peer must be
+			configured to accept and keep them open longer than
+			the idle timeout at the connecting Squid, to minimize
+			race conditions typical to idle used persistent
+			connections. Default request_timeout and
+			server_idle_pconn_timeout values ensure such a
+			configuration.
 	
 	name=xxx	Unique name for the peer.
 			Required if you have multiple peers on the same host
@@ -3374,6 +3318,39 @@ DOC_START
 	and http://fog.hpl.external.hp.com/techreports/98/HPL-98-173.html.
 DOC_END
 
+NAME: minimum_object_size
+COMMENT: (bytes)
+TYPE: b_int64_t
+DEFAULT: 0 KB
+DEFAULT_DOC: no limit
+LOC: Config.Store.minObjectSize
+DOC_START
+	Objects smaller than this size will NOT be saved on disk.  The
+	value is specified in bytes, and the default is 0 KB, which
+	means all responses can be stored.
+DOC_END
+
+NAME: maximum_object_size
+COMMENT: (bytes)
+TYPE: b_int64_t
+DEFAULT: 4 MB
+LOC: Config.Store.maxObjectSize
+DOC_START
+	Set the default value for max-size parameter on any cache_dir.
+	The value is specified in bytes, and the default is 4 MB.
+	
+	If you wish to get a high BYTES hit ratio, you should probably
+	increase this (one 32 MB object hit counts for 3200 10KB
+	hits).
+	
+	If you wish to increase hit ratio more than you want to
+	save bandwidth you should leave this low.
+	
+	NOTE: if using the LFUDA replacement policy you should increase
+	this value to maximize the byte hit rate improvement of LFUDA!
+	See cache_replacement_policy for a discussion of this policy.
+DOC_END
+
 NAME: cache_dir
 TYPE: cachedir
 DEFAULT: none
@@ -3523,9 +3500,9 @@ DOC_START
 
 	max-size=n	the maximum object size in bytes this cache_dir
 			supports.
-			The value in maximum_object_size directive, sets
-			a default unless more specific details are available
-			about the cache_dir (ie a small store capacity).
+			The value in maximum_object_size directive sets
+			the default unless more specific details are
+			available (ie a small store capacity).
 
 	Note: To make optimal use of the max-size limits you should order
 	the cache_dir lines with the smallest max-size value first.
@@ -3611,40 +3588,6 @@ DOC_START
 	A value of 0 indicates no limit.
 DOC_END
 
-NAME: minimum_object_size
-COMMENT: (bytes)
-TYPE: b_int64_t
-DEFAULT: 0 KB
-DEFAULT_DOC: no limit
-LOC: Config.Store.minObjectSize
-DOC_START
-	Objects smaller than this size will NOT be saved on disk.  The
-	value is specified in bytes, and the default is 0 KB, which
-	means all responses can be stored.
-DOC_END
-
-NAME: maximum_object_size
-COMMENT: (bytes)
-TYPE: b_int64_t
-DEFAULT: 4 MB
-LOC: Config.Store.maxObjectSize
-DOC_START
-	The default limit on size of objects stored to disk.
-	This size is used for cache_dir where max-size is not set.
-	The value is specified in bytes, and the default is 4 MB.
-
-	If you wish to get a high BYTES hit ratio, you should probably
-	increase this (one 32 MB object hit counts for 3200 10KB
-	hits).
-
-	If you wish to increase hit ratio more than you want to
-	save bandwidth you should leave this low.
-
-	NOTE: if using the LFUDA replacement policy you should increase
-	this value to maximize the byte hit rate improvement of LFUDA!
-	See replacement_policy below for a discussion of this policy.
-DOC_END
-
 NAME: cache_swap_low
 COMMENT: (percent, 0-100)
 TYPE: int
@@ -3733,10 +3676,22 @@ DOC_START
 		err_code    The ID of an error response served by Squid or
 				a similar internal error identifier.
 		err_detail  Additional err_code-dependent error information.
-		note	The meta header specified by the argument. Also
+		note	The annotation specified by the argument. Also
 			logs the adaptation meta headers set by the
 			adaptation_meta configuration parameter.
-			If no argument given all meta headers logged.
+			If no argument given all annotations logged.
+			The argument may include a separator to use with
+			annotation values:
+                            name[:separator]
+			By default, multiple note values are separated with ","
+			and multiple notes are separated with "\r\n".
+			When logging named notes with %{name}note, the
+			explicitly configured separator is used between note
+			values. When logging all notes with %note, the
+			explicitly configured separator is used between
+			individual notes. There is currently no way to
+			specify both value and notes separators when logging
+			all notes with %note.
 
 	Connection related format codes:
 
@@ -3806,15 +3761,20 @@ DOC_START
 		[http::]ru	Request URL from client (historic, filtered for logging)
 		[http::]>ru	Request URL from client
 		[http::]<ru	Request URL sent to server or peer
+		[http::]>rs	Request URL scheme from client
+		[http::]<rs	Request URL scheme sent to server or peer
 		[http::]>rd	Request URL domain from client
-		[http::]rp	Request URL-Path excluding hostname
-		[http::]>rp	Request URL-Path excluding hostname from client
-		[http::]<rp	Request URL-Path excluding hostname sent to server or peer
+		[http::]>rd	Request URL domain sent to server or peer
+		[http::]>rP	Request URL port from client
+		[http::]<rP	Request URL port sent to server or peer
+		[http::]rp	Request URL path excluding hostname
+		[http::]>rp	Request URL path excluding hostname from client
+		[http::]<rp	Request URL path excluding hostname sent to server or peer
 		[http::]rv	Request protocol version
 		[http::]>rv	Request protocol version from client
 		[http::]<rv	Request protocol version sent to server or peer
 
-		[http::]>h	Original received request header. 
+		[http::]>h	Original received request header.
 				Usually differs from the request header sent by
 				Squid, although most fields are often preserved.
 				Accepts optional header field name/value filter
@@ -4490,9 +4450,9 @@ DOC_START
 DOC_END
 
 NAME: ftp_epsv
-TYPE: onoff
-DEFAULT: on
-LOC: Config.Ftp.epsv
+TYPE: ftp_epsv
+DEFAULT: none
+LOC: Config.accessList.ftp_epsv
 DOC_START
 	FTP Protocol extensions permit the use of a special "EPSV" command.
 
@@ -4501,10 +4461,18 @@ DOC_START
 	and therefore, translation of the data portion of the segments 
 	will never be needed.
 
-	Turning this OFF will prevent EPSV being attempted.
-	WARNING: Doing so will convert Squid back to the old behavior with all
-	the related problems with external NAT devices/layers.
+	EPSV is often required to interoperate with FTP servers on IPv6
+	networks. On the other hand, it may break some IPv4 servers.
+
+	By default, EPSV may try EPSV with any FTP server. To fine tune
+	that decision, you may restrict EPSV to certain clients or servers
+	using ACLs:
+
+		ftp_epsv allow|deny al1 acl2 ...
+
+	WARNING: Disabling EPSV may cause problems with external NAT and IPv6.
 
+	Only fast ACLs are supported.
 	Requires ftp_passive to be ON (default) for any effect.
 DOC_END
 
@@ -9019,13 +8987,15 @@ DOC_END
 NAME: high_memory_warning
 TYPE: b_size_t
 LOC: Config.warnings.high_memory
+IFDEF: HAVE_MSTATS&&HAVE_GNUMALLOC_H
 DEFAULT: 0 KB
 DEFAULT_DOC: disabled.
 DOC_START
-	If the memory usage (as determined by mallinfo) exceeds
-	this amount, Squid prints a WARNING with debug level 0 to get
+	If the memory usage (as determined by gnumalloc, if available and used)
+	exceeds	this amount, Squid prints a WARNING with debug level 0 to get
 	the administrators attention.
 DOC_END
+# TODO: link high_memory_warning to mempools?
 
 NAME: sleep_after_fork
 COMMENT: (microseconds)
@@ -874,11 +874,11 @@ gen_quote_escape(const std::string &var)
 
     for (int i = 0; i < var.length(); ++i) {
         switch (var[i]) {
-            case '"':
-            case '\\':
-                esc += '\\';
-            default:
-                esc += var[i];
+        case '"':
+        case '\\':
+            esc += '\\';
+        default:
+            esc += var[i];
         }
     }
 
@@ -5,33 +5,34 @@ BEGIN {
 	print "*/"
 	print "#include \"autoconf.h\""
 	print "static struct { const char *name; const char *enable; int defined;} defines[] = {"
-	define["USE_DELAY_POOLS"]="--enable-delay-pools"
+	define["_SQUID_WINDOWS_"]="MS Windows"
 	define["FOLLOW_X_FORWARDED_FOR"]="--enable-follow-x-forwarded-for"
-	define["FOLLOW_X_FORWARDED_FOR&&USE_DELAY_POOLS"]="--enable-follow-x-forwarded-for and --enable-delay-pools"
-	define["FOLLOW_X_FORWARDED_FOR&&USE_ADAPTATION"]="--enable-follow-x-forwarded-for and (--enable-icap-client and/or --enable-ecap)"
 	define["FOLLOW_X_FORWARDED_FOR&&LINUX_NETFILTER"]="--enable-follow-x-forwarded-for and --enable-linux-netfilter"
-	define["USE_HTTP_VIOLATIONS"]="--enable-http-violations"
+	define["FOLLOW_X_FORWARDED_FOR&&USE_ADAPTATION"]="--enable-follow-x-forwarded-for and (--enable-icap-client and/or --enable-ecap)"
+	define["FOLLOW_X_FORWARDED_FOR&&USE_DELAY_POOLS"]="--enable-follow-x-forwarded-for and --enable-delay-pools"
+	define["HAVE_MSTATS&&HAVE_GNUMALLOC_H"]="GNU Malloc with mstats()"
 	define["ICAP_CLIENT"]="--enable-icap-client"
+	define["SO_MARK&&USE_LIBCAP"]="Packet MARK (Linux)"
 	define["SQUID_SNMP"]="--enable-snmp"
 	define["USE_ADAPTATION"]="--enable-ecap or --enable-icap-client"
 	define["USE_AUTH"]="--enable-auth"
 	define["USE_CACHE_DIGESTS"]="--enable-cache-digests"
+	define["USE_DELAY_POOLS"]="--enable-delay-pools"
 	define["USE_ECAP"]="--enable-ecap"
 	define["USE_ERR_LOCALES"]="--enable-auto-locale"
 	define["USE_HTCP"]="--enable-htcp"
+	define["USE_HTTP_VIOLATIONS"]="--enable-http-violations"
 	define["USE_ICMP"]="--enable-icmp"
 	define["USE_IDENT"]="--enable-ident-lookups"
 	define["USE_LOADABLE_MODULES"]="--enable-loadable-modules"
+	define["USE_OPENSSL"]="--with-openssl"
+	define["USE_QOS_TOS"]="--enable-zph-qos"
 	define["USE_SQUID_ESI"]="--enable-esi"
 	define["USE_SQUID_EUI"]="--enable-eui"
 	define["USE_SSL_CRTD"]="--enable-ssl-crtd"
-	define["USE_SSL"]="--enable-ssl"
 	define["USE_UNLINKD"]="--enable-unlinkd"
 	define["USE_WCCP"]="--enable-wccp"
 	define["USE_WCCPv2"]="--enable-wccpv2"
-	define["USE_QOS_TOS"]="--enable-zph-qos"
-	define["_SQUID_WINDOWS_"]="MS Windows"
-	define["SO_MARK&&USE_LIBCAP"]="Packet MARK (Linux)"
 }
 /^IFDEF:/ {
 	if (define[$2] != "")
@@ -94,6 +94,7 @@
 #include "comm.h"
 #include "comm/Connection.h"
 #include "comm/Loops.h"
+#include "comm/Read.h"
 #include "comm/TcpAcceptor.h"
 #include "comm/Write.h"
 #include "CommCalls.h"
@@ -135,7 +136,7 @@
 #if USE_DELAY_POOLS
 #include "ClientInfo.h"
 #endif
-#if USE_SSL
+#if USE_OPENSSL
 #include "ssl/context_storage.h"
 #include "ssl/gadgets.h"
 #include "ssl/helper.h"
@@ -191,7 +192,7 @@ CBDATA_CLASS_INIT(ClientSocketContext);
 static IOCB clientWriteComplete;
 static IOCB clientWriteBodyComplete;
 static IOACB httpAccept;
-#if USE_SSL
+#if USE_OPENSSL
 static IOACB httpsAccept;
 #endif
 static CTCB clientLifetimeTimeout;
@@ -237,8 +238,8 @@ ClientSocketContext::getClientReplyContext() const
 }
 
 /**
- * This routine should be called to grow the inbuf and then
- * call comm_read().
+ * This routine should be called to grow the in.buf and then
+ * call Comm::Read().
  */
 void
 ConnStateData::readSomeData()
@@ -248,12 +249,12 @@ ConnStateData::readSomeData()
 
     debugs(33, 4, HERE << clientConnection << ": reading request...");
 
-    if (!maybeMakeSpaceAvailable())
+    if (!in.maybeMakeSpaceAvailable())
         return;
 
     typedef CommCbMemFunT<ConnStateData, CommIoCbParams> Dialer;
     reader = JobCallback(33, 5, Dialer, this, ConnStateData::clientReadRequest);
-    comm_read(clientConnection, in.addressToReadInto(), getAvailableBufferLength(), reader);
+    Comm::Read(clientConnection, reader);
 }
 
 void
@@ -374,12 +375,12 @@ ClientSocketContext::writeControlMsg(HttpControlMsg &msg)
 
 /// called when we wrote the 1xx response
 void
-ClientSocketContext::wroteControlMsg(const Comm::ConnectionPointer &conn, char *, size_t, comm_err_t errflag, int xerrno)
+ClientSocketContext::wroteControlMsg(const Comm::ConnectionPointer &conn, char *, size_t, Comm::Flag errflag, int xerrno)
 {
-    if (errflag == COMM_ERR_CLOSING)
+    if (errflag == Comm::ERR_CLOSING)
         return;
 
-    if (errflag == COMM_OK) {
+    if (errflag == Comm::OK) {
         ScheduleCallHere(cbControlMsgSent);
         return;
     }
@@ -395,7 +396,7 @@ ClientSocketContext::wroteControlMsg(const Comm::ConnectionPointer &conn, char *
 
 /// wroteControlMsg() wrapper: ClientSocketContext is not an AsyncJob
 void
-ClientSocketContext::WroteControlMsg(const Comm::ConnectionPointer &conn, char *bufnotused, size_t size, comm_err_t errflag, int xerrno, void *data)
+ClientSocketContext::WroteControlMsg(const Comm::ConnectionPointer &conn, char *bufnotused, size_t size, Comm::Flag errflag, int xerrno, void *data)
 {
     ClientSocketContext *context = static_cast<ClientSocketContext*>(data);
     context->wroteControlMsg(conn, bufnotused, size, errflag, xerrno);
@@ -635,7 +636,7 @@ ClientHttpRequest::logRequest()
     if (getConn() != NULL && getConn()->clientConnection != NULL && getConn()->clientConnection->rfc931[0])
         al->cache.rfc931 = getConn()->clientConnection->rfc931;
 
-#if USE_SSL && 0
+#if USE_OPENSSL && 0
 
     /* This is broken. Fails if the connection has been closed. Needs
      * to snarf the ssl details some place earlier..
@@ -882,7 +883,7 @@ ConnStateData::~ConnStateData()
     if (bodyPipe != NULL)
         stopProducingFor(bodyPipe, false);
 
-#if USE_SSL
+#if USE_OPENSSL
     delete sslServerBump;
 #endif
 }
@@ -898,10 +899,8 @@ clientSetKeepaliveFlag(ClientHttpRequest * http)
 {
     HttpRequest *request = http->request;
 
-    debugs(33, 3, "clientSetKeepaliveFlag: http_ver = " <<
-           request->http_ver.major << "." << request->http_ver.minor);
-    debugs(33, 3, "clientSetKeepaliveFlag: method = " <<
-           RequestMethodStr(request->method));
+    debugs(33, 3, "http_ver = " << request->http_ver);
+    debugs(33, 3, "method = " << request->method);
 
     // TODO: move to HttpRequest::hdrCacheInit, just like HttpReply.
     request->flags.proxyKeepalive = request->persistent();
@@ -1062,7 +1061,7 @@ ClientSocketContext::sendBody(HttpReply * rep, StoreIOBuffer bodyData)
                                              CommIoCbPtrFun(clientWriteComplete, this));
         Comm::Write(clientConnection, &mb, call);
     }  else
-        writeComplete(clientConnection, NULL, 0, COMM_OK);
+        writeComplete(clientConnection, NULL, 0, Comm::OK);
 }
 
 /**
@@ -1504,7 +1503,7 @@ clientSocketRecipient(clientStreamNode * node, ClientHttpRequest * http,
     const bool mustSendLastChunk = http->request->flags.chunkedReply &&
                                    !http->request->flags.streamError && !context->startOfOutput();
     if (responseFinishedOrFailed(rep, receivedData) && !mustSendLastChunk) {
-        context->writeComplete(context->clientConnection, NULL, 0, COMM_OK);
+        context->writeComplete(context->clientConnection, NULL, 0, Comm::OK);
         PROF_stop(clientSocketRecipient);
         return;
     }
@@ -1548,7 +1547,7 @@ clientSocketDetach(clientStreamNode * node, ClientHttpRequest * http)
 }
 
 static void
-clientWriteBodyComplete(const Comm::ConnectionPointer &conn, char *buf, size_t size, comm_err_t errflag, int xerrno, void *data)
+clientWriteBodyComplete(const Comm::ConnectionPointer &conn, char *buf, size_t size, Comm::Flag errflag, int xerrno, void *data)
 {
     debugs(33,7, HERE << "clientWriteBodyComplete schedules clientWriteComplete");
     clientWriteComplete(conn, NULL, size, errflag, xerrno, data);
@@ -1561,7 +1560,7 @@ ConnStateData::readNextRequest()
 
     fd_note(clientConnection->fd, "Idle client: Waiting for next request");
     /**
-     * Set the timeout BEFORE calling clientReadRequest().
+     * Set the timeout BEFORE calling readSomeData().
      */
     typedef CommCbMemFunT<ConnStateData, CommTimeoutCbParams> TimeoutDialer;
     AsyncCall::Pointer timeoutCall = JobCallback(33, 5,
@@ -1842,7 +1841,7 @@ ClientSocketContext::socketState()
  * no more data to send.
  */
 void
-clientWriteComplete(const Comm::ConnectionPointer &conn, char *bufnotused, size_t size, comm_err_t errflag, int xerrno, void *data)
+clientWriteComplete(const Comm::ConnectionPointer &conn, char *bufnotused, size_t size, Comm::Flag errflag, int xerrno, void *data)
 {
     ClientSocketContext *context = (ClientSocketContext *)data;
     context->writeComplete(conn, bufnotused, size, errflag);
@@ -1889,7 +1888,7 @@ ConnStateData::stopSending(const char *error)
     if (!stoppedReceiving()) {
         if (const int64_t expecting = mayNeedToReadMoreBody()) {
             debugs(33, 5, HERE << "must still read " << expecting <<
-                   " request body bytes with " << in.notYetUsed << " unused");
+                   " request body bytes with " << in.buf.length() << " unused");
             return; // wait for the request receiver to finish reading
         }
     }
@@ -1898,7 +1897,7 @@ ConnStateData::stopSending(const char *error)
 }
 
 void
-ClientSocketContext::writeComplete(const Comm::ConnectionPointer &conn, char *bufnotused, size_t size, comm_err_t errflag)
+ClientSocketContext::writeComplete(const Comm::ConnectionPointer &conn, char *bufnotused, size_t size, Comm::Flag errflag)
 {
     const StoreEntry *entry = http->storeEntry();
     http->out.size += size;
@@ -1907,9 +1906,9 @@ ClientSocketContext::writeComplete(const Comm::ConnectionPointer &conn, char *bu
            (entry ? entry->objectLen() : 0));
     clientUpdateSocketStats(http->logType, size);
 
-    /* Bail out quickly on COMM_ERR_CLOSING - close handlers will tidy up */
+    /* Bail out quickly on Comm::ERR_CLOSING - close handlers will tidy up */
 
-    if (errflag == COMM_ERR_CLOSING || !Comm::IsConnOpen(conn))
+    if (errflag == Comm::ERR_CLOSING || !Comm::IsConnOpen(conn))
         return;
 
     if (errflag || clientHttpRequestStatus(conn->fd, http)) {
@@ -1956,7 +1955,7 @@ parseHttpRequestAbort(ConnStateData * csd, const char *uri)
     ClientSocketContext *context;
     StoreIOBuffer tempBuffer;
     http = new ClientHttpRequest(csd);
-    http->req_sz = csd->in.notYetUsed;
+    http->req_sz = csd->in.buf.length();
     http->uri = xstrdup(uri);
     setLogUri (http, uri);
     context = new ClientSocketContext(csd->clientConnection, http);
@@ -2379,32 +2378,26 @@ parseHttpRequest(ConnStateData *csd, HttpParser *hp, HttpRequestMethod * method_
     return result;
 }
 
-int
-ConnStateData::getAvailableBufferLength() const
-{
-    assert (in.allocatedSize > in.notYetUsed); // allocated more than used
-    const size_t result = in.allocatedSize - in.notYetUsed - 1;
-    // huge request_header_max_size may lead to more than INT_MAX unused space
-    assert (static_cast<ssize_t>(result) <= INT_MAX);
-    return result;
-}
-
 bool
-ConnStateData::maybeMakeSpaceAvailable()
+ConnStateData::In::maybeMakeSpaceAvailable()
 {
-    if (getAvailableBufferLength() < 2) {
-        size_t newSize;
-        if (in.allocatedSize >= Config.maxRequestBufferSize) {
+    if (buf.spaceSize() < 2) {
+        const SBuf::size_type haveCapacity = buf.length() + buf.spaceSize();
+        if (haveCapacity >= Config.maxRequestBufferSize) {
             debugs(33, 4, "request buffer full: client_request_buffer_max_size=" << Config.maxRequestBufferSize);
             return false;
         }
-        if ((newSize=in.allocatedSize * 2) > Config.maxRequestBufferSize) {
-            newSize=Config.maxRequestBufferSize;
+        if (haveCapacity == 0) {
+            // haveCapacity is based on the SBuf visible window of the MemBlob buffer, which may fill up.
+            // at which point bump the buffer back to default. This allocates a new MemBlob with any un-parsed bytes.
+            buf.reserveCapacity(CLIENT_REQ_BUF_SZ);
+        } else {
+            const SBuf::size_type wantCapacity = min(static_cast<SBuf::size_type>(Config.maxRequestBufferSize), haveCapacity*2);
+            buf.reserveCapacity(wantCapacity);
         }
-        in.buf = (char *)memReallocBuf(in.buf, newSize, &in.allocatedSize);
-        debugs(33, 2, "growing request buffer: notYetUsed=" << in.notYetUsed << " size=" << in.allocatedSize);
+        debugs(33, 2, "growing request buffer: available=" << buf.spaceSize() << " used=" << buf.length());
     }
-    return true;
+    return (buf.spaceSize() >= 2);
 }
 
 void
@@ -2430,31 +2423,11 @@ ConnStateData::getConcurrentRequestCount() const
     return result;
 }
 
-int
-ConnStateData::connReadWasError(comm_err_t flag, int size, int xerrno)
-{
-    if (flag != COMM_OK) {
-        debugs(33, 2, "connReadWasError: FD " << clientConnection << ": got flag " << flag);
-        return 1;
-    }
-
-    if (size < 0) {
-        if (!ignoreErrno(xerrno)) {
-            debugs(33, 2, "connReadWasError: FD " << clientConnection << ": " << xstrerr(xerrno));
-            return 1;
-        } else if (in.notYetUsed == 0) {
-            debugs(33, 2, "connReadWasError: FD " << clientConnection << ": no data to process (" << xstrerr(xerrno) << ")");
-        }
-    }
-
-    return 0;
-}
-
 int
 ConnStateData::connFinishedWithConn(int size)
 {
     if (size == 0) {
-        if (getConcurrentRequestCount() == 0 && in.notYetUsed == 0) {
+        if (getConcurrentRequestCount() == 0 && in.buf.isEmpty()) {
             /* no current or pending requests */
             debugs(33, 4, HERE << clientConnection << " closed");
             return 1;
@@ -2472,26 +2445,19 @@ ConnStateData::connFinishedWithConn(int size)
 void
 connNoteUseOfBuffer(ConnStateData* conn, size_t byteCount)
 {
-    assert(byteCount > 0 && byteCount <= conn->in.notYetUsed);
-    conn->in.notYetUsed -= byteCount;
-    debugs(33, 5, HERE << "conn->in.notYetUsed = " << conn->in.notYetUsed);
-    /*
-     * If there is still data that will be used,
-     * move it to the beginning.
-     */
-
-    if (conn->in.notYetUsed > 0)
-        memmove(conn->in.buf, conn->in.buf + byteCount, conn->in.notYetUsed);
+    assert(byteCount > 0 && byteCount <= conn->in.buf.length());
+    conn->in.buf.consume(byteCount);
+    debugs(33, 5, "conn->in.buf has " << conn->in.buf.length() << " bytes unused.");
 }
 
 /// respond with ERR_TOO_BIG if request header exceeds request_header_max_size
 void
 ConnStateData::checkHeaderLimits()
 {
-    if (in.notYetUsed < Config.maxRequestHeaderSize)
+    if (in.buf.length() < Config.maxRequestHeaderSize)
         return; // can accumulte more header data
 
-    debugs(33, 3, "Request header is too large (" << in.notYetUsed << " > " <<
+    debugs(33, 3, "Request header is too large (" << in.buf.length() << " > " <<
            Config.maxRequestHeaderSize << " bytes)");
 
     ClientSocketContext *context = parseHttpRequestAbort(this, "error:request-too-large");
@@ -2531,7 +2497,7 @@ ConnStateData::quitAfterError(HttpRequest *request)
     debugs(33,4, HERE << "Will close after error: " << clientConnection);
 }
 
-#if USE_SSL
+#if USE_OPENSSL
 bool ConnStateData::serveDelayedError(ClientSocketContext *context)
 {
     ClientHttpRequest *http = context->http;
@@ -2615,7 +2581,7 @@ bool ConnStateData::serveDelayedError(ClientSocketContext *context)
 
     return false;
 }
-#endif // USE_SSL
+#endif // USE_OPENSSL
 
 static void
 clientProcessRequest(ConnStateData *conn, HttpParser *hp, ClientSocketContext *context, const HttpRequestMethod& method, Http::ProtocolVersion http_ver)
@@ -2642,15 +2608,15 @@ clientProcessRequest(ConnStateData *conn, HttpParser *hp, ClientSocketContext *c
         assert (repContext);
         switch (hp->request_parse_status) {
         case Http::scHeaderTooLarge:
-            repContext->setReplyToError(ERR_TOO_BIG, Http::scBadRequest, method, http->uri, conn->clientConnection->remote, NULL, conn->in.buf, NULL);
+            repContext->setReplyToError(ERR_TOO_BIG, Http::scBadRequest, method, http->uri, conn->clientConnection->remote, NULL, conn->in.buf.c_str(), NULL);
             break;
         case Http::scMethodNotAllowed:
             repContext->setReplyToError(ERR_UNSUP_REQ, Http::scMethodNotAllowed, method, http->uri,
-                                        conn->clientConnection->remote, NULL, conn->in.buf, NULL);
+                                        conn->clientConnection->remote, NULL, conn->in.buf.c_str(), NULL);
             break;
         default:
             repContext->setReplyToError(ERR_INVALID_REQ, hp->request_parse_status, method, http->uri,
-                                        conn->clientConnection->remote, NULL, conn->in.buf, NULL);
+                                        conn->clientConnection->remote, NULL, conn->in.buf.c_str(), NULL);
         }
         assert(context->http->out.offset == 0);
         context->pullData();
@@ -2741,20 +2707,23 @@ clientProcessRequest(ConnStateData *conn, HttpParser *hp, ClientSocketContext *c
     }
 
     if (internalCheck(request->urlpath.termedBuf())) {
-        if (internalHostnameIs(request->GetHost()) &&
-                request->port == getMyPort()) {
+        if (internalHostnameIs(request->GetHost()) && request->port == getMyPort()) {
+            debugs(33, 2, "internal URL found: " << request->url.getScheme() << "://" << request->GetHost() <<
+                   ':' << request->port);
             http->flags.internal = true;
         } else if (Config.onoff.global_internal_static && internalStaticCheck(request->urlpath.termedBuf())) {
+            debugs(33, 2, "internal URL found: " << request->url.getScheme() << "://" << request->GetHost() <<
+                   ':' << request->port << " (global_internal_static on)");
             request->SetHost(internalHostname());
             request->port = getMyPort();
             http->flags.internal = true;
-        }
+        } else
+            debugs(33, 2, "internal URL found: " << request->url.getScheme() << "://" << request->GetHost() <<
+                   ':' << request->port << " (not this proxy)");
     }
 
-    if (http->flags.internal) {
-        request->protocol = AnyP::PROTO_HTTP;
+    if (http->flags.internal)
         request->login[0] = '\0';
-    }
 
     request->flags.internal = http->flags.internal;
     setLogUri (http, urlCanonicalClean(request.getRaw()));
@@ -2831,9 +2800,13 @@ clientProcessRequest(ConnStateData *conn, HttpParser *hp, ClientSocketContext *c
     if (http->request->method == Http::METHOD_CONNECT) {
         context->mayUseConnection(true);
         conn->flags.readMore = false;
+
+        // consume header early so that tunnel gets just the body
+        connNoteUseOfBuffer(conn, http->req_sz);
+        notedUseOfBuffer = true;
     }
 
-#if USE_SSL
+#if USE_OPENSSL
     if (conn->switchedToHttps() && conn->serveDelayedError(context))
         goto finish;
 #endif
@@ -2856,7 +2829,7 @@ clientProcessRequest(ConnStateData *conn, HttpParser *hp, ClientSocketContext *c
             assert (repContext);
             conn->quitAfterError(request.getRaw());
             repContext->setReplyToError(ERR_TOO_BIG,
-                                        Http::scRequestEntityTooLarge, Http::METHOD_NONE, NULL,
+                                        Http::scPayloadTooLarge, Http::METHOD_NONE, NULL,
                                         conn->clientConnection->remote, http->request, NULL, NULL);
             assert(context->http->out.offset == 0);
             context->pullData();
@@ -2900,9 +2873,9 @@ clientProcessRequest(ConnStateData *conn, HttpParser *hp, ClientSocketContext *c
 static void
 connStripBufferWhitespace (ConnStateData * conn)
 {
-    while (conn->in.notYetUsed > 0 && xisspace(conn->in.buf[0])) {
-        memmove(conn->in.buf, conn->in.buf + 1, conn->in.notYetUsed - 1);
-        -- conn->in.notYetUsed;
+    // XXX: kill this whole function.
+    while (!conn->in.buf.isEmpty() && xisspace(conn->in.buf.at(0))) {
+        conn->in.buf.consume(1);
     }
 }
 
@@ -2945,24 +2918,20 @@ ConnStateData::clientParseRequests()
 
     // Loop while we have read bytes that are not needed for producing the body
     // On errors, bodyPipe may become nil, but readMore will be cleared
-    while (in.notYetUsed > 0 && !bodyPipe && flags.readMore) {
+    while (!in.buf.isEmpty() && !bodyPipe && flags.readMore) {
         connStripBufferWhitespace(this);
 
         /* Don't try to parse if the buffer is empty */
-        if (in.notYetUsed == 0)
+        if (in.buf.isEmpty())
             break;
 
         /* Limit the number of concurrent requests */
         if (concurrentRequestQueueFilled())
             break;
 
-        /* Should not be needed anymore */
-        /* Terminate the string */
-        in.buf[in.notYetUsed] = '\0';
-
         /* Begin the parsing */
         PROF_start(parseHttpRequest);
-        HttpParserInit(&parser_, in.buf, in.notYetUsed);
+        HttpParserInit(&parser_, in.buf.c_str(), in.buf.length());
 
         /* Process request */
         Http::ProtocolVersion http_ver;
@@ -3002,62 +2971,71 @@ ConnStateData::clientParseRequests()
 void
 ConnStateData::clientReadRequest(const CommIoCbParams &io)
 {
-    debugs(33,5,HERE << io.conn << " size " << io.size);
+    debugs(33,5, io.conn);
     Must(reading());
     reader = NULL;
 
-    /* Bail out quickly on COMM_ERR_CLOSING - close handlers will tidy up */
-
-    if (io.flag == COMM_ERR_CLOSING) {
-        debugs(33,5, HERE << io.conn << " closing Bailout.");
+    /* Bail out quickly on Comm::ERR_CLOSING - close handlers will tidy up */
+    if (io.flag == Comm::ERR_CLOSING) {
+        debugs(33,5, io.conn << " closing Bailout.");
         return;
     }
 
     assert(Comm::IsConnOpen(clientConnection));
     assert(io.conn->fd == clientConnection->fd);
 
     /*
-     * Don't reset the timeout value here.  The timeout value will be
-     * set to Config.Timeout.request by httpAccept() and
-     * clientWriteComplete(), and should apply to the request as a
-     * whole, not individual read() calls.  Plus, it breaks our
-     * lame half-close detection
+     * Don't reset the timeout value here. The value should be
+     * counting Config.Timeout.request and applies to the request
+     * as a whole, not individual read() calls.
+     * Plus, it breaks our lame *HalfClosed() detection
      */
-    if (connReadWasError(io.flag, io.size, io.xerrno)) {
-        notifyAllContexts(io.xerrno);
-        io.conn->close();
+
+    CommIoCbParams rd(this); // will be expanded with ReadNow results
+    rd.conn = io.conn;
+    switch (Comm::ReadNow(rd, in.buf)) {
+    case Comm::INPROGRESS:
+        if (in.buf.isEmpty())
+            debugs(33, 2, io.conn << ": no data to process, " << xstrerr(rd.xerrno));
+        readSomeData();
         return;
-    }
 
-    if (io.flag == COMM_OK) {
-        if (io.size > 0) {
-            kb_incr(&(statCounter.client_http.kbytes_in), io.size);
+    case Comm::OK:
+        kb_incr(&(statCounter.client_http.kbytes_in), rd.size);
+        // may comm_close or setReplyToError
+        if (!handleReadData())
+            return;
 
-            // may comm_close or setReplyToError
-            if (!handleReadData(io.buf, io.size))
-                return;
+        /* Continue to process previously read data */
+        break;
 
-        } else if (io.size == 0) {
-            debugs(33, 5, HERE << io.conn << " closed?");
+    case Comm::ENDFILE: // close detected by 0-byte read
+        debugs(33, 5, io.conn << " closed?");
 
-            if (connFinishedWithConn(io.size)) {
-                clientConnection->close();
-                return;
-            }
+        if (connFinishedWithConn(rd.size)) {
+            clientConnection->close();
+            return;
+        }
 
-            /* It might be half-closed, we can't tell */
-            fd_table[io.conn->fd].flags.socket_eof = true;
+        /* It might be half-closed, we can't tell */
+        fd_table[io.conn->fd].flags.socket_eof = true;
+        commMarkHalfClosed(io.conn->fd);
+        fd_note(io.conn->fd, "half-closed");
 
-            commMarkHalfClosed(io.conn->fd);
+        /* There is one more close check at the end, to detect aborted
+         * (partial) requests. At this point we can't tell if the request
+         * is partial.
+         */
 
-            fd_note(io.conn->fd, "half-closed");
+        /* Continue to process previously read data */
+        break;
 
-            /* There is one more close check at the end, to detect aborted
-             * (partial) requests. At this point we can't tell if the request
-             * is partial.
-             */
-            /* Continue to process previously read data */
-        }
+        // case Comm::COMM_ERROR:
+    default: // no other flags should ever occur
+        debugs(33, 2, io.conn << ": got flag " << rd.flag << "; " << xstrerr(rd.xerrno));
+        notifyAllContexts(rd.xerrno);
+        io.conn->close();
+        return;
     }
 
     /* Process next request */
@@ -3095,17 +3073,8 @@ ConnStateData::clientReadRequest(const CommIoCbParams &io)
  * \retval true  we did not call comm_close or setReplyToError
  */
 bool
-ConnStateData::handleReadData(char *buf, size_t size)
+ConnStateData::handleReadData()
 {
-    char *current_buf = in.addressToReadInto();
-
-    if (buf != current_buf)
-        memmove(current_buf, buf, size);
-
-    in.notYetUsed += size;
-
-    in.buf[in.notYetUsed] = '\0'; /* Terminate the string */
-
     // if we are reading a body, stuff data into the body pipe
     if (bodyPipe != NULL)
         return handleRequestBodyData();
@@ -3133,7 +3102,7 @@ ConnStateData::handleRequestBodyData()
         }
     } else { // identity encoding
         debugs(33,5, HERE << "handling plain request body for " << clientConnection);
-        putSize = bodyPipe->putMoreData(in.buf, in.notYetUsed);
+        putSize = bodyPipe->putMoreData(in.buf.c_str(), in.buf.length());
         if (!bodyPipe->mayNeedMoreData()) {
             // BodyPipe will clear us automagically when we produced everything
             bodyPipe = NULL;
@@ -3163,17 +3132,17 @@ ConnStateData::handleRequestBodyData()
 err_type
 ConnStateData::handleChunkedRequestBody(size_t &putSize)
 {
-    debugs(33,7, HERE << "chunked from " << clientConnection << ": " << in.notYetUsed);
+    debugs(33, 7, "chunked from " << clientConnection << ": " << in.buf.length());
 
     try { // the parser will throw on errors
 
-        if (!in.notYetUsed) // nothing to do (MemBuf::init requires this check)
+        if (in.buf.isEmpty()) // nothing to do
             return ERR_NONE;
 
         MemBuf raw; // ChunkedCodingParser only works with MemBufs
         // add one because MemBuf will assert if it cannot 0-terminate
-        raw.init(in.notYetUsed, in.notYetUsed+1);
-        raw.append(in.buf, in.notYetUsed);
+        raw.init(in.buf.length(), in.buf.length()+1);
+        raw.append(in.buf.c_str(), in.buf.length());
 
         const mb_size_t wasContentSize = raw.contentSize();
         BodyPipeCheckout bpc(*bodyPipe);
@@ -3221,7 +3190,7 @@ ConnStateData::abortChunkedRequestBody(const err_type error)
         clientReplyContext *repContext = dynamic_cast<clientReplyContext*>(node->data.getRaw());
         assert(repContext);
         const Http::StatusCode scode = (error == ERR_TOO_BIG) ?
-                                       Http::scRequestEntityTooLarge : HTTP_BAD_REQUEST;
+                                       Http::scPayloadTooLarge : HTTP_BAD_REQUEST;
         repContext->setReplyToError(error, scode,
                                     repContext->http->request->method,
                                     repContext->http->uri,
@@ -3292,7 +3261,7 @@ clientLifetimeTimeout(const CommTimeoutCbParams &io)
 
 ConnStateData::ConnStateData(const MasterXaction::Pointer &xact) :
         AsyncJob("ConnStateData"),
-#if USE_SSL
+#if USE_OPENSSL
         sslBumpMode(Ssl::bumpEnd),
         switchedToHttps_(false),
         sslServerBump(NULL),
@@ -3313,7 +3282,8 @@ ConnStateData::ConnStateData(const MasterXaction::Pointer &xact) :
     log_addr = xact->tcpClient->remote;
     log_addr.applyMask(Config.Addrs.client_netmask);
 
-    in.buf = (char *)memAllocBuf(CLIENT_REQ_BUF_SZ, &in.allocatedSize);
+    // ensure a buffer is present for this connection
+    in.maybeMakeSpaceAvailable();
 
     if (port->disable_pmtu_discovery != DISABLE_PMTU_OFF &&
             (transparent() || port->disable_pmtu_discovery == DISABLE_PMTU_ALWAYS)) {
@@ -3366,7 +3336,7 @@ httpAccept(const CommAcceptCbParams &params)
         return;
     }
 
-    if (params.flag != COMM_OK) {
+    if (params.flag != Comm::OK) {
         // Its possible the call was still queued when the client disconnected
         debugs(33, 2, "httpAccept: " << s->listenConn << ": accept failure: " << xstrerr(params.xerrno));
         return;
@@ -3436,7 +3406,7 @@ httpAccept(const CommAcceptCbParams &params)
 #endif
 }
 
-#if USE_SSL
+#if USE_OPENSSL
 
 /** Create SSL connection structure and update fd_table */
 static SSL *
@@ -3655,10 +3625,12 @@ httpsSslBumpAccessCheckDone(allow_t answer, void *data)
 
         // fake a CONNECT request to force connState to tunnel
         static char ip[MAX_IPSTRLEN];
-        static char reqStr[MAX_IPSTRLEN + 80];
         connState->clientConnection->local.toUrl(ip, sizeof(ip));
-        snprintf(reqStr, sizeof(reqStr), "CONNECT %s HTTP/1.1\r\nHost: %s\r\n\r\n", ip, ip);
-        bool ret = connState->handleReadData(reqStr, strlen(reqStr));
+        // Pre-pend this fake request to the TLS bits already in the buffer
+        SBuf retStr;
+        retStr.append("CONNECT ").append(ip).append(" HTTP/1.1\r\nHost: ").append(ip).append("\r\n\r\n");
+        connState->in.buf = retStr.append(connState->in.buf);
+        bool ret = connState->handleReadData();
         if (ret)
             ret = connState->clientParseRequests();
 
@@ -3682,7 +3654,7 @@ httpsAccept(const CommAcceptCbParams &params)
         return;
     }
 
-    if (params.flag != COMM_OK) {
+    if (params.flag != Comm::OK) {
         // Its possible the call was still queued when the client disconnected
         debugs(33, 2, "httpsAccept: " << s->listenConn << ": accept failure: " << xstrerr(params.xerrno));
         return;
@@ -3951,7 +3923,13 @@ ConnStateData::getSslContextDone(SSL_CTX * sslContext, bool isNew)
     if (!httpsCreate(clientConnection, sslContext))
         return;
 
-    // commSetConnTimeout() was called for this request before we switched.
+    // bumped intercepted conns should already have Config.Timeout.request set
+    // but forwarded connections may only have Config.Timeout.lifetime. [Re]set
+    // to make sure the connection does not get stuck on non-SSL clients.
+    typedef CommCbMemFunT<ConnStateData, CommTimeoutCbParams> TimeoutDialer;
+    AsyncCall::Pointer timeoutCall = JobCallback(33, 5, TimeoutDialer,
+                                     this, ConnStateData::requestTimeout);
+    commSetConnTimeout(clientConnection, Config.Timeout.request, timeoutCall);
 
     // Disable the client read handler until CachePeer selection is complete
     Comm::SetSelect(clientConnection->fd, COMM_SELECT_READ, NULL, NULL, 0);
@@ -4026,7 +4004,7 @@ ConnStateData::httpsPeeked(Comm::ConnectionPointer serverConnection)
     getSslContextStart();
 }
 
-#endif /* USE_SSL */
+#endif /* USE_OPENSSL */
 
 /// check FD after clientHttp[s]ConnectionOpened, adjust HttpSockets as needed
 static bool
@@ -4069,7 +4047,7 @@ clientHttpConnectionsOpen(void)
             continue;
         }
 
-#if USE_SSL
+#if USE_OPENSSL
         if (s->flags.tunnelSslBumping && !Config.accessList.ssl_bump) {
             debugs(33, DBG_IMPORTANT, "WARNING: No ssl_bump configured. Disabling ssl-bump on " << AnyP::UriScheme(s->transport.protocol) << "_port " << s->s);
             s->flags.tunnelSslBumping = false;
@@ -4107,7 +4085,7 @@ clientHttpConnectionsOpen(void)
     }
 }
 
-#if USE_SSL
+#if USE_OPENSSL
 static void
 clientHttpsConnectionsOpen(void)
 {
@@ -4191,7 +4169,7 @@ void
 clientOpenListenSockets(void)
 {
     clientHttpConnectionsOpen();
-#if USE_SSL
+#if USE_OPENSSL
     clientHttpsConnectionsOpen();
 #endif
 
@@ -4210,7 +4188,7 @@ clientHttpConnectionsClose(void)
         }
     }
 
-#if USE_SSL
+#if USE_OPENSSL
     for (AnyP::PortCfg *s = Config.Sockaddr.https; s; s = s->next) {
         if (s->listenConn != NULL) {
             debugs(1, DBG_IMPORTANT, "Closing HTTPS port " << s->listenConn->local);
@@ -4324,7 +4302,7 @@ void
 ConnStateData::stopReading()
 {
     if (reading()) {
-        comm_read_cancel(clientConnection->fd, reader);
+        Comm::ReadCancel(clientConnection->fd, reader);
         reader = NULL;
     }
 }
@@ -4350,7 +4328,7 @@ ConnStateData::mayNeedToReadMoreBody() const
         return -1; // probably need to read more, but we cannot be sure
 
     const int64_t needToProduce = bodyPipe->unproducedSize();
-    const int64_t haveAvailable = static_cast<int64_t>(in.notYetUsed);
+    const int64_t haveAvailable = static_cast<int64_t>(in.buf.length());
 
     if (needToProduce <= haveAvailable)
         return 0; // we have read what we need (but are waiting for pipe space)
@@ -4420,20 +4398,13 @@ ConnStateData::finishDechunkingRequest(bool withSuccess)
     in.bodyParser = NULL;
 }
 
-char *
-ConnStateData::In::addressToReadInto() const
-{
-    return buf + notYetUsed;
-}
-
-ConnStateData::In::In() : bodyParser(NULL),
-        buf (NULL), notYetUsed (0), allocatedSize (0)
+ConnStateData::In::In() :
+        bodyParser(NULL),
+        buf()
 {}
 
 ConnStateData::In::~In()
 {
-    if (allocatedSize)
-        memFreeBuf(allocatedSize, buf);
     delete bodyParser; // TODO: pool
 }
 
@@ -4531,15 +4502,14 @@ ConnStateData::startPinnedConnectionMonitoring()
     typedef CommCbMemFunT<ConnStateData, CommIoCbParams> Dialer;
     pinning.readHandler = JobCallback(33, 3,
                                       Dialer, this, ConnStateData::clientPinnedConnectionRead);
-    static char unusedBuf[8];
-    comm_read(pinning.serverConnection, unusedBuf, sizeof(unusedBuf), pinning.readHandler);
+    Comm::Read(pinning.serverConnection, pinning.readHandler);
 }
 
 void
 ConnStateData::stopPinnedConnectionMonitoring()
 {
     if (pinning.readHandler != NULL) {
-        comm_read_cancel(pinning.serverConnection->fd, pinning.readHandler);
+        Comm::ReadCancel(pinning.serverConnection->fd, pinning.readHandler);
         pinning.readHandler = NULL;
     }
 }
@@ -4551,7 +4521,7 @@ ConnStateData::clientPinnedConnectionRead(const CommIoCbParams &io)
 {
     pinning.readHandler = NULL; // Comm unregisters handlers before calling
 
-    if (io.flag == COMM_ERR_CLOSING)
+    if (io.flag == Comm::ERR_CLOSING)
         return; // close handler will clean up
 
     // We could use getConcurrentRequestCount(), but this may be faster.
@@ -36,10 +36,11 @@
 #include "comm.h"
 #include "HttpControlMsg.h"
 #include "HttpParser.h"
+#include "SBuf.h"
 #if USE_AUTH
 #include "auth/UserRequest.h"
 #endif
-#if USE_SSL
+#if USE_OPENSSL
 #include "ssl/support.h"
 #endif
 
@@ -86,7 +87,7 @@ class ClientSocketContext : public RefCountable
     ClientSocketContext(const Comm::ConnectionPointer &aConn, ClientHttpRequest *aReq);
     ~ClientSocketContext();
     bool startOfOutput() const;
-    void writeComplete(const Comm::ConnectionPointer &conn, char *bufnotused, size_t size, comm_err_t errflag);
+    void writeComplete(const Comm::ConnectionPointer &conn, char *bufnotused, size_t size, Comm::Flag errflag);
     void keepaliveNextRequest();
 
     Comm::ConnectionPointer clientConnection; /// details about the client connection socket.
@@ -142,7 +143,7 @@ class ClientSocketContext : public RefCountable
 
 protected:
     static IOCB WroteControlMsg;
-    void wroteControlMsg(const Comm::ConnectionPointer &conn, char *bufnotused, size_t size, comm_err_t errflag, int xerrno);
+    void wroteControlMsg(const Comm::ConnectionPointer &conn, char *bufnotused, size_t size, Comm::Flag errflag, int xerrno);
 
 private:
     void prepareReply(HttpReply * rep);
@@ -161,7 +162,7 @@ class ClientSocketContext : public RefCountable
 };
 
 class ConnectionDetail;
-#if USE_SSL
+#if USE_OPENSSL
 namespace Ssl
 {
 class ServerBump;
@@ -189,14 +190,12 @@ class ConnStateData : public BodyProducer, public HttpControlMsgSink
     ~ConnStateData();
 
     void readSomeData();
-    int getAvailableBufferLength() const;
     bool areAllContextsForThisConnection() const;
     void freeAllContexts();
     void notifyAllContexts(const int xerrno); ///< tell everybody about the err
     /// Traffic parsing
     bool clientParseRequests();
     void readNextRequest();
-    bool maybeMakeSpaceAvailable();
     ClientSocketContext::Pointer getCurrentContext() const;
     void addContextToQueue(ClientSocketContext * context);
     int getConcurrentRequestCount() const;
@@ -212,12 +211,10 @@ class ConnStateData : public BodyProducer, public HttpControlMsgSink
     struct In {
         In();
         ~In();
-        char *addressToReadInto() const;
+        bool maybeMakeSpaceAvailable();
 
         ChunkedCodingParser *bodyParser; ///< parses chunked request body
-        char *buf;
-        size_t notYetUsed;
-        size_t allocatedSize;
+        SBuf buf;
     } in;
 
     /** number of body bytes we need to comm_read for the "current" request
@@ -293,7 +290,7 @@ class ConnStateData : public BodyProducer, public HttpControlMsgSink
     virtual void noteMoreBodySpaceAvailable(BodyPipe::Pointer);
     virtual void noteBodyConsumerAborted(BodyPipe::Pointer);
 
-    bool handleReadData(char *buf, size_t size);
+    bool handleReadData();
     bool handleRequestBodyData();
 
     /**
@@ -337,7 +334,7 @@ class ConnStateData : public BodyProducer, public HttpControlMsgSink
     /// The caller assumes responsibility for connection closure detection.
     void stopPinnedConnectionMonitoring();
 
-#if USE_SSL
+#if USE_OPENSSL
     /// called by FwdState when it is done bumping the server
     void httpsPeeked(Comm::ConnectionPointer serverConnection);
 
@@ -388,7 +385,6 @@ class ConnStateData : public BodyProducer, public HttpControlMsgSink
     void clientPinnedConnectionRead(const CommIoCbParams &io);
 
 private:
-    int connReadWasError(comm_err_t flag, int size, int xerrno);
     int connFinishedWithConn(int size);
     void clientAfterReadingRequests();
     bool concurrentRequestQueueFilled() const;
@@ -402,7 +398,7 @@ class ConnStateData : public BodyProducer, public HttpControlMsgSink
 
     // XXX: CBDATA plays with public/private and leaves the following 'private' fields all public... :(
 
-#if USE_SSL
+#if USE_OPENSSL
     bool switchedToHttps_;
     /// The SSL server host name appears in CONNECT request or the server ip address for the intercepted requests
     String sslConnectHostOrIp; ///< The SSL server host name as passed in the CONNECT request
@@ -583,7 +583,7 @@ clientReplyContext::cacheHit(StoreIOBuffer result)
              */
             http->logType = LOG_TCP_CLIENT_REFRESH_MISS;
             processMiss();
-        } else if (r->protocol == AnyP::PROTO_HTTP) {
+        } else if (r->url.getScheme() == AnyP::PROTO_HTTP) {
             debugs(88, 3, "validate HIT object? YES.");
             /*
              * Object needs to be revalidated
@@ -631,7 +631,7 @@ clientReplyContext::processMiss()
     char *url = http->uri;
     HttpRequest *r = http->request;
     ErrorState *err = NULL;
-    debugs(88, 4, "clientProcessMiss: '" << RequestMethodStr(r->method) << " " << url << "'");
+    debugs(88, 4, r->method << ' ' << url);
 
     /**
      * We might have a left-over StoreEntry from a failed cache hit
@@ -687,10 +687,6 @@ clientReplyContext::processMiss()
             return;
         }
 
-        /** Check for internal requests. Update Protocol info if so. */
-        if (http->flags.internal)
-            r->protocol = AnyP::PROTO_INTERNAL;
-
         assert(r->clientConnectionManager == http->getConn());
 
         /** Start forwarding to get the new object from network */
@@ -708,10 +704,9 @@ clientReplyContext::processMiss()
 void
 clientReplyContext::processOnlyIfCachedMiss()
 {
-    debugs(88, 4, "clientProcessOnlyIfCachedMiss: '" <<
-           RequestMethodStr(http->request->method) << " " << http->uri << "'");
-    http->al->http.code = Http::scGateway_Timeout;
-    ErrorState *err = clientBuildError(ERR_ONLY_IF_CACHED_MISS, Http::scGateway_Timeout, NULL,
+    debugs(88, 4, http->request->method << ' ' << http->uri);
+    http->al->http.code = Http::scGatewayTimeout;
+    ErrorState *err = clientBuildError(ERR_ONLY_IF_CACHED_MISS, Http::scGatewayTimeout, NULL,
                                        http->getConn()->clientConnection->remote, http->request);
     removeClientStoreReference(&sc, http);
     startError(err);
@@ -835,7 +830,7 @@ purgeEntriesByUrl(HttpRequest * req, const char *url)
     for (HttpRequestMethod m(Http::METHOD_NONE); m != Http::METHOD_ENUM_END; ++m) {
         if (m.respMaybeCacheable()) {
             if (StoreEntry *entry = storeGetPublic(url, m)) {
-                debugs(88, 5, "purging " << *entry << ' ' << RequestMethodStr(m) << ' ' << url);
+                debugs(88, 5, "purging " << *entry << ' ' << m << ' ' << url);
 #if USE_HTCP
                 neighborsHtcpClear(entry, url, req, m, HTCP_CLR_INVALIDATION);
                 if (m == Http::METHOD_GET || m == Http::METHOD_HEAD) {
@@ -1352,7 +1347,7 @@ clientReplyContext::buildReplyHeader()
             if (http->storeEntry()->timestamp <= squid_curtime) {
                 // put X-Cache-Age: instead of Age:
                 char age[64];
-                snprintf(age, sizeof(age), "%ld", (long int) squid_curtime - http->storeEntry()->timestamp);
+                snprintf(age, sizeof(age), "%" PRId64, static_cast<int64_t>(squid_curtime - http->storeEntry()->timestamp));
                 hdr->putExt("X-Cache-Age", age);
             }
         } else if (http->storeEntry()->timestamp <= squid_curtime) {
@@ -1995,9 +1990,9 @@ clientReplyContext::ProcessReplyAccessResult(allow_t rv, void *voidMe)
 void
 clientReplyContext::processReplyAccessResult(const allow_t &accessAllowed)
 {
-    debugs(88, 2, "The reply for " << RequestMethodStr(http->request->method)
-           << " " << http->uri << " is " << accessAllowed << ", because it matched '"
-           << (AclMatchedName ? AclMatchedName : "NO ACL's") << "'" );
+    debugs(88, 2, "The reply for " << http->request->method
+           << ' ' << http->uri << " is " << accessAllowed << ", because it matched "
+           << (AclMatchedName ? AclMatchedName : "NO ACL's"));
 
     if (accessAllowed != ACCESS_ALLOWED) {
         ErrorState *err;
@@ -88,7 +88,7 @@
 #include "adaptation/icap/History.h"
 #endif
 #endif
-#if USE_SSL
+#if USE_OPENSSL
 #include "ssl/ServerBump.h"
 #include "ssl/support.h"
 #endif
@@ -110,7 +110,7 @@ CBDATA_CLASS_INIT(ClientRequestContext);
 /* Local functions */
 /* other */
 static void clientAccessCheckDoneWrapper(allow_t, void *);
-#if USE_SSL
+#if USE_OPENSSL
 static void sslBumpAccessCheckDoneWrapper(allow_t, void *);
 #endif
 static int clientHierarchical(ClientHttpRequest * http);
@@ -146,7 +146,7 @@ ClientRequestContext::ClientRequestContext(ClientHttpRequest *anHttp) : http(cbd
     store_id_fail_count = 0;
     no_cache_done = false;
     interpreted_req_hdrs = false;
-#if USE_SSL
+#if USE_OPENSSL
     sslBumpCheckDone = false;
 #endif
     debugs(85,3, HERE << this << " ClientRequestContext constructed");
@@ -167,7 +167,7 @@ ClientHttpRequest::ClientHttpRequest(ConnStateData * aConn) :
     al->cache.port =  cbdataReference(aConn->port);
     al->cache.caddr = aConn->log_addr;
 
-#if USE_SSL
+#if USE_OPENSSL
     if (aConn->clientConnection != NULL && aConn->clientConnection->isOpen()) {
         if (SSL *ssl = fd_table[aConn->clientConnection->fd].ssl)
             al->cache.sslClientCert.reset(SSL_get_peer_certificate(ssl));
@@ -177,7 +177,7 @@ ClientHttpRequest::ClientHttpRequest(ConnStateData * aConn) :
 #if USE_ADAPTATION
     request_satisfaction_mode = false;
 #endif
-#if USE_SSL
+#if USE_OPENSSL
     sslBumpNeed_ = Ssl::bumpEnd;
 #endif
 }
@@ -678,10 +678,10 @@ ClientRequestContext::hostHeaderVerify()
         // Verify forward-proxy requested URL domain matches the Host: header
         debugs(85, 3, HERE << "FAIL on validate URL port " << http->request->port << " matches Host: port " << portStr);
         hostHeaderVerifyFailed("URL port", portStr);
-    } else if (!portStr && http->request->method != Http::METHOD_CONNECT && http->request->port != urlDefaultPort(http->request->protocol)) {
+    } else if (!portStr && http->request->method != Http::METHOD_CONNECT && http->request->port != urlDefaultPort(http->request->url.getScheme())) {
         // Verify forward-proxy requested URL domain matches the Host: header
         // Special case: we don't have a default-port to check for CONNECT. Assume URL is correct.
-        debugs(85, 3, HERE << "FAIL on validate URL port " << http->request->port << " matches Host: default port " << urlDefaultPort(http->request->protocol));
+        debugs(85, 3, "FAIL on validate URL port " << http->request->port << " matches Host: default port " << urlDefaultPort(http->request->url.getScheme()));
         hostHeaderVerifyFailed("URL port", "default port");
     } else {
         // Okay no problem.
@@ -758,8 +758,7 @@ ClientRequestContext::clientAccessCheckDone(const allow_t &answer)
     acl_checklist = NULL;
     err_type page_id;
     Http::StatusCode status;
-    debugs(85, 2, "The request " <<
-           RequestMethodStr(http->request->method) << " " <<
+    debugs(85, 2, "The request " << http->request->method << ' ' <<
            http->uri << " is " << answer <<
            "; last ACL checked: " << (AclMatchedName ? AclMatchedName : "[none]"));
 
@@ -855,7 +854,7 @@ ClientHttpRequest::noteAdaptationAclCheckDone(Adaptation::ServiceGroupPointer g)
     if (ih != NULL) {
         if (getConn() != NULL && getConn()->clientConnection != NULL) {
             ih->rfc931 = getConn()->clientConnection->rfc931;
-#if USE_SSL
+#if USE_OPENSSL
             if (getConn()->clientConnection->isOpen()) {
                 ih->ssluser = sslGetUserEmail(fd_table[getConn()->clientConnection->fd].ssl);
             }
@@ -984,13 +983,13 @@ clientHierarchical(ClientHttpRequest * http)
     if (request->flags.loopDetected)
         return 0;
 
-    if (request->protocol == AnyP::PROTO_HTTP)
+    if (request->url.getScheme() == AnyP::PROTO_HTTP)
         return method.respMaybeCacheable();
 
-    if (request->protocol == AnyP::PROTO_GOPHER)
+    if (request->url.getScheme() == AnyP::PROTO_GOPHER)
         return gopherCachable(request);
 
-    if (request->protocol == AnyP::PROTO_CACHE_OBJECT)
+    if (request->url.getScheme() == AnyP::PROTO_CACHE_OBJECT)
         return 0;
 
     return 1;
@@ -1279,17 +1278,17 @@ ClientRequestContext::clientRedirectDone(const HelperReply &reply)
 
             // TODO: change default redirect status for appropriate requests
             // Squid defaults to 302 status for now for better compatibility with old clients.
-            // HTTP/1.0 client should get 302 (Http::scMovedTemporarily)
+            // HTTP/1.0 client should get 302 (Http::scFound)
             // HTTP/1.1 client contacting reverse-proxy should get 307 (Http::scTemporaryRedirect)
             // HTTP/1.1 client being diverted by forward-proxy should get 303 (Http::scSeeOther)
-            Http::StatusCode status = Http::scMovedTemporarily;
+            Http::StatusCode status = Http::scFound;
             if (statusNote != NULL) {
                 const char * result = statusNote;
                 status = static_cast<Http::StatusCode>(atoi(result));
             }
 
             if (status == Http::scMovedPermanently
-                    || status == Http::scMovedTemporarily
+                    || status == Http::scFound
                     || status == Http::scSeeOther
                     || status == Http::scPermanentRedirect
                     || status == Http::scTemporaryRedirect) {
@@ -1438,7 +1437,7 @@ ClientRequestContext::checkNoCacheDone(const allow_t &answer)
     http->doCallouts();
 }
 
-#if USE_SSL
+#if USE_OPENSSL
 bool
 ClientRequestContext::sslBumpAccessCheck()
 {
@@ -1516,16 +1515,15 @@ ClientRequestContext::sslBumpAccessCheckDone(const allow_t &answer)
 void
 ClientHttpRequest::processRequest()
 {
-    debugs(85, 4, "clientProcessRequest: " << RequestMethodStr(request->method) << " '" << uri << "'");
+    debugs(85, 4, request->method << ' ' << uri);
 
     if (request->method == Http::METHOD_CONNECT && !redirect.status) {
-#if USE_SSL
+#if USE_OPENSSL
         if (sslBumpNeeded()) {
             sslBumpStart();
             return;
         }
 #endif
-        logType = LOG_TCP_MISS;
         getConn()->stopReading(); // tunnels read for themselves
         tunnelStart(this, &out.size, &al->http.code, al);
         return;
@@ -1549,7 +1547,7 @@ ClientHttpRequest::httpStart()
     PROF_stop(httpStart);
 }
 
-#if USE_SSL
+#if USE_OPENSSL
 
 void
 ClientHttpRequest::sslBumpNeed(Ssl::BumpMode mode)
@@ -1560,7 +1558,7 @@ ClientHttpRequest::sslBumpNeed(Ssl::BumpMode mode)
 
 // called when comm_write has completed
 static void
-SslBumpEstablish(const Comm::ConnectionPointer &, char *, size_t, comm_err_t errflag, int, void *data)
+SslBumpEstablish(const Comm::ConnectionPointer &, char *, size_t, Comm::Flag errflag, int, void *data)
 {
     ClientHttpRequest *r = static_cast<ClientHttpRequest*>(data);
     debugs(85, 5, HERE << "responded to CONNECT: " << r << " ? " << errflag);
@@ -1570,10 +1568,10 @@ SslBumpEstablish(const Comm::ConnectionPointer &, char *, size_t, comm_err_t err
 }
 
 void
-ClientHttpRequest::sslBumpEstablish(comm_err_t errflag)
+ClientHttpRequest::sslBumpEstablish(Comm::Flag errflag)
 {
-    // Bail out quickly on COMM_ERR_CLOSING - close handlers will tidy up
-    if (errflag == COMM_ERR_CLOSING)
+    // Bail out quickly on Comm::ERR_CLOSING - close handlers will tidy up
+    if (errflag == Comm::ERR_CLOSING)
         return;
 
     if (errflag) {
@@ -1789,7 +1787,7 @@ ClientHttpRequest::doCallouts()
         }
     }
 
-#if USE_SSL
+#if USE_OPENSSL
     // We need to check for SslBump even if the calloutContext->error is set
     // because bumping may require delaying the error until after CONNECT.
     if (!calloutContext->sslBumpCheckDone) {
@@ -1803,7 +1801,7 @@ ClientHttpRequest::doCallouts()
     if (calloutContext->error) {
         const char *storeUri = request->storeId();
         StoreEntry *e= storeCreateEntry(storeUri, storeUri, request->flags, request->method);
-#if USE_SSL
+#if USE_OPENSSL
         if (sslBumpNeeded()) {
             // set final error but delay sending until we bump
             Ssl::ServerBump *srvBump = new Ssl::ServerBump(request, e);
@@ -142,7 +142,7 @@ class ClientHttpRequest
     StoreEntry *loggingEntry_;
     ConnStateData * conn_;
 
-#if USE_SSL
+#if USE_OPENSSL
     /// whether (and how) the request needs to be bumped
     Ssl::BumpMode sslBumpNeed_;
 
@@ -154,7 +154,7 @@ class ClientHttpRequest
     /// set the sslBumpNeeded state
     void sslBumpNeed(Ssl::BumpMode mode);
     void sslBumpStart();
-    void sslBumpEstablish(comm_err_t errflag);
+    void sslBumpEstablish(Comm::Flag errflag);
 #endif
 
 #if USE_ADAPTATION
@@ -39,6 +39,7 @@
 #include "comm/Connection.h"
 #include "comm/IoCallback.h"
 #include "comm/Loops.h"
+#include "comm/Read.h"
 #include "comm/TcpAcceptor.h"
 #include "comm/Write.h"
 #include "CommRead.h"
@@ -54,12 +55,13 @@
 #include "ip/tools.h"
 #include "pconn.h"
 #include "profiler/Profiler.h"
+#include "SBuf.h"
 #include "SquidConfig.h"
 #include "StatCounters.h"
 #include "StoreIOBuffer.h"
 #include "tools.h"
 
-#if USE_SSL
+#if USE_OPENSSL
 #include "ssl/support.h"
 #endif
 
@@ -79,7 +81,6 @@
  * New C-like simple comm code. This stuff is a mess and doesn't really buy us anything.
  */
 
-static void commStopHalfClosedMonitor(int fd);
 static IOCB commHalfClosedReader;
 static void comm_init_opened(const Comm::ConnectionPointer &conn, tos_t tos, nfmark_t nfmark, const char *note, struct addrinfo *AI);
 static int comm_apply_flags(int new_socket, Ip::Address &addr, int flags, struct addrinfo *AI);
@@ -97,7 +98,7 @@ static bool WillCheckHalfClosed = false; /// true if check is scheduled
 static EVH commHalfClosedCheck;
 static void commPlanHalfClosedCheck();
 
-static comm_err_t commBind(int s, struct addrinfo &);
+static Comm::Flag commBind(int s, struct addrinfo &);
 static void commSetReuseAddr(int);
 static void commSetNoLinger(int);
 #ifdef TCP_NODELAY
@@ -113,75 +114,6 @@ isOpen(const int fd)
     return fd >= 0 && fd_table && fd_table[fd].flags.open != 0;
 }
 
-/**
- * Attempt a read
- *
- * If the read attempt succeeds or fails, call the callback.
- * Else, wait for another IO notification.
- */
-void
-commHandleRead(int fd, void *data)
-{
-    Comm::IoCallback *ccb = (Comm::IoCallback *) data;
-
-    assert(data == COMMIO_FD_READCB(fd));
-    assert(ccb->active());
-    /* Attempt a read */
-    ++ statCounter.syscalls.sock.reads;
-    errno = 0;
-    int retval;
-    retval = FD_READ_METHOD(fd, ccb->buf, ccb->size);
-    debugs(5, 3, "comm_read_try: FD " << fd << ", size " << ccb->size << ", retval " << retval << ", errno " << errno);
-
-    if (retval < 0 && !ignoreErrno(errno)) {
-        debugs(5, 3, "comm_read_try: scheduling COMM_ERROR");
-        ccb->offset = 0;
-        ccb->finish(COMM_ERROR, errno);
-        return;
-    };
-
-    /* See if we read anything */
-    /* Note - read 0 == socket EOF, which is a valid read */
-    if (retval >= 0) {
-        fd_bytes(fd, retval, FD_READ);
-        ccb->offset = retval;
-        ccb->finish(COMM_OK, errno);
-        return;
-    }
-
-    /* Nope, register for some more IO */
-    Comm::SetSelect(fd, COMM_SELECT_READ, commHandleRead, data, 0);
-}
-
-/**
- * Queue a read. handler/handler_data are called when the read
- * completes, on error, or on file descriptor close.
- */
-void
-comm_read(const Comm::ConnectionPointer &conn, char *buf, int size, AsyncCall::Pointer &callback)
-{
-    debugs(5, 5, "comm_read, queueing read for " << conn << "; asynCall " << callback);
-
-    /* Make sure we are open and not closing */
-    assert(Comm::IsConnOpen(conn));
-    assert(!fd_table[conn->fd].closing());
-    Comm::IoCallback *ccb = COMMIO_FD_READCB(conn->fd);
-
-    // Make sure we are either not reading or just passively monitoring.
-    // Active/passive conflicts are OK and simply cancel passive monitoring.
-    if (ccb->active()) {
-        // if the assertion below fails, we have an active comm_read conflict
-        assert(fd_table[conn->fd].halfClosedReader != NULL);
-        commStopHalfClosedMonitor(conn->fd);
-        assert(!ccb->active());
-    }
-    ccb->conn = conn;
-
-    /* Queue the read */
-    ccb->setCallback(Comm::IOCB_READ, callback, (char *)buf, NULL, size);
-    Comm::SetSelect(conn->fd, COMM_SELECT_READ, commHandleRead, ccb, 0);
-}
-
 /**
  * Empty the read buffers
  *
@@ -203,115 +135,6 @@ comm_empty_os_read_buffers(int fd)
 #endif
 }
 
-/**
- * Return whether the FD has a pending completed callback.
- * NP: does not work.
- */
-int
-comm_has_pending_read_callback(int fd)
-{
-    assert(isOpen(fd));
-    // XXX: We do not know whether there is a read callback scheduled.
-    // This is used for pconn management that should probably be more
-    // tightly integrated into comm to minimize the chance that a
-    // closing pconn socket will be used for a new transaction.
-    return false;
-}
-
-// Does comm check this fd for read readiness?
-// Note that when comm is not monitoring, there can be a pending callback
-// call, which may resume comm monitoring once fired.
-bool
-comm_monitors_read(int fd)
-{
-    assert(isOpen(fd) && COMMIO_FD_READCB(fd));
-    // Being active is usually the same as monitoring because we always
-    // start monitoring the FD when we configure Comm::IoCallback for I/O
-    // and we usually configure Comm::IoCallback for I/O when we starting
-    // monitoring a FD for reading.
-    return COMMIO_FD_READCB(fd)->active();
-}
-
-/**
- * Cancel a pending read. Assert that we have the right parameters,
- * and that there are no pending read events!
- *
- * XXX: We do not assert that there are no pending read events and
- * with async calls it becomes even more difficult.
- * The whole interface should be reworked to do callback->cancel()
- * instead of searching for places where the callback may be stored and
- * updating the state of those places.
- *
- * AHC Don't call the comm handlers?
- */
-void
-comm_read_cancel(int fd, IOCB *callback, void *data)
-{
-    if (!isOpen(fd)) {
-        debugs(5, 4, "comm_read_cancel fails: FD " << fd << " closed");
-        return;
-    }
-
-    Comm::IoCallback *cb = COMMIO_FD_READCB(fd);
-    // TODO: is "active" == "monitors FD"?
-    if (!cb->active()) {
-        debugs(5, 4, "comm_read_cancel fails: FD " << fd << " inactive");
-        return;
-    }
-
-    typedef CommCbFunPtrCallT<CommIoCbPtrFun> Call;
-    Call *call = dynamic_cast<Call*>(cb->callback.getRaw());
-    if (!call) {
-        debugs(5, 4, "comm_read_cancel fails: FD " << fd << " lacks callback");
-        return;
-    }
-
-    call->cancel("old comm_read_cancel");
-
-    typedef CommIoCbParams Params;
-    const Params &params = GetCommParams<Params>(cb->callback);
-
-    /* Ok, we can be reasonably sure we won't lose any data here! */
-    assert(call->dialer.handler == callback);
-    assert(params.data == data);
-
-    /* Delete the callback */
-    cb->cancel("old comm_read_cancel");
-
-    /* And the IO event */
-    Comm::SetSelect(fd, COMM_SELECT_READ, NULL, NULL, 0);
-}
-
-void
-comm_read_cancel(int fd, AsyncCall::Pointer &callback)
-{
-    callback->cancel("comm_read_cancel");
-
-    if (!isOpen(fd)) {
-        debugs(5, 4, "comm_read_cancel fails: FD " << fd << " closed");
-        return;
-    }
-
-    Comm::IoCallback *cb = COMMIO_FD_READCB(fd);
-
-    if (!cb->active()) {
-        debugs(5, 4, "comm_read_cancel fails: FD " << fd << " inactive");
-        return;
-    }
-
-    AsyncCall::Pointer call = cb->callback;
-    assert(call != NULL); // XXX: should never fail (active() checks for callback==NULL)
-
-    /* Ok, we can be reasonably sure we won't lose any data here! */
-    assert(call == callback);
-
-    /* Delete the callback */
-    cb->cancel("comm_read_cancel");
-
-    /* And the IO event */
-    Comm::SetSelect(fd, COMM_SELECT_READ, NULL, NULL, 0);
-}
-
 /**
  * synchronous wrapper around udp socket functions
  */
@@ -396,19 +219,19 @@ comm_local_port(int fd)
     return F->local_addr.port();
 }
 
-static comm_err_t
+static Comm::Flag
 commBind(int s, struct addrinfo &inaddr)
 {
     ++ statCounter.syscalls.sock.binds;
 
     if (bind(s, inaddr.ai_addr, inaddr.ai_addrlen) == 0) {
         debugs(50, 6, "commBind: bind socket FD " << s << " to " << fd_table[s].local_addr);
-        return COMM_OK;
+        return Comm::OK;
     }
 
     debugs(50, 0, "commBind: Cannot bind socket FD " << s << " to " << fd_table[s].local_addr << ": " << xstrerror());
 
-    return COMM_ERROR;
+    return Comm::COMM_ERROR;
 }
 
 /**
@@ -681,14 +504,14 @@ comm_apply_flags(int new_socket,
         if ( addr.isNoAddr() )
             debugs(5,0,"CRITICAL: Squid is attempting to bind() port " << addr << "!!");
 
-        if (commBind(new_socket, *AI) != COMM_OK) {
+        if (commBind(new_socket, *AI) != Comm::OK) {
             comm_close(new_socket);
             return -1;
         }
     }
 
     if (flags & COMM_NONBLOCKING)
-        if (commSetNonBlocking(new_socket) == COMM_ERROR) {
+        if (commSetNonBlocking(new_socket) == Comm::COMM_ERROR) {
             comm_close(new_socket);
             return -1;
         }
@@ -795,7 +618,7 @@ commUnsetConnTimeout(const Comm::ConnectionPointer &conn)
 int
 comm_connect_addr(int sock, const Ip::Address &address)
 {
-    comm_err_t status = COMM_OK;
+    Comm::Flag status = Comm::OK;
     fde *F = &fd_table[sock];
     int x = 0;
     int err = 0;
@@ -814,7 +637,7 @@ comm_connect_addr(int sock, const Ip::Address &address)
      */
     if (F->sock_family == AF_INET && !address.isIPv4()) {
         errno = ENETUNREACH;
-        return COMM_ERR_PROTOCOL;
+        return Comm::ERR_PROTOCOL;
     }
 
     /* Handle IPv4 over IPv6-only socket case.
@@ -826,7 +649,7 @@ comm_connect_addr(int sock, const Ip::Address &address)
      */
     if (!F->local_addr.isIPv4() && address.isIPv4()) {
         errno = ENETUNREACH;
-        return COMM_ERR_PROTOCOL;
+        return Comm::ERR_PROTOCOL;
     }
 
     address.getAddrInfo(AI, F->sock_family);
@@ -901,21 +724,21 @@ comm_connect_addr(int sock, const Ip::Address &address)
     PROF_stop(comm_connect_addr);
 
     if (errno == 0 || errno == EISCONN)
-        status = COMM_OK;
+        status = Comm::OK;
     else if (ignoreErrno(errno))
-        status = COMM_INPROGRESS;
+        status = Comm::INPROGRESS;
     else if (errno == EAFNOSUPPORT || errno == EINVAL)
-        return COMM_ERR_PROTOCOL;
+        return Comm::ERR_PROTOCOL;
     else
-        return COMM_ERROR;
+        return Comm::COMM_ERROR;
 
     address.toStr(F->ipaddr, MAX_IPSTRLEN);
 
     F->remote_port = address.port(); /* remote_port is HS */
 
-    if (status == COMM_OK) {
+    if (status == Comm::OK) {
         debugs(5, DBG_DATA, "comm_connect_addr: FD " << sock << " connected to " << address);
-    } else if (status == COMM_INPROGRESS) {
+    } else if (status == Comm::INPROGRESS) {
         debugs(5, DBG_DATA, "comm_connect_addr: FD " << sock << " connection pending");
     }
 
@@ -967,7 +790,7 @@ commLingerTimeout(const FdeCbParams &params)
 void
 comm_lingering_close(int fd)
 {
-#if USE_SSL
+#if USE_OPENSSL
     if (fd_table[fd].ssl)
         ssl_shutdown_method(fd_table[fd].ssl);
 #endif
@@ -1026,7 +849,7 @@ old_comm_reset_close(int fd)
     comm_close(fd);
 }
 
-#if USE_SSL
+#if USE_OPENSSL
 void
 commStartSslClose(const FdeCbParams &params)
 {
@@ -1038,7 +861,7 @@ commStartSslClose(const FdeCbParams &params)
 void
 comm_close_complete(const FdeCbParams &params)
 {
-#if USE_SSL
+#if USE_OPENSSL
     fde *F = &fd_table[params.fd];
 
     if (F->ssl) {
@@ -1067,7 +890,7 @@ comm_close_complete(const FdeCbParams &params)
  * + call read handlers with ERR_CLOSING
  * + call closing handlers
  *
- * NOTE: COMM_ERR_CLOSING will NOT be called for CommReads' sitting in a
+ * NOTE: Comm::ERR_CLOSING will NOT be called for CommReads' sitting in a
  * DeferredReadManager.
  */
 void
@@ -1101,7 +924,7 @@ _comm_close(int fd, char const *file, int line)
 
     F->flags.close_request = true;
 
-#if USE_SSL
+#if USE_OPENSSL
     if (F->ssl) {
         AsyncCall::Pointer startCall=commCbCall(5,4, "commStartSslClose",
                                                 FdeCbPtrFun(commStartSslClose, NULL));
@@ -1119,11 +942,11 @@ _comm_close(int fd, char const *file, int line)
     // notify read/write handlers after canceling select reservations, if any
     if (COMMIO_FD_WRITECB(fd)->active()) {
         Comm::SetSelect(fd, COMM_SELECT_WRITE, NULL, NULL, 0);
-        COMMIO_FD_WRITECB(fd)->finish(COMM_ERR_CLOSING, errno);
+        COMMIO_FD_WRITECB(fd)->finish(Comm::ERR_CLOSING, errno);
     }
     if (COMMIO_FD_READCB(fd)->active()) {
         Comm::SetSelect(fd, COMM_SELECT_READ, NULL, NULL, 0);
-        COMMIO_FD_READCB(fd)->finish(COMM_ERR_CLOSING, errno);
+        COMMIO_FD_READCB(fd)->finish(Comm::ERR_CLOSING, errno);
     }
 
 #if USE_DELAY_POOLS
@@ -1138,9 +961,6 @@ _comm_close(int fd, char const *file, int line)
 
     commCallCloseHandlers(fd);
 
-    if (F->pconn.uses && F->pconn.pool)
-        F->pconn.pool->noteUses(F->pconn.uses);
-
     comm_empty_os_read_buffers(fd);
 
     AsyncCall::Pointer completeCall=commCbCall(5,4, "comm_close_complete",
@@ -1184,7 +1004,7 @@ comm_udp_sendto(int fd,
 
         debugs(50, DBG_IMPORTANT, "comm_udp_sendto: FD " << fd << ", (family=" << fd_table[fd].sock_family << ") " << to_addr << ": " << xstrerror());
 
-    return COMM_ERROR;
+    return Comm::COMM_ERROR;
 }
 
 void
@@ -1309,7 +1129,7 @@ commSetNonBlocking(int fd)
 
         if (ioctl(fd, FIONBIO, &nonblocking) < 0) {
             debugs(50, 0, "commSetNonBlocking: FD " << fd << ": " << xstrerror() << " " << fd_table[fd].type);
-            return COMM_ERROR;
+            return Comm::COMM_ERROR;
         }
 
 #if _SQUID_CYGWIN_
@@ -1320,12 +1140,12 @@ commSetNonBlocking(int fd)
 
         if ((flags = fcntl(fd, F_GETFL, dummy)) < 0) {
             debugs(50, 0, "FD " << fd << ": fcntl F_GETFL: " << xstrerror());
-            return COMM_ERROR;
+            return Comm::COMM_ERROR;
         }
 
         if (fcntl(fd, F_SETFL, flags | SQUID_NONBLOCK) < 0) {
             debugs(50, 0, "commSetNonBlocking: FD " << fd << ": " << xstrerror());
-            return COMM_ERROR;
+            return Comm::COMM_ERROR;
         }
 
 #endif
@@ -1350,13 +1170,13 @@ commUnsetNonBlocking(int fd)
 
     if ((flags = fcntl(fd, F_GETFL, dummy)) < 0) {
         debugs(50, 0, "FD " << fd << ": fcntl F_GETFL: " << xstrerror());
-        return COMM_ERROR;
+        return Comm::COMM_ERROR;
     }
 
     if (fcntl(fd, F_SETFL, flags & (~SQUID_NONBLOCK)) < 0) {
 #endif
         debugs(50, 0, "commUnsetNonBlocking: FD " << fd << ": " << xstrerror());
-        return COMM_ERROR;
+        return Comm::COMM_ERROR;
     }
 
     fd_table[fd].flags.nonblocking = false;
@@ -1791,7 +1611,7 @@ checkTimeouts(void)
             // We have an active write callback and we are timed out
             debugs(5, 5, "checkTimeouts: FD " << fd << " auto write timeout");
             Comm::SetSelect(fd, COMM_SELECT_WRITE, NULL, NULL, 0);
-            COMMIO_FD_WRITECB(fd)->finish(COMM_ERROR, ETIMEDOUT);
+            COMMIO_FD_WRITECB(fd)->finish(Comm::COMM_ERROR, ETIMEDOUT);
         } else if (AlreadyTimedOut(F))
             continue;
 
@@ -1847,7 +1667,7 @@ commHalfClosedCheck(void *)
         if (!fd_table[c->fd].halfClosedReader) { // not reading already
             AsyncCall::Pointer call = commCbCall(5,4, "commHalfClosedReader",
                                                  CommIoCbPtrFun(&commHalfClosedReader, NULL));
-            comm_read(c, NULL, 0, call);
+            Comm::Read(c, call);
             fd_table[c->fd].halfClosedReader = call;
         } else
             c->fd = -1; // XXX: temporary. prevent c replacement erase closing listed FD
@@ -1866,23 +1686,23 @@ commHasHalfClosedMonitor(int fd)
 }
 
 /// stop waiting for possibly half-closed connection to close
-static void
+void
 commStopHalfClosedMonitor(int const fd)
 {
     debugs(5, 5, HERE << "removing FD " << fd << " from " << *TheHalfClosed);
 
     // cancel the read if one was scheduled
     AsyncCall::Pointer reader = fd_table[fd].halfClosedReader;
     if (reader != NULL)
-        comm_read_cancel(fd, reader);
+        Comm::ReadCancel(fd, reader);
     fd_table[fd].halfClosedReader = NULL;
 
     TheHalfClosed->del(fd);
 }
 
 /// I/O handler for the possibly half-closed connection monitoring code
 static void
-commHalfClosedReader(const Comm::ConnectionPointer &conn, char *, size_t size, comm_err_t flag, int, void *)
+commHalfClosedReader(const Comm::ConnectionPointer &conn, char *, size_t size, Comm::Flag flag, int, void *)
 {
     // there cannot be more data coming in on half-closed connections
     assert(size == 0);
@@ -1892,11 +1712,11 @@ commHalfClosedReader(const Comm::ConnectionPointer &conn, char *, size_t size, c
     fd_table[conn->fd].halfClosedReader = NULL; // done reading, for now
 
     // nothing to do if fd is being closed
-    if (flag == COMM_ERR_CLOSING)
+    if (flag == Comm::ERR_CLOSING)
         return;
 
     // if read failed, close the connection
-    if (flag != COMM_OK) {
+    if (flag != Comm::OK) {
         debugs(5, 3, HERE << "closing " << conn);
         conn->close();
         return;
@@ -2053,17 +1873,17 @@ CommSelectEngine::checkEvents(int timeout)
 
     switch (Comm::DoSelect(timeout)) {
 
-    case COMM_OK:
+    case Comm::OK:
 
-    case COMM_TIMEOUT:
+    case Comm::TIMEOUT:
         return 0;
 
-    case COMM_IDLE:
+    case Comm::IDLE:
 
-    case COMM_SHUTDOWN:
+    case Comm::SHUTDOWN:
         return EVENT_IDLE;
 
-    case COMM_ERROR:
+    case Comm::COMM_ERROR:
         return EVENT_ERROR;
 
     default:
@@ -2137,15 +1957,15 @@ comm_open_uds(int sock_type,
         commSetReuseAddr(new_socket);
 
     if (flags & COMM_NONBLOCKING) {
-        if (commSetNonBlocking(new_socket) != COMM_OK) {
+        if (commSetNonBlocking(new_socket) != Comm::OK) {
             comm_close(new_socket);
             PROF_stop(comm_open);
             return -1;
         }
     }
 
     if (flags & COMM_DOBIND) {
-        if (commBind(new_socket, AI) != COMM_OK) {
+        if (commBind(new_socket, AI) != Comm::OK) {
             comm_close(new_socket);
             PROF_stop(comm_open);
             return -1;
@@ -71,18 +71,11 @@ int ignoreErrno(int);
 void commCloseAllSockets(void);
 void checkTimeouts(void);
 
-//typedef void IOACB(int fd, int nfd, Comm::ConnectionPointer details, comm_err_t flag, int xerrno, void *data);
 void comm_add_close_handler(int fd, CLCB *, void *);
 void comm_add_close_handler(int fd, AsyncCall::Pointer &);
 void comm_remove_close_handler(int fd, CLCB *, void *);
 void comm_remove_close_handler(int fd, AsyncCall::Pointer &);
 
-int comm_has_pending_read_callback(int fd);
-bool comm_monitors_read(int fd);
-//void comm_read(const Comm::ConnectionPointer &conn, char *buf, int len, IOCB *handler, void *data);
-void comm_read(const Comm::ConnectionPointer &conn, char *buf, int len, AsyncCall::Pointer &callback);
-void comm_read_cancel(int fd, IOCB *callback, void *data);
-void comm_read_cancel(int fd, AsyncCall::Pointer &callback);
 int comm_udp_recvfrom(int fd, void *buf, size_t len, int flags, Ip::Address &from);
 int comm_udp_recv(int fd, void *buf, size_t len, int flags);
 ssize_t comm_udp_send(int s, const void *buf, size_t len, int flags);
@@ -17,9 +17,7 @@
 #include "SquidConfig.h"
 #include "SquidTime.h"
 
-#if HAVE_ERRNO_H
-#include <errno.h>
-#endif
+#include <cerrno>
 
 class CachePeer;
 
@@ -64,7 +62,7 @@ Comm::ConnOpener::swanSong()
 {
     if (callback_ != NULL) {
         // inform the still-waiting caller we are dying
-        sendAnswer(COMM_ERR_CONNECT, 0, "Comm::ConnOpener::swanSong");
+        sendAnswer(Comm::ERR_CONNECT, 0, "Comm::ConnOpener::swanSong");
     }
 
     // did we abort with a temporary FD assigned?
@@ -101,7 +99,7 @@ Comm::ConnOpener::getHost() const
  * Pass the results back to the external handler.
  */
 void
-Comm::ConnOpener::sendAnswer(comm_err_t errFlag, int xerrno, const char *why)
+Comm::ConnOpener::sendAnswer(Comm::Flag errFlag, int xerrno, const char *why)
 {
     // only mark the address good/bad AFTER connect is finished.
     if (host_ != NULL) {
@@ -230,7 +228,7 @@ Comm::ConnOpener::start()
     }
 
     if (createFd())
-        connect();
+        doConnect();
 }
 
 /// called at the end of Comm::ConnOpener::DelayedConnectRetry event
@@ -241,7 +239,7 @@ Comm::ConnOpener::restart()
     calls_.sleep_ = false;
 
     if (createFd())
-        connect();
+        doConnect();
 }
 
 /// Create a socket for the future connection or return false.
@@ -257,7 +255,7 @@ Comm::ConnOpener::createFd()
 
     temporaryFd_ = comm_openex(SOCK_STREAM, IPPROTO_TCP, conn_->local, conn_->flags, conn_->tos, conn_->nfmark, host_);
     if (temporaryFd_ < 0) {
-        sendAnswer(COMM_ERR_CONNECT, 0, "Comm::ConnOpener::createFd");
+        sendAnswer(Comm::ERR_CONNECT, 0, "Comm::ConnOpener::createFd");
         return false;
     }
 
@@ -306,12 +304,12 @@ Comm::ConnOpener::connected()
     Must(fd_table[conn_->fd].flags.open);
     fd_table[conn_->fd].local_addr = conn_->local;
 
-    sendAnswer(COMM_OK, 0, "Comm::ConnOpener::connected");
+    sendAnswer(Comm::OK, 0, "Comm::ConnOpener::connected");
 }
 
 /// Make an FD connection attempt.
 void
-Comm::ConnOpener::connect()
+Comm::ConnOpener::doConnect()
 {
     Must(conn_ != NULL);
     Must(temporaryFd_ >= 0);
@@ -320,13 +318,13 @@ Comm::ConnOpener::connect()
 
     switch (comm_connect_addr(temporaryFd_, conn_->remote) ) {
 
-    case COMM_INPROGRESS:
-        debugs(5, 5, HERE << conn_ << ": COMM_INPROGRESS");
+    case Comm::INPROGRESS:
+        debugs(5, 5, HERE << conn_ << ": Comm::INPROGRESS");
         Comm::SetSelect(temporaryFd_, COMM_SELECT_WRITE, Comm::ConnOpener::InProgressConnectRetry, new Pointer(this), 0);
         break;
 
-    case COMM_OK:
-        debugs(5, 5, HERE << conn_ << ": COMM_OK - connected");
+    case Comm::OK:
+        debugs(5, 5, HERE << conn_ << ": Comm::OK - connected");
         connected();
         break;
 
@@ -344,7 +342,7 @@ Comm::ConnOpener::connect()
         } else {
             // send ERROR back to the upper layer.
             debugs(5, 5, HERE << conn_ << ": * - ERR tried too many times already.");
-            sendAnswer(COMM_ERR_CONNECT, xerrno, "Comm::ConnOpener::connect");
+            sendAnswer(Comm::ERR_CONNECT, xerrno, "Comm::ConnOpener::doConnect");
         }
     }
     }
@@ -410,7 +408,7 @@ Comm::ConnOpener::earlyAbort(const CommCloseCbParams &io)
     debugs(5, 3, HERE << io.conn);
     calls_.earlyAbort_ = NULL;
     // NP: is closing or shutdown better?
-    sendAnswer(COMM_ERR_CLOSING, io.xerrno, "Comm::ConnOpener::earlyAbort");
+    sendAnswer(Comm::ERR_CLOSING, io.xerrno, "Comm::ConnOpener::earlyAbort");
 }
 
 /**
@@ -422,11 +420,11 @@ Comm::ConnOpener::timeout(const CommTimeoutCbParams &)
 {
     debugs(5, 5, HERE << conn_ << ": * - ERR took too long to receive response.");
     calls_.timeout_ = NULL;
-    sendAnswer(COMM_TIMEOUT, ETIMEDOUT, "Comm::ConnOpener::timeout");
+    sendAnswer(Comm::TIMEOUT, ETIMEDOUT, "Comm::ConnOpener::timeout");
 }
 
-/* Legacy Wrapper for the retry event after COMM_INPROGRESS
- * XXX: As soon as Comm::SetSelect() accepts Async calls we can use a ConnOpener::connect call
+/* Legacy Wrapper for the retry event after Comm::INPROGRESS
+ * XXX: As soon as Comm::SetSelect() accepts Async calls we can use a ConnOpener::doConnect call
  */
 void
 Comm::ConnOpener::InProgressConnectRetry(int fd, void *data)
@@ -437,7 +435,7 @@ Comm::ConnOpener::InProgressConnectRetry(int fd, void *data)
         // Ew. we are now outside the all AsyncJob protections.
         // get back inside by scheduling another call...
         typedef NullaryMemFunT<Comm::ConnOpener> Dialer;
-        AsyncCall::Pointer call = JobCallback(5, 4, Dialer, cs, Comm::ConnOpener::connect);
+        AsyncCall::Pointer call = JobCallback(5, 4, Dialer, cs, Comm::ConnOpener::doConnect);
         ScheduleCallHere(call);
     }
     delete ptr;
@@ -4,8 +4,8 @@
 #include "base/AsyncCall.h"
 #include "base/AsyncJob.h"
 #include "cbdata.h"
+#include "comm/Flag.h"
 #include "comm/forward.h"
-#include "comm_err_t.h"
 #include "CommCalls.h"
 
 namespace Comm
@@ -40,10 +40,10 @@ class ConnOpener : public AsyncJob
 
     void earlyAbort(const CommCloseCbParams &);
     void timeout(const CommTimeoutCbParams &);
-    void sendAnswer(comm_err_t errFlag, int xerrno, const char *why);
+    void sendAnswer(Comm::Flag errFlag, int xerrno, const char *why);
     static void InProgressConnectRetry(int fd, void *data);
     static void DelayedConnectRetry(void *data);
-    void connect();
+    void doConnect();
     void connected();
     void lookupLocalAddress();
 
@@ -66,7 +66,7 @@ class ConnOpener : public AsyncJob
     int totalTries_;   ///< total number of connection attempts over all destinations so far.
     int failRetries_;  ///< number of retries current destination has been tried.
 
-    /// if we are not done by then, we will call back with COMM_TIMEOUT
+    /// if we are not done by then, we will call back with Comm::TIMEOUT
     time_t deadline_;
 
     /// handles to calls which we may need to cancel.
@@ -4,6 +4,7 @@
 #include "comm.h"
 #include "comm/Connection.h"
 #include "fde.h"
+#include "neighbors.h"
 #include "SquidTime.h"
 
 class CachePeer;
@@ -66,7 +67,7 @@ Comm::Connection::close()
         comm_close(fd);
         fd = -1;
         if (CachePeer *p=getPeer())
-            -- p->stats.conn_open;
+            peerConnClosed(p);
     }
 }
 
@@ -0,0 +1,25 @@
+#ifndef _SQUID_SRC_COMM_FLAG_H
+#define _SQUID_SRC_COMM_FLAG_H
+
+namespace Comm
+{
+
+typedef enum {
+    OK = 0,
+    COMM_ERROR = -1,
+    NOMESSAGE = -3,
+    TIMEOUT = -4,
+    SHUTDOWN = -5,
+    IDLE = -6, /* there are no active fds and no pending callbacks. */
+    INPROGRESS = -7,
+    ERR_CONNECT = -8,
+    ERR_DNS = -9,
+    ERR_CLOSING = -10,
+    ERR_PROTOCOL = -11, /* IPv4 or IPv6 cannot be used on the fd socket */
+    ENDFILE = -12, /**< read(2) returned success, but with 0 bytes */
+    ERR__END__ = -999999 /* Dummy entry to make syntax valid (comma on line above), do not use. New entries added above */
+} Flag;
+
+} // namespace Comm
+
+#endif /* _SQUID_SRC_COMM_FLAG_H */
@@ -103,13 +103,13 @@ Comm::IoCallback::reset()
 
 // Schedule the callback call and clear the callback
 void
-Comm::IoCallback::finish(comm_err_t code, int xerrn)
+Comm::IoCallback::finish(Comm::Flag code, int xerrn)
 {
     debugs(5, 3, HERE << "called for " << conn << " (" << code << ", " << xerrno << ")");
     assert(active());
 
     /* free data */
-    if (freefunc) {
+    if (freefunc && buf) {
         freefunc(buf);
         buf = NULL;
         freefunc = NULL;
@@ -2,10 +2,12 @@
 #define _SQUID_COMM_IOCALLBACK_H
 
 #include "base/AsyncCall.h"
+#include "comm/Flag.h"
 #include "comm/forward.h"
-#include "comm_err_t.h"
 #include "typedefs.h"
 
+class SBuf;
+
 namespace Comm
 {
 
@@ -27,7 +29,7 @@ class IoCallback
     FREE *freefunc;
     int size;
     int offset;
-    comm_err_t errcode;
+    Comm::Flag errcode;
     int xerrno;
 #if USE_DELAY_POOLS
     unsigned int quotaQueueReserv; ///< reservation ID from CommQuotaQueue
@@ -43,7 +45,7 @@ class IoCallback
     void cancel(const char *reason);
 
     /// finish the IO operation imediately and schedule the callback with the current state.
-    void finish(comm_err_t code, int xerrn);
+    void finish(Comm::Flag code, int xerrn);
 
 private:
     void reset();
@@ -1,7 +1,7 @@
 #ifndef _SQUID_SRC_COMM_LOOPS_H
 #define _SQUID_SRC_COMM_LOOPS_H
 
-#include "comm_err_t.h"
+#include "comm/Flag.h"
 
 // for PF
 #include "typedefs.h"
@@ -27,7 +27,7 @@ void ResetSelect(int);
 /** Perform a select() or equivalent call.
  * This is used by the main select loop engine to check for FD with IO available.
  */
-comm_err_t DoSelect(int);
+Comm::Flag DoSelect(int);
 
 void QuickPollRequired(void);
 
@@ -11,6 +11,7 @@ libcomm_la_SOURCES= \
 	ConnOpener.h \
 	Connection.cc \
 	Connection.h \
+	Flag.h \
 	forward.h \
 	IoCallback.cc \
 	IoCallback.h \
@@ -21,6 +22,8 @@ libcomm_la_SOURCES= \
 	ModPoll.cc \
 	ModSelect.cc \
 	ModSelectWin32.cc \
+	Read.cc \
+	Read.h \
 	TcpAcceptor.cc \
 	TcpAcceptor.h \
 	UdpOpenDialer.h \
@@ -336,7 +336,7 @@ Comm::ResetSelect(int fd)
  *
  * @param msec milliseconds to poll for (limited by max_poll_time)
  */
-comm_err_t
+Comm::Flag
 Comm::DoSelect(int msec)
 {
     int num, i;
@@ -366,7 +366,7 @@ Comm::DoSelect(int msec)
         /* error during poll */
         getCurrentTime();
         PROF_stop(comm_check_incoming);
-        return COMM_ERROR;
+        return Comm::COMM_ERROR;
     }
 
     PROF_stop(comm_check_incoming);
@@ -375,7 +375,7 @@ Comm::DoSelect(int msec)
     statCounter.select_fds_hist.count(num);
 
     if (num == 0)
-        return COMM_TIMEOUT; /* no error */
+        return Comm::TIMEOUT; /* no error */
 
     PROF_start(comm_handle_ready_fd);
 
@@ -453,7 +453,7 @@ Comm::DoSelect(int msec)
     }
 
     PROF_stop(comm_handle_ready_fd);
-    return COMM_OK;
+    return Comm::OK;
 }
 
 void
@@ -65,12 +65,10 @@
 
 #define DEBUG_EPOLL 0
 
+#include <cerrno>
 #if HAVE_SYS_EPOLL_H
 #include <sys/epoll.h>
 #endif
-#if HAVE_ERRNO_H
-#include <errno.h>
-#endif
 
 static int kdpfd;
 static int max_poll_time = 1000;
@@ -241,7 +239,7 @@ commIncomingStats(StoreEntry * sentry)
  * comm_setselect and fd_table[] and calls callbacks for IO ready
  * events.
  */
-comm_err_t
+Comm::Flag
 Comm::DoSelect(int msec)
 {
     int num, i,fd;
@@ -269,7 +267,7 @@ Comm::DoSelect(int msec)
 
         PROF_stop(comm_check_incoming);
 
-        return COMM_ERROR;
+        return Comm::COMM_ERROR;
     }
 
     PROF_stop(comm_check_incoming);
@@ -278,7 +276,7 @@ Comm::DoSelect(int msec)
     statCounter.select_fds_hist.count(num);
 
     if (num == 0)
-        return COMM_TIMEOUT;		/* No error.. */
+        return Comm::TIMEOUT;		/* No error.. */
 
     PROF_start(comm_handle_ready_fd);
 
@@ -325,7 +323,7 @@ Comm::DoSelect(int msec)
 
     PROF_stop(comm_handle_ready_fd);
 
-    return COMM_OK;
+    return Comm::OK;
 }
 
 void
@@ -60,12 +60,10 @@
 #include "StatCounters.h"
 #include "Store.h"
 
+#include <cerrno>
 #if HAVE_SYS_EVENT_H
 #include <sys/event.h>
 #endif
-#if HAVE_ERRNO_H
-#include <errno.h>
-#endif
 
 #define KE_LENGTH        128
 
@@ -244,7 +242,7 @@ Comm::ResetSelect(int fd)
  * events.
  */
 
-comm_err_t
+Comm::Flag
 Comm::DoSelect(int msec)
 {
     int num, i;
@@ -273,15 +271,15 @@ Comm::DoSelect(int msec)
 
         getCurrentTime();
 
-        return COMM_ERROR;
+        return Comm::COMM_ERROR;
 
         /* NOTREACHED */
     }
 
     getCurrentTime();
 
     if (num == 0)
-        return COMM_OK;		/* No error.. */
+        return Comm::OK;		/* No error.. */
 
     for (i = 0; i < num; ++i) {
         int fd = (int) ke[i].ident;
@@ -315,7 +313,7 @@ Comm::DoSelect(int msec)
         }
     }
 
-    return COMM_OK;
+    return Comm::OK;
 }
 
 void
@@ -45,12 +45,10 @@
 #include "StatCounters.h"
 #include "Store.h"
 
+#include <cerrno>
 #if HAVE_POLL_H
 #include <poll.h>
 #endif
-#if HAVE_ERRNO_H
-#include <errno.h>
-#endif
 
 /* Needed for poll() on Linux at least */
 #if USE_POLL
@@ -350,7 +348,7 @@ comm_poll_tcp_incoming(void)
 }
 
 /* poll all sockets; call handlers for those that are ready. */
-comm_err_t
+Comm::Flag
 Comm::DoSelect(int msec)
 {
     struct pollfd pfds[SQUID_MAXFD];
@@ -425,9 +423,9 @@ Comm::DoSelect(int msec)
          */
         if (nfds == 0 && npending == 0) {
             if (shutting_down)
-                return COMM_SHUTDOWN;
+                return Comm::SHUTDOWN;
             else
-                return COMM_IDLE;
+                return Comm::IDLE;
         }
 
         for (;;) {
@@ -447,7 +445,7 @@ Comm::DoSelect(int msec)
 
             assert(errno != EINVAL);
 
-            return COMM_ERROR;
+            return Comm::COMM_ERROR;
 
             /* NOTREACHED */
         }
@@ -582,12 +580,12 @@ Comm::DoSelect(int msec)
 
         statCounter.select_time += (current_dtime - start);
 
-        return COMM_OK;
+        return Comm::OK;
     } while (timeout > current_dtime);
 
     debugs(5, 8, "comm_poll: time out: " << squid_curtime << ".");
 
-    return COMM_TIMEOUT;
+    return Comm::TIMEOUT;
 }
 
 static void
@@ -45,12 +45,10 @@
 #include "StatHist.h"
 #include "Store.h"
 
+#include <cerrno>
 #if HAVE_SYS_STAT_H
 #include <sys/stat.h>
 #endif
-#if HAVE_ERRNO_H
-#include <errno.h>
-#endif
 
 static int MAX_POLL_TIME = 1000;	/* see also Comm::QuickPollRequired() */
 
@@ -346,7 +344,7 @@ comm_select_tcp_incoming(void)
 
 #define DEBUG_FDBITS 0
 /* Select on all sockets; call handlers for those that are ready. */
-comm_err_t
+Comm::Flag
 Comm::DoSelect(int msec)
 {
     fd_set readfds;
@@ -442,7 +440,7 @@ Comm::DoSelect(int msec)
 #endif
         if (nreadfds + nwritefds == 0) {
             assert(shutting_down);
-            return COMM_SHUTDOWN;
+            return Comm::SHUTDOWN;
         }
 
         if (msec > MAX_POLL_TIME)
@@ -468,7 +466,7 @@ Comm::DoSelect(int msec)
 
             examine_select(&readfds, &writefds);
 
-            return COMM_ERROR;
+            return Comm::COMM_ERROR;
 
             /* NOTREACHED */
         }
@@ -630,11 +628,11 @@ Comm::DoSelect(int msec)
 
         statCounter.select_time += (current_dtime - start);
 
-        return COMM_OK;
+        return Comm::OK;
     } while (timeout > current_dtime);
     debugs(5, 8, "comm_select: time out: " << squid_curtime);
 
-    return COMM_TIMEOUT;
+    return Comm::TIMEOUT;
 }
 
 static void
@@ -42,9 +42,7 @@
 #include "StatHist.h"
 #include "Store.h"
 
-#if HAVE_ERRNO_H
-#include <errno.h>
-#endif
+#include <cerrno>
 
 static int MAX_POLL_TIME = 1000;	/* see also Comm::QuickPollRequired() */
 
@@ -343,7 +341,7 @@ comm_select_tcp_incoming(void)
 
 #define DEBUG_FDBITS 0
 /* Select on all sockets; call handlers for those that are ready. */
-comm_err_t
+Comm::Flag
 Comm::DoSelect(int msec)
 {
     fd_set readfds;
@@ -436,7 +434,7 @@ Comm::DoSelect(int msec)
 #endif
         if (nreadfds + nwritefds == 0) {
             assert(shutting_down);
-            return COMM_SHUTDOWN;
+            return Comm::SHUTDOWN;
         }
 
         if (msec > MAX_POLL_TIME)
@@ -462,7 +460,7 @@ Comm::DoSelect(int msec)
 
             examine_select(&readfds, &writefds);
 
-            return COMM_ERROR;
+            return Comm::COMM_ERROR;
 
             /* NOTREACHED */
         }
@@ -644,11 +642,11 @@ Comm::DoSelect(int msec)
 
         statCounter.select_time += (current_dtime - start);
 
-        return COMM_OK;
+        return Comm::OK;
     } while (timeout > current_dtime);
     debugs(5, 8, "comm_select: time out: " << squid_curtime);
 
-    return COMM_TIMEOUT;
+    return Comm::TIMEOUT;
 }
 
 static void
@@ -0,0 +1,234 @@
+/*
+ * DEBUG: section 05    Socket Functions
+ */
+#include "squid.h"
+#include "comm.h"
+#include "comm/IoCallback.h"
+#include "comm/Loops.h"
+#include "comm/Read.h"
+#include "comm_internal.h"
+#include "CommCalls.h"
+#include "Debug.h"
+#include "fd.h"
+#include "fde.h"
+#include "SBuf.h"
+#include "StatCounters.h"
+//#include "tools.h"
+
+// Does comm check this fd for read readiness?
+// Note that when comm is not monitoring, there can be a pending callback
+// call, which may resume comm monitoring once fired.
+bool
+Comm::MonitorsRead(int fd)
+{
+    assert(isOpen(fd) && COMMIO_FD_READCB(fd));
+    // Being active is usually the same as monitoring because we always
+    // start monitoring the FD when we configure Comm::IoCallback for I/O
+    // and we usually configure Comm::IoCallback for I/O when we starting
+    // monitoring a FD for reading.
+    return COMMIO_FD_READCB(fd)->active();
+}
+
+void
+Comm::Read(const Comm::ConnectionPointer &conn, AsyncCall::Pointer &callback)
+{
+    // TODO: move comm_read_base() internals into here
+    // when comm_read() char* API is no longer needed
+    comm_read_base(conn, NULL, 0, callback);
+}
+
+/**
+ * Queue a read.
+ * If a buffer is given the callback is scheduled when the read
+ * completes, on error, or on file descriptor close.
+ *
+ * If no buffer (NULL) is given the callback is scheduled when
+ * the socket FD is ready for a read(2)/recv(2).
+ */
+void
+comm_read_base(const Comm::ConnectionPointer &conn, char *buf, int size, AsyncCall::Pointer &callback)
+{
+    debugs(5, 5, "comm_read, queueing read for " << conn << "; asynCall " << callback);
+
+    /* Make sure we are open and not closing */
+    assert(Comm::IsConnOpen(conn));
+    assert(!fd_table[conn->fd].closing());
+    Comm::IoCallback *ccb = COMMIO_FD_READCB(conn->fd);
+
+    // Make sure we are either not reading or just passively monitoring.
+    // Active/passive conflicts are OK and simply cancel passive monitoring.
+    if (ccb->active()) {
+        // if the assertion below fails, we have an active comm_read conflict
+        assert(fd_table[conn->fd].halfClosedReader != NULL);
+        commStopHalfClosedMonitor(conn->fd);
+        assert(!ccb->active());
+    }
+    ccb->conn = conn;
+
+    /* Queue the read */
+    ccb->setCallback(Comm::IOCB_READ, callback, (char *)buf, NULL, size);
+    Comm::SetSelect(conn->fd, COMM_SELECT_READ, Comm::HandleRead, ccb, 0);
+}
+
+Comm::Flag
+Comm::ReadNow(CommIoCbParams &params, SBuf &buf)
+{
+    /* Attempt a read */
+    ++ statCounter.syscalls.sock.reads;
+    const SBuf::size_type sz = buf.spaceSize();
+    char *inbuf = buf.rawSpace(sz);
+    errno = 0;
+    const int retval = FD_READ_METHOD(params.conn->fd, inbuf, sz);
+    params.xerrno = errno;
+
+    debugs(5, 3, params.conn << ", size " << sz << ", retval " << retval << ", errno " << params.xerrno);
+
+    if (retval > 0) { // data read most common case
+        buf.append(inbuf, retval);
+        fd_bytes(params.conn->fd, retval, FD_READ);
+        params.flag = Comm::OK;
+        params.size = retval;
+
+    } else if (retval == 0) { // remote closure (somewhat less) common
+        // Note - read 0 == socket EOF, which is a valid read.
+        params.flag = Comm::ENDFILE;
+
+    } else if (retval < 0) { // connection errors are worst-case
+        debugs(5, 3, params.conn << " Comm::COMM_ERROR: " << xstrerr(params.xerrno));
+        if (ignoreErrno(params.xerrno))
+            params.flag =  Comm::INPROGRESS;
+        else
+            params.flag =  Comm::COMM_ERROR;
+    }
+
+    return params.flag;
+}
+
+/**
+ * Handle an FD which is ready for read(2).
+ *
+ * If there is no provided buffer to fill call the callback.
+ *
+ * Otherwise attempt a read into the provided buffer.
+ * If the read attempt succeeds or fails, call the callback.
+ * Else, wait for another IO notification.
+ */
+void
+Comm::HandleRead(int fd, void *data)
+{
+    Comm::IoCallback *ccb = (Comm::IoCallback *) data;
+
+    assert(data == COMMIO_FD_READCB(fd));
+    assert(ccb->active());
+
+    // Without a buffer, just call back.
+    // The callee may ReadMore() to get the data.
+    if (!ccb->buf) {
+        ccb->finish(Comm::OK, 0);
+        return;
+    }
+
+    /* For legacy callers : Attempt a read */
+    // Keep in sync with Comm::ReadNow()!
+    ++ statCounter.syscalls.sock.reads;
+    errno = 0;
+    int retval = FD_READ_METHOD(fd, ccb->buf, ccb->size);
+    debugs(5, 3, "FD " << fd << ", size " << ccb->size << ", retval " << retval << ", errno " << errno);
+
+    /* See if we read anything */
+    /* Note - read 0 == socket EOF, which is a valid read */
+    if (retval >= 0) {
+        fd_bytes(fd, retval, FD_READ);
+        ccb->offset = retval;
+        ccb->finish(Comm::OK, errno);
+        return;
+
+    } else if (retval < 0 && !ignoreErrno(errno)) {
+        debugs(5, 3, "comm_read_try: scheduling Comm::COMM_ERROR");
+        ccb->offset = 0;
+        ccb->finish(Comm::COMM_ERROR, errno);
+        return;
+    };
+
+    /* Nope, register for some more IO */
+    Comm::SetSelect(fd, COMM_SELECT_READ, Comm::HandleRead, data, 0);
+}
+
+/**
+ * Cancel a pending read. Assert that we have the right parameters,
+ * and that there are no pending read events!
+ *
+ * XXX: We do not assert that there are no pending read events and
+ * with async calls it becomes even more difficult.
+ * The whole interface should be reworked to do callback->cancel()
+ * instead of searching for places where the callback may be stored and
+ * updating the state of those places.
+ *
+ * AHC Don't call the comm handlers?
+ */
+void
+comm_read_cancel(int fd, IOCB *callback, void *data)
+{
+    if (!isOpen(fd)) {
+        debugs(5, 4, "fails: FD " << fd << " closed");
+        return;
+    }
+
+    Comm::IoCallback *cb = COMMIO_FD_READCB(fd);
+    // TODO: is "active" == "monitors FD"?
+    if (!cb->active()) {
+        debugs(5, 4, "fails: FD " << fd << " inactive");
+        return;
+    }
+
+    typedef CommCbFunPtrCallT<CommIoCbPtrFun> Call;
+    Call *call = dynamic_cast<Call*>(cb->callback.getRaw());
+    if (!call) {
+        debugs(5, 4, "fails: FD " << fd << " lacks callback");
+        return;
+    }
+
+    call->cancel("old comm_read_cancel");
+
+    typedef CommIoCbParams Params;
+    const Params &params = GetCommParams<Params>(cb->callback);
+
+    /* Ok, we can be reasonably sure we won't lose any data here! */
+    assert(call->dialer.handler == callback);
+    assert(params.data == data);
+
+    /* Delete the callback */
+    cb->cancel("old comm_read_cancel");
+
+    /* And the IO event */
+    Comm::SetSelect(fd, COMM_SELECT_READ, NULL, NULL, 0);
+}
+
+void
+Comm::ReadCancel(int fd, AsyncCall::Pointer &callback)
+{
+    callback->cancel("comm_read_cancel");
+
+    if (!isOpen(fd)) {
+        debugs(5, 4, "fails: FD " << fd << " closed");
+        return;
+    }
+
+    Comm::IoCallback *cb = COMMIO_FD_READCB(fd);
+
+    if (!cb->active()) {
+        debugs(5, 4, "fails: FD " << fd << " inactive");
+        return;
+    }
+
+    AsyncCall::Pointer call = cb->callback;
+
+    /* Ok, we can be reasonably sure we won't lose any data here! */
+    assert(call == callback);
+
+    /* Delete the callback */
+    cb->cancel("comm_read_cancel");
+
+    /* And the IO event */
+    Comm::SetSelect(fd, COMM_SELECT_READ, NULL, NULL, 0);
+}
@@ -0,0 +1,54 @@
+#ifndef _SQUID_COMM_READ_H
+#define _SQUID_COMM_READ_H
+
+#include "base/AsyncCall.h"
+#include "comm/forward.h"
+#include "CommCalls.h"
+
+class SBuf;
+
+namespace Comm
+{
+
+/**
+ * Start monitoring for read.
+ *
+ * callback is scheduled when the read is possible,
+ * or on file descriptor close.
+ */
+void Read(const Comm::ConnectionPointer &conn, AsyncCall::Pointer &callback);
+
+/// whether the FD socket is being monitored for read
+bool MonitorsRead(int fd);
+
+/**
+ * Perform a read(2) on a connection immediately.
+ *
+ * The returned flag is also placed in params.flag.
+ *
+ * \retval Comm::OK          data has been read and placed in buf, amount in params.size
+ * \retval Comm::COMM_ERROR  an error occured, the code is placed in params.xerrno
+ * \retval Comm::INPROGRESS  unable to read at this time, or a minor error occured
+ * \retval Comm::ENDFILE     0-byte read has occured.
+ *                           Usually indicates the remote end has disconnected.
+ */
+Comm::Flag ReadNow(CommIoCbParams &params, SBuf &buf);
+
+/// Cancel the read pending on FD. No action if none pending.
+void ReadCancel(int fd, AsyncCall::Pointer &callback);
+
+/// callback handler to process an FD which is available for reading
+extern PF HandleRead;
+
+} // namespace Comm
+
+// Legacy API to be removed
+void comm_read_base(const Comm::ConnectionPointer &conn, char *buf, int len, AsyncCall::Pointer &callback);
+inline void comm_read(const Comm::ConnectionPointer &conn, char *buf, int len, AsyncCall::Pointer &callback)
+{
+    assert(buf != NULL);
+    comm_read_base(conn, buf, len, callback);
+}
+void comm_read_cancel(int fd, IOCB *callback, void *data);
+
+#endif /* _SQUID_COMM_READ_H */