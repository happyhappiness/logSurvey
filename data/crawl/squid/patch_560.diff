@@ -100,7 +100,7 @@ xprof_comp(xprof_stats_node ** ii, xprof_stats_node ** jj)
 static void
 xprof_sorthist(TimersArray * xprof_list)
 {
-    for (int i = 0; i < XPROF_LAST; i++) {
+    for (int i = 0; i < XPROF_LAST; ++i) {
         sortlist[i] = xprof_list[i];
     }
 
@@ -151,7 +151,7 @@ xprof_summary_item(StoreEntry * sentry, char const *descr, TimersArray * list)
     storeAppendPrintf(sentry,
                       "Probe Name\t  Events\t cumulated time \t best case \t average \t worst case\t Rate / sec \t %% in int\n");
 
-    for (i = 0; i < XPROF_LAST; i++) {
+    for (i = 0; i < XPROF_LAST; ++i) {
         if (!hist[i]->name)
             continue;
 
@@ -193,7 +193,7 @@ xprof_average(TimersArray ** list, int secs)
 
     now = get_tick();
 
-    for (i = 0; i < XPROF_LAST; i++) {
+    for (i = 0; i < XPROF_LAST; ++i) {
         hist[i]->name = head[i]->name;
         hist[i]->accu.summ += head[i]->accu.summ;
         hist[i]->accu.count += head[i]->accu.count;	/* accumulate multisec */
@@ -295,7 +295,7 @@ xprof_event(void *data)
     xprof_Init();
     xprof_delta = now - xprof_start_t;
     xprof_start_t = now;
-    xprof_events++;
+    ++xprof_events;
 
     if (!xprof_average_delta)
         xprof_average_delta = xprof_delta;
@@ -363,7 +363,7 @@ strwordtok(char *buf, char **t)
         goto error;
 
     while (*p && xisspace(*p))
-        p++;
+        ++p;
 
     if (!*p)
         goto error;
@@ -374,7 +374,7 @@ strwordtok(char *buf, char **t)
         switch (ch) {
 
         case '\\':
-            p++;
+            ++p;
 
             switch (*p) {
 
@@ -395,23 +395,24 @@ strwordtok(char *buf, char **t)
 
             }
 
-            *d++ = ch;
+            *d = ch;
+            ++d;
 
             if (ch)
-                p++;
+                ++p;
 
             break;
 
         case '"':
             quoted = !quoted;
 
-            p++;
+            ++p;
 
             break;
 
         default:
             if (!quoted && xisspace(*p)) {
-                p++;
+                ++p;
                 goto done;
             }
 
@@ -421,7 +422,7 @@ strwordtok(char *buf, char **t)
     }
 
 done:
-    *d++ = '\0';
+    *d = '\0';
 
 error:
     *t = (char *) p;
@@ -107,7 +107,7 @@ whichPeer(const Ip::Address &from)
     debugs(15, 3, "whichPeer: from " << from);
 
     for (p = Config.peers; p; p = p->next) {
-        for (j = 0; j < p->n_addresses; j++) {
+        for (j = 0; j < p->n_addresses; ++j) {
             if (from == p->addresses[j] && from.GetPort() == p->icp.port) {
                 return p;
             }
@@ -271,7 +271,7 @@ neighborsCount(HttpRequest * request)
 
     for (p = Config.peers; p; p = p->next)
         if (peerWouldBePinged(p, request))
-            count++;
+            ++count;
 
     debugs(15, 3, "neighborsCount: " << count);
 
@@ -332,7 +332,7 @@ getRoundRobinParent(HttpRequest * request)
     }
 
     if (q)
-        q->rr_count++;
+        ++ q->rr_count;
 
     debugs(15, 3, HERE << "returning " << (q ? q->host : "NULL"));
 
@@ -612,7 +612,7 @@ neighborsUdpPing(HttpRequest * request,
         if (!peerWouldBePinged(p, request))
             continue;		/* next peer */
 
-        peers_pinged++;
+        ++peers_pinged;
 
         debugs(15, 4, "neighborsUdpPing: pinging peer " << p->host << " for '" << url << "'");
 
@@ -659,9 +659,9 @@ neighborsUdpPing(HttpRequest * request,
             }
         }
 
-        queries_sent++;
+        ++queries_sent;
 
-        p->stats.pings_sent++;
+        ++ p->stats.pings_sent;
 
         if (p->type == PEER_MULTICAST) {
             mcast_exprep += p->mcast.n_replies_expected;
@@ -670,10 +670,10 @@ neighborsUdpPing(HttpRequest * request,
             /* its alive, expect a reply from it */
 
             if (neighborType(p, request) == PEER_PARENT) {
-                parent_exprep++;
+                ++parent_exprep;
                 parent_timeout += p->stats.rtt;
             } else {
-                sibling_exprep++;
+                ++sibling_exprep;
                 sibling_timeout += p->stats.rtt;
             }
         } else {
@@ -807,7 +807,7 @@ neighborsDigestSelect(HttpRequest * request)
         if (lookup == LOOKUP_NONE)
             continue;
 
-        choice_count++;
+        ++choice_count;
 
         if (lookup == LOOKUP_MISS)
             continue;
@@ -822,7 +822,7 @@ neighborsDigestSelect(HttpRequest * request)
             best_rtt = p_rtt;
 
             if (p_rtt)		/* informative choice (aka educated guess) */
-                ichoice_count++;
+                ++ichoice_count;
 
             debugs(15, 4, "neighborsDigestSelect: peer " << p->host << " leads with rtt " << best_rtt);
         }
@@ -856,10 +856,10 @@ static void
 neighborAlive(peer * p, const MemObject * mem, const icp_common_t * header)
 {
     peerAlive(p);
-    p->stats.pings_acked++;
+    ++ p->stats.pings_acked;
 
     if ((icp_opcode) header->opcode <= ICP_END)
-        p->icp.counts[header->opcode]++;
+        ++ p->icp.counts[header->opcode];
 
     p->icp.version = (int) header->version;
 }
@@ -893,8 +893,8 @@ static void
 neighborAliveHtcp(peer * p, const MemObject * mem, const htcpReplyData * htcp)
 {
     peerAlive(p);
-    p->stats.pings_acked++;
-    p->htcp.counts[htcp->hit ? 1 : 0]++;
+    ++ p->stats.pings_acked;
+    ++ p->htcp.counts[htcp->hit ? 1 : 0];
     p->htcp.version = htcp->version;
 }
 
@@ -906,9 +906,9 @@ neighborCountIgnored(peer * p)
     if (p == NULL)
         return;
 
-    p->stats.ignored_replies++;
+    ++ p->stats.ignored_replies;
 
-    NLateReplies++;
+    ++NLateReplies;
 }
 
 static peer *non_peers = NULL;
@@ -939,7 +939,7 @@ neighborIgnoreNonPeer(const Ip::Address &from, icp_opcode opcode)
         non_peers = np;
     }
 
-    np->icp.counts[opcode]++;
+    ++ np->icp.counts[opcode];
 
     if (isPowTen(++np->stats.ignored_replies))
         debugs(15, 1, "WARNING: Ignored " << np->stats.ignored_replies << " replies from non-peer " << np->host);
@@ -1214,10 +1214,10 @@ peerDNSConfigure(const ipcache_addrs *ia, const DnsLookupDetails &, void *data)
 
     p->tcp_up = p->connect_fail_limit;
 
-    for (j = 0; j < (int) ia->count && j < PEER_MAX_ADDRESSES; j++) {
+    for (j = 0; j < (int) ia->count && j < PEER_MAX_ADDRESSES; ++j) {
         p->addresses[j] = ia->in_addrs[j];
         debugs(15, 2, "--> IP address #" << j << ": " << p->addresses[j]);
-        p->n_addresses++;
+        ++ p->n_addresses;
     }
 
     p->in_addr.SetEmpty();
@@ -1311,13 +1311,13 @@ peerProbeConnect(peer * p)
         return ret;/* don't probe to often */
 
     /* for each IP address of this peer. find one that we can connect to and probe it. */
-    for (int i = 0; i < p->n_addresses; i++) {
+    for (int i = 0; i < p->n_addresses; ++i) {
         Comm::ConnectionPointer conn = new Comm::Connection;
         conn->remote = p->addresses[i];
         conn->remote.SetPort(p->http_port);
         getOutgoingAddress(NULL, conn);
 
-        p->testing_now++;
+        ++ p->testing_now;
 
         AsyncCall::Pointer call = commCbCall(15,3, "peerProbeConnectDone", CommConnectCbPtrFun(peerProbeConnectDone, p));
         Comm::ConnOpener *cs = new Comm::ConnOpener(conn, call, ctimeout);
@@ -1439,7 +1439,7 @@ peerCountHandleIcpReply(peer * p, peer_t type, AnyP::ProtocolType proto, void *h
     assert(proto == AnyP::PROTO_ICP);
     assert(fake);
     assert(mem);
-    psstate->ping.n_recv++;
+    ++ psstate->ping.n_recv;
     rtt_av_factor = RTT_AV_FACTOR;
 
     if (p->options.weighted_roundrobin)
@@ -1602,7 +1602,7 @@ dump_peers(StoreEntry * sentry, peer * peers)
         storeAppendPrintf(sentry, "Flags      :");
         dump_peer_options(sentry, e);
 
-        for (i = 0; i < e->n_addresses; i++) {
+        for (i = 0; i < e->n_addresses; ++i) {
             storeAppendPrintf(sentry, "Address[%d] : %s\n", i,
                               e->addresses[i].NtoA(ntoabuf,MAX_IPSTRLEN) );
         }
@@ -99,7 +99,7 @@ IdleConnList::removeAt(int index)
         return false;
 
     // shuffle the remaining entries to fill the new gap.
-    for (; index < size_ - 1; index++)
+    for (; index < size_ - 1; ++index)
         theList_[index] = theList_[index + 1];
     theList_[--size_] = NULL;
 
@@ -136,7 +136,7 @@ IdleConnList::closeN(size_t n)
 
         size_t index;
         // ensure the first N entries are closed
-        for (index = 0; index < n; index++) {
+        for (index = 0; index < n; ++index) {
             const Comm::ConnectionPointer conn = theList_[index];
             theList_[index] = NULL;
             clearHandlers(conn);
@@ -145,7 +145,7 @@ IdleConnList::closeN(size_t n)
                 parent_->noteConnectionRemoved();
         }
         // shuffle the list N down.
-        for (index = 0; index < (size_t)size_ - n; index++) {
+        for (index = 0; index < (size_t)size_ - n; ++index) {
             theList_[index] = theList_[index + n];
         }
         // ensure the last N entries are unset
@@ -177,7 +177,7 @@ IdleConnList::push(const Comm::ConnectionPointer &conn)
         capacity_ <<= 1;
         const Comm::ConnectionPointer *oldList = theList_;
         theList_ = new Comm::ConnectionPointer[capacity_];
-        for (int index = 0; index < size_; index++)
+        for (int index = 0; index < size_; ++index)
             theList_[index] = oldList[index];
 
         delete[] oldList;
@@ -349,7 +349,7 @@ PconnPool::dumpHist(StoreEntry * e) const
                       "\t----  ---------\n",
                       descr);
 
-    for (int i = 0; i < PCONN_HIST_SZ; i++) {
+    for (int i = 0; i < PCONN_HIST_SZ; ++i) {
         if (hist[i] == 0)
             continue;
 
@@ -365,7 +365,8 @@ PconnPool::dumpHash(StoreEntry *e) const
 
     int i = 0;
     for (hash_link *walker = hid->next; walker; walker = hash_next(hid)) {
-        storeAppendPrintf(e, "\t item %5d: %s\n", i++, (char *)(walker->key));
+        storeAppendPrintf(e, "\t item %5d: %s\n", i, (char *)(walker->key));
+        ++i;
     }
 }
 
@@ -377,7 +378,7 @@ PconnPool::PconnPool(const char *aDescr) : table(NULL), descr(aDescr),
     int i;
     table = hash_create((HASHCMP *) strcmp, 229, hash_string);
 
-    for (i = 0; i < PCONN_HIST_SZ; i++)
+    for (i = 0; i < PCONN_HIST_SZ; ++i)
         hist[i] = 0;
 
     PconnModule::GetInstance()->add(this);
@@ -465,7 +466,7 @@ PconnPool::noteUses(int uses)
     if (uses >= PCONN_HIST_SZ)
         uses = PCONN_HIST_SZ - 1;
 
-    hist[uses]++;
+    ++hist[uses];
 }
 
 /* ========== PconnModule ============================================ */
@@ -504,15 +505,15 @@ PconnModule::add(PconnPool *aPool)
 {
     assert(poolCount < MAX_NUM_PCONN_POOLS);
     *(pools+poolCount) = aPool;
-    poolCount++;
+    ++poolCount;
 }
 
 void
 PconnModule::dump(StoreEntry *e)
 {
     int i;
 
-    for (i = 0; i < poolCount; i++) {
+    for (i = 0; i < poolCount; ++i) {
         storeAppendPrintf(e, "\n Pool %d Stats\n", i);
         (*(pools+i))->dumpHist(e);
         storeAppendPrintf(e, "\n Pool %d Hash Table\n",i);
@@ -327,7 +327,7 @@ extern "C" {
                 krb5_kt_default_name(kparam.context, buf, KT_PATH_MAX);
                 p = strchr(buf, ':');
                 if (p)
-                    p++;
+                    ++p;
                 if (keytab_filename)
                     xfree(keytab_filename);
                 keytab_filename = xstrdup(p ? p : buf);
@@ -244,7 +244,7 @@ peerSelectDnsPaths(ps_state *psstate)
         debugs(44, 2, "Found sources for '" << psstate->entry->url() << "'");
         debugs(44, 2, "  always_direct = " << psstate->always_direct);
         debugs(44, 2, "   never_direct = " << psstate->never_direct);
-        for (size_t i = 0; i < psstate->paths->size(); i++) {
+        for (size_t i = 0; i < psstate->paths->size(); ++i) {
             if ((*psstate->paths)[i]->peerType == HIER_DIRECT)
                 debugs(44, 2, "         DIRECT = " << (*psstate->paths)[i]);
             else
@@ -279,7 +279,7 @@ peerSelectDnsResults(const ipcache_addrs *ia, const DnsLookupDetails &details, v
 
         // loop over each result address, adding to the possible destinations.
         int ip = ia->cur;
-        for (int n = 0; n < ia->count; n++, ip++) {
+        for (int n = 0; n < ia->count; ++n, ++ip) {
             Comm::ConnectionPointer p;
 
             if (ip >= ia->count) ip = 0; // looped back to zero.
@@ -700,7 +700,7 @@ peerPingTimeout(void *data)
         return;
     }
 
-    PeerStats.timeouts++;
+    ++PeerStats.timeouts;
     psstate->ping.timedout = 1;
     peerSelectFoo(psstate);
 }
@@ -768,7 +768,7 @@ peerHandleIcpReply(peer * p, peer_t type, icp_common_t * header, void *data)
 
 #endif
 
-    psstate->ping.n_recv++;
+    ++ psstate->ping.n_recv;
 
     if (op == ICP_MISS || op == ICP_DECHO) {
         if (type == PEER_PARENT)
@@ -794,7 +794,7 @@ peerHandleHtcpReply(peer * p, peer_t type, htcpReplyData * htcp, void *data)
     debugs(44, 3, "peerHandleHtcpReply: " <<
            (htcp->hit ? "HIT" : "MISS") << " " <<
            psstate->entry->url()  );
-    psstate->ping.n_recv++;
+    ++ psstate->ping.n_recv;
 
     if (htcp->hit) {
         psstate->hit = p;
@@ -66,7 +66,7 @@ peerSourceHashInit(void)
     char *t;
     /* Clean up */
 
-    for (k = 0; k < n_sourcehash_peers; k++) {
+    for (k = 0; k < n_sourcehash_peers; ++k) {
         cbdataReferenceDone(sourcehash_peers[k]);
     }
 
@@ -83,7 +83,7 @@ peerSourceHashInit(void)
         if (p->weight == 0)
             continue;
 
-        n_sourcehash_peers++;
+        ++n_sourcehash_peers;
 
         W += p->weight;
     }
@@ -106,7 +106,7 @@ peerSourceHashInit(void)
         /* calculate this peers hash */
         p->sourcehash.hash = 0;
 
-        for (t = p->name; *t != 0; t++)
+        for (t = p->name; *t != 0; ++t)
             p->sourcehash.hash += ROTATE_LEFT(p->sourcehash.hash, 19) + (unsigned int) *t;
 
         p->sourcehash.hash += p->sourcehash.hash * 0x62531965;
@@ -142,7 +142,7 @@ peerSourceHashInit(void)
 
     X_last = 0.0;		/* Empty X_0, nullifies the first pow statement */
 
-    for (k = 1; k <= K; k++) {
+    for (k = 1; k <= K; ++k) {
         double Kk1 = (double) (K - k + 1);
         p = sourcehash_peers[k - 1];
         p->sourcehash.load_multiplier = (Kk1 * (p->sourcehash.load_factor - P_last)) / Xn;
@@ -183,11 +183,11 @@ peerSourceHashSelectParent(HttpRequest * request)
     /* calculate hash key */
     debugs(39, 2, "peerSourceHashSelectParent: Calculating hash for " << key);
 
-    for (c = key; *c != 0; c++)
+    for (c = key; *c != 0; ++c)
         user_hash += ROTATE_LEFT(user_hash, 19) + *c;
 
     /* select peer */
-    for (k = 0; k < n_sourcehash_peers; k++) {
+    for (k = 0; k < n_sourcehash_peers; ++k) {
         tp = sourcehash_peers[k];
         combined_hash = (user_hash ^ tp->sourcehash.hash);
         combined_hash += combined_hash * 0x62531965;
@@ -70,7 +70,7 @@ peerUserHashInit(void)
     char *t;
     /* Clean up */
 
-    for (k = 0; k < n_userhash_peers; k++) {
+    for (k = 0; k < n_userhash_peers; ++k) {
         cbdataReferenceDone(userhash_peers[k]);
     }
 
@@ -90,7 +90,7 @@ peerUserHashInit(void)
         if (p->weight == 0)
             continue;
 
-        n_userhash_peers++;
+        ++n_userhash_peers;
 
         W += p->weight;
     }
@@ -111,7 +111,7 @@ peerUserHashInit(void)
         /* calculate this peers hash */
         p->userhash.hash = 0;
 
-        for (t = p->name; *t != 0; t++)
+        for (t = p->name; *t != 0; ++t)
             p->userhash.hash += ROTATE_LEFT(p->userhash.hash, 19) + (unsigned int) *t;
 
         p->userhash.hash += p->userhash.hash * 0x62531965;
@@ -147,7 +147,7 @@ peerUserHashInit(void)
 
     X_last = 0.0;		/* Empty X_0, nullifies the first pow statement */
 
-    for (k = 1; k <= K; k++) {
+    for (k = 1; k <= K; ++k) {
         double Kk1 = (double) (K - k + 1);
         p = userhash_peers[k - 1];
         p->userhash.load_multiplier = (Kk1 * (p->userhash.load_factor - P_last)) / Xn;
@@ -191,11 +191,11 @@ peerUserHashSelectParent(HttpRequest * request)
     /* calculate hash key */
     debugs(39, 2, "peerUserHashSelectParent: Calculating hash for " << key);
 
-    for (c = key; *c != 0; c++)
+    for (c = key; *c != 0; ++c)
         user_hash += ROTATE_LEFT(user_hash, 19) + *c;
 
     /* select peer */
-    for (k = 0; k < n_userhash_peers; k++) {
+    for (k = 0; k < n_userhash_peers; ++k) {
         tp = userhash_peers[k];
         combined_hash = (user_hash ^ tp->userhash.hash);
         combined_hash += combined_hash * 0x62531965;
@@ -89,7 +89,7 @@ main(int argc, char *argv[])
     const char *logfile;
     char ip[4];
 
-    for (len = 0; len < 32; len++) {
+    for (len = 0; len < 32; ++len) {
         signal(len, sig_handle);
     }
 
@@ -135,7 +135,7 @@ redirectStart(ClientHttpRequest * http, RH * handler, void *data)
 
     if (Config.onoff.redirector_bypass && redirectors->stats.queue_size) {
         /* Skip redirector if there is one request queued */
-        n_bypassed++;
+        ++n_bypassed;
         handler(data, NULL);
         return;
     }
@@ -443,8 +443,8 @@ refreshIsCachable(const StoreEntry * entry)
      * be refreshed.
      */
     int reason = refreshCheck(entry, NULL, Config.minimum_expiry_time);
-    refreshCounts[rcStore].total++;
-    refreshCounts[rcStore].status[reason]++;
+    ++ refreshCounts[rcStore].total;
+    ++ refreshCounts[rcStore].status[reason];
 
     if (reason < STALE_MUST_REVALIDATE)
         /* Does not need refresh. This is certainly cachable */
@@ -491,8 +491,8 @@ int
 refreshCheckHTTP(const StoreEntry * entry, HttpRequest * request)
 {
     int reason = refreshCheck(entry, request, 0);
-    refreshCounts[rcHTTP].total++;
-    refreshCounts[rcHTTP].status[reason]++;
+    ++ refreshCounts[rcHTTP].total;
+    ++ refreshCounts[rcHTTP].status[reason];
     request->flags.stale_if_hit = refreshIsStaleIfHit(reason);
     return (Config.onoff.offline || reason < 200) ? 0 : 1;
 }
@@ -501,8 +501,8 @@ int
 refreshCheckICP(const StoreEntry * entry, HttpRequest * request)
 {
     int reason = refreshCheck(entry, request, 30);
-    refreshCounts[rcICP].total++;
-    refreshCounts[rcICP].status[reason]++;
+    ++ refreshCounts[rcICP].total;
+    ++ refreshCounts[rcICP].status[reason];
     return (reason < 200) ? 0 : 1;
 }
 
@@ -511,8 +511,8 @@ int
 refreshCheckHTCP(const StoreEntry * entry, HttpRequest * request)
 {
     int reason = refreshCheck(entry, request, 10);
-    refreshCounts[rcHTCP].total++;
-    refreshCounts[rcHTCP].status[reason]++;
+    ++ refreshCounts[rcHTCP].total;
+    ++ refreshCounts[rcHTCP].status[reason];
     return (reason < 200) ? 0 : 1;
 }
 
@@ -525,8 +525,8 @@ refreshCheckDigest(const StoreEntry * entry, time_t delta)
     int reason = refreshCheck(entry,
                               entry->mem_obj ? entry->mem_obj->request : NULL,
                               delta);
-    refreshCounts[rcCDigest].total++;
-    refreshCounts[rcCDigest].status[reason]++;
+    ++ refreshCounts[rcCDigest].total;
+    ++ refreshCounts[rcCDigest].status[reason];
     return (reason < 200) ? 0 : 1;
 }
 
@@ -210,7 +210,7 @@ snmp_meshPtblFn(variable_list * Var, snint * ErrP)
     *ErrP = SNMP_ERR_NOERROR;
 
     u_int index = Var->name[LEN_SQ_MESH + 3] ;
-    for (p = Config.peers; p != NULL; p = p->next, cnt++) {
+    for (p = Config.peers; p != NULL; p = p->next, ++cnt) {
         if (p->index == index) {
             laddr = p->in_addr ;
             break;
@@ -497,7 +497,7 @@ snmpAgentResponse(struct snmp_pdu *PDU) {
                 oid *NextOidName = NULL;
                 snint NextOidNameLen = 0;
 
-                index++;
+                ++index;
 
                 if (get_next)
                     ParseFn = snmpTreeNext(VarPtr->name, VarPtr->name_length, &NextOidName, &NextOidNameLen);
@@ -568,11 +568,11 @@ snmpTreeGet(oid * Current, snint CurrentLen)
     mibTreeEntry = mib_tree_head;
 
     if (Current[count] == mibTreeEntry->name[count]) {
-        count++;
+        ++count;
 
         while ((mibTreeEntry) && (count < CurrentLen) && (!mibTreeEntry->parsefunction)) {
             mibTreeEntry = snmpTreeEntry(Current[count], count, mibTreeEntry);
-            count++;
+            ++count;
         }
     }
 
@@ -594,13 +594,13 @@ snmpAggrType(oid* Current, snint CurrentLen)
     int count = 0;
 
     if (Current[count] == mibTreeEntry->name[count]) {
-        count++;
+        ++count;
 
         while (mibTreeEntry != NULL && count < CurrentLen) {
             mibTreeEntry = snmpTreeEntry(Current[count], count, mibTreeEntry);
             if (mibTreeEntry != NULL)
                 type = mibTreeEntry->aggrType;
-            count++;
+            ++count;
         }
     }
 
@@ -622,7 +622,7 @@ snmpTreeNext(oid * Current, snint CurrentLen, oid ** Next, snint * NextLen)
     mibTreeEntry = mib_tree_head;
 
     if (Current[count] == mibTreeEntry->name[count]) {
-        count++;
+        ++count;
 
         while ((mibTreeEntry) && (count < CurrentLen) && (!mibTreeEntry->parsefunction)) {
             mib_tree_entry *nextmibTreeEntry = snmpTreeEntry(Current[count], count, mibTreeEntry);
@@ -632,7 +632,7 @@ snmpTreeNext(oid * Current, snint CurrentLen, oid ** Next, snint * NextLen)
             else
                 mibTreeEntry = nextmibTreeEntry;
 
-            count++;
+            ++count;
         }
         debugs(49, 5, "snmpTreeNext: Recursed down to requested object");
     } else {
@@ -659,7 +659,7 @@ snmpTreeNext(oid * Current, snint CurrentLen, oid ** Next, snint * NextLen)
         if (nextoid) {
             debugs(49, 5, "snmpTreeNext: Next OID found for sibling" << nextoid );
             mibTreeEntry = nextoid;
-            count++;
+            ++count;
         } else {
             debugs(49, 5, "snmpTreeNext: Attempting to recurse up for next object");
 
@@ -728,7 +728,7 @@ time_Inst(oid * name, snint * len, mib_tree_entry * current, oid_ParseFn ** Fn)
         identifier = name[*len - 1];
 
         while ((loop < TIME_INDEX_LEN) && (identifier != index[loop]))
-            loop++;
+            ++loop;
 
         if (loop < (TIME_INDEX_LEN - 1)) {
             instance = (oid *)xmalloc(sizeof(name) * (*len));
@@ -862,7 +862,7 @@ snmpTreeSiblingEntry(oid entry, snint len, mib_tree_entry * current)
             next = current->leaves[count];
         }
 
-        count++;
+        ++count;
     }
 
     /* Exactly the sibling on right */
@@ -889,7 +889,7 @@ snmpTreeEntry(oid entry, snint len, mib_tree_entry * current)
             next = current->leaves[count];
         }
 
-        count++;
+        ++count;
     }
 
     return (next);
@@ -902,7 +902,7 @@ snmpAddNodeChild(mib_tree_entry *entry, mib_tree_entry *child)
     entry->leaves = (mib_tree_entry **)xrealloc(entry->leaves, sizeof(mib_tree_entry *) * (entry->children + 1));
     entry->leaves[entry->children] = child;
     entry->leaves[entry->children]->parent = entry;
-    entry->children++;
+    ++ entry->children;
 }
 
 mib_tree_entry *
@@ -931,7 +931,7 @@ snmpLookupNodeStr(mib_tree_entry *root, const char *str)
     while (r < namelen) {
 
         /* Find the child node which matches this */
-        for (i = 0; i < e->children && e->leaves[i]->name[r] != name[r]; i++) ; // seek-loop
+        for (i = 0; i < e->children && e->leaves[i]->name[r] != name[r]; ++i) ; // seek-loop
 
         /* Are we pointing to that node? */
         if (i >= e->children)
@@ -940,7 +940,7 @@ snmpLookupNodeStr(mib_tree_entry *root, const char *str)
 
         /* Skip to that node! */
         e = e->leaves[i];
-        r++;
+        ++r;
     }
 
     xfree(name);
@@ -962,7 +962,7 @@ snmpCreateOidFromStr(const char *str, oid **name, int *nl)
     while ( (p = strsep(&s_, delim)) != NULL) {
         *name = (oid*)xrealloc(*name, sizeof(oid) * ((*nl) + 1));
         (*name)[*nl] = atoi(p);
-        (*nl)++;
+        ++(*nl);
     }
 
     xfree(s);
@@ -1030,7 +1030,7 @@ snmpAddNode(oid * name, int len, oid_ParseFn * parsefunction, instance_Fn * inst
     if (children > 0) {
         entry->leaves = (mib_tree_entry **)xmalloc(sizeof(mib_tree_entry *) * children);
 
-        for (loop = 0; loop < children; loop++) {
+        for (loop = 0; loop < children; ++loop) {
             entry->leaves[loop] = va_arg(args, mib_tree_entry *);
             entry->leaves[loop]->parent = entry;
         }
@@ -1054,7 +1054,7 @@ snmpCreateOid(int length,...)
     new_oid = (oid *)xmalloc(sizeof(oid) * length);
 
     if (length > 0) {
-        for (loop = 0; loop < length; loop++) {
+        for (loop = 0; loop < length; ++loop) {
             new_oid[loop] = va_arg(args, int);
         }
     }
@@ -1073,7 +1073,7 @@ snmpDebugOid(oid * Name, snint Len, MemBuf &outbuf)
     if (outbuf.isNull())
         outbuf.init(16, MAX_IPSTRLEN);
 
-    for (x = 0; x < Len; x++) {
+    for (x = 0; x < Len; ++x) {
         size_t bytes = snprintf(mbuf, sizeof(mbuf), ".%u", (unsigned int) Name[x]);
         outbuf.append(mbuf, bytes);
     }
@@ -1111,9 +1111,10 @@ addr2oid(Ip::Address &addr, oid * Dest)
         addr.GetInAddr(i6addr);
         cp = (u_char *) &i6addr;
     }
-    for ( i=0 ; i < size ; i++) {
+    for ( i=0 ; i < size ; ++i) {
         // OID's are in network order
-        Dest[i] = *cp++;
+        Dest[i] = *cp;
+        ++cp;
     }
     MemBuf tmp;
     debugs(49, 7, "addr2oid: Dest : " << snmpDebugOid(Dest, size, tmp));
@@ -1138,7 +1139,7 @@ oid2addr(oid * id, Ip::Address &addr, u_int size)
         cp = (u_char *) &(i6addr);
     MemBuf tmp;
     debugs(49, 7, "oid2addr: id : " << snmpDebugOid(id, size, tmp) );
-    for (i=0 ; i<size; i++) {
+    for (i=0 ; i<size; ++i) {
         cp[i] = id[i];
     }
     if ( size == sizeof(struct in_addr) )
@@ -215,19 +215,19 @@ GetIoStats(Mgr::IoActionData& stats)
 
     stats.http_reads = IOStats.Http.reads;
 
-    for (i = 0; i < _iostats::histSize; i++) {
+    for (i = 0; i < _iostats::histSize; ++i) {
         stats.http_read_hist[i] = IOStats.Http.read_hist[i];
     }
 
     stats.ftp_reads = IOStats.Ftp.reads;
 
-    for (i = 0; i < _iostats::histSize; i++) {
+    for (i = 0; i < _iostats::histSize; ++i) {
         stats.ftp_read_hist[i] = IOStats.Ftp.read_hist[i];
     }
 
     stats.gopher_reads = IOStats.Gopher.reads;
 
-    for (i = 0; i < _iostats::histSize; i++) {
+    for (i = 0; i < _iostats::histSize; ++i) {
         stats.gopher_read_hist[i] = IOStats.Gopher.read_hist[i];
     }
 }
@@ -241,7 +241,7 @@ DumpIoStats(Mgr::IoActionData& stats, StoreEntry* sentry)
     storeAppendPrintf(sentry, "number of reads: %.0f\n", stats.http_reads);
     storeAppendPrintf(sentry, "Read Histogram:\n");
 
-    for (i = 0; i < _iostats::histSize; i++) {
+    for (i = 0; i < _iostats::histSize; ++i) {
         storeAppendPrintf(sentry, "%5d-%5d: %9.0f %2.0f%%\n",
                           i ? (1 << (i - 1)) + 1 : 1,
                           1 << i,
@@ -254,7 +254,7 @@ DumpIoStats(Mgr::IoActionData& stats, StoreEntry* sentry)
     storeAppendPrintf(sentry, "number of reads: %.0f\n", stats.ftp_reads);
     storeAppendPrintf(sentry, "Read Histogram:\n");
 
-    for (i = 0; i < _iostats::histSize; i++) {
+    for (i = 0; i < _iostats::histSize; ++i) {
         storeAppendPrintf(sentry, "%5d-%5d: %9.0f %2.0f%%\n",
                           i ? (1 << (i - 1)) + 1 : 1,
                           1 << i,
@@ -267,7 +267,7 @@ DumpIoStats(Mgr::IoActionData& stats, StoreEntry* sentry)
     storeAppendPrintf(sentry, "number of reads: %.0f\n", stats.gopher_reads);
     storeAppendPrintf(sentry, "Read Histogram:\n");
 
-    for (i = 0; i < _iostats::histSize; i++) {
+    for (i = 0; i < _iostats::histSize; ++i) {
         storeAppendPrintf(sentry, "%5d-%5d: %9.0f %2.0f%%\n",
                           i ? (1 << (i - 1)) + 1 : 1,
                           1 << i,
@@ -1385,10 +1385,10 @@ statInit(void)
     int i;
     debugs(18, 5, "statInit: Initializing...");
 
-    for (i = 0; i < N_COUNT_HIST; i++)
+    for (i = 0; i < N_COUNT_HIST; ++i)
         statCountersInit(&CountHist[i]);
 
-    for (i = 0; i < N_COUNT_HOUR_HIST; i++)
+    for (i = 0; i < N_COUNT_HOUR_HIST; ++i)
         statCountersInit(&CountHourHist[i]);
 
     statCountersInit(&statCounter);
@@ -1419,7 +1419,7 @@ statAvgTick(void *notused)
     statCountersClean(CountHist + N_COUNT_HIST - 1);
     memmove(p, t, (N_COUNT_HIST - 1) * sizeof(StatCounters));
     statCountersCopy(t, c);
-    NCountHist++;
+    ++NCountHist;
 
     if ((NCountHist % COUNT_INTERVAL) == 0) {
         /* we have an hours worth of readings.  store previous hour */
@@ -1429,7 +1429,7 @@ statAvgTick(void *notused)
         statCountersClean(CountHourHist + N_COUNT_HOUR_HIST - 1);
         memmove(p2, t2, (N_COUNT_HOUR_HIST - 1) * sizeof(StatCounters));
         statCountersCopy(t2, c2);
-        NCountHourHist++;
+        ++NCountHourHist;
     }
 
     if (Config.warnings.high_rptm > 0) {
@@ -1795,10 +1795,10 @@ statFreeMemory(void)
 {
     int i;
 
-    for (i = 0; i < N_COUNT_HIST; i++)
+    for (i = 0; i < N_COUNT_HIST; ++i)
         statCountersClean(&CountHist[i]);
 
-    for (i = 0; i < N_COUNT_HOUR_HIST; i++)
+    for (i = 0; i < N_COUNT_HOUR_HIST; ++i)
         statCountersClean(&CountHourHist[i]);
 }
 
@@ -2081,7 +2081,7 @@ statClientRequests(StoreEntry * s)
  */
 
 #define GRAPH_PER_MIN(Y) \
-    for (i=0;i<(N_COUNT_HIST-2);i++) { \
+    for (i=0;i<(N_COUNT_HIST-2);++i) { \
 	dt = tvSubDsec(CountHist[i+1].timestamp, CountHist[i].timestamp); \
 	if (dt <= 0.0) \
 	    break; \
@@ -2091,7 +2091,7 @@ statClientRequests(StoreEntry * s)
     }
 
 #define GRAPH_PER_HOUR(Y) \
-    for (i=0;i<(N_COUNT_HOUR_HIST-2);i++) { \
+    for (i=0;i<(N_COUNT_HOUR_HIST-2);++i) { \
 	dt = tvSubDsec(CountHourHist[i+1].timestamp, CountHourHist[i].timestamp); \
 	if (dt <= 0.0) \
 	    break; \
@@ -514,7 +514,7 @@ void
 
 StoreEntry::lock()
 {
-    lock_count++;
+    ++lock_count;
     debugs(20, 3, "StoreEntry::lock: key '" << getMD5Text() <<"' count=" <<
            lock_count  );
     lastref = squid_curtime;
@@ -974,34 +974,34 @@ StoreEntry::checkCachable()
 
     if (mem_obj->method != METHOD_GET) {
         debugs(20, 2, "StoreEntry::checkCachable: NO: non-GET method");
-        store_check_cachable_hist.no.non_get++;
+        ++store_check_cachable_hist.no.non_get;
     } else
 #endif
         if (store_status == STORE_OK && EBIT_TEST(flags, ENTRY_BAD_LENGTH)) {
             debugs(20, 2, "StoreEntry::checkCachable: NO: wrong content-length");
-            store_check_cachable_hist.no.wrong_content_length++;
+            ++store_check_cachable_hist.no.wrong_content_length;
         } else if (!EBIT_TEST(flags, ENTRY_CACHABLE)) {
             debugs(20, 2, "StoreEntry::checkCachable: NO: not cachable");
-            store_check_cachable_hist.no.not_entry_cachable++;
+            ++store_check_cachable_hist.no.not_entry_cachable;
         } else if (EBIT_TEST(flags, ENTRY_NEGCACHED)) {
             debugs(20, 3, "StoreEntry::checkCachable: NO: negative cached");
-            store_check_cachable_hist.no.negative_cached++;
+            ++store_check_cachable_hist.no.negative_cached;
             return 0;           /* avoid release call below */
         } else if ((getReply()->content_length > 0 &&
                     getReply()->content_length
                     > Config.Store.maxObjectSize) ||
                    mem_obj->endOffset() > Config.Store.maxObjectSize) {
             debugs(20, 2, "StoreEntry::checkCachable: NO: too big");
-            store_check_cachable_hist.no.too_big++;
+            ++store_check_cachable_hist.no.too_big;
         } else if (getReply()->content_length > Config.Store.maxObjectSize) {
             debugs(20, 2, "StoreEntry::checkCachable: NO: too big");
-            store_check_cachable_hist.no.too_big++;
+            ++store_check_cachable_hist.no.too_big;
         } else if (checkTooSmall()) {
             debugs(20, 2, "StoreEntry::checkCachable: NO: too small");
-            store_check_cachable_hist.no.too_small++;
+            ++store_check_cachable_hist.no.too_small;
         } else if (EBIT_TEST(flags, KEY_PRIVATE)) {
             debugs(20, 3, "StoreEntry::checkCachable: NO: private key");
-            store_check_cachable_hist.no.private_key++;
+            ++store_check_cachable_hist.no.private_key;
         } else if (swap_status != SWAPOUT_NONE) {
             /*
              * here we checked the swap_status because the remaining
@@ -1011,12 +1011,12 @@ StoreEntry::checkCachable()
             return 1;
         } else if (storeTooManyDiskFilesOpen()) {
             debugs(20, 2, "StoreEntry::checkCachable: NO: too many disk files open");
-            store_check_cachable_hist.no.too_many_open_files++;
+            ++store_check_cachable_hist.no.too_many_open_files;
         } else if (fdNFree() < RESERVED_FD) {
             debugs(20, 2, "StoreEntry::checkCachable: NO: too many FD's open");
-            store_check_cachable_hist.no.too_many_open_fds++;
+            ++store_check_cachable_hist.no.too_many_open_fds;
         } else {
-            store_check_cachable_hist.yes.Default++;
+            ++store_check_cachable_hist.yes.Default;
             return 1;
         }
 
@@ -1107,7 +1107,7 @@ StoreEntry::complete()
 void
 StoreEntry::abort()
 {
-    statCounter.aborted_requests++;
+    ++statCounter.aborted_requests;
     assert(store_status == STORE_PENDING);
     assert(mem_obj != NULL);
     debugs(20, 6, "storeAbort: " << getMD5Text());
@@ -1187,7 +1187,7 @@ storeGetMemSpace(int size)
 
     while ((e = walker->Next(walker))) {
         e->purgeMem();
-        released++;
+        ++released;
 
         if (mem_node::InUseCount() + pages_needed < store_pages_max)
             break;
@@ -1276,7 +1276,7 @@ StoreEntry::release()
              * Fake a call to StoreEntry->lock()  When rebuilding is done,
              * we'll just call StoreEntry->unlock() on these.
              */
-            lock_count++;
+            ++lock_count;
             setReleaseFlag();
             LateReleaseStack.push_back(this);
         } else {
@@ -1315,7 +1315,7 @@ storeLateRelease(void *unused)
         return;
     }
 
-    for (i = 0; i < 10; i++) {
+    for (i = 0; i < 10; ++i) {
         e = LateReleaseStack.count ? LateReleaseStack.pop() : NULL;
 
         if (e == NULL) {
@@ -1325,7 +1325,7 @@ storeLateRelease(void *unused)
         }
 
         e->unlock();
-        n++;
+        ++n;
     }
 
     eventAdd("storeLateRelease", storeLateRelease, NULL, 0.0, 1);
@@ -1644,7 +1644,7 @@ StoreEntry::setMemStatus(mem_status_t new_status)
             debugs(20, 4, "StoreEntry::setMemStatus: inserted mem node " << mem_obj->url << " key: " << getMD5Text());
         }
 
-        hot_obj_count++; // TODO: maintain for the shared hot cache as well
+        ++hot_obj_count; // TODO: maintain for the shared hot cache as well
     } else {
         if (EBIT_TEST(flags, ENTRY_SPECIAL)) {
             debugs(20, 4, "StoreEntry::setMemStatus: special entry " << mem_obj->url);
@@ -1761,7 +1761,7 @@ storeReplAdd(const char *type, REMOVALPOLICYCREATE * create)
     int i;
 
     /* find the number of currently known repl types */
-    for (i = 0; storerepl_list && storerepl_list[i].typestr; i++) {
+    for (i = 0; storerepl_list && storerepl_list[i].typestr; ++i) {
         if (strcmp(storerepl_list[i].typestr, type) == 0) {
             debugs(20, 1, "WARNING: Trying to load store replacement policy " << type << " twice.");
             return;
@@ -1786,7 +1786,7 @@ createRemovalPolicy(RemovalPolicySettings * settings)
 {
     storerepl_entry_t *r;
 
-    for (r = storerepl_list; r && r->typestr; r++) {
+    for (r = storerepl_list; r && r->typestr; ++r) {
         if (strcmp(r->typestr, settings->type) == 0)
             return r->create(settings->args);
     }
@@ -190,7 +190,7 @@ store_client::store_client(StoreEntry *e) : entry (e)
 {
     cmp_offset = 0;
     flags.disk_io_pending = 0;
-    entry->refcount++;
+    ++ entry->refcount;
 
     if (getType() == STORE_DISK_CLIENT)
         /* assert we'll be able to get the data we want */
@@ -709,7 +709,7 @@ storeUnregister(store_client * sc, StoreEntry * e, void *data)
     if (sc->swapin_sio != NULL) {
         storeClose(sc->swapin_sio, StoreIOState::readerDone);
         sc->swapin_sio = NULL;
-        statCounter.swap.ins++;
+        ++statCounter.swap.ins;
     }
 
     if (sc->_callback.pending()) {
@@ -758,7 +758,8 @@ StoreEntry::invokeHandlers()
     for (node = mem_obj->clients.head; node; node = nx) {
         sc = (store_client *)node->data;
         nx = node->next;
-        debugs(90, 3, "StoreEntry::InvokeHandlers: checking client #" << i++  );
+        debugs(90, 3, "StoreEntry::InvokeHandlers: checking client #" << i  );
+        ++i;
 
         if (!sc->_callback.pending())
             continue;
@@ -165,10 +165,10 @@ storeDigestDel(const StoreEntry * entry)
 
     if (!EBIT_TEST(entry->flags, KEY_PRIVATE)) {
         if (!cacheDigestTest(store_digest,  (const cache_key *)entry->key)) {
-            sd_stats.del_lost_count++;
+            ++sd_stats.del_lost_count;
             debugs(71, 6, "storeDigestDel: lost entry, key: " << entry->getMD5Text() << " url: " << entry->url()  );
         } else {
-            sd_stats.del_count++;
+            ++sd_stats.del_count;
             cacheDigestDel(store_digest,  (const cache_key *)entry->key);
             debugs(71, 6, "storeDigestDel: deled entry, key: " << entry->getMD5Text());
         }
@@ -275,19 +275,19 @@ storeDigestAdd(const StoreEntry * entry)
     assert(entry && store_digest);
 
     if (storeDigestAddable(entry)) {
-        sd_stats.add_count++;
+        ++sd_stats.add_count;
 
         if (cacheDigestTest(store_digest, (const cache_key *)entry->key))
-            sd_stats.add_coll_count++;
+            ++sd_stats.add_coll_count;
 
         cacheDigestAdd(store_digest,  (const cache_key *)entry->key);
 
         debugs(71, 6, "storeDigestAdd: added entry, key: " << entry->getMD5Text());
     } else {
-        sd_stats.rej_count++;
+        ++sd_stats.rej_count;
 
         if (cacheDigestTest(store_digest,  (const cache_key *)entry->key))
-            sd_stats.rej_coll_count++;
+            ++sd_stats.rej_coll_count;
     }
 }
 
@@ -337,7 +337,7 @@ storeDigestRebuildFinish(void)
 {
     assert(sd_state.rebuild_lock);
     sd_state.rebuild_lock = 0;
-    sd_state.rebuild_count++;
+    ++sd_state.rebuild_count;
     debugs(71, 2, "storeDigestRebuildFinish: done.");
     eventAdd("storeDigestRebuildStart", storeDigestRebuildStart, NULL, (double)
              Config.digest.rebuild_period, 1);
@@ -444,7 +444,7 @@ storeDigestRewriteFinish(StoreEntry * e)
     e->mem_obj->unlinkRequest();
     e->unlock();
     sd_state.rewrite_lock = NULL;
-    sd_state.rewrite_count++;
+    ++sd_state.rewrite_count;
     eventAdd("storeDigestRewriteStart", storeDigestRewriteStart, NULL, (double)
              Config.digest.rewrite_period, 1);
     /* resume pending Rebuild if any */
@@ -204,7 +204,7 @@ storeDirSelectSwapDirRoundRobin(const StoreEntry * e)
     if (objsize != -1)
         objsize += e->mem_obj->swap_hdr_sz;
 
-    for (i = 0; i < Config.cacheSwap.n_configured; i++) {
+    for (i = 0; i < Config.cacheSwap.n_configured; ++i) {
         if (++dirn >= Config.cacheSwap.n_configured)
             dirn = 0;
 
@@ -253,7 +253,7 @@ storeDirSelectSwapDirLeastLoad(const StoreEntry * e)
     if (objsize != -1)
         objsize += e->mem_obj->swap_hdr_sz;
 
-    for (i = 0; i < Config.cacheSwap.n_configured; i++) {
+    for (i = 0; i < Config.cacheSwap.n_configured; ++i) {
         SD = dynamic_cast<SwapDir *>(INDEXSD(i));
         SD->flags.selected = 0;
 
@@ -456,7 +456,7 @@ storeDirWriteCleanLogs(int reopen)
     getCurrentTime();
     start = current_time;
 
-    for (dirn = 0; dirn < Config.cacheSwap.n_configured; dirn++) {
+    for (dirn = 0; dirn < Config.cacheSwap.n_configured; ++dirn) {
         sd = dynamic_cast<SwapDir *>(INDEXSD(dirn));
 
         if (sd->writeCleanStart() < 0) {
@@ -473,7 +473,7 @@ storeDirWriteCleanLogs(int reopen)
     while (notdone) {
         notdone = 0;
 
-        for (dirn = 0; dirn < Config.cacheSwap.n_configured; dirn++) {
+        for (dirn = 0; dirn < Config.cacheSwap.n_configured; ++dirn) {
             sd = dynamic_cast<SwapDir *>(INDEXSD(dirn));
 
             if (NULL == sd->cleanLog)
@@ -500,7 +500,7 @@ storeDirWriteCleanLogs(int reopen)
     }
 
     /* Flush */
-    for (dirn = 0; dirn < Config.cacheSwap.n_configured; dirn++)
+    for (dirn = 0; dirn < Config.cacheSwap.n_configured; ++dirn)
         dynamic_cast<SwapDir *>(INDEXSD(dirn))->writeCleanDone();
 
     if (reopen)
@@ -663,7 +663,7 @@ free_cachedir(SquidConfig::_cacheSwap * swap)
     if (reconfiguring)
         return;
 
-    for (i = 0; i < swap->n_configured; i++) {
+    for (i = 0; i < swap->n_configured; ++i) {
         /* TODO XXX this lets the swapdir free resources asynchronously
         * swap->swapDirs[i]->deactivate();
         * but there may be such a means already.
@@ -879,7 +879,7 @@ StoreHashIndex::callback()
     do {
         j = 0;
 
-        for (int i = 0; i < Config.cacheSwap.n_configured; i++) {
+        for (int i = 0; i < Config.cacheSwap.n_configured; ++i) {
             if (ndir >= Config.cacheSwap.n_configured)
                 ndir = ndir % Config.cacheSwap.n_configured;
 
@@ -896,15 +896,15 @@ StoreHashIndex::callback()
         }
     } while (j > 0);
 
-    ndir++;
+    ++ndir;
 
     return result;
 }
 
 void
 StoreHashIndex::create()
 {
-    for (int i = 0; i < Config.cacheSwap.n_configured; i++) {
+    for (int i = 0; i < Config.cacheSwap.n_configured; ++i) {
         if (dir(i).active())
             store(i)->create();
     }
@@ -950,7 +950,7 @@ StoreHashIndex::init()
     store_table = hash_create(storeKeyHashCmp,
                               store_hash_buckets, storeKeyHashHash);
 
-    for (int i = 0; i < Config.cacheSwap.n_configured; i++) {
+    for (int i = 0; i < Config.cacheSwap.n_configured; ++i) {
         /* this starts a search of the store dirs, loading their
          * index. under the new Store api this should be
          * driven by the StoreHashIndex, not by each store.
@@ -975,7 +975,7 @@ StoreHashIndex::maxSize() const
 {
     uint64_t result = 0;
 
-    for (int i = 0; i < Config.cacheSwap.n_configured; i++) {
+    for (int i = 0; i < Config.cacheSwap.n_configured; ++i) {
         if (dir(i).doReportStat())
             result += store(i)->maxSize();
     }
@@ -988,7 +988,7 @@ StoreHashIndex::minSize() const
 {
     uint64_t result = 0;
 
-    for (int i = 0; i < Config.cacheSwap.n_configured; i++) {
+    for (int i = 0; i < Config.cacheSwap.n_configured; ++i) {
         if (dir(i).doReportStat())
             result += store(i)->minSize();
     }
@@ -1001,7 +1001,7 @@ StoreHashIndex::currentSize() const
 {
     uint64_t result = 0;
 
-    for (int i = 0; i < Config.cacheSwap.n_configured; i++) {
+    for (int i = 0; i < Config.cacheSwap.n_configured; ++i) {
         if (dir(i).doReportStat())
             result += store(i)->currentSize();
     }
@@ -1014,7 +1014,7 @@ StoreHashIndex::currentCount() const
 {
     uint64_t result = 0;
 
-    for (int i = 0; i < Config.cacheSwap.n_configured; i++) {
+    for (int i = 0; i < Config.cacheSwap.n_configured; ++i) {
         if (dir(i).doReportStat())
             result += store(i)->currentCount();
     }
@@ -1027,7 +1027,7 @@ StoreHashIndex::maxObjectSize() const
 {
     int64_t result = -1;
 
-    for (int i = 0; i < Config.cacheSwap.n_configured; i++) {
+    for (int i = 0; i < Config.cacheSwap.n_configured; ++i) {
         if (dir(i).active() && store(i)->maxObjectSize() > result)
             result = store(i)->maxObjectSize();
     }
@@ -1039,7 +1039,7 @@ void
 StoreHashIndex::getStats(StoreInfoStats &stats) const
 {
     // accumulate per-disk cache stats
-    for (int i = 0; i < Config.cacheSwap.n_configured; i++) {
+    for (int i = 0; i < Config.cacheSwap.n_configured; ++i) {
         StoreInfoStats dirStats;
         store(i)->getStats(dirStats);
         stats += dirStats;
@@ -1058,7 +1058,7 @@ StoreHashIndex::stat(StoreEntry & output) const
 
     /* Now go through each store, calling its stat routine */
 
-    for (i = 0; i < Config.cacheSwap.n_configured; i++) {
+    for (i = 0; i < Config.cacheSwap.n_configured; ++i) {
         storeAppendPrintf(&output, "\n");
         store(i)->stat(output);
     }
@@ -1082,7 +1082,7 @@ StoreHashIndex::maintain()
     int i;
     /* walk each fs */
 
-    for (i = 0; i < Config.cacheSwap.n_configured; i++) {
+    for (i = 0; i < Config.cacheSwap.n_configured; ++i) {
         /* XXX FixMe: This should be done "in parallell" on the different
          * cache_dirs, not one at a time.
          */
@@ -1177,6 +1177,6 @@ StoreSearchHashIndex::copyBucket()
         entries.push_back(e);
     }
 
-    bucket++;
+    ++bucket;
     debugs(47,3, "got entries: " << entries.size());
 }
@@ -16,7 +16,7 @@ storeCreate(StoreEntry * e, StoreIOState::STFNCB * file_callback, StoreIOState::
 {
     assert (e);
 
-    store_io_stats.create.calls++;
+    ++store_io_stats.create.calls;
 
     /*
      * Pick the swapdir
@@ -26,7 +26,7 @@ storeCreate(StoreEntry * e, StoreIOState::STFNCB * file_callback, StoreIOState::
 
     if (dirn == -1) {
         debugs(20, 2, "storeCreate: no swapdirs for " << *e);
-        store_io_stats.create.select_fail++;
+        ++store_io_stats.create.select_fail;
         return NULL;
     }
 
@@ -37,9 +37,9 @@ storeCreate(StoreEntry * e, StoreIOState::STFNCB * file_callback, StoreIOState::
     StoreIOState::Pointer sio = SD->createStoreIO(*e, file_callback, close_callback, callback_data);
 
     if (sio == NULL)
-        store_io_stats.create.create_fail++;
+        ++store_io_stats.create.create_fail;
     else
-        store_io_stats.create.success++;
+        ++store_io_stats.create.success;
 
     return sio;
 }
@@ -44,7 +44,7 @@ storeKeyText(const cache_key *key)
     static char buf[SQUID_MD5_DIGEST_LENGTH * 2+1];
     int i;
 
-    for (i = 0; i < SQUID_MD5_DIGEST_LENGTH; i++)
+    for (i = 0; i < SQUID_MD5_DIGEST_LENGTH; ++i)
         snprintf(&buf[i*2],sizeof(buf) - i*2, "%02X", *(key + i));
 
     return buf;
@@ -58,7 +58,7 @@ storeKeyScan(const char *buf)
     int j = 0;
     char t[3];
 
-    for (i = 0; i < SQUID_MD5_DIGEST_LENGTH; i++) {
+    for (i = 0; i < SQUID_MD5_DIGEST_LENGTH; ++i) {
         t[0] = *(buf + (j++));
         t[1] = *(buf + (j++));
         t[2] = '\0';
@@ -75,7 +75,7 @@ storeKeyHashCmp(const void *a, const void *b)
     const unsigned char *B = (const unsigned char *)b;
     int i;
 
-    for (i = 0; i < SQUID_MD5_DIGEST_LENGTH; i++) {
+    for (i = 0; i < SQUID_MD5_DIGEST_LENGTH; ++i) {
         if (A[i] < B[i])
             return -1;
 
@@ -68,7 +68,7 @@ storeLog(int tag, const StoreEntry * e)
     if (NULL == storelog)
         return;
 
-    storeLogTagsCounts[tag]++;
+    ++storeLogTagsCounts[tag];
     if (mem != NULL) {
         if (mem->log_url == NULL) {
             debugs(20, 1, "storeLog: NULL log_url for " << mem->url);
@@ -161,7 +161,7 @@ void
 storeLogTagsHist(StoreEntry *e)
 {
     int tag;
-    for (tag = 0; tag <= STORE_LOG_SWAPOUTFAIL; tag++) {
+    for (tag = 0; tag <= STORE_LOG_SWAPOUTFAIL; ++tag) {
         storeAppendPrintf(e, "%s %d\n",
                           storeLogTags[tag],
                           storeLogTagsCounts[tag]);
@@ -91,7 +91,7 @@ storeCleanup(void *datanotused)
 
         if (opt_store_doublecheck)
             if (storeCleanupDoubleCheck(e))
-                store_errors++;
+                ++store_errors;
 
         EBIT_SET(e->flags, ENTRY_VALIDATED);
 
@@ -222,7 +222,7 @@ storeRebuildProgress(int sd_index, int total, int sofar)
     if (squid_curtime - last_report < 15)
         return;
 
-    for (sd_index = 0; sd_index < Config.cacheSwap.n_configured; sd_index++) {
+    for (sd_index = 0; sd_index < Config.cacheSwap.n_configured; ++sd_index) {
         n += (double) RebuildProgress[sd_index].scanned;
         d += (double) RebuildProgress[sd_index].total;
     }
@@ -292,7 +292,7 @@ storeRebuildLoadEntry(int fd, int diskIndex, MemBuf &buf,
     assert(buf.hasSpace()); // caller must allocate
 
     const int len = FD_READ_METHOD(fd, buf.space(), buf.spaceSize());
-    statCounter.syscalls.disk.reads++;
+    ++ statCounter.syscalls.disk.reads;
     if (len < 0) {
         const int xerrno = errno;
         debugs(47, DBG_IMPORTANT, "WARNING: cache_dir[" << diskIndex << "]: " <<
@@ -363,7 +363,7 @@ storeRebuildParseEntry(MemBuf &buf, StoreEntry &tmpe, cache_key *key,
     }
 
     if (EBIT_TEST(tmpe.flags, KEY_PRIVATE)) {
-        counts.badflags++;
+        ++ counts.badflags;
         return false;
     }
 
@@ -397,7 +397,7 @@ storeRebuildKeepEntry(const StoreEntry &tmpe, const cache_key *key,
         if (e->lastref >= tmpe.lastref) {
             /* key already exists, old entry is newer */
             /* keep old, ignore new */
-            counts.dupcount++;
+            ++counts.dupcount;
 
             // For some stores, get() creates/unpacks a store entry. Signal
             // such stores that we will no longer use the get() result:
@@ -409,7 +409,7 @@ storeRebuildKeepEntry(const StoreEntry &tmpe, const cache_key *key,
             /* URL already exists, this swapfile not being used */
             /* junk old, load new */
             e->release();	/* release old entry */
-            counts.dupcount++;
+            ++counts.dupcount;
         }
     }
 
@@ -125,22 +125,24 @@ storeSwapMetaPack(tlv * tlv_list, int *length)
     int j = 0;
     char *buf;
     assert(length != NULL);
-    buflen++;			/* STORE_META_OK */
+    ++buflen;			/* STORE_META_OK */
     buflen += sizeof(int);	/* size of header to follow */
 
     for (t = tlv_list; t; t = t->next)
         buflen += sizeof(char) + sizeof(int) + t->length;
 
     buf = (char *)xmalloc(buflen);
 
-    buf[j++] = (char) STORE_META_OK;
+    buf[j] = (char) STORE_META_OK;
+    ++j;
 
     memcpy(&buf[j], &buflen, sizeof(int));
 
     j += sizeof(int);
 
     for (t = tlv_list; t; t = t->next) {
-        buf[j++] = t->getType();
+        buf[j] = t->getType();
+        ++j;
         memcpy(&buf[j], &t->length, sizeof(int));
         j += sizeof(int);
         memcpy(&buf[j], t->value, t->length);
@@ -190,22 +190,22 @@ fileIteratorAdvance(FileIterator * fi)
         const time_t last_time = fi->inner_time;
         fi->inner_time = -1;
         res = fi->reader(fi);
-        fi->line_count++;
+        ++ fi->line_count;
 
         if (fi->inner_time < 0)
             fi->inner_time = last_time;
         else
             fi->inner_time += fi->time_offset;
 
         if (res == frError)
-            fi->bad_line_count++;
+            ++ fi->bad_line_count;
         else if (res == frEof) {
             fprintf(stderr, "exhausted %s (%d entries) at %s",
                     fi->fname, fi->line_count, ctime(&fi->inner_time));
             fi->inner_time = -1;
         } else if (fi->inner_time < last_time) {
             assert(last_time >= 0);
-            fi->time_warp_count++;
+            ++ fi->time_warp_count;
             fi->inner_time = last_time;
         }
 
@@ -332,18 +332,18 @@ cacheQueryPeer(Cache * cache, const cache_key * key)
     const int peer_has_it = hash_lookup(cache->peer->hash, key) != NULL;
     const int we_think_we_have_it = cacheDigestTest(cache->digest, key);
 
-    cache->qstats.query_count++;
+    ++ cache->qstats.query_count;
 
     if (peer_has_it) {
         if (we_think_we_have_it)
-            cache->qstats.true_hit_count++;
+            ++ cache->qstats.true_hit_count;
         else
-            cache->qstats.false_miss_count++;
+            ++ cache->qstats.false_miss_count;
     } else {
         if (we_think_we_have_it)
-            cache->qstats.false_hit_count++;
+            ++ cache->qstats.false_hit_count;
         else
-            cache->qstats.true_miss_count++;
+            ++ cache->qstats.true_miss_count;
     }
 }
 
@@ -383,7 +383,7 @@ static void
 cacheFetch(Cache * cache, const RawAccessLogEntry * e)
 {
     assert(e);
-    cache->req_count++;
+    ++ cache->req_count;
 
     if (e->use_icp)
         cacheQueryPeer(cache, e->key);
@@ -467,7 +467,7 @@ accessLogReader(FileIterator * fi)
     while (*url)
         url--;
 
-    url++;
+    ++url;
 
     *hier = '\0';
 
@@ -505,7 +505,7 @@ cachePurge(Cache * cache, storeSwapLogData * s, int update_digest)
     CacheEntry *olde = (CacheEntry *) hash_lookup(cache->hash, s->key);
 
     if (!olde) {
-        cache->bad_del_count++;
+        ++ cache->bad_del_count;
     } else {
         assert(cache->count);
         hash_remove_link(cache->hash, (hash_link *) olde);
@@ -525,11 +525,11 @@ cacheStore(Cache * cache, storeSwapLogData * s, int update_digest)
     CacheEntry *olde = (CacheEntry *) hash_lookup(cache->hash, s->key);
 
     if (olde) {
-        cache->bad_add_count++;
+        ++ cache->bad_add_count;
     } else {
         CacheEntry *e = cacheEntryCreate(s);
         hash_join(cache->hash, (hash_link *)&e->key);
-        cache->count++;
+        ++ cache->count;
 
         if (update_digest)
             cacheDigestAdd(cache->digest, e->key);
@@ -642,7 +642,7 @@ main(int argc, char *argv[])
                     next_time = fis[i]->inner_time;
                 }
 
-                active_fi_count++;
+                ++active_fi_count;
             }
         }
 
@@ -1313,12 +1313,12 @@ strwordquote(MemBuf * mb, const char *str)
 
         case '\n':
             mb->append("\\n", 2);
-            str++;
+            ++str;
             break;
 
         case '\r':
             mb->append("\\r", 2);
-            str++;
+            ++str;
             break;
 
         case '\0':
@@ -1327,7 +1327,7 @@ strwordquote(MemBuf * mb, const char *str)
         default:
             mb->append("\\", 1);
             mb->append(str, 1);
-            str++;
+            ++str;
             break;
         }
     }
@@ -1363,9 +1363,11 @@ restoreCapabilities(int keep)
         int ncaps = 0;
         int rc = 0;
         cap_value_t cap_list[10];
-        cap_list[ncaps++] = CAP_NET_BIND_SERVICE;
+        cap_list[ncaps] = CAP_NET_BIND_SERVICE;
+        ++ncaps;
         if (Ip::Interceptor.TransparentActive() || Ip::Qos::TheConfig.isHitNfmarkActive() || Ip::Qos::TheConfig.isAclNfmarkActive()) {
-            cap_list[ncaps++] = CAP_NET_ADMIN;
+            cap_list[ncaps] = CAP_NET_ADMIN;
+            ++ncaps;
         }
 
         cap_clear_flag(caps, CAP_EFFECTIVE);
@@ -638,8 +638,8 @@ tunnelStart(ClientHttpRequest * http, int64_t * size_ptr, int *status_ptr)
     }
 
     debugs(26, 3, HERE << "'" << RequestMethodStr(request->method) << " " << url << " " << request->http_ver << "'");
-    statCounter.server.all.requests++;
-    statCounter.server.other.requests++;
+    ++statCounter.server.all.requests;
+    ++statCounter.server.other.requests;
 
     tunnelState = new TunnelStateData;
 #if USE_DELAY_POOLS
@@ -108,7 +108,7 @@ unlinkdUnlink(const char *path)
         if (bytes_read > 0) {
             rbuf[bytes_read] = '\0';
 
-            for (i = 0; i < bytes_read; i++)
+            for (i = 0; i < bytes_read; ++i)
                 if ('\n' == rbuf[i])
                     queuelen--;
 
@@ -119,7 +119,8 @@ unlinkdUnlink(const char *path)
     l = strlen(path);
     assert(l < MAXPATHLEN);
     xstrncpy(buf, path, MAXPATHLEN);
-    buf[l++] = '\n';
+    buf[l] = '\n';
+    ++l;
     bytes_written = write(unlinkd_wfd, buf, l);
 
     if (bytes_written < 0) {
@@ -139,7 +140,7 @@ unlinkdUnlink(const char *path)
     * in counting unlink operations.
     */
     ++statCounter.syscalls.disk.unlinks;
-    queuelen++;
+    ++queuelen;
 }
 
 void
@@ -254,7 +254,7 @@ urlParse(const HttpRequestMethod& method, char *url, HttpRequest *request)
         src = url;
         i = 0;
         /* Find first : - everything before is protocol */
-        for (i = 0, dst = proto; i < l && *src != ':'; i++, src++, dst++) {
+        for (i = 0, dst = proto; i < l && *src != ':'; ++i, ++src, ++dst) {
             *dst = *src;
         }
         if (i >= l)
@@ -271,7 +271,7 @@ urlParse(const HttpRequestMethod& method, char *url, HttpRequest *request)
         // bug 1881: If we don't get a "/" then we imply it was there
         // bug 3074: We could just be given a "?" or "#". These also imply "/"
         // bug 3233: whitespace is also a hostname delimiter.
-        for (dst = host; i < l && *src != '/' && *src != '?' && *src != '#' && *src != '\0' && !xisspace(*src); i++, src++, dst++) {
+        for (dst = host; i < l && *src != '/' && *src != '?' && *src != '#' && *src != '\0' && !xisspace(*src); ++i, ++src, ++dst) {
             *dst = *src;
         }
 
@@ -292,7 +292,7 @@ urlParse(const HttpRequestMethod& method, char *url, HttpRequest *request)
             dst = urlpath;
         }
         /* Then everything from / (inclusive) until \r\n or \0 - thats urlpath */
-        for (; i < l && *src != '\r' && *src != '\n' && *src != '\0'; i++, src++, dst++) {
+        for (; i < l && *src != '\r' && *src != '\n' && *src != '\0'; ++i, ++src, ++dst) {
             *dst = *src;
         }
 
@@ -301,7 +301,8 @@ urlParse(const HttpRequestMethod& method, char *url, HttpRequest *request)
             return NULL;
         /* If the URL path is empty we set it to be "/" */
         if (dst == urlpath) {
-            *(dst++) = '/';
+            *dst = '/';
+            ++dst;
         }
         *dst = '\0';
 
@@ -322,18 +323,20 @@ urlParse(const HttpRequestMethod& method, char *url, HttpRequest *request)
             dst = host;
             /* only for IPv6 sadly, pre-IPv6/URL code can't handle the clean result properly anyway. */
             src = host;
-            src++;
+            ++src;
             l = strlen(host);
             i = 1;
-            for (; i < l && *src != ']' && *src != '\0'; i++, src++, dst++) {
+            for (; i < l && *src != ']' && *src != '\0'; ++i, ++src, ++dst) {
                 *dst = *src;
             }
 
             /* we moved in-place, so truncate the actual hostname found */
-            *(dst++) = '\0';
+            *dst = '\0';
+            ++dst;
 
             /* skip ahead to either start of port, or original EOS */
-            while (*dst != '\0' && *dst != ':') dst++;
+            while (*dst != '\0' && *dst != ':')
+                ++dst;
             t = dst;
         } else {
             t = strrchr(host, ':');
@@ -354,21 +357,23 @@ urlParse(const HttpRequestMethod& method, char *url, HttpRequest *request)
 
         if (t && *t == ':') {
             *t = '\0';
-            t++;
+            ++t;
             port = atoi(t);
         }
     }
 
-    for (t = host; *t; t++)
+    for (t = host; *t; ++t)
         *t = xtolower(*t);
 
     if (stringHasWhitespace(host)) {
         if (URI_WHITESPACE_STRIP == Config.uri_whitespace) {
             t = q = host;
             while (*t) {
-                if (!xisspace(*t))
-                    *q++ = *t;
-                t++;
+                if (!xisspace(*t)) {
+                    *q = *t;
+                    ++q;
+                }
+                ++t;
             }
             *q = '\0';
         }
@@ -433,9 +438,11 @@ urlParse(const HttpRequestMethod& method, char *url, HttpRequest *request)
         default:
             t = q = urlpath;
             while (*t) {
-                if (!xisspace(*t))
-                    *q++ = *t;
-                t++;
+                if (!xisspace(*t)) {
+                    *q = *t;
+                    ++q;
+                }
+                ++t;
             }
             *q = '\0';
         }
@@ -581,8 +588,10 @@ urlCanonicalClean(const HttpRequest * request)
              */
 
             if (Config.onoff.strip_query_terms)
-                if ((t = strchr(buf, '?')))
-                    *(++t) = '\0';
+                if ((t = strchr(buf, '?'))) {
+                    ++t;
+                    *t = '\0';
+                }
 
             break;
         }
@@ -634,7 +643,7 @@ urlIsRelative(const char *url)
         return (false);
     }
 
-    for (p = url; *p != '\0' && *p != ':' && *p != '/'; p++);
+    for (p = url; *p != '\0' && *p != ':' && *p != '/'; ++p);
 
     if (*p == ':') {
         return (false);
@@ -698,10 +707,11 @@ urlMakeAbsolute(const HttpRequest * req, const char *relUrl)
         const char *last_slash = strrchr(path, '/');
 
         if (last_slash == NULL) {
-            urlbuf[urllen++] = '/';
+            urlbuf[urllen] = '/';
+            ++urllen;
             strncpy(&urlbuf[urllen], relUrl, MAX_URL - urllen - 1);
         } else {
-            last_slash++;
+            ++last_slash;
             size_t pathlen = last_slash - path;
             if (pathlen > MAX_URL - urllen - 1) {
                 pathlen = MAX_URL - urllen - 1;
@@ -746,7 +756,7 @@ matchDomainName(const char *h, const char *d)
     int hl;
 
     while ('.' == *h)
-        h++;
+        ++h;
 
     hl = strlen(h);
 
@@ -969,7 +979,7 @@ URLHostName::trimAuth()
     char *t;
 
     if ((t = strrchr(Host, '@'))) {
-        t++;
+        ++t;
         memmove(Host, t, strlen(t) + 1);
     }
 }