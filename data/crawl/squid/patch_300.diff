@@ -1,3 +1,16 @@
+Changes to squid-3.4.6 (25 Jun 2014):
+
+	- Regression: segmentation fault logging with %tg format specifier
+	- Bug 4065: round-robin neighbor selection with unequal weights
+	- Bug 4056: assertion MemPools[type] from netdbExchangeStart()
+	- Bug 4050: segmentation fault in CommSelectEngine::checkEvents on helper response
+	- Fix segmentation fault setting up server SSL connnection
+	- Fix hanging Non-HTTPS connections on SSL-bump enabled port
+	- Fix Cache Manager actions listed more than once
+	- ... and many minor memory leaks
+	- ... and several portability build issues
+	- ... and some documentation updates
+
 Changes to squid-3.4.5 (02 May 2014):
 
 	- Regression Bug 4051: inverted test on CONNECT payload existence
@@ -35,12 +35,18 @@ AC_DEFUN([SQUID_DEFAULT_INCLUDES],[[
 dnl *BSD net headers
 AC_DEFUN([SQUID_BSDNET_INCLUDES],[
 SQUID_DEFAULT_INCLUDES
+#if HAVE_SYS_PARAM_H
+#include <sys/param.h>
+#endif
 #if HAVE_SYS_TIME_H
 #include <sys/time.h>
 #endif
 #if HAVE_SYS_SOCKET_H
 #include <sys/socket.h>
 #endif
+#if HAVE_NET_IF_H
+#include <net/if.h>
+#endif
 #if HAVE_NETINET_IN_H
 #include <netinet/in.h>
 #endif
@@ -50,15 +56,9 @@ SQUID_DEFAULT_INCLUDES
 #if HAVE_NETINET_IP_COMPAT_H
 #include <netinet/ip_compat.h>
 #endif
-#if HAVE_NET_IF_H
-#include <net/if.h>
-#endif
 #if HAVE_NETINET_IP_FIL_H
 #include <netinet/ip_fil.h>
 #endif
-#if HAVE_SYS_PARAM_H
-#include <sys/param.h>
-#endif
 ])
 
 dnl ===========================================================================
@@ -148,33 +148,76 @@ SQUIDCEXTERN int WIN32_truncate(const char *pathname, off_t length);
 #define umask _umask
 #define unlink _unlink
 
+#ifndef O_RDONLY
 #define O_RDONLY        _O_RDONLY
+#endif
+#ifndef O_WRONLY
 #define O_WRONLY        _O_WRONLY
+#endif
+#ifndef O_RDWR
 #define O_RDWR          _O_RDWR
+#endif
+#ifndef O_APPEND
 #define O_APPEND        _O_APPEND
-
+#endif
+#ifndef O_CREAT
 #define O_CREAT         _O_CREAT
+#endif
+#ifndef O_TRUNC
 #define O_TRUNC         _O_TRUNC
+#endif
+#ifndef O_EXCL
 #define O_EXCL          _O_EXCL
-
+#endif
+#ifndef O_TEXT
 #define O_TEXT          _O_TEXT
+#endif
+#ifndef O_BINARY
 #define O_BINARY        _O_BINARY
+#endif
+#ifndef O_RAW
 #define O_RAW           _O_BINARY
+#endif
+#ifndef O_TEMPORARY
 #define O_TEMPORARY     _O_TEMPORARY
+#endif
+#ifndef O_NOINHERIT
 #define O_NOINHERIT     _O_NOINHERIT
+#endif
+#ifndef O_SEQUENTIAL
 #define O_SEQUENTIAL    _O_SEQUENTIAL
+#endif
+#ifndef O_RANDOM
 #define O_RANDOM        _O_RANDOM
+#endif
+#ifndef O_NDELAY
 #define O_NDELAY	0
+#endif
 
+#ifndef S_IFMT
 #define S_IFMT   _S_IFMT
+#endif
+#ifndef S_IFDIR
 #define S_IFDIR  _S_IFDIR
+#endif
+#ifndef S_IFCHR
 #define S_IFCHR  _S_IFCHR
+#endif
+#ifndef S_IFREG
 #define S_IFREG  _S_IFREG
+#endif
+#ifndef S_IREAD
 #define S_IREAD  _S_IREAD
+#endif
+#ifndef S_IWRITE
 #define S_IWRITE _S_IWRITE
+#endif
+#ifndef S_IEXEC
 #define S_IEXEC  _S_IEXEC
-
+#endif
+#ifndef S_IRWXO
 #define S_IRWXO 007
+#endif
 
 #if defined(_MSC_VER)
 #define	S_ISDIR(m) (((m) & _S_IFDIR) == _S_IFDIR)
@@ -49,7 +49,7 @@
 #define INT64_MIN LONG_MIN
 #else
 /* 32 bit system */
-#define INT64_MIN       -9223372036854775807L-1L
+#define INT64_MIN       (-9223372036854775807LL-1LL)
 #endif
 #endif
 
@@ -59,7 +59,7 @@
 #define INT64_MAX LONG_MAX
 #else
 /* 32 bit system */
-#define INT64_MAX       9223372036854775807L
+#define INT64_MAX       9223372036854775807LL
 #endif
 #endif
 
@@ -2,9 +2,7 @@
 #include "compat/xalloc.h"
 #include "compat/xstring.h"
 
-#if HAVE_ERRNO_H
-#include <errno.h>
-#endif
+#include <cerrno>
 
 char *
 xstrdup(const char *s)
@@ -47,9 +47,7 @@
  *      Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.
  */
 
-#if HAVE_ERRNO_H
-#include <errno.h>
-#endif
+#include <cerrno>
 
 bool
 xstrtoul(const char *s, char **end, unsigned long *value,
@@ -53,17 +53,19 @@ if test "x${enable_arch_native}" != "xno"; then
 fi
 
 # might be cross-compiling.
-if test "x$HOSTCXX" = "x"; then
-  HOSTCXX="$CXX"
+# NP: BUILDCXXFLAGS defined at the end of configure after CXXFLAGS fully known.
+AC_ARG_VAR([BUILDCXX],[path to compiler for building compile-time tools. e.g. cf_gen])
+if test "x$HOSTCXX" != "x" -a "x$BUILDCXX" = "x"; then
+  AC_MSG_WARN([Cross-compiling with HOSTCXX is deprecated. Uses BUILDCXX instead.])
+  BUILDCXX="$HOSTCXX"
+fi
+if test "x$BUILDCXX" = "x"; then
+  BUILDCXX="$CXX"
   if test "x$squid_cv_check_marchnative" = "xyes"; then
     CXXFLAGS="$CXXFLAGS -march=native"
   fi
 fi
-if test "x$squid_cv_check_marchnative" = "xyes"; then
-  # always valid for the Host compiler.
-  HOSTCXX="$HOSTCXX -march=native"
-fi
-AC_SUBST(HOSTCXX)
+AC_SUBST(BUILDCXX)
 
 AC_MSG_CHECKING([simplified host os])
 simple_host_os=`echo $host_os|sed 's/[0-9].*//g;s/-.*//g'`
@@ -974,13 +976,12 @@ AC_SUBST(XMLLIB)
 
 # icap argument handling
 AC_ARG_ENABLE(icap-client,
-  AS_HELP_STRING([--enable-icap-client],[Enable the ICAP client.]),
-    [squid_opt_use_icap_client=$enableval],
-    [squid_opt_use_icap_client=no])
-SQUID_DEFINE_BOOL(ICAP_CLIENT,$squid_opt_use_icap_client,
-     [Enable ICAP client features in Squid])
-AM_CONDITIONAL(USE_ICAP_CLIENT, [test "x$squid_opt_use_icap_client" = "xyes" ])
-if test "x$squid_opt_use_icap_client" = "xyes" ; then
+  AS_HELP_STRING([--disable-icap-client],[Disable the ICAP client.]),[
+  SQUID_YESNO([$enableval],[Unrecognized argument to --disable-icap-client: $enableval])
+])
+SQUID_DEFINE_BOOL(ICAP_CLIENT,${enable_icap_client:=yes}, [Enable ICAP client features in Squid])
+AM_CONDITIONAL(USE_ICAP_CLIENT, [test "x$enable_icap_client" != "xno" ])
+if test "x$enable_icap_client" != "xno" ; then
   ICAP_LIBS="icap/libicap.la"
   squid_opt_use_adaptation=yes
 else
@@ -1133,7 +1134,7 @@ if test "x${enable_eui:=yes}" = "xyes" ; then
       AC_MSG_WARN([EUI support probably will not work on host $host.])
       ;;
   esac
-  #Iphlpapi.h check delayed after winsock2.h
+  # iphlpapi.h check delayed after winsock2.h
   AC_CHECK_HEADERS( \
     windows.h \
     sys/sockio.h \
@@ -2513,7 +2514,7 @@ if test "x$squid_host_os" = "xmingw" ; then
   AC_CHECK_HEADERS( \
     windows.h \
     ws2tcpip.h \
-    Iphlpapi.h ,,,[
+    iphlpapi.h ,,,[
 #if HAVE_WINDOWS_H
 #include <windows.h>
 #endif
@@ -3417,6 +3418,18 @@ AC_SUBST(XTRA_LIBS)
 AC_SUBST(SQUID_CFLAGS)
 AC_SUBST(SQUID_CXXFLAGS)
 
+AC_ARG_VAR([BUILDCXXFLAGS],[C++ compiler flags for building compile-time tools. e.g. cf_gen])
+if test "x$BUILDCXXFLAGS" = "x"; then
+  # if we are NOT cross-compiling, use the default build flags for cf_gen and friends
+  # otherwise rely on the user-provided value
+  if test "x$squid_cv_check_marchnative" = "xyes"; then
+    # always valid for the Build compiler.
+    BUILDCXXFLAGS="-march=native"
+  fi
+  BUILDCXXFLAGS="$BUILDCXXFLAGS $CXXFLAGS"
+fi
+AC_SUBST(BUILDCXXFLAGS)
+
 AC_MSG_NOTICE([BUILD LIBRARIES: $LIBS])
 AC_MSG_NOTICE([BUILD EXTRA LIBRARIES: $XTRA_LIBS])
 AC_MSG_NOTICE([BUILD OBJECTS: $OBJS])
@@ -3425,6 +3438,7 @@ AC_MSG_NOTICE([BUILD C FLAGS: $CFLAGS])
 AC_MSG_NOTICE([BUILD EXTRA C FLAGS: $SQUID_CFLAGS])
 AC_MSG_NOTICE([BUILD C++ FLAGS: $CXXFLAGS])
 AC_MSG_NOTICE([BUILD EXTRA C++ FLAGS: $SQUID_CXXFLAGS])
+AC_MSG_NOTICE([BUILD Tools C++ FLAGS: $BUILDCXXFLAGS])
 
 dnl Clean up after OSF/1 core dump bug
 rm -f core 
@@ -3467,6 +3481,7 @@ AC_CONFIG_FILES([
 	src/ipc/Makefile
 	src/ssl/Makefile
 	src/mgr/Makefile
+	src/parser/Makefile
 	src/snmp/Makefile
 	contrib/Makefile
 	icons/Makefile
@@ -1,6 +1,6 @@
 <!doctype linuxdoc system>
 <article>
-<title>Squid 3.4.5 release notes</title>
+<title>Squid 3.4.6 release notes</title>
 <author>Squid Developers</author>
 
 <abstract>
@@ -13,7 +13,7 @@ for Applied Network Research and members of the Web Caching community.
 
 <sect>Notice
 <p>
-The Squid Team are pleased to announce the release of Squid-3.4.5 for testing.
+The Squid Team are pleased to announce the release of Squid-3.4.6 for testing.
 
 This new release is available for download from <url url="http://www.squid-cache.org/Versions/v3/3.4/"> or the
  <url url="http://www.squid-cache.org/Mirrors/http-mirrors.html" name="mirrors">.
@@ -330,7 +330,15 @@ This section gives an account of those changes in three categories:
 <sect1>New options<label id="newoptions">
 <p>
 <descrip>
-	<p><em>There are no new ./configure options in Squid-3.5.</em>
+	<tag>BUILDCXX=</tag>
+	<p>Used when cross-compiling Squid.
+	<p>The path and name of a compiler for building cf_gen and related
+	   tools used in the compile process.
+
+	<tag>BUILDCXXFLAGS=</tag>
+	<p>Used when cross-compiling Squid.
+	<p>C++ compiler flags used for building cf_gen and related
+	   tools used in the compile process.
 
 	<tag>--without-gnutls</tag>
 	<p>New option to explicitly disable use of GnuTLS encryption library.
@@ -342,7 +350,9 @@ This section gives an account of those changes in three categories:
 <sect1>Changes to existing options<label id="modifiedoptions">
 <p>
 <descrip>
-	<p><em>There are no changes to existing ./configure options in Squid-3.5.</em>
+	<tag>--enable-icap-client</tag>
+	<p>Deprecated. ICAP client is now auto-enabled.
+	   Use --disable-icap-client to disable if you need to.
 
 </descrip>
 </p>
@@ -69,9 +69,6 @@ rfc4918.txt
 	HTTP Extensions for Distributed Authoring -- WEBDAV
 	Numerous extension methods to HTTP
 
-rfc2616.txt
-	Hypertext Transfer Protocol -- HTTP/1.1
-
 rfc2617.txt
 	HTTP/1.1 Basic and Digest authentication
 
@@ -166,3 +163,41 @@ rfc6762.txt
 	Multicast DNS
 	Details the DNS requirements on the Squid internal DNS client
 	for resolving URLs in the .local domain.
+
+rfc7230.txt
+	Hypertext Transfer Protocol (HTTP/1.1): Message Syntax and Routing
+	Details the message 'frame' delimiters, first-line, and URL
+	syntax, generic parsing rules, connection management, routing,
+	and transfer encoding.
+
+rfc7231.txt
+	Hypertext Transfer Protocol (HTTP/1.1): Semantics and Content
+	Details the basic HTTP methods, headers and status code values
+	and behaviour requirements imposed by each.
+
+rfc7232.txt
+	Hypertext Transfer Protocol (HTTP/1.1): Conditional Requests
+	Last-Modified and Etag validator headers,
+	If-* conditional headers,
+	304 and 412 status codes.
+
+rfc7233.txt
+	Hypertext Transfer Protocol (HTTP/1.1): Range Requests
+	Defines range requests and the rules for constructing and
+	combining responses to those requests.
+
+rfc7234.txt
+	Hypertext Transfer Protocol (HTTP/1.1): Caching
+	Defines HTTP caches and the associated header fields that
+	control cache behavior or indicate cacheable response messages.
+
+rfc7235.txt
+	Hypertext Transfer Protocol (HTTP/1.1): Authentication
+
+rfc7238.txt
+	The Hypertext Transfer Protocol Status Code 308 (Permanent Redirect)
+
+rfc7239.txt
+	Forwarded HTTP Extension
+	Details the Forwarded: header replacement for X-Forwarded-For
+	and other X-Forwarded-* variants
@@ -0,0 +1,1571 @@
+
+
+
+
+
+
+Internet Engineering Task Force (IETF)                  R. Fielding, Ed.
+Request for Comments: 7232                                         Adobe
+Obsoletes: 2616                                          J. Reschke, Ed.
+Category: Standards Track                                     greenbytes
+ISSN: 2070-1721                                                June 2014
+
+
+      Hypertext Transfer Protocol (HTTP/1.1): Conditional Requests
+
+Abstract
+
+   The Hypertext Transfer Protocol (HTTP) is a stateless application-
+   level protocol for distributed, collaborative, hypertext information
+   systems.  This document defines HTTP/1.1 conditional requests,
+   including metadata header fields for indicating state changes,
+   request header fields for making preconditions on such state, and
+   rules for constructing the responses to a conditional request when
+   one or more preconditions evaluate to false.
+
+Status of This Memo
+
+   This is an Internet Standards Track document.
+
+   This document is a product of the Internet Engineering Task Force
+   (IETF).  It represents the consensus of the IETF community.  It has
+   received public review and has been approved for publication by the
+   Internet Engineering Steering Group (IESG).  Further information on
+   Internet Standards is available in Section 2 of RFC 5741.
+
+   Information about the current status of this document, any errata,
+   and how to provide feedback on it may be obtained at
+   http://www.rfc-editor.org/info/rfc7232.
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+Fielding & Reschke           Standards Track                    [Page 1]
+
+RFC 7232              HTTP/1.1 Conditional Requests            June 2014
+
+
+Copyright Notice
+
+   Copyright (c) 2014 IETF Trust and the persons identified as the
+   document authors.  All rights reserved.
+
+   This document is subject to BCP 78 and the IETF Trust's Legal
+   Provisions Relating to IETF Documents
+   (http://trustee.ietf.org/license-info) in effect on the date of
+   publication of this document.  Please review these documents
+   carefully, as they describe your rights and restrictions with respect
+   to this document.  Code Components extracted from this document must
+   include Simplified BSD License text as described in Section 4.e of
+   the Trust Legal Provisions and are provided without warranty as
+   described in the Simplified BSD License.
+
+   This document may contain material from IETF Documents or IETF
+   Contributions published or made publicly available before November
+   10, 2008.  The person(s) controlling the copyright in some of this
+   material may not have granted the IETF Trust the right to allow
+   modifications of such material outside the IETF Standards Process.
+   Without obtaining an adequate license from the person(s) controlling
+   the copyright in such materials, this document may not be modified
+   outside the IETF Standards Process, and derivative works of it may
+   not be created outside the IETF Standards Process, except to format
+   it for publication as an RFC or to translate it into languages other
+   than English.
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+Fielding & Reschke           Standards Track                    [Page 2]
+
+RFC 7232              HTTP/1.1 Conditional Requests            June 2014
+
+
+Table of Contents
+
+   1. Introduction ....................................................4
+      1.1. Conformance and Error Handling .............................4
+      1.2. Syntax Notation ............................................4
+   2. Validators ......................................................5
+      2.1. Weak versus Strong .........................................5
+      2.2. Last-Modified ..............................................7
+           2.2.1. Generation ..........................................7
+           2.2.2. Comparison ..........................................8
+      2.3. ETag .......................................................9
+           2.3.1. Generation .........................................10
+           2.3.2. Comparison .........................................10
+           2.3.3. Example: Entity-Tags Varying on
+                  Content-Negotiated Resources .......................11
+      2.4. When to Use Entity-Tags and Last-Modified Dates ...........12
+   3. Precondition Header Fields .....................................13
+      3.1. If-Match ..................................................13
+      3.2. If-None-Match .............................................14
+      3.3. If-Modified-Since .........................................16
+      3.4. If-Unmodified-Since .......................................17
+      3.5. If-Range ..................................................18
+   4. Status Code Definitions ........................................18
+      4.1. 304 Not Modified ..........................................18
+      4.2. 412 Precondition Failed ...................................19
+   5. Evaluation .....................................................19
+   6. Precedence .....................................................20
+   7. IANA Considerations ............................................22
+      7.1. Status Code Registration ..................................22
+      7.2. Header Field Registration .................................22
+   8. Security Considerations ........................................22
+   9. Acknowledgments ................................................23
+   10. References ....................................................24
+      10.1. Normative References .....................................24
+      10.2. Informative References ...................................24
+   Appendix A. Changes from RFC 2616 .................................25
+   Appendix B. Imported ABNF .........................................25
+   Appendix C. Collected ABNF ........................................26
+   Index .............................................................27
+
+
+
+
+
+
+
+
+
+
+
+
+Fielding & Reschke           Standards Track                    [Page 3]
+
+RFC 7232              HTTP/1.1 Conditional Requests            June 2014
+
+
+1.  Introduction
+
+   Conditional requests are HTTP requests [RFC7231] that include one or
+   more header fields indicating a precondition to be tested before
+   applying the method semantics to the target resource.  This document
+   defines the HTTP/1.1 conditional request mechanisms in terms of the
+   architecture, syntax notation, and conformance criteria defined in
+   [RFC7230].
+
+   Conditional GET requests are the most efficient mechanism for HTTP
+   cache updates [RFC7234].  Conditionals can also be applied to
+   state-changing methods, such as PUT and DELETE, to prevent the "lost
+   update" problem: one client accidentally overwriting the work of
+   another client that has been acting in parallel.
+
+   Conditional request preconditions are based on the state of the
+   target resource as a whole (its current value set) or the state as
+   observed in a previously obtained representation (one value in that
+   set).  A resource might have multiple current representations, each
+   with its own observable state.  The conditional request mechanisms
+   assume that the mapping of requests to a "selected representation"
+   (Section 3 of [RFC7231]) will be consistent over time if the server
+   intends to take advantage of conditionals.  Regardless, if the
+   mapping is inconsistent and the server is unable to select the
+   appropriate representation, then no harm will result when the
+   precondition evaluates to false.
+
+   The conditional request preconditions defined by this specification
+   (Section 3) are evaluated when applicable to the recipient
+   (Section 5) according to their order of precedence (Section 6).
+
+1.1.  Conformance and Error Handling
+
+   The key words "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT",
+   "SHOULD", "SHOULD NOT", "RECOMMENDED", "MAY", and "OPTIONAL" in this
+   document are to be interpreted as described in [RFC2119].
+
+   Conformance criteria and considerations regarding error handling are
+   defined in Section 2.5 of [RFC7230].
+
+1.2.  Syntax Notation
+
+   This specification uses the Augmented Backus-Naur Form (ABNF)
+   notation of [RFC5234] with a list extension, defined in Section 7 of
+   [RFC7230], that allows for compact definition of comma-separated
+   lists using a '#' operator (similar to how the '*' operator indicates
+
+
+
+
+
+Fielding & Reschke           Standards Track                    [Page 4]
+
+RFC 7232              HTTP/1.1 Conditional Requests            June 2014
+
+
+   repetition).  Appendix B describes rules imported from other
+   documents.  Appendix C shows the collected grammar with all list
+   operators expanded to standard ABNF notation.
+
+2.  Validators
+
+   This specification defines two forms of metadata that are commonly
+   used to observe resource state and test for preconditions:
+   modification dates (Section 2.2) and opaque entity tags
+   (Section 2.3).  Additional metadata that reflects resource state has
+   been defined by various extensions of HTTP, such as Web Distributed
+   Authoring and Versioning (WebDAV, [RFC4918]), that are beyond the
+   scope of this specification.  A resource metadata value is referred
+   to as a "validator" when it is used within a precondition.
+
+2.1.  Weak versus Strong
+
+   Validators come in two flavors: strong or weak.  Weak validators are
+   easy to generate but are far less useful for comparisons.  Strong
+   validators are ideal for comparisons but can be very difficult (and
+   occasionally impossible) to generate efficiently.  Rather than impose
+   that all forms of resource adhere to the same strength of validator,
+   HTTP exposes the type of validator in use and imposes restrictions on
+   when weak validators can be used as preconditions.
+
+   A "strong validator" is representation metadata that changes value
+   whenever a change occurs to the representation data that would be
+   observable in the payload body of a 200 (OK) response to GET.
+
+   A strong validator might change for reasons other than a change to
+   the representation data, such as when a semantically significant part
+   of the representation metadata is changed (e.g., Content-Type), but
+   it is in the best interests of the origin server to only change the
+   value when it is necessary to invalidate the stored responses held by
+   remote caches and authoring tools.
+
+   Cache entries might persist for arbitrarily long periods, regardless
+   of expiration times.  Thus, a cache might attempt to validate an
+   entry using a validator that it obtained in the distant past.  A
+   strong validator is unique across all versions of all representations
+   associated with a particular resource over time.  However, there is
+   no implication of uniqueness across representations of different
+   resources (i.e., the same strong validator might be in use for
+   representations of multiple resources at the same time and does not
+   imply that those representations are equivalent).
+
+
+
+
+
+
+Fielding & Reschke           Standards Track                    [Page 5]
+
+RFC 7232              HTTP/1.1 Conditional Requests            June 2014
+
+
+   There are a variety of strong validators used in practice.  The best
+   are based on strict revision control, wherein each change to a
+   representation always results in a unique node name and revision
+   identifier being assigned before the representation is made
+   accessible to GET.  A collision-resistant hash function applied to
+   the representation data is also sufficient if the data is available
+   prior to the response header fields being sent and the digest does
+   not need to be recalculated every time a validation request is
+   received.  However, if a resource has distinct representations that
+   differ only in their metadata, such as might occur with content
+   negotiation over media types that happen to share the same data
+   format, then the origin server needs to incorporate additional
+   information in the validator to distinguish those representations.
+
+   In contrast, a "weak validator" is representation metadata that might
+   not change for every change to the representation data.  This
+   weakness might be due to limitations in how the value is calculated,
+   such as clock resolution, an inability to ensure uniqueness for all
+   possible representations of the resource, or a desire of the resource
+   owner to group representations by some self-determined set of
+   equivalency rather than unique sequences of data.  An origin server
+   SHOULD change a weak entity-tag whenever it considers prior
+   representations to be unacceptable as a substitute for the current
+   representation.  In other words, a weak entity-tag ought to change
+   whenever the origin server wants caches to invalidate old responses.
+
+   For example, the representation of a weather report that changes in
+   content every second, based on dynamic measurements, might be grouped
+   into sets of equivalent representations (from the origin server's
+   perspective) with the same weak validator in order to allow cached
+   representations to be valid for a reasonable period of time (perhaps
+   adjusted dynamically based on server load or weather quality).
+   Likewise, a representation's modification time, if defined with only
+   one-second resolution, might be a weak validator if it is possible
+   for the representation to be modified twice during a single second
+   and retrieved between those modifications.
+
+   Likewise, a validator is weak if it is shared by two or more
+   representations of a given resource at the same time, unless those
+   representations have identical representation data.  For example, if
+   the origin server sends the same validator for a representation with
+   a gzip content coding applied as it does for a representation with no
+   content coding, then that validator is weak.  However, two
+   simultaneous representations might share the same strong validator if
+   they differ only in the representation metadata, such as when two
+   different media types are available for the same representation data.
+
+
+
+
+
+Fielding & Reschke           Standards Track                    [Page 6]
+
+RFC 7232              HTTP/1.1 Conditional Requests            June 2014
+
+
+   Strong validators are usable for all conditional requests, including
+   cache validation, partial content ranges, and "lost update"
+   avoidance.  Weak validators are only usable when the client does not
+   require exact equality with previously obtained representation data,
+   such as when validating a cache entry or limiting a web traversal to
+   recent changes.
+
+2.2.  Last-Modified
+
+   The "Last-Modified" header field in a response provides a timestamp
+   indicating the date and time at which the origin server believes the
+   selected representation was last modified, as determined at the
+   conclusion of handling the request.
+
+     Last-Modified = HTTP-date
+
+   An example of its use is
+
+     Last-Modified: Tue, 15 Nov 1994 12:45:26 GMT
+
+2.2.1.  Generation
+
+   An origin server SHOULD send Last-Modified for any selected
+   representation for which a last modification date can be reasonably
+   and consistently determined, since its use in conditional requests
+   and evaluating cache freshness ([RFC7234]) results in a substantial
+   reduction of HTTP traffic on the Internet and can be a significant
+   factor in improving service scalability and reliability.
+
+   A representation is typically the sum of many parts behind the
+   resource interface.  The last-modified time would usually be the most
+   recent time that any of those parts were changed.  How that value is
+   determined for any given resource is an implementation detail beyond
+   the scope of this specification.  What matters to HTTP is how
+   recipients of the Last-Modified header field can use its value to
+   make conditional requests and test the validity of locally cached
+   responses.
+
+   An origin server SHOULD obtain the Last-Modified value of the
+   representation as close as possible to the time that it generates the
+   Date field value for its response.  This allows a recipient to make
+   an accurate assessment of the representation's modification time,
+   especially if the representation changes near the time that the
+   response is generated.
+
+   An origin server with a clock MUST NOT send a Last-Modified date that
+   is later than the server's time of message origination (Date).  If
+   the last modification time is derived from implementation-specific
+
+
+
+Fielding & Reschke           Standards Track                    [Page 7]
+
+RFC 7232              HTTP/1.1 Conditional Requests            June 2014
+
+
+   metadata that evaluates to some time in the future, according to the
+   origin server's clock, then the origin server MUST replace that value
+   with the message origination date.  This prevents a future
+   modification date from having an adverse impact on cache validation.
+
+   An origin server without a clock MUST NOT assign Last-Modified values
+   to a response unless these values were associated with the resource
+   by some other system or user with a reliable clock.
+
+2.2.2.  Comparison
+
+   A Last-Modified time, when used as a validator in a request, is
+   implicitly weak unless it is possible to deduce that it is strong,
+   using the following rules:
+
+   o  The validator is being compared by an origin server to the actual
+      current validator for the representation and,
+
+   o  That origin server reliably knows that the associated
+      representation did not change twice during the second covered by
+      the presented validator.
+
+   or
+
+   o  The validator is about to be used by a client in an
+      If-Modified-Since, If-Unmodified-Since, or If-Range header field,
+      because the client has a cache entry for the associated
+      representation, and
+
+   o  That cache entry includes a Date value, which gives the time when
+      the origin server sent the original response, and
+
+   o  The presented Last-Modified time is at least 60 seconds before the
+      Date value.
+
+   or
+
+   o  The validator is being compared by an intermediate cache to the
+      validator stored in its cache entry for the representation, and
+
+   o  That cache entry includes a Date value, which gives the time when
+      the origin server sent the original response, and
+
+   o  The presented Last-Modified time is at least 60 seconds before the
+      Date value.
+
+
+
+
+
+
+Fielding & Reschke           Standards Track                    [Page 8]
+
+RFC 7232              HTTP/1.1 Conditional Requests            June 2014
+
+
+   This method relies on the fact that if two different responses were
+   sent by the origin server during the same second, but both had the
+   same Last-Modified time, then at least one of those responses would
+   have a Date value equal to its Last-Modified time.  The arbitrary
+   60-second limit guards against the possibility that the Date and
+   Last-Modified values are generated from different clocks or at
+   somewhat different times during the preparation of the response.  An
+   implementation MAY use a value larger than 60 seconds, if it is
+   believed that 60 seconds is too short.
+
+2.3.  ETag
+
+   The "ETag" header field in a response provides the current entity-tag
+   for the selected representation, as determined at the conclusion of
+   handling the request.  An entity-tag is an opaque validator for
+   differentiating between multiple representations of the same
+   resource, regardless of whether those multiple representations are
+   due to resource state changes over time, content negotiation
+   resulting in multiple representations being valid at the same time,
+   or both.  An entity-tag consists of an opaque quoted string, possibly
+   prefixed by a weakness indicator.
+
+     ETag       = entity-tag
+
+     entity-tag = [ weak ] opaque-tag
+     weak       = %x57.2F ; "W/", case-sensitive
+     opaque-tag = DQUOTE *etagc DQUOTE
+     etagc      = %x21 / %x23-7E / obs-text
+                ; VCHAR except double quotes, plus obs-text
+
+      Note: Previously, opaque-tag was defined to be a quoted-string
+      ([RFC2616], Section 3.11); thus, some recipients might perform
+      backslash unescaping.  Servers therefore ought to avoid backslash
+      characters in entity tags.
+
+   An entity-tag can be more reliable for validation than a modification
+   date in situations where it is inconvenient to store modification
+   dates, where the one-second resolution of HTTP date values is not
+   sufficient, or where modification dates are not consistently
+   maintained.
+
+   Examples:
+
+     ETag: "xyzzy"
+     ETag: W/"xyzzy"
+     ETag: ""
+
+
+
+
+
+Fielding & Reschke           Standards Track                    [Page 9]
+
+RFC 7232              HTTP/1.1 Conditional Requests            June 2014
+
+
+   An entity-tag can be either a weak or strong validator, with strong
+   being the default.  If an origin server provides an entity-tag for a
+   representation and the generation of that entity-tag does not satisfy
+   all of the characteristics of a strong validator (Section 2.1), then
+   the origin server MUST mark the entity-tag as weak by prefixing its
+   opaque value with "W/" (case-sensitive).
+
+2.3.1.  Generation
+
+   The principle behind entity-tags is that only the service author
+   knows the implementation of a resource well enough to select the most
+   accurate and efficient validation mechanism for that resource, and
+   that any such mechanism can be mapped to a simple sequence of octets
+   for easy comparison.  Since the value is opaque, there is no need for
+   the client to be aware of how each entity-tag is constructed.
+
+   For example, a resource that has implementation-specific versioning
+   applied to all changes might use an internal revision number, perhaps
+   combined with a variance identifier for content negotiation, to
+   accurately differentiate between representations.  Other
+   implementations might use a collision-resistant hash of
+   representation content, a combination of various file attributes, or
+   a modification timestamp that has sub-second resolution.
+
+   An origin server SHOULD send an ETag for any selected representation
+   for which detection of changes can be reasonably and consistently
+   determined, since the entity-tag's use in conditional requests and
+   evaluating cache freshness ([RFC7234]) can result in a substantial
+   reduction of HTTP network traffic and can be a significant factor in
+   improving service scalability and reliability.
+
+2.3.2.  Comparison
+
+   There are two entity-tag comparison functions, depending on whether
+   or not the comparison context allows the use of weak validators:
+
+   o  Strong comparison: two entity-tags are equivalent if both are not
+      weak and their opaque-tags match character-by-character.
+
+   o  Weak comparison: two entity-tags are equivalent if their
+      opaque-tags match character-by-character, regardless of either or
+      both being tagged as "weak".
+
+
+
+
+
+
+
+
+
+Fielding & Reschke           Standards Track                   [Page 10]
+
+RFC 7232              HTTP/1.1 Conditional Requests            June 2014
+
+
+   The example below shows the results for a set of entity-tag pairs and
+   both the weak and strong comparison function results:
+
+   +--------+--------+-------------------+-----------------+
+   | ETag 1 | ETag 2 | Strong Comparison | Weak Comparison |
+   +--------+--------+-------------------+-----------------+
+   | W/"1"  | W/"1"  | no match          | match           |
+   | W/"1"  | W/"2"  | no match          | no match        |
+   | W/"1"  | "1"    | no match          | match           |
+   | "1"    | "1"    | match             | match           |
+   +--------+--------+-------------------+-----------------+
+
+2.3.3.  Example: Entity-Tags Varying on Content-Negotiated Resources
+
+   Consider a resource that is subject to content negotiation (Section
+   3.4 of [RFC7231]), and where the representations sent in response to
+   a GET request vary based on the Accept-Encoding request header field
+   (Section 5.3.4 of [RFC7231]):
+
+   >> Request:
+
+     GET /index HTTP/1.1
+     Host: www.example.com
+     Accept-Encoding: gzip
+
+
+   In this case, the response might or might not use the gzip content
+   coding.  If it does not, the response might look like:
+
+   >> Response:
+
+     HTTP/1.1 200 OK
+     Date: Fri, 26 Mar 2010 00:05:00 GMT
+     ETag: "123-a"
+     Content-Length: 70
+     Vary: Accept-Encoding
+     Content-Type: text/plain
+
+     Hello World!
+     Hello World!
+     Hello World!
+     Hello World!
+     Hello World!
+
+
+
+
+
+
+
+
+Fielding & Reschke           Standards Track                   [Page 11]
+
+RFC 7232              HTTP/1.1 Conditional Requests            June 2014
+
+
+   An alternative representation that does use gzip content coding would
+   be:
+
+   >> Response:
+
+     HTTP/1.1 200 OK
+     Date: Fri, 26 Mar 2010 00:05:00 GMT
+     ETag: "123-b"
+     Content-Length: 43
+     Vary: Accept-Encoding
+     Content-Type: text/plain
+     Content-Encoding: gzip
+
+     ...binary data...
+
+      Note: Content codings are a property of the representation data,
+      so a strong entity-tag for a content-encoded representation has to
+      be distinct from the entity tag of an unencoded representation to
+      prevent potential conflicts during cache updates and range
+      requests.  In contrast, transfer codings (Section 4 of [RFC7230])
+      apply only during message transfer and do not result in distinct
+      entity-tags.
+
+2.4.  When to Use Entity-Tags and Last-Modified Dates
+
+   In 200 (OK) responses to GET or HEAD, an origin server:
+
+   o  SHOULD send an entity-tag validator unless it is not feasible to
+      generate one.
+
+   o  MAY send a weak entity-tag instead of a strong entity-tag, if
+      performance considerations support the use of weak entity-tags, or
+      if it is unfeasible to send a strong entity-tag.
+
+   o  SHOULD send a Last-Modified value if it is feasible to send one.
+
+   In other words, the preferred behavior for an origin server is to
+   send both a strong entity-tag and a Last-Modified value in successful
+   responses to a retrieval request.
+
+   A client:
+
+   o  MUST send that entity-tag in any cache validation request (using
+      If-Match or If-None-Match) if an entity-tag has been provided by
+      the origin server.
+
+
+
+
+
+
+Fielding & Reschke           Standards Track                   [Page 12]
+
+RFC 7232              HTTP/1.1 Conditional Requests            June 2014
+
+
+   o  SHOULD send the Last-Modified value in non-subrange cache
+      validation requests (using If-Modified-Since) if only a
+      Last-Modified value has been provided by the origin server.
+
+   o  MAY send the Last-Modified value in subrange cache validation
+      requests (using If-Unmodified-Since) if only a Last-Modified value
+      has been provided by an HTTP/1.0 origin server.  The user agent
+      SHOULD provide a way to disable this, in case of difficulty.
+
+   o  SHOULD send both validators in cache validation requests if both
+      an entity-tag and a Last-Modified value have been provided by the
+      origin server.  This allows both HTTP/1.0 and HTTP/1.1 caches to
+      respond appropriately.
+
+3.  Precondition Header Fields
+
+   This section defines the syntax and semantics of HTTP/1.1 header
+   fields for applying preconditions on requests.  Section 5 defines
+   when the preconditions are applied.  Section 6 defines the order of
+   evaluation when more than one precondition is present.
+
+3.1.  If-Match
+
+   The "If-Match" header field makes the request method conditional on
+   the recipient origin server either having at least one current
+   representation of the target resource, when the field-value is "*",
+   or having a current representation of the target resource that has an
+   entity-tag matching a member of the list of entity-tags provided in
+   the field-value.
+
+   An origin server MUST use the strong comparison function when
+   comparing entity-tags for If-Match (Section 2.3.2), since the client
+   intends this precondition to prevent the method from being applied if
+   there have been any changes to the representation data.
+
+     If-Match = "*" / 1#entity-tag
+
+   Examples:
+
+     If-Match: "xyzzy"
+     If-Match: "xyzzy", "r2d2xxxx", "c3piozzzz"
+     If-Match: *
+
+   If-Match is most often used with state-changing methods (e.g., POST,
+   PUT, DELETE) to prevent accidental overwrites when multiple user
+   agents might be acting in parallel on the same resource (i.e., to
+
+
+
+
+
+Fielding & Reschke           Standards Track                   [Page 13]
+
+RFC 7232              HTTP/1.1 Conditional Requests            June 2014
+
+
+   prevent the "lost update" problem).  It can also be used with safe
+   methods to abort a request if the selected representation does not
+   match one already stored (or partially stored) from a prior request.
+
+   An origin server that receives an If-Match header field MUST evaluate
+   the condition prior to performing the method (Section 5).  If the
+   field-value is "*", the condition is false if the origin server does
+   not have a current representation for the target resource.  If the
+   field-value is a list of entity-tags, the condition is false if none
+   of the listed tags match the entity-tag of the selected
+   representation.
+
+   An origin server MUST NOT perform the requested method if a received
+   If-Match condition evaluates to false; instead, the origin server
+   MUST respond with either a) the 412 (Precondition Failed) status code
+   or b) one of the 2xx (Successful) status codes if the origin server
+   has verified that a state change is being requested and the final
+   state is already reflected in the current state of the target
+   resource (i.e., the change requested by the user agent has already
+   succeeded, but the user agent might not be aware of it, perhaps
+   because the prior response was lost or a compatible change was made
+   by some other user agent).  In the latter case, the origin server
+   MUST NOT send a validator header field in the response unless it can
+   verify that the request is a duplicate of an immediately prior change
+   made by the same user agent.
+
+   The If-Match header field can be ignored by caches and intermediaries
+   because it is not applicable to a stored response.
+
+3.2.  If-None-Match
+
+   The "If-None-Match" header field makes the request method conditional
+   on a recipient cache or origin server either not having any current
+   representation of the target resource, when the field-value is "*",
+   or having a selected representation with an entity-tag that does not
+   match any of those listed in the field-value.
+
+   A recipient MUST use the weak comparison function when comparing
+   entity-tags for If-None-Match (Section 2.3.2), since weak entity-tags
+   can be used for cache validation even if there have been changes to
+   the representation data.
+
+     If-None-Match = "*" / 1#entity-tag
+
+
+
+
+
+
+
+
+Fielding & Reschke           Standards Track                   [Page 14]
+
+RFC 7232              HTTP/1.1 Conditional Requests            June 2014
+
+
+   Examples:
+
+     If-None-Match: "xyzzy"
+     If-None-Match: W/"xyzzy"
+     If-None-Match: "xyzzy", "r2d2xxxx", "c3piozzzz"
+     If-None-Match: W/"xyzzy", W/"r2d2xxxx", W/"c3piozzzz"
+     If-None-Match: *
+
+   If-None-Match is primarily used in conditional GET requests to enable
+   efficient updates of cached information with a minimum amount of
+   transaction overhead.  When a client desires to update one or more
+   stored responses that have entity-tags, the client SHOULD generate an
+   If-None-Match header field containing a list of those entity-tags
+   when making a GET request; this allows recipient servers to send a
+   304 (Not Modified) response to indicate when one of those stored
+   responses matches the selected representation.
+
+   If-None-Match can also be used with a value of "*" to prevent an
+   unsafe request method (e.g., PUT) from inadvertently modifying an
+   existing representation of the target resource when the client
+   believes that the resource does not have a current representation
+   (Section 4.2.1 of [RFC7231]).  This is a variation on the "lost
+   update" problem that might arise if more than one client attempts to
+   create an initial representation for the target resource.
+
+   An origin server that receives an If-None-Match header field MUST
+   evaluate the condition prior to performing the method (Section 5).
+   If the field-value is "*", the condition is false if the origin
+   server has a current representation for the target resource.  If the
+   field-value is a list of entity-tags, the condition is false if one
+   of the listed tags match the entity-tag of the selected
+   representation.
+
+   An origin server MUST NOT perform the requested method if the
+   condition evaluates to false; instead, the origin server MUST respond
+   with either a) the 304 (Not Modified) status code if the request
+   method is GET or HEAD or b) the 412 (Precondition Failed) status code
+   for all other request methods.
+
+   Requirements on cache handling of a received If-None-Match header
+   field are defined in Section 4.3.2 of [RFC7234].
+
+
+
+
+
+
+
+
+
+
+Fielding & Reschke           Standards Track                   [Page 15]
+
+RFC 7232              HTTP/1.1 Conditional Requests            June 2014
+
+
+3.3.  If-Modified-Since
+
+   The "If-Modified-Since" header field makes a GET or HEAD request
+   method conditional on the selected representation's modification date
+   being more recent than the date provided in the field-value.
+   Transfer of the selected representation's data is avoided if that
+   data has not changed.
+
+     If-Modified-Since = HTTP-date
+
+   An example of the field is:
+
+     If-Modified-Since: Sat, 29 Oct 1994 19:43:31 GMT
+
+   A recipient MUST ignore If-Modified-Since if the request contains an
+   If-None-Match header field; the condition in If-None-Match is
+   considered to be a more accurate replacement for the condition in
+   If-Modified-Since, and the two are only combined for the sake of
+   interoperating with older intermediaries that might not implement
+   If-None-Match.
+
+   A recipient MUST ignore the If-Modified-Since header field if the
+   received field-value is not a valid HTTP-date, or if the request
+   method is neither GET nor HEAD.
+
+   A recipient MUST interpret an If-Modified-Since field-value's
+   timestamp in terms of the origin server's clock.
+
+   If-Modified-Since is typically used for two distinct purposes: 1) to
+   allow efficient updates of a cached representation that does not have
+   an entity-tag and 2) to limit the scope of a web traversal to
+   resources that have recently changed.
+
+   When used for cache updates, a cache will typically use the value of
+   the cached message's Last-Modified field to generate the field value
+   of If-Modified-Since.  This behavior is most interoperable for cases
+   where clocks are poorly synchronized or when the server has chosen to
+   only honor exact timestamp matches (due to a problem with
+   Last-Modified dates that appear to go "back in time" when the origin
+   server's clock is corrected or a representation is restored from an
+   archived backup).  However, caches occasionally generate the field
+   value based on other data, such as the Date header field of the
+   cached message or the local clock time that the message was received,
+   particularly when the cached message does not contain a Last-Modified
+   field.
+
+
+
+
+
+
+Fielding & Reschke           Standards Track                   [Page 16]
+
+RFC 7232              HTTP/1.1 Conditional Requests            June 2014
+
+
+   When used for limiting the scope of retrieval to a recent time
+   window, a user agent will generate an If-Modified-Since field value
+   based on either its own local clock or a Date header field received
+   from the server in a prior response.  Origin servers that choose an
+   exact timestamp match based on the selected representation's
+   Last-Modified field will not be able to help the user agent limit its
+   data transfers to only those changed during the specified window.
+
+   An origin server that receives an If-Modified-Since header field
+   SHOULD evaluate the condition prior to performing the method
+   (Section 5).  The origin server SHOULD NOT perform the requested
+   method if the selected representation's last modification date is
+   earlier than or equal to the date provided in the field-value;
+   instead, the origin server SHOULD generate a 304 (Not Modified)
+   response, including only those metadata that are useful for
+   identifying or updating a previously cached response.
+
+   Requirements on cache handling of a received If-Modified-Since header
+   field are defined in Section 4.3.2 of [RFC7234].
+
+3.4.  If-Unmodified-Since
+
+   The "If-Unmodified-Since" header field makes the request method
+   conditional on the selected representation's last modification date
+   being earlier than or equal to the date provided in the field-value.
+   This field accomplishes the same purpose as If-Match for cases where
+   the user agent does not have an entity-tag for the representation.
+
+     If-Unmodified-Since = HTTP-date
+
+   An example of the field is:
+
+     If-Unmodified-Since: Sat, 29 Oct 1994 19:43:31 GMT
+
+   A recipient MUST ignore If-Unmodified-Since if the request contains
+   an If-Match header field; the condition in If-Match is considered to
+   be a more accurate replacement for the condition in
+   If-Unmodified-Since, and the two are only combined for the sake of
+   interoperating with older intermediaries that might not implement
+   If-Match.
+
+   A recipient MUST ignore the If-Unmodified-Since header field if the
+   received field-value is not a valid HTTP-date.
+
+   A recipient MUST interpret an If-Unmodified-Since field-value's
+   timestamp in terms of the origin server's clock.
+
+
+
+
+
+Fielding & Reschke           Standards Track                   [Page 17]
+
+RFC 7232              HTTP/1.1 Conditional Requests            June 2014
+
+
+   If-Unmodified-Since is most often used with state-changing methods
+   (e.g., POST, PUT, DELETE) to prevent accidental overwrites when
+   multiple user agents might be acting in parallel on a resource that
+   does not supply entity-tags with its representations (i.e., to
+   prevent the "lost update" problem).  It can also be used with safe
+   methods to abort a request if the selected representation does not
+   match one already stored (or partially stored) from a prior request.
+
+   An origin server that receives an If-Unmodified-Since header field
+   MUST evaluate the condition prior to performing the method
+   (Section 5).  The origin server MUST NOT perform the requested method
+   if the selected representation's last modification date is more
+   recent than the date provided in the field-value; instead the origin
+   server MUST respond with either a) the 412 (Precondition Failed)
+   status code or b) one of the 2xx (Successful) status codes if the
+   origin server has verified that a state change is being requested and
+   the final state is already reflected in the current state of the
+   target resource (i.e., the change requested by the user agent has
+   already succeeded, but the user agent might not be aware of that
+   because the prior response message was lost or a compatible change
+   was made by some other user agent).  In the latter case, the origin
+   server MUST NOT send a validator header field in the response unless
+   it can verify that the request is a duplicate of an immediately prior
+   change made by the same user agent.
+
+   The If-Unmodified-Since header field can be ignored by caches and
+   intermediaries because it is not applicable to a stored response.
+
+3.5.  If-Range
+
+   The "If-Range" header field provides a special conditional request
+   mechanism that is similar to the If-Match and If-Unmodified-Since
+   header fields but that instructs the recipient to ignore the Range
+   header field if the validator doesn't match, resulting in transfer of
+   the new selected representation instead of a 412 (Precondition
+   Failed) response.  If-Range is defined in Section 3.2 of [RFC7233].
+
+4.  Status Code Definitions
+
+4.1.  304 Not Modified
+
+   The 304 (Not Modified) status code indicates that a conditional GET
+   or HEAD request has been received and would have resulted in a 200
+   (OK) response if it were not for the fact that the condition
+   evaluated to false.  In other words, there is no need for the server
+   to transfer a representation of the target resource because the
+   request indicates that the client, which made the request
+
+
+
+
+Fielding & Reschke           Standards Track                   [Page 18]
+
+RFC 7232              HTTP/1.1 Conditional Requests            June 2014
+
+
+   conditional, already has a valid representation; the server is
+   therefore redirecting the client to make use of that stored
+   representation as if it were the payload of a 200 (OK) response.
+
+   The server generating a 304 response MUST generate any of the
+   following header fields that would have been sent in a 200 (OK)
+   response to the same request: Cache-Control, Content-Location, Date,
+   ETag, Expires, and Vary.
+
+   Since the goal of a 304 response is to minimize information transfer
+   when the recipient already has one or more cached representations, a
+   sender SHOULD NOT generate representation metadata other than the
+   above listed fields unless said metadata exists for the purpose of
+   guiding cache updates (e.g., Last-Modified might be useful if the
+   response does not have an ETag field).
+
+   Requirements on a cache that receives a 304 response are defined in
+   Section 4.3.4 of [RFC7234].  If the conditional request originated
+   with an outbound client, such as a user agent with its own cache
+   sending a conditional GET to a shared proxy, then the proxy SHOULD
+   forward the 304 response to that client.
+
+   A 304 response cannot contain a message-body; it is always terminated
+   by the first empty line after the header fields.
+
+4.2.  412 Precondition Failed
+
+   The 412 (Precondition Failed) status code indicates that one or more
+   conditions given in the request header fields evaluated to false when
+   tested on the server.  This response code allows the client to place
+   preconditions on the current resource state (its current
+   representations and metadata) and, thus, prevent the request method
+   from being applied if the target resource is in an unexpected state.
+
+5.  Evaluation
+
+   Except when excluded below, a recipient cache or origin server MUST
+   evaluate received request preconditions after it has successfully
+   performed its normal request checks and just before it would perform
+   the action associated with the request method.  A server MUST ignore
+   all received preconditions if its response to the same request
+   without those conditions would have been a status code other than a
+   2xx (Successful) or 412 (Precondition Failed).  In other words,
+   redirects and failures take precedence over the evaluation of
+   preconditions in conditional requests.
+
+
+
+
+
+
+Fielding & Reschke           Standards Track                   [Page 19]
+
+RFC 7232              HTTP/1.1 Conditional Requests            June 2014
+
+
+   A server that is not the origin server for the target resource and
+   cannot act as a cache for requests on the target resource MUST NOT
+   evaluate the conditional request header fields defined by this
+   specification, and it MUST forward them if the request is forwarded,
+   since the generating client intends that they be evaluated by a
+   server that can provide a current representation.  Likewise, a server
+   MUST ignore the conditional request header fields defined by this
+   specification when received with a request method that does not
+   involve the selection or modification of a selected representation,
+   such as CONNECT, OPTIONS, or TRACE.
+
+   Conditional request header fields that are defined by extensions to
+   HTTP might place conditions on all recipients, on the state of the
+   target resource in general, or on a group of resources.  For
+   instance, the "If" header field in WebDAV can make a request
+   conditional on various aspects of multiple resources, such as locks,
+   if the recipient understands and implements that field ([RFC4918],
+   Section 10.4).
+
+   Although conditional request header fields are defined as being
+   usable with the HEAD method (to keep HEAD's semantics consistent with
+   those of GET), there is no point in sending a conditional HEAD
+   because a successful response is around the same size as a 304 (Not
+   Modified) response and more useful than a 412 (Precondition Failed)
+   response.
+
+6.  Precedence
+
+   When more than one conditional request header field is present in a
+   request, the order in which the fields are evaluated becomes
+   important.  In practice, the fields defined in this document are
+   consistently implemented in a single, logical order, since "lost
+   update" preconditions have more strict requirements than cache
+   validation, a validated cache is more efficient than a partial
+   response, and entity tags are presumed to be more accurate than date
+   validators.
+
+   A recipient cache or origin server MUST evaluate the request
+   preconditions defined by this specification in the following order:
+
+   1.  When recipient is the origin server and If-Match is present,
+       evaluate the If-Match precondition:
+
+       *  if true, continue to step 3
+
+       *  if false, respond 412 (Precondition Failed) unless it can be
+          determined that the state-changing request has already
+          succeeded (see Section 3.1)
+
+
+
+Fielding & Reschke           Standards Track                   [Page 20]
+
+RFC 7232              HTTP/1.1 Conditional Requests            June 2014
+
+
+   2.  When recipient is the origin server, If-Match is not present, and
+       If-Unmodified-Since is present, evaluate the If-Unmodified-Since
+       precondition:
+
+       *  if true, continue to step 3
+
+       *  if false, respond 412 (Precondition Failed) unless it can be
+          determined that the state-changing request has already
+          succeeded (see Section 3.4)
+
+   3.  When If-None-Match is present, evaluate the If-None-Match
+       precondition:
+
+       *  if true, continue to step 5
+
+       *  if false for GET/HEAD, respond 304 (Not Modified)
+
+       *  if false for other methods, respond 412 (Precondition Failed)
+
+   4.  When the method is GET or HEAD, If-None-Match is not present, and
+       If-Modified-Since is present, evaluate the If-Modified-Since
+       precondition:
+
+       *  if true, continue to step 5
+
+       *  if false, respond 304 (Not Modified)
+
+   5.  When the method is GET and both Range and If-Range are present,
+       evaluate the If-Range precondition:
+
+       *  if the validator matches and the Range specification is
+          applicable to the selected representation, respond 206
+          (Partial Content) [RFC7233]
+
+   6.  Otherwise,
+
+       *  all conditions are met, so perform the requested action and
+          respond according to its success or failure.
+
+   Any extension to HTTP/1.1 that defines additional conditional request
+   header fields ought to define its own expectations regarding the
+   order for evaluating such fields in relation to those defined in this
+   document and other conditionals that might be found in practice.
+
+
+
+
+
+
+
+
+Fielding & Reschke           Standards Track                   [Page 21]
+
+RFC 7232              HTTP/1.1 Conditional Requests            June 2014
+
+
+7.  IANA Considerations
+
+7.1.  Status Code Registration
+
+   The "Hypertext Transfer Protocol (HTTP) Status Code Registry" located
+   at <http://www.iana.org/assignments/http-status-codes> has been
+   updated with the registrations below:
+
+   +-------+---------------------+-------------+
+   | Value | Description         | Reference   |
+   +-------+---------------------+-------------+
+   | 304   | Not Modified        | Section 4.1 |
+   | 412   | Precondition Failed | Section 4.2 |
+   +-------+---------------------+-------------+
+
+7.2.  Header Field Registration
+
+   HTTP header fields are registered within the "Message Headers"
+   registry maintained at
+   <http://www.iana.org/assignments/message-headers/>.
+
+   This document defines the following HTTP header fields, so their
+   associated registry entries have been updated according to the
+   permanent registrations below (see [BCP90]):
+
+   +---------------------+----------+----------+-------------+
+   | Header Field Name   | Protocol | Status   | Reference   |
+   +---------------------+----------+----------+-------------+
+   | ETag                | http     | standard | Section 2.3 |
+   | If-Match            | http     | standard | Section 3.1 |
+   | If-Modified-Since   | http     | standard | Section 3.3 |
+   | If-None-Match       | http     | standard | Section 3.2 |
+   | If-Unmodified-Since | http     | standard | Section 3.4 |
+   | Last-Modified       | http     | standard | Section 2.2 |
+   +---------------------+----------+----------+-------------+
+
+   The change controller is: "IETF (iesg@ietf.org) - Internet
+   Engineering Task Force".
+
+8.  Security Considerations
+
+   This section is meant to inform developers, information providers,
+   and users of known security concerns specific to the HTTP conditional
+   request mechanisms.  More general security considerations are
+   addressed in HTTP "Message Syntax and Routing" [RFC7230] and
+   "Semantics and Content" [RFC7231].
+
+
+
+
+
+Fielding & Reschke           Standards Track                   [Page 22]
+
+RFC 7232              HTTP/1.1 Conditional Requests            June 2014
+
+
+   The validators defined by this specification are not intended to
+   ensure the validity of a representation, guard against malicious
+   changes, or detect man-in-the-middle attacks.  At best, they enable
+   more efficient cache updates and optimistic concurrent writes when
+   all participants are behaving nicely.  At worst, the conditions will
+   fail and the client will receive a response that is no more harmful
+   than an HTTP exchange without conditional requests.
+
+   An entity-tag can be abused in ways that create privacy risks.  For
+   example, a site might deliberately construct a semantically invalid
+   entity-tag that is unique to the user or user agent, send it in a
+   cacheable response with a long freshness time, and then read that
+   entity-tag in later conditional requests as a means of re-identifying
+   that user or user agent.  Such an identifying tag would become a
+   persistent identifier for as long as the user agent retained the
+   original cache entry.  User agents that cache representations ought
+   to ensure that the cache is cleared or replaced whenever the user
+   performs privacy-maintaining actions, such as clearing stored cookies
+   or changing to a private browsing mode.
+
+9.  Acknowledgments
+
+   See Section 10 of [RFC7230].
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+Fielding & Reschke           Standards Track                   [Page 23]
+
+RFC 7232              HTTP/1.1 Conditional Requests            June 2014
+
+
+10.  References
+
+10.1.  Normative References
+
+   [RFC2119]  Bradner, S., "Key words for use in RFCs to Indicate
+              Requirement Levels", BCP 14, RFC 2119, March 1997.
+
+   [RFC5234]  Crocker, D., Ed. and P. Overell, "Augmented BNF for Syntax
+              Specifications: ABNF", STD 68, RFC 5234, January 2008.
+
+   [RFC7230]  Fielding, R., Ed. and J. Reschke, Ed., "Hypertext Transfer
+              Protocol (HTTP/1.1): Message Syntax and Routing",
+              RFC 7230, June 2014.
+
+   [RFC7231]  Fielding, R., Ed. and J. Reschke, Ed., "Hypertext Transfer
+              Protocol (HTTP/1.1): Semantics and Content", RFC 7231,
+              June 2014.
+
+   [RFC7233]  Fielding, R., Ed., Lafon, Y., Ed., and J. Reschke, Ed.,
+              "Hypertext Transfer Protocol (HTTP/1.1): Range Requests",
+              RFC 7233, June 2014.
+
+   [RFC7234]  Fielding, R., Ed., Nottingham, M., Ed., and J. Reschke,
+              Ed., "Hypertext Transfer Protocol (HTTP/1.1): Caching",
+              RFC 7234, June 2014.
+
+10.2.  Informative References
+
+   [BCP90]    Klyne, G., Nottingham, M., and J. Mogul, "Registration
+              Procedures for Message Header Fields", BCP 90, RFC 3864,
+              September 2004.
+
+   [RFC2616]  Fielding, R., Gettys, J., Mogul, J., Frystyk, H.,
+              Masinter, L., Leach, P., and T. Berners-Lee, "Hypertext
+              Transfer Protocol -- HTTP/1.1", RFC 2616, June 1999.
+
+   [RFC4918]  Dusseault, L., Ed., "HTTP Extensions for Web Distributed
+              Authoring and Versioning (WebDAV)", RFC 4918, June 2007.
+
+
+
+
+
+
+
+
+
+
+
+
+
+Fielding & Reschke           Standards Track                   [Page 24]
+
+RFC 7232              HTTP/1.1 Conditional Requests            June 2014
+
+
+Appendix A.  Changes from RFC 2616
+
+   The definition of validator weakness has been expanded and clarified.
+   (Section 2.1)
+
+   Weak entity-tags are now allowed in all requests except range
+   requests.  (Sections 2.1 and 3.2)
+
+   The ETag header field ABNF has been changed to not use quoted-string,
+   thus avoiding escaping issues.  (Section 2.3)
+
+   ETag is defined to provide an entity tag for the selected
+   representation, thereby clarifying what it applies to in various
+   situations (such as a PUT response).  (Section 2.3)
+
+   The precedence for evaluation of conditional requests has been
+   defined.  (Section 6)
+
+Appendix B.  Imported ABNF
+
+   The following core rules are included by reference, as defined in
+   Appendix B.1 of [RFC5234]: ALPHA (letters), CR (carriage return),
+   CRLF (CR LF), CTL (controls), DIGIT (decimal 0-9), DQUOTE (double
+   quote), HEXDIG (hexadecimal 0-9/A-F/a-f), LF (line feed), OCTET (any
+   8-bit sequence of data), SP (space), and VCHAR (any visible US-ASCII
+   character).
+
+   The rules below are defined in [RFC7230]:
+
+     OWS           = <OWS, see [RFC7230], Section 3.2.3>
+     obs-text      = <obs-text, see [RFC7230], Section 3.2.6>
+
+   The rules below are defined in other parts:
+
+     HTTP-date     = <HTTP-date, see [RFC7231], Section 7.1.1.1>
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+Fielding & Reschke           Standards Track                   [Page 25]
+
+RFC 7232              HTTP/1.1 Conditional Requests            June 2014
+
+
+Appendix C.  Collected ABNF
+
+   In the collected ABNF below, list rules are expanded as per Section
+   1.2 of [RFC7230].
+
+   ETag = entity-tag
+
+   HTTP-date = <HTTP-date, see [RFC7231], Section 7.1.1.1>
+
+   If-Match = "*" / ( *( "," OWS ) entity-tag *( OWS "," [ OWS
+    entity-tag ] ) )
+   If-Modified-Since = HTTP-date
+   If-None-Match = "*" / ( *( "," OWS ) entity-tag *( OWS "," [ OWS
+    entity-tag ] ) )
+   If-Unmodified-Since = HTTP-date
+
+   Last-Modified = HTTP-date
+
+   OWS = <OWS, see [RFC7230], Section 3.2.3>
+
+   entity-tag = [ weak ] opaque-tag
+   etagc = "!" / %x23-7E ; '#'-'~'
+    / obs-text
+
+   obs-text = <obs-text, see [RFC7230], Section 3.2.6>
+   opaque-tag = DQUOTE *etagc DQUOTE
+
+   weak = %x57.2F ; W/
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+Fielding & Reschke           Standards Track                   [Page 26]
+
+RFC 7232              HTTP/1.1 Conditional Requests            June 2014
+
+
+Index
+
+   3
+      304 Not Modified (status code)  19
+
+   4
+      412 Precondition Failed (status code)  18
+
+   E
+      ETag header field  9
+
+   G
+      Grammar
+         entity-tag  9
+         ETag  9
+         etagc  9
+         If-Match  13
+         If-Modified-Since  15
+         If-None-Match  14
+         If-Unmodified-Since  17
+         Last-Modified  7
+         opaque-tag  9
+         weak  9
+
+   I
+      If-Match header field  13
+      If-Modified-Since header field  16
+      If-None-Match header field  14
+      If-Unmodified-Since header field  17
+
+   L
+      Last-Modified header field  7
+
+   M
+      metadata  5
+
+   S
+      selected representation  4
+
+   V
+      validator  5
+         strong  5
+         weak  5
+
+
+
+
+
+
+
+
+Fielding & Reschke           Standards Track                   [Page 27]
+
+RFC 7232              HTTP/1.1 Conditional Requests            June 2014
+
+
+Authors' Addresses
+
+   Roy T. Fielding (editor)
+   Adobe Systems Incorporated
+   345 Park Ave
+   San Jose, CA  95110
+   USA
+
+   EMail: fielding@gbiv.com
+   URI:   http://roy.gbiv.com/
+
+
+   Julian F. Reschke (editor)
+   greenbytes GmbH
+   Hafenweg 16
+   Muenster, NW  48155
+   Germany
+
+   EMail: julian.reschke@greenbytes.de
+   URI:   http://greenbytes.de/tech/webdav/
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+Fielding & Reschke           Standards Track                   [Page 28]
+
@@ -0,0 +1,1403 @@
+
+
+
+
+
+
+Internet Engineering Task Force (IETF)                  R. Fielding, Ed.
+Request for Comments: 7233                                         Adobe
+Obsoletes: 2616                                            Y. Lafon, Ed.
+Category: Standards Track                                            W3C
+ISSN: 2070-1721                                          J. Reschke, Ed.
+                                                              greenbytes
+                                                              June 2014
+
+
+         Hypertext Transfer Protocol (HTTP/1.1): Range Requests
+
+Abstract
+
+   The Hypertext Transfer Protocol (HTTP) is a stateless application-
+   level protocol for distributed, collaborative, hypertext information
+   systems.  This document defines range requests and the rules for
+   constructing and combining responses to those requests.
+
+Status of This Memo
+
+   This is an Internet Standards Track document.
+
+   This document is a product of the Internet Engineering Task Force
+   (IETF).  It represents the consensus of the IETF community.  It has
+   received public review and has been approved for publication by the
+   Internet Engineering Steering Group (IESG).  Further information on
+   Internet Standards is available in Section 2 of RFC 5741.
+
+   Information about the current status of this document, any errata,
+   and how to provide feedback on it may be obtained at
+   http://www.rfc-editor.org/info/rfc7233.
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+Fielding, et al.             Standards Track                    [Page 1]
+
+RFC 7233                 HTTP/1.1 Range Requests               June 2014
+
+
+Copyright Notice
+
+   Copyright (c) 2014 IETF Trust and the persons identified as the
+   document authors.  All rights reserved.
+
+   This document is subject to BCP 78 and the IETF Trust's Legal
+   Provisions Relating to IETF Documents
+   (http://trustee.ietf.org/license-info) in effect on the date of
+   publication of this document.  Please review these documents
+   carefully, as they describe your rights and restrictions with respect
+   to this document.  Code Components extracted from this document must
+   include Simplified BSD License text as described in Section 4.e of
+   the Trust Legal Provisions and are provided without warranty as
+   described in the Simplified BSD License.
+
+   This document may contain material from IETF Documents or IETF
+   Contributions published or made publicly available before November
+   10, 2008.  The person(s) controlling the copyright in some of this
+   material may not have granted the IETF Trust the right to allow
+   modifications of such material outside the IETF Standards Process.
+   Without obtaining an adequate license from the person(s) controlling
+   the copyright in such materials, this document may not be modified
+   outside the IETF Standards Process, and derivative works of it may
+   not be created outside the IETF Standards Process, except to format
+   it for publication as an RFC or to translate it into languages other
+   than English.
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+Fielding, et al.             Standards Track                    [Page 2]
+
+RFC 7233                 HTTP/1.1 Range Requests               June 2014
+
+
+Table of Contents
+
+   1. Introduction ....................................................4
+      1.1. Conformance and Error Handling .............................4
+      1.2. Syntax Notation ............................................4
+   2. Range Units .....................................................5
+      2.1. Byte Ranges ................................................5
+      2.2. Other Range Units ..........................................7
+      2.3. Accept-Ranges ..............................................7
+   3. Range Requests ..................................................8
+      3.1. Range ......................................................8
+      3.2. If-Range ...................................................9
+   4. Responses to a Range Request ...................................10
+      4.1. 206 Partial Content .......................................10
+      4.2. Content-Range .............................................12
+      4.3. Combining Ranges ..........................................14
+      4.4. 416 Range Not Satisfiable .................................15
+   5. IANA Considerations ............................................16
+      5.1. Range Unit Registry .......................................16
+           5.1.1. Procedure ..........................................16
+           5.1.2. Registrations ......................................16
+      5.2. Status Code Registration ..................................17
+      5.3. Header Field Registration .................................17
+      5.4. Internet Media Type Registration ..........................17
+           5.4.1. Internet Media Type multipart/byteranges ...........18
+   6. Security Considerations ........................................19
+      6.1. Denial-of-Service Attacks Using Range .....................19
+   7. Acknowledgments ................................................19
+   8. References .....................................................20
+      8.1. Normative References ......................................20
+      8.2. Informative References ....................................20
+   Appendix A. Internet Media Type multipart/byteranges ..............21
+   Appendix B. Changes from RFC 2616 .................................22
+   Appendix C. Imported ABNF .........................................22
+   Appendix D. Collected ABNF ........................................23
+   Index .............................................................24
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+Fielding, et al.             Standards Track                    [Page 3]
+
+RFC 7233                 HTTP/1.1 Range Requests               June 2014
+
+
+1.  Introduction
+
+   Hypertext Transfer Protocol (HTTP) clients often encounter
+   interrupted data transfers as a result of canceled requests or
+   dropped connections.  When a client has stored a partial
+   representation, it is desirable to request the remainder of that
+   representation in a subsequent request rather than transfer the
+   entire representation.  Likewise, devices with limited local storage
+   might benefit from being able to request only a subset of a larger
+   representation, such as a single page of a very large document, or
+   the dimensions of an embedded image.
+
+   This document defines HTTP/1.1 range requests, partial responses, and
+   the multipart/byteranges media type.  Range requests are an OPTIONAL
+   feature of HTTP, designed so that recipients not implementing this
+   feature (or not supporting it for the target resource) can respond as
+   if it is a normal GET request without impacting interoperability.
+   Partial responses are indicated by a distinct status code to not be
+   mistaken for full responses by caches that might not implement the
+   feature.
+
+   Although the range request mechanism is designed to allow for
+   extensible range types, this specification only defines requests for
+   byte ranges.
+
+1.1.  Conformance and Error Handling
+
+   The key words "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT",
+   "SHOULD", "SHOULD NOT", "RECOMMENDED", "MAY", and "OPTIONAL" in this
+   document are to be interpreted as described in [RFC2119].
+
+   Conformance criteria and considerations regarding error handling are
+   defined in Section 2.5 of [RFC7230].
+
+1.2.  Syntax Notation
+
+   This specification uses the Augmented Backus-Naur Form (ABNF)
+   notation of [RFC5234] with a list extension, defined in Section 7 of
+   [RFC7230], that allows for compact definition of comma-separated
+   lists using a '#' operator (similar to how the '*' operator indicates
+   repetition).  Appendix C describes rules imported from other
+   documents.  Appendix D shows the collected grammar with all list
+   operators expanded to standard ABNF notation.
+
+
+
+
+
+
+
+
+Fielding, et al.             Standards Track                    [Page 4]
+
+RFC 7233                 HTTP/1.1 Range Requests               June 2014
+
+
+2.  Range Units
+
+   A representation can be partitioned into subranges according to
+   various structural units, depending on the structure inherent in the
+   representation's media type.  This "range unit" is used in the
+   Accept-Ranges (Section 2.3) response header field to advertise
+   support for range requests, the Range (Section 3.1) request header
+   field to delineate the parts of a representation that are requested,
+   and the Content-Range (Section 4.2) payload header field to describe
+   which part of a representation is being transferred.
+
+     range-unit       = bytes-unit / other-range-unit
+
+2.1.  Byte Ranges
+
+   Since representation data is transferred in payloads as a sequence of
+   octets, a byte range is a meaningful substructure for any
+   representation transferable over HTTP (Section 3 of [RFC7231]).  The
+   "bytes" range unit is defined for expressing subranges of the data's
+   octet sequence.
+
+     bytes-unit       = "bytes"
+
+   A byte-range request can specify a single range of bytes or a set of
+   ranges within a single representation.
+
+     byte-ranges-specifier = bytes-unit "=" byte-range-set
+     byte-range-set  = 1#( byte-range-spec / suffix-byte-range-spec )
+     byte-range-spec = first-byte-pos "-" [ last-byte-pos ]
+     first-byte-pos  = 1*DIGIT
+     last-byte-pos   = 1*DIGIT
+
+   The first-byte-pos value in a byte-range-spec gives the byte-offset
+   of the first byte in a range.  The last-byte-pos value gives the
+   byte-offset of the last byte in the range; that is, the byte
+   positions specified are inclusive.  Byte offsets start at zero.
+
+   Examples of byte-ranges-specifier values:
+
+   o  The first 500 bytes (byte offsets 0-499, inclusive):
+
+        bytes=0-499
+
+   o  The second 500 bytes (byte offsets 500-999, inclusive):
+
+        bytes=500-999
+
+
+
+
+
+Fielding, et al.             Standards Track                    [Page 5]
+
+RFC 7233                 HTTP/1.1 Range Requests               June 2014
+
+
+   A byte-range-spec is invalid if the last-byte-pos value is present
+   and less than the first-byte-pos.
+
+   A client can limit the number of bytes requested without knowing the
+   size of the selected representation.  If the last-byte-pos value is
+   absent, or if the value is greater than or equal to the current
+   length of the representation data, the byte range is interpreted as
+   the remainder of the representation (i.e., the server replaces the
+   value of last-byte-pos with a value that is one less than the current
+   length of the selected representation).
+
+   A client can request the last N bytes of the selected representation
+   using a suffix-byte-range-spec.
+
+     suffix-byte-range-spec = "-" suffix-length
+     suffix-length = 1*DIGIT
+
+   If the selected representation is shorter than the specified
+   suffix-length, the entire representation is used.
+
+   Additional examples, assuming a representation of length 10000:
+
+   o  The final 500 bytes (byte offsets 9500-9999, inclusive):
+
+        bytes=-500
+
+   Or:
+
+        bytes=9500-
+
+   o  The first and last bytes only (bytes 0 and 9999):
+
+        bytes=0-0,-1
+
+   o  Other valid (but not canonical) specifications of the second 500
+      bytes (byte offsets 500-999, inclusive):
+
+        bytes=500-600,601-999
+        bytes=500-700,601-999
+
+   If a valid byte-range-set includes at least one byte-range-spec with
+   a first-byte-pos that is less than the current length of the
+   representation, or at least one suffix-byte-range-spec with a
+   non-zero suffix-length, then the byte-range-set is satisfiable.
+   Otherwise, the byte-range-set is unsatisfiable.
+
+
+
+
+
+
+Fielding, et al.             Standards Track                    [Page 6]
+
+RFC 7233                 HTTP/1.1 Range Requests               June 2014
+
+
+   In the byte-range syntax, first-byte-pos, last-byte-pos, and
+   suffix-length are expressed as decimal number of octets.  Since there
+   is no predefined limit to the length of a payload, recipients MUST
+   anticipate potentially large decimal numerals and prevent parsing
+   errors due to integer conversion overflows.
+
+2.2.  Other Range Units
+
+   Range units are intended to be extensible.  New range units ought to
+   be registered with IANA, as defined in Section 5.1.
+
+     other-range-unit = token
+
+2.3.  Accept-Ranges
+
+   The "Accept-Ranges" header field allows a server to indicate that it
+   supports range requests for the target resource.
+
+     Accept-Ranges     = acceptable-ranges
+     acceptable-ranges = 1#range-unit / "none"
+
+   An origin server that supports byte-range requests for a given target
+   resource MAY send
+
+     Accept-Ranges: bytes
+
+   to indicate what range units are supported.  A client MAY generate
+   range requests without having received this header field for the
+   resource involved.  Range units are defined in Section 2.
+
+   A server that does not support any kind of range request for the
+   target resource MAY send
+
+     Accept-Ranges: none
+
+   to advise the client not to attempt a range request.
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+Fielding, et al.             Standards Track                    [Page 7]
+
+RFC 7233                 HTTP/1.1 Range Requests               June 2014
+
+
+3.  Range Requests
+
+3.1.  Range
+
+   The "Range" header field on a GET request modifies the method
+   semantics to request transfer of only one or more subranges of the
+   selected representation data, rather than the entire selected
+   representation data.
+
+     Range = byte-ranges-specifier / other-ranges-specifier
+     other-ranges-specifier = other-range-unit "=" other-range-set
+     other-range-set = 1*VCHAR
+
+   A server MAY ignore the Range header field.  However, origin servers
+   and intermediate caches ought to support byte ranges when possible,
+   since Range supports efficient recovery from partially failed
+   transfers and partial retrieval of large representations.  A server
+   MUST ignore a Range header field received with a request method other
+   than GET.
+
+   An origin server MUST ignore a Range header field that contains a
+   range unit it does not understand.  A proxy MAY discard a Range
+   header field that contains a range unit it does not understand.
+
+   A server that supports range requests MAY ignore or reject a Range
+   header field that consists of more than two overlapping ranges, or a
+   set of many small ranges that are not listed in ascending order,
+   since both are indications of either a broken client or a deliberate
+   denial-of-service attack (Section 6.1).  A client SHOULD NOT request
+   multiple ranges that are inherently less efficient to process and
+   transfer than a single range that encompasses the same data.
+
+   A client that is requesting multiple ranges SHOULD list those ranges
+   in ascending order (the order in which they would typically be
+   received in a complete representation) unless there is a specific
+   need to request a later part earlier.  For example, a user agent
+   processing a large representation with an internal catalog of parts
+   might need to request later parts first, particularly if the
+   representation consists of pages stored in reverse order and the user
+   agent wishes to transfer one page at a time.
+
+   The Range header field is evaluated after evaluating the precondition
+   header fields defined in [RFC7232], and only if the result in absence
+   of the Range header field would be a 200 (OK) response.  In other
+   words, Range is ignored when a conditional GET would result in a 304
+   (Not Modified) response.
+
+
+
+
+
+Fielding, et al.             Standards Track                    [Page 8]
+
+RFC 7233                 HTTP/1.1 Range Requests               June 2014
+
+
+   The If-Range header field (Section 3.2) can be used as a precondition
+   to applying the Range header field.
+
+   If all of the preconditions are true, the server supports the Range
+   header field for the target resource, and the specified range(s) are
+   valid and satisfiable (as defined in Section 2.1), the server SHOULD
+   send a 206 (Partial Content) response with a payload containing one
+   or more partial representations that correspond to the satisfiable
+   ranges requested, as defined in Section 4.
+
+   If all of the preconditions are true, the server supports the Range
+   header field for the target resource, and the specified range(s) are
+   invalid or unsatisfiable, the server SHOULD send a 416 (Range Not
+   Satisfiable) response.
+
+3.2.  If-Range
+
+   If a client has a partial copy of a representation and wishes to have
+   an up-to-date copy of the entire representation, it could use the
+   Range header field with a conditional GET (using either or both of
+   If-Unmodified-Since and If-Match.)  However, if the precondition
+   fails because the representation has been modified, the client would
+   then have to make a second request to obtain the entire current
+   representation.
+
+   The "If-Range" header field allows a client to "short-circuit" the
+   second request.  Informally, its meaning is as follows: if the
+   representation is unchanged, send me the part(s) that I am requesting
+   in Range; otherwise, send me the entire representation.
+
+     If-Range = entity-tag / HTTP-date
+
+   A client MUST NOT generate an If-Range header field in a request that
+   does not contain a Range header field.  A server MUST ignore an
+   If-Range header field received in a request that does not contain a
+   Range header field.  An origin server MUST ignore an If-Range header
+   field received in a request for a target resource that does not
+   support Range requests.
+
+   A client MUST NOT generate an If-Range header field containing an
+   entity-tag that is marked as weak.  A client MUST NOT generate an
+   If-Range header field containing an HTTP-date unless the client has
+   no entity-tag for the corresponding representation and the date is a
+   strong validator in the sense defined by Section 2.2.2 of [RFC7232].
+
+   A server that evaluates an If-Range precondition MUST use the strong
+   comparison function when comparing entity-tags (Section 2.3.2 of
+   [RFC7232]) and MUST evaluate the condition as false if an HTTP-date
+
+
+
+Fielding, et al.             Standards Track                    [Page 9]
+
+RFC 7233                 HTTP/1.1 Range Requests               June 2014
+
+
+   validator is provided that is not a strong validator in the sense
+   defined by Section 2.2.2 of [RFC7232].  A valid entity-tag can be
+   distinguished from a valid HTTP-date by examining the first two
+   characters for a DQUOTE.
+
+   If the validator given in the If-Range header field matches the
+   current validator for the selected representation of the target
+   resource, then the server SHOULD process the Range header field as
+   requested.  If the validator does not match, the server MUST ignore
+   the Range header field.  Note that this comparison by exact match,
+   including when the validator is an HTTP-date, differs from the
+   "earlier than or equal to" comparison used when evaluating an
+   If-Unmodified-Since conditional.
+
+4.  Responses to a Range Request
+
+4.1.  206 Partial Content
+
+   The 206 (Partial Content) status code indicates that the server is
+   successfully fulfilling a range request for the target resource by
+   transferring one or more parts of the selected representation that
+   correspond to the satisfiable ranges found in the request's Range
+   header field (Section 3.1).
+
+   If a single part is being transferred, the server generating the 206
+   response MUST generate a Content-Range header field, describing what
+   range of the selected representation is enclosed, and a payload
+   consisting of the range.  For example:
+
+     HTTP/1.1 206 Partial Content
+     Date: Wed, 15 Nov 1995 06:25:24 GMT
+     Last-Modified: Wed, 15 Nov 1995 04:58:08 GMT
+     Content-Range: bytes 21010-47021/47022
+     Content-Length: 26012
+     Content-Type: image/gif
+
+     ... 26012 bytes of partial image data ...
+
+   If multiple parts are being transferred, the server generating the
+   206 response MUST generate a "multipart/byteranges" payload, as
+   defined in Appendix A, and a Content-Type header field containing the
+   multipart/byteranges media type and its required boundary parameter.
+   To avoid confusion with single-part responses, a server MUST NOT
+   generate a Content-Range header field in the HTTP header section of a
+   multiple part response (this field will be sent in each part
+   instead).
+
+
+
+
+
+Fielding, et al.             Standards Track                   [Page 10]
+
+RFC 7233                 HTTP/1.1 Range Requests               June 2014
+
+
+   Within the header area of each body part in the multipart payload,
+   the server MUST generate a Content-Range header field corresponding
+   to the range being enclosed in that body part.  If the selected
+   representation would have had a Content-Type header field in a 200
+   (OK) response, the server SHOULD generate that same Content-Type
+   field in the header area of each body part.  For example:
+
+     HTTP/1.1 206 Partial Content
+     Date: Wed, 15 Nov 1995 06:25:24 GMT
+     Last-Modified: Wed, 15 Nov 1995 04:58:08 GMT
+     Content-Length: 1741
+     Content-Type: multipart/byteranges; boundary=THIS_STRING_SEPARATES
+
+     --THIS_STRING_SEPARATES
+     Content-Type: application/pdf
+     Content-Range: bytes 500-999/8000
+
+     ...the first range...
+     --THIS_STRING_SEPARATES
+     Content-Type: application/pdf
+     Content-Range: bytes 7000-7999/8000
+
+     ...the second range
+     --THIS_STRING_SEPARATES--
+
+   When multiple ranges are requested, a server MAY coalesce any of the
+   ranges that overlap, or that are separated by a gap that is smaller
+   than the overhead of sending multiple parts, regardless of the order
+   in which the corresponding byte-range-spec appeared in the received
+   Range header field.  Since the typical overhead between parts of a
+   multipart/byteranges payload is around 80 bytes, depending on the
+   selected representation's media type and the chosen boundary
+   parameter length, it can be less efficient to transfer many small
+   disjoint parts than it is to transfer the entire selected
+   representation.
+
+   A server MUST NOT generate a multipart response to a request for a
+   single range, since a client that does not request multiple parts
+   might not support multipart responses.  However, a server MAY
+   generate a multipart/byteranges payload with only a single body part
+   if multiple ranges were requested and only one range was found to be
+   satisfiable or only one range remained after coalescing.  A client
+   that cannot process a multipart/byteranges response MUST NOT generate
+   a request that asks for multiple ranges.
+
+   When a multipart response payload is generated, the server SHOULD
+   send the parts in the same order that the corresponding
+   byte-range-spec appeared in the received Range header field,
+
+
+
+Fielding, et al.             Standards Track                   [Page 11]
+
+RFC 7233                 HTTP/1.1 Range Requests               June 2014
+
+
+   excluding those ranges that were deemed unsatisfiable or that were
+   coalesced into other ranges.  A client that receives a multipart
+   response MUST inspect the Content-Range header field present in each
+   body part in order to determine which range is contained in that body
+   part; a client cannot rely on receiving the same ranges that it
+   requested, nor the same order that it requested.
+
+   When a 206 response is generated, the server MUST generate the
+   following header fields, in addition to those required above, if the
+   field would have been sent in a 200 (OK) response to the same
+   request: Date, Cache-Control, ETag, Expires, Content-Location, and
+   Vary.
+
+   If a 206 is generated in response to a request with an If-Range
+   header field, the sender SHOULD NOT generate other representation
+   header fields beyond those required above, because the client is
+   understood to already have a prior response containing those header
+   fields.  Otherwise, the sender MUST generate all of the
+   representation header fields that would have been sent in a 200 (OK)
+   response to the same request.
+
+   A 206 response is cacheable by default; i.e., unless otherwise
+   indicated by explicit cache controls (see Section 4.2.2 of
+   [RFC7234]).
+
+4.2.  Content-Range
+
+   The "Content-Range" header field is sent in a single part 206
+   (Partial Content) response to indicate the partial range of the
+   selected representation enclosed as the message payload, sent in each
+   part of a multipart 206 response to indicate the range enclosed
+   within each body part, and sent in 416 (Range Not Satisfiable)
+   responses to provide information about the selected representation.
+
+     Content-Range       = byte-content-range
+                         / other-content-range
+
+     byte-content-range  = bytes-unit SP
+                           ( byte-range-resp / unsatisfied-range )
+
+     byte-range-resp     = byte-range "/" ( complete-length / "*" )
+     byte-range          = first-byte-pos "-" last-byte-pos
+     unsatisfied-range   = "*/" complete-length
+
+     complete-length     = 1*DIGIT
+
+     other-content-range = other-range-unit SP other-range-resp
+     other-range-resp    = *CHAR
+
+
+
+Fielding, et al.             Standards Track                   [Page 12]
+
+RFC 7233                 HTTP/1.1 Range Requests               June 2014
+
+
+   If a 206 (Partial Content) response contains a Content-Range header
+   field with a range unit (Section 2) that the recipient does not
+   understand, the recipient MUST NOT attempt to recombine it with a
+   stored representation.  A proxy that receives such a message SHOULD
+   forward it downstream.
+
+   For byte ranges, a sender SHOULD indicate the complete length of the
+   representation from which the range has been extracted, unless the
+   complete length is unknown or difficult to determine.  An asterisk
+   character ("*") in place of the complete-length indicates that the
+   representation length was unknown when the header field was
+   generated.
+
+   The following example illustrates when the complete length of the
+   selected representation is known by the sender to be 1234 bytes:
+
+     Content-Range: bytes 42-1233/1234
+
+   and this second example illustrates when the complete length is
+   unknown:
+
+     Content-Range: bytes 42-1233/*
+
+   A Content-Range field value is invalid if it contains a
+   byte-range-resp that has a last-byte-pos value less than its
+   first-byte-pos value, or a complete-length value less than or equal
+   to its last-byte-pos value.  The recipient of an invalid
+   Content-Range MUST NOT attempt to recombine the received content with
+   a stored representation.
+
+   A server generating a 416 (Range Not Satisfiable) response to a
+   byte-range request SHOULD send a Content-Range header field with an
+   unsatisfied-range value, as in the following example:
+
+     Content-Range: bytes */1234
+
+   The complete-length in a 416 response indicates the current length of
+   the selected representation.
+
+   The Content-Range header field has no meaning for status codes that
+   do not explicitly describe its semantic.  For this specification,
+   only the 206 (Partial Content) and 416 (Range Not Satisfiable) status
+   codes describe a meaning for Content-Range.
+
+
+
+
+
+
+
+
+Fielding, et al.             Standards Track                   [Page 13]
+
+RFC 7233                 HTTP/1.1 Range Requests               June 2014
+
+
+   The following are examples of Content-Range values in which the
+   selected representation contains a total of 1234 bytes:
+
+   o  The first 500 bytes:
+
+        Content-Range: bytes 0-499/1234
+
+   o  The second 500 bytes:
+
+        Content-Range: bytes 500-999/1234
+
+   o  All except for the first 500 bytes:
+
+        Content-Range: bytes 500-1233/1234
+
+   o  The last 500 bytes:
+
+        Content-Range: bytes 734-1233/1234
+
+4.3.  Combining Ranges
+
+   A response might transfer only a subrange of a representation if the
+   connection closed prematurely or if the request used one or more
+   Range specifications.  After several such transfers, a client might
+   have received several ranges of the same representation.  These
+   ranges can only be safely combined if they all have in common the
+   same strong validator (Section 2.1 of [RFC7232]).
+
+   A client that has received multiple partial responses to GET requests
+   on a target resource MAY combine those responses into a larger
+   continuous range if they share the same strong validator.
+
+   If the most recent response is an incomplete 200 (OK) response, then
+   the header fields of that response are used for any combined response
+   and replace those of the matching stored responses.
+
+   If the most recent response is a 206 (Partial Content) response and
+   at least one of the matching stored responses is a 200 (OK), then the
+   combined response header fields consist of the most recent 200
+   response's header fields.  If all of the matching stored responses
+   are 206 responses, then the stored response with the most recent
+   header fields is used as the source of header fields for the combined
+   response, except that the client MUST use other header fields
+   provided in the new response, aside from Content-Range, to replace
+   all instances of the corresponding header fields in the stored
+   response.
+
+
+
+
+
+Fielding, et al.             Standards Track                   [Page 14]
+
+RFC 7233                 HTTP/1.1 Range Requests               June 2014
+
+
+   The combined response message body consists of the union of partial
+   content ranges in the new response and each of the selected
+   responses.  If the union consists of the entire range of the
+   representation, then the client MUST process the combined response as
+   if it were a complete 200 (OK) response, including a Content-Length
+   header field that reflects the complete length.  Otherwise, the
+   client MUST process the set of continuous ranges as one of the
+   following: an incomplete 200 (OK) response if the combined response
+   is a prefix of the representation, a single 206 (Partial Content)
+   response containing a multipart/byteranges body, or multiple 206
+   (Partial Content) responses, each with one continuous range that is
+   indicated by a Content-Range header field.
+
+4.4.  416 Range Not Satisfiable
+
+   The 416 (Range Not Satisfiable) status code indicates that none of
+   the ranges in the request's Range header field (Section 3.1) overlap
+   the current extent of the selected resource or that the set of ranges
+   requested has been rejected due to invalid ranges or an excessive
+   request of small or overlapping ranges.
+
+   For byte ranges, failing to overlap the current extent means that the
+   first-byte-pos of all of the byte-range-spec values were greater than
+   the current length of the selected representation.  When this status
+   code is generated in response to a byte-range request, the sender
+   SHOULD generate a Content-Range header field specifying the current
+   length of the selected representation (Section 4.2).
+
+   For example:
+
+     HTTP/1.1 416 Range Not Satisfiable
+     Date: Fri, 20 Jan 2012 15:41:54 GMT
+     Content-Range: bytes */47022
+
+      Note: Because servers are free to ignore Range, many
+      implementations will simply respond with the entire selected
+      representation in a 200 (OK) response.  That is partly because
+      most clients are prepared to receive a 200 (OK) to complete the
+      task (albeit less efficiently) and partly because clients might
+      not stop making an invalid partial request until they have
+      received a complete representation.  Thus, clients cannot depend
+      on receiving a 416 (Range Not Satisfiable) response even when it
+      is most appropriate.
+
+
+
+
+
+
+
+
+Fielding, et al.             Standards Track                   [Page 15]
+
+RFC 7233                 HTTP/1.1 Range Requests               June 2014
+
+
+5.  IANA Considerations
+
+5.1.  Range Unit Registry
+
+   The "HTTP Range Unit Registry" defines the namespace for the range
+   unit names and refers to their corresponding specifications.  The
+   registry has been created and is now maintained at
+   <http://www.iana.org/assignments/http-parameters>.
+
+5.1.1.  Procedure
+
+   Registration of an HTTP Range Unit MUST include the following fields:
+
+   o  Name
+
+   o  Description
+
+   o  Pointer to specification text
+
+   Values to be added to this namespace require IETF Review (see
+   [RFC5226], Section 4.1).
+
+5.1.2.  Registrations
+
+   The initial range unit registry contains the registrations below:
+
+   +-------------+---------------------------------------+-------------+
+   | Range Unit  | Description                           | Reference   |
+   | Name        |                                       |             |
+   +-------------+---------------------------------------+-------------+
+   | bytes       | a range of octets                     | Section 2.1 |
+   | none        | reserved as keyword, indicating no    | Section 2.3 |
+   |             | ranges are supported                  |             |
+   +-------------+---------------------------------------+-------------+
+
+   The change controller is: "IETF (iesg@ietf.org) - Internet
+   Engineering Task Force".
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+Fielding, et al.             Standards Track                   [Page 16]
+
+RFC 7233                 HTTP/1.1 Range Requests               June 2014
+
+
+5.2.  Status Code Registration
+
+   The "Hypertext Transfer Protocol (HTTP) Status Code Registry" located
+   at <http://www.iana.org/assignments/http-status-codes> has been
+   updated to include the registrations below:
+
+   +-------+-----------------------+-------------+
+   | Value | Description           | Reference   |
+   +-------+-----------------------+-------------+
+   | 206   | Partial Content       | Section 4.1 |
+   | 416   | Range Not Satisfiable | Section 4.4 |
+   +-------+-----------------------+-------------+
+
+5.3.  Header Field Registration
+
+   HTTP header fields are registered within the "Message Headers"
+   registry maintained at
+   <http://www.iana.org/assignments/message-headers/>.
+
+   This document defines the following HTTP header fields, so their
+   associated registry entries have been updated according to the
+   permanent registrations below (see [BCP90]):
+
+   +-------------------+----------+----------+-------------+
+   | Header Field Name | Protocol | Status   | Reference   |
+   +-------------------+----------+----------+-------------+
+   | Accept-Ranges     | http     | standard | Section 2.3 |
+   | Content-Range     | http     | standard | Section 4.2 |
+   | If-Range          | http     | standard | Section 3.2 |
+   | Range             | http     | standard | Section 3.1 |
+   +-------------------+----------+----------+-------------+
+
+   The change controller is: "IETF (iesg@ietf.org) - Internet
+   Engineering Task Force".
+
+5.4.  Internet Media Type Registration
+
+   IANA maintains the registry of Internet media types [BCP13] at
+   <http://www.iana.org/assignments/media-types>.
+
+   This document serves as the specification for the Internet media type
+   "multipart/byteranges".  The following has been registered with IANA.
+
+
+
+
+
+
+
+
+
+Fielding, et al.             Standards Track                   [Page 17]
+
+RFC 7233                 HTTP/1.1 Range Requests               June 2014
+
+
+5.4.1.  Internet Media Type multipart/byteranges
+
+   Type name:  multipart
+
+   Subtype name:  byteranges
+
+   Required parameters:  boundary
+
+   Optional parameters:  N/A
+
+   Encoding considerations:  only "7bit", "8bit", or "binary" are
+      permitted
+
+   Security considerations:  see Section 6
+
+   Interoperability considerations:  N/A
+
+   Published specification:  This specification (see Appendix A).
+
+   Applications that use this media type:  HTTP components supporting
+      multiple ranges in a single request.
+
+   Fragment identifier considerations:  N/A
+
+   Additional information:
+
+      Deprecated alias names for this type:  N/A
+
+      Magic number(s):  N/A
+
+      File extension(s):  N/A
+
+      Macintosh file type code(s):  N/A
+
+   Person and email address to contact for further information:  See
+      Authors' Addresses section.
+
+   Intended usage:  COMMON
+
+   Restrictions on usage:  N/A
+
+   Author:  See Authors' Addresses section.
+
+   Change controller:  IESG
+
+
+
+
+
+
+
+Fielding, et al.             Standards Track                   [Page 18]
+
+RFC 7233                 HTTP/1.1 Range Requests               June 2014
+
+
+6.  Security Considerations
+
+   This section is meant to inform developers, information providers,
+   and users of known security concerns specific to the HTTP range
+   request mechanisms.  More general security considerations are
+   addressed in HTTP messaging [RFC7230] and semantics [RFC7231].
+
+6.1.  Denial-of-Service Attacks Using Range
+
+   Unconstrained multiple range requests are susceptible to denial-of-
+   service attacks because the effort required to request many
+   overlapping ranges of the same data is tiny compared to the time,
+   memory, and bandwidth consumed by attempting to serve the requested
+   data in many parts.  Servers ought to ignore, coalesce, or reject
+   egregious range requests, such as requests for more than two
+   overlapping ranges or for many small ranges in a single set,
+   particularly when the ranges are requested out of order for no
+   apparent reason.  Multipart range requests are not designed to
+   support random access.
+
+7.  Acknowledgments
+
+   See Section 10 of [RFC7230].
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+Fielding, et al.             Standards Track                   [Page 19]
+
+RFC 7233                 HTTP/1.1 Range Requests               June 2014
+
+
+8.  References
+
+8.1.  Normative References
+
+   [RFC2046]  Freed, N. and N. Borenstein, "Multipurpose Internet Mail
+              Extensions (MIME) Part Two: Media Types", RFC 2046,
+              November 1996.
+
+   [RFC2119]  Bradner, S., "Key words for use in RFCs to Indicate
+              Requirement Levels", BCP 14, RFC 2119, March 1997.
+
+   [RFC5234]  Crocker, D., Ed. and P. Overell, "Augmented BNF for Syntax
+              Specifications: ABNF", STD 68, RFC 5234, January 2008.
+
+   [RFC7230]  Fielding, R., Ed. and J. Reschke, Ed., "Hypertext Transfer
+              Protocol (HTTP/1.1): Message Syntax and Routing",
+              RFC 7230, June 2014.
+
+   [RFC7231]  Fielding, R., Ed. and J. Reschke, Ed., "Hypertext Transfer
+              Protocol (HTTP/1.1): Semantics and Content", RFC 7231,
+              June 2014.
+
+   [RFC7232]  Fielding, R., Ed. and J. Reschke, Ed., "Hypertext Transfer
+              Protocol (HTTP/1.1): Conditional Requests", RFC 7232,
+              June 2014.
+
+   [RFC7234]  Fielding, R., Ed., Nottingham, M., Ed., and J. Reschke,
+              Ed., "Hypertext Transfer Protocol (HTTP/1.1): Caching",
+              RFC 7234, June 2014.
+
+8.2.  Informative References
+
+   [BCP13]    Freed, N., Klensin, J., and T. Hansen, "Media Type
+              Specifications and Registration Procedures", BCP 13,
+              RFC 6838, January 2013.
+
+   [BCP90]    Klyne, G., Nottingham, M., and J. Mogul, "Registration
+              Procedures for Message Header Fields", BCP 90, RFC 3864,
+              September 2004.
+
+   [RFC2616]  Fielding, R., Gettys, J., Mogul, J., Frystyk, H.,
+              Masinter, L., Leach, P., and T. Berners-Lee, "Hypertext
+              Transfer Protocol -- HTTP/1.1", RFC 2616, June 1999.
+
+   [RFC5226]  Narten, T. and H. Alvestrand, "Guidelines for Writing an
+              IANA Considerations Section in RFCs", BCP 26, RFC 5226,
+              May 2008.
+
+
+
+
+Fielding, et al.             Standards Track                   [Page 20]
+
+RFC 7233                 HTTP/1.1 Range Requests               June 2014
+
+
+Appendix A.  Internet Media Type multipart/byteranges
+
+   When a 206 (Partial Content) response message includes the content of
+   multiple ranges, they are transmitted as body parts in a multipart
+   message body ([RFC2046], Section 5.1) with the media type of
+   "multipart/byteranges".
+
+   The multipart/byteranges media type includes one or more body parts,
+   each with its own Content-Type and Content-Range fields.  The
+   required boundary parameter specifies the boundary string used to
+   separate each body part.
+
+   Implementation Notes:
+
+   1.  Additional CRLFs might precede the first boundary string in the
+       body.
+
+   2.  Although [RFC2046] permits the boundary string to be quoted, some
+       existing implementations handle a quoted boundary string
+       incorrectly.
+
+   3.  A number of clients and servers were coded to an early draft of
+       the byteranges specification that used a media type of multipart/
+       x-byteranges, which is almost (but not quite) compatible with
+       this type.
+
+   Despite the name, the "multipart/byteranges" media type is not
+   limited to byte ranges.  The following example uses an "exampleunit"
+   range unit:
+
+     HTTP/1.1 206 Partial Content
+     Date: Tue, 14 Nov 1995 06:25:24 GMT
+     Last-Modified: Tue, 14 July 04:58:08 GMT
+     Content-Length: 2331785
+     Content-Type: multipart/byteranges; boundary=THIS_STRING_SEPARATES
+
+     --THIS_STRING_SEPARATES
+     Content-Type: video/example
+     Content-Range: exampleunit 1.2-4.3/25
+
+     ...the first range...
+     --THIS_STRING_SEPARATES
+     Content-Type: video/example
+     Content-Range: exampleunit 11.2-14.3/25
+
+     ...the second range
+     --THIS_STRING_SEPARATES--
+
+
+
+
+Fielding, et al.             Standards Track                   [Page 21]
+
+RFC 7233                 HTTP/1.1 Range Requests               June 2014
+
+
+Appendix B.  Changes from RFC 2616
+
+   Servers are given more leeway in how they respond to a range request,
+   in order to mitigate abuse by malicious (or just greedy) clients.
+   (Section 3.1)
+
+   A weak validator cannot be used in a 206 response.  (Section 4.1)
+
+   The Content-Range header field only has meaning when the status code
+   explicitly defines its use.  (Section 4.2)
+
+   This specification introduces a Range Unit Registry.  (Section 5.1)
+
+   multipart/byteranges can consist of a single part.  (Appendix A)
+
+Appendix C.  Imported ABNF
+
+   The following core rules are included by reference, as defined in
+   Appendix B.1 of [RFC5234]: ALPHA (letters), CR (carriage return),
+   CRLF (CR LF), CTL (controls), DIGIT (decimal 0-9), DQUOTE (double
+   quote), HEXDIG (hexadecimal 0-9/A-F/a-f), LF (line feed), OCTET (any
+   8-bit sequence of data), SP (space), and VCHAR (any visible US-ASCII
+   character).
+
+   Note that all rules derived from token are to be compared
+   case-insensitively, like range-unit and acceptable-ranges.
+
+   The rules below are defined in [RFC7230]:
+
+     OWS        = <OWS, see [RFC7230], Section 3.2.3>
+     token      = <token, see [RFC7230], Section 3.2.6>
+
+   The rules below are defined in other parts:
+
+     HTTP-date  = <HTTP-date, see [RFC7231], Section 7.1.1.1>
+     entity-tag = <entity-tag, see [RFC7232], Section 2.3>
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+Fielding, et al.             Standards Track                   [Page 22]
+
+RFC 7233                 HTTP/1.1 Range Requests               June 2014
+
+
+Appendix D.  Collected ABNF
+
+   In the collected ABNF below, list rules are expanded as per Section
+   1.2 of [RFC7230].
+
+   Accept-Ranges = acceptable-ranges
+
+   Content-Range = byte-content-range / other-content-range
+
+   HTTP-date = <HTTP-date, see [RFC7231], Section 7.1.1.1>
+
+   If-Range = entity-tag / HTTP-date
+
+   OWS = <OWS, see [RFC7230], Section 3.2.3>
+
+   Range = byte-ranges-specifier / other-ranges-specifier
+
+   acceptable-ranges = ( *( "," OWS ) range-unit *( OWS "," [ OWS
+    range-unit ] ) ) / "none"
+
+   byte-content-range = bytes-unit SP ( byte-range-resp /
+    unsatisfied-range )
+   byte-range = first-byte-pos "-" last-byte-pos
+   byte-range-resp = byte-range "/" ( complete-length / "*" )
+   byte-range-set = *( "," OWS ) ( byte-range-spec /
+    suffix-byte-range-spec ) *( OWS "," [ OWS ( byte-range-spec /
+    suffix-byte-range-spec ) ] )
+   byte-range-spec = first-byte-pos "-" [ last-byte-pos ]
+   byte-ranges-specifier = bytes-unit "=" byte-range-set
+   bytes-unit = "bytes"
+
+   complete-length = 1*DIGIT
+
+   entity-tag = <entity-tag, see [RFC7232], Section 2.3>
+
+   first-byte-pos = 1*DIGIT
+
+   last-byte-pos = 1*DIGIT
+
+   other-content-range = other-range-unit SP other-range-resp
+   other-range-resp = *CHAR
+   other-range-set = 1*VCHAR
+   other-range-unit = token
+   other-ranges-specifier = other-range-unit "=" other-range-set
+
+   range-unit = bytes-unit / other-range-unit
+
+   suffix-byte-range-spec = "-" suffix-length
+
+
+
+Fielding, et al.             Standards Track                   [Page 23]
+
+RFC 7233                 HTTP/1.1 Range Requests               June 2014
+
+
+   suffix-length = 1*DIGIT
+
+   token = <token, see [RFC7230], Section 3.2.6>
+
+   unsatisfied-range = "*/" complete-length
+
+Index
+
+   2
+      206 Partial Content (status code)  10
+
+   4
+      416 Range Not Satisfiable (status code)  15
+
+   A
+      Accept-Ranges header field  7
+
+   C
+      Content-Range header field  12
+
+   G
+      Grammar
+         Accept-Ranges  7
+         acceptable-ranges  7
+         byte-content-range  12
+         byte-range  12
+         byte-range-resp  12
+         byte-range-set  5
+         byte-range-spec  5
+         byte-ranges-specifier  5
+         bytes-unit  5
+         complete-length  12
+         Content-Range  12
+         first-byte-pos  5
+         If-Range  9
+         last-byte-pos  5
+         other-content-range  12
+         other-range-resp  12
+         other-range-unit  5, 7
+         Range  8
+         range-unit  5
+         ranges-specifier  5
+         suffix-byte-range-spec  6
+         suffix-length  6
+         unsatisfied-range  12
+
+
+
+
+
+
+Fielding, et al.             Standards Track                   [Page 24]
+
+RFC 7233                 HTTP/1.1 Range Requests               June 2014
+
+
+   I
+      If-Range header field  9
+
+   M
+      Media Type
+         multipart/byteranges  18, 21
+         multipart/x-byteranges  19
+      multipart/byteranges Media Type  18, 21
+      multipart/x-byteranges Media Type  21
+
+   R
+      Range header field  8
+
+Authors' Addresses
+
+   Roy T. Fielding (editor)
+   Adobe Systems Incorporated
+   345 Park Ave
+   San Jose, CA  95110
+   USA
+
+   EMail: fielding@gbiv.com
+   URI:   http://roy.gbiv.com/
+
+
+   Yves Lafon (editor)
+   World Wide Web Consortium
+   W3C / ERCIM
+   2004, rte des Lucioles
+   Sophia-Antipolis, AM  06902
+   France
+
+   EMail: ylafon@w3.org
+   URI:   http://www.raubacapeu.net/people/yves/
+
+
+   Julian F. Reschke (editor)
+   greenbytes GmbH
+   Hafenweg 16
+   Muenster, NW  48155
+   Germany
+
+   EMail: julian.reschke@greenbytes.de
+   URI:   http://greenbytes.de/tech/webdav/
+
+
+
+
+
+
+
+Fielding, et al.             Standards Track                   [Page 25]
+
@@ -0,0 +1,2411 @@
+
+
+
+
+
+
+Internet Engineering Task Force (IETF)                  R. Fielding, Ed.
+Request for Comments: 7234                                         Adobe
+Obsoletes: 2616                                       M. Nottingham, Ed.
+Category: Standards Track                                         Akamai
+ISSN: 2070-1721                                          J. Reschke, Ed.
+                                                              greenbytes
+                                                               June 2014
+
+
+            Hypertext Transfer Protocol (HTTP/1.1): Caching
+
+Abstract
+
+   The Hypertext Transfer Protocol (HTTP) is a stateless application-
+   level protocol for distributed, collaborative, hypertext information
+   systems.  This document defines HTTP caches and the associated header
+   fields that control cache behavior or indicate cacheable response
+   messages.
+
+Status of This Memo
+
+   This is an Internet Standards Track document.
+
+   This document is a product of the Internet Engineering Task Force
+   (IETF).  It represents the consensus of the IETF community.  It has
+   received public review and has been approved for publication by the
+   Internet Engineering Steering Group (IESG).  Further information on
+   Internet Standards is available in Section 2 of RFC 5741.
+
+   Information about the current status of this document, any errata,
+   and how to provide feedback on it may be obtained at
+   http://www.rfc-editor.org/info/rfc7234.
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+Fielding, et al.             Standards Track                    [Page 1]
+
+RFC 7234                    HTTP/1.1 Caching                   June 2014
+
+
+Copyright Notice
+
+   Copyright (c) 2014 IETF Trust and the persons identified as the
+   document authors.  All rights reserved.
+
+   This document is subject to BCP 78 and the IETF Trust's Legal
+   Provisions Relating to IETF Documents
+   (http://trustee.ietf.org/license-info) in effect on the date of
+   publication of this document.  Please review these documents
+   carefully, as they describe your rights and restrictions with respect
+   to this document.  Code Components extracted from this document must
+   include Simplified BSD License text as described in Section 4.e of
+   the Trust Legal Provisions and are provided without warranty as
+   described in the Simplified BSD License.
+
+   This document may contain material from IETF Documents or IETF
+   Contributions published or made publicly available before November
+   10, 2008.  The person(s) controlling the copyright in some of this
+   material may not have granted the IETF Trust the right to allow
+   modifications of such material outside the IETF Standards Process.
+   Without obtaining an adequate license from the person(s) controlling
+   the copyright in such materials, this document may not be modified
+   outside the IETF Standards Process, and derivative works of it may
+   not be created outside the IETF Standards Process, except to format
+   it for publication as an RFC or to translate it into languages other
+   than English.
+
+Table of Contents
+
+   1. Introduction ....................................................4
+      1.1. Conformance and Error Handling .............................4
+      1.2. Syntax Notation ............................................4
+           1.2.1. Delta Seconds .......................................5
+   2. Overview of Cache Operation .....................................5
+   3. Storing Responses in Caches .....................................6
+      3.1. Storing Incomplete Responses ...............................7
+      3.2. Storing Responses to Authenticated Requests ................7
+      3.3. Combining Partial Content ..................................8
+   4. Constructing Responses from Caches ..............................8
+      4.1. Calculating Secondary Keys with Vary .......................9
+      4.2. Freshness .................................................11
+           4.2.1. Calculating Freshness Lifetime .....................12
+           4.2.2. Calculating Heuristic Freshness ....................13
+           4.2.3. Calculating Age ....................................13
+           4.2.4. Serving Stale Responses ............................15
+      4.3. Validation ................................................16
+           4.3.1. Sending a Validation Request .......................16
+           4.3.2. Handling a Received Validation Request .............16
+
+
+
+Fielding, et al.             Standards Track                    [Page 2]
+
+RFC 7234                    HTTP/1.1 Caching                   June 2014
+
+
+           4.3.3. Handling a Validation Response .....................18
+           4.3.4. Freshening Stored Responses upon Validation ........18
+           4.3.5. Freshening Responses via HEAD ......................19
+      4.4. Invalidation ..............................................20
+   5. Header Field Definitions .......................................21
+      5.1. Age .......................................................21
+      5.2. Cache-Control .............................................21
+           5.2.1. Request Cache-Control Directives ...................22
+           5.2.2. Response Cache-Control Directives ..................24
+           5.2.3. Cache Control Extensions ...........................27
+      5.3. Expires ...................................................28
+      5.4. Pragma ....................................................29
+      5.5. Warning ...................................................29
+           5.5.1. Warning: 110 - "Response is Stale" .................31
+           5.5.2. Warning: 111 - "Revalidation Failed" ...............31
+           5.5.3. Warning: 112 - "Disconnected Operation" ............31
+           5.5.4. Warning: 113 - "Heuristic Expiration" ..............31
+           5.5.5. Warning: 199 - "Miscellaneous Warning" .............32
+           5.5.6. Warning: 214 - "Transformation Applied" ............32
+           5.5.7. Warning: 299 - "Miscellaneous Persistent Warning" ..32
+   6. History Lists ..................................................32
+   7. IANA Considerations ............................................32
+      7.1. Cache Directive Registry ..................................32
+           7.1.1. Procedure ..........................................32
+           7.1.2. Considerations for New Cache Control Directives ....33
+           7.1.3. Registrations ......................................33
+      7.2. Warn Code Registry ........................................34
+           7.2.1. Procedure ..........................................34
+           7.2.2. Registrations ......................................34
+      7.3. Header Field Registration .................................34
+   8. Security Considerations ........................................35
+   9. Acknowledgments ................................................36
+   10. References ....................................................36
+      10.1. Normative References .....................................36
+      10.2. Informative References ...................................37
+   Appendix A. Changes from RFC 2616 .................................38
+   Appendix B. Imported ABNF .........................................39
+   Appendix C. Collected ABNF ........................................39
+   Index .............................................................41
+
+
+
+
+
+
+
+
+
+
+
+
+Fielding, et al.             Standards Track                    [Page 3]
+
+RFC 7234                    HTTP/1.1 Caching                   June 2014
+
+
+1.  Introduction
+
+   HTTP is typically used for distributed information systems, where
+   performance can be improved by the use of response caches.  This
+   document defines aspects of HTTP/1.1 related to caching and reusing
+   response messages.
+
+   An HTTP cache is a local store of response messages and the subsystem
+   that controls storage, retrieval, and deletion of messages in it.  A
+   cache stores cacheable responses in order to reduce the response time
+   and network bandwidth consumption on future, equivalent requests.
+   Any client or server MAY employ a cache, though a cache cannot be
+   used by a server that is acting as a tunnel.
+
+   A shared cache is a cache that stores responses to be reused by more
+   than one user; shared caches are usually (but not always) deployed as
+   a part of an intermediary.  A private cache, in contrast, is
+   dedicated to a single user; often, they are deployed as a component
+   of a user agent.
+
+   The goal of caching in HTTP/1.1 is to significantly improve
+   performance by reusing a prior response message to satisfy a current
+   request.  A stored response is considered "fresh", as defined in
+   Section 4.2, if the response can be reused without "validation"
+   (checking with the origin server to see if the cached response
+   remains valid for this request).  A fresh response can therefore
+   reduce both latency and network overhead each time it is reused.
+   When a cached response is not fresh, it might still be reusable if it
+   can be freshened by validation (Section 4.3) or if the origin is
+   unavailable (Section 4.2.4).
+
+1.1.  Conformance and Error Handling
+
+   The key words "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT",
+   "SHOULD", "SHOULD NOT", "RECOMMENDED", "MAY", and "OPTIONAL" in this
+   document are to be interpreted as described in [RFC2119].
+
+   Conformance criteria and considerations regarding error handling are
+   defined in Section 2.5 of [RFC7230].
+
+1.2.  Syntax Notation
+
+   This specification uses the Augmented Backus-Naur Form (ABNF)
+   notation of [RFC5234] with a list extension, defined in Section 7 of
+   [RFC7230], that allows for compact definition of comma-separated
+   lists using a '#' operator (similar to how the '*' operator indicates
+
+
+
+
+
+Fielding, et al.             Standards Track                    [Page 4]
+
+RFC 7234                    HTTP/1.1 Caching                   June 2014
+
+
+   repetition).  Appendix B describes rules imported from other
+   documents.  Appendix C shows the collected grammar with all list
+   operators expanded to standard ABNF notation.
+
+1.2.1.  Delta Seconds
+
+   The delta-seconds rule specifies a non-negative integer, representing
+   time in seconds.
+
+     delta-seconds  = 1*DIGIT
+
+   A recipient parsing a delta-seconds value and converting it to binary
+   form ought to use an arithmetic type of at least 31 bits of
+   non-negative integer range.  If a cache receives a delta-seconds
+   value greater than the greatest integer it can represent, or if any
+   of its subsequent calculations overflows, the cache MUST consider the
+   value to be either 2147483648 (2^31) or the greatest positive integer
+   it can conveniently represent.
+
+      Note: The value 2147483648 is here for historical reasons,
+      effectively represents infinity (over 68 years), and does not need
+      to be stored in binary form; an implementation could produce it as
+      a canned string if any overflow occurs, even if the calculations
+      are performed with an arithmetic type incapable of directly
+      representing that number.  What matters here is that an overflow
+      be detected and not treated as a negative value in later
+      calculations.
+
+2.  Overview of Cache Operation
+
+   Proper cache operation preserves the semantics of HTTP transfers
+   ([RFC7231]) while eliminating the transfer of information already
+   held in the cache.  Although caching is an entirely OPTIONAL feature
+   of HTTP, it can be assumed that reusing a cached response is
+   desirable and that such reuse is the default behavior when no
+   requirement or local configuration prevents it.  Therefore, HTTP
+   cache requirements are focused on preventing a cache from either
+   storing a non-reusable response or reusing a stored response
+   inappropriately, rather than mandating that caches always store and
+   reuse particular responses.
+
+   Each cache entry consists of a cache key and one or more HTTP
+   responses corresponding to prior requests that used the same key.
+   The most common form of cache entry is a successful result of a
+   retrieval request: i.e., a 200 (OK) response to a GET request, which
+   contains a representation of the resource identified by the request
+   target (Section 4.3.1 of [RFC7231]).  However, it is also possible to
+   cache permanent redirects, negative results (e.g., 404 (Not Found)),
+
+
+
+Fielding, et al.             Standards Track                    [Page 5]
+
+RFC 7234                    HTTP/1.1 Caching                   June 2014
+
+
+   incomplete results (e.g., 206 (Partial Content)), and responses to
+   methods other than GET if the method's definition allows such caching
+   and defines something suitable for use as a cache key.
+
+   The primary cache key consists of the request method and target URI.
+   However, since HTTP caches in common use today are typically limited
+   to caching responses to GET, many caches simply decline other methods
+   and use only the URI as the primary cache key.
+
+   If a request target is subject to content negotiation, its cache
+   entry might consist of multiple stored responses, each differentiated
+   by a secondary key for the values of the original request's selecting
+   header fields (Section 4.1).
+
+3.  Storing Responses in Caches
+
+   A cache MUST NOT store a response to any request, unless:
+
+   o  The request method is understood by the cache and defined as being
+      cacheable, and
+
+   o  the response status code is understood by the cache, and
+
+   o  the "no-store" cache directive (see Section 5.2) does not appear
+      in request or response header fields, and
+
+   o  the "private" response directive (see Section 5.2.2.6) does not
+      appear in the response, if the cache is shared, and
+
+   o  the Authorization header field (see Section 4.2 of [RFC7235]) does
+      not appear in the request, if the cache is shared, unless the
+      response explicitly allows it (see Section 3.2), and
+
+   o  the response either:
+
+      *  contains an Expires header field (see Section 5.3), or
+
+      *  contains a max-age response directive (see Section 5.2.2.8), or
+
+      *  contains a s-maxage response directive (see Section 5.2.2.9)
+         and the cache is shared, or
+
+      *  contains a Cache Control Extension (see Section 5.2.3) that
+         allows it to be cached, or
+
+      *  has a status code that is defined as cacheable by default (see
+         Section 4.2.2), or
+
+
+
+
+Fielding, et al.             Standards Track                    [Page 6]
+
+RFC 7234                    HTTP/1.1 Caching                   June 2014
+
+
+      *  contains a public response directive (see Section 5.2.2.5).
+
+   Note that any of the requirements listed above can be overridden by a
+   cache-control extension; see Section 5.2.3.
+
+   In this context, a cache has "understood" a request method or a
+   response status code if it recognizes it and implements all specified
+   caching-related behavior.
+
+   Note that, in normal operation, some caches will not store a response
+   that has neither a cache validator nor an explicit expiration time,
+   as such responses are not usually useful to store.  However, caches
+   are not prohibited from storing such responses.
+
+3.1.  Storing Incomplete Responses
+
+   A response message is considered complete when all of the octets
+   indicated by the message framing ([RFC7230]) are received prior to
+   the connection being closed.  If the request method is GET, the
+   response status code is 200 (OK), and the entire response header
+   section has been received, a cache MAY store an incomplete response
+   message body if the cache entry is recorded as incomplete.  Likewise,
+   a 206 (Partial Content) response MAY be stored as if it were an
+   incomplete 200 (OK) cache entry.  However, a cache MUST NOT store
+   incomplete or partial-content responses if it does not support the
+   Range and Content-Range header fields or if it does not understand
+   the range units used in those fields.
+
+   A cache MAY complete a stored incomplete response by making a
+   subsequent range request ([RFC7233]) and combining the successful
+   response with the stored entry, as defined in Section 3.3.  A cache
+   MUST NOT use an incomplete response to answer requests unless the
+   response has been made complete or the request is partial and
+   specifies a range that is wholly within the incomplete response.  A
+   cache MUST NOT send a partial response to a client without explicitly
+   marking it as such using the 206 (Partial Content) status code.
+
+3.2.  Storing Responses to Authenticated Requests
+
+   A shared cache MUST NOT use a cached response to a request with an
+   Authorization header field (Section 4.2 of [RFC7235]) to satisfy any
+   subsequent request unless a cache directive that allows such
+   responses to be stored is present in the response.
+
+   In this specification, the following Cache-Control response
+   directives (Section 5.2.2) have such an effect: must-revalidate,
+   public, and s-maxage.
+
+
+
+
+Fielding, et al.             Standards Track                    [Page 7]
+
+RFC 7234                    HTTP/1.1 Caching                   June 2014
+
+
+   Note that cached responses that contain the "must-revalidate" and/or
+   "s-maxage" response directives are not allowed to be served stale
+   (Section 4.2.4) by shared caches.  In particular, a response with
+   either "max-age=0, must-revalidate" or "s-maxage=0" cannot be used to
+   satisfy a subsequent request without revalidating it on the origin
+   server.
+
+3.3.  Combining Partial Content
+
+   A response might transfer only a partial representation if the
+   connection closed prematurely or if the request used one or more
+   Range specifiers ([RFC7233]).  After several such transfers, a cache
+   might have received several ranges of the same representation.  A
+   cache MAY combine these ranges into a single stored response, and
+   reuse that response to satisfy later requests, if they all share the
+   same strong validator and the cache complies with the client
+   requirements in Section 4.3 of [RFC7233].
+
+   When combining the new response with one or more stored responses, a
+   cache MUST:
+
+   o  delete any Warning header fields in the stored response with
+      warn-code 1xx (see Section 5.5);
+
+   o  retain any Warning header fields in the stored response with
+      warn-code 2xx; and,
+
+   o  use other header fields provided in the new response, aside from
+      Content-Range, to replace all instances of the corresponding
+      header fields in the stored response.
+
+4.  Constructing Responses from Caches
+
+   When presented with a request, a cache MUST NOT reuse a stored
+   response, unless:
+
+   o  The presented effective request URI (Section 5.5 of [RFC7230]) and
+      that of the stored response match, and
+
+   o  the request method associated with the stored response allows it
+      to be used for the presented request, and
+
+   o  selecting header fields nominated by the stored response (if any)
+      match those presented (see Section 4.1), and
+
+
+
+
+
+
+
+Fielding, et al.             Standards Track                    [Page 8]
+
+RFC 7234                    HTTP/1.1 Caching                   June 2014
+
+
+   o  the presented request does not contain the no-cache pragma
+      (Section 5.4), nor the no-cache cache directive (Section 5.2.1),
+      unless the stored response is successfully validated
+      (Section 4.3), and
+
+   o  the stored response does not contain the no-cache cache directive
+      (Section 5.2.2.2), unless it is successfully validated
+      (Section 4.3), and
+
+   o  the stored response is either:
+
+      *  fresh (see Section 4.2), or
+
+      *  allowed to be served stale (see Section 4.2.4), or
+
+      *  successfully validated (see Section 4.3).
+
+   Note that any of the requirements listed above can be overridden by a
+   cache-control extension; see Section 5.2.3.
+
+   When a stored response is used to satisfy a request without
+   validation, a cache MUST generate an Age header field (Section 5.1),
+   replacing any present in the response with a value equal to the
+   stored response's current_age; see Section 4.2.3.
+
+   A cache MUST write through requests with methods that are unsafe
+   (Section 4.2.1 of [RFC7231]) to the origin server; i.e., a cache is
+   not allowed to generate a reply to such a request before having
+   forwarded the request and having received a corresponding response.
+
+   Also, note that unsafe requests might invalidate already-stored
+   responses; see Section 4.4.
+
+   When more than one suitable response is stored, a cache MUST use the
+   most recent response (as determined by the Date header field).  It
+   can also forward the request with "Cache-Control: max-age=0" or
+   "Cache-Control: no-cache" to disambiguate which response to use.
+
+   A cache that does not have a clock available MUST NOT use stored
+   responses without revalidating them upon every use.
+
+4.1.  Calculating Secondary Keys with Vary
+
+   When a cache receives a request that can be satisfied by a stored
+   response that has a Vary header field (Section 7.1.4 of [RFC7231]),
+   it MUST NOT use that response unless all of the selecting header
+
+
+
+
+
+Fielding, et al.             Standards Track                    [Page 9]
+
+RFC 7234                    HTTP/1.1 Caching                   June 2014
+
+
+   fields nominated by the Vary header field match in both the original
+   request (i.e., that associated with the stored response), and the
+   presented request.
+
+   The selecting header fields from two requests are defined to match if
+   and only if those in the first request can be transformed to those in
+   the second request by applying any of the following:
+
+   o  adding or removing whitespace, where allowed in the header field's
+      syntax
+
+   o  combining multiple header fields with the same field name (see
+      Section 3.2 of [RFC7230])
+
+   o  normalizing both header field values in a way that is known to
+      have identical semantics, according to the header field's
+      specification (e.g., reordering field values when order is not
+      significant; case-normalization, where values are defined to be
+      case-insensitive)
+
+   If (after any normalization that might take place) a header field is
+   absent from a request, it can only match another request if it is
+   also absent there.
+
+   A Vary header field-value of "*" always fails to match.
+
+   The stored response with matching selecting header fields is known as
+   the selected response.
+
+   If multiple selected responses are available (potentially including
+   responses without a Vary header field), the cache will need to choose
+   one to use.  When a selecting header field has a known mechanism for
+   doing so (e.g., qvalues on Accept and similar request header fields),
+   that mechanism MAY be used to select preferred responses; of the
+   remainder, the most recent response (as determined by the Date header
+   field) is used, as per Section 4.
+
+   If no selected response is available, the cache cannot satisfy the
+   presented request.  Typically, it is forwarded to the origin server
+   in a (possibly conditional; see Section 4.3) request.
+
+
+
+
+
+
+
+
+
+
+
+Fielding, et al.             Standards Track                   [Page 10]
+
+RFC 7234                    HTTP/1.1 Caching                   June 2014
+
+
+4.2.  Freshness
+
+   A fresh response is one whose age has not yet exceeded its freshness
+   lifetime.  Conversely, a stale response is one where it has.
+
+   A response's freshness lifetime is the length of time between its
+   generation by the origin server and its expiration time.  An explicit
+   expiration time is the time at which the origin server intends that a
+   stored response can no longer be used by a cache without further
+   validation, whereas a heuristic expiration time is assigned by a
+   cache when no explicit expiration time is available.
+
+   A response's age is the time that has passed since it was generated
+   by, or successfully validated with, the origin server.
+
+   When a response is "fresh" in the cache, it can be used to satisfy
+   subsequent requests without contacting the origin server, thereby
+   improving efficiency.
+
+   The primary mechanism for determining freshness is for an origin
+   server to provide an explicit expiration time in the future, using
+   either the Expires header field (Section 5.3) or the max-age response
+   directive (Section 5.2.2.8).  Generally, origin servers will assign
+   future explicit expiration times to responses in the belief that the
+   representation is not likely to change in a semantically significant
+   way before the expiration time is reached.
+
+   If an origin server wishes to force a cache to validate every
+   request, it can assign an explicit expiration time in the past to
+   indicate that the response is already stale.  Compliant caches will
+   normally validate a stale cached response before reusing it for
+   subsequent requests (see Section 4.2.4).
+
+   Since origin servers do not always provide explicit expiration times,
+   caches are also allowed to use a heuristic to determine an expiration
+   time under certain circumstances (see Section 4.2.2).
+
+   The calculation to determine if a response is fresh is:
+
+      response_is_fresh = (freshness_lifetime > current_age)
+
+   freshness_lifetime is defined in Section 4.2.1; current_age is
+   defined in Section 4.2.3.
+
+   Clients can send the max-age or min-fresh cache directives in a
+   request to constrain or relax freshness calculations for the
+   corresponding response (Section 5.2.1).
+
+
+
+
+Fielding, et al.             Standards Track                   [Page 11]
+
+RFC 7234                    HTTP/1.1 Caching                   June 2014
+
+
+   When calculating freshness, to avoid common problems in date parsing:
+
+   o  Although all date formats are specified to be case-sensitive, a
+      cache recipient SHOULD match day, week, and time-zone names
+      case-insensitively.
+
+   o  If a cache recipient's internal implementation of time has less
+      resolution than the value of an HTTP-date, the recipient MUST
+      internally represent a parsed Expires date as the nearest time
+      equal to or earlier than the received value.
+
+   o  A cache recipient MUST NOT allow local time zones to influence the
+      calculation or comparison of an age or expiration time.
+
+   o  A cache recipient SHOULD consider a date with a zone abbreviation
+      other than GMT or UTC to be invalid for calculating expiration.
+
+   Note that freshness applies only to cache operation; it cannot be
+   used to force a user agent to refresh its display or reload a
+   resource.  See Section 6 for an explanation of the difference between
+   caches and history mechanisms.
+
+4.2.1.  Calculating Freshness Lifetime
+
+   A cache can calculate the freshness lifetime (denoted as
+   freshness_lifetime) of a response by using the first match of the
+   following:
+
+   o  If the cache is shared and the s-maxage response directive
+      (Section 5.2.2.9) is present, use its value, or
+
+   o  If the max-age response directive (Section 5.2.2.8) is present,
+      use its value, or
+
+   o  If the Expires response header field (Section 5.3) is present, use
+      its value minus the value of the Date response header field, or
+
+   o  Otherwise, no explicit expiration time is present in the response.
+      A heuristic freshness lifetime might be applicable; see
+      Section 4.2.2.
+
+   Note that this calculation is not vulnerable to clock skew, since all
+   of the information comes from the origin server.
+
+
+
+
+
+
+
+
+Fielding, et al.             Standards Track                   [Page 12]
+
+RFC 7234                    HTTP/1.1 Caching                   June 2014
+
+
+   When there is more than one value present for a given directive
+   (e.g., two Expires header fields, multiple Cache-Control: max-age
+   directives), the directive's value is considered invalid.  Caches are
+   encouraged to consider responses that have invalid freshness
+   information to be stale.
+
+4.2.2.  Calculating Heuristic Freshness
+
+   Since origin servers do not always provide explicit expiration times,
+   a cache MAY assign a heuristic expiration time when an explicit time
+   is not specified, employing algorithms that use other header field
+   values (such as the Last-Modified time) to estimate a plausible
+   expiration time.  This specification does not provide specific
+   algorithms, but does impose worst-case constraints on their results.
+
+   A cache MUST NOT use heuristics to determine freshness when an
+   explicit expiration time is present in the stored response.  Because
+   of the requirements in Section 3, this means that, effectively,
+   heuristics can only be used on responses without explicit freshness
+   whose status codes are defined as cacheable by default (see Section
+   6.1 of [RFC7231]), and those responses without explicit freshness
+   that have been marked as explicitly cacheable (e.g., with a "public"
+   response directive).
+
+   If the response has a Last-Modified header field (Section 2.2 of
+   [RFC7232]), caches are encouraged to use a heuristic expiration value
+   that is no more than some fraction of the interval since that time.
+   A typical setting of this fraction might be 10%.
+
+   When a heuristic is used to calculate freshness lifetime, a cache
+   SHOULD generate a Warning header field with a 113 warn-code (see
+   Section 5.5.4) in the response if its current_age is more than 24
+   hours and such a warning is not already present.
+
+      Note: Section 13.9 of [RFC2616] prohibited caches from calculating
+      heuristic freshness for URIs with query components (i.e., those
+      containing '?').  In practice, this has not been widely
+      implemented.  Therefore, origin servers are encouraged to send
+      explicit directives (e.g., Cache-Control: no-cache) if they wish
+      to preclude caching.
+
+4.2.3.  Calculating Age
+
+   The Age header field is used to convey an estimated age of the
+   response message when obtained from a cache.  The Age field value is
+   the cache's estimate of the number of seconds since the response was
+   generated or validated by the origin server.  In essence, the Age
+
+
+
+
+Fielding, et al.             Standards Track                   [Page 13]
+
+RFC 7234                    HTTP/1.1 Caching                   June 2014
+
+
+   value is the sum of the time that the response has been resident in
+   each of the caches along the path from the origin server, plus the
+   amount of time it has been in transit along network paths.
+
+   The following data is used for the age calculation:
+
+   age_value
+
+      The term "age_value" denotes the value of the Age header field
+      (Section 5.1), in a form appropriate for arithmetic operation; or
+      0, if not available.
+
+   date_value
+
+      The term "date_value" denotes the value of the Date header field,
+      in a form appropriate for arithmetic operations.  See Section
+      7.1.1.2 of [RFC7231] for the definition of the Date header field,
+      and for requirements regarding responses without it.
+
+   now
+
+      The term "now" means "the current value of the clock at the host
+      performing the calculation".  A host ought to use NTP ([RFC5905])
+      or some similar protocol to synchronize its clocks to Coordinated
+      Universal Time.
+
+   request_time
+
+      The current value of the clock at the host at the time the request
+      resulting in the stored response was made.
+
+   response_time
+
+      The current value of the clock at the host at the time the
+      response was received.
+
+   A response's age can be calculated in two entirely independent ways:
+
+   1.  the "apparent_age": response_time minus date_value, if the local
+       clock is reasonably well synchronized to the origin server's
+       clock.  If the result is negative, the result is replaced by
+       zero.
+
+   2.  the "corrected_age_value", if all of the caches along the
+       response path implement HTTP/1.1.  A cache MUST interpret this
+       value relative to the time the request was initiated, not the
+       time that the response was received.
+
+
+
+
+Fielding, et al.             Standards Track                   [Page 14]
+
+RFC 7234                    HTTP/1.1 Caching                   June 2014
+
+
+     apparent_age = max(0, response_time - date_value);
+
+     response_delay = response_time - request_time;
+     corrected_age_value = age_value + response_delay;
+
+   These are combined as
+
+     corrected_initial_age = max(apparent_age, corrected_age_value);
+
+   unless the cache is confident in the value of the Age header field
+   (e.g., because there are no HTTP/1.0 hops in the Via header field),
+   in which case the corrected_age_value MAY be used as the
+   corrected_initial_age.
+
+   The current_age of a stored response can then be calculated by adding
+   the amount of time (in seconds) since the stored response was last
+   validated by the origin server to the corrected_initial_age.
+
+     resident_time = now - response_time;
+     current_age = corrected_initial_age + resident_time;
+
+4.2.4.  Serving Stale Responses
+
+   A "stale" response is one that either has explicit expiry information
+   or is allowed to have heuristic expiry calculated, but is not fresh
+   according to the calculations in Section 4.2.
+
+   A cache MUST NOT generate a stale response if it is prohibited by an
+   explicit in-protocol directive (e.g., by a "no-store" or "no-cache"
+   cache directive, a "must-revalidate" cache-response-directive, or an
+   applicable "s-maxage" or "proxy-revalidate" cache-response-directive;
+   see Section 5.2.2).
+
+   A cache MUST NOT send stale responses unless it is disconnected
+   (i.e., it cannot contact the origin server or otherwise find a
+   forward path) or doing so is explicitly allowed (e.g., by the
+   max-stale request directive; see Section 5.2.1).
+
+   A cache SHOULD generate a Warning header field with the 110 warn-code
+   (see Section 5.5.1) in stale responses.  Likewise, a cache SHOULD
+   generate a 112 warn-code (see Section 5.5.3) in stale responses if
+   the cache is disconnected.
+
+   A cache SHOULD NOT generate a new Warning header field when
+   forwarding a response that does not have an Age header field, even if
+   the response is already stale.  A cache need not validate a response
+   that merely became stale in transit.
+
+
+
+
+Fielding, et al.             Standards Track                   [Page 15]
+
+RFC 7234                    HTTP/1.1 Caching                   June 2014
+
+
+4.3.  Validation
+
+   When a cache has one or more stored responses for a requested URI,
+   but cannot serve any of them (e.g., because they are not fresh, or
+   one cannot be selected; see Section 4.1), it can use the conditional
+   request mechanism [RFC7232] in the forwarded request to give the next
+   inbound server an opportunity to select a valid stored response to
+   use, updating the stored metadata in the process, or to replace the
+   stored response(s) with a new response.  This process is known as
+   "validating" or "revalidating" the stored response.
+
+4.3.1.  Sending a Validation Request
+
+   When sending a conditional request for cache validation, a cache
+   sends one or more precondition header fields containing validator
+   metadata from its stored response(s), which is then compared by
+   recipients to determine whether a stored response is equivalent to a
+   current representation of the resource.
+
+   One such validator is the timestamp given in a Last-Modified header
+   field (Section 2.2 of [RFC7232]), which can be used in an
+   If-Modified-Since header field for response validation, or in an
+   If-Unmodified-Since or If-Range header field for representation
+   selection (i.e., the client is referring specifically to a previously
+   obtained representation with that timestamp).
+
+   Another validator is the entity-tag given in an ETag header field
+   (Section 2.3 of [RFC7232]).  One or more entity-tags, indicating one
+   or more stored responses, can be used in an If-None-Match header
+   field for response validation, or in an If-Match or If-Range header
+   field for representation selection (i.e., the client is referring
+   specifically to one or more previously obtained representations with
+   the listed entity-tags).
+
+4.3.2.  Handling a Received Validation Request
+
+   Each client in the request chain may have its own cache, so it is
+   common for a cache at an intermediary to receive conditional requests
+   from other (outbound) caches.  Likewise, some user agents make use of
+   conditional requests to limit data transfers to recently modified
+   representations or to complete the transfer of a partially retrieved
+   representation.
+
+   If a cache receives a request that can be satisfied by reusing one of
+   its stored 200 (OK) or 206 (Partial Content) responses, the cache
+   SHOULD evaluate any applicable conditional header field preconditions
+   received in that request with respect to the corresponding validators
+   contained within the selected response.  A cache MUST NOT evaluate
+
+
+
+Fielding, et al.             Standards Track                   [Page 16]
+
+RFC 7234                    HTTP/1.1 Caching                   June 2014
+
+
+   conditional header fields that are only applicable to an origin
+   server, found in a request with semantics that cannot be satisfied
+   with a cached response, or applied to a target resource for which it
+   has no stored responses; such preconditions are likely intended for
+   some other (inbound) server.
+
+   The proper evaluation of conditional requests by a cache depends on
+   the received precondition header fields and their precedence, as
+   defined in Section 6 of [RFC7232].  The If-Match and
+   If-Unmodified-Since conditional header fields are not applicable to a
+   cache.
+
+   A request containing an If-None-Match header field (Section 3.2 of
+   [RFC7232]) indicates that the client wants to validate one or more of
+   its own stored responses in comparison to whichever stored response
+   is selected by the cache.  If the field-value is "*", or if the
+   field-value is a list of entity-tags and at least one of them matches
+   the entity-tag of the selected stored response, a cache recipient
+   SHOULD generate a 304 (Not Modified) response (using the metadata of
+   the selected stored response) instead of sending that stored
+   response.
+
+   When a cache decides to revalidate its own stored responses for a
+   request that contains an If-None-Match list of entity-tags, the cache
+   MAY combine the received list with a list of entity-tags from its own
+   stored set of responses (fresh or stale) and send the union of the
+   two lists as a replacement If-None-Match header field value in the
+   forwarded request.  If a stored response contains only partial
+   content, the cache MUST NOT include its entity-tag in the union
+   unless the request is for a range that would be fully satisfied by
+   that partial stored response.  If the response to the forwarded
+   request is 304 (Not Modified) and has an ETag header field value with
+   an entity-tag that is not in the client's list, the cache MUST
+   generate a 200 (OK) response for the client by reusing its
+   corresponding stored response, as updated by the 304 response
+   metadata (Section 4.3.4).
+
+   If an If-None-Match header field is not present, a request containing
+   an If-Modified-Since header field (Section 3.3 of [RFC7232])
+   indicates that the client wants to validate one or more of its own
+   stored responses by modification date.  A cache recipient SHOULD
+   generate a 304 (Not Modified) response (using the metadata of the
+   selected stored response) if one of the following cases is true: 1)
+   the selected stored response has a Last-Modified field-value that is
+   earlier than or equal to the conditional timestamp; 2) no
+   Last-Modified field is present in the selected stored response, but
+   it has a Date field-value that is earlier than or equal to the
+   conditional timestamp; or, 3) neither Last-Modified nor Date is
+
+
+
+Fielding, et al.             Standards Track                   [Page 17]
+
+RFC 7234                    HTTP/1.1 Caching                   June 2014
+
+
+   present in the selected stored response, but the cache recorded it as
+   having been received at a time earlier than or equal to the
+   conditional timestamp.
+
+   A cache that implements partial responses to range requests, as
+   defined in [RFC7233], also needs to evaluate a received If-Range
+   header field (Section 3.2 of [RFC7233]) with respect to its selected
+   stored response.
+
+4.3.3.  Handling a Validation Response
+
+   Cache handling of a response to a conditional request is dependent
+   upon its status code:
+
+   o  A 304 (Not Modified) response status code indicates that the
+      stored response can be updated and reused; see Section 4.3.4.
+
+   o  A full response (i.e., one with a payload body) indicates that
+      none of the stored responses nominated in the conditional request
+      is suitable.  Instead, the cache MUST use the full response to
+      satisfy the request and MAY replace the stored response(s).
+
+   o  However, if a cache receives a 5xx (Server Error) response while
+      attempting to validate a response, it can either forward this
+      response to the requesting client, or act as if the server failed
+      to respond.  In the latter case, the cache MAY send a previously
+      stored response (see Section 4.2.4).
+
+4.3.4.  Freshening Stored Responses upon Validation
+
+   When a cache receives a 304 (Not Modified) response and already has
+   one or more stored 200 (OK) responses for the same cache key, the
+   cache needs to identify which of the stored responses are updated by
+   this new response and then update the stored response(s) with the new
+   information provided in the 304 response.
+
+   The stored response to update is identified by using the first match
+   (if any) of the following:
+
+   o  If the new response contains a strong validator (see Section 2.1
+      of [RFC7232]), then that strong validator identifies the selected
+      representation for update.  All of the stored responses with the
+      same strong validator are selected.  If none of the stored
+      responses contain the same strong validator, then the cache MUST
+      NOT use the new response to update any stored responses.
+
+
+
+
+
+
+Fielding, et al.             Standards Track                   [Page 18]
+
+RFC 7234                    HTTP/1.1 Caching                   June 2014
+
+
+   o  If the new response contains a weak validator and that validator
+      corresponds to one of the cache's stored responses, then the most
+      recent of those matching stored responses is selected for update.
+
+   o  If the new response does not include any form of validator (such
+      as in the case where a client generates an If-Modified-Since
+      request from a source other than the Last-Modified response header
+      field), and there is only one stored response, and that stored
+      response also lacks a validator, then that stored response is
+      selected for update.
+
+   If a stored response is selected for update, the cache MUST:
+
+   o  delete any Warning header fields in the stored response with
+      warn-code 1xx (see Section 5.5);
+
+   o  retain any Warning header fields in the stored response with
+      warn-code 2xx; and,
+
+   o  use other header fields provided in the 304 (Not Modified)
+      response to replace all instances of the corresponding header
+      fields in the stored response.
+
+4.3.5.  Freshening Responses via HEAD
+
+   A response to the HEAD method is identical to what an equivalent
+   request made with a GET would have been, except it lacks a body.
+   This property of HEAD responses can be used to invalidate or update a
+   cached GET response if the more efficient conditional GET request
+   mechanism is not available (due to no validators being present in the
+   stored response) or if transmission of the representation body is not
+   desired even if it has changed.
+
+   When a cache makes an inbound HEAD request for a given request target
+   and receives a 200 (OK) response, the cache SHOULD update or
+   invalidate each of its stored GET responses that could have been
+   selected for that request (see Section 4.1).
+
+   For each of the stored responses that could have been selected, if
+   the stored response and HEAD response have matching values for any
+   received validator fields (ETag and Last-Modified) and, if the HEAD
+   response has a Content-Length header field, the value of
+   Content-Length matches that of the stored response, the cache SHOULD
+   update the stored response as described below; otherwise, the cache
+   SHOULD consider the stored response to be stale.
+
+
+
+
+
+
+Fielding, et al.             Standards Track                   [Page 19]
+
+RFC 7234                    HTTP/1.1 Caching                   June 2014
+
+
+   If a cache updates a stored response with the metadata provided in a
+   HEAD response, the cache MUST:
+
+   o  delete any Warning header fields in the stored response with
+      warn-code 1xx (see Section 5.5);
+
+   o  retain any Warning header fields in the stored response with
+      warn-code 2xx; and,
+
+   o  use other header fields provided in the HEAD response to replace
+      all instances of the corresponding header fields in the stored
+      response and append new header fields to the stored response's
+      header section unless otherwise restricted by the Cache-Control
+      header field.
+
+4.4.  Invalidation
+
+   Because unsafe request methods (Section 4.2.1 of [RFC7231]) such as
+   PUT, POST or DELETE have the potential for changing state on the
+   origin server, intervening caches can use them to keep their contents
+   up to date.
+
+   A cache MUST invalidate the effective Request URI (Section 5.5 of
+   [RFC7230]) as well as the URI(s) in the Location and Content-Location
+   response header fields (if present) when a non-error status code is
+   received in response to an unsafe request method.
+
+   However, a cache MUST NOT invalidate a URI from a Location or
+   Content-Location response header field if the host part of that URI
+   differs from the host part in the effective request URI (Section 5.5
+   of [RFC7230]).  This helps prevent denial-of-service attacks.
+
+   A cache MUST invalidate the effective request URI (Section 5.5 of
+   [RFC7230]) when it receives a non-error response to a request with a
+   method whose safety is unknown.
+
+   Here, a "non-error response" is one with a 2xx (Successful) or 3xx
+   (Redirection) status code.  "Invalidate" means that the cache will
+   either remove all stored responses related to the effective request
+   URI or will mark these as "invalid" and in need of a mandatory
+   validation before they can be sent in response to a subsequent
+   request.
+
+   Note that this does not guarantee that all appropriate responses are
+   invalidated.  For example, a state-changing request might invalidate
+   responses in the caches it travels through, but relevant responses
+   still might be stored in other caches that it has not.
+
+
+
+
+Fielding, et al.             Standards Track                   [Page 20]
+
+RFC 7234                    HTTP/1.1 Caching                   June 2014
+
+
+5.  Header Field Definitions
+
+   This section defines the syntax and semantics of HTTP/1.1 header
+   fields related to caching.
+
+5.1.  Age
+
+   The "Age" header field conveys the sender's estimate of the amount of
+   time since the response was generated or successfully validated at
+   the origin server.  Age values are calculated as specified in
+   Section 4.2.3.
+
+     Age = delta-seconds
+
+   The Age field-value is a non-negative integer, representing time in
+   seconds (see Section 1.2.1).
+
+   The presence of an Age header field implies that the response was not
+   generated or validated by the origin server for this request.
+   However, lack of an Age header field does not imply the origin was
+   contacted, since the response might have been received from an
+   HTTP/1.0 cache that does not implement Age.
+
+5.2.  Cache-Control
+
+   The "Cache-Control" header field is used to specify directives for
+   caches along the request/response chain.  Such cache directives are
+   unidirectional in that the presence of a directive in a request does
+   not imply that the same directive is to be given in the response.
+
+   A cache MUST obey the requirements of the Cache-Control directives
+   defined in this section.  See Section 5.2.3 for information about how
+   Cache-Control directives defined elsewhere are handled.
+
+      Note: Some HTTP/1.0 caches might not implement Cache-Control.
+
+   A proxy, whether or not it implements a cache, MUST pass cache
+   directives through in forwarded messages, regardless of their
+   significance to that application, since the directives might be
+   applicable to all recipients along the request/response chain.  It is
+   not possible to target a directive to a specific cache.
+
+   Cache directives are identified by a token, to be compared
+   case-insensitively, and have an optional argument, that can use both
+   token and quoted-string syntax.  For the directives defined below
+   that define arguments, recipients ought to accept both forms, even if
+   one is documented to be preferred.  For any directive not defined by
+   this specification, a recipient MUST accept both forms.
+
+
+
+Fielding, et al.             Standards Track                   [Page 21]
+
+RFC 7234                    HTTP/1.1 Caching                   June 2014
+
+
+     Cache-Control   = 1#cache-directive
+
+     cache-directive = token [ "=" ( token / quoted-string ) ]
+
+   For the cache directives defined below, no argument is defined (nor
+   allowed) unless stated otherwise.
+
+5.2.1.  Request Cache-Control Directives
+
+5.2.1.1.  max-age
+
+   Argument syntax:
+
+      delta-seconds (see Section 1.2.1)
+
+   The "max-age" request directive indicates that the client is
+   unwilling to accept a response whose age is greater than the
+   specified number of seconds.  Unless the max-stale request directive
+   is also present, the client is not willing to accept a stale
+   response.
+
+   This directive uses the token form of the argument syntax: e.g.,
+   'max-age=5' not 'max-age="5"'.  A sender SHOULD NOT generate the
+   quoted-string form.
+
+5.2.1.2.  max-stale
+
+   Argument syntax:
+
+      delta-seconds (see Section 1.2.1)
+
+   The "max-stale" request directive indicates that the client is
+   willing to accept a response that has exceeded its freshness
+   lifetime.  If max-stale is assigned a value, then the client is
+   willing to accept a response that has exceeded its freshness lifetime
+   by no more than the specified number of seconds.  If no value is
+   assigned to max-stale, then the client is willing to accept a stale
+   response of any age.
+
+   This directive uses the token form of the argument syntax: e.g.,
+   'max-stale=10' not 'max-stale="10"'.  A sender SHOULD NOT generate
+   the quoted-string form.
+
+5.2.1.3.  min-fresh
+
+   Argument syntax:
+
+      delta-seconds (see Section 1.2.1)
+
+
+
+Fielding, et al.             Standards Track                   [Page 22]
+
+RFC 7234                    HTTP/1.1 Caching                   June 2014
+
+
+   The "min-fresh" request directive indicates that the client is
+   willing to accept a response whose freshness lifetime is no less than
+   its current age plus the specified time in seconds.  That is, the
+   client wants a response that will still be fresh for at least the
+   specified number of seconds.
+
+   This directive uses the token form of the argument syntax: e.g.,
+   'min-fresh=20' not 'min-fresh="20"'.  A sender SHOULD NOT generate
+   the quoted-string form.
+
+5.2.1.4.  no-cache
+
+   The "no-cache" request directive indicates that a cache MUST NOT use
+   a stored response to satisfy the request without successful
+   validation on the origin server.
+
+5.2.1.5.  no-store
+
+   The "no-store" request directive indicates that a cache MUST NOT
+   store any part of either this request or any response to it.  This
+   directive applies to both private and shared caches.  "MUST NOT
+   store" in this context means that the cache MUST NOT intentionally
+   store the information in non-volatile storage, and MUST make a
+   best-effort attempt to remove the information from volatile storage
+   as promptly as possible after forwarding it.
+
+   This directive is NOT a reliable or sufficient mechanism for ensuring
+   privacy.  In particular, malicious or compromised caches might not
+   recognize or obey this directive, and communications networks might
+   be vulnerable to eavesdropping.
+
+   Note that if a request containing this directive is satisfied from a
+   cache, the no-store request directive does not apply to the already
+   stored response.
+
+5.2.1.6.  no-transform
+
+   The "no-transform" request directive indicates that an intermediary
+   (whether or not it implements a cache) MUST NOT transform the
+   payload, as defined in Section 5.7.2 of [RFC7230].
+
+5.2.1.7.  only-if-cached
+
+   The "only-if-cached" request directive indicates that the client only
+   wishes to obtain a stored response.  If it receives this directive, a
+   cache SHOULD either respond using a stored response that is
+   consistent with the other constraints of the request, or respond with
+
+
+
+
+Fielding, et al.             Standards Track                   [Page 23]
+
+RFC 7234                    HTTP/1.1 Caching                   June 2014
+
+
+   a 504 (Gateway Timeout) status code.  If a group of caches is being
+   operated as a unified system with good internal connectivity, a
+   member cache MAY forward such a request within that group of caches.
+
+5.2.2.  Response Cache-Control Directives
+
+5.2.2.1.  must-revalidate
+
+   The "must-revalidate" response directive indicates that once it has
+   become stale, a cache MUST NOT use the response to satisfy subsequent
+   requests without successful validation on the origin server.
+
+   The must-revalidate directive is necessary to support reliable
+   operation for certain protocol features.  In all circumstances a
+   cache MUST obey the must-revalidate directive; in particular, if a
+   cache cannot reach the origin server for any reason, it MUST generate
+   a 504 (Gateway Timeout) response.
+
+   The must-revalidate directive ought to be used by servers if and only
+   if failure to validate a request on the representation could result
+   in incorrect operation, such as a silently unexecuted financial
+   transaction.
+
+5.2.2.2.  no-cache
+
+   Argument syntax:
+
+      #field-name
+
+   The "no-cache" response directive indicates that the response MUST
+   NOT be used to satisfy a subsequent request without successful
+   validation on the origin server.  This allows an origin server to
+   prevent a cache from using it to satisfy a request without contacting
+   it, even by caches that have been configured to send stale responses.
+
+   If the no-cache response directive specifies one or more field-names,
+   then a cache MAY use the response to satisfy a subsequent request,
+   subject to any other restrictions on caching.  However, any header
+   fields in the response that have the field-name(s) listed MUST NOT be
+   sent in the response to a subsequent request without successful
+   revalidation with the origin server.  This allows an origin server to
+   prevent the re-use of certain header fields in a response, while
+   still allowing caching of the rest of the response.
+
+   The field-names given are not limited to the set of header fields
+   defined by this specification.  Field names are case-insensitive.
+
+
+
+
+
+Fielding, et al.             Standards Track                   [Page 24]
+
+RFC 7234                    HTTP/1.1 Caching                   June 2014
+
+
+   This directive uses the quoted-string form of the argument syntax.  A
+   sender SHOULD NOT generate the token form (even if quoting appears
+   not to be needed for single-entry lists).
+
+   Note: Although it has been back-ported to many implementations, some
+   HTTP/1.0 caches will not recognize or obey this directive.  Also,
+   no-cache response directives with field-names are often handled by
+   caches as if an unqualified no-cache directive was received; i.e.,
+   the special handling for the qualified form is not widely
+   implemented.
+
+5.2.2.3.  no-store
+
+   The "no-store" response directive indicates that a cache MUST NOT
+   store any part of either the immediate request or response.  This
+   directive applies to both private and shared caches.  "MUST NOT
+   store" in this context means that the cache MUST NOT intentionally
+   store the information in non-volatile storage, and MUST make a
+   best-effort attempt to remove the information from volatile storage
+   as promptly as possible after forwarding it.
+
+   This directive is NOT a reliable or sufficient mechanism for ensuring
+   privacy.  In particular, malicious or compromised caches might not
+   recognize or obey this directive, and communications networks might
+   be vulnerable to eavesdropping.
+
+5.2.2.4.  no-transform
+
+   The "no-transform" response directive indicates that an intermediary
+   (regardless of whether it implements a cache) MUST NOT transform the
+   payload, as defined in Section 5.7.2 of [RFC7230].
+
+5.2.2.5.  public
+
+   The "public" response directive indicates that any cache MAY store
+   the response, even if the response would normally be non-cacheable or
+   cacheable only within a private cache.  (See Section 3.2 for
+   additional details related to the use of public in response to a
+   request containing Authorization, and Section 3 for details of how
+   public affects responses that would normally not be stored, due to
+   their status codes not being defined as cacheable by default; see
+   Section 4.2.2.)
+
+5.2.2.6.  private
+
+   Argument syntax:
+
+      #field-name
+
+
+
+Fielding, et al.             Standards Track                   [Page 25]
+
+RFC 7234                    HTTP/1.1 Caching                   June 2014
+
+
+   The "private" response directive indicates that the response message
+   is intended for a single user and MUST NOT be stored by a shared
+   cache.  A private cache MAY store the response and reuse it for later
+   requests, even if the response would normally be non-cacheable.
+
+   If the private response directive specifies one or more field-names,
+   this requirement is limited to the field-values associated with the
+   listed response header fields.  That is, a shared cache MUST NOT
+   store the specified field-names(s), whereas it MAY store the
+   remainder of the response message.
+
+   The field-names given are not limited to the set of header fields
+   defined by this specification.  Field names are case-insensitive.
+
+   This directive uses the quoted-string form of the argument syntax.  A
+   sender SHOULD NOT generate the token form (even if quoting appears
+   not to be needed for single-entry lists).
+
+   Note: This usage of the word "private" only controls where the
+   response can be stored; it cannot ensure the privacy of the message
+   content.  Also, private response directives with field-names are
+   often handled by caches as if an unqualified private directive was
+   received; i.e., the special handling for the qualified form is not
+   widely implemented.
+
+5.2.2.7.  proxy-revalidate
+
+   The "proxy-revalidate" response directive has the same meaning as the
+   must-revalidate response directive, except that it does not apply to
+   private caches.
+
+5.2.2.8.  max-age
+
+   Argument syntax:
+
+      delta-seconds (see Section 1.2.1)
+
+   The "max-age" response directive indicates that the response is to be
+   considered stale after its age is greater than the specified number
+   of seconds.
+
+   This directive uses the token form of the argument syntax: e.g.,
+   'max-age=5' not 'max-age="5"'.  A sender SHOULD NOT generate the
+   quoted-string form.
+
+
+
+
+
+
+
+Fielding, et al.             Standards Track                   [Page 26]
+
+RFC 7234                    HTTP/1.1 Caching                   June 2014
+
+
+5.2.2.9.  s-maxage
+
+   Argument syntax:
+
+      delta-seconds (see Section 1.2.1)
+
+   The "s-maxage" response directive indicates that, in shared caches,
+   the maximum age specified by this directive overrides the maximum age
+   specified by either the max-age directive or the Expires header
+   field.  The s-maxage directive also implies the semantics of the
+   proxy-revalidate response directive.
+
+   This directive uses the token form of the argument syntax: e.g.,
+   's-maxage=10' not 's-maxage="10"'.  A sender SHOULD NOT generate the
+   quoted-string form.
+
+5.2.3.  Cache Control Extensions
+
+   The Cache-Control header field can be extended through the use of one
+   or more cache-extension tokens, each with an optional value.  A cache
+   MUST ignore unrecognized cache directives.
+
+   Informational extensions (those that do not require a change in cache
+   behavior) can be added without changing the semantics of other
+   directives.
+
+   Behavioral extensions are designed to work by acting as modifiers to
+   the existing base of cache directives.  Both the new directive and
+   the old directive are supplied, such that applications that do not
+   understand the new directive will default to the behavior specified
+   by the old directive, and those that understand the new directive
+   will recognize it as modifying the requirements associated with the
+   old directive.  In this way, extensions to the existing cache-control
+   directives can be made without breaking deployed caches.
+
+   For example, consider a hypothetical new response directive called
+   "community" that acts as a modifier to the private directive: in
+   addition to private caches, any cache that is shared only by members
+   of the named community is allowed to cache the response.  An origin
+   server wishing to allow the UCI community to use an otherwise private
+   response in their shared cache(s) could do so by including
+
+     Cache-Control: private, community="UCI"
+
+   A cache that recognizes such a community cache-extension could
+   broaden its behavior in accordance with that extension.  A cache that
+   does not recognize the community cache-extension would ignore it and
+   adhere to the private directive.
+
+
+
+Fielding, et al.             Standards Track                   [Page 27]
+
+RFC 7234                    HTTP/1.1 Caching                   June 2014
+
+
+5.3.  Expires
+
+   The "Expires" header field gives the date/time after which the
+   response is considered stale.  See Section 4.2 for further discussion
+   of the freshness model.
+
+   The presence of an Expires field does not imply that the original
+   resource will change or cease to exist at, before, or after that
+   time.
+
+   The Expires value is an HTTP-date timestamp, as defined in Section
+   7.1.1.1 of [RFC7231].
+
+     Expires = HTTP-date
+
+   For example
+
+     Expires: Thu, 01 Dec 1994 16:00:00 GMT
+
+   A cache recipient MUST interpret invalid date formats, especially the
+   value "0", as representing a time in the past (i.e., "already
+   expired").
+
+   If a response includes a Cache-Control field with the max-age
+   directive (Section 5.2.2.8), a recipient MUST ignore the Expires
+   field.  Likewise, if a response includes the s-maxage directive
+   (Section 5.2.2.9), a shared cache recipient MUST ignore the Expires
+   field.  In both these cases, the value in Expires is only intended
+   for recipients that have not yet implemented the Cache-Control field.
+
+   An origin server without a clock MUST NOT generate an Expires field
+   unless its value represents a fixed time in the past (always expired)
+   or its value has been associated with the resource by a system or
+   user with a reliable clock.
+
+   Historically, HTTP required the Expires field-value to be no more
+   than a year in the future.  While longer freshness lifetimes are no
+   longer prohibited, extremely large values have been demonstrated to
+   cause problems (e.g., clock overflows due to use of 32-bit integers
+   for time values), and many caches will evict a response far sooner
+   than that.
+
+
+
+
+
+
+
+
+
+
+Fielding, et al.             Standards Track                   [Page 28]
+
+RFC 7234                    HTTP/1.1 Caching                   June 2014
+
+
+5.4.  Pragma
+
+   The "Pragma" header field allows backwards compatibility with
+   HTTP/1.0 caches, so that clients can specify a "no-cache" request
+   that they will understand (as Cache-Control was not defined until
+   HTTP/1.1).  When the Cache-Control header field is also present and
+   understood in a request, Pragma is ignored.
+
+   In HTTP/1.0, Pragma was defined as an extensible field for
+   implementation-specified directives for recipients.  This
+   specification deprecates such extensions to improve interoperability.
+
+     Pragma           = 1#pragma-directive
+     pragma-directive = "no-cache" / extension-pragma
+     extension-pragma = token [ "=" ( token / quoted-string ) ]
+
+   When the Cache-Control header field is not present in a request,
+   caches MUST consider the no-cache request pragma-directive as having
+   the same effect as if "Cache-Control: no-cache" were present (see
+   Section 5.2.1).
+
+   When sending a no-cache request, a client ought to include both the
+   pragma and cache-control directives, unless Cache-Control: no-cache
+   is purposefully omitted to target other Cache-Control response
+   directives at HTTP/1.1 caches.  For example:
+
+     GET / HTTP/1.1
+     Host: www.example.com
+     Cache-Control: max-age=30
+     Pragma: no-cache
+
+   will constrain HTTP/1.1 caches to serve a response no older than 30
+   seconds, while precluding implementations that do not understand
+   Cache-Control from serving a cached response.
+
+      Note: Because the meaning of "Pragma: no-cache" in responses is
+      not specified, it does not provide a reliable replacement for
+      "Cache-Control: no-cache" in them.
+
+5.5.  Warning
+
+   The "Warning" header field is used to carry additional information
+   about the status or transformation of a message that might not be
+   reflected in the status code.  This information is typically used to
+   warn about possible incorrectness introduced by caching operations or
+   transformations applied to the payload of the message.
+
+
+
+
+
+Fielding, et al.             Standards Track                   [Page 29]
+
+RFC 7234                    HTTP/1.1 Caching                   June 2014
+
+
+   Warnings can be used for other purposes, both cache-related and
+   otherwise.  The use of a warning, rather than an error status code,
+   distinguishes these responses from true failures.
+
+   Warning header fields can in general be applied to any message,
+   however some warn-codes are specific to caches and can only be
+   applied to response messages.
+
+     Warning       = 1#warning-value
+
+     warning-value = warn-code SP warn-agent SP warn-text
+                                           [ SP warn-date ]
+
+     warn-code  = 3DIGIT
+     warn-agent = ( uri-host [ ":" port ] ) / pseudonym
+                     ; the name or pseudonym of the server adding
+                     ; the Warning header field, for use in debugging
+                     ; a single "-" is recommended when agent unknown
+     warn-text  = quoted-string
+     warn-date  = DQUOTE HTTP-date DQUOTE
+
+   Multiple warnings can be generated in a response (either by the
+   origin server or by a cache), including multiple warnings with the
+   same warn-code number that only differ in warn-text.
+
+   A user agent that receives one or more Warning header fields SHOULD
+   inform the user of as many of them as possible, in the order that
+   they appear in the response.  Senders that generate multiple Warning
+   header fields are encouraged to order them with this user agent
+   behavior in mind.  A sender that generates new Warning header fields
+   MUST append them after any existing Warning header fields.
+
+   Warnings are assigned three digit warn-codes.  The first digit
+   indicates whether the Warning is required to be deleted from a stored
+   response after validation:
+
+   o  1xx warn-codes describe the freshness or validation status of the
+      response, and so they MUST be deleted by a cache after validation.
+      They can only be generated by a cache when validating a cached
+      entry, and MUST NOT be generated in any other situation.
+
+   o  2xx warn-codes describe some aspect of the representation that is
+      not rectified by a validation (for example, a lossy compression of
+      the representation) and they MUST NOT be deleted by a cache after
+      validation, unless a full response is sent, in which case they
+      MUST be.
+
+
+
+
+
+Fielding, et al.             Standards Track                   [Page 30]
+
+RFC 7234                    HTTP/1.1 Caching                   June 2014
+
+
+   If a sender generates one or more 1xx warn-codes in a message to be
+   sent to a recipient known to implement only HTTP/1.0, the sender MUST
+   include in each corresponding warning-value a warn-date that matches
+   the Date header field in the message.  For example:
+
+     HTTP/1.1 200 OK
+     Date: Sat, 25 Aug 2012 23:34:45 GMT
+     Warning: 112 - "network down" "Sat, 25 Aug 2012 23:34:45 GMT"
+
+
+   Warnings have accompanying warn-text that describes the error, e.g.,
+   for logging.  It is advisory only, and its content does not affect
+   interpretation of the warn-code.
+
+   If a recipient that uses, evaluates, or displays Warning header
+   fields receives a warn-date that is different from the Date value in
+   the same message, the recipient MUST exclude the warning-value
+   containing that warn-date before storing, forwarding, or using the
+   message.  This allows recipients to exclude warning-values that were
+   improperly retained after a cache validation.  If all of the
+   warning-values are excluded, the recipient MUST exclude the Warning
+   header field as well.
+
+   The following warn-codes are defined by this specification, each with
+   a recommended warn-text in English, and a description of its meaning.
+   The procedure for defining additional warn codes is described in
+   Section 7.2.1.
+
+5.5.1.  Warning: 110 - "Response is Stale"
+
+   A cache SHOULD generate this whenever the sent response is stale.
+
+5.5.2.  Warning: 111 - "Revalidation Failed"
+
+   A cache SHOULD generate this when sending a stale response because an
+   attempt to validate the response failed, due to an inability to reach
+   the server.
+
+5.5.3.  Warning: 112 - "Disconnected Operation"
+
+   A cache SHOULD generate this if it is intentionally disconnected from
+   the rest of the network for a period of time.
+
+5.5.4.  Warning: 113 - "Heuristic Expiration"
+
+   A cache SHOULD generate this if it heuristically chose a freshness
+   lifetime greater than 24 hours and the response's age is greater than
+   24 hours.
+
+
+
+Fielding, et al.             Standards Track                   [Page 31]
+
+RFC 7234                    HTTP/1.1 Caching                   June 2014
+
+
+5.5.5.  Warning: 199 - "Miscellaneous Warning"
+
+   The warning text can include arbitrary information to be presented to
+   a human user or logged.  A system receiving this warning MUST NOT
+   take any automated action, besides presenting the warning to the
+   user.
+
+5.5.6.  Warning: 214 - "Transformation Applied"
+
+   This Warning code MUST be added by a proxy if it applies any
+   transformation to the representation, such as changing the
+   content-coding, media-type, or modifying the representation data,
+   unless this Warning code already appears in the response.
+
+5.5.7.  Warning: 299 - "Miscellaneous Persistent Warning"
+
+   The warning text can include arbitrary information to be presented to
+   a human user or logged.  A system receiving this warning MUST NOT
+   take any automated action.
+
+6.  History Lists
+
+   User agents often have history mechanisms, such as "Back" buttons and
+   history lists, that can be used to redisplay a representation
+   retrieved earlier in a session.
+
+   The freshness model (Section 4.2) does not necessarily apply to
+   history mechanisms.  That is, a history mechanism can display a
+   previous representation even if it has expired.
+
+   This does not prohibit the history mechanism from telling the user
+   that a view might be stale or from honoring cache directives (e.g.,
+   Cache-Control: no-store).
+
+7.  IANA Considerations
+
+7.1.  Cache Directive Registry
+
+   The "Hypertext Transfer Protocol (HTTP) Cache Directive Registry"
+   defines the namespace for the cache directives.  It has been created
+   and is now maintained at
+   <http://www.iana.org/assignments/http-cache-directives>.
+
+7.1.1.  Procedure
+
+   A registration MUST include the following fields:
+
+   o  Cache Directive Name
+
+
+
+Fielding, et al.             Standards Track                   [Page 32]
+
+RFC 7234                    HTTP/1.1 Caching                   June 2014
+
+
+   o  Pointer to specification text
+
+   Values to be added to this namespace require IETF Review (see
+   [RFC5226], Section 4.1).
+
+7.1.2.  Considerations for New Cache Control Directives
+
+   New extension directives ought to consider defining:
+
+   o  What it means for a directive to be specified multiple times,
+
+   o  When the directive does not take an argument, what it means when
+      an argument is present,
+
+   o  When the directive requires an argument, what it means when it is
+      missing,
+
+   o  Whether the directive is specific to requests, responses, or able
+      to be used in either.
+
+   See also Section 5.2.3.
+
+7.1.3.  Registrations
+
+   The registry has been populated with the registrations below:
+
+   +------------------------+----------------------------------+
+   | Cache Directive        | Reference                        |
+   +------------------------+----------------------------------+
+   | max-age                | Section 5.2.1.1, Section 5.2.2.8 |
+   | max-stale              | Section 5.2.1.2                  |
+   | min-fresh              | Section 5.2.1.3                  |
+   | must-revalidate        | Section 5.2.2.1                  |
+   | no-cache               | Section 5.2.1.4, Section 5.2.2.2 |
+   | no-store               | Section 5.2.1.5, Section 5.2.2.3 |
+   | no-transform           | Section 5.2.1.6, Section 5.2.2.4 |
+   | only-if-cached         | Section 5.2.1.7                  |
+   | private                | Section 5.2.2.6                  |
+   | proxy-revalidate       | Section 5.2.2.7                  |
+   | public                 | Section 5.2.2.5                  |
+   | s-maxage               | Section 5.2.2.9                  |
+   | stale-if-error         | [RFC5861], Section 4             |
+   | stale-while-revalidate | [RFC5861], Section 3             |
+   +------------------------+----------------------------------+
+
+
+
+
+
+
+
+Fielding, et al.             Standards Track                   [Page 33]
+
+RFC 7234                    HTTP/1.1 Caching                   June 2014
+
+
+7.2.  Warn Code Registry
+
+   The "Hypertext Transfer Protocol (HTTP) Warn Codes" registry defines
+   the namespace for warn codes.  It has been created and is now
+   maintained at <http://www.iana.org/assignments/http-warn-codes>.
+
+7.2.1.  Procedure
+
+   A registration MUST include the following fields:
+
+   o  Warn Code (3 digits)
+
+   o  Short Description
+
+   o  Pointer to specification text
+
+   Values to be added to this namespace require IETF Review (see
+   [RFC5226], Section 4.1).
+
+7.2.2.  Registrations
+
+   The registry has been populated with the registrations below:
+
+   +-----------+----------------------------------+---------------+
+   | Warn Code | Short Description                | Reference     |
+   +-----------+----------------------------------+---------------+
+   | 110       | Response is Stale                | Section 5.5.1 |
+   | 111       | Revalidation Failed              | Section 5.5.2 |
+   | 112       | Disconnected Operation           | Section 5.5.3 |
+   | 113       | Heuristic Expiration             | Section 5.5.4 |
+   | 199       | Miscellaneous Warning            | Section 5.5.5 |
+   | 214       | Transformation Applied           | Section 5.5.6 |
+   | 299       | Miscellaneous Persistent Warning | Section 5.5.7 |
+   +-----------+----------------------------------+---------------+
+
+7.3.  Header Field Registration
+
+   HTTP header fields are registered within the "Message Headers"
+   registry maintained at
+   <http://www.iana.org/assignments/message-headers/>.
+
+
+
+
+
+
+
+
+
+
+
+Fielding, et al.             Standards Track                   [Page 34]
+
+RFC 7234                    HTTP/1.1 Caching                   June 2014
+
+
+   This document defines the following HTTP header fields, so the
+   "Permanent Message Header Field Names" registry has been updated
+   accordingly (see [BCP90]).
+
+   +-------------------+----------+----------+-------------+
+   | Header Field Name | Protocol | Status   | Reference   |
+   +-------------------+----------+----------+-------------+
+   | Age               | http     | standard | Section 5.1 |
+   | Cache-Control     | http     | standard | Section 5.2 |
+   | Expires           | http     | standard | Section 5.3 |
+   | Pragma            | http     | standard | Section 5.4 |
+   | Warning           | http     | standard | Section 5.5 |
+   +-------------------+----------+----------+-------------+
+
+   The change controller is: "IETF (iesg@ietf.org) - Internet
+   Engineering Task Force".
+
+8.  Security Considerations
+
+   This section is meant to inform developers, information providers,
+   and users of known security concerns specific to HTTP caching.  More
+   general security considerations are addressed in HTTP messaging
+   [RFC7230] and semantics [RFC7231].
+
+   Caches expose additional potential vulnerabilities, since the
+   contents of the cache represent an attractive target for malicious
+   exploitation.  Because cache contents persist after an HTTP request
+   is complete, an attack on the cache can reveal information long after
+   a user believes that the information has been removed from the
+   network.  Therefore, cache contents need to be protected as sensitive
+   information.
+
+   In particular, various attacks might be amplified by being stored in
+   a shared cache; such "cache poisoning" attacks use the cache to
+   distribute a malicious payload to many clients, and are especially
+   effective when an attacker can use implementation flaws, elevated
+   privileges, or other techniques to insert such a response into a
+   cache.  One common attack vector for cache poisoning is to exploit
+   differences in message parsing on proxies and in user agents; see
+   Section 3.3.3 of [RFC7230] for the relevant requirements.
+
+   Likewise, implementation flaws (as well as misunderstanding of cache
+   operation) might lead to caching of sensitive information (e.g.,
+   authentication credentials) that is thought to be private, exposing
+   it to unauthorized parties.
+
+
+
+
+
+
+Fielding, et al.             Standards Track                   [Page 35]
+
+RFC 7234                    HTTP/1.1 Caching                   June 2014
+
+
+   Furthermore, the very use of a cache can bring about privacy
+   concerns.  For example, if two users share a cache, and the first one
+   browses to a site, the second may be able to detect that the other
+   has been to that site, because the resources from it load more
+   quickly, thanks to the cache.
+
+   Note that the Set-Cookie response header field [RFC6265] does not
+   inhibit caching; a cacheable response with a Set-Cookie header field
+   can be (and often is) used to satisfy subsequent requests to caches.
+   Servers who wish to control caching of these responses are encouraged
+   to emit appropriate Cache-Control response header fields.
+
+9.  Acknowledgments
+
+   See Section 10 of [RFC7230].
+
+10.  References
+
+10.1.  Normative References
+
+   [RFC2119]  Bradner, S., "Key words for use in RFCs to Indicate
+              Requirement Levels", BCP 14, RFC 2119, March 1997.
+
+   [RFC5234]  Crocker, D., Ed. and P. Overell, "Augmented BNF for Syntax
+              Specifications: ABNF", STD 68, RFC 5234, January 2008.
+
+   [RFC7230]  Fielding, R., Ed. and J. Reschke, Ed., "Hypertext Transfer
+              Protocol (HTTP/1.1): Message Syntax and Routing",
+              RFC 7230, June 2014.
+
+   [RFC7231]  Fielding, R., Ed. and J. Reschke, Ed., "Hypertext Transfer
+              Protocol (HTTP/1.1): Semantics and Content", RFC 7231,
+              June 2014.
+
+   [RFC7232]  Fielding, R., Ed. and J. Reschke, Ed., "Hypertext Transfer
+              Protocol (HTTP/1.1): Conditional Requests", RFC 7232,
+              June 2014.
+
+   [RFC7233]  Fielding, R., Ed., Lafon, Y., Ed., and J. Reschke, Ed.,
+              "Hypertext Transfer Protocol (HTTP/1.1): Range Requests",
+              RFC 7233, June 2014.
+
+   [RFC7235]  Fielding, R., Ed. and J. Reschke, Ed., "Hypertext Transfer
+              Protocol (HTTP/1.1): Authentication", RFC 7235, June 2014.
+
+
+
+
+
+
+
+Fielding, et al.             Standards Track                   [Page 36]
+
+RFC 7234                    HTTP/1.1 Caching                   June 2014
+
+
+10.2.  Informative References
+
+   [BCP90]    Klyne, G., Nottingham, M., and J. Mogul, "Registration
+              Procedures for Message Header Fields", BCP 90, RFC 3864,
+              September 2004.
+
+   [RFC2616]  Fielding, R., Gettys, J., Mogul, J., Frystyk, H.,
+              Masinter, L., Leach, P., and T. Berners-Lee, "Hypertext
+              Transfer Protocol -- HTTP/1.1", RFC 2616, June 1999.
+
+   [RFC5226]  Narten, T. and H. Alvestrand, "Guidelines for Writing an
+              IANA Considerations Section in RFCs", BCP 26, RFC 5226,
+              May 2008.
+
+   [RFC5861]  Nottingham, M., "HTTP Cache-Control Extensions for Stale
+              Content", RFC 5861, April 2010.
+
+   [RFC5905]  Mills, D., Martin, J., Ed., Burbank, J., and W. Kasch,
+              "Network Time Protocol Version 4: Protocol and Algorithms
+              Specification", RFC 5905, June 2010.
+
+   [RFC6265]  Barth, A., "HTTP State Management Mechanism", RFC 6265,
+              April 2011.
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+Fielding, et al.             Standards Track                   [Page 37]
+
+RFC 7234                    HTTP/1.1 Caching                   June 2014
+
+
+Appendix A.  Changes from RFC 2616
+
+   The specification has been substantially rewritten for clarity.
+
+   The conditions under which an authenticated response can be cached
+   have been clarified.  (Section 3.2)
+
+   New status codes can now define that caches are allowed to use
+   heuristic freshness with them.  Caches are now allowed to calculate
+   heuristic freshness for URIs with query components.  (Section 4.2.2)
+
+   The algorithm for calculating age is now less conservative.  Caches
+   are now required to handle dates with time zones as if they're
+   invalid, because it's not possible to accurately guess.
+   (Section 4.2.3)
+
+   The Content-Location response header field is no longer used to
+   determine the appropriate response to use when validating.
+   (Section 4.3)
+
+   The algorithm for selecting a cached negotiated response to use has
+   been clarified in several ways.  In particular, it now explicitly
+   allows header-specific canonicalization when processing selecting
+   header fields.  (Section 4.1)
+
+   Requirements regarding denial-of-service attack avoidance when
+   performing invalidation have been clarified.  (Section 4.4)
+
+   Cache invalidation only occurs when a successful response is
+   received.  (Section 4.4)
+
+   Cache directives are explicitly defined to be case-insensitive.
+   Handling of multiple instances of cache directives when only one is
+   expected is now defined.  (Section 5.2)
+
+   The "no-store" request directive doesn't apply to responses; i.e., a
+   cache can satisfy a request with no-store on it and does not
+   invalidate it.  (Section 5.2.1.5)
+
+   The qualified forms of the private and no-cache cache directives are
+   noted to not be widely implemented; for example, "private=foo" is
+   interpreted by many caches as simply "private".  Additionally, the
+   meaning of the qualified form of no-cache has been clarified.
+   (Section 5.2.2)
+
+   The "no-cache" response directive's meaning has been clarified.
+   (Section 5.2.2.2)
+
+
+
+
+Fielding, et al.             Standards Track                   [Page 38]
+
+RFC 7234                    HTTP/1.1 Caching                   June 2014
+
+
+   The one-year limit on Expires header field values has been removed;
+   instead, the reasoning for using a sensible value is given.
+   (Section 5.3)
+
+   The Pragma header field is now only defined for backwards
+   compatibility; future pragmas are deprecated.  (Section 5.4)
+
+   Some requirements regarding production and processing of the Warning
+   header fields have been relaxed, as it is not widely implemented.
+   Furthermore, the Warning header field no longer uses RFC 2047
+   encoding, nor does it allow multiple languages, as these aspects were
+   not implemented.  (Section 5.5)
+
+   This specification introduces the Cache Directive and Warn Code
+   Registries, and defines considerations for new cache directives.
+   (Section 7.1 and Section 7.2)
+
+Appendix B.  Imported ABNF
+
+   The following core rules are included by reference, as defined in
+   Appendix B.1 of [RFC5234]: ALPHA (letters), CR (carriage return),
+   CRLF (CR LF), CTL (controls), DIGIT (decimal 0-9), DQUOTE (double
+   quote), HEXDIG (hexadecimal 0-9/A-F/a-f), LF (line feed), OCTET (any
+   8-bit sequence of data), SP (space), and VCHAR (any visible US-ASCII
+   character).
+
+   The rules below are defined in [RFC7230]:
+
+     OWS           = <OWS, see [RFC7230], Section 3.2.3>
+     field-name    = <field-name, see [RFC7230], Section 3.2>
+     quoted-string = <quoted-string, see [RFC7230], Section 3.2.6>
+     token         = <token, see [RFC7230], Section 3.2.6>
+
+     port          = <port, see [RFC7230], Section 2.7>
+     pseudonym     = <pseudonym, see [RFC7230], Section 5.7.1>
+     uri-host      = <uri-host, see [RFC7230], Section 2.7>
+
+   The rules below are defined in other parts:
+
+     HTTP-date     = <HTTP-date, see [RFC7231], Section 7.1.1.1>
+
+
+
+
+
+
+
+
+
+
+
+Fielding, et al.             Standards Track                   [Page 39]
+
+RFC 7234                    HTTP/1.1 Caching                   June 2014
+
+
+Appendix C.  Collected ABNF
+
+   In the collected ABNF below, list rules are expanded as per Section
+   1.2 of [RFC7230].
+
+   Age = delta-seconds
+
+   Cache-Control = *( "," OWS ) cache-directive *( OWS "," [ OWS
+    cache-directive ] )
+
+   Expires = HTTP-date
+
+   HTTP-date = <HTTP-date, see [RFC7231], Section 7.1.1.1>
+
+   OWS = <OWS, see [RFC7230], Section 3.2.3>
+
+   Pragma = *( "," OWS ) pragma-directive *( OWS "," [ OWS
+    pragma-directive ] )
+
+   Warning = *( "," OWS ) warning-value *( OWS "," [ OWS warning-value ]
+    )
+
+   cache-directive = token [ "=" ( token / quoted-string ) ]
+
+   delta-seconds = 1*DIGIT
+
+   extension-pragma = token [ "=" ( token / quoted-string ) ]
+
+   field-name = <field-name, see [RFC7230], Section 3.2>
+
+   port = <port, see [RFC7230], Section 2.7>
+   pragma-directive = "no-cache" / extension-pragma
+   pseudonym = <pseudonym, see [RFC7230], Section 5.7.1>
+
+   quoted-string = <quoted-string, see [RFC7230], Section 3.2.6>
+
+   token = <token, see [RFC7230], Section 3.2.6>
+
+   uri-host = <uri-host, see [RFC7230], Section 2.7>
+
+   warn-agent = ( uri-host [ ":" port ] ) / pseudonym
+   warn-code = 3DIGIT
+   warn-date = DQUOTE HTTP-date DQUOTE
+   warn-text = quoted-string
+   warning-value = warn-code SP warn-agent SP warn-text [ SP warn-date
+    ]
+
+
+
+
+
+Fielding, et al.             Standards Track                   [Page 40]
+
+RFC 7234                    HTTP/1.1 Caching                   June 2014
+
+
+Index
+
+   1
+      110 (warn-code)  31
+      111 (warn-code)  31
+      112 (warn-code)  31
+      113 (warn-code)  31
+      199 (warn-code)  32
+
+   2
+      214 (warn-code)  32
+      299 (warn-code)  32
+
+   A
+      age  11
+      Age header field  21
+
+   C
+      cache  4
+      cache entry  5
+      cache key  5-6
+      Cache-Control header field  21
+
+   D
+      Disconnected Operation (warn-text)  31
+
+   E
+      Expires header field  28
+      explicit expiration time  11
+
+   F
+      fresh  11
+      freshness lifetime  11
+
+   G
+      Grammar
+         Age  21
+         Cache-Control  22
+         cache-directive  22
+         delta-seconds  5
+         Expires  28
+         extension-pragma  29
+         Pragma  29
+         pragma-directive  29
+         warn-agent  29
+         warn-code  29
+         warn-date  29
+         warn-text  29
+
+
+
+Fielding, et al.             Standards Track                   [Page 41]
+
+RFC 7234                    HTTP/1.1 Caching                   June 2014
+
+
+         Warning  29
+         warning-value  29
+
+   H
+      Heuristic Expiration (warn-text)  31
+      heuristic expiration time  11
+   M
+      max-age (cache directive)  22, 26
+      max-stale (cache directive)  22
+      min-fresh (cache directive)  22
+      Miscellaneous Persistent Warning (warn-text)  32
+      Miscellaneous Warning (warn-text)  32
+      must-revalidate (cache directive)  24
+
+   N
+      no-cache (cache directive)  23, 25
+      no-store (cache directive)  23, 24
+      no-transform (cache directive)  23, 25
+
+   O
+      only-if-cached (cache directive)  23
+
+   P
+      Pragma header field  29
+      private (cache directive)  25
+      private cache  4
+      proxy-revalidate (cache directive)  26
+      public (cache directive)  25
+
+   R
+      Response is Stale (warn-text)  30
+      Revalidation Failed (warn-text)  31
+
+   S
+      s-maxage (cache directive)  27
+      shared cache  4
+      stale  11
+      strong validator  18
+
+   T
+      Transformation Applied (warn-text)  32
+
+   V
+      validator  16
+
+   W
+      Warning header field  29
+
+
+
+
+Fielding, et al.             Standards Track                   [Page 42]
+
+RFC 7234                    HTTP/1.1 Caching                   June 2014
+
+
+Authors' Addresses
+
+   Roy T. Fielding (editor)
+   Adobe Systems Incorporated
+   345 Park Ave
+   San Jose, CA  95110
+   USA
+
+   EMail: fielding@gbiv.com
+   URI:   http://roy.gbiv.com/
+
+
+   Mark Nottingham (editor)
+   Akamai
+
+   EMail: mnot@mnot.net
+   URI:   http://www.mnot.net/
+
+
+   Julian F. Reschke (editor)
+   greenbytes GmbH
+   Hafenweg 16
+   Muenster, NW  48155
+   Germany
+
+   EMail: julian.reschke@greenbytes.de
+   URI:   http://greenbytes.de/tech/webdav/
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+Fielding, et al.             Standards Track                   [Page 43]
+
@@ -0,0 +1,1067 @@
+
+
+
+
+
+
+Internet Engineering Task Force (IETF)                  R. Fielding, Ed.
+Request for Comments: 7235                                         Adobe
+Obsoletes: 2616                                          J. Reschke, Ed.
+Updates: 2617                                                 greenbytes
+Category: Standards Track                                      June 2014
+ISSN: 2070-1721
+
+
+         Hypertext Transfer Protocol (HTTP/1.1): Authentication
+
+Abstract
+
+   The Hypertext Transfer Protocol (HTTP) is a stateless application-
+   level protocol for distributed, collaborative, hypermedia information
+   systems.  This document defines the HTTP Authentication framework.
+
+Status of This Memo
+
+   This is an Internet Standards Track document.
+
+   This document is a product of the Internet Engineering Task Force
+   (IETF).  It represents the consensus of the IETF community.  It has
+   received public review and has been approved for publication by the
+   Internet Engineering Steering Group (IESG).  Further information on
+   Internet Standards is available in Section 2 of RFC 5741.
+
+   Information about the current status of this document, any errata,
+   and how to provide feedback on it may be obtained at
+   http://www.rfc-editor.org/info/rfc7235.
+
+Copyright Notice
+
+   Copyright (c) 2014 IETF Trust and the persons identified as the
+   document authors.  All rights reserved.
+
+   This document is subject to BCP 78 and the IETF Trust's Legal
+   Provisions Relating to IETF Documents
+   (http://trustee.ietf.org/license-info) in effect on the date of
+   publication of this document.  Please review these documents
+   carefully, as they describe your rights and restrictions with respect
+   to this document.  Code Components extracted from this document must
+   include Simplified BSD License text as described in Section 4.e of
+   the Trust Legal Provisions and are provided without warranty as
+   described in the Simplified BSD License.
+
+   This document may contain material from IETF Documents or IETF
+   Contributions published or made publicly available before November
+   10, 2008.  The person(s) controlling the copyright in some of this
+
+
+
+Fielding & Reschke           Standards Track                    [Page 1]
+
+RFC 7235                 HTTP/1.1 Authentication               June 2014
+
+
+   material may not have granted the IETF Trust the right to allow
+   modifications of such material outside the IETF Standards Process.
+   Without obtaining an adequate license from the person(s) controlling
+   the copyright in such materials, this document may not be modified
+   outside the IETF Standards Process, and derivative works of it may
+   not be created outside the IETF Standards Process, except to format
+   it for publication as an RFC or to translate it into languages other
+   than English.
+
+Table of Contents
+
+   1. Introduction ....................................................3
+      1.1. Conformance and Error Handling .............................3
+      1.2. Syntax Notation ............................................3
+   2. Access Authentication Framework .................................3
+      2.1. Challenge and Response .....................................3
+      2.2. Protection Space (Realm) ...................................5
+   3. Status Code Definitions .........................................6
+      3.1. 401 Unauthorized ...........................................6
+      3.2. 407 Proxy Authentication Required ..........................6
+   4. Header Field Definitions ........................................7
+      4.1. WWW-Authenticate ...........................................7
+      4.2. Authorization ..............................................8
+      4.3. Proxy-Authenticate .........................................8
+      4.4. Proxy-Authorization ........................................9
+   5. IANA Considerations .............................................9
+      5.1. Authentication Scheme Registry .............................9
+           5.1.1. Procedure ...........................................9
+           5.1.2. Considerations for New Authentication Schemes ......10
+      5.2. Status Code Registration ..................................11
+      5.3. Header Field Registration .................................11
+   6. Security Considerations ........................................12
+      6.1. Confidentiality of Credentials ............................12
+      6.2. Authentication Credentials and Idle Clients ...............12
+      6.3. Protection Spaces .........................................13
+   7. Acknowledgments ................................................14
+   8. References .....................................................14
+      8.1. Normative References ......................................14
+      8.2. Informative References ....................................14
+   Appendix A. Changes from RFCs 2616 and 2617 .......................16
+   Appendix B. Imported ABNF .........................................16
+   Appendix C. Collected ABNF ........................................17
+   Index .............................................................18
+
+
+
+
+
+
+
+
+Fielding & Reschke           Standards Track                    [Page 2]
+
+RFC 7235                 HTTP/1.1 Authentication               June 2014
+
+
+1.  Introduction
+
+   HTTP provides a general framework for access control and
+   authentication, via an extensible set of challenge-response
+   authentication schemes, which can be used by a server to challenge a
+   client request and by a client to provide authentication information.
+   This document defines HTTP/1.1 authentication in terms of the
+   architecture defined in "Hypertext Transfer Protocol (HTTP/1.1):
+   Message Syntax and Routing" [RFC7230], including the general
+   framework previously described in "HTTP Authentication: Basic and
+   Digest Access Authentication" [RFC2617] and the related fields and
+   status codes previously defined in "Hypertext Transfer Protocol --
+   HTTP/1.1" [RFC2616].
+
+   The IANA Authentication Scheme Registry (Section 5.1) lists
+   registered authentication schemes and their corresponding
+   specifications, including the "basic" and "digest" authentication
+   schemes previously defined by RFC 2617.
+
+1.1.  Conformance and Error Handling
+
+   The key words "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT",
+   "SHOULD", "SHOULD NOT", "RECOMMENDED", "MAY", and "OPTIONAL" in this
+   document are to be interpreted as described in [RFC2119].
+
+   Conformance criteria and considerations regarding error handling are
+   defined in Section 2.5 of [RFC7230].
+
+1.2.  Syntax Notation
+
+   This specification uses the Augmented Backus-Naur Form (ABNF)
+   notation of [RFC5234] with a list extension, defined in Section 7 of
+   [RFC7230], that allows for compact definition of comma-separated
+   lists using a '#' operator (similar to how the '*' operator indicates
+   repetition).  Appendix B describes rules imported from other
+   documents.  Appendix C shows the collected grammar with all list
+   operators expanded to standard ABNF notation.
+
+2.  Access Authentication Framework
+
+2.1.  Challenge and Response
+
+   HTTP provides a simple challenge-response authentication framework
+   that can be used by a server to challenge a client request and by a
+   client to provide authentication information.  It uses a case-
+   insensitive token as a means to identify the authentication scheme,
+   followed by additional information necessary for achieving
+
+
+
+
+Fielding & Reschke           Standards Track                    [Page 3]
+
+RFC 7235                 HTTP/1.1 Authentication               June 2014
+
+
+   authentication via that scheme.  The latter can be either a comma-
+   separated list of parameters or a single sequence of characters
+   capable of holding base64-encoded information.
+
+   Authentication parameters are name=value pairs, where the name token
+   is matched case-insensitively, and each parameter name MUST only
+   occur once per challenge.
+
+     auth-scheme    = token
+
+     auth-param     = token BWS "=" BWS ( token / quoted-string )
+
+     token68        = 1*( ALPHA / DIGIT /
+                          "-" / "." / "_" / "~" / "+" / "/" ) *"="
+
+   The token68 syntax allows the 66 unreserved URI characters
+   ([RFC3986]), plus a few others, so that it can hold a base64,
+   base64url (URL and filename safe alphabet), base32, or base16 (hex)
+   encoding, with or without padding, but excluding whitespace
+   ([RFC4648]).
+
+   A 401 (Unauthorized) response message is used by an origin server to
+   challenge the authorization of a user agent, including a
+   WWW-Authenticate header field containing at least one challenge
+   applicable to the requested resource.
+
+   A 407 (Proxy Authentication Required) response message is used by a
+   proxy to challenge the authorization of a client, including a
+   Proxy-Authenticate header field containing at least one challenge
+   applicable to the proxy for the requested resource.
+
+     challenge   = auth-scheme [ 1*SP ( token68 / #auth-param ) ]
+
+      Note: Many clients fail to parse a challenge that contains an
+      unknown scheme.  A workaround for this problem is to list well-
+      supported schemes (such as "basic") first.
+
+   A user agent that wishes to authenticate itself with an origin server
+   -- usually, but not necessarily, after receiving a 401 (Unauthorized)
+   -- can do so by including an Authorization header field with the
+   request.
+
+   A client that wishes to authenticate itself with a proxy -- usually,
+   but not necessarily, after receiving a 407 (Proxy Authentication
+   Required) -- can do so by including a Proxy-Authorization header
+   field with the request.
+
+
+
+
+
+Fielding & Reschke           Standards Track                    [Page 4]
+
+RFC 7235                 HTTP/1.1 Authentication               June 2014
+
+
+   Both the Authorization field value and the Proxy-Authorization field
+   value contain the client's credentials for the realm of the resource
+   being requested, based upon a challenge received in a response
+   (possibly at some point in the past).  When creating their values,
+   the user agent ought to do so by selecting the challenge with what it
+   considers to be the most secure auth-scheme that it understands,
+   obtaining credentials from the user as appropriate.  Transmission of
+   credentials within header field values implies significant security
+   considerations regarding the confidentiality of the underlying
+   connection, as described in Section 6.1.
+
+     credentials = auth-scheme [ 1*SP ( token68 / #auth-param ) ]
+
+   Upon receipt of a request for a protected resource that omits
+   credentials, contains invalid credentials (e.g., a bad password) or
+   partial credentials (e.g., when the authentication scheme requires
+   more than one round trip), an origin server SHOULD send a 401
+   (Unauthorized) response that contains a WWW-Authenticate header field
+   with at least one (possibly new) challenge applicable to the
+   requested resource.
+
+   Likewise, upon receipt of a request that omits proxy credentials or
+   contains invalid or partial proxy credentials, a proxy that requires
+   authentication SHOULD generate a 407 (Proxy Authentication Required)
+   response that contains a Proxy-Authenticate header field with at
+   least one (possibly new) challenge applicable to the proxy.
+
+   A server that receives valid credentials that are not adequate to
+   gain access ought to respond with the 403 (Forbidden) status code
+   (Section 6.5.3 of [RFC7231]).
+
+   HTTP does not restrict applications to this simple challenge-response
+   framework for access authentication.  Additional mechanisms can be
+   used, such as authentication at the transport level or via message
+   encapsulation, and with additional header fields specifying
+   authentication information.  However, such additional mechanisms are
+   not defined by this specification.
+
+2.2.  Protection Space (Realm)
+
+   The "realm" authentication parameter is reserved for use by
+   authentication schemes that wish to indicate a scope of protection.
+
+   A protection space is defined by the canonical root URI (the scheme
+   and authority components of the effective request URI; see Section
+   5.5 of [RFC7230]) of the server being accessed, in combination with
+   the realm value if present.  These realms allow the protected
+   resources on a server to be partitioned into a set of protection
+
+
+
+Fielding & Reschke           Standards Track                    [Page 5]
+
+RFC 7235                 HTTP/1.1 Authentication               June 2014
+
+
+   spaces, each with its own authentication scheme and/or authorization
+   database.  The realm value is a string, generally assigned by the
+   origin server, that can have additional semantics specific to the
+   authentication scheme.  Note that a response can have multiple
+   challenges with the same auth-scheme but with different realms.
+
+   The protection space determines the domain over which credentials can
+   be automatically applied.  If a prior request has been authorized,
+   the user agent MAY reuse the same credentials for all other requests
+   within that protection space for a period of time determined by the
+   authentication scheme, parameters, and/or user preferences (such as a
+   configurable inactivity timeout).  Unless specifically allowed by the
+   authentication scheme, a single protection space cannot extend
+   outside the scope of its server.
+
+   For historical reasons, a sender MUST only generate the quoted-string
+   syntax.  Recipients might have to support both token and
+   quoted-string syntax for maximum interoperability with existing
+   clients that have been accepting both notations for a long time.
+
+3.  Status Code Definitions
+
+3.1.  401 Unauthorized
+
+   The 401 (Unauthorized) status code indicates that the request has not
+   been applied because it lacks valid authentication credentials for
+   the target resource.  The server generating a 401 response MUST send
+   a WWW-Authenticate header field (Section 4.1) containing at least one
+   challenge applicable to the target resource.
+
+   If the request included authentication credentials, then the 401
+   response indicates that authorization has been refused for those
+   credentials.  The user agent MAY repeat the request with a new or
+   replaced Authorization header field (Section 4.2).  If the 401
+   response contains the same challenge as the prior response, and the
+   user agent has already attempted authentication at least once, then
+   the user agent SHOULD present the enclosed representation to the
+   user, since it usually contains relevant diagnostic information.
+
+3.2.  407 Proxy Authentication Required
+
+   The 407 (Proxy Authentication Required) status code is similar to 401
+   (Unauthorized), but it indicates that the client needs to
+   authenticate itself in order to use a proxy.  The proxy MUST send a
+   Proxy-Authenticate header field (Section 4.3) containing a challenge
+   applicable to that proxy for the target resource.  The client MAY
+   repeat the request with a new or replaced Proxy-Authorization header
+   field (Section 4.4).
+
+
+
+Fielding & Reschke           Standards Track                    [Page 6]
+
+RFC 7235                 HTTP/1.1 Authentication               June 2014
+
+
+4.  Header Field Definitions
+
+   This section defines the syntax and semantics of header fields
+   related to the HTTP authentication framework.
+
+4.1.  WWW-Authenticate
+
+   The "WWW-Authenticate" header field indicates the authentication
+   scheme(s) and parameters applicable to the target resource.
+
+     WWW-Authenticate = 1#challenge
+
+   A server generating a 401 (Unauthorized) response MUST send a
+   WWW-Authenticate header field containing at least one challenge.  A
+   server MAY generate a WWW-Authenticate header field in other response
+   messages to indicate that supplying credentials (or different
+   credentials) might affect the response.
+
+   A proxy forwarding a response MUST NOT modify any WWW-Authenticate
+   fields in that response.
+
+   User agents are advised to take special care in parsing the field
+   value, as it might contain more than one challenge, and each
+   challenge can contain a comma-separated list of authentication
+   parameters.  Furthermore, the header field itself can occur multiple
+   times.
+
+   For instance:
+
+     WWW-Authenticate: Newauth realm="apps", type=1,
+                       title="Login to \"apps\"", Basic realm="simple"
+
+   This header field contains two challenges; one for the "Newauth"
+   scheme with a realm value of "apps", and two additional parameters
+   "type" and "title", and another one for the "Basic" scheme with a
+   realm value of "simple".
+
+      Note: The challenge grammar production uses the list syntax as
+      well.  Therefore, a sequence of comma, whitespace, and comma can
+      be considered either as applying to the preceding challenge, or to
+      be an empty entry in the list of challenges.  In practice, this
+      ambiguity does not affect the semantics of the header field value
+      and thus is harmless.
+
+
+
+
+
+
+
+
+Fielding & Reschke           Standards Track                    [Page 7]
+
+RFC 7235                 HTTP/1.1 Authentication               June 2014
+
+
+4.2.  Authorization
+
+   The "Authorization" header field allows a user agent to authenticate
+   itself with an origin server -- usually, but not necessarily, after
+   receiving a 401 (Unauthorized) response.  Its value consists of
+   credentials containing the authentication information of the user
+   agent for the realm of the resource being requested.
+
+     Authorization = credentials
+
+   If a request is authenticated and a realm specified, the same
+   credentials are presumed to be valid for all other requests within
+   this realm (assuming that the authentication scheme itself does not
+   require otherwise, such as credentials that vary according to a
+   challenge value or using synchronized clocks).
+
+   A proxy forwarding a request MUST NOT modify any Authorization fields
+   in that request.  See Section 3.2 of [RFC7234] for details of and
+   requirements pertaining to handling of the Authorization field by
+   HTTP caches.
+
+4.3.  Proxy-Authenticate
+
+   The "Proxy-Authenticate" header field consists of at least one
+   challenge that indicates the authentication scheme(s) and parameters
+   applicable to the proxy for this effective request URI (Section 5.5
+   of [RFC7230]).  A proxy MUST send at least one Proxy-Authenticate
+   header field in each 407 (Proxy Authentication Required) response
+   that it generates.
+
+     Proxy-Authenticate = 1#challenge
+
+   Unlike WWW-Authenticate, the Proxy-Authenticate header field applies
+   only to the next outbound client on the response chain.  This is
+   because only the client that chose a given proxy is likely to have
+   the credentials necessary for authentication.  However, when multiple
+   proxies are used within the same administrative domain, such as
+   office and regional caching proxies within a large corporate network,
+   it is common for credentials to be generated by the user agent and
+   passed through the hierarchy until consumed.  Hence, in such a
+   configuration, it will appear as if Proxy-Authenticate is being
+   forwarded because each proxy will send the same challenge set.
+
+   Note that the parsing considerations for WWW-Authenticate apply to
+   this header field as well; see Section 4.1 for details.
+
+
+
+
+
+
+Fielding & Reschke           Standards Track                    [Page 8]
+
+RFC 7235                 HTTP/1.1 Authentication               June 2014
+
+
+4.4.  Proxy-Authorization
+
+   The "Proxy-Authorization" header field allows the client to identify
+   itself (or its user) to a proxy that requires authentication.  Its
+   value consists of credentials containing the authentication
+   information of the client for the proxy and/or realm of the resource
+   being requested.
+
+     Proxy-Authorization = credentials
+
+   Unlike Authorization, the Proxy-Authorization header field applies
+   only to the next inbound proxy that demanded authentication using the
+   Proxy-Authenticate field.  When multiple proxies are used in a chain,
+   the Proxy-Authorization header field is consumed by the first inbound
+   proxy that was expecting to receive credentials.  A proxy MAY relay
+   the credentials from the client request to the next proxy if that is
+   the mechanism by which the proxies cooperatively authenticate a given
+   request.
+
+5.  IANA Considerations
+
+5.1.  Authentication Scheme Registry
+
+   The "Hypertext Transfer Protocol (HTTP) Authentication Scheme
+   Registry" defines the namespace for the authentication schemes in
+   challenges and credentials.  It has been created and is now
+   maintained at <http://www.iana.org/assignments/http-authschemes>.
+
+5.1.1.  Procedure
+
+   Registrations MUST include the following fields:
+
+   o  Authentication Scheme Name
+
+   o  Pointer to specification text
+
+   o  Notes (optional)
+
+   Values to be added to this namespace require IETF Review (see
+   [RFC5226], Section 4.1).
+
+
+
+
+
+
+
+
+
+
+
+Fielding & Reschke           Standards Track                    [Page 9]
+
+RFC 7235                 HTTP/1.1 Authentication               June 2014
+
+
+5.1.2.  Considerations for New Authentication Schemes
+
+   There are certain aspects of the HTTP Authentication Framework that
+   put constraints on how new authentication schemes can work:
+
+   o  HTTP authentication is presumed to be stateless: all of the
+      information necessary to authenticate a request MUST be provided
+      in the request, rather than be dependent on the server remembering
+      prior requests.  Authentication based on, or bound to, the
+      underlying connection is outside the scope of this specification
+      and inherently flawed unless steps are taken to ensure that the
+      connection cannot be used by any party other than the
+      authenticated user (see Section 2.3 of [RFC7230]).
+
+   o  The authentication parameter "realm" is reserved for defining
+      protection spaces as described in Section 2.2.  New schemes MUST
+      NOT use it in a way incompatible with that definition.
+
+   o  The "token68" notation was introduced for compatibility with
+      existing authentication schemes and can only be used once per
+      challenge or credential.  Thus, new schemes ought to use the
+      auth-param syntax instead, because otherwise future extensions
+      will be impossible.
+
+   o  The parsing of challenges and credentials is defined by this
+      specification and cannot be modified by new authentication
+      schemes.  When the auth-param syntax is used, all parameters ought
+      to support both token and quoted-string syntax, and syntactical
+      constraints ought to be defined on the field value after parsing
+      (i.e., quoted-string processing).  This is necessary so that
+      recipients can use a generic parser that applies to all
+      authentication schemes.
+
+      Note: The fact that the value syntax for the "realm" parameter is
+      restricted to quoted-string was a bad design choice not to be
+      repeated for new parameters.
+
+   o  Definitions of new schemes ought to define the treatment of
+      unknown extension parameters.  In general, a "must-ignore" rule is
+      preferable to a "must-understand" rule, because otherwise it will
+      be hard to introduce new parameters in the presence of legacy
+      recipients.  Furthermore, it's good to describe the policy for
+      defining new parameters (such as "update the specification" or
+      "use this registry").
+
+   o  Authentication schemes need to document whether they are usable in
+      origin-server authentication (i.e., using WWW-Authenticate),
+      and/or proxy authentication (i.e., using Proxy-Authenticate).
+
+
+
+Fielding & Reschke           Standards Track                   [Page 10]
+
+RFC 7235                 HTTP/1.1 Authentication               June 2014
+
+
+   o  The credentials carried in an Authorization header field are
+      specific to the user agent and, therefore, have the same effect on
+      HTTP caches as the "private" Cache-Control response directive
+      (Section 5.2.2.6 of [RFC7234]), within the scope of the request in
+      which they appear.
+
+      Therefore, new authentication schemes that choose not to carry
+      credentials in the Authorization header field (e.g., using a newly
+      defined header field) will need to explicitly disallow caching, by
+      mandating the use of either Cache-Control request directives
+      (e.g., "no-store", Section 5.2.1.5 of [RFC7234]) or response
+      directives (e.g., "private").
+
+5.2.  Status Code Registration
+
+   The "Hypertext Transfer Protocol (HTTP) Status Code Registry" located
+   at <http://www.iana.org/assignments/http-status-codes> has been
+   updated with the registrations below:
+
+   +-------+-------------------------------+-------------+
+   | Value | Description                   | Reference   |
+   +-------+-------------------------------+-------------+
+   | 401   | Unauthorized                  | Section 3.1 |
+   | 407   | Proxy Authentication Required | Section 3.2 |
+   +-------+-------------------------------+-------------+
+
+5.3.  Header Field Registration
+
+   HTTP header fields are registered within the "Message Headers"
+   registry maintained at
+   <http://www.iana.org/assignments/message-headers/>.
+
+   This document defines the following HTTP header fields, so the
+   "Permanent Message Header Field Names" registry has been updated
+   accordingly (see [BCP90]).
+
+   +---------------------+----------+----------+-------------+
+   | Header Field Name   | Protocol | Status   | Reference   |
+   +---------------------+----------+----------+-------------+
+   | Authorization       | http     | standard | Section 4.2 |
+   | Proxy-Authenticate  | http     | standard | Section 4.3 |
+   | Proxy-Authorization | http     | standard | Section 4.4 |
+   | WWW-Authenticate    | http     | standard | Section 4.1 |
+   +---------------------+----------+----------+-------------+
+
+   The change controller is: "IETF (iesg@ietf.org) - Internet
+   Engineering Task Force".
+
+
+
+
+Fielding & Reschke           Standards Track                   [Page 11]
+
+RFC 7235                 HTTP/1.1 Authentication               June 2014
+
+
+6.  Security Considerations
+
+   This section is meant to inform developers, information providers,
+   and users of known security concerns specific to HTTP authentication.
+   More general security considerations are addressed in HTTP messaging
+   [RFC7230] and semantics [RFC7231].
+
+   Everything about the topic of HTTP authentication is a security
+   consideration, so the list of considerations below is not exhaustive.
+   Furthermore, it is limited to security considerations regarding the
+   authentication framework, in general, rather than discussing all of
+   the potential considerations for specific authentication schemes
+   (which ought to be documented in the specifications that define those
+   schemes).  Various organizations maintain topical information and
+   links to current research on Web application security (e.g.,
+   [OWASP]), including common pitfalls for implementing and using the
+   authentication schemes found in practice.
+
+6.1.  Confidentiality of Credentials
+
+   The HTTP authentication framework does not define a single mechanism
+   for maintaining the confidentiality of credentials; instead, each
+   authentication scheme defines how the credentials are encoded prior
+   to transmission.  While this provides flexibility for the development
+   of future authentication schemes, it is inadequate for the protection
+   of existing schemes that provide no confidentiality on their own, or
+   that do not sufficiently protect against replay attacks.
+   Furthermore, if the server expects credentials that are specific to
+   each individual user, the exchange of those credentials will have the
+   effect of identifying that user even if the content within
+   credentials remains confidential.
+
+   HTTP depends on the security properties of the underlying transport-
+   or session-level connection to provide confidential transmission of
+   header fields.  In other words, if a server limits access to
+   authenticated users using this framework, the server needs to ensure
+   that the connection is properly secured in accordance with the nature
+   of the authentication scheme used.  For example, services that depend
+   on individual user authentication often require a connection to be
+   secured with TLS ("Transport Layer Security", [RFC5246]) prior to
+   exchanging any credentials.
+
+6.2.  Authentication Credentials and Idle Clients
+
+   Existing HTTP clients and user agents typically retain authentication
+   information indefinitely.  HTTP does not provide a mechanism for the
+   origin server to direct clients to discard these cached credentials,
+   since the protocol has no awareness of how credentials are obtained
+
+
+
+Fielding & Reschke           Standards Track                   [Page 12]
+
+RFC 7235                 HTTP/1.1 Authentication               June 2014
+
+
+   or managed by the user agent.  The mechanisms for expiring or
+   revoking credentials can be specified as part of an authentication
+   scheme definition.
+
+   Circumstances under which credential caching can interfere with the
+   application's security model include but are not limited to:
+
+   o  Clients that have been idle for an extended period, following
+      which the server might wish to cause the client to re-prompt the
+      user for credentials.
+
+   o  Applications that include a session termination indication (such
+      as a "logout" or "commit" button on a page) after which the server
+      side of the application "knows" that there is no further reason
+      for the client to retain the credentials.
+
+   User agents that cache credentials are encouraged to provide a
+   readily accessible mechanism for discarding cached credentials under
+   user control.
+
+6.3.  Protection Spaces
+
+   Authentication schemes that solely rely on the "realm" mechanism for
+   establishing a protection space will expose credentials to all
+   resources on an origin server.  Clients that have successfully made
+   authenticated requests with a resource can use the same
+   authentication credentials for other resources on the same origin
+   server.  This makes it possible for a different resource to harvest
+   authentication credentials for other resources.
+
+   This is of particular concern when an origin server hosts resources
+   for multiple parties under the same canonical root URI (Section 2.2).
+   Possible mitigation strategies include restricting direct access to
+   authentication credentials (i.e., not making the content of the
+   Authorization request header field available), and separating
+   protection spaces by using a different host name (or port number) for
+   each party.
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+Fielding & Reschke           Standards Track                   [Page 13]
+
+RFC 7235                 HTTP/1.1 Authentication               June 2014
+
+
+7.  Acknowledgments
+
+   This specification takes over the definition of the HTTP
+   Authentication Framework, previously defined in RFC 2617.  We thank
+   John Franks, Phillip M. Hallam-Baker, Jeffery L. Hostetler, Scott D.
+   Lawrence, Paul J. Leach, Ari Luotonen, and Lawrence C. Stewart for
+   their work on that specification.  See Section 6 of [RFC2617] for
+   further acknowledgements.
+
+   See Section 10 of [RFC7230] for the Acknowledgments related to this
+   document revision.
+
+8.  References
+
+8.1.  Normative References
+
+   [RFC2119]  Bradner, S., "Key words for use in RFCs to Indicate
+              Requirement Levels", BCP 14, RFC 2119, March 1997.
+
+   [RFC5234]  Crocker, D., Ed. and P. Overell, "Augmented BNF for Syntax
+              Specifications: ABNF", STD 68, RFC 5234, January 2008.
+
+   [RFC7230]  Fielding, R., Ed. and J. Reschke, Ed., "Hypertext Transfer
+              Protocol (HTTP/1.1): Message Syntax and Routing",
+              RFC 7230, June 2014.
+
+   [RFC7231]  Fielding, R., Ed. and J. Reschke, Ed., "Hypertext Transfer
+              Protocol (HTTP/1.1): Semantics and Content", RFC 7231,
+              June 2014.
+
+   [RFC7234]  Fielding, R., Ed., Nottingham, M., Ed., and J. Reschke,
+              Ed., "Hypertext Transfer Protocol (HTTP/1.1): Caching",
+              RFC 7234, June 2014.
+
+8.2.  Informative References
+
+   [BCP90]    Klyne, G., Nottingham, M., and J. Mogul, "Registration
+              Procedures for Message Header Fields", BCP 90, RFC 3864,
+              September 2004.
+
+   [OWASP]    van der Stock, A., Ed., "A Guide to Building Secure Web
+              Applications and Web Services", The Open Web Application
+              Security Project (OWASP) 2.0.1, July 2005,
+              <https://www.owasp.org/>.
+
+   [RFC2616]  Fielding, R., Gettys, J., Mogul, J., Frystyk, H.,
+              Masinter, L., Leach, P., and T. Berners-Lee, "Hypertext
+              Transfer Protocol -- HTTP/1.1", RFC 2616, June 1999.
+
+
+
+Fielding & Reschke           Standards Track                   [Page 14]
+
+RFC 7235                 HTTP/1.1 Authentication               June 2014
+
+
+   [RFC2617]  Franks, J., Hallam-Baker, P., Hostetler, J., Lawrence, S.,
+              Leach, P., Luotonen, A., and L. Stewart, "HTTP
+              Authentication: Basic and Digest Access Authentication",
+              RFC 2617, June 1999.
+
+   [RFC3986]  Berners-Lee, T., Fielding, R., and L. Masinter, "Uniform
+              Resource Identifier (URI): Generic Syntax", STD 66,
+              RFC 3986, January 2005.
+
+   [RFC4648]  Josefsson, S., "The Base16, Base32, and Base64 Data
+              Encodings", RFC 4648, October 2006.
+
+   [RFC5226]  Narten, T. and H. Alvestrand, "Guidelines for Writing an
+              IANA Considerations Section in RFCs", BCP 26, RFC 5226,
+              May 2008.
+
+   [RFC5246]  Dierks, T. and E. Rescorla, "The Transport Layer Security
+              (TLS) Protocol Version 1.2", RFC 5246, August 2008.
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+Fielding & Reschke           Standards Track                   [Page 15]
+
+RFC 7235                 HTTP/1.1 Authentication               June 2014
+
+
+Appendix A.  Changes from RFCs 2616 and 2617
+
+   The framework for HTTP Authentication is now defined by this
+   document, rather than RFC 2617.
+
+   The "realm" parameter is no longer always required on challenges;
+   consequently, the ABNF allows challenges without any auth parameters.
+   (Section 2)
+
+   The "token68" alternative to auth-param lists has been added for
+   consistency with legacy authentication schemes such as "Basic".
+   (Section 2)
+
+   This specification introduces the Authentication Scheme Registry,
+   along with considerations for new authentication schemes.
+   (Section 5.1)
+
+Appendix B.  Imported ABNF
+
+   The following core rules are included by reference, as defined in
+   Appendix B.1 of [RFC5234]: ALPHA (letters), CR (carriage return),
+   CRLF (CR LF), CTL (controls), DIGIT (decimal 0-9), DQUOTE (double
+   quote), HEXDIG (hexadecimal 0-9/A-F/a-f), LF (line feed), OCTET (any
+   8-bit sequence of data), SP (space), and VCHAR (any visible US-ASCII
+   character).
+
+   The rules below are defined in [RFC7230]:
+
+     BWS           = <BWS, see [RFC7230], Section 3.2.3>
+     OWS           = <OWS, see [RFC7230], Section 3.2.3>
+     quoted-string = <quoted-string, see [RFC7230], Section 3.2.6>
+     token         = <token, see [RFC7230], Section 3.2.6>
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+Fielding & Reschke           Standards Track                   [Page 16]
+
+RFC 7235                 HTTP/1.1 Authentication               June 2014
+
+
+Appendix C.  Collected ABNF
+
+   In the collected ABNF below, list rules are expanded as per Section
+   1.2 of [RFC7230].
+
+   Authorization = credentials
+
+   BWS = <BWS, see [RFC7230], Section 3.2.3>
+
+   OWS = <OWS, see [RFC7230], Section 3.2.3>
+
+   Proxy-Authenticate = *( "," OWS ) challenge *( OWS "," [ OWS
+    challenge ] )
+   Proxy-Authorization = credentials
+
+   WWW-Authenticate = *( "," OWS ) challenge *( OWS "," [ OWS challenge
+    ] )
+
+   auth-param = token BWS "=" BWS ( token / quoted-string )
+   auth-scheme = token
+
+   challenge = auth-scheme [ 1*SP ( token68 / [ ( "," / auth-param ) *(
+    OWS "," [ OWS auth-param ] ) ] ) ]
+   credentials = auth-scheme [ 1*SP ( token68 / [ ( "," / auth-param )
+    *( OWS "," [ OWS auth-param ] ) ] ) ]
+
+   quoted-string = <quoted-string, see [RFC7230], Section 3.2.6>
+
+   token = <token, see [RFC7230], Section 3.2.6>
+   token68 = 1*( ALPHA / DIGIT / "-" / "." / "_" / "~" / "+" / "/" )
+    *"="
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+Fielding & Reschke           Standards Track                   [Page 17]
+
+RFC 7235                 HTTP/1.1 Authentication               June 2014
+
+
+Index
+
+   4
+      401 Unauthorized (status code)  6
+      407 Proxy Authentication Required (status code)  6
+
+   A
+      Authorization header field  8
+
+   C
+      Canonical Root URI  5
+
+   G
+      Grammar
+         auth-param  4
+         auth-scheme  4
+         Authorization  8
+         challenge  4
+         credentials  5
+         Proxy-Authenticate  8
+         Proxy-Authorization  9
+         token68  4
+         WWW-Authenticate  7
+
+   P
+      Protection Space  5
+      Proxy-Authenticate header field  8
+      Proxy-Authorization header field  9
+
+   R
+      Realm  5
+
+   W
+      WWW-Authenticate header field  7
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+Fielding & Reschke           Standards Track                   [Page 18]
+
+RFC 7235                 HTTP/1.1 Authentication               June 2014
+
+
+Authors' Addresses
+
+   Roy T. Fielding (editor)
+   Adobe Systems Incorporated
+   345 Park Ave
+   San Jose, CA  95110
+   USA
+
+   EMail: fielding@gbiv.com
+   URI:   http://roy.gbiv.com/
+
+
+   Julian F. Reschke (editor)
+   greenbytes GmbH
+   Hafenweg 16
+   Muenster, NW  48155
+   Germany
+
+   EMail: julian.reschke@greenbytes.de
+   URI:   http://greenbytes.de/tech/webdav/
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+Fielding & Reschke           Standards Track                   [Page 19]
+
@@ -0,0 +1,339 @@
+
+
+
+
+
+
+Internet Engineering Task Force (IETF)                        J. Reschke
+Request for Comments: 7238                                    greenbytes
+Category: Experimental                                         June 2014
+ISSN: 2070-1721
+
+
+  The Hypertext Transfer Protocol Status Code 308 (Permanent Redirect)
+
+Abstract
+
+   This document specifies the additional Hypertext Transfer Protocol
+   (HTTP) status code 308 (Permanent Redirect).
+
+Status of This Memo
+
+   This document is not an Internet Standards Track specification; it is
+   published for examination, experimental implementation, and
+   evaluation.
+
+   This document defines an Experimental Protocol for the Internet
+   community.  This document is a product of the Internet Engineering
+   Task Force (IETF).  It represents the consensus of the IETF
+   community.  It has received public review and has been approved for
+   publication by the Internet Engineering Steering Group (IESG).  Not
+   all documents approved by the IESG are a candidate for any level of
+   Internet Standard; see Section 2 of RFC 5741.
+
+   Information about the current status of this document, any errata,
+   and how to provide feedback on it may be obtained at
+   http://www.rfc-editor.org/info/rfc7238.
+
+Copyright Notice
+
+   Copyright (c) 2014 IETF Trust and the persons identified as the
+   document authors.  All rights reserved.
+
+   This document is subject to BCP 78 and the IETF Trust's Legal
+   Provisions Relating to IETF Documents
+   (http://trustee.ietf.org/license-info) in effect on the date of
+   publication of this document.  Please review these documents
+   carefully, as they describe your rights and restrictions with respect
+   to this document.  Code Components extracted from this document must
+   include Simplified BSD License text as described in Section 4.e of
+   the Trust Legal Provisions and are provided without warranty as
+   described in the Simplified BSD License.
+
+
+
+
+
+
+Reschke                       Experimental                      [Page 1]
+
+RFC 7238                  HTTP Status Code 308                 June 2014
+
+
+Table of Contents
+
+   1.  Introduction  . . . . . . . . . . . . . . . . . . . . . . . . . 2
+   2.  Notational Conventions  . . . . . . . . . . . . . . . . . . . . 2
+   3.  308 Permanent Redirect  . . . . . . . . . . . . . . . . . . . . 2
+   4.  Deployment Considerations . . . . . . . . . . . . . . . . . . . 3
+   5.  Security Considerations . . . . . . . . . . . . . . . . . . . . 4
+   6.  IANA Considerations . . . . . . . . . . . . . . . . . . . . . . 4
+   7.  Acknowledgements  . . . . . . . . . . . . . . . . . . . . . . . 5
+   8.  References  . . . . . . . . . . . . . . . . . . . . . . . . . . 5
+     8.1.  Normative References  . . . . . . . . . . . . . . . . . . . 5
+     8.2.  Informative References  . . . . . . . . . . . . . . . . . . 5
+
+1.  Introduction
+
+   HTTP defines a set of status codes for the purpose of redirecting a
+   request to a different URI ([RFC3986]).  The history of these status
+   codes is summarized in Section 6.4 of [RFC7231], which also
+   classifies the existing status codes into four categories.
+
+   The first of these categories contains the status codes 301 (Moved
+   Permanently), 302 (Found), and 307 (Temporary Redirect), which can be
+   classified as below:
+
+   +-------------------------------------------+-----------+-----------+
+   |                                           | Permanent | Temporary |
+   +-------------------------------------------+-----------+-----------+
+   | Allows changing the request method from   | 301       | 302       |
+   | POST to GET                               |           |           |
+   | Does not allow changing the request       | -         | 307       |
+   | method from POST to GET                   |           |           |
+   +-------------------------------------------+-----------+-----------+
+
+   Section 6.4.7 of [RFC7231] states that HTTP does not define a
+   permanent variant of status code 307; this specification adds the
+   status code 308, defining this missing variant (Section 3).
+
+2.  Notational Conventions
+
+   The key words "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT",
+   "SHOULD", "SHOULD NOT", "RECOMMENDED", "MAY", and "OPTIONAL" in this
+   document are to be interpreted as described in [RFC2119].
+
+3.  308 Permanent Redirect
+
+   The 308 (Permanent Redirect) status code indicates that the target
+   resource has been assigned a new permanent URI and any future
+   references to this resource ought to use one of the enclosed URIs.
+
+
+
+Reschke                       Experimental                      [Page 2]
+
+RFC 7238                  HTTP Status Code 308                 June 2014
+
+
+   Clients with link editing capabilities ought to automatically re-link
+   references to the effective request URI (Section 5.5 of [RFC7230]) to
+   one or more of the new references sent by the server, where possible.
+
+   The server SHOULD generate a Location header field ([RFC7231],
+   Section 7.1.2) in the response containing a preferred URI reference
+   for the new permanent URI.  The user agent MAY use the Location field
+   value for automatic redirection.  The server's response payload
+   usually contains a short hypertext note with a hyperlink to the new
+   URI(s).
+
+   A 308 response is cacheable by default; i.e., unless otherwise
+   indicated by the method definition or explicit cache controls (see
+   [RFC7234], Section 4.2.2).
+
+      Note: This status code is similar to 301 (Moved Permanently)
+      ([RFC7231], Section 6.4.2), except that it does not allow changing
+      the request method from POST to GET.
+
+4.  Deployment Considerations
+
+   Section 6 of [RFC7231] requires recipients to treat unknown 3xx
+   status codes the same way as status code 300 Multiple Choices
+   ([RFC7231], Section 6.4.1).  Thus, servers will not be able to rely
+   on automatic redirection happening similar to status codes 301, 302,
+   or 307.
+
+   Therefore, initial use of status code 308 will be restricted to cases
+   where the server has sufficient confidence in the client's
+   understanding the new code or when a fallback to the semantics of
+   status code 300 is not problematic.  Server implementers are advised
+   not to vary the status code based on characteristics of the request,
+   such as the User-Agent header field ("User-Agent Sniffing") -- doing
+   so usually results in code that is both hard to maintain and hard to
+   debug and would also require special attention to caching (i.e.,
+   setting a "Vary" response header field, as defined in Section 7.1.4
+   of [RFC7231]).
+
+   Note that many existing HTML-based user agents will emulate a refresh
+   when encountering an HTML <meta> refresh directive ([HTML]).  This
+   can be used as another fallback.  For example:
+
+   Client request:
+
+     GET / HTTP/1.1
+     Host: example.com
+
+
+
+
+
+Reschke                       Experimental                      [Page 3]
+
+RFC 7238                  HTTP Status Code 308                 June 2014
+
+
+   Server response:
+
+     HTTP/1.1 308 Permanent Redirect
+     Content-Type: text/html; charset=UTF-8
+     Location: http://example.com/new
+     Content-Length: 454
+
+     <!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
+                           "http://www.w3.org/TR/html4/strict.dtd">
+     <html>
+        <head>
+           <title>Permanent Redirect</title>
+           <meta http-equiv="refresh"
+                 content="0; url=http://example.com/new">
+        </head>
+        <body>
+           <p>
+              The document has been moved to
+              <a href="http://example.com/new"
+              >http://example.com/new</a>.
+           </p>
+        </body>
+     </html>
+
+5.  Security Considerations
+
+   All security considerations that apply to HTTP redirects apply to the
+   308 status code as well (see Section 9 of [RFC7231]).
+
+6.  IANA Considerations
+
+   The registration below has been added to the "Hypertext Transfer
+   Protocol (HTTP) Status Code Registry" (defined in Section 8.2 of
+   [RFC7231] and located at
+   <http://www.iana.org/assignments/http-status-codes>):
+
+   +-------+--------------------+---------------------------------+
+   | Value | Description        | Reference                       |
+   +-------+--------------------+---------------------------------+
+   | 308   | Permanent Redirect | Section 3 of this specification |
+   +-------+--------------------+---------------------------------+
+
+
+
+
+
+
+
+
+
+
+Reschke                       Experimental                      [Page 4]
+
+RFC 7238                  HTTP Status Code 308                 June 2014
+
+
+7.  Acknowledgements
+
+   The definition for the new status code 308 reuses text from the
+   HTTP/1.1 definitions of status codes 301 and 307.
+
+   Furthermore, thanks to Ben Campbell, Cyrus Daboo, Eran Hammer-Lahav,
+   Bjoern Hoehrmann, Subramanian Moonesamy, Peter Saint-Andre, and
+   Robert Sparks for feedback on this document.
+
+8.  References
+
+8.1.  Normative References
+
+   [RFC2119]  Bradner, S., "Key words for use in RFCs to Indicate
+              Requirement Levels", BCP 14, RFC 2119, March 1997.
+
+   [RFC3986]  Berners-Lee, T., Fielding, R., and L. Masinter, "Uniform
+              Resource Identifier (URI): Generic Syntax", STD 66,
+              RFC 3986, January 2005.
+
+   [RFC7230]  Fielding, R., Ed. and J. Reschke, Ed., "Hypertext Transfer
+              Protocol (HTTP/1.1): Message Syntax and Routing",
+              RFC 7230, June 2014.
+
+   [RFC7231]  Fielding, R., Ed. and J. Reschke, Ed., "Hypertext Transfer
+              Protocol (HTTP/1.1): Semantics and Content", RFC 7231,
+              June 2014.
+
+   [RFC7234]  Fielding, R., Ed., Nottingham, M., Ed., and J. Reschke,
+              Ed., "Hypertext Transfer Protocol (HTTP/1.1): Caching",
+              RFC 7234, June 2014.
+
+8.2.  Informative References
+
+   [HTML]     Raggett, D., Le Hors, A., and I. Jacobs, "HTML 4.01
+              Specification", W3C Recommendation REC-html401-19991224,
+              December 1999,
+              <http://www.w3.org/TR/1999/REC-html401-19991224>.
+
+              Latest version available at
+              <http://www.w3.org/TR/html401>.
+
+
+
+
+
+
+
+
+
+
+Reschke                       Experimental                      [Page 5]
+
+RFC 7238                  HTTP Status Code 308                 June 2014
+
+
+Author's Address
+
+   Julian F. Reschke
+   greenbytes GmbH
+   Hafenweg 16
+   Muenster, NW  48155
+   Germany
+
+   EMail: julian.reschke@greenbytes.de
+   URI:   http://greenbytes.de/tech/webdav/
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+Reschke                       Experimental                      [Page 6]
+
@@ -0,0 +1,899 @@
+
+
+
+
+
+
+Internet Engineering Task Force (IETF)                      A. Petersson
+Request for Comments: 7239                                    M. Nilsson
+Category: Standards Track                                 Opera Software
+ISSN: 2070-1721                                                June 2014
+
+
+                        Forwarded HTTP Extension
+
+Abstract
+
+   This document defines an HTTP extension header field that allows
+   proxy components to disclose information lost in the proxying
+   process, for example, the originating IP address of a request or IP
+   address of the proxy on the user-agent-facing interface.  In a path
+   of proxying components, this makes it possible to arrange it so that
+   each subsequent component will have access to, for example, all IP
+   addresses used in the chain of proxied HTTP requests.
+
+   This document also specifies guidelines for a proxy administrator to
+   anonymize the origin of a request.
+
+Status of This Memo
+
+   This is an Internet Standards Track document.
+
+   This document is a product of the Internet Engineering Task Force
+   (IETF).  It represents the consensus of the IETF community.  It has
+   received public review and has been approved for publication by the
+   Internet Engineering Steering Group (IESG).  Further information on
+   Internet Standards is available in Section 2 of RFC 5741.
+
+   Information about the current status of this document, any errata,
+   and how to provide feedback on it may be obtained at
+   http://www.rfc-editor.org/info/rfc7239.
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+Petersson & Nilsson          Standards Track                    [Page 1]
+
+RFC 7239                Forwarded HTTP Extension               June 2014
+
+
+Copyright Notice
+
+   Copyright (c) 2014 IETF Trust and the persons identified as the
+   document authors.  All rights reserved.
+
+   This document is subject to BCP 78 and the IETF Trust's Legal
+   Provisions Relating to IETF Documents
+   (http://trustee.ietf.org/license-info) in effect on the date of
+   publication of this document.  Please review these documents
+   carefully, as they describe your rights and restrictions with respect
+   to this document.  Code Components extracted from this document must
+   include Simplified BSD License text as described in Section 4.e of
+   the Trust Legal Provisions and are provided without warranty as
+   described in the Simplified BSD License.
+
+Table of Contents
+
+   1. Introduction ....................................................3
+   2. Notational Conventions ..........................................4
+   3. Syntax Notations ................................................4
+   4. Forwarded HTTP Header Field .....................................4
+   5. Parameters ......................................................6
+      5.1. Forwarded By ...............................................6
+      5.2. Forwarded For ..............................................6
+      5.3. Forwarded Host .............................................7
+      5.4. Forwarded Proto ............................................7
+      5.5. Extensions .................................................7
+   6. Node Identifiers ................................................8
+      6.1. IPv4 and IPv6 Identifiers ..................................9
+      6.2. The "unknown" Identifier ...................................9
+      6.3. Obfuscated Identifier ......................................9
+   7. Implementation Considerations ..................................10
+      7.1. HTTP Lists ................................................10
+      7.2. Header Field Preservation .................................10
+      7.3. Relation to Via ...........................................10
+      7.4. Transition ................................................11
+      7.5. Example Usage .............................................11
+   8. Security Considerations ........................................12
+      8.1. Header Validity and Integrity .............................12
+      8.2. Information Leak ..........................................12
+      8.3. Privacy Considerations ....................................12
+   9. IANA Considerations ............................................14
+   10. References ....................................................14
+      10.1. Normative References .....................................14
+      10.2. Informative References ...................................15
+   Appendix A. Acknowledgments .......................................16
+
+
+
+
+
+Petersson & Nilsson          Standards Track                    [Page 2]
+
+RFC 7239                Forwarded HTTP Extension               June 2014
+
+
+1.  Introduction
+
+   In today's HTTP landscape, there are a multitude of different
+   applications that act as proxies for the user agents.  In many cases,
+   these proxies exists without the action or knowledge of the end-user.
+   These cases occur, for example, when the proxy exists as a part of
+   the infrastructure within the organization running the web server.
+   Such proxies may be used for features such as load balancing or
+   crypto offload.  Another example is when the proxy is used within the
+   same organization as the user, and the proxy is used to cache
+   resources.  However, these proxies make the requests appear as if
+   they originated from the proxy's IP address, and they may change
+   other information in the original request.  This represents a loss of
+   information from the original request.
+
+   This loss of information can cause problems for a web server that has
+   a specific use for the clients' IP addresses that will not be met by
+   using the address of the proxy or other information changed by the
+   proxy.  The main uses of this information are for diagnostics, access
+   control, and abuse management.  Diagnostic functions can include
+   event logging, troubleshooting, and statistics gathering, and the
+   information collected is usually only stored for short periods of
+   time and only gathered in response to a particular problem or a
+   complaint from the client.  Access control can be operated by
+   configuring a list of client IP addresses from which access is
+   permitted, but this approach will not work if a proxy is used, unless
+   the proxy is trusted and is, itself, configured with a list of
+   allowed client addresses for the server.  Cases of abuse require
+   identification of the abuser and this uses many of the same features
+   identified for diagnostics.
+
+   Most of the time that a proxy is used, this loss of information is
+   not the primary purpose, or even a desired effect, of using the
+   proxy.  Thus, to restore the desired functionality when a proxy is in
+   use, a way of disclosing the original information at the HTTP level
+   is needed.  Clearly, however, when the purpose of using a proxy is to
+   provide client anonymity, the proxy will not use the feature defined
+   in this document.
+
+   It should be noted that the use of a reverse proxy also hides
+   information.  Again, where the loss of information is not a
+   deliberate function of the use of the reverse proxy, it can be
+   desirable to find a way to encode the information within the HTTP
+   messages so that the consumer can see it.
+
+   A common way to disclose this information is by using the non-
+   standard header fields such as X-Forwarded-For, X-Forwarded-By, and
+   X-Forwarded-Proto.  There are many benefits to using a standardized
+
+
+
+Petersson & Nilsson          Standards Track                    [Page 3]
+
+RFC 7239                Forwarded HTTP Extension               June 2014
+
+
+   approach to commonly desired protocol function: not least is
+   interoperability between implementations.  This document standardizes
+   a header field called "Forwarded" and provides the syntax and
+   semantics for disclosing such information.  "Forwarded" also combines
+   all the information within one single header field, making it
+   possible to correlate that information.  With the header field format
+   described in this document, it is possible to know what information
+   belongs together, as long as the proxies are trusted.  Such
+   conclusions are not possible to make with the X-Forwarded class of
+   header fields.  The header field defined in this document is optional
+   such that implementations of proxies that are intended to provide
+   privacy are not required to operate or implement the header field.
+
+   Note that similar issues to those described for proxies also arise
+   with use of NATs.  This is discussed further in [RFC6269].
+
+2.  Notational Conventions
+
+   The key words "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT",
+   "SHOULD", "SHOULD NOT", "RECOMMENDED", "MAY", and "OPTIONAL" in this
+   document are to be interpreted as described in [RFC2119].
+
+3.  Syntax Notations
+
+   This specification uses the Augmented Backus-Naur Form (ABNF)
+   notation of [RFC5234] with the list rule extension defined in Section
+   7 of [RFC7230].
+
+4.  Forwarded HTTP Header Field
+
+   The "Forwarded" HTTP header field is an OPTIONAL header field that,
+   when used, contains a list of parameter-identifier pairs that
+   disclose information that is altered or lost when a proxy is involved
+   in the path of the request.  Due to the sensitive nature of the data
+   passed in this header field (see Sections 8.2 and 8.3), this header
+   field should be turned off by default.  Further, each parameter
+   should be configured individually.  "Forwarded" is only for use in
+   HTTP requests and is not to be used in HTTP responses.  This applies
+   to forwarding proxies, as well as reverse proxies.  Information
+   passed in this header field can be, for example, the source IP
+   address of the request, the IP address of the incoming interface on
+   the proxy, or whether HTTP or HTTPS was used.  If the request is
+   passing through several proxies, each proxy can add a set of
+   parameters; it can also remove previously added "Forwarded" header
+   fields.
+
+
+
+
+
+
+Petersson & Nilsson          Standards Track                    [Page 4]
+
+RFC 7239                Forwarded HTTP Extension               June 2014
+
+
+   The top-level list is represented as a list of HTTP header
+   field-values as defined in Section 3.2 of [RFC7230].  The first
+   element in this list holds information added by the first proxy that
+   implements and uses this header field, and each subsequent element
+   holds information added by each subsequent proxy.  Because this
+   header field is optional, any proxy in the chain may choose not to
+   update this header field.  Each field-value is a semicolon-separated
+   list; this sublist consists of parameter-identifier pairs.
+   Parameter-identifier pairs are grouped together by an equals sign.
+   Each parameter MUST NOT occur more than once per field-value.  The
+   parameter names are case-insensitive.  The header field value can be
+   defined in ABNF syntax as:
+
+       Forwarded   = 1#forwarded-element
+
+       forwarded-element =
+           [ forwarded-pair ] *( ";" [ forwarded-pair ] )
+
+       forwarded-pair = token "=" value
+       value          = token / quoted-string
+
+       token = <Defined in [RFC7230], Section 3.2.6>
+       quoted-string = <Defined in [RFC7230], Section 3.2.6>
+
+   Examples:
+
+       Forwarded: for="_gazonk"
+       Forwarded: For="[2001:db8:cafe::17]:4711"
+       Forwarded: for=192.0.2.60;proto=http;by=203.0.113.43
+       Forwarded: for=192.0.2.43, for=198.51.100.17
+
+   Note that as ":" and "[]" are not valid characters in "token", IPv6
+   addresses are written as "quoted-string".
+
+   A proxy server that wants to add a new "Forwarded" header field value
+   can either append it to the last existing "Forwarded" header field
+   after a comma separator or add a new field at the end of the header
+   block.  A proxy MAY remove all "Forwarded" header fields from a
+   request.  It MUST, however, ensure that the correct header field is
+   updated in case of multiple "Forwarded" header fields.
+
+
+
+
+
+
+
+
+
+
+
+Petersson & Nilsson          Standards Track                    [Page 5]
+
+RFC 7239                Forwarded HTTP Extension               June 2014
+
+
+5.  Parameters
+
+   This document specifies a number of parameters and valid values for
+   each of them:
+
+   o  "by" identifies the user-agent facing interface of the proxy.
+
+   o  "for" identifies the node making the request to the proxy.
+
+   o  "host" is the host request header field as received by the proxy.
+
+   o  "proto" indicates what protocol was used to make the request.
+
+5.1.  Forwarded By
+
+   The "by" parameter is used to disclose the interface where the
+   request came in to the proxy server.  When proxies choose to use the
+   "by" parameter, its default configuration SHOULD contain an
+   obfuscated identifier as described in Section 6.3.  If the server
+   receiving proxied requests requires some address-based functionality,
+   this parameter MAY instead contain an IP address (and, potentially, a
+   port number).  A third option is the "unknown" identifier described
+   in Section 6.2.
+
+   The syntax of a "by" value, after potential quoted-string unescaping,
+   conforms to the "node" ABNF described in Section 6.
+
+   This is primarily added by reverse proxies that wish to forward this
+   information to the backend server.  It can also be interesting in a
+   multihomed environment to signal to backend servers from which the
+   request came.
+
+5.2.  Forwarded For
+
+   The "for" parameter is used to disclose information about the client
+   that initiated the request and subsequent proxies in a chain of
+   proxies.  When proxies choose to use the "for" parameter, its default
+   configuration SHOULD contain an obfuscated identifier as described in
+   Section 6.3.  If the server receiving proxied requests requires some
+   address-based functionality, this parameter MAY instead contain an IP
+   address (and, potentially, a port number).  A third option is the
+   "unknown" identifier described in Section 6.2.
+
+   The syntax of a "for" value, after potential quoted-string
+   unescaping, conforms to the "node" ABNF described in Section 6.
+
+
+
+
+
+
+Petersson & Nilsson          Standards Track                    [Page 6]
+
+RFC 7239                Forwarded HTTP Extension               June 2014
+
+
+   In a chain of proxy servers where this is fully utilized, the first
+   "for" parameter will disclose the client where the request was first
+   made, followed by any subsequent proxy identifiers.  The last proxy
+   in the chain is not part of the list of "for" parameters.  The last
+   proxy's IP address, and optionally a port number, are, however,
+   readily available as the remote IP address at the transport layer.
+   It can, however, be more relevant to read information about the last
+   proxy from preceding "Forwarded" header field's "by" parameter, if
+   present.
+
+5.3.  Forwarded Host
+
+   The "host" parameter is used to forward the original value of the
+   "Host" header field.  This can be used, for example, by the origin
+   server if a reverse proxy is rewriting the "Host" header field to
+   some internal host name.
+
+   The syntax for a "host" value, after potential quoted-string
+   unescaping, MUST conform to the Host ABNF described in Section 5.4 of
+   [RFC7230].
+
+5.4.  Forwarded Proto
+
+   The "proto" parameter has the value of the used protocol type.  The
+   syntax of a "proto" value, after potential quoted-string unescaping,
+   MUST conform to the URI scheme name as defined in Section 3.1 in
+   [RFC3986] and registered with IANA according to [RFC4395].  Typical
+   values are "http" or "https".
+
+   For example, in an environment where a reverse proxy is also used as
+   a crypto offloader, this allows the origin server to rewrite URLs in
+   a document to match the type of connection as the user agent
+   requested, even though all connections to the origin server are
+   unencrypted HTTP.
+
+5.5.  Extensions
+
+   Extensions allow for additional parameters and values.  Extensions
+   can be particularly useful in reverse proxy environments.  All
+   extension parameters SHOULD be registered in the "HTTP Forwarded
+   Parameter" registry.  If certain extensions are expected to have
+   widespread deployment, they SHOULD also be standardized.  This is
+   further discussed in Section 9.
+
+
+
+
+
+
+
+
+Petersson & Nilsson          Standards Track                    [Page 7]
+
+RFC 7239                Forwarded HTTP Extension               June 2014
+
+
+6.  Node Identifiers
+
+   The node identifier is one of the following:
+
+   o  The client's IP address, with an optional port number
+
+   o  A token indicating that the IP address of the client is not known
+      to the proxy server
+
+   o  A generated token, allowing for tracing and debugging, while
+      allowing the internal structure or sensitive information to be
+      hidden
+
+   The node identifier is defined by the ABNF syntax as:
+
+       node     = nodename [ ":" node-port ]
+       nodename = IPv4address / "[" IPv6address "]" /
+                   "unknown" / obfnode
+
+       IPv4address = <Defined in [RFC3986], Section 3.2.2>
+       IPv6address = <Defined in [RFC3986], Section 3.2.2>
+       obfnode = "_" 1*( ALPHA / DIGIT / "." / "_" / "-")
+
+       node-port     = port / obfport
+       port          = 1*5DIGIT
+       obfport       = "_" 1*(ALPHA / DIGIT / "." / "_" / "-")
+
+       DIGIT = <Defined in [RFC5234], Section 3.4>
+       ALPHA = <Defined in [RFC5234], Section B.1>
+
+   Each of the identifiers may optionally have the port identifier, for
+   example, allowing the identification of the endpoint in a NATed
+   environment.  The "node-port" can be identified either by its port
+   number or by a generated token obfuscating the real port number.  An
+   obfuscated port may be used in situations where the possessor of the
+   proxy wants the ability to trace requests -- for example, in debug
+   purposes -- but does not want to reveal internal information.
+
+   Note that the ABNF above also allows port numbers to be appended to
+   the "unknown" identifier.  Interpretation of such notation is,
+   however, left to the possessor of a proxy adding such a value to the
+   header field.  To distinguish an "obfport" from a port, the "obfport"
+   MUST have a leading underscore.  Further, it MUST also consist of
+   only "ALPHA", "DIGIT", and the characters ".", "_", and "-".
+
+   It is important to note that an IPv6 address and any nodename with
+   node-port specified MUST be quoted, since ":" is not an allowed
+   character in "token".
+
+
+
+Petersson & Nilsson          Standards Track                    [Page 8]
+
+RFC 7239                Forwarded HTTP Extension               June 2014
+
+
+   Examples:
+
+             "192.0.2.43:47011"
+             "[2001:db8:cafe::17]:47011"
+
+6.1.  IPv4 and IPv6 Identifiers
+
+   The ABNF rules for "IPv6address" and "IPv4address" are defined in
+   [RFC3986].  The "IPv6address" SHOULD comply with textual
+   representation recommendations [RFC5952] (for example, lowercase,
+   compression of zeros).
+
+   Note that the IP address may be one from the internal nets, as
+   defined in [RFC1918] and [RFC4193].  Also, note that an IPv6 address
+   is always enclosed in square brackets.
+
+6.2.  The "unknown" Identifier
+
+   The "unknown" identifier is used when the identity of the preceding
+   entity is not known, but the proxy server still wants to signal that
+   a forwarding of the request was made.  One example would be a proxy
+   server process generating an outgoing request without direct access
+   to the incoming request TCP socket.
+
+6.3.  Obfuscated Identifier
+
+   A generated identifier may be used where there is a wish to keep the
+   internal IP addresses secret, while still allowing the "Forwarded"
+   header field to be used for tracing and debugging.  This can also be
+   useful if the proxy uses some sort of interface labels and there is a
+   desire to pass them rather than an IP address.  Unless static
+   assignment of identifiers is necessary for the server's use of the
+   identifiers, obfuscated identifiers SHOULD be randomly generated for
+   each request.  If the server requires that identifiers persist across
+   requests, they SHOULD NOT persist longer than client IP addresses.
+   To distinguish the obfuscated identifier from other identifiers, it
+   MUST have a leading underscore "_".  Furthermore, it MUST also
+   consist of only "ALPHA", "DIGIT", and the characters ".", "_", and
+   "-".
+   Example:
+
+       Forwarded: for=_hidden, for=_SEVKISEK
+
+
+
+
+
+
+
+
+
+Petersson & Nilsson          Standards Track                    [Page 9]
+
+RFC 7239                Forwarded HTTP Extension               June 2014
+
+
+7.  Implementation Considerations
+
+7.1.  HTTP Lists
+
+   Note that an HTTP list allows white spaces to occur between the
+   identifiers, and the list may be split over multiple header fields.
+   As an example, the header field
+
+       Forwarded: for=192.0.2.43,for="[2001:db8:cafe::17]",for=unknown
+
+   is equivalent to the header field
+
+       Forwarded: for=192.0.2.43, for="[2001:db8:cafe::17]", for=unknown
+
+   which is equivalent to the header fields
+
+       Forwarded: for=192.0.2.43
+       Forwarded: for="[2001:db8:cafe::17]", for=unknown
+
+7.2.  Header Field Preservation
+
+   There are some cases when this header field should be kept and some
+   cases where it should not be kept.  A directly forwarded request
+   should preserve and possibly extend it.  If a single incoming request
+   causes the proxy to make multiple outbound requests, special care
+   must be taken to decide whether or not the header field should be
+   preserved.  In many cases, the header field should be preserved, but
+   if the outbound request is not a direct consequence of the incoming
+   request, the header field should not be preserved.  Consider also the
+   case when a proxy has detected a content mismatch in a 304 response
+   and is following the instructions in [RFC7232], Section 4.1 to repeat
+   the request unconditionally, in which case the new request is still
+   basically a direct consequence of the origin request, and the header
+   field should probably be kept.
+
+7.3.  Relation to Via
+
+   The "Via" header field (see [RFC7230], Section 5.7.1) is a header
+   field with a similar use case as this header field.  The "Via" header
+   field, however, only provides information about the proxy itself, and
+   thereby leaves out the information about the client connecting to the
+   proxy server.  The "Forwarded" header field, on the other hand, has
+   relaying information from the client-facing side of the proxy server
+   as its main purpose.  As "Via" is already widely deployed, its format
+   cannot be changed to address the problems that "Forwarded" addresses.
+
+
+
+
+
+
+Petersson & Nilsson          Standards Track                   [Page 10]
+
+RFC 7239                Forwarded HTTP Extension               June 2014
+
+
+   Note that it is not possible to combine information from this header
+   field with the information from the Via header field.  Some proxies
+   will not update the "Forwarded" header field, some proxies will not
+   update the Via header field, and some proxies will update both.
+
+7.4.  Transition
+
+   If a proxy gets incoming requests with X-Forwarded-* header fields
+   present, it is encouraged to convert these into the header field
+   described in this document, if it can be done in a sensible way.  If
+   the request only contains one type -- for example, X-Forwarded-For --
+   this can be translated to "Forwarded", by prepending each element
+   with "for=".  Note that IPv6 addresses may not be quoted in
+   X-Forwarded-For and may not be enclosed by square brackets, but they
+   are quoted and enclosed in square brackets in "Forwarded".
+
+       X-Forwarded-For: 192.0.2.43, 2001:db8:cafe::17
+
+   becomes:
+
+       Forwarded: for=192.0.2.43, for="[2001:db8:cafe::17]"
+
+   However, special care must be taken if, for example, both
+   X-Forwarded-For and X-Forwarded-By exist.  In such cases, it may not
+   be possible to do a conversion, since it is not possible to know in
+   which order the already existing fields were added.  Also, note that
+   removing the X-Forwarded-For header field may cause issues for
+   parties that have not yet implemented support for this new header
+   field.
+
+7.5.  Example Usage
+
+   A request from a client with IP address 192.0.2.43 passes through a
+   proxy with IP address 198.51.100.17, then through another proxy with
+   IP address 203.0.113.60 before reaching an origin server.  This
+   could, for example, be an office client behind a corporate malware
+   filter talking to a origin server through a reverse proxy.
+
+   o  The HTTP request between the client and the first proxy has no
+      "Forwarded" header field.
+
+   o  The HTTP request between the first and second proxy has a
+      "Forwarded: for=192.0.2.43" header field.
+
+   o  The HTTP request between the second proxy and the origin server
+      has a "Forwarded: for=192.0.2.43,
+      for=198.51.100.17;by=203.0.113.60;proto=http;host=example.com"
+      header field.
+
+
+
+Petersson & Nilsson          Standards Track                   [Page 11]
+
+RFC 7239                Forwarded HTTP Extension               June 2014
+
+
+   Note that, at some points in a connection chain, the information
+   might not be updated in the "Forwarded" header field, either because
+   of lack of support of this HTTP extension or because of a policy
+   decision not to disclose information about this network component.
+
+8.  Security Considerations
+
+8.1.  Header Validity and Integrity
+
+   The "Forwarded" HTTP header field cannot be relied upon to be
+   correct, as it may be modified, whether mistakenly or for malicious
+   reasons, by every node on the way to the server, including the client
+   making the request.
+
+   One approach to ensure that the "Forwarded" HTTP header field is
+   correct is to verify the correctness of proxies and to whitelist them
+   as trusted.  This approach has at least two weaknesses.  First, the
+   chain of IP addresses listed before the request came to the proxy
+   cannot be trusted.  Second, unless the communication between proxies
+   and the endpoint is secured, the data can be modified by an attacker
+   with access to the network.
+
+8.2.  Information Leak
+
+   The "Forwarded" HTTP header field can reveal internal structures of
+   the network setup behind the NAT or proxy setup, which may be
+   undesired.  This can be addressed either by using obfuscated
+   elements, by preventing the internal nodes from updating the HTTP
+   header field, or by having an egress proxy remove entries that reveal
+   internal network information.
+
+   This header field should never be copied into response messages by
+   origin servers or intermediaries, as it can reveal the whole proxy
+   chain to the client.  As a side effect, special care must be taken in
+   hosting environments not to allow the TRACE request where the
+   "Forwarded" field is used, as it would appear in the body of the
+   response message.
+
+8.3.  Privacy Considerations
+
+   In recent years, there have been growing concerns about privacy.
+   There is a trade-off between ensuring privacy for users versus
+   disclosing information that is useful, for example, for debugging,
+   statistics, and generating location-dependent content.  The
+   "Forwarded" HTTP header field, by design, exposes information that
+   some users consider privacy sensitive, in order to allow for such
+   uses.  For any proxy, if the HTTP request contains header fields that
+
+
+
+
+Petersson & Nilsson          Standards Track                   [Page 12]
+
+RFC 7239                Forwarded HTTP Extension               June 2014
+
+
+   specifically request privacy semantics, the proxy SHOULD NOT use the
+   "Forwarded" header field, nor in any other manner pass private
+   information, such as IP addresses, on to the next hop.
+
+   The client's IP address, that may be forwarded in the "for" parameter
+   of this header field, is considered to be privacy sensitive by many
+   people, as the IP address may be able to uniquely identify a client,
+   what operator the user is using, and possibly a rough estimation of
+   where the user is geographically located.
+
+   Proxies using this extension will preserve the information of a
+   direct connection.  This has an end-user privacy impact regardless of
+   whether the end-user or deployer knows or expects that this is the
+   case.
+
+   Implementers and deployers of such proxies need to consider whether,
+   and how, deploying this extension affects user privacy.
+
+   The default configuration for both the "by" and "for" parameters
+   SHOULD contain obfuscated identifiers.  These identifiers SHOULD be
+   randomly generated per request.  If identifiers that persist across
+   requests are required, their lifetimes SHOULD be limited and they
+   SHOULD NOT persist longer than client IP addresses.  When generating
+   obfuscated identifiers, care must be taken not to include potentially
+   sensitive information in them.
+
+   Note that users' IP addresses may already be forwarded by proxies
+   using the header field X-Forwarded-For, which is widely used.  It
+   should also be noted that if the user were doing the connection
+   directly without passing the proxy, the client's IP address would be
+   sent to the web server.  Users that do not actively choose an
+   anonymizing proxy cannot rely on having their IP address shielded.
+   These users who want to minimize the risk of being tracked must also
+   note that there are other ways information may leak, for example, by
+   browser header field fingerprinting.  The Forwarded header field
+   itself, even when used without a uniquely identifying client
+   identifier, may make fingerprinting more feasible by revealing the
+   chain of proxies traversed by the client's request.
+
+
+
+
+
+
+
+
+
+
+
+
+
+Petersson & Nilsson          Standards Track                   [Page 13]
+
+RFC 7239                Forwarded HTTP Extension               June 2014
+
+
+9.  IANA Considerations
+
+   This document specifies the HTTP header field listed below, which has
+   been added to the "Permanent Message Header Field Names" registry
+   defined in [RFC3864].
+
+   Header field: Forwarded
+   Applicable protocol: http
+   Status: standard
+   Author/Change controller:
+       IETF (iesg@ietf.org)
+       Internet Engineering Task Force
+   Specification document(s): this specification (Section 4)
+   Related information: None
+
+   The "Forwarded" header field contains parameters for which IANA has
+   created and now maintains a new registry entitled "HTTP Forwarded
+   Parameters".  Initial registrations are given below.  For future
+   assignments, the registration procedure is IETF Review [RFC5226].
+   The security and privacy implications of all new parameters should be
+   thoroughly documented.  New parameters and their values MUST conform
+   with the forwarded-pair as defined in ABNF in Section 4.  Further, a
+   short description should be provided in the registration.
+
+   +-------------+---------------------------------------+-------------+
+   | Parameter   | Description                           | Reference   |
+   | name        |                                       |             |
+   +-------------+---------------------------------------+-------------+
+   | by          | IP address of incoming interface of a | Section 5.1 |
+   |             | proxy                                 |             |
+   | for         | IP address of client making a request | Section 5.2 |
+   |             | through a proxy                       |             |
+   | host        | Host header field of the incoming     | Section 5.3 |
+   |             | request                               |             |
+   | proto       | Application protocol used for         | Section 5.4 |
+   |             | incoming request                      |             |
+   +-------------+---------------------------------------+-------------+
+
+                       Table 1: Initial Assignments
+
+10.  References
+
+10.1.  Normative References
+
+   [RFC1918]  Rekhter, Y., Moskowitz, R., Karrenberg, D., Groot, G., and
+              E. Lear, "Address Allocation for Private Internets",
+              BCP 5, RFC 1918, February 1996.
+
+
+
+
+Petersson & Nilsson          Standards Track                   [Page 14]
+
+RFC 7239                Forwarded HTTP Extension               June 2014
+
+
+   [RFC2119]  Bradner, S., "Key words for use in RFCs to Indicate
+              Requirement Levels", BCP 14, RFC 2119, March 1997.
+
+   [RFC3864]  Klyne, G., Nottingham, M., and J. Mogul, "Registration
+              Procedures for Message Header Fields", BCP 90, RFC 3864,
+              September 2004.
+
+   [RFC3986]  Berners-Lee, T., Fielding, R., and L. Masinter, "Uniform
+              Resource Identifier (URI): Generic Syntax", STD 66,
+              RFC 3986, January 2005.
+
+   [RFC4193]  Hinden, R. and B. Haberman, "Unique Local IPv6 Unicast
+              Addresses", RFC 4193, October 2005.
+
+   [RFC4395]  Hansen, T., Hardie, T., and L. Masinter, "Guidelines and
+              Registration Procedures for New URI Schemes", BCP 35,
+              RFC 4395, February 2006.
+
+   [RFC5226]  Narten, T. and H. Alvestrand, "Guidelines for Writing an
+              IANA Considerations Section in RFCs", BCP 26, RFC 5226,
+              May 2008.
+
+   [RFC5234]  Crocker, D. and P. Overell, "Augmented BNF for Syntax
+              Specifications: ABNF", STD 68, RFC 5234, January 2008.
+
+   [RFC5952]  Kawamura, S. and M. Kawashima, "A Recommendation for IPv6
+              Address Text Representation", RFC 5952, August 2010.
+
+   [RFC7230]  Fielding, R., Ed. and J. Reschke, Ed., "Hypertext Transfer
+              Protocol (HTTP/1.1): Message Syntax and Routing",
+              RFC 7230, June 2014.
+
+   [RFC7232]  Fielding, R., Ed. and J. Reschke, Ed., "Hypertext Transfer
+              Protocol (HTTP/1.1): Conditional Requests", RFC 7232,
+              June 2014.
+
+10.2.  Informative References
+
+   [RFC6269]  Ford, M., Boucadair, M., Durand, A., Levis, P., and P.
+              Roberts, "Issues with IP Address Sharing", RFC 6269,
+              June 2011.
+
+
+
+
+
+
+
+
+
+
+Petersson & Nilsson          Standards Track                   [Page 15]
+
+RFC 7239                Forwarded HTTP Extension               June 2014
+
+
+Appendix A.  Acknowledgments
+
+   Thanks to Per Cederqvist, Alissa Cooper, Adrian Farrel, Stephen
+   Farrell, Ned Freed, Per Hedbor, Amos Jeffries, Poul-Henning Kamp,
+   Murray S. Kucherawy, Barry Leiba, Salvatore Loreto, Alexey Melnikov,
+   S. Moonesamy, Susan Nichols, Mark Nottingham, Julian Reschke, John
+   Sullivan, Willy Tarreau, and Dan Wing for their feedback.
+
+Authors' Addresses
+
+   Andreas Petersson
+   Opera Software
+
+   EMail: andreas@sbin.se
+
+
+   Martin Nilsson
+   Opera Software
+   S:t Larsgatan 12
+   Linkoping  SE-582 24
+
+   EMail: nilsson@opera.com
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+Petersson & Nilsson          Standards Track                   [Page 16]
+
@@ -34,7 +34,7 @@ LDADD = \
 	$(XTRA_LIBS)
 
 ## we need our local files too (but avoid -I. at all costs)
-INCLUDES += -I$(srcdir) -I$(top_srcdir)/lib
+AM_CPPFLAGS += -I$(srcdir) -I$(top_srcdir)/lib
 
 
 install-data-local: msntauth.conf.default
@@ -14,4 +14,4 @@ LDADD = \
 	$(XTRA_LIBS)
 
 ## we need our local files too (but avoid -I. at all costs)
-INCLUDES += -I$(srcdir)
+AM_CPPFLAGS += -I$(srcdir)
@@ -1,7 +1,7 @@
 include $(top_srcdir)/src/Common.am
 
 ## we need our local files too (but avoid -I. at all costs)
-INCLUDES += -I$(srcdir)
+AM_CPPFLAGS += -I$(srcdir)
 
 libexec_PROGRAMS = basic_nis_auth
 
@@ -1,7 +1,7 @@
 include $(top_srcdir)/src/Common.am
 
 ## we need our local files too (but avoid -I. at all costs)
-INCLUDES += -I$(srcdir)
+AM_CPPFLAGS += -I$(srcdir)
 
 libexec_PROGRAMS 	= basic_radius_auth
 man_MANS 		= basic_radius_auth.8
@@ -1,7 +1,7 @@
 include $(top_srcdir)/src/Common.am
 
 ## we need our local files too (but avoid -I. at all costs)
-INCLUDES += -I$(srcdir)
+AM_CPPFLAGS += -I$(srcdir)
 
 if ENABLE_WIN32SPECIFIC
 libexec_PROGRAMS = basic_sspi_auth
@@ -46,4 +46,7 @@
 /* send ERR result to Squid with a string parameter. */
 #define SEND_BH(x)	fprintf(stdout, "BH %s\n",x)
 
+/* send TT result to Squid with a string parameter. */
+#define SEND_TT(x)	fprintf(stdout, "TT %s\n",x)
+
 #endif /* __SQUID_HELPERS_DEFINES_H */
@@ -1,7 +1,7 @@
 include $(top_srcdir)/src/Common.am
 
 ## we need our local files too (but avoid -I. at all costs)
-INCLUDES += -I$(srcdir)
+AM_CPPFLAGS += -I$(srcdir)
 
 libexec_PROGRAMS = digest_ldap_auth
 digest_ldap_auth_SOURCES = digest_pw_auth.cc \
@@ -1,8 +1,7 @@
 include $(top_srcdir)/src/Common.am
 
 ## we need our local files too (but avoid -I. at all costs)
-INCLUDES += -I$(srcdir)
-
+AM_CPPFLAGS += -I$(srcdir)
 
 libexec_PROGRAMS = digest_edirectory_auth
 digest_edirectory_auth_SOURCES = digest_pw_auth.cc \
@@ -1,7 +1,7 @@
 include $(top_srcdir)/src/Common.am
 
 ## we need our local files too (but avoid -I. at all costs)
-INCLUDES += -I$(srcdir)
+AM_CPPFLAGS += -I$(srcdir)
 
 man_MANS = digest_file_auth.8
 libexec_PROGRAMS = digest_file_auth
@@ -4,6 +4,7 @@ libexec_PROGRAMS = ext_lm_group_acl
 ext_lm_group_acl_SOURCES = ext_lm_group_acl.cc
 
 LDADD = \
+	$(top_builddir)/lib/libmiscencoding.la \
 	$(COMPAT_LIB) \
 	-lnetapi32 \
 	-ladvapi32 \
@@ -90,7 +90,7 @@ int _wcsicmp(const wchar_t *, const wchar_t *);
 
 int use_global = 0;
 int use_PDC_only = 0;
-char *program_name;
+const char *program_name;
 pid_t mypid;
 char *machinedomain;
 int use_case_insensitive_compare = 0;
@@ -534,12 +534,15 @@ main(int argc, char *argv[])
     }
     debug("External ACL win32 group helper build " __DATE__ ", " __TIME__
           " starting up...\n");
-    if (use_global)
+    if (use_global) {
         debug("Domain Global group mode enabled using '%s' as default domain.\n", DefaultDomain);
-    if (use_case_insensitive_compare)
+    }
+    if (use_case_insensitive_compare) {
         debug("Warning: running in case insensitive mode !!!\n");
-    if (use_PDC_only)
+    }
+    if (use_PDC_only) {
         debug("Warning: using only PDCs for group validation !!!\n");
+    }
 
     /* Main Loop */
     while (fgets(buf, HELPER_INPUT_BUFFER, stdin)) {
@@ -3,7 +3,7 @@ include $(top_srcdir)/src/Common.am
 EXTRA_DIST = README required.m4 cert_tool ext_kerberos_ldap_group_acl.8
 SUBDIRS = 
 
-AM_CPPFLAGS = $(INCLUDES) -I$(srcdir)
+AM_CPPFLAGS += -I$(srcdir)
 
 libexec_SCRIPTS = cert_tool
 
@@ -28,9 +28,7 @@
 #ifdef HAVE_LDAP
 
 #include "support.h"
-#ifdef HAVE_ERRNO_H
-#include <errno.h>
-#endif
+#include <cerrno>
 
 char *convert_domain_to_bind_path(char *domain);
 char *escape_filter(char *filter);
@@ -28,9 +28,7 @@
 #ifdef HAVE_LDAP
 
 #include "support.h"
-#ifdef HAVE_ERRNO_H
-#include <errno.h>
-#endif
+#include <cerrno>
 #ifdef HAVE_NETDB_H
 #include <netdb.h>
 #endif
@@ -6,6 +6,7 @@ negotiate_sspi_auth_SOURCES = negotiate_sspi_auth.cc
 
 LDADD	= \
 	-L$(top_builddir)/lib -lsspwin32 \
+	$(top_builddir)/lib/libmiscencoding.la \
 	$(COMPAT_LIB) \
 	-ladvapi32 \
 	$(XTRA_LIBS)
@@ -37,8 +37,10 @@
  *
  */
 #include "squid.h"
+#include "base64.h"
 #include "helpers/defines.h"
-#include "libntlmauth/support_bits.cci"
+#include "ntlmauth/ntlmauth.h"
+#include "ntlmauth/support_bits.cci"
 #include "sspwin32.h"
 #include "util.h"
 
@@ -135,7 +137,7 @@ manage_request()
     if (fgets(buf, HELPER_INPUT_BUFFER, stdin))
         return 0;
 
-    c = memchr(buf, '\n', HELPER_INPUT_BUFFER);		/* safer against overrun than strchr */
+    c = static_cast<char*>(memchr(buf, '\n', HELPER_INPUT_BUFFER));
     if (c) {
         if (oversized) {
             SEND("BH illegal request received");
@@ -153,13 +155,13 @@ manage_request()
         decodedLen = base64_decode(decoded, sizeof(decoded), buf+3);
         strncpy(helper_command, buf, 2);
         debug("Got '%s' from Squid with data:\n", helper_command);
-        hex_dump(decoded, decodedLen);
+        hex_dump(reinterpret_cast<unsigned char*>(decoded), decodedLen);
     } else
         debug("Got '%s' from Squid\n", buf);
 
     if (memcmp(buf, "YR ", 3) == 0) {	/* refresh-request */
         /* figure out what we got */
-        decoded = base64_decode(buf + 3);
+        decodedLen = base64_decode(decoded, sizeof(decoded), buf + 3);
         if ((size_t)decodedLen < sizeof(ntlmhdr)) {		/* decoding failure, return error */
             SEND("NA * Packet format error, couldn't base64-decode");
             return 1;
@@ -176,7 +178,7 @@ manage_request()
                     decodedLen = base64_decode(decoded, sizeof(decoded), c);
                     debug("sending 'AF' %s to squid with data:\n", cred);
                     if (c != NULL)
-                        hex_dump(decoded, decodedLen);
+                        hex_dump(reinterpret_cast<unsigned char*>(decoded), decodedLen);
                     else
                         fprintf(stderr, "No data available.\n");
                     printf("AF %s %s\n", c, cred);
@@ -186,7 +188,7 @@ manage_request()
                 if (Negotiate_packet_debug_enabled) {
                     decodedLen = base64_decode(decoded, sizeof(decoded), c);
                     debug("sending 'TT' to squid with data:\n");
-                    hex_dump(decoded, decodedLen);
+                    hex_dump(reinterpret_cast<unsigned char*>(decoded), decodedLen);
                     printf("TT %s\n", c);
                 } else {
                     SEND2("TT %s", c);
@@ -236,7 +238,7 @@ manage_request()
                 decodedLen = base64_decode(decoded, sizeof(decoded), c);
                 debug("sending 'AF' %s to squid with data:\n", cred);
                 if (c != NULL)
-                    hex_dump(decoded, decodedLen);
+                    hex_dump(reinterpret_cast<unsigned char*>(decoded), decodedLen);
                 else
                     fprintf(stderr, "No data available.\n");
                 printf("AF %s %s\n", c, cred);
@@ -248,7 +250,7 @@ manage_request()
             if (Negotiate_packet_debug_enabled) {
                 decodedLen = base64_decode(decoded, sizeof(decoded), c);
                 debug("sending 'TT' to squid with data:\n");
-                hex_dump(decoded, decodedLen);
+                hex_dump(reinterpret_cast<unsigned char*>(decoded), decodedLen);
                 printf("TT %s\n", c);
             } else
                 SEND2("TT %s", c);
@@ -5,7 +5,7 @@ SUBDIRS =
 
 libexec_PROGRAMS = negotiate_kerberos_auth negotiate_kerberos_auth_test
 
-AM_CPPFLAGS = $(INCLUDES) -I$(srcdir)
+AM_CPPFLAGS += -I$(srcdir)
 
 negotiate_kerberos_auth_SOURCES = negotiate_kerberos_auth.cc negotiate_kerberos_pac.cc negotiate_kerberos.h
 negotiate_kerberos_auth_LDFLAGS = 
@@ -1 +1 @@
-BUILD_HELPER="wrapper"
+AC_CHECK_FUNCS(vfork,[BUILD_HELPER="wrapper"])
@@ -9,6 +9,7 @@ ntlm_sspi_auth_SOURCES = ntlm_sspi_auth.cc
 LDADD = \
 	$(top_builddir)/lib/ntlmauth/libntlmauth.la \
 	-L$(top_builddir)/lib -lsspwin32 \
+	$(top_builddir)/lib/libmiscencoding.la \
 	$(COMPAT_LIB) \
 	-lnetapi32 \
 	-ladvapi32 \
@@ -61,12 +61,13 @@
 
 /************* END CONFIGURATION ***************/
 
-typedef unsigned char uchar;
+//typedef unsigned char uchar;
 
 #include "squid.h"
+#include "base64.h"
 #include "helpers/defines.h"
-#include "libntlmauth/ntlmauth.h"
-#include "libntlmauth/support_bits.h"
+#include "ntlmauth/ntlmauth.h"
+#include "ntlmauth/support_bits.cci"
 #include "sspwin32.h"
 #include "util.h"
 
@@ -82,8 +83,6 @@ typedef unsigned char uchar;
 #include <lm.h>
 #include <ntsecapi.h>
 
-#define BUFFER_SIZE 10240
-
 int NTLM_packet_debug_enabled = 0;
 static int have_challenge;
 char * NTAllowedGroup;
@@ -272,10 +271,10 @@ char * GetDomainName(void)
     return DomainName;
 }
 
-/* returns NULL on failure, or a pointer to
- * the user's credentials (domain\\username)
- * upon success. WARNING. It's pointing to static storage.
- * In case of problem sets as side-effect ntlm_errno to one of the
+/*
+ * Fills auth with the user's credentials.
+ *
+ * In case of problem returns one of the
  * codes defined in libntlmauth/ntlmauth.h
  */
 int
@@ -284,7 +283,6 @@ ntlm_check_auth(ntlm_authenticate * auth, char *user, char *domain, int auth_len
     int x;
     int rv;
     char credentials[DNLEN+UNLEN+2];	/* we can afford to waste */
-    lstring tmp;
 
     if (!NTLM_LocalCall) {
 
@@ -341,7 +339,7 @@ helperfail(const char *reason)
 #if FAIL_DEBUG
     fail_debug_enabled =1;
 #endif
-    SEND2("BH %s", reason);
+    SEND_BH(reason);
 }
 
 /*
@@ -411,11 +409,10 @@ int
 manage_request()
 {
     ntlmhdr *fast_header;
-    char buf[BUFFER_SIZE];
-    char decoded[BUFFER_SIZE];
+    char buf[HELPER_INPUT_BUFFER];
+    char decoded[HELPER_INPUT_BUFFER];
     int decodedLen;
     char helper_command[3];
-    char *c, *cred;
     int oversized = 0;
     char * ErrorMessage;
     static ntlm_negotiate local_nego;
@@ -424,38 +421,40 @@ manage_request()
 
     /* NP: for some reason this helper sometimes needs to accept
      * from clients that send no negotiate packet. */
-    if (memcpy(local_nego.signature, "NTLMSSP", 8) != 0) {
+    if (memcpy(local_nego.hdr.signature, "NTLMSSP", 8) != 0) {
         memset(&local_nego, 0, sizeof(ntlm_negotiate));	/* reset */
-        memcpy(local_nego.signature, "NTLMSSP", 8);     /* set the signature */
-        local_nego.type = le32toh(NTLM_NEGOTIATE);      /* this is a challenge */
+        memcpy(local_nego.hdr.signature, "NTLMSSP", 8);     /* set the signature */
+        local_nego.hdr.type = le32toh(NTLM_NEGOTIATE);      /* this is a challenge */
         local_nego.flags = le32toh(NTLM_NEGOTIATE_ALWAYS_SIGN |
                                    NTLM_NEGOTIATE_USE_NTLM |
                                    NTLM_NEGOTIATE_USE_LM |
                                    NTLM_NEGOTIATE_ASCII );
     }
 
-try_again:
-    if (fgets(buf, BUFFER_SIZE, stdin) == NULL)
-        return 0;
+    do {
+        if (fgets(buf, sizeof(buf), stdin) == NULL)
+            return 0;
 
-    c = memchr(buf, '\n', BUFFER_SIZE);	/* safer against overrun than strchr */
-    if (c) {
-        if (oversized) {
-            helperfail("illegal request received");
-            fprintf(stderr, "Illegal request received: '%s'\n", buf);
-            return 1;
+        char *c = static_cast<char*>(memchr(buf, '\n', sizeof(buf)));
+        if (c) {
+            if (oversized) {
+                helperfail("messge=\"illegal request received\"");
+                fprintf(stderr, "Illegal request received: '%s'\n", buf);
+                return 1;
+            }
+            *c = '\0';
+        } else {
+            fprintf(stderr, "No newline in '%s'\n", buf);
+            oversized = 1;
+            continue;
         }
-        *c = '\0';
-    } else {
-        fprintf(stderr, "No newline in '%s'\n", buf);
-        oversized = 1;
-        goto try_again;
-    }
+    } while (false);
+
     if ((strlen(buf) > 3) && NTLM_packet_debug_enabled) {
         decodedLen = base64_decode(decoded, sizeof(decoded), buf+3);
         strncpy(helper_command, buf, 2);
         debug("Got '%s' from Squid with data:\n", helper_command);
-        hex_dump(decoded, decodedLen);
+        hex_dump(reinterpret_cast<unsigned char*>(decoded), decodedLen);
     } else
         debug("Got '%s' from Squid\n", buf);
     if (memcmp(buf, "YR", 2) == 0) {	/* refresh-request */
@@ -464,102 +463,102 @@ manage_request()
             decodedLen = base64_decode(decoded, sizeof(decoded), buf+3);
         else {
             debug("Negotiate packet not supplied - self generated\n");
-            memcpy(decoded, local_lego, sizeof(local_nego));
-            decodedLen = sizeof(localnego);
+            memcpy(decoded, &local_nego, sizeof(local_nego));
+            decodedLen = sizeof(local_nego);
         }
         if ((size_t)decodedLen < sizeof(ntlmhdr)) {		/* decoding failure, return error */
-            SEND("NA Packet format error, couldn't base64-decode");
+            SEND_ERR("message=\"Packet format error, couldn't base64-decode\"");
             return 1;
         }
         /* fast-track-decode request type. */
         fast_header = (struct _ntlmhdr *) decoded;
 
         /* sanity-check: it IS a NTLMSSP packet, isn't it? */
         if (ntlm_validate_packet(fast_header, NTLM_ANY) != NTLM_ERR_NONE) {
-            SEND("NA Broken authentication packet");
+            SEND_ERR("message=\"Broken authentication packet\"");
             return 1;
         }
         switch (fast_header->type) {
-        case NTLM_NEGOTIATE:
+        case NTLM_NEGOTIATE: {
             /* Obtain challenge against SSPI */
             debug("attempting SSPI challenge retrieval\n");
-            if ((c = (char *) SSP_MakeChallenge((ntlm_negotiate *) decoded, decodedLen)) != NULL ) {
+            char *c = (char *) SSP_MakeChallenge((ntlm_negotiate *) decoded, decodedLen);
+            if (c) {
+                SEND_TT(c);
                 if (NTLM_packet_debug_enabled) {
-                    printf("TT %s\n",c);
                     decodedLen = base64_decode(decoded, sizeof(decoded), c);
-                    debug("sending 'TT' to squid with data:\n");
-                    hex_dump(decoded, decodedLen);
-                    if (NTLM_LocalCall)
+                    debug("send 'TT' to squid with data:\n");
+                    hex_dump(reinterpret_cast<unsigned char*>(decoded), decodedLen);
+                    if (NTLM_LocalCall) {
                         debug("NTLM Local Call detected\n");
-                } else {
-                    SEND2("TT %s", c);
+                    }
                 }
                 have_challenge = 1;
             } else
-                helperfail("can't obtain challenge");
+                helperfail("message=\"can't obtain challenge\"");
 
             return 1;
-            /* notreached */
+        }
+        /* notreached */
         case NTLM_CHALLENGE:
-            SEND("NA Got a challenge. We refuse to have our authority disputed");
+            SEND_ERR("message=\"Got a challenge. We refuse to have our authority disputed\"");
             return 1;
             /* notreached */
         case NTLM_AUTHENTICATE:
-            SEND("NA Got authentication request instead of negotiate request");
+            SEND_ERR("message=\"Got authentication request instead of negotiate request\"");
             return 1;
             /* notreached */
         default:
-            helperfail("unknown refresh-request packet type");
+            helperfail("message=\"unknown refresh-request packet type\"");
             return 1;
         }
         return 1;
     }
     if (memcmp(buf, "KK ", 3) == 0) {	/* authenticate-request */
         if (!have_challenge) {
-            helperfail("invalid challenge");
+            helperfail("message=\"invalid challenge\"");
             return 1;
         }
         /* figure out what we got */
         decodedLen = base64_decode(decoded, sizeof(decoded), buf+3);
 
         if ((size_t)decodedLen < sizeof(ntlmhdr)) {		/* decoding failure, return error */
-            SEND("NA Packet format error, couldn't base64-decode");
+            SEND_ERR("message=\"Packet format error, couldn't base64-decode\"");
             return 1;
         }
         /* fast-track-decode request type. */
         fast_header = (struct _ntlmhdr *) decoded;
 
         /* sanity-check: it IS a NTLMSSP packet, isn't it? */
         if (ntlm_validate_packet(fast_header, NTLM_ANY) != NTLM_ERR_NONE) {
-            SEND("NA Broken authentication packet");
+            SEND_ERR("message=\"Broken authentication packet\"");
             return 1;
         }
         switch (fast_header->type) {
         case NTLM_NEGOTIATE:
-            SEND("NA Invalid negotiation request received");
+            SEND_ERR("message=\"Invalid negotiation request received\"");
             return 1;
             /* notreached */
         case NTLM_CHALLENGE:
-            SEND
-            ("NA Got a challenge. We refuse to have our authority disputed");
+            SEND_ERR("message=\"Got a challenge. We refuse to have our authority disputed\"");
             return 1;
             /* notreached */
-        case NTLM_AUTHENTICATE:
+        case NTLM_AUTHENTICATE: {
             /* check against SSPI */
-            err = ntlm_check_auth((ntlm_authenticate *) decoded, user, domain, decodedLen);
+            int err = ntlm_check_auth((ntlm_authenticate *) decoded, user, domain, decodedLen);
             have_challenge = 0;
             if (err != NTLM_ERR_NONE) {
 #if FAIL_DEBUG
                 fail_debug_enabled =1;
 #endif
-                switch (ntlm_errno) {
+                switch (err) {
                 case NTLM_ERR_NONE:
                     break;
                 case NTLM_BAD_NTGROUP:
-                    SEND("NA Incorrect Group Membership");
+                    SEND_ERR("message=\"Incorrect Group Membership\"");
                     return 1;
                 case NTLM_BAD_REQUEST:
-                    SEND("NA Incorrect Request Format");
+                    SEND_ERR("message=\"Incorrect Request Format\"");
                     return 1;
                 case NTLM_SSPI_ERROR:
                     FormatMessage(
@@ -576,28 +575,31 @@ manage_request()
                         ErrorMessage[strlen(ErrorMessage) - 1] = '\0';
                     if (ErrorMessage[strlen(ErrorMessage) - 1] == '\r')
                         ErrorMessage[strlen(ErrorMessage) - 1] = '\0';
-                    SEND2("NA %s", ErrorMessage);
+                    SEND_ERR(ErrorMessage); // TODO update to new syntax
                     LocalFree(ErrorMessage);
                     return 1;
                 default:
-                    SEND("NA Unknown Error");
+                    SEND_ERR("message=\"Unknown Error\"");
                     return 1;
                 }
             }
             /* let's lowercase them for our convenience */
-            SEND3("AF %s\\%s", lc(domain), lc(user));
+            lc(domain);
+            lc(user);
+            fprintf(stdout, "OK user=\"%s\\%s\"", domain, user);
             return 1;
+        }
         default:
-            helperfail("unknown authentication packet type");
+            helperfail("message=\"unknown authentication packet type\"");
             return 1;
         }
         return 1;
     } else {	/* not an auth-request */
-        helperfail("illegal request received");
+        helperfail("message=\"illegal request received\"");
         fprintf(stderr, "Illegal request received: '%s'\n", buf);
         return 1;
     }
-    helperfail("detected protocol error");
+    helperfail("message=\"detected protocol error\"");
     return 1;
     /********* END ********/
 }
@@ -11,7 +11,7 @@ ntlm_fake_auth_LDADD = \
 	$(CRYPTLIB) \
 	$(XTRA_LIBS)
 
-INCLUDES += -I$(top_srcdir)/lib
+AM_CPPFLAGS += -I$(top_srcdir)/lib
 
 ## Demo using perl.
 ## ntlm_fake_auth.pl: ntlm_fake_auth.pl.in
@@ -13,6 +13,6 @@ ntlm_smb_lm_auth_LDADD = \
 	$(CRYPTLIB) \
 	$(XTRA_LIBS)
 
-INCLUDES += -I$(top_srcdir)/lib
+AM_CPPFLAGS += -I$(top_srcdir)/lib
 
 EXTRA_DIST = required.m4
@@ -33,6 +33,9 @@ class SplayNode
     SplayNode<V> * insert(Value data, SPLAYCMP * compare);
 
     template <class FindValue> SplayNode<V> * splay(const FindValue &data, int( * compare)(FindValue const &a, Value const &b)) const;
+
+    /// recursively visit left nodes, this node, and then right nodes
+    template <class Visitor> void visit(Visitor &v) const;
 };
 
 typedef SplayNode<void *> splayNode;
@@ -73,6 +76,9 @@ class Splay
 
     const_iterator end() const;
 
+    /// recursively visit all nodes, in left-to-right order
+    template <class Visitor> void visit(Visitor &v) const;
+
     size_t elements;
 };
 
@@ -276,6 +282,27 @@ SplayNode<V>::splay(FindValue const &dataToFind, int( * compare)(FindValue const
     return top;
 }
 
+template <class V>
+template <class Visitor>
+void
+SplayNode<V>::visit(Visitor &visitor) const
+{
+    if (left)
+        left->visit(visitor);
+    visitor(data);
+    if (right)
+        right->visit(visitor);
+}
+
+template <class V>
+template <class Visitor>
+void
+Splay<V>::visit(Visitor &visitor) const
+{
+    if (head)
+        head->visit(visitor);
+}
+
 template <class V>
 template <class FindValue>
 typename Splay<V>::Value const *
@@ -362,6 +389,7 @@ Splay<V>::end() const
     return const_iterator(NULL);
 }
 
+// XXX: This does not seem to iterate the whole thing in some cases.
 template <class V>
 class SplayConstIterator
 {
@@ -70,7 +70,7 @@ extern "C" {
 
     HMODULE LoadSecurityDll(int, const char *);
     void UnloadSecurityDll(void);
-    BOOL WINAPI SSP_LogonUser(unsigned char *, unsigned char *, unsigned char *);
+    BOOL WINAPI SSP_LogonUser(PTSTR, PTSTR, PTSTR);
     BOOL WINAPI SSP_ValidateNTLMCredentials(PVOID, int, char *);
     const char * WINAPI SSP_ValidateNegotiateCredentials(PVOID, int, PBOOL, int *, char *);
     const char * WINAPI SSP_MakeChallenge(PVOID, int);
@@ -9,9 +9,7 @@ noinst_LIBRARIES = libTrie.a
 noinst_HEADERS = Trie.h TrieNode.h TrieCharTransform.h
 
 libTrie_a_SOURCES = Trie.cc \
-	Trie.cci \
 	Trie.h \
 	TrieNode.cc \
-	TrieNode.cci \
 	TrieNode.h \
 	TrieCharTransform.h
@@ -19,40 +19,22 @@
 
 #include "squid.h"
 #include "Trie.h"
-#if HAVE_UNISTD_H
-#include <unistd.h>
-#endif
 #include "TrieCharTransform.h"
 #include "TrieNode.h"
 
-#if !_USE_INLINE_
-#include "Trie.cci"
+#if HAVE_UNISTD_H
+#include <unistd.h>
 #endif
 
 Trie::Trie(TrieCharTransform *aTransform) : head(0) , transform(aTransform)
 {}
 
-extern "C" void *TrieCreate()
-{
-    return new Trie;
-}
-
 Trie::~Trie()
 {
     delete head;
     delete transform;
 }
 
-extern "C" void TrieDestroy(void *aTrie)
-{
-    delete (Trie *)aTrie;
-}
-
-extern "C" void *TrieFind(void *aTrie, char const *aString, size_t theLength)
-{
-    return ((Trie *)aTrie)->find(aString, theLength);
-}
-
 bool
 Trie::add(char const *aString, size_t theLength, void *privatedata)
 {
@@ -70,9 +52,3 @@ Trie::add(char const *aString, size_t theLength, void *privatedata)
 
     return head->add(aString, theLength, privatedata, transform);
 }
-
-extern "C" int TrieAdd(void *aTrie, char const *aString, size_t theLength, void *privatedata)
-{
-
-    return ((Trie *)aTrie)->add(aString, theLength, privatedata);
-}
@@ -1,42 +0,0 @@
-/*
- * Copyright (c) 2002,2003 Robert Collins <rbtcollins@hotmail.com>
- *
- * This program is free software; you can redistribute it and/or modify
- * it under the terms of the GNU General Public License as published by
- * the Free Software Foundation; either version 2 of the License, or
- * (at your option) any later version.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
- * GNU General Public License for more details.
- *
- * You should have received a copy of the GNU General Public License
- * along with this program; if not, write to the Free Software
- * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111, USA.
- *
- */
-
-#ifdef __cplusplus
-#include "Trie.h"
-#include "TrieNode.h"
-
-void *
-Trie::find (char const *aString, size_t theLength)
-{
-    if (head)
-        return head->find (aString, theLength, transform, false);
-
-    return NULL;
-}
-
-void *
-Trie::findPrefix (char const *aString, size_t theLength)
-{
-    if (head)
-        return head->find (aString, theLength, transform, true);
-
-    return NULL;
-}
-
-#endif
@@ -20,36 +20,13 @@
 #ifndef   LIBTRIE_SQUID_H
 #define   LIBTRIE_SQUID_H
 
-/* This is the header for libTrie.
- * libTrie provides both C and C++
- * bindings. libtrie itself is written in C++.
- */
-
+#include "TrieNode.h"
 #if HAVE_SYS_TYPES_H
 #include <sys/types.h>
 #endif
 
-/* C bindings */
-#ifndef   __cplusplus
-
-/* TODO: provide parameterisation for C bindings */
-void *TrieCreate (void);
-void TrieDestroy (void *);
-void *TrieFind (void *, char const *, size_t);
-int TrieAdd (void *, char const *, size_t, void *);
-
-/* C++ bindings */
-#else
-
-/* MinGW needs NULL definition */
-#ifndef NULL
-#define NULL 0
-#endif
-
 class TrieCharTransform;
 
-class TrieNode;
-
 /* TODO: parameterize this to be more generic -
 * i.e. M-ary internal node sizes etc
 */
@@ -67,11 +44,11 @@ class Trie
     * If found, return the private data.
     * If not found, return NULL.
     */
-    _SQUID_INLINE_ void *find (char const *, size_t);
+    inline void *find (char const *, size_t);
     /* find any element of the trie in the buffer from the
     * beginning thereof
     */
-    _SQUID_INLINE_ void *findPrefix (char const *, size_t);
+    inline void *findPrefix (char const *, size_t);
 
     /* Add a string.
     * returns false if the string is already
@@ -87,10 +64,22 @@ class Trie
     TrieCharTransform *transform;
 };
 
-#endif /* __cplusplus */
+void *
+Trie::find (char const *aString, size_t theLength)
+{
+    if (head)
+        return head->find (aString, theLength, transform, false);
 
-#if _USE_INLINE_
-#include "Trie.cci"
-#endif
+    return NULL;
+}
+
+void *
+Trie::findPrefix (char const *aString, size_t theLength)
+{
+    if (head)
+        return head->find (aString, theLength, transform, true);
+
+    return NULL;
+}
 
 #endif /* LIBTRIE_SQUID_H */
@@ -60,7 +60,3 @@ TrieNode::add(char const *aString, size_t theLength, void *privatedata, TrieChar
         return true;
     }
 }
-
-#if !_USE_INLINE_
-#include "TrieNode.cci"
-#endif
@@ -1,57 +0,0 @@
-/*
- * Copyright (c) 2002,2003 Robert Collins <rbtcollins@hotmail.com>
- *
- * This program is free software; you can redistribute it and/or modify
- * it under the terms of the GNU General Public License as published by
- * the Free Software Foundation; either version 2 of the License, or
- * (at your option) any later version.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
- * GNU General Public License for more details.
- *
- * You should have received a copy of the GNU General Public License
- * along with this program; if not, write to the Free Software
- * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111, USA.
- *
- */
-
-#ifdef __cplusplus
-#include "TrieCharTransform.h"
-#include "TrieNode.h"
-#if HAVE_UNISTD_H
-#include <unistd.h>
-#endif
-#include <ctype.h>
-
-/* recursive. TODO? make iterative */
-void *
-TrieNode::find (char const *aString, size_t theLength, TrieCharTransform *transform, bool const prefix) const
-{
-    if (theLength) {
-        int index = -1;
-        unsigned char pos = transform ? (*transform) (*aString) : *aString;
-
-        if (internal[pos])
-            index = pos;
-
-        if (index > -1) {
-            void *result;
-            result = internal[index]->find(aString + 1, theLength - 1, transform, prefix);
-
-            if (result)
-                return result;
-        }
-
-        if (prefix)
-            return _privateData;
-
-        return NULL;
-    } else {
-        /* terminal node */
-        return _privateData;
-    }
-}
-
-#endif
@@ -20,32 +20,15 @@
 #ifndef   LIBTRIE_TRIENODE_H
 #define   LIBTRIE_TRIENODE_H
 
-/* This is an internal header for libTrie.
- * libTrie provides both C and C++
- * bindings.
- * libTrie itself is written in C++.
- * For C bindings see Trei.h
- */
-
-/* C bindings */
-#ifndef   __cplusplus
+#include "TrieCharTransform.h"
 
-/* C++ bindings */
-#else
 #include <sys/types.h>
 #include <utility>
 
-/* MinGW needs NULL definition */
-#ifndef NULL
-#define NULL 0
-#endif
-
 /* TODO: parameterize this to be more generic -
 * i.e. M-ary internal node sizes etc
 */
 
-class TrieCharTransform;
-
 class TrieNode
 {
 
@@ -59,15 +42,14 @@ class TrieNode
     * If found, return the private data.
     * If not found, return NULL.
     */
-    _SQUID_INLINE_ void *find (char const *, size_t, TrieCharTransform *, bool const prefix) const;
+    inline void *find (char const *, size_t, TrieCharTransform *, bool const prefix) const;
 
     /* Add a string.
     * returns false if the string is already
     * present or can't be added.
     */
 
-    bool add
-    (char const *, size_t, void *, TrieCharTransform *);
+    bool add (char const *, size_t, void *, TrieCharTransform *);
 
 private:
     /* 256-way Trie */
@@ -82,10 +64,32 @@ class TrieNode
     void *_privateData;
 };
 
-#endif /* __cplusplus */
-
-#if _USE_INLINE_
-#include "TrieNode.cci"
-#endif
-
+/* recursive. TODO? make iterative */
+void *
+TrieNode::find (char const *aString, size_t theLength, TrieCharTransform *transform, bool const prefix) const
+{
+    if (theLength) {
+        int index = -1;
+        unsigned char pos = transform ? (*transform) (*aString) : *aString;
+
+        if (internal[pos])
+            index = pos;
+
+        if (index > -1) {
+            void *result;
+            result = internal[index]->find(aString + 1, theLength - 1, transform, prefix);
+
+            if (result)
+                return result;
+        }
+
+        if (prefix)
+            return _privateData;
+
+        return NULL;
+    } else {
+        /* terminal node */
+        return _privateData;
+    }
+}
 #endif /* LIBTRIE_TRIENODE_H */
@@ -1,15 +1,10 @@
 include $(top_srcdir)/src/Common.am
 
-INCLUDES += -I$(top_srcdir)/include
+AM_CPPFLAGS += -I$(top_srcdir)/include
 
-# TESTS = trie trie-c
 TESTS += trie
 
-# check_PROGRAMS = trie trie-c
 check_PROGRAMS += trie
 
 trie_SOURCES = trie.cc
 trie_LDADD = $(top_builddir)/lib/libTrie/libTrie.a
-
-#trie_c_SOURCES = trie-c.c
-#trie_c_LDADD = $(top_builddir)/lib/libTrie/libTrie.a -lm
@@ -1,41 +0,0 @@
-/*
- * Copyright (c) 2002 Robert Collins <rbtcollins@hotmail.com>
- *
- * This program is free software; you can redistribute it and/or modify
- * it under the terms of the GNU General Public License as published by
- * the Free Software Foundation; either version 2 of the License, or
- * (at your option) any later version.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
- * GNU General Public License for more details.
- *
- * You should have received a copy of the GNU General Public License
- * along with this program; if not, write to the Free Software
- * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111, USA.
- *
- */
-
-#include "squid.h"
-#include "Trie.h"
-
-int
-main (int argc, char **argv)
-{
-    void *aTrie = TrieCreate();
-    if (!TrieAdd (aTrie, "User-Agent", 10, (void *)1)) {
-        fprintf(stderr,"Could not add User-Agent\n");
-        return 1;
-    }
-    if (TrieAdd (aTrie, "User-Agent", 10, (void *)2)) {
-        fprintf(stderr, "Could add duplicate User-Agent\n");
-        return 1;
-    }
-    if (TrieFind (aTrie, "User-Agent", 10) != (void *)1) {
-        fprintf(stderr, "Could not find User-Agent\n");
-        return 1;
-    }
-    TrieDestroy (aTrie);
-    return 0;
-}
@@ -1,7 +1,7 @@
 include $(top_srcdir)/src/Common.am
 include $(top_srcdir)/src/TestHeaders.am
 
-INCLUDES += -I$(top_srcdir)/lib
+AM_CPPFLAGS += -I$(top_srcdir)/lib
 
 noinst_LTLIBRARIES = libntlmauth.la
 
@@ -1,6 +1,6 @@
 include $(top_srcdir)/src/Common.am
 
-INCLUDES += -I$(top_srcdir)/lib
+AM_CPPFLAGS += -I$(top_srcdir)/lib
 
 noinst_LTLIBRARIES = librfcnb.la
 
@@ -1,6 +1,6 @@
 include $(top_srcdir)/src/Common.am
 
-INCLUDES += -I$(top_srcdir)/lib
+AM_CPPFLAGS += -I$(top_srcdir)/lib
 
 noinst_LTLIBRARIES = libsmblib.la
 
@@ -4,17 +4,17 @@
 ## 
 AM_CFLAGS = $(SQUID_CFLAGS)
 AM_CXXFLAGS = $(SQUID_CXXFLAGS)
+AM_CPPFLAGS = \
+	-I$(top_srcdir) \
+	-I$(top_builddir)/include \
+	-I$(top_srcdir)/include
+
 noinst_LTLIBRARIES = libsnmplib.la
 libsnmplib_la_SOURCES  = asn1.c parse.c snmp_vars.c \
 	coexistance.c snmp_api.c snmp_error.c  \
 	mib.c snmp_api_error.c   \
 	snmp_msg.c \
 	snmp_pdu.c  snmplib_debug.c
 
-INCLUDES = \
-	-I$(top_srcdir) \
-	-I$(top_builddir)/include \
-	-I$(top_srcdir)/include
-
 VERSION		= 3.4
 DEFS		= -DSQUID_SNMP=1
@@ -60,5 +60,4 @@ AccessLogEntry::~AccessLogEntry()
     HTTPMSGUNLOCK(icap.reply);
     HTTPMSGUNLOCK(icap.request);
 #endif
-    cbdataReferenceDone(cache.port);
 }
@@ -185,7 +185,7 @@ class AccessLogEntry: public RefCountable
         const char *ssluser;
         Ssl::X509_Pointer sslClientCert; ///< cert received from the client
 #endif
-        AnyP::PortCfg *port;
+        AnyP::PortCfgPointer port;
 
     } cache;
 
@@ -102,8 +102,8 @@
 
   \par
   The read, write, and accept notifications (scheduled in step #2
-  above) carry the COMM_ERR_CLOSING error flag. When handling
-  COMM_ERR_CLOSING event, the user code should limit
+  above) carry the Comm::ERR_CLOSING error flag. When handling
+  Comm::ERR_CLOSING event, the user code should limit
   descriptor-related processing, especially Comm calls, because
   supported Comm functionality is very limited when the descriptor is
   closing. New code should use the close handlers instead (scheduled
@@ -121,7 +121,7 @@
   Since all notifications are asynchronous, it is possible for a read
   or write notification that was scheduled before comm_close() was
   called to arrive at its destination after comm_close() was called.
-  Such notification will arrive with COMM_ERR_CLOSING flag even though
+  Such notification will arrive with Comm::ERR_CLOSING flag even though
   that flag was not set at the time of the I/O (and the I/O may have
   been successful). This behavior may change.
 
@@ -140,12 +140,12 @@
   instead.
 
   \par
-  COMM_ERR_CLOSING interface will be removed. The read, write, and
+  Comm::ERR_CLOSING interface will be removed. The read, write, and
   accept notifications will not be scheduled after comm_close() is
   called.  New user code should register close handlers instead.
 
   \par
-  When COMM_ERR_CLOSING interface is removed, pending notifications
+  When Comm::ERR_CLOSING interface is removed, pending notifications
   (if any) will be canceled after comm_close() is called. However, the
   cancellation may be removed later if Comm is modified to provide safe
   access to closing descriptors and their fragile state. New user code
@@ -1,4 +1,5 @@
 #include "squid.h"
+#include "anyp/PortCfg.h"
 #include "comm/Connection.h"
 #include "CommCalls.h"
 #include "fde.h"
@@ -7,7 +8,7 @@
 /* CommCommonCbParams */
 
 CommCommonCbParams::CommCommonCbParams(void *aData):
-        data(cbdataReference(aData)), conn(), flag(COMM_OK), xerrno(0), fd(-1)
+        data(cbdataReference(aData)), conn(), flag(Comm::OK), xerrno(0), fd(-1)
 {
 }
 
@@ -31,7 +32,7 @@ CommCommonCbParams::print(std::ostream &os) const
 
     if (xerrno)
         os << ", errno=" << xerrno;
-    if (flag != COMM_OK)
+    if (flag != Comm::OK)
         os << ", flag=" << flag;
     if (data)
         os << ", data=" << data;
@@ -84,9 +85,9 @@ CommIoCbParams::syncWithComm()
 {
     // change parameters if the call was scheduled before comm_close but
     // is being fired after comm_close
-    if ((conn->fd < 0 || fd_table[conn->fd].closing()) && flag != COMM_ERR_CLOSING) {
-        debugs(5, 3, HERE << "converting late call to COMM_ERR_CLOSING: " << conn);
-        flag = COMM_ERR_CLOSING;
+    if ((conn->fd < 0 || fd_table[conn->fd].closing()) && flag != Comm::ERR_CLOSING) {
+        debugs(5, 3, HERE << "converting late call to Comm::ERR_CLOSING: " << conn);
+        flag = Comm::ERR_CLOSING;
     }
     return true; // now we are in sync and can handle the call
 }
@@ -3,8 +3,8 @@
 
 #include "base/AsyncCall.h"
 #include "base/AsyncJobCalls.h"
+#include "comm/Flag.h"
 #include "comm/forward.h"
-#include "comm_err_t.h"
 #include "MasterXaction.h"
 
 /* CommCalls implement AsyncCall interface for comm_* callbacks.
@@ -24,8 +24,8 @@
 class CommAcceptCbParams;
 typedef void IOACB(const CommAcceptCbParams &params);
 
-typedef void CNCB(const Comm::ConnectionPointer &conn, comm_err_t status, int xerrno, void *data);
-typedef void IOCB(const Comm::ConnectionPointer &conn, char *, size_t size, comm_err_t flag, int xerrno, void *data);
+typedef void CNCB(const Comm::ConnectionPointer &conn, Comm::Flag status, int xerrno, void *data);
+typedef void IOCB(const Comm::ConnectionPointer &conn, char *, size_t size, Comm::Flag flag, int xerrno, void *data);
 
 class CommTimeoutCbParams;
 typedef void CTCB(const CommTimeoutCbParams &params);
@@ -72,12 +72,12 @@ class CommCommonCbParams
      *  - On read calls this is the connection just read from.
      *  - On close calls this describes the connection which is now closed.
      *  - On timeouts this is the connection whose operation timed out.
-     *   + NP: timeouts might also return to the connect/read/write handler with COMM_ERR_TIMEOUT.
+     *   + NP: timeouts might also return to the connect/read/write handler with Comm::TIMEOUT.
      */
     Comm::ConnectionPointer conn;
 
-    comm_err_t flag;  ///< comm layer result status.
-    int xerrno;      ///< The last errno to occur. non-zero if flag is COMM_ERR.
+    Comm::Flag flag;  ///< comm layer result status.
+    int xerrno;      ///< The last errno to occur. non-zero if flag is Comm::COMM_ERROR.
 
     int fd; ///< FD which the call was about. Set by the async call creator.
 private:
@@ -106,8 +106,6 @@ class CommConnectCbParams: public CommCommonCbParams
     bool syncWithComm(); // see CommCommonCbParams::syncWithComm
 };
 
-class SBuf;
-
 // read/write (I/O) parameters
 class CommIoCbParams: public CommCommonCbParams
 {
@@ -120,7 +118,6 @@ class CommIoCbParams: public CommCommonCbParams
 public:
     char *buf;
     size_t size;
-    SBuf *buf2;  // alternative buffer for use when buf is unset
 };
 
 // close parameters
@@ -13,7 +13,7 @@ CLEANFILES =
 check_PROGRAMS = 
 TESTS =
 
-INCLUDES = \
+AM_CPPFLAGS = \
 	-I$(top_srcdir) \
 	-I$(top_srcdir)/include \
 	-I$(top_srcdir)/lib \
@@ -23,12 +23,12 @@ INCLUDES = \
 
 ## Kerberos headers require their include path.
 ## Because we use libcompat for comm_err.h header protections ...
-INCLUDES += $(KRB5INCS)
+AM_CPPFLAGS += $(KRB5INCS)
 
 ## Loadable Modules requires LTDL include paths.
 ## Because we need this to use the libray linking headers...
 if ENABLE_LOADABLE_MODULES
-INCLUDES += $(INCLTDL)
+AM_CPPFLAGS += $(INCLTDL)
 endif
 
 ## make all compiled sources depend on generated files
@@ -53,9 +53,7 @@
 #include "DiskIO/WriteRequest.h"
 #include "globals.h"
 
-#if HAVE_ERRNO_H
-#include <errno.h>
-#endif
+#include <cerrno>
 
 CBDATA_CLASS_INIT(AIODiskFile);
 
@@ -38,9 +38,7 @@
 #include "StatCounters.h"
 #include "win32.h"
 
-#if HAVE_ERRNO_H
-#include <errno.h>
-#endif
+#include <cerrno>
 
 #if _SQUID_WINDOWS_
 VOID CALLBACK IoCompletionRoutine(DWORD dwErrorCode,
@@ -40,9 +40,7 @@
 #include "DiskIO/WriteRequest.h"
 #include "globals.h"
 
-#if HAVE_ERRNO_H
-#include <errno.h>
-#endif
+#include <cerrno>
 
 CBDATA_CLASS_INIT(BlockingFile);
 
@@ -46,6 +46,7 @@
 #include "Store.h"
 #include "unlinkd.h"
 
+#include <cerrno>
 #if HAVE_SYS_IPC_H
 #include <sys/ipc.h>
 #endif
@@ -55,9 +56,6 @@
 #if HAVE_SYS_SHM_H
 #include <sys/shm.h>
 #endif
-#if HAVE_ERRNO_H
-#include <errno.h>
-#endif
 
 diskd_stats_t diskd_stats;
 
@@ -43,9 +43,7 @@
 #include "StatCounters.h"
 #include "Store.h"
 
-#if HAVE_ERRNO_H
-#include <errno.h>
-#endif
+#include <cerrno>
 
 /* === PUBLIC =========================================================== */
 
@@ -41,11 +41,11 @@
 #include "SquidTime.h"
 #include "Store.h"
 
+#include <cerrno>
 #include <csignal>
 #include <sys/stat.h>
 #include <fcntl.h>
 #include <pthread.h>
-#include <errno.h>
 #include <dirent.h>
 #if HAVE_SCHED_H
 #include <sched.h>
@@ -40,10 +40,10 @@
 #include "SquidTime.h"
 #include "Store.h"
 
+#include <cerrno>
 #include <csignal>
 #include <sys/stat.h>
 #include <fcntl.h>
-#include <errno.h>
 #include <dirent.h>
 
 #define RIDICULOUS_LENGTH	4096
@@ -18,14 +18,14 @@
 #include "ipc/Queue.h"
 #include "ipc/StrandSearch.h"
 #include "ipc/UdsOp.h"
+#include "SBuf.h"
 #include "SquidConfig.h"
 #include "SquidTime.h"
 #include "StatCounters.h"
 #include "tools.h"
 
-#if HAVE_ERRNO_H
-#include <errno.h>
-#endif
+#include <cerrno>
+
 CBDATA_CLASS_INIT(IpcIoFile);
 
 /// shared memory segment path to use for IpcIoFile maps
@@ -43,8 +43,8 @@ std::auto_ptr<IpcIoFile::Queue> IpcIoFile::queue;
 
 bool IpcIoFile::DiskerHandleMoreRequestsScheduled = false;
 
-static bool DiskerOpen(const String &path, int flags, mode_t mode);
-static void DiskerClose(const String &path);
+static bool DiskerOpen(const SBuf &path, int flags, mode_t mode);
+static void DiskerClose(const SBuf &path);
 
 /// IpcIo wrapper for debugs() streams; XXX: find a better class name
 struct SipcIo {
@@ -98,7 +98,7 @@ IpcIoFile::open(int flags, mode_t mode, RefCount<IORequestor> callback)
         queue.reset(new Queue(ShmLabel, IamWorkerProcess() ? Queue::groupA : Queue::groupB, KidIdentifier));
 
     if (IamDiskProcess()) {
-        error_ = !DiskerOpen(dbName, flags, mode);
+        error_ = !DiskerOpen(SBuf(dbName.termedBuf()), flags, mode);
         if (error_)
             return;
 
@@ -140,7 +140,8 @@ IpcIoFile::openCompleted(const Ipc::StrandSearchResponse *const response)
     Must(diskId < 0); // we do not know our disker yet
 
     if (!response) {
-        debugs(79, DBG_IMPORTANT, HERE << "error: timeout");
+        debugs(79, DBG_IMPORTANT, "ERROR: " << dbName << " communication " <<
+               "channel establishment timeout");
         error_ = true;
     } else {
         diskId = response->strand.kidId;
@@ -150,7 +151,8 @@ IpcIoFile::openCompleted(const Ipc::StrandSearchResponse *const response)
             Must(inserted);
         } else {
             error_ = true;
-            debugs(79, DBG_IMPORTANT, HERE << "error: no disker claimed " << dbName);
+            debugs(79, DBG_IMPORTANT, "ERROR: no disker claimed " <<
+                   "responsibility for " << dbName);
         }
     }
 
@@ -175,7 +177,7 @@ IpcIoFile::close()
     assert(ioRequestor != NULL);
 
     if (IamDiskProcess())
-        DiskerClose(dbName);
+        DiskerClose(SBuf(dbName.termedBuf()));
     // XXX: else nothing to do?
 
     ioRequestor->closeCompleted();
@@ -227,10 +229,12 @@ IpcIoFile::readCompleted(ReadRequest *readRequest,
         ioError = true; // I/O timeout does not warrant setting error_?
     } else {
         if (response->xerrno) {
-            debugs(79, DBG_IMPORTANT, HERE << "error: " << xstrerr(response->xerrno));
+            debugs(79, DBG_IMPORTANT, "ERROR: " << dbName << " read: " <<
+                   xstrerr(response->xerrno));
             ioError = error_ = true;
         } else if (!response->page) {
-            debugs(79, DBG_IMPORTANT, HERE << "error: run out of shared memory pages");
+            debugs(79, DBG_IMPORTANT, "ERROR: " << dbName << " read ran " <<
+                   "out of shared memory pages");
             ioError = true;
         } else {
             const char *const buf = Ipc::Mem::PagePointer(response->page);
@@ -358,14 +362,15 @@ IpcIoFile::push(IpcIoPendingRequest *const pending)
             Notify(diskId); // must notify disker
         trackPendingRequest(ipcIo.requestId, pending);
     } catch (const Queue::Full &) {
-        debugs(47, DBG_IMPORTANT, "Worker I/O push queue overflow: " <<
+        debugs(47, DBG_IMPORTANT, "ERROR: worker I/O push queue for " <<
+               dbName << " overflow: " <<
                SipcIo(KidIdentifier, ipcIo, diskId)); // TODO: report queue len
         // TODO: grow queue size
 
         pending->completeIo(NULL);
         delete pending;
     } catch (const TextException &e) {
-        debugs(47, DBG_IMPORTANT, HERE << e.what());
+        debugs(47, DBG_IMPORTANT, "ERROR: " << dbName << " exception: " << e.what());
         pending->completeIo(NULL);
         delete pending;
     }
@@ -523,15 +528,15 @@ IpcIoFile::checkTimeouts()
 
     if (timeoutsBefore > timeoutsNow) { // some requests were rescued
         // notification message lost or significantly delayed?
-        debugs(47, DBG_IMPORTANT, "WARNING: communication with disker " <<
-               "may be too slow or disrupted for about " <<
+        debugs(47, DBG_IMPORTANT, "WARNING: communication with " << dbName <<
+               " may be too slow or disrupted for about " <<
                Timeout << "s; rescued " << (timeoutsBefore - timeoutsNow) <<
                " out of " << timeoutsBefore << " I/Os");
     }
 
     if (timeoutsNow) {
         debugs(47, DBG_IMPORTANT, "WARNING: abandoning " <<
-               timeoutsNow << " I/Os after at least " <<
+               timeoutsNow << ' ' << dbName << " I/Os after at least " <<
                Timeout << "s timeout");
     }
 
@@ -631,6 +636,7 @@ IpcIoPendingRequest::completeIo(IpcIoMsg *const response)
 
 /* XXX: disker code that should probably be moved elsewhere */
 
+static SBuf DbName; ///< full db file name
 static int TheFile = -1; ///< db file descriptor
 
 static void
@@ -682,8 +688,8 @@ diskerWriteAttempts(IpcIoMsg &ipcIo)
         if (result < 0) {
             ipcIo.xerrno = errno;
             assert(ipcIo.xerrno);
-            debugs(47, DBG_IMPORTANT,  "disker" << KidIdentifier <<
-                   " error writing " << toWrite << '/' << ipcIo.len <<
+            debugs(47, DBG_IMPORTANT, "ERROR: " << DbName << " failure" <<
+                   " writing " << toWrite << '/' << ipcIo.len <<
                    " at " << ipcIo.offset << '+' << wroteSoFar <<
                    " on " << attempts << " try: " << xstrerr(ipcIo.xerrno));
             ipcIo.len = wroteSoFar;
@@ -712,8 +718,8 @@ diskerWriteAttempts(IpcIoMsg &ipcIo)
         toWrite -= wroteNow;
     }
 
-    debugs(47, DBG_IMPORTANT,  "disker" << KidIdentifier <<
-           " exhausted all " << attemptLimit << " attempts while writing " <<
+    debugs(47, DBG_IMPORTANT, "ERROR: " << DbName << " exhausted all " <<
+           attemptLimit << " attempts while writing " <<
            toWrite << '/' << ipcIo.len << " at " << ipcIo.offset << '+' <<
            wroteSoFar);
     return; // not a fatal I/O error, unless the caller treats it as such
@@ -776,9 +782,9 @@ IpcIoFile::WaitBeforePop()
         const int64_t toSpend = balance - maxImbalance/2;
 
         if (toSpend/1e3 > Timeout)
-            debugs(47, DBG_IMPORTANT, "WARNING: Rock disker delays I/O " <<
-                   "requests for " << (toSpend/1e3) << " seconds to obey " <<
-                   ioRate << "/sec rate limit");
+            debugs(47, DBG_IMPORTANT, "WARNING: " << DbName << " delays " <<
+                   "I/O requests for " << (toSpend/1e3) << " seconds " <<
+                   "to obey " << ioRate << "/sec rate limit");
 
         debugs(47, 3, HERE << "rate limiting by " << toSpend << " ms to get" <<
                (1e3*maxRate) << "/sec rate");
@@ -843,7 +849,7 @@ void
 IpcIoFile::DiskerHandleRequest(const int workerId, IpcIoMsg &ipcIo)
 {
     if (ipcIo.command != IpcIo::cmdRead && ipcIo.command != IpcIo::cmdWrite) {
-        debugs(0, DBG_CRITICAL, HERE << "disker" << KidIdentifier <<
+        debugs(0, DBG_CRITICAL, "ERROR: " << DbName <<
                " should not receive " << ipcIo.command <<
                " ipcIo" << workerId << '.' << ipcIo.requestId);
         return;
@@ -869,41 +875,44 @@ IpcIoFile::DiskerHandleRequest(const int workerId, IpcIoMsg &ipcIo)
         // before push()ing and because if disker pops N requests at a time,
         // we should make sure the worker pop() queue length is the worker
         // push queue length plus N+1. XXX: implement the N+1 difference.
-        debugs(47, DBG_IMPORTANT, "BUG: Worker I/O pop queue overflow: " <<
+        debugs(47, DBG_IMPORTANT, "BUG: Worker I/O pop queue for " <<
+               DbName << " overflow: " <<
                SipcIo(workerId, ipcIo, KidIdentifier)); // TODO: report queue len
 
         // the I/O request we could not push will timeout
     }
 }
 
 static bool
-DiskerOpen(const String &path, int flags, mode_t mode)
+DiskerOpen(const SBuf &path, int flags, mode_t mode)
 {
     assert(TheFile < 0);
 
-    TheFile = file_open(path.termedBuf(), flags);
+    DbName = path;
+    TheFile = file_open(DbName.c_str(), flags);
 
     if (TheFile < 0) {
         const int xerrno = errno;
-        debugs(47, DBG_CRITICAL, HERE << "rock db error opening " << path << ": " <<
+        debugs(47, DBG_CRITICAL, "ERROR: cannot open " << DbName << ": " <<
                xstrerr(xerrno));
         return false;
     }
 
     ++store_open_disk_fd;
-    debugs(79,3, HERE << "rock db opened " << path << ": FD " << TheFile);
+    debugs(79,3, "rock db opened " << DbName << ": FD " << TheFile);
     return true;
 }
 
 static void
-DiskerClose(const String &path)
+DiskerClose(const SBuf &path)
 {
     if (TheFile >= 0) {
         file_close(TheFile);
         debugs(79,3, HERE << "rock db closed " << path << ": FD " << TheFile);
         TheFile = -1;
         --store_open_disk_fd;
     }
+    DbName.clear();
 }
 
 /// reports our needs for shared memory pages to Ipc::Mem::Pages
@@ -11,15 +11,13 @@
 #include "DiskIO/WriteRequest.h"
 #include "globals.h"
 
+#include <cerrno>
 #if HAVE_SYS_MMAN_H
 #include <sys/mman.h>
 #endif
 #if HAVE_SYS_STAT_H
 #include <sys/stat.h>
 #endif
-#if HAVE_ERRNO_H
-#include <errno.h>
-#endif
 
 // Some systems such as Hurd provide mmap() API but do not support MAP_NORESERVE
 #ifndef MAP_NORESERVE
@@ -68,7 +68,7 @@ class ServerStateData: public Ftp::ServerStateData
     void readCwdOrCdupReply();
     void readUserOrPassReply();
 
-    virtual void dataChannelConnected(const Comm::ConnectionPointer &conn, comm_err_t err, int xerrno);
+    virtual void dataChannelConnected(const Comm::ConnectionPointer &conn, Comm::Flag err, int xerrno);
     void scheduleReadControlReply();
 
     bool forwardingCompleted; ///< completeForwarding() has been called
@@ -653,12 +653,12 @@ ServerStateData::readTransferDoneReply()
 }
 
 void
-ServerStateData::dataChannelConnected(const Comm::ConnectionPointer &conn, comm_err_t err, int xerrno)
+ServerStateData::dataChannelConnected(const Comm::ConnectionPointer &conn, Comm::Flag err, int xerrno)
 {
     debugs(9, 3, HERE);
     data.opener = NULL;
 
-    if (err != COMM_OK) {
+    if (err != Comm::OK) {
         debugs(9, 2, HERE << "Failed to connect FTP server data channel.");
         forwardError(ERR_CONNECT_FAIL, xerrno);
         return;
@@ -12,6 +12,7 @@
 #include "StatCounters.h"
 #include "client_side.h"
 #include "comm/ConnOpener.h"
+#include "comm/Read.h"
 #include "comm/TcpAcceptor.h"
 #include "comm/Write.h"
 #include "errorpage.h"
@@ -295,7 +296,7 @@ ServerStateData::readControlReply(const CommIoCbParams &io)
         kb_incr(&(statCounter.server.ftp.kbytes_in), io.size);
     }
 
-    if (io.flag == COMM_ERR_CLOSING)
+    if (io.flag == Comm::ERR_CLOSING)
         return;
 
     if (EBIT_TEST(entry->flags, ENTRY_ABORTED)) {
@@ -305,11 +306,11 @@ ServerStateData::readControlReply(const CommIoCbParams &io)
 
     assert(ctrl.offset < ctrl.size);
 
-    if (io.flag == COMM_OK && io.size > 0) {
+    if (io.flag == Comm::OK && io.size > 0) {
         fd_bytes(io.fd, io.size, FD_READ);
     }
 
-    if (io.flag != COMM_OK) {
+    if (io.flag != Comm::OK) {
         debugs(50, ignoreErrno(io.xerrno) ? 3 : DBG_IMPORTANT,
                "ftpReadControlReply: read error: " << xstrerr(io.xerrno));
 
@@ -695,10 +696,11 @@ ServerStateData::connectDataChannel()
 
     // Generate a new data channel descriptor to be opened.
     Comm::ConnectionPointer conn = new Comm::Connection;
-    conn->local = ctrl.conn->local;
+    conn->setAddrs(ctrl.conn->local, data.host);
     conn->local.port(0);
-    conn->remote = data.host;
     conn->remote.port(data.port);
+    conn->tos = ctrl.conn->tos;
+    conn->nfmark = ctrl.conn->nfmark;
 
     debugs(9, 3, HERE << "connecting to " << conn->remote);
 
@@ -710,7 +712,7 @@ ServerStateData::connectDataChannel()
 }
 
 void
-ServerStateData::dataChannelConnected(const Comm::ConnectionPointer &conn, comm_err_t status, int xerrno, void *data)
+ServerStateData::dataChannelConnected(const Comm::ConnectionPointer &conn, Comm::Flag status, int xerrno, void *data)
 {
     ServerStateData *ftpState = static_cast<ServerStateData *>(data);
     ftpState->dataChannelConnected(conn, status, xerrno);
@@ -787,7 +789,7 @@ ServerStateData::writeCommandCallback(const CommIoCbParams &io)
         kb_incr(&(statCounter.server.ftp.kbytes_out), io.size);
     }
 
-    if (io.flag == COMM_ERR_CLOSING)
+    if (io.flag == Comm::ERR_CLOSING)
         return;
 
     if (io.flag) {
@@ -873,7 +875,7 @@ ServerStateData::dataRead(const CommIoCbParams &io)
         kb_incr(&(statCounter.server.ftp.kbytes_in), io.size);
     }
 
-    if (io.flag == COMM_ERR_CLOSING)
+    if (io.flag == Comm::ERR_CLOSING)
         return;
 
     assert(io.fd == data.conn->fd);
@@ -883,8 +885,8 @@ ServerStateData::dataRead(const CommIoCbParams &io)
         return;
     }
 
-    if (io.flag == COMM_OK && io.size > 0) {
-        debugs(9, 5, HERE << "appended " << io.size << " bytes to readBuf");
+    if (io.flag == Comm::OK && io.size > 0) {
+        debugs(9, 5, "appended " << io.size << " bytes to readBuf");
         data.readBuf->appended(io.size);
 #if USE_DELAY_POOLS
         DelayId delayId = entry->mem_obj->mostBytesAllowed();
@@ -898,7 +900,7 @@ ServerStateData::dataRead(const CommIoCbParams &io)
         ++ IOStats.Ftp.read_hist[bin];
     }
 
-    if (io.flag != COMM_OK) {
+    if (io.flag != Comm::OK) {
         debugs(50, ignoreErrno(io.xerrno) ? 3 : DBG_IMPORTANT,
                HERE << "read error: " << xstrerr(io.xerrno));
 
@@ -140,7 +140,7 @@ class ServerStateData: public ::ServerStateData
     virtual void handleControlReply();
     void writeCommandCallback(const CommIoCbParams &io);
     static CNCB dataChannelConnected;
-    virtual void dataChannelConnected(const Comm::ConnectionPointer &conn, comm_err_t status, int xerrno) = 0;
+    virtual void dataChannelConnected(const Comm::ConnectionPointer &conn, Comm::Flag status, int xerrno) = 0;
     void dataRead(const CommIoCbParams &io);
     void dataComplete();
     AsyncCall::Pointer dataCloser();
@@ -82,9 +82,8 @@
 #include "ssl/ServerBump.h"
 #include "ssl/support.h"
 #endif
-#if HAVE_ERRNO_H
-#include <errno.h>
-#endif
+
+#include <cerrno>
 
 static PSC fwdPeerSelectionCompleteWrapper;
 static CLCB fwdServerClosedWrapper;
@@ -541,7 +540,7 @@ fwdServerClosedWrapper(const CommCloseCbParams &params)
 }
 
 void
-fwdConnectDoneWrapper(const Comm::ConnectionPointer &conn, comm_err_t status, int xerrno, void *data)
+fwdConnectDoneWrapper(const Comm::ConnectionPointer &conn, Comm::Flag status, int xerrno, void *data)
 {
     FwdState *fwd = (FwdState *) data;
     fwd->connectDone(conn, status, xerrno);
@@ -673,9 +672,9 @@ FwdState::handleUnregisteredServerEnd()
 }
 
 void
-FwdState::connectDone(const Comm::ConnectionPointer &conn, comm_err_t status, int xerrno)
+FwdState::connectDone(const Comm::ConnectionPointer &conn, Comm::Flag status, int xerrno)
 {
-    if (status != COMM_OK) {
+    if (status != Comm::OK) {
         ErrorState *const anErr = makeConnectingError(ERR_CONNECT_FAIL);
         anErr->xerrno = xerrno;
         fail(anErr);
@@ -711,8 +710,10 @@ FwdState::connectDone(const Comm::ConnectionPointer &conn, comm_err_t status, in
             AsyncCall::Pointer callback = asyncCall(17,4,
                                                     "FwdState::ConnectedToPeer",
                                                     FwdStatePeerAnswerDialer(&FwdState::connectedToPeer, this));
+            // Use positive timeout when less than one second is left.
+            const time_t sslNegotiationTimeout = max(static_cast<time_t>(1), timeLeft());
             Ssl::PeerConnector *connector =
-                new Ssl::PeerConnector(requestPointer, serverConnection(), callback);
+                new Ssl::PeerConnector(requestPointer, serverConnection(), callback, sslNegotiationTimeout);
             AsyncJob::Start(connector); // will call our callback
             return;
         }
@@ -769,21 +770,9 @@ FwdState::connectTimeout(int fd)
     }
 }
 
-/**
- * Called after Forwarding path selection (via peer select) has taken place.
- * And whenever forwarding needs to attempt a new connection (routing failover)
- * We have a vector of possible localIP->remoteIP paths now ready to start being connected.
- */
-void
-FwdState::connectStart()
+time_t
+FwdState::timeLeft() const
 {
-    assert(serverDestinations.size() > 0);
-
-    debugs(17, 3, "fwdConnectStart: " << entry->url());
-
-    if (!request->hier.first_conn_start.tv_sec) // first attempt
-        request->hier.first_conn_start = current_time;
-
     /* connection timeout */
     int ctimeout;
     if (serverDestinations[0]->getPeer()) {
@@ -799,7 +788,25 @@ FwdState::connectStart()
         ftimeout = 5;
 
     if (ftimeout < ctimeout)
-        ctimeout = ftimeout;
+        return (time_t)ftimeout;
+    else
+        return (time_t)ctimeout;
+}
+
+/**
+ * Called after forwarding path selection (via peer select) has taken place
+ * and whenever forwarding needs to attempt a new connection (routing failover).
+ * We have a vector of possible localIP->remoteIP paths now ready to start being connected.
+ */
+void
+FwdState::connectStart()
+{
+    assert(serverDestinations.size() > 0);
+
+    debugs(17, 3, "fwdConnectStart: " << entry->url());
+
+    if (!request->hier.first_conn_start.tv_sec) // first attempt
+        request->hier.first_conn_start = current_time;
 
     if (serverDestinations[0]->getPeer() && request->flags.sslBumped) {
         debugs(50, 4, "fwdConnectStart: Ssl bumped connections through parent proxy are not allowed");
@@ -830,6 +837,20 @@ FwdState::connectStart()
             if (pinned_connection->pinnedAuth())
                 request->flags.auth = true;
             comm_add_close_handler(serverConn->fd, fwdServerClosedWrapper, this);
+
+            /* Update server side TOS and Netfilter mark on the connection. */
+            if (Ip::Qos::TheConfig.isAclTosActive()) {
+                debugs(17, 3, HERE << "setting tos for pinned connection to " << (int)serverConn->tos );
+                serverConn->tos = GetTosToServer(request);
+                Ip::Qos::setSockTos(serverConn, serverConn->tos);
+            }
+#if SO_MARK
+            if (Ip::Qos::TheConfig.isAclNfmarkActive()) {
+                serverConn->nfmark = GetNfmarkToServer(request);
+                Ip::Qos::setSockNfmark(serverConn, serverConn->nfmark);
+            }
+#endif
+
             // the server may close the pinned connection before this request
             pconnRace = racePossible;
             dispatch();
@@ -896,7 +917,7 @@ FwdState::connectStart()
     GetMarkingsToServer(request, *serverDestinations[0]);
 
     calls.connector = commCbCall(17,3, "fwdConnectDoneWrapper", CommConnectCbPtrFun(fwdConnectDoneWrapper, this));
-    Comm::ConnOpener *cs = new Comm::ConnOpener(serverDestinations[0], calls.connector, ctimeout);
+    Comm::ConnOpener *cs = new Comm::ConnOpener(serverDestinations[0], calls.connector, timeLeft());
     if (host)
         cs->setHost(host);
     AsyncJob::Start(cs);
@@ -73,8 +73,9 @@ class FwdState : public RefCountable
     bool reforwardableStatus(const Http::StatusCode s) const;
     void serverClosed(int fd);
     void connectStart();
-    void connectDone(const Comm::ConnectionPointer & conn, comm_err_t status, int xerrno);
+    void connectDone(const Comm::ConnectionPointer & conn, Comm::Flag status, int xerrno);
     void connectTimeout(int fd);
+    time_t timeLeft() const; ///< the time left before the forwarding timeout expired
     bool checkRetry();
     bool checkRetriable();
     void dispatch();
@@ -111,6 +111,7 @@ static const HttpHeaderFieldAttrs HeadersAttrs[] = {
     {"ETag", HDR_ETAG, ftETag},
     {"Expect", HDR_EXPECT, ftStr},
     {"Expires", HDR_EXPIRES, ftDate_1123},
+    {"Forwarded", HDR_FORWARDED, ftStr},
     {"From", HDR_FROM, ftStr},
     {"Host", HDR_HOST, ftStr},
     {"HTTP2-Settings", HDR_HTTP2_SETTINGS, ftStr}, /* for now */
@@ -221,6 +222,7 @@ static http_hdr_type ListHeadersArr[] = {
 #endif
     HDR_SURROGATE_CAPABILITY,
     HDR_SURROGATE_CONTROL,
+    HDR_FORWARDED,
     HDR_X_FORWARDED_FOR
 };
 
@@ -272,7 +274,7 @@ static http_hdr_type RequestHeadersArr[] = {
     HDR_ORIGIN,
     HDR_PROXY_CONNECTION,
     HDR_PROXY_AUTHORIZATION, HDR_RANGE, HDR_REFERER, HDR_REQUEST_RANGE,
-    HDR_USER_AGENT, HDR_X_FORWARDED_FOR, HDR_SURROGATE_CAPABILITY
+    HDR_USER_AGENT, HDR_FORWARDED, HDR_X_FORWARDED_FOR, HDR_SURROGATE_CAPABILITY
 };
 
 static HttpHeaderMask HopByHopHeadersMask;
@@ -83,6 +83,7 @@ typedef enum {
     HDR_ETAG,                           /**< RFC 2608, 2616 */
     HDR_EXPECT,                         /**< RFC 2616, 2616 */
     HDR_EXPIRES,                        /**< RFC 2608, 2616 */
+    HDR_FORWARDED,                      /**< RFC 7239 */
     HDR_FROM,                           /**< RFC 2608, 2616 */
     HDR_HOST,                           /**< RFC 2608, 2616 */
     HDR_HTTP2_SETTINGS,                 /**< HTTP/2.0 upgrade header. see draft-ietf-httpbis-http2-04 */
@@ -137,7 +138,7 @@ typedef enum {
     HDR_AUTHENTICATION_INFO,            /**< RFC 2617 */
     HDR_X_CACHE,                        /**< Squid custom header */
     HDR_X_CACHE_LOOKUP,	                /**< Squid custom header. temporary hack that became de-facto. TODO remove */
-    HDR_X_FORWARDED_FOR,                /**< Squid custom header */
+    HDR_X_FORWARDED_FOR,                /**< obsolete Squid custom header */
     HDR_X_REQUEST_URI,                  /**< Squid custom header appended if ADD_X_REQUEST_URI is defined */
     HDR_X_SQUID_ERROR,                  /**< Squid custom header on generated error responses */
 #if X_ACCELERATOR_VARY
@@ -55,10 +55,8 @@
 #endif
 
 #include <algorithm>
+#include <cerrno>
 #include <string>
-#if HAVE_ERRNO_H
-#include <errno.h>
-#endif
 
 static void httpHeaderPutStrvf(HttpHeader * hdr, http_hdr_type id, const char *fmt, va_list vargs);
 
@@ -68,7 +68,7 @@ class HttpMsg : public RefCountable
 
 public:
     /// HTTP-Version field in the first line of the message.
-    /// see draft-ietf-httpbis-p1-messaging-26 section 3.1
+    /// see RFC 7230 section 3.1
     Http::ProtocolVersion http_ver;
 
     HttpHeader header;
@@ -26,6 +26,7 @@ typedef enum {
     LOG_TCP_DENIED_REPLY,
     LOG_TCP_OFFLINE_HIT,
     LOG_TCP_REDIRECT,
+    LOG_TCP_TUNNEL,             // a binary tunnel was established for this transaction
     LOG_UDP_HIT,
     LOG_UDP_MISS,
     LOG_UDP_DENIED,
@@ -46,8 +46,8 @@ LOADABLE_MODULES_SOURCES = \
 	LoadableModules.h \
 	LoadableModules.cc
 
-SUBDIRS	= base anyp comm eui acl format fs repl
-DIST_SUBDIRS = base anyp comm eui acl format fs repl
+SUBDIRS	= base anyp parser comm eui acl format fs repl
+DIST_SUBDIRS = base anyp parser comm eui acl format fs repl
 
 if ENABLE_AUTH
 SUBDIRS += auth
@@ -234,7 +234,7 @@ cf_gen_LDADD=
 cf_gen.$(OBJEXT): cf_gen_defines.cci
 
 ## cf_gen.cc needs src/cf_gen_defines.cci
-INCLUDES += -I$(top_builddir)/src
+AM_CPPFLAGS += -I$(top_builddir)/src
 
 
 ACL_REGISTRATION_SOURCES = AclRegs.cc AuthReg.cc
@@ -264,7 +264,6 @@ DiskIO/DiskIOModules_gen.cc: Makefile
 libsquid_la_SOURCES = \
 	comm.cc \
 	comm.h \
-	comm_err_t.h \
 	CommCalls.cc \
 	CommCalls.h \
 	DescriptorSet.cc \
@@ -651,6 +650,7 @@ squid_LDADD = \
 	$(ADAPTATION_LIBS) \
 	$(ESI_LIBS) \
 	$(SNMP_LIBS) \
+	parser/libsquid-parser.la \
 	$(top_builddir)/lib/libmisccontainers.la \
 	$(top_builddir)/lib/libmiscencoding.la \
 	$(top_builddir)/lib/libmiscutil.la \
@@ -690,11 +690,11 @@ squid_LDFLAGS = -export-dynamic -dlopen force
 ## squid_LDFLAGS = -all-static -dlopen self
 ##
 ## LTDL headers require their local include path...
-INCLUDES += $(INCLTDL)
+AM_CPPFLAGS += $(INCLTDL)
 endif
 
 ## Kerberos libraries require their include path...
-INCLUDES += $(KRB5INCS)
+AM_CPPFLAGS += $(KRB5INCS)
 
 
 unlinkd_SOURCES = unlinkd_daemon.cc
@@ -973,7 +973,7 @@ cache_cf.o: cf_parser.cci
 
 # cf_gen builds the configuration files.
 cf_gen$(EXEEXT): $(cf_gen_SOURCES) $(cf_gen_DEPENDENCIES) cf_gen_defines.cci
-	$(HOSTCXX) -o $@ $(srcdir)/cf_gen.cc -I$(srcdir) -I$(top_builddir)/include/ -I$(top_builddir)/src
+	$(BUILDCXX) $(BUILDCXXFLAGS) -o $@ $(srcdir)/cf_gen.cc -I$(srcdir) -I$(top_builddir)/include/ -I$(top_builddir)/src
 
 # squid.conf.default is built by cf_gen when making cf_parser.cci
 squid.conf.default squid.conf.documented: cf_parser.cci
@@ -1152,6 +1152,8 @@ tests_testHttpReply_SOURCES=\
 	HttpMsg.h \
 	HttpReply.cc \
 	HttpReply.h \
+	MasterXaction.cc \
+	MasterXaction.h \
 	Mem.h \
 	tests/stub_mem.cc \
 	RegexList.h \
@@ -1178,11 +1180,17 @@ tests_testHttpReply_SOURCES=\
 	YesNoNone.h \
 	tests/stub_cache_cf.cc \
 	tests/stub_cache_manager.cc \
+	tests/stub_comm.cc \
 	tests/stub_debug.cc \
 	tests/stub_errorpage.cc \
+	tests/stub_event.cc \
+	tests/stub_fd.cc \
 	tests/stub_HelperChildConfig.cc \
 	tests/stub_libformat.cc \
 	tests/stub_libauth.cc \
+	tests/stub_libcomm.cc \
+	tests/stub_libmgr.cc \
+	tests/stub_libsslsquid.cc \
 	StatCounters.h \
 	StatCounters.cc \
 	StatHist.h \
@@ -1204,14 +1212,15 @@ nodist_tests_testHttpReply_SOURCES=\
 	$(TESTSOURCES)
 tests_testHttpReply_LDFLAGS = $(LIBADD_DL)
 tests_testHttpReply_LDADD=\
+	CommCalls.o \
 	http/libsquid-http.la \
 	acl/libacls.la \
 	acl/libapi.la \
 	acl/libstate.la \
 	anyp/libanyp.la \
 	ip/libip.la \
 	base/libbase.la \
-	$(SSL_LIBS) \
+	ipc/libipc.la \
 	$(top_builddir)/lib/libmisccontainers.la \
 	$(top_builddir)/lib/libmiscencoding.la \
 	$(top_builddir)/lib/libmiscutil.la \
@@ -1373,12 +1382,16 @@ tests_testBoilerplate_SOURCES = \
 	tests/testBoilerplate.cc \
 	tests/testMain.cc \
 	tests/testBoilerplate.h \
+	tests/stub_debug.cc \
 	tests/stub_time.cc
 nodist_tests_testBoilerplate_SOURCES = \
+	tests/stub_cbdata.cc \
+	tests/stub_MemBuf.cc \
 	$(TESTSOURCES)
 tests_testBoilerplate_LDADD= \
 	$(SQUID_CPPUNIT_LIBS) \
 	$(SSLLIB) \
+	base/libbase.la \
 	$(COMPAT_LIB) \
 	$(XTRA_LIBS)
 tests_testBoilerplate_LDFLAGS = $(LIBADD_DL)
@@ -1794,14 +1807,14 @@ tests_testDiskIO_LDADD = \
 	acl/libstate.la \
 	libsquid.la \
 	comm/libcomm.la \
-	anyp/libanyp.la \
 	ip/libip.la \
 	fs/libfs.la \
 	ipc/libipc.la \
 	$(REPL_OBJS) \
 	$(DISK_LIBS) \
 	$(DISK_OS_LIBS) \
 	acl/libapi.la \
+	anyp/libanyp.la \
 	mgr/libmgr.la \
 	$(SSL_LIBS) \
 	ipc/libipc.la \
@@ -2974,6 +2987,7 @@ tests_testStore_SOURCES= \
 	tests/stub_libauth.cc \
 	tests/stub_libeui.cc \
 	tests/stub_libformat.cc \
+	tests/stub_libsslsquid.cc \
 	HttpBody.h \
 	HttpBody.cc \
 	tests/stub_HttpReply.cc \
@@ -3028,7 +3042,6 @@ tests_testStore_LDADD= \
 	ip/libip.la \
 	fs/libfs.la \
 	mgr/libmgr.la \
-	$(SSL_LIBS) \
 	ipc/libipc.la \
 	anyp/libanyp.la \
 	$(top_builddir)/lib/libmisccontainers.la \
@@ -3437,7 +3450,6 @@ tests_testRock_LDADD = \
 	http/libsquid-http.la \
 	libsquid.la \
 	comm/libcomm.la \
-	anyp/libanyp.la \
 	ip/libip.la \
 	fs/libfs.la \
 	$(COMMON_LIBS) \
@@ -3447,6 +3459,7 @@ tests_testRock_LDADD = \
 	acl/libacls.la \
 	acl/libapi.la \
 	acl/libstate.la \
+	anyp/libanyp.la \
 	eui/libeui.la \
 	$(SSL_LIBS) \
 	ipc/libipc.la \
@@ -3460,7 +3473,7 @@ tests_testRock_LDADD = \
 	$(SSLLIB) \
 	$(COMPAT_LIB) \
 	$(XTRA_LIBS)
-tests_testRock_LDFLAGS = $(INCLUDES) $(LIBADD_DL)
+tests_testRock_LDFLAGS = $(AM_CPPFLAGS) $(LIBADD_DL)
 tests_testRock_DEPENDENCIES = \
 	$(SWAP_TEST_DS)
 
@@ -2,7 +2,6 @@
 #define SQUID_SRC_MASTERXACTION_H
 
 #include "anyp/forward.h"
-#include "base/CbcPointer.h"
 #include "base/InstanceId.h"
 #include "base/Lock.h"
 #include "comm/forward.h"
@@ -18,9 +18,11 @@
 #include "tools.h"
 
 /// shared memory segment path to use for MemStore maps
-static const char *MapLabel = "cache_mem_map";
+static const SBuf MapLabel("cache_mem_map");
 /// shared memory segment path to use for the free slices index
 static const char *SpaceLabel = "cache_mem_space";
+/// shared memory segment path to use for IDs of shared pages with slice data
+static const char *ExtrasLabel = "cache_mem_ex";
 // TODO: sync with Rock::SwapDir::*Path()
 
 // We store free slot IDs (i.e., "space") as Page objects so that we can use
@@ -61,6 +63,7 @@ MemStore::init()
     }
 
     freeSlots = shm_old(Ipc::Mem::PageStack)(SpaceLabel);
+    extras = shm_old(Extras)(ExtrasLabel);
 
     Must(!map);
     map = new MemStoreMap(MapLabel);
@@ -91,21 +94,25 @@ MemStore::stat(StoreEntry &e) const
                       Math::doublePercent(currentSize(), maxSize()));
 
     if (map) {
-        const int limit = map->entryLimit();
-        storeAppendPrintf(&e, "Maximum entries: %9d\n", limit);
-        if (limit > 0) {
+        const int entryLimit = map->entryLimit();
+        const int slotLimit = map->sliceLimit();
+        storeAppendPrintf(&e, "Maximum entries: %9d\n", entryLimit);
+        if (entryLimit > 0) {
             storeAppendPrintf(&e, "Current entries: %" PRId64 " %.2f%%\n",
-                              currentCount(), (100.0 * currentCount() / limit));
+                              currentCount(), (100.0 * currentCount() / entryLimit));
+        }
 
+        storeAppendPrintf(&e, "Maximum slots:   %9d\n", slotLimit);
+        if (slotLimit > 0) {
             const unsigned int slotsFree =
                 Ipc::Mem::PagesAvailable(Ipc::Mem::PageId::cachePage);
-            if (slotsFree <= static_cast<const unsigned int>(limit)) {
-                const int usedSlots = limit - static_cast<const int>(slotsFree);
+            if (slotsFree <= static_cast<const unsigned int>(slotLimit)) {
+                const int usedSlots = slotLimit - static_cast<const int>(slotsFree);
                 storeAppendPrintf(&e, "Used slots:      %9d %.2f%%\n",
-                                  usedSlots, (100.0 * usedSlots / limit));
+                                  usedSlots, (100.0 * usedSlots / slotLimit));
             }
 
-            if (limit < 100) { // XXX: otherwise too expensive to count
+            if (slotLimit < 100) { // XXX: otherwise too expensive to count
                 Ipc::ReadWriteLockStats stats;
                 map->updateStats(stats);
                 stats.dump(e);
@@ -323,15 +330,16 @@ MemStore::copyFromShm(StoreEntry &e, const sfileno index, const Ipc::StoreMapAnc
             const size_t prefixSize = e.mem_obj->endOffset() - sliceOffset;
             assert(prefixSize <= wasSize);
 
-            const MemStoreMap::Extras &extras = map->extras(sid);
-            char *page = static_cast<char*>(PagePointer(extras.page));
+            const MemStoreMapExtras::Item &extra = extras->items[sid];
+
+            char *page = static_cast<char*>(PagePointer(extra.page));
             const StoreIOBuffer sliceBuf(wasSize - prefixSize,
                                          e.mem_obj->endOffset(),
                                          page + prefixSize);
             if (!copyFromShmSlice(e, sliceBuf, wasEof))
                 return false;
             debugs(20, 9, "entry " << index << " copied slice " << sid <<
-                   " from " << extras.page << " +" << prefixSize);
+                   " from " << extra.page << '+' << prefixSize);
         }
         // else skip a [possibly incomplete] slice that we copied earlier
 
@@ -411,7 +419,7 @@ MemStore::copyFromShmSlice(StoreEntry &e, const StoreIOBuffer &buf, bool eof)
 
 /// whether we should cache the entry
 bool
-MemStore::shouldCache(const StoreEntry &e) const
+MemStore::shouldCache(StoreEntry &e) const
 {
     if (e.mem_status == IN_MEMORY) {
         debugs(20, 5, "already loaded from mem-cache: " << e);
@@ -453,6 +461,11 @@ MemStore::shouldCache(const StoreEntry &e) const
         return false; // will not cache due to cachable entry size limits
     }
 
+    if (!e.mem_obj->isContiguous()) {
+        debugs(20, 5, "not contiguous");
+        return false;
+    }
+
     if (!map) {
         debugs(20, 5, HERE << "No map to mem-cache " << e);
         return false;
@@ -482,6 +495,7 @@ MemStore::startCaching(StoreEntry &e)
     e.mem_obj->memCache.io = MemObject::ioWriting;
     slot->set(e);
     map->startAppending(index);
+    e.memOutDecision(true);
     return true;
 }
 
@@ -513,7 +527,7 @@ MemStore::copyToShm(StoreEntry &e)
     if (anchor.start < 0) { // must allocate the very first slot for e
         Ipc::Mem::PageId page;
         anchor.start = reserveSapForWriting(page); // throws
-        map->extras(anchor.start).page = page;
+        extras->items[anchor.start].page = page;
     }
 
     lastWritingSlice = anchor.start;
@@ -533,7 +547,7 @@ MemStore::copyToShm(StoreEntry &e)
 
             Ipc::Mem::PageId page;
             slice.next = lastWritingSlice = reserveSapForWriting(page);
-            map->extras(lastWritingSlice).page = page;
+            extras->items[lastWritingSlice].page = page;
             debugs(20, 7, "entry " << index << " new slice: " << lastWritingSlice);
         }
 
@@ -550,7 +564,7 @@ MemStore::copyToShmSlice(StoreEntry &e, Ipc::StoreMapAnchor &anchor)
     Ipc::StoreMap::Slice &slice =
         map->writeableSlice(e.mem_obj->memCache.index, lastWritingSlice);
 
-    Ipc::Mem::PageId page = map->extras(lastWritingSlice).page;
+    Ipc::Mem::PageId page = extras->items[lastWritingSlice].page;
     assert(lastWritingSlice >= 0 && page);
     debugs(20, 7, "entry " << e << " slice " << lastWritingSlice << " has " <<
            page);
@@ -614,9 +628,9 @@ MemStore::reserveSapForWriting(Ipc::Mem::PageId &page)
 }
 
 void
-MemStore::noteFreeMapSlice(const sfileno sliceId)
+MemStore::noteFreeMapSlice(const Ipc::StoreMapSliceId sliceId)
 {
-    Ipc::Mem::PageId &pageId = map->extras(sliceId).page;
+    Ipc::Mem::PageId &pageId = extras->items[sliceId].page;
     debugs(20, 9, "slice " << sliceId << " freed " << pageId);
     assert(pageId);
     Ipc::Mem::PageId slotId;
@@ -646,7 +660,7 @@ MemStore::write(StoreEntry &e)
     case MemObject::ioUndecided:
         if (!shouldCache(e) || !startCaching(e)) {
             e.mem_obj->memCache.io = MemObject::ioDone;
-            Store::Root().transientsAbandon(e);
+            e.memOutDecision(false);
             return;
         }
         break;
@@ -753,7 +767,7 @@ class MemStoreRr: public Ipc::Mem::RegisteredRunner
 {
 public:
     /* RegisteredRunner API */
-    MemStoreRr(): spaceOwner(NULL), mapOwner(NULL) {}
+    MemStoreRr(): spaceOwner(NULL), mapOwner(NULL), extrasOwner(NULL) {}
     virtual void finalizeConfig();
     virtual void claimMemoryNeeds();
     virtual void useConfig();
@@ -766,6 +780,7 @@ class MemStoreRr: public Ipc::Mem::RegisteredRunner
 private:
     Ipc::Mem::Owner<Ipc::Mem::PageStack> *spaceOwner; ///< free slices Owner
     MemStoreMap::Owner *mapOwner; ///< primary map Owner
+    Ipc::Mem::Owner<MemStoreMapExtras> *extrasOwner; ///< PageIds Owner
 };
 
 RunnerRegistrationEntry(MemStoreRr);
@@ -820,14 +835,16 @@ MemStoreRr::create()
 
     Must(!spaceOwner);
     spaceOwner = shm_new(Ipc::Mem::PageStack)(SpaceLabel, SpacePoolId,
-                 entryLimit,
-                 sizeof(Ipc::Mem::PageId));
+                 entryLimit, 0);
     Must(!mapOwner);
     mapOwner = MemStoreMap::Init(MapLabel, entryLimit);
+    Must(!extrasOwner);
+    extrasOwner = shm_new(MemStoreMapExtras)(ExtrasLabel, entryLimit);
 }
 
 MemStoreRr::~MemStoreRr()
 {
+    delete extrasOwner;
     delete mapOwner;
     delete spaceOwner;
 }
@@ -7,10 +7,11 @@
 #include "Store.h"
 
 // StoreEntry restoration info not already stored by Ipc::StoreMap
-struct MemStoreMapExtras {
+struct MemStoreMapExtraItem {
     Ipc::Mem::PageId page; ///< shared memory page with entry slice content
 };
-typedef Ipc::StoreMapWithExtras<MemStoreMapExtras> MemStoreMap;
+typedef Ipc::StoreMapItems<MemStoreMapExtraItem> MemStoreMapExtras;
+typedef Ipc::StoreMap MemStoreMap;
 
 /// Stores HTTP entities in RAM. Current implementation uses shared memory.
 /// Unlike a disk store (SwapDir), operations are synchronous (and fast).
@@ -58,7 +59,7 @@ class MemStore: public Store, public Ipc::StoreMapCleaner
     static int64_t EntryLimit();
 
 protected:
-    bool shouldCache(const StoreEntry &e) const;
+    bool shouldCache(StoreEntry &e) const;
     bool startCaching(StoreEntry &e);
 
     void copyToShm(StoreEntry &e);
@@ -72,13 +73,16 @@ class MemStore: public Store, public Ipc::StoreMapCleaner
     sfileno reserveSapForWriting(Ipc::Mem::PageId &page);
 
     // Ipc::StoreMapCleaner API
-    virtual void noteFreeMapSlice(const sfileno sliceId);
+    virtual void noteFreeMapSlice(const Ipc::StoreMapSliceId sliceId);
 
 private:
     // TODO: move freeSlots into map
     Ipc::Mem::Pointer<Ipc::Mem::PageStack> freeSlots; ///< unused map slot IDs
     MemStoreMap *map; ///< index of mem-cached entries
 
+    typedef MemStoreMapExtras Extras;
+    Ipc::Mem::Pointer<Extras> extras; ///< IDs of pages with slice data
+
     /// the last allocate slice for writing a store entry (during copyToShm)
     sfileno lastWritingSlice;
 
@@ -31,6 +31,7 @@
 #include "AccessLogEntry.h"
 #include "acl/FilledChecklist.h"
 #include "acl/Gadgets.h"
+#include "client_side.h"
 #include "ConfigParser.h"
 #include "globals.h"
 #include "HttpReply.h"
@@ -202,6 +203,20 @@ NotePairs::add(const char *key, const char *note)
     entries.push_back(new NotePairs::Entry(key, note));
 }
 
+void
+NotePairs::remove(const char *key)
+{
+    std::vector<NotePairs::Entry *>::iterator i = entries.begin();
+    while (i != entries.end()) {
+        if ((*i)->name.cmp(key) == 0) {
+            delete *i;
+            i = entries.erase(i);
+        } else {
+            ++i;
+        }
+    }
+}
+
 void
 NotePairs::addStrList(const char *key, const char *values)
 {
@@ -243,6 +258,15 @@ NotePairs::appendNewOnly(const NotePairs *src)
     }
 }
 
+void
+NotePairs::replaceOrAdd(const NotePairs *src)
+{
+    for (std::vector<NotePairs::Entry *>::const_iterator  i = src->entries.begin(); i != src->entries.end(); ++i) {
+        remove((*i)->name.termedBuf());
+    }
+    append(src);
+}
+
 NotePairs &
 SyncNotes(AccessLogEntry &ale, HttpRequest &request)
 {
@@ -258,3 +282,16 @@ SyncNotes(AccessLogEntry &ale, HttpRequest &request)
     }
     return *ale.notes;
 }
+
+void
+UpdateRequestNotes(ConnStateData *csd, HttpRequest &request, NotePairs const &helperNotes)
+{
+    // Tag client connection if the helper responded with clt_conn_tag=tag.
+    if (const char *connTag = helperNotes.findFirst("clt_conn_tag")) {
+        if (csd)
+            csd->connectionTag(connTag);
+    }
+    if (!request.notes)
+        request.notes = new NotePairs;
+    request.notes->replaceOrAdd(&helperNotes);
+}
@@ -135,6 +135,12 @@ class NotePairs: public RefCountable
      */
     void append(const NotePairs *src);
 
+    /**
+     * Replace existing list entries with the src NotePairs entries.
+     * Entries which do not exist in the destination set are added.
+     */
+    void replaceOrAdd(const NotePairs *src);
+
     /**
      * Append any new entries of the src NotePairs list to our list.
      * Entries which already exist in the destination set are ignored.
@@ -159,6 +165,11 @@ class NotePairs: public RefCountable
      */
     void add(const char *key, const char *value);
 
+    /**
+     * Remove all notes with a given key.
+     */
+    void remove(const char *key);
+
     /**
      * Adds a note key and values strList to the notes list.
      * If the key name already exists in list, add the new values to its set
@@ -197,4 +208,9 @@ class AccessLogEntry;
  */
 NotePairs &SyncNotes(AccessLogEntry &ale, HttpRequest &request);
 
+class ConnStateData;
+/**
+ * Updates ConnStateData ids and HttpRequest notes from helpers received notes.
+ */
+void UpdateRequestNotes(ConnStateData *csd, HttpRequest &request, NotePairs const &notes);
 #endif
@@ -13,6 +13,7 @@
 #include "pconn.h"
 #include "PeerPoolMgr.h"
 #include "SquidConfig.h"
+#include "SquidTime.h"
 #if USE_OPENSSL
 #include "ssl/PeerConnector.h"
 #endif
@@ -91,7 +92,7 @@ PeerPoolMgr::handleOpenedConnection(const CommConnectCbParams &params)
         return;
     }
 
-    if (params.flag != COMM_OK) {
+    if (params.flag != Comm::OK) {
         /* it might have been a timeout with a partially open link */
         if (params.conn != NULL)
             params.conn->close();
@@ -112,8 +113,14 @@ PeerPoolMgr::handleOpenedConnection(const CommConnectCbParams &params)
 
         securer = asyncCall(48, 4, "PeerPoolMgr::handleSecuredPeer",
                             MyAnswerDialer(this, &PeerPoolMgr::handleSecuredPeer));
+
+        const int peerTimeout = peer->connect_timeout > 0 ?
+                                peer->connect_timeout : Config.Timeout.peer_connect;
+        const int timeUsed = squid_curtime - params.conn->startTime();
+        // Use positive timeout when less than one second is left for conn.
+        const int timeLeft = max(1, (peerTimeout - timeUsed));
         Ssl::PeerConnector *connector =
-            new Ssl::PeerConnector(request, params.conn, securer);
+            new Ssl::PeerConnector(request, params.conn, securer, timeLeft);
         AsyncJob::Start(connector); // will call our callback
         return;
     }
@@ -376,7 +376,7 @@ ServerStateData::sentRequestBody(const CommIoCbParams &io)
         // kids should increment their counters
     }
 
-    if (io.flag == COMM_ERR_CLOSING)
+    if (io.flag == Comm::ERR_CLOSING)
         return;
 
     if (!requestBodySource) {
@@ -137,13 +137,6 @@ class SquidConfig
 #endif
     } Port;
 
-    struct {
-        AnyP::PortCfg *http;
-#if USE_OPENSSL
-        AnyP::PortCfg *https;
-#endif
-        AnyP::PortCfg *ftp;
-    } Sockaddr;
 #if SQUID_SNMP
 
     struct {
@@ -102,6 +102,12 @@ class StoreEntry : public hash_link
     /// whether we may start writing to disk (now or in the future)
     virtual bool mayStartSwapOut();
     virtual void trimMemory(const bool preserveSwappable);
+
+    // called when a decision to cache in memory has been made
+    void memOutDecision(const bool willCacheInRam);
+    // called when a decision to cache on disk has been made
+    void swapOutDecision(const MemObject::SwapOut::Decision &decision);
+
     void abort();
     void unlink();
     void makePublic();
@@ -120,11 +126,14 @@ class StoreEntry : public hash_link
     bool swappingOut() const { return swap_status == SWAPOUT_WRITING; }
     void swapOutFileClose(int how);
     const char *url() const;
-    int checkCachable();
+    /// Satisfies cachability requirements shared among disk and RAM caches.
+    /// Encapsulates common checks of mayStartSwapOut() and memoryCachable().
+    /// TODO: Rename and make private so only those two methods can call this.
+    bool checkCachable();
     int checkNegativeHit() const;
     int locked() const;
     int validToSend() const;
-    bool memoryCachable() const; ///< may be cached in memory
+    bool memoryCachable(); ///< checkCachable() and can be cached in memory
 
     /// if needed, initialize mem_obj member w/o URI-related information
     MemObject *makeMemObject();
@@ -231,6 +240,9 @@ class StoreEntry : public hash_link
     void kickProducer();
 #endif
 
+protected:
+    void transientsAbandonmentCheck();
+
 private:
     static MemAllocator *pool;
 
@@ -272,7 +284,7 @@ class NullStoreEntry:public StoreEntry
     store_client_t storeClientType() const {return STORE_MEM_CLIENT;}
 
     char const *getSerialisedMetaData();
-    bool mayStartSwapout() {return false;}
+    virtual bool mayStartSwapOut() { return false; }
 
     void trimMemory(const bool preserveSwappable) {}
 
@@ -102,7 +102,7 @@ class store_client
     void scheduleDiskRead();
     void scheduleMemRead();
     void scheduleRead();
-    void startSwapin();
+    bool startSwapin();
     void unpackHeader(char const *buf, ssize_t len);
 
     int type;
@@ -104,7 +104,7 @@ class StoreController : public Store
 private:
     void createOneStore(Store &aStore);
     StoreEntry *find(const cache_key *key);
-    bool keepForLocalMemoryCache(const StoreEntry &e) const;
+    bool keepForLocalMemoryCache(StoreEntry &e) const;
     bool anchorCollapsed(StoreEntry &collapsed, bool &inSync);
     bool anchorCollapsedOnDisk(StoreEntry &collapsed, bool &inSync);
 
@@ -19,8 +19,10 @@
 
 #include <limits>
 
-/// shared memory segment path to use for Transients maps
-static const char *MapLabel = "transients_map";
+/// shared memory segment path to use for Transients map
+static const SBuf MapLabel("transients_map");
+/// shared memory segment path to use for Transients map extras
+static const char *ExtrasLabel = "transients_ex";
 
 Transients::Transients(): map(NULL), locals(NULL)
 {
@@ -43,6 +45,8 @@ Transients::init()
     map = new TransientsMap(MapLabel);
     map->cleaner = this;
 
+    extras = shm_old(TransientsMapExtras)(ExtrasLabel);
+
     locals = new Locals(entryLimit, 0);
 }
 
@@ -177,14 +181,14 @@ Transients::get(const cache_key *key)
 StoreEntry *
 Transients::copyFromShm(const sfileno index)
 {
-    const TransientsMap::Extras &extras = map->extras(index);
+    const TransientsMapExtras::Item &extra = extras->items[index];
 
     // create a brand new store entry and initialize it with stored info
-    StoreEntry *e = storeCreatePureEntry(extras.url, extras.url,
-                                         extras.reqFlags, extras.reqMethod);
+    StoreEntry *e = storeCreatePureEntry(extra.url, extra.url,
+                                         extra.reqFlags, extra.reqMethod);
 
     assert(e->mem_obj);
-    e->mem_obj->method = extras.reqMethod;
+    e->mem_obj->method = extra.reqMethod;
     e->mem_obj->xitTable.io = MemObject::ioReading;
     e->mem_obj->xitTable.index = index;
 
@@ -271,24 +275,24 @@ Transients::copyToShm(const StoreEntry &e, const sfileno index,
                       const RequestFlags &reqFlags,
                       const HttpRequestMethod &reqMethod)
 {
-    TransientsMap::Extras &extras = map->extras(index);
+    TransientsMapExtras::Item &extra = extras->items[index];
 
     const char *url = e.url();
     const size_t urlLen = strlen(url);
-    Must(urlLen < sizeof(extras.url)); // we have space to store it all, plus 0
-    strncpy(extras.url, url, sizeof(extras.url));
-    extras.url[urlLen] = '\0';
+    Must(urlLen < sizeof(extra.url)); // we have space to store it all, plus 0
+    strncpy(extra.url, url, sizeof(extra.url));
+    extra.url[urlLen] = '\0';
 
-    extras.reqFlags = reqFlags;
+    extra.reqFlags = reqFlags;
 
     Must(reqMethod != Http::METHOD_OTHER);
-    extras.reqMethod = reqMethod.id();
+    extra.reqMethod = reqMethod.id();
 
     return true;
 }
 
 void
-Transients::noteFreeMapSlice(const sfileno sliceId)
+Transients::noteFreeMapSlice(const Ipc::StoreMapSliceId sliceId)
 {
     // TODO: we should probably find the entry being deleted and abort it
 }
@@ -383,7 +387,7 @@ class TransientsRr: public Ipc::Mem::RegisteredRunner
 {
 public:
     /* RegisteredRunner API */
-    TransientsRr(): mapOwner(NULL) {}
+    TransientsRr(): mapOwner(NULL), extrasOwner(NULL) {}
     virtual void useConfig();
     virtual ~TransientsRr();
 
@@ -392,6 +396,7 @@ class TransientsRr: public Ipc::Mem::RegisteredRunner
 
 private:
     TransientsMap::Owner *mapOwner;
+    Ipc::Mem::Owner<TransientsMapExtras> *extrasOwner;
 };
 
 RunnerRegistrationEntry(TransientsRr);
@@ -415,9 +420,12 @@ TransientsRr::create()
 
     Must(!mapOwner);
     mapOwner = TransientsMap::Init(MapLabel, entryLimit);
+    Must(!extrasOwner);
+    extrasOwner = shm_new(TransientsMapExtras)(ExtrasLabel, entryLimit);
 }
 
 TransientsRr::~TransientsRr()
 {
+    delete extrasOwner;
     delete mapOwner;
 }
@@ -9,12 +9,13 @@
 #include <vector>
 
 // StoreEntry restoration info not already stored by Ipc::StoreMap
-struct TransientsMapExtras {
+struct TransientsMapExtraItem {
     char url[MAX_URL+1]; ///< Request-URI; TODO: decrease MAX_URL by one
     RequestFlags reqFlags; ///< request flags
     Http::MethodType reqMethod; ///< request method; extensions are not supported
 };
-typedef Ipc::StoreMapWithExtras<TransientsMapExtras> TransientsMap;
+typedef Ipc::StoreMapItems<TransientsMapExtraItem> TransientsMapExtras;
+typedef Ipc::StoreMap TransientsMap;
 
 /// Keeps track of store entries being delivered to clients that arrived before
 /// those entries were [fully] cached. This shared table is necessary to sync
@@ -73,12 +74,16 @@ class Transients: public Store, public Ipc::StoreMapCleaner
     bool abandonedAt(const sfileno index) const;
 
     // Ipc::StoreMapCleaner API
-    virtual void noteFreeMapSlice(const sfileno sliceId);
+    virtual void noteFreeMapSlice(const Ipc::StoreMapSliceId sliceId);
 
 private:
     /// shared packed info indexed by Store keys, for creating new StoreEntries
     TransientsMap *map;
 
+    /// shared packed info that standard StoreMap does not store for us
+    typedef TransientsMapExtras Extras;
+    Ipc::Mem::Pointer<Extras> extras;
+
     typedef std::vector<StoreEntry*> Locals;
     /// local collapsed entries indexed by transient ID, for syncing old StoreEntries
     Locals *locals;
@@ -510,7 +510,7 @@ int WIN32_Subsystem_Init(int * argc, char *** argv)
             return 1;
 
         /* Register the service Handler function */
-        svcHandle = RegisterServiceCtrlHandler(service_name, WIN32_svcHandler);
+        svcHandle = RegisterServiceCtrlHandler(service_name.c_str(), WIN32_svcHandler);
 
         if (svcHandle == 0)
             return 1;
@@ -671,12 +671,13 @@ WIN32_RemoveService()
     SC_HANDLE schService;
     SC_HANDLE schSCManager;
 
-    if (!service_name)
-        service_name = xstrdup(APP_SHORTNAME);
+    if (service_name.isEmpty())
+        service_name = SBuf(APP_SHORTNAME);
 
-    strcat(REGKEY, service_name);
+    const char *service =  service_name.c_str();
+    strcat(REGKEY, service);
 
-    keys[4] = service_name;
+    keys[4] = service;
 
     schSCManager = OpenSCManager(NULL,	/* machine (NULL == local)    */
                                  NULL,			/* database (NULL == default) */
@@ -686,7 +687,7 @@ WIN32_RemoveService()
     if (!schSCManager)
         fprintf(stderr, "OpenSCManager failed\n");
     else {
-        schService = OpenService(schSCManager, service_name, SERVICE_ALL_ACCESS);
+        schService = OpenService(schSCManager, service, SERVICE_ALL_ACCESS);
 
         if (schService == NULL)
             fprintf(stderr, "OpenService failed\n");
@@ -711,7 +712,7 @@ WIN32_RemoveService()
             if (DeleteService(schService) == 0)
                 fprintf(stderr, "DeleteService failed.\n");
             else
-                printf("Service %s deleted successfully.\n", service_name);
+                printf("Service " SQUIDSBUFPH " deleted successfully.\n", SQUIDSBUFPRINT(service_name));
 
             CloseServiceHandle(schService);
         }
@@ -723,12 +724,13 @@ WIN32_RemoveService()
 void
 WIN32_SetServiceCommandLine()
 {
-    if (!service_name)
-        service_name = xstrdup(APP_SHORTNAME);
+    if (service_name.isEmpty())
+        service_name = SBuf(APP_SHORTNAME);
 
-    strcat(REGKEY, service_name);
+    const char *service = servie_name.c_str();
+    strcat(REGKEY, service);
 
-    keys[4] = service_name;
+    keys[4] = service;
 
     /* Now store the Service Command Line in the registry */
     WIN32_StoreKey(COMMANDLINE, REG_SZ, (unsigned char *) WIN32_Command_Line, strlen(WIN32_Command_Line) + 1);
@@ -743,19 +745,20 @@ WIN32_InstallService()
     char szPath[512];
     int lenpath;
 
-    if (!service_name)
-        service_name = xstrdup(APP_SHORTNAME);
+    if (service_name.isEmpty())
+        service_name = SBuf(APP_SHORTNAME);
 
-    strcat(REGKEY, service_name);
+    const char *service = service_name.c_str();
+    strcat(REGKEY, service);
 
-    keys[4] = service_name;
+    keys[4] = service;
 
     if ((lenpath = GetModuleFileName(NULL, ServicePath, 512)) == 0) {
         fprintf(stderr, "Can't get executable path\n");
         exit(1);
     }
 
-    snprintf(szPath, sizeof(szPath), "%s %s:%s", ServicePath, _WIN_SQUID_SERVICE_OPTION, service_name);
+    snprintf(szPath, sizeof(szPath), "%s %s:" SQUIDSBUFPH, ServicePath, _WIN_SQUID_SERVICE_OPTION, SQUIDSBUFPRINT(service_name));
     schSCManager = OpenSCManager(NULL,	/* machine (NULL == local)    */
                                  NULL,			/* database (NULL == default) */
                                  SC_MANAGER_ALL_ACCESS	/* access required            */
@@ -766,8 +769,8 @@ WIN32_InstallService()
         exit(1);
     } else {
         schService = CreateService(schSCManager,    /* SCManager database     */
-                                   service_name,			    /* name of service        */
-                                   service_name,			    /* name to display        */
+                                   service,			    /* name of service        */
+                                   service,			    /* name to display        */
                                    SERVICE_ALL_ACCESS,			    /* desired access         */
                                    SERVICE_WIN32_OWN_PROCESS,		    /* service type           */
                                    SERVICE_AUTO_START,			    /* start type             */
@@ -801,7 +804,7 @@ WIN32_InstallService()
             WIN32_StoreKey(CONFIGFILE, REG_SZ, (unsigned char *) ConfigFile, strlen(ConfigFile) + 1);
 
             printf("Squid Cache version %s for %s\n", version_string, CONFIG_HOST_TYPE);
-            printf("installed successfully as %s Windows System Service.\n", service_name);
+            printf("installed successfully as " SQUIDSBUFPH " Windows System Service.\n", SQUIDSBUFPRINT(service_name));
             printf("To run, start it from the Services Applet of Control Panel.\n");
             printf("Don't forget to edit squid.conf before starting it.\n\n");
         } else {
@@ -821,8 +824,8 @@ WIN32_sendSignal(int WIN32_signal)
     SC_HANDLE schService;
     SC_HANDLE schSCManager;
 
-    if (!service_name)
-        service_name = xstrdup(APP_SHORTNAME);
+    if (service_name.isEmpty())
+        service_name = SBuf(APP_SHORTNAME);
 
     schSCManager = OpenSCManager(NULL,	/* machine (NULL == local)    */
                                  NULL,			/* database (NULL == default) */
@@ -875,24 +878,24 @@ WIN32_sendSignal(int WIN32_signal)
 
     /* Open a handle to the service. */
     schService = OpenService(schSCManager,	/* SCManager database */
-                             service_name,	/* name of service    */
+                             service_name.c_str(),	/* name of service    */
                              fdwAccess);		/* specify access     */
 
     if (schService == NULL) {
-        fprintf(stderr, "%s: ERROR: Could not open Service %s\n", APP_SHORTNAME, service_name);
+        fprintf(stderr, "%s: ERROR: Could not open Service " SQUIDSBUFPH "\n", APP_SHORTNAME, SQUIDSBUFPRINT(service_name));
         exit(1);
     } else {
         /* Send a control value to the service. */
 
         if (!ControlService(schService,	/* handle of service      */
                             fdwControl,	/* control value to send  */
                             &ssStatus)) {	/* address of status info */
-            fprintf(stderr, "%s: ERROR: Could not Control Service %s\n",
-                    APP_SHORTNAME, service_name);
+            fprintf(stderr, "%s: ERROR: Could not Control Service " SQUIDSBUFPH "\n",
+                    APP_SHORTNAME, SQUIDSBUFPRINT(service_name));
             exit(1);
         } else {
             /* Print the service status. */
-            printf("\nStatus of %s Service:\n", service_name);
+            printf("\nStatus of " SQUIDSBUFPH " Service:\n", SQUIDSBUFPRINT(service_name));
             printf("  Service Type: 0x%lx\n", ssStatus.dwServiceType);
             printf("  Current State: 0x%lx\n", ssStatus.dwCurrentState);
             printf("  Controls Accepted: 0x%lx\n", ssStatus.dwControlsAccepted);
@@ -931,10 +934,11 @@ int main(int argc, char **argv)
             return 1;
         }
 
-        service_name = xstrdup(c+1);
-        DispatchTable[0].lpServiceName=service_name;
-        strcat(REGKEY, service_name);
-        keys[4] = service_name;
+        service_name = SBuf(c+1);
+        const char *service = service_name.c_str();
+        DispatchTable[0].lpServiceName=service;
+        strcat(REGKEY, service);
+        keys[4] = service;
 
         if (!StartServiceCtrlDispatcher(DispatchTable)) {
             fprintf(stderr, "StartServiceCtrlDispatcher error = %ld\n",
@@ -225,8 +225,8 @@ ACL::ParseAclLine(ConfigParser &parser, ACL ** head)
 
     // Is this ACL going to work?
     if (strcmp(theType, "myip") == 0) {
-        AnyP::PortCfg *p = Config.Sockaddr.http;
-        while (p) {
+        AnyP::PortCfgPointer p = HttpPortList;
+        while (p != NULL) {
             // Bug 3239: not reliable when there is interception traffic coming
             if (p->flags.natIntercept)
                 debugs(28, DBG_CRITICAL, "WARNING: 'myip' ACL is not reliable for interception proxies. Please use 'myportname' instead.");
@@ -235,8 +235,8 @@ ACL::ParseAclLine(ConfigParser &parser, ACL ** head)
         debugs(28, DBG_IMPORTANT, "UPGRADE: ACL 'myip' type is has been renamed to 'localip' and matches the IP the client connected to.");
         theType = "localip";
     } else if (strcmp(theType, "myport") == 0) {
-        AnyP::PortCfg *p = Config.Sockaddr.http;
-        while (p) {
+        AnyP::PortCfgPointer p = HttpPortList;
+        while (p != NULL) {
             // Bug 3239: not reliable when there is interception traffic coming
             // Bug 3239: myport - not reliable (yet) when there is interception traffic coming
             if (p->flags.natIntercept)
@@ -262,26 +262,38 @@ aclRegister(ACL *acl)
     }
 }
 
+/// remove registered acl from the centralized deletion set
+static
+void
+aclDeregister(ACL *acl)
+{
+    if (acl->registered) {
+        if (RegisteredAcls)
+            RegisteredAcls->erase(acl);
+        acl->registered = false;
+    }
+}
+
 /*********************/
 /* Destroy functions */
 /*********************/
 
-/// helper for RegisteredAcls cleanup
-static void
-aclDeleteOne(ACL *acl)
-{
-    delete acl;
-}
-
 /// called to delete ALL Acls.
 void
 aclDestroyAcls(ACL ** head)
 {
     *head = NULL; // Config.aclList
     if (AclSet *acls = RegisteredAcls) {
         debugs(28, 8, "deleting all " << acls->size() << " ACLs");
-        std::for_each(acls->begin(), acls->end(), &aclDeleteOne);
-        acls->clear();
+        while (!acls->empty()) {
+            ACL *acl = *acls->begin();
+            // We use centralized deletion (this function) so ~ACL should not
+            // delete other ACLs, but we still deregister first to prevent any
+            // accesses to the being-deleted ACL via RegisteredAcls.
+            assert(acl->registered); // make sure we are making progress
+            aclDeregister(acl);
+            delete acl;
+        }
     }
 }
 
@@ -290,7 +302,8 @@ aclDestroyAclList(ACLList **list)
 {
     debugs(28, 8, "aclDestroyAclList: invoked");
     assert(list);
-    cbdataFree(*list);
+    delete *list;
+    *list = NULL;
 }
 
 void
@@ -299,7 +312,8 @@ aclDestroyAccessList(acl_access ** list)
     assert(list);
     if (*list)
         debugs(28, 3, "destroying: " << *list << ' ' << (*list)->name);
-    cbdataFree(*list);
+    delete *list;
+    *list = NULL;
 }
 
 /* maex@space.net (06.09.1996)
@@ -2,6 +2,7 @@
 #include "acl/Acl.h"
 #include "acl/BoolOps.h"
 #include "acl/Checklist.h"
+#include "acl/Gadgets.h"
 #include "acl/InnerNode.h"
 #include "cache_cf.h"
 #include "ConfigParser.h"
@@ -26,6 +27,7 @@ Acl::InnerNode::add(ACL *node)
 {
     assert(node != NULL);
     nodes.push_back(node);
+    aclRegister(node);
 }
 
 // one call parses one "acl name acltype name1 name2 ..." line
@@ -1,5 +1,6 @@
 #include "squid.h"
 #include "acl/Gadgets.h"
+#include "acl/Tree.h"
 #include "adaptation/AccessRule.h"
 #include "adaptation/Service.h"
 #include "adaptation/ServiceGroups.h"
@@ -14,7 +15,7 @@ Adaptation::AccessRule::AccessRule(const String &aGroupId): id(++LastId), groupI
 
 Adaptation::AccessRule::~AccessRule()
 {
-    // XXX: leaking acls here?
+    delete acl;
 }
 
 void
@@ -10,6 +10,7 @@
 #include "comm.h"
 #include "comm/Connection.h"
 #include "comm/ConnOpener.h"
+#include "comm/Read.h"
 #include "comm/Write.h"
 #include "CommCalls.h"
 #include "err_detail_type.h"
@@ -120,7 +121,7 @@ Adaptation::Icap::Xaction::openConnection()
         CbcPointer<Xaction> self(this);
         Dialer dialer(self, &Adaptation::Icap::Xaction::noteCommConnected);
         dialer.params.conn = connection;
-        dialer.params.flag = COMM_OK;
+        dialer.params.flag = Comm::OK;
         // fake other parameters by copying from the existing connection
         connector = asyncCall(93,3, "Adaptation::Icap::Xaction::noteCommConnected", dialer);
         ScheduleCallHere(connector);
@@ -152,7 +153,7 @@ Adaptation::Icap::Xaction::dnsLookupDone(const ipcache_addrs *ia)
         CbcPointer<Xaction> self(this);
         Dialer dialer(self, &Adaptation::Icap::Xaction::noteCommConnected);
         dialer.params.conn = connection;
-        dialer.params.flag = COMM_ERROR;
+        dialer.params.flag = Comm::COMM_ERROR;
         // fake other parameters by copying from the existing connection
         connector = asyncCall(93,3, "Adaptation::Icap::Xaction::noteCommConnected", dialer);
         ScheduleCallHere(connector);
@@ -185,7 +186,7 @@ Adaptation::Icap::Xaction::reusedConnection(void *data)
 {
     debugs(93, 5, HERE << "reused connection");
     Adaptation::Icap::Xaction *x = (Adaptation::Icap::Xaction*)data;
-    x->noteCommConnected(COMM_OK);
+    x->noteCommConnected(Comm::OK);
 }
 #endif
 
@@ -227,15 +228,15 @@ void Adaptation::Icap::Xaction::noteCommConnected(const CommConnectCbParams &io)
 {
     cs = NULL;
 
-    if (io.flag == COMM_TIMEOUT) {
+    if (io.flag == Comm::TIMEOUT) {
         handleCommTimedout();
         return;
     }
 
     Must(connector != NULL);
     connector = NULL;
 
-    if (io.flag != COMM_OK)
+    if (io.flag != Comm::OK)
         dieOnConnectionFailure(); // throws
 
     typedef CommCbMemFunT<Adaptation::Icap::Xaction, CommTimeoutCbParams> TimeoutDialer;
@@ -286,7 +287,7 @@ void Adaptation::Icap::Xaction::noteCommWrote(const CommIoCbParams &io)
         ignoreLastWrite = false;
         debugs(93, 7, HERE << "ignoring last write; status: " << io.flag);
     } else {
-        Must(io.flag == COMM_OK);
+        Must(io.flag == Comm::OK);
         al.icap.bytesSent += io.size;
         updateTimeout();
         handleCommWrote(io.size);
@@ -392,7 +393,7 @@ void Adaptation::Icap::Xaction::noteCommRead(const CommIoCbParams &io)
     Must(reader != NULL);
     reader = NULL;
 
-    Must(io.flag == COMM_OK);
+    Must(io.flag == Comm::OK);
 
     if (!io.size) {
         commEof = true;
@@ -428,7 +429,7 @@ void Adaptation::Icap::Xaction::cancelRead()
 {
     if (reader != NULL) {
         Must(haveConnection());
-        comm_read_cancel(connection->fd, reader);
+        Comm::ReadCancel(connection->fd, reader);
         reader = NULL;
     }
 }
@@ -41,12 +41,6 @@
 #include "ipcache.h"
 #include "MemBuf.h"
 
-class CommConnectCbParams;
-namespace Comm
-{
-class ConnOpener;
-}
-
 namespace Adaptation
 {
 namespace Icap
@@ -9,13 +9,17 @@
 #include <cstring>
 #include <limits>
 
-CBDATA_NAMESPACED_CLASS_INIT(AnyP, PortCfg);
+AnyP::PortCfgPointer HttpPortList;
+#if USE_OPENSSL
+AnyP::PortCfgPointer HttpsPortList;
+#endif
+AnyP::PortCfgPointer FtpPortList;
 
 int NHttpSockets = 0;
 int HttpSockets[MAXTCPLISTENPORTS];
 
 AnyP::PortCfg::PortCfg() :
-        next(NULL),
+        next(),
         s(),
         transport(AnyP::PROTO_HTTP,1,1), // "Squid is an HTTP proxy", etc.
         name(NULL),
@@ -85,10 +89,10 @@ AnyP::PortCfg::~PortCfg()
 #endif
 }
 
-AnyP::PortCfg *
+AnyP::PortCfgPointer
 AnyP::PortCfg::clone() const
 {
-    AnyP::PortCfg *b = new AnyP::PortCfg();
+    AnyP::PortCfgPointer b = new AnyP::PortCfg();
     b->s = s;
     if (name)
         b->name = xstrdup(name);
@@ -13,12 +13,12 @@
 namespace AnyP
 {
 
-class PortCfg
+class PortCfg : public RefCountable
 {
 public:
     PortCfg();
     ~PortCfg();
-    AnyP::PortCfg *clone() const;
+    AnyP::PortCfgPointer clone() const;
 #if USE_OPENSSL
     /// creates, configures, and validates SSL context and related port options
     void configureSslServerContext();
@@ -31,7 +31,7 @@ class PortCfg
      */
     void setTransport(const char *aProtocol);
 
-    PortCfg *next;
+    PortCfgPointer next;
 
     Ip::Address s;
     AnyP::ProtocolVersion transport; ///< transport protocol and version received by this port
@@ -95,15 +95,26 @@ class PortCfg
     long sslOptions; ///< SSL engine options
 #endif
 
-    bool ftp_track_dirs; ///< Whether to track FTP directories
-
-    CBDATA_CLASS2(PortCfg); // namespaced
+    bool ftp_track_dirs; ///< whether ftp_port should track FTP directories
 };
 
 } // namespace AnyP
 
+/// list of Squid http_port configured
+extern AnyP::PortCfgPointer HttpPortList;
+
+#if USE_OPENSSL
+/// list of Squid https_port configured
+extern AnyP::PortCfgPointer HttpsPortList;
+#endif
+
+/// list of Squid ftp_port configured
+extern AnyP::PortCfgPointer FtpPortList;
+
+#if !defined(MAXTCPLISTENPORTS)
 // Max number of TCP listening ports
 #define MAXTCPLISTENPORTS 128
+#endif
 
 // TODO: kill this global array. Need to check performance of array vs list though.
 extern int NHttpSockets;
@@ -1,13 +1,13 @@
 #ifndef _SQUID_SRC_ANYP_FORWARD_H
 #define _SQUID_SRC_ANYP_FORWARD_H
 
-#include "base/CbcPointer.h"
+#include "base/RefCount.h"
 
 namespace AnyP
 {
 
 class PortCfg;
-typedef CbcPointer<PortCfg> PortCfgPointer;
+typedef RefCount<PortCfg> PortCfgPointer;
 
 class UriScheme;
 
@@ -40,6 +40,7 @@
 #include "format/Format.h"
 #include "globals.h"
 #include "Store.h"
+#include "wordlist.h"
 
 Auth::ConfigVector Auth::TheConfig;
 
@@ -94,7 +95,31 @@ Auth::Config::registerWithCacheManager(void)
 void
 Auth::Config::parse(Auth::Config * scheme, int n_configured, char *param_str)
 {
-    if (strcmp(param_str, "children") == 0) {
+    if (strcmp(param_str, "program") == 0) {
+        if (authenticateProgram)
+            wordlistDestroy(&authenticateProgram);
+
+        parse_wordlist(&authenticateProgram);
+
+        requirePathnameExists("Authentication helper program", authenticateProgram->key);
+
+    } else if (strcmp(param_str, "realm") == 0) {
+        realm.clear();
+
+        char *token = ConfigParser::NextQuotedOrToEol();
+
+        while (*token && xisspace(*token))
+            ++token;
+
+        if (!token || !*token) {
+            debugs(29, DBG_PARSE_NOTE(DBG_IMPORTANT), "ERROR: Missing auth_param " << scheme->type() << " realm");
+            self_destruct();
+            return;
+        }
+
+        realm = token;
+
+    } else if (strcmp(param_str, "children") == 0) {
         authenticateChildren.parseConfig();
 
     } else if (strcmp(param_str, "key_extras") == 0) {
@@ -119,16 +144,31 @@ Auth::Config::parse(Auth::Config * scheme, int n_configured, char *param_str)
     }
 }
 
-void
-Auth::Config::dump(StoreEntry *entry, const char *name, Auth::Config *scheme)
+bool
+Auth::Config::dump(StoreEntry *entry, const char *name, Auth::Config *scheme) const
 {
+    if (!authenticateProgram)
+        return false; // not configured
+
+    wordlist *list = authenticateProgram;
+    storeAppendPrintf(entry, "%s %s", name, scheme->type());
+    while (list != NULL) {
+        storeAppendPrintf(entry, " %s", list->key);
+        list = list->next;
+    }
+    storeAppendPrintf(entry, "\n");
+
+    storeAppendPrintf(entry, "%s %s realm " SQUIDSBUFPH "\n", name, scheme->type(), SQUIDSBUFPRINT(realm));
+
     storeAppendPrintf(entry, "%s %s children %d startup=%d idle=%d concurrency=%d\n",
                       name, scheme->type(),
                       authenticateChildren.n_max, authenticateChildren.n_startup,
                       authenticateChildren.n_idle, authenticateChildren.concurrency);
 
     if (keyExtrasLine.size() > 0)
         storeAppendPrintf(entry, "%s %s key_extras \"%s\"\n", name, scheme->type(), keyExtrasLine.termedBuf());
+
+    return true;
 }
 
 void
@@ -122,8 +122,9 @@ class Config
     /**
      * Responsible for writing to the StoreEntry the configuration parameters that a user
      * would put in a config file to recreate the running configuration.
+     * Returns whether the scheme is configured.
      */
-    virtual void dump(StoreEntry *, const char *, Config *);
+    virtual bool dump(StoreEntry *, const char *, Config *) const;
 
     /** add headers as needed when challenging for auth */
     virtual void fixHeader(UserRequest::Pointer, HttpReply *, http_hdr_type, HttpRequest *) = 0;
@@ -148,6 +149,10 @@ class Config
     wordlist *authenticateProgram; ///< Helper program to run, includes all parameters
     String keyExtrasLine;  ///< The format of the request to the auth helper
     Format::Format *keyExtras; ///< The compiled request format
+
+protected:
+    /// RFC 7235 section 2.2 - Protection Space (Realm)
+    SBuf realm;
 };
 
 typedef std::vector<Config *> ConfigVector;
@@ -264,10 +264,8 @@ authTryGetUser(Auth::UserRequest::Pointer auth_user_request, ConnStateData * con
         // XXX: we have no access to the transaction / AccessLogEntry so cant SyncNotes().
         // workaround by using anything already set in HttpRequest
         // OR use new and rely on a later Sync copying these to AccessLogEntry
-        if (!request->notes)
-            request->notes = new NotePairs;
 
-        request->notes->appendNewOnly(&res->user()->notes);
+        UpdateRequestNotes(conn, *request, res->user()->notes);
     }
 
     return res;
@@ -76,8 +76,7 @@ Auth::Basic::Config::active() const
 bool
 Auth::Basic::Config::configured() const
 {
-    if ((authenticateProgram != NULL) && (authenticateChildren.n_max != 0) &&
-            (basicAuthRealm != NULL)) {
+    if ((authenticateProgram != NULL) && (authenticateChildren.n_max != 0) && !realm.isEmpty()) {
         debugs(29, 9, HERE << "returning configured");
         return true;
     }
@@ -96,8 +95,8 @@ void
 Auth::Basic::Config::fixHeader(Auth::UserRequest::Pointer auth_user_request, HttpReply *rep, http_hdr_type hdrType, HttpRequest * request)
 {
     if (authenticateProgram) {
-        debugs(29, 9, HERE << "Sending type:" << hdrType << " header: 'Basic realm=\"" << basicAuthRealm << "\"'");
-        httpHeaderPutStrf(&rep->header, hdrType, "Basic realm=\"%s\"", basicAuthRealm);
+        debugs(29, 9, "Sending type:" << hdrType << " header: 'Basic realm=\"" << realm << "\"'");
+        httpHeaderPutStrf(&rep->header, hdrType, "Basic realm=\"" SQUIDSBUFPH "\"", SQUIDSBUFPRINT(realm));
     }
 }
 
@@ -129,56 +128,33 @@ Auth::Basic::Config::done()
 
     if (authenticateProgram)
         wordlistDestroy(&authenticateProgram);
-
-    if (basicAuthRealm)
-        safe_free(basicAuthRealm);
 }
 
-void
-Auth::Basic::Config::dump(StoreEntry * entry, const char *name, Auth::Config * scheme)
+bool
+Auth::Basic::Config::dump(StoreEntry * entry, const char *name, Auth::Config * scheme) const
 {
-    wordlist *list = authenticateProgram;
-    storeAppendPrintf(entry, "%s %s", name, "basic");
-
-    while (list != NULL) {
-        storeAppendPrintf(entry, " %s", list->key);
-        list = list->next;
-    }
-
-    storeAppendPrintf(entry, "\n");
+    if (!Auth::Config::dump(entry, name, scheme))
+        return false; // not configured
 
-    storeAppendPrintf(entry, "%s basic realm %s\n", name, basicAuthRealm);
     storeAppendPrintf(entry, "%s basic credentialsttl %d seconds\n", name, (int) credentialsTTL);
     storeAppendPrintf(entry, "%s basic casesensitive %s\n", name, casesensitive ? "on" : "off");
-    Auth::Config::dump(entry, name, scheme);
+    storeAppendPrintf(entry, "%s basic utf8 %s\n", name, utf8 ? "on" : "off");
+    return true;
 }
 
 Auth::Basic::Config::Config() :
         credentialsTTL( 2*60*60 ),
         casesensitive(0),
         utf8(0)
 {
-    basicAuthRealm = xstrdup("Squid proxy-caching web server");
-}
-
-Auth::Basic::Config::~Config()
-{
-    safe_free(basicAuthRealm);
+    static const SBuf defaultRealm("Squid proxy-caching web server");
+    realm = defaultRealm;
 }
 
 void
 Auth::Basic::Config::parse(Auth::Config * scheme, int n_configured, char *param_str)
 {
-    if (strcmp(param_str, "program") == 0) {
-        if (authenticateProgram)
-            wordlistDestroy(&authenticateProgram);
-
-        parse_wordlist(&authenticateProgram);
-
-        requirePathnameExists("auth_param basic program", authenticateProgram->key);
-    } else if (strcmp(param_str, "realm") == 0) {
-        parse_eol(&basicAuthRealm);
-    } else if (strcmp(param_str, "credentialsttl") == 0) {
+    if (strcmp(param_str, "credentialsttl") == 0) {
         parse_time_t(&credentialsTTL);
     } else if (strcmp(param_str, "casesensitive") == 0) {
         parse_onoff(&casesensitive);
@@ -23,13 +23,12 @@ class Config : public Auth::Config
 {
 public:
     Config();
-    ~Config();
     virtual bool active() const;
     virtual bool configured() const;
     virtual Auth::UserRequest::Pointer decode(char const *proxy_auth, const char *requestRealm);
     virtual void done();
     virtual void rotateHelpers();
-    virtual void dump(StoreEntry *, const char *, Auth::Config *);
+    virtual bool dump(StoreEntry *, const char *, Auth::Config *) const;
     virtual void fixHeader(Auth::UserRequest::Pointer, HttpReply *, http_hdr_type, HttpRequest *);
     virtual void init(Auth::Config *);
     virtual void parse(Auth::Config *, int, char *);
@@ -38,7 +37,6 @@ class Config : public Auth::Config
     virtual const char * type() const;
 
 public:
-    char *basicAuthRealm;
     time_t credentialsTTL;
     int casesensitive;
     int utf8;
@@ -487,24 +487,18 @@ Auth::Digest::Config::rotateHelpers()
     /* NP: dynamic helper restart will ensure they start up again as needed. */
 }
 
-void
-Auth::Digest::Config::dump(StoreEntry * entry, const char *name, Auth::Config * scheme)
+bool
+Auth::Digest::Config::dump(StoreEntry * entry, const char *name, Auth::Config * scheme) const
 {
-    wordlist *list = authenticateProgram;
-    debugs(29, 9, "Dumping configuration");
-    storeAppendPrintf(entry, "%s %s", name, "digest");
+    if (!Auth::Config::dump(entry, name, scheme))
+        return false;
 
-    while (list != NULL) {
-        storeAppendPrintf(entry, " %s", list->key);
-        list = list->next;
-    }
-
-    storeAppendPrintf(entry, "\n%s %s realm %s\n%s %s nonce_max_count %d\n%s %s nonce_max_duration %d seconds\n%s %s nonce_garbage_interval %d seconds\n",
-                      name, "digest", digestAuthRealm,
+    storeAppendPrintf(entry, "%s %s nonce_max_count %d\n%s %s nonce_max_duration %d seconds\n%s %s nonce_garbage_interval %d seconds\n",
                       name, "digest", noncemaxuses,
                       name, "digest", (int) noncemaxduration,
                       name, "digest", (int) nonceGCInterval);
-    Auth::Config::dump(entry, name, scheme);
+    storeAppendPrintf(entry, "%s digest utf8 %s\n", name, utf8 ? "on" : "off");
+    return true;
 }
 
 bool
@@ -518,7 +512,7 @@ Auth::Digest::Config::configured() const
 {
     if ((authenticateProgram != NULL) &&
             (authenticateChildren.n_max != 0) &&
-            (digestAuthRealm != NULL) && (noncemaxduration > -1))
+            !realm.isEmpty() && (noncemaxduration > -1))
         return true;
 
     return false;
@@ -550,12 +544,13 @@ Auth::Digest::Config::fixHeader(Auth::UserRequest::Pointer auth_user_request, Ht
     }
 
     debugs(29, 9, "Sending type:" << hdrType <<
-           " header: 'Digest realm=\"" << digestAuthRealm << "\", nonce=\"" <<
+           " header: 'Digest realm=\"" << realm << "\", nonce=\"" <<
            authenticateDigestNonceNonceb64(nonce) << "\", qop=\"" << QOP_AUTH <<
            "\", stale=" << (stale ? "true" : "false"));
 
     /* in the future, for WWW auth we may want to support the domain entry */
-    httpHeaderPutStrf(&rep->header, hdrType, "Digest realm=\"%s\", nonce=\"%s\", qop=\"%s\", stale=%s", digestAuthRealm, authenticateDigestNonceNonceb64(nonce), QOP_AUTH, stale ? "true" : "false");
+    httpHeaderPutStrf(&rep->header, hdrType, "Digest realm=\"" SQUIDSBUFPH "\", nonce=\"%s\", qop=\"%s\", stale=%s",
+                      SQUIDSBUFPRINT(realm), authenticateDigestNonceNonceb64(nonce), QOP_AUTH, stale ? "true" : "false");
 }
 
 /* Initialize helpers and the like for this auth scheme. Called AFTER parsing the
@@ -613,12 +608,9 @@ Auth::Digest::Config::done()
 
     if (authenticateProgram)
         wordlistDestroy(&authenticateProgram);
-
-    safe_free(digestAuthRealm);
 }
 
 Auth::Digest::Config::Config() :
-        digestAuthRealm(NULL),
         nonceGCInterval(5*60),
         noncemaxduration(30*60),
         noncemaxuses(50),
@@ -638,8 +630,6 @@ Auth::Digest::Config::parse(Auth::Config * scheme, int n_configured, char *param
         parse_wordlist(&authenticateProgram);
 
         requirePathnameExists("auth_param digest program", authenticateProgram->key);
-    } else if (strcmp(param_str, "realm") == 0) {
-        parse_eol(&digestAuthRealm);
     } else if (strcmp(param_str, "nonce_garbage_interval") == 0) {
         parse_time_t(&nonceGCInterval);
     } else if (strcmp(param_str, "nonce_max_duration") == 0) {
@@ -75,15 +75,14 @@ class Config : public Auth::Config
     virtual Auth::UserRequest::Pointer decode(char const *proxy_auth, const char *requestRealm);
     virtual void done();
     virtual void rotateHelpers();
-    virtual void dump(StoreEntry *, const char *, Auth::Config *);
+    virtual bool dump(StoreEntry *, const char *, Auth::Config *) const;
     virtual void fixHeader(Auth::UserRequest::Pointer, HttpReply *, http_hdr_type, HttpRequest *);
     virtual void init(Auth::Config *);
     virtual void parse(Auth::Config *, int, char *);
     virtual void registerWithCacheManager(void);
     virtual const char * type() const;
 
 public:
-    char *digestAuthRealm;
     time_t nonceGCInterval;
     time_t noncemaxduration;
     unsigned int noncemaxuses;
@@ -108,19 +108,14 @@ Auth::Negotiate::Config::done()
     debugs(29, DBG_IMPORTANT, "Reconfigure: Negotiate authentication configuration cleared.");
 }
 
-void
-Auth::Negotiate::Config::dump(StoreEntry * entry, const char *name, Auth::Config * scheme)
+bool
+Auth::Negotiate::Config::dump(StoreEntry * entry, const char *name, Auth::Config * scheme) const
 {
-    wordlist *list = authenticateProgram;
-    storeAppendPrintf(entry, "%s %s", name, "negotiate");
-
-    while (list != NULL) {
-        storeAppendPrintf(entry, " %s", list->key);
-        list = list->next;
-    }
+    if (!Auth::Config::dump(entry, name, scheme))
+        return false;
 
-    storeAppendPrintf(entry, "\n%s %s keep_alive %s\n", name, "negotiate", keep_alive ? "on" : "off");
-    Auth::Config::dump(entry, name, scheme);
+    storeAppendPrintf(entry, "%s negotiate keep_alive %s\n", name, keep_alive ? "on" : "off");
+    return true;
 }
 
 Auth::Negotiate::Config::Config() : keep_alive(1)
@@ -34,7 +34,7 @@ class Config : public Auth::Config
     virtual Auth::UserRequest::Pointer decode(char const *proxy_auth, const char *requestRealm);
     virtual void done();
     virtual void rotateHelpers();
-    virtual void dump(StoreEntry *, const char *, Auth::Config *);
+    virtual bool dump(StoreEntry *, const char *, Auth::Config *) const;
     virtual void fixHeader(Auth::UserRequest::Pointer, HttpReply *, http_hdr_type, HttpRequest *);
     virtual void init(Auth::Config *);
     virtual void parse(Auth::Config *, int, char *);
@@ -100,19 +100,14 @@ Auth::Ntlm::Config::done()
     debugs(29, DBG_IMPORTANT, "Reconfigure: NTLM authentication configuration cleared.");
 }
 
-void
-Auth::Ntlm::Config::dump(StoreEntry * entry, const char *name, Auth::Config * scheme)
+bool
+Auth::Ntlm::Config::dump(StoreEntry * entry, const char *name, Auth::Config * scheme) const
 {
-    wordlist *list = authenticateProgram;
-    storeAppendPrintf(entry, "%s %s", name, "ntlm");
-
-    while (list != NULL) {
-        storeAppendPrintf(entry, " %s", list->key);
-        list = list->next;
-    }
+    if (!Auth::Config::dump(entry, name, scheme))
+        return false;
 
-    storeAppendPrintf(entry, "\n%s %s keep_alive %s\n", name, "ntlm", keep_alive ? "on" : "off");
-    Auth::Config::dump(entry, name, scheme);
+    storeAppendPrintf(entry, "%s ntlm keep_alive %s\n", name, keep_alive ? "on" : "off");
+    return true;
 }
 
 Auth::Ntlm::Config::Config() : keep_alive(1)
@@ -30,7 +30,7 @@ class Config : public Auth::Config
     virtual Auth::UserRequest::Pointer decode(char const *proxy_auth, const char *requestRealm);
     virtual void done();
     virtual void rotateHelpers();
-    virtual void dump(StoreEntry *, const char *, Auth::Config *);
+    virtual bool dump(StoreEntry *, const char *, Auth::Config *) const;
     virtual void fixHeader(Auth::UserRequest::Pointer, HttpReply *, http_hdr_type, HttpRequest *);
     virtual void init(Auth::Config *);
     virtual void parse(Auth::Config *, int, char *);
@@ -53,7 +53,7 @@ be dialed is irrelevant here.
 handle the call back, then it must cancel it.  Whether that Call will be
 scheduled is irrelevant here. If the Recipient has an AsyncCall pointer,
 calling AsyncCall::cancel is sufficient, but the code should use
-call-specific APIs when possible (e.g., comm_read_cancel or comm_close).
+call-specific APIs when possible (e.g., Comm::ReadCancel or comm_close).
 
 - Processed calls should be forgotten: If you scheduled, received, or
 cancel the call, set its pointer to NULL. The Caller should forget the
@@ -34,10 +34,13 @@ CharacterSet::add(const unsigned char c)
 CharacterSet &
 CharacterSet::addRange(unsigned char low, unsigned char high)
 {
-    while (low <= high) {
+    //manual loop splitting is needed to cover case where high is 255
+    // otherwise low will wrap, resulting in infinite loop
+    while (low < high) {
         chars_[static_cast<uint8_t>(low)] = 1;
         ++low;
     }
+    chars_[static_cast<uint8_t>(high)] = 1;
     return *this;
 }
 
@@ -58,20 +61,35 @@ CharacterSet::CharacterSet(const char *label, unsigned char low, unsigned char h
 }
 
 const CharacterSet
+// RFC 5234
 CharacterSet::ALPHA("ALPHA", "abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ"),
 CharacterSet::BIT("BIT","01"),
 CharacterSet::CR("CR","\r"),
-CharacterSet::LF("LF","\n"),
+#if __cplusplus == 201103L
+//CharacterSet::CTL("CTL",{{0x01,0x1f},{0x7f,0x7f}}),
+#endif
 CharacterSet::DIGIT("DIGIT","0123456789"),
 CharacterSet::DQUOTE("DQUOTE","\""),
-CharacterSet::HTAB("HTAB","\t"),
 CharacterSet::HEXDIG("HEXDIG","0123456789aAbBcCdDeEfF"),
+CharacterSet::HTAB("HTAB","\t"),
+CharacterSet::LF("LF","\n"),
 CharacterSet::SP("SP"," "),
 CharacterSet::VCHAR("VCHAR", 0x21, 0x7e),
+// RFC 7230
 CharacterSet::WSP("WSP"," \t"),
+#if __cplusplus == 201103L
+//CharacterSet::CTEXT("ctext",{{0x09,0x09},{0x20,0x20},{0x2a,0x5b},{0x5d,0x7e},{0x80,0xff}}),
+#endif
 CharacterSet::TCHAR("TCHAR","!#$%&'*+-.^_`|~0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ"),
-CharacterSet::SPECIAL("SPECIAL","()<>@,;:\\\"/[]?={}")
-// QDTEXT and OBSTEXT are omitted for now as they require c++11 constructors
-//,CharacterSet::QDTEXT("QDTEXT",{{9,9},{0x20,0x21},{0x23,0x5b},{0x5d,0x7e},{0x80,0xff}})
-//,CharacterSet::OBSTEXT("OBSTEXT",0x80,0xff)
+CharacterSet::SPECIAL("SPECIAL","()<>@,;:\\\"/[]?={}"),
+#if __cplusplus == 201103L
+//CharacterSet::QDTEXT("QDTEXT",{{0x09,0x09},{0x20,0x21},{0x23,0x5b},{0x5d,0x7e},{0x80,0xff}}),
+#endif
+CharacterSet::OBSTEXT("OBSTEXT",0x80,0xff),
+// RFC 7232
+#if __cplusplus == 201103L
+//CharacterSet::ETAGC("ETAGC",{{0x21,0x21},{0x23,0x7e},{0x80,0xff}}),
+#endif
+// RFC 7235
+CharacterSet::TOKEN68C("TOKEN68C","-._~+/0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ")
 ;
@@ -36,38 +36,64 @@ class CharacterSet
     /// optional set label for debugging (default: "anonymous")
     const char * name;
 
-    // common character sets, insipired to RFC5234
+    // common character sets, RFC 5234
     // A-Za-z
     static const CharacterSet ALPHA;
     // 0-1
     static const CharacterSet BIT;
     // carriage return
     static const CharacterSet CR;
-    // line feed
-    static const CharacterSet LF;
-    // double quote
-    static const CharacterSet DQUOTE;
+    // controls
+#if __cplusplus == 201103L
+    // ready but disabled as needs C++11 constructor
+    //static const CharacterSet CTL;
+#endif
     // 0-9
     static const CharacterSet DIGIT;
+    // double quote
+    static const CharacterSet DQUOTE;
     // 0-9aAbBcCdDeEfF
     static const CharacterSet HEXDIG;
     // horizontal tab
     static const CharacterSet HTAB;
+    // line feed
+    static const CharacterSet LF;
     // white space
     static const CharacterSet SP;
     // visible (printable) characters
     static const CharacterSet VCHAR;
     // <space><tab>
     static const CharacterSet WSP;
-    // character sets from draft httpbis
+
+    // HTTP character sets, RFC 7230
+    // ctext
+#if __cplusplus == 201103L
+    // ready but disabled as needs C++11 constructor
+    //static const CharacterSet CTEXT;
+#endif
+    // XXX: maybe field-vchar = VCHAR / obs-text
     // any VCHAR except for SPECIAL
     static const CharacterSet TCHAR;
     // special VCHARs
     static const CharacterSet SPECIAL;
-    // qdtext (ready but not enabled as it requires a c++11 constructor)
+    // qdtext
+#if __cplusplus == 201103L
+    // ready but disabled as needs C++11 constructor
     //static const CharacterSet QDTEXT;
-    // obs-text (ready but not enabled as it requires a c++11 constructor)
-    //static const CharacterSet OBSTEXT;
+#endif
+    // obs-text
+    static const CharacterSet OBSTEXT;
+
+    // HTTP character sets, RFC 7232
+    // etagc
+#if __cplusplus == 201103L
+    // ready but disabled as needs C++11 constructor
+    //static const CharacterSet ETAGC;
+#endif
+
+    // HTTP character sets, RFC 7235
+    // token68 (internal charaters only, excludes '=' terminator)
+    static const CharacterSet TOKEN68C;
 
 private:
     /** index of characters in this set
@@ -140,6 +140,10 @@ LruMap<EntryValue, EntryCost>::add(const char *key, EntryValue *t)
 
     del(key);
     trim();
+
+    if (memLimit() == 0)
+        return false;
+
     index.push_front(new Entry(key, t));
     storage.insert(MapPair(key, index.begin()));
 
@@ -185,7 +189,7 @@ template <class EntryValue, size_t EntryCost>
 void
 LruMap<EntryValue, EntryCost>::trim()
 {
-    while (memLimit() > 0 && size() >= memLimit()) {
+    while (size() >= memLimit()) {
         QueueIterator i = index.end();
         --i;
         if (i != index.end()) {
@@ -180,7 +180,6 @@ static void dump_access_log(StoreEntry * entry, const char *name, CustomLog * de
 static void free_access_log(CustomLog ** definitions);
 static bool setLogformat(CustomLog *cl, const char *name, const bool dieWhenMissing);
 
-static void update_maxobjsize(void);
 static void configDoConfigure(void);
 static void parse_refreshpattern(RefreshPattern **);
 static uint64_t parseTimeUnits(const char *unit,  bool allowMsec);
@@ -229,10 +228,10 @@ static int check_null_IpAddress_list(const Ip::Address_list *);
 #endif /* CURRENTLY_UNUSED */
 #endif /* USE_WCCPv2 */
 
-static void parsePortCfg(AnyP::PortCfg **, const char *protocol);
+static void parsePortCfg(AnyP::PortCfgPointer *, const char *protocol);
 #define parse_PortCfg(l) parsePortCfg((l), token)
-static void dump_PortCfg(StoreEntry *, const char *, const AnyP::PortCfg *);
-static void free_PortCfg(AnyP::PortCfg **);
+static void dump_PortCfg(StoreEntry *, const char *, const AnyP::PortCfgPointer &);
+#define free_PortCfg(h)  *(h)=NULL
 
 #if USE_OPENSSL
 static void parse_sslproxy_cert_sign(sslproxy_cert_sign **cert_sign);
@@ -279,29 +278,6 @@ self_destruct(void)
     LegacyParser.destruct();
 }
 
-static void
-update_maxobjsize(void)
-{
-    int64_t ms = -1;
-
-    // determine the maximum size object that can be stored to disk
-    for (int i = 0; i < Config.cacheSwap.n_configured; ++i) {
-        assert (Config.cacheSwap.swapDirs[i].getRaw());
-
-        const int64_t storeMax = dynamic_cast<SwapDir *>(Config.cacheSwap.swapDirs[i].getRaw())->maxObjectSize();
-        if (ms < storeMax)
-            ms = storeMax;
-    }
-
-    // Ensure that we do not discard objects which could be stored only in memory.
-    // It is governed by maximum_object_size_in_memory (for now)
-    // TODO: update this to check each in-memory location (SMP and local memory limits differ)
-    if (ms < static_cast<int64_t>(Config.Store.maxInMemObjSize))
-        ms = Config.Store.maxInMemObjSize;
-
-    store_maxobjsize = ms;
-}
-
 static void
 SetConfigFilename(char const *file_name, bool is_pipe)
 {
@@ -382,7 +358,7 @@ SubstituteMacro(char*& line, int& len, const char* macroName, const char* substS
 static void
 ProcessMacros(char*& line, int& len)
 {
-    SubstituteMacro(line, len, "${service_name}", service_name);
+    SubstituteMacro(line, len, "${service_name}", service_name.c_str());
     SubstituteMacro(line, len, "${process_name}", TheKidName);
     SubstituteMacro(line, len, "${process_number}", xitoa(KidIdentifier));
 }
@@ -725,7 +701,6 @@ configDoConfigure(void)
 #endif
 
     storeConfigure();
-    update_maxobjsize(); // check for late maximum_object_size directive
 
     snprintf(ThisCache, sizeof(ThisCache), "%s (%s)",
              uniqueHostname(),
@@ -892,16 +867,18 @@ configDoConfigure(void)
             Config2.effectiveGroupID = pwd->pw_gid;
 
 #if HAVE_PUTENV
-
             if (pwd->pw_dir && *pwd->pw_dir) {
-                int len;
-                char *env_str = (char *)xcalloc((len = strlen(pwd->pw_dir) + 6), 1);
-                snprintf(env_str, len, "HOME=%s", pwd->pw_dir);
-                putenv(env_str);
+                // putenv() leaks by design; avoid leaks when nothing changes
+                static SBuf lastDir;
+                if (lastDir.isEmpty() || !lastDir.cmp(pwd->pw_dir)) {
+                    lastDir = pwd->pw_dir;
+                    int len = strlen(pwd->pw_dir) + 6;
+                    char *env_str = (char *)xcalloc(len, 1);
+                    snprintf(env_str, len, "HOME=%s", pwd->pw_dir);
+                    putenv(env_str);
+                }
             }
-
 #endif
-
         }
     } else {
         Config2.effectiveUserID = geteuid();
@@ -934,15 +911,15 @@ configDoConfigure(void)
         }
     }
 
-    for (AnyP::PortCfg *s = Config.Sockaddr.http; s != NULL; s = s->next) {
+    for (AnyP::PortCfgPointer s = HttpPortList; s != NULL; s = s->next) {
         if (!s->flags.tunnelSslBumping)
             continue;
 
         debugs(3, DBG_IMPORTANT, "Initializing http_port " << s->s << " SSL context");
         s->configureSslServerContext();
     }
 
-    for (AnyP::PortCfg *s = Config.Sockaddr.https; s != NULL; s = s->next) {
+    for (AnyP::PortCfgPointer s = HttpsPortList; s != NULL; s = s->next) {
         debugs(3, DBG_IMPORTANT, "Initializing https_port " << s->s << " SSL context");
         s->configureSslServerContext();
     }
@@ -1486,6 +1463,12 @@ parse_acl_tos(acl_tos ** head)
         return;
     }
 
+    const unsigned int chTos = tos & 0xFC;
+    if (chTos != tos) {
+        debugs(3, DBG_PARSE_NOTE(DBG_IMPORTANT), "WARNING: Tos value '" << tos << "' adjusted to '" << chTos << "'");
+        tos = chTos;
+    }
+
     CBDATA_INIT_TYPE_FREECB(acl_tos, freed_acl_tos);
 
     l = cbdataAlloc(acl_tos);
@@ -1935,9 +1918,6 @@ parse_cachedir(SquidConfig::_cacheSwap * swap)
             }
 
             sd->reconfigure();
-
-            update_maxobjsize();
-
             return;
         }
     }
@@ -1961,9 +1941,6 @@ parse_cachedir(SquidConfig::_cacheSwap * swap)
     sd->parse(swap->n_configured, path_str);
 
     ++swap->n_configured;
-
-    /* Update the max object size */
-    update_maxobjsize();
 }
 
 static const char *
@@ -3513,7 +3490,7 @@ check_null_IpAddress_list(const Ip::Address_list * s)
 #endif /* USE_WCCPv2 */
 
 static void
-parsePortSpecification(AnyP::PortCfg * s, char *token)
+parsePortSpecification(const AnyP::PortCfgPointer &s, char *token)
 {
     char *host = NULL;
     unsigned short port = 0;
@@ -3590,7 +3567,7 @@ parsePortSpecification(AnyP::PortCfg * s, char *token)
 }
 
 static void
-parse_port_option(AnyP::PortCfg * s, char *token)
+parse_port_option(AnyP::PortCfgPointer &s, char *token)
 {
     /* modes first */
 
@@ -3788,18 +3765,17 @@ parse_port_option(AnyP::PortCfg * s, char *token)
 void
 add_http_port(char *portspec)
 {
-    AnyP::PortCfg *s = new AnyP::PortCfg();
+    AnyP::PortCfgPointer s = new AnyP::PortCfg();
     s->setTransport("HTTP");
     parsePortSpecification(s, portspec);
     // we may need to merge better if the above returns a list with clones
     assert(s->next == NULL);
-    s->next = cbdataReference(Config.Sockaddr.http);
-    cbdataReferenceDone(Config.Sockaddr.http);
-    Config.Sockaddr.http = cbdataReference(s);
+    s->next = HttpPortList;
+    HttpPortList = s;
 }
 
 static void
-parsePortCfg(AnyP::PortCfg ** head, const char *optionName)
+parsePortCfg(AnyP::PortCfgPointer *head, const char *optionName)
 {
     const char *protocol = NULL;
     if (strcmp(optionName, "http_port") == 0 ||
@@ -3821,7 +3797,7 @@ parsePortCfg(AnyP::PortCfg ** head, const char *optionName)
         return;
     }
 
-    AnyP::PortCfg *s = new AnyP::PortCfg();
+    AnyP::PortCfgPointer s = new AnyP::PortCfg();
     s->setTransport(protocol);
     parsePortSpecification(s, token);
 
@@ -3853,19 +3829,19 @@ parsePortCfg(AnyP::PortCfg ** head, const char *optionName)
 
     if (Ip::EnableIpv6&IPV6_SPECIAL_SPLITSTACK && s->s.isAnyAddr()) {
         // clone the port options from *s to *(s->next)
-        s->next = cbdataReference(s->clone());
+        s->next = s->clone();
         s->next->s.setIPv4();
         debugs(3, 3, AnyP::UriScheme(s->transport.protocol).c_str() << "_port: clone wildcard address for split-stack: " << s->s << " and " << s->next->s);
     }
 
-    while (*head)
-        head = &(*head)->next;
+    while (*head != NULL)
+        head = &((*head)->next);
 
-    *head = cbdataReference(s);
+    *head = s;
 }
 
 static void
-dump_generic_port(StoreEntry * e, const char *n, const AnyP::PortCfg * s)
+dump_generic_port(StoreEntry * e, const char *n, const AnyP::PortCfgPointer &s)
 {
     char buf[MAX_IPSTRLEN];
 
@@ -3989,23 +3965,11 @@ dump_generic_port(StoreEntry * e, const char *n, const AnyP::PortCfg * s)
 }
 
 static void
-dump_PortCfg(StoreEntry * e, const char *n, const AnyP::PortCfg * s)
+dump_PortCfg(StoreEntry * e, const char *n, const AnyP::PortCfgPointer &s)
 {
-    while (s) {
-        dump_generic_port(e, n, s);
+    for (AnyP::PortCfgPointer p = s; p != NULL; p = p->next) {
+        dump_generic_port(e, n, p);
         storeAppendPrintf(e, "\n");
-        s = s->next;
-    }
-}
-
-static void
-free_PortCfg(AnyP::PortCfg ** head)
-{
-    AnyP::PortCfg *s;
-
-    while ((s = *head) != NULL) {
-        *head = s->next;
-        cbdataReferenceDone(s);
     }
 }
 
@@ -37,10 +37,7 @@
  */
 
 #include "squid.h"
-
-#if HAVE_ERRNO_H
-#include <errno.h>
-#endif
+#include <cerrno>
 
 typedef struct {
     const char *name;
@@ -82,7 +82,7 @@ void
 CacheManager::registerProfile(const Mgr::ActionProfile::Pointer &profile)
 {
     Must(profile != NULL);
-    if (std::find(menu_.begin(), menu_.end(), profile) == menu_.end()) {
+    if (!CacheManager::findAction(profile->name)) {
         menu_.push_back(profile);
         debugs(16, 3, HERE << "registered profile: " << *profile);
     } else {
@@ -173,7 +173,7 @@ DOC_END
 NAME: ignore_ims_on_miss
 TYPE: obsolete
 DOC_START
-	Remove this line. The HTTP/1.1 feature is now fully supported by default.
+	Remove this line. The HTTP/1.1 feature is now configured by 'cache_miss_revalidate'.
 DOC_END
 
 # Options Removed in 3.2
@@ -294,7 +294,7 @@ DOC_START
 	This is used to define parameters for the various authentication
 	schemes supported by Squid.
 
-	format: auth_param scheme parameter [setting]
+		format: auth_param scheme parameter [setting]
 
 	The order in which authentication schemes are presented to the client is
 	dependent on the order the scheme first appears in config file. IE
@@ -331,307 +331,188 @@ DOC_START
 	=== Parameters common to all schemes. ===
 
 	"program" cmdline
-	Specifies the command for the external authenticator.  Such a program
-	runs a loop that, on every iteration, reads a request line from
-	the standard and responds with a scheme-specific answer. The loop
-	stops when all input is exchausted (EOF). See scheme-specific
-	"program" descriptions below for details.
+		Specifies the command for the external authenticator.
 
-	"key_extras" format
-	Specifies a string to be append to request line format for the
-	authentication helper. "Quoted" format values may contain spaces and
-	logformat %macros. In theory, any logformat %macro can be used.
-	In practice, a %macro expands as a dash (-) if the helper request is
-	sent before the required macro information is available to Squid.
-	By default, Squid uses request formats provided in scheme-specific
-	examples below (search for %credentials).
-	The expanded key_extras value is added to the Squid credentials
-	cache and, hence, will affect authentication. It can be used to
-	autenticate different users with identical user names (e.g., when user
-	authentication depends on http_port).
-	Avoid adding frequently changing information to key_extras. For
-	example, if you add user source IP, and it changes frequently
-	in your environment, then max_user_ip ACL is going to treat every
-	user+IP combination as a unique "user", breaking the ACL and
-	wasting a lot of memory on those user records. It will also force
-	users to authenticate from scratch whenever their IP changes.
-
-	=== Parameters for the basic scheme follow. ===
+		By default, each authentication scheme is not used unless a
+		program is specified.
 
-	"program" cmdline
-	Specify the command for the external authenticator.  Such a program
-	reads a request line ("username password" by default) and replies
-	with one of three results:
+		See http://wiki.squid-cache.org/Features/AddonHelpers for
+		more details on helper operations and creating your own.
 
-	  OK
-		the user exists.
+	"key_extras" format
+		Specifies a string to be append to request line format for
+		the authentication helper. "Quoted" format values may contain
+		spaces and logformat %macros. In theory, any logformat %macro
+		can be used. In practice, a %macro expands as a dash (-) if
+		the helper request is sent before the required macro
+		information is available to Squid.
+
+		By default, Squid uses request formats provided in
+		scheme-specific examples below (search for %credentials).
+
+		The expanded key_extras value is added to the Squid credentials
+		cache and, hence, will affect authentication. It can be used to
+		autenticate different users with identical user names (e.g.,
+		when user authentication depends on http_port).
+
+		Avoid adding frequently changing information to key_extras. For
+		example, if you add user source IP, and it changes frequently
+		in your environment, then max_user_ip ACL is going to treat
+		every user+IP combination as a unique "user", breaking the ACL
+		and wasting a lot of memory on those user records. It will also
+		force users to authenticate from scratch whenever their IP
+		changes.
+
+	"realm" string
+		Specifies the protection scope (aka realm name) which is to be
+		reported to the client for the authentication scheme. It is
+		commonly part of the text the user will see when prompted for
+		their username and password.
+
+		For Basic the default is "Squid proxy-caching web server".
+		For Digest there is no default, this parameter is mandatory.
+		For NTLM and Negotiate this parameter is ignored.
 
-	  ERR
-		the user does not exist.
+	"children" numberofchildren [startup=N] [idle=N] [concurrency=N]
 
-	  BH
-		An internal error occurred in the helper, preventing
-		a result being identified.
+		The maximum number of authenticator processes to spawn. If
+		you start too few Squid will have to wait for them to process
+		a backlog of credential verifications, slowing it down. When
+		password verifications are done via a (slow) network you are
+		likely to need lots of authenticator processes.
 
-	"ERR" and "BH" results may optionally be followed by message="..."
-	containing a description available as %m in the returned error page.
+		The startup= and idle= options permit some skew in the exact
+		amount run. A minimum of startup=N will begin during startup
+		and reconfigure. Squid will start more in groups of up to
+		idle=N in an attempt to meet traffic needs and to keep idle=N
+		free above those traffic needs up to the maximum.
 
-	If you use an authenticator, make sure you have 1 acl of type
-	proxy_auth.
+		The concurrency= option sets the number of concurrent requests
+		the helper can process.  The default of 0 is used for helpers
+		who only supports one request at a time. Setting this to a
+		number greater than 0 changes the protocol used to include a
+		channel ID field first on the request/response line, allowing
+		multiple requests to be sent to the same helper in parallel
+		without waiting for the response.
 
-	By default, the basic authentication scheme is not used unless a
-	program is specified.
+		Concurrency must not be set unless it's known the helper
+		supports the input format with channel-ID fields.
 
-	If you want to use the traditional NCSA proxy authentication, set
-	this line to something like
+		NOTE: NTLM and Negotiate schemes do not support concurrency
+			in the Squid code module even though some helpers can.
 
-	auth_param basic program @DEFAULT_PREFIX@/libexec/basic_ncsa_auth @DEFAULT_PREFIX@/etc/passwd
 
-	"utf8" on|off
-	HTTP uses iso-latin-1 as character set, while some authentication
-	backends such as LDAP expects UTF-8. If this is set to on Squid will
-	translate the HTTP iso-latin-1 charset to UTF-8 before sending the
-	username & password to the helper.
+IF HAVE_AUTH_MODULE_BASIC
+	=== Basic authentication parameters ===
 
-	"children" numberofchildren [startup=N] [idle=N] [concurrency=N]
-	The maximum number of authenticator processes to spawn. If you start too few
-	Squid will have to wait for them to process a backlog of credential
-	verifications, slowing it down. When password verifications are
-	done via a (slow) network you are likely to need lots of
-	authenticator processes.
-
-	The startup= and idle= options permit some skew in the exact amount
-	run. A minimum of startup=N will begin during startup and reconfigure.
-	Squid will start more in groups of up to idle=N in an attempt to meet
-	traffic needs and to keep idle=N free above those traffic needs up to
-	the maximum.
-
-	The concurrency= option sets the number of concurrent requests the
-	helper can process.  The default of 0 is used for helpers who only
-	supports one request at a time. Setting this to a number greater than
-	0 changes the protocol used to include a channel number first on the
-	request/response line, allowing multiple requests to be sent to the
-	same helper in parallel without waiting for the response.
-	Must not be set unless it's known the helper supports this.
-
-	auth_param basic children 20 startup=0 idle=1
-
-	"realm" realmstring
-	Specifies the realm name which is to be reported to the
-	client for the basic proxy authentication scheme (part of
-	the text the user will see when prompted their username and
-	password). There is no default.
-	auth_param basic realm Squid proxy-caching web server
+	"utf8" on|off
+		HTTP uses iso-latin-1 as character set, while some
+		authentication backends such as LDAP expects UTF-8. If this is
+		set to on Squid will translate the HTTP iso-latin-1 charset to
+		UTF-8 before sending the username and password to the helper.
 
 	"credentialsttl" timetolive
-	Specifies how long squid assumes an externally validated
-	username:password pair is valid for - in other words how
-	often the helper program is called for that user. Set this
-	low to force revalidation with short lived passwords.  Note
-	setting this high does not impact your susceptibility
-	to replay attacks unless you are using an one-time password
-	system (such as SecureID).  If you are using such a system,
-	you will be vulnerable to replay attacks unless you also
-	use the max_user_ip ACL in an http_access rule.
-
-	"casesensitive" on|off
-	Specifies if usernames are case sensitive. Most user databases are
-	case insensitive allowing the same username to be spelled using both
-	lower and upper case letters, but some are case sensitive. This
-	makes a big difference for user_max_ip ACL processing and similar.
-	auth_param basic casesensitive off
-
-	=== Parameters for the digest scheme follow ===
+		Specifies how long squid assumes an externally validated
+		username:password pair is valid for - in other words how
+		often the helper program is called for that user. Set this
+		low to force revalidation with short lived passwords.
 
-	"program" cmdline
-	Specify the command for the external authenticator.  Such a program
-	reads a request_format line ("username":"realm" by default) and
-	replies with one of three results:
-
-	  OK ha1="..."
-		the user exists. The ha1= key is mandatory and
-		contains the appropriate H(A1) value, hex encoded.
-		See rfc 2616 for the definition of H(A1).
-
-	  ERR
-		the user does not exist.
+		NOTE: setting this high does not impact your susceptibility
+		to replay attacks unless you are using an one-time password
+		system (such as SecureID). If you are using such a system,
+		you will be vulnerable to replay attacks unless you also
+		use the max_user_ip ACL in an http_access rule.
 
-	  BH
-		An internal error occurred in the helper, preventing
-		a result being identified.
-
-	"ERR" and "BH" results may optionally be followed by message="..."
-	containing a description available as %m in the returned error page.
-
-	By default, the digest authentication scheme is not used unless a
-	program is specified.
-
-	If you want to use a digest authenticator, set this line to
-	something like
+	"casesensitive" on|off
+		Specifies if usernames are case sensitive. Most user databases
+		are case insensitive allowing the same username to be spelled
+		using both lower and upper case letters, but some are case
+		sensitive. This makes a big difference for user_max_ip ACL
+		processing and similar.
 
-	auth_param digest program @DEFAULT_PREFIX@/bin/digest_pw_auth @DEFAULT_PREFIX@/etc/digpass
+ENDIF
+IF HAVE_AUTH_MODULE_DIGEST
+	=== Digest authentication parameters ===
 
 	"utf8" on|off
-	HTTP uses iso-latin-1 as character set, while some authentication
-	backends such as LDAP expects UTF-8. If this is set to on Squid will
-	translate the HTTP iso-latin-1 charset to UTF-8 before sending the
-	username & password to the helper.
-
-	"children" numberofchildren [startup=N] [idle=N] [concurrency=N]
-	The maximum number of authenticator processes to spawn (default 5).
-	If you start too few Squid will have to wait for them to
-	process a backlog of H(A1) calculations, slowing it down.
-	When the H(A1) calculations are done via a (slow) network
-	you are likely to need lots of authenticator processes.
-
-	The startup= and idle= options permit some skew in the exact amount
-	run. A minimum of startup=N will begin during startup and reconfigure.
-	Squid will start more in groups of up to idle=N in an attempt to meet
-	traffic needs and to keep idle=N free above those traffic needs up to
-	the maximum.
-
-	The concurrency= option sets the number of concurrent requests the
-	helper can process.  The default of 0 is used for helpers who only
-	supports one request at a time. Setting this to a number greater than
-	0 changes the protocol used to include a channel number first on the
-	request/response line, allowing multiple requests to be sent to the
-	same helper in parallel without waiting for the response.
-	Must not be set unless it's known the helper supports this.
-
-	auth_param digest children 20 startup=0 idle=1
-
-	"realm" realmstring
-	Specifies the realm name which is to be reported to the
-	client for the digest proxy authentication scheme (part of
-	the text the user will see when prompted their username and
-	password). There is no default.
-	auth_param digest realm Squid proxy-caching web server
+		HTTP uses iso-latin-1 as character set, while some
+		authentication backends such as LDAP expects UTF-8. If this is
+		set to on Squid will translate the HTTP iso-latin-1 charset to
+		UTF-8 before sending the username and password to the helper.
 
 	"nonce_garbage_interval" timeinterval
-	Specifies the interval that nonces that have been issued
-	to client_agent's are checked for validity.
+		Specifies the interval that nonces that have been issued
+		to client_agent's are checked for validity.
 
 	"nonce_max_duration" timeinterval
-	Specifies the maximum length of time a given nonce will be
-	valid for.
+		Specifies the maximum length of time a given nonce will be
+		valid for.
 
 	"nonce_max_count" number
-	Specifies the maximum number of times a given nonce can be
-	used.
+		Specifies the maximum number of times a given nonce can be
+		used.
 
 	"nonce_strictness" on|off
-	Determines if squid requires strict increment-by-1 behavior
-	for nonce counts, or just incrementing (off - for use when
-	user agents generate nonce counts that occasionally miss 1
-	(ie, 1,2,4,6)). Default off.
+		Determines if squid requires strict increment-by-1 behavior
+		for nonce counts, or just incrementing (off - for use when
+		user agents generate nonce counts that occasionally miss 1
+		(ie, 1,2,4,6)). Default off.
 
 	"check_nonce_count" on|off
-	This directive if set to off can disable the nonce count check
-	completely to work around buggy digest qop implementations in
-	certain mainstream browser versions. Default on to check the
-	nonce count to protect from authentication replay attacks.
+		This directive if set to off can disable the nonce count check
+		completely to work around buggy digest qop implementations in
+		certain mainstream browser versions. Default on to check the
+		nonce count to protect from authentication replay attacks.
 
 	"post_workaround" on|off
-	This is a workaround to certain buggy browsers who sends
-	an incorrect request digest in POST requests when reusing
-	the same nonce as acquired earlier on a GET request.
+		This is a workaround to certain buggy browsers who send an
+		incorrect request digest in POST requests when reusing the
+		same nonce as acquired earlier on a GET request.
 
-	=== NTLM scheme options follow ===
-
-	"program" cmdline
-	Specify the command for the external NTLM authenticator.
-	Such a program reads exchanged NTLMSSP packets with
-	the browser via Squid until authentication is completed.
-	If you use an NTLM authenticator, make sure you have 1 acl
-	of type proxy_auth.  By default, the NTLM authenticator program
-	is not used.
-
-	auth_param ntlm program /usr/bin/ntlm_auth
-
-	"children" numberofchildren [startup=N] [idle=N]
-	The maximum number of authenticator processes to spawn (default 5).
-	If you start too few Squid will have to wait for them to
-	process a backlog of credential verifications, slowing it
-	down. When credential verifications are done via a (slow)
-	network you are likely to need lots of authenticator
-	processes.
-
-	The startup= and idle= options permit some skew in the exact amount
-	run. A minimum of startup=N will begin during startup and reconfigure.
-	Squid will start more in groups of up to idle=N in an attempt to meet
-	traffic needs and to keep idle=N free above those traffic needs up to
-	the maximum.
-
-	auth_param ntlm children 20 startup=0 idle=1
+ENDIF
+IF HAVE_AUTH_MODULE_NEGOTIATE
+	=== Negotiate authentication parameters ===
 
 	"keep_alive" on|off
-	If you experience problems with PUT/POST requests when using the
-	Negotiate authentication scheme then you can try setting this to
-	off. This will cause Squid to forcibly close the connection on
-	the initial requests where the browser asks which schemes are
-	supported by the proxy.
-
-	auth_param ntlm keep_alive on
+		If you experience problems with PUT/POST requests when using
+		the this authentication scheme then you can try setting this
+		to off. This will cause Squid to forcibly close the connection
+		on the initial request where the browser asks which schemes
+		are supported by the proxy.
 
-	=== Options for configuring the NEGOTIATE auth-scheme follow ===
-
-	"program" cmdline
-	Specify the command for the external Negotiate authenticator.
-	This protocol is used in Microsoft Active-Directory enabled setups with
-	the Microsoft Internet Explorer or Mozilla Firefox browsers.
-	Its main purpose is to exchange credentials with the Squid proxy
-	using the Kerberos mechanisms.
-	If you use a Negotiate authenticator, make sure you have at least
-	one acl of type proxy_auth active. By default, the negotiate
-	authenticator program is not used.
-	The only supported program for this role is the ntlm_auth
-	program distributed as part of Samba, version 4 or later.
-
-	auth_param negotiate program /usr/bin/ntlm_auth --helper-protocol=gss-spnego
-
-	"children" numberofchildren [startup=N] [idle=N]
-	The maximum number of authenticator processes to spawn (default 5).
-	If you start too few Squid will have to wait for them to
-	process a backlog of credential verifications, slowing it
-	down. When credential verifications are done via a (slow)
-	network you are likely to need lots of authenticator
-	processes.
-
-	The startup= and idle= options permit some skew in the exact amount
-	run. A minimum of startup=N will begin during startup and reconfigure.
-	Squid will start more in groups of up to idle=N in an attempt to meet
-	traffic needs and to keep idle=N free above those traffic needs up to
-	the maximum.
-
-	auth_param negotiate children 20 startup=0 idle=1
+ENDIF
+IF HAVE_AUTH_MODULE_NTLM
+	=== NTLM authentication parameters ===
 
 	"keep_alive" on|off
-	If you experience problems with PUT/POST requests when using the
-	Negotiate authentication scheme then you can try setting this to
-	off. This will cause Squid to forcibly close the connection on
-	the initial requests where the browser asks which schemes are
-	supported by the proxy.
+		If you experience problems with PUT/POST requests when using
+		the this authentication scheme then you can try setting this
+		to off. This will cause Squid to forcibly close the connection
+		on the initial request where the browser asks which schemes
+		are supported by the proxy.
+ENDIF
 
-	auth_param negotiate keep_alive on
-	
-	Examples:
+	=== Example Configuration ===
+
+	This configuration displays the recommended authentication scheme
+	order from most to least secure with recommended minimum configuration
+	settings for each scheme:
 
-#Recommended minimum configuration per scheme:
 #auth_param negotiate program <uncomment and complete this line to activate>
 #auth_param negotiate children 20 startup=0 idle=1
 #auth_param negotiate keep_alive on
 #
-#auth_param ntlm program <uncomment and complete this line to activate>
-#auth_param ntlm children 20 startup=0 idle=1
-#auth_param ntlm keep_alive on
-#
-#auth_param digest program <uncomment and complete this line>
+#auth_param digest program <uncomment and complete this line to activate>
 #auth_param digest children 20 startup=0 idle=1
 #auth_param digest realm Squid proxy-caching web server
 #auth_param digest nonce_garbage_interval 5 minutes
 #auth_param digest nonce_max_duration 30 minutes
 #auth_param digest nonce_max_count 50
 #
+#auth_param ntlm program <uncomment and complete this line to activate>
+#auth_param ntlm children 20 startup=0 idle=1
+#auth_param ntlm keep_alive on
+#
 #auth_param basic program <uncomment and complete this line>
 #auth_param basic children 5 startup=5 idle=1
 #auth_param basic realm Squid proxy-caching web server
@@ -710,7 +591,7 @@ DOC_START
 			Up to the value of children-max. (default 1)
 	  concurrency=n	concurrency level per process. Only used with helpers
 			capable of processing more than one query at a time.
-	  cache=n	limit the result cache size, default is unbounded.
+	  cache=n	limit the result cache size, default is 262144.
 	  grace=n	Percentage remaining of TTL where a refresh of a
 			cached entry should be initiated without needing to
 			wait for a new reply. (default is for no grace period)
@@ -835,6 +716,10 @@ DOC_START
 	  log=		String to be logged in access.log. Available as
 	  		%ea in logformat specifications.
 
+  	  clt_conn_tag= Associates a TAG with the client TCP connection.
+			Please see url_rewrite_program related documentation for
+			this kv-pair.
+
 	Any keywords may be sent on any response whether OK, ERR or BH.
 
 	All response keyword values need to be a single token with URL
@@ -1090,7 +975,9 @@ DOC_START
 	  # use REQUIRED to accept any non-null user name.
 
 	acl aclname tag tagvalue ...
-	  # string match on tag returned by external acl helper [slow]
+	  # string match on tag returned by external acl helper [fast]
+	  # DEPRECATED. Only the first tag will match with this ACL.
+	  # Use the 'note' ACL instead for handling multiple tag values.
 
 	acl aclname hier_code codename ...
 	  # string match against squid hierarchy code(s); [fast]
@@ -1615,7 +1502,7 @@ COMMENT_END
 NAME: http_port ascii_port
 TYPE: PortCfg
 DEFAULT: none
-LOC: Config.Sockaddr.http
+LOC: HttpPortList
 DOC_START
 	Usage:	port [mode] [options]
 		hostname:port [mode] [options]
@@ -1852,7 +1739,7 @@ NAME: https_port
 IFDEF: USE_OPENSSL
 TYPE: PortCfg
 DEFAULT: none
-LOC: Config.Sockaddr.https
+LOC: HttpsPortList
 DOC_START
 	Usage:  [ip:]port cert=certificate.pem [key=key.pem] [mode] [options...]
 
@@ -1982,7 +1869,7 @@ DOC_END
 NAME: ftp_port
 TYPE: PortCfg
 DEFAULT: none
-LOC: Config.Sockaddr.ftp
+LOC: FtpPortList
 DOC_START
 	Usage:  [ip:]port [options]
 
@@ -2022,6 +1909,8 @@ DOC_START
 
 	Processing proceeds in the order specified, and stops at first fully
 	matching line.
+
+	Only fast ACLs are supported.
 DOC_END
 
 NAME: clientside_tos
@@ -2064,6 +1953,8 @@ DOC_START
 	acl good_service_net src 10.0.1.0/24
 	tcp_outgoing_mark 0x00 normal_service_net
 	tcp_outgoing_mark 0x20 good_service_net
+
+	Only fast ACLs are supported.
 DOC_END
 
 NAME: clientside_mark
@@ -3693,6 +3584,19 @@ DOC_START
 	disks. This algorithm does not spread objects by size, so any
 	I/O loading per-disk may appear very unbalanced and volatile.
 
+	If several cache_dirs use similar min-size, max-size, or other
+	limits to to reject certain responses, then do not group such
+	cache_dir lines together, to avoid round-robin selection bias
+	towards the first cache_dir after the group. Instead, interleave
+	cache_dir lines from different groups. For example:
+
+		store_dir_select_algorithm round-robin
+		cache_dir rock /hdd1 ... min-size=100000
+		cache_dir rock /ssd1 ... max-size=99999
+		cache_dir rock /hdd2 ... min-size=100000
+		cache_dir rock /ssd2 ... max-size=99999
+		cache_dir rock /hdd3 ... min-size=100000
+		cache_dir rock /ssd3 ... max-size=99999
 DOC_END
 
 NAME: max_open_disk_fds
@@ -4710,7 +4614,8 @@ DOC_START
 
 	  [channel-ID <SP>] URL [<SP> extras]<NL>
 
-
+	See url_rewrite_extras on how to send "extras" with optional values to
+	the helper.
 	After processing the request the helper must reply using the following format:
 
 	  [channel-ID <SP>] result [<SP> kv-pairs]
@@ -4742,10 +4647,14 @@ DOC_START
 		reserved for delivering a log message.
 
 
-	In the future, the interface protocol will be extended with
-	key=value pairs ("kv-pairs" shown above).  Helper programs
-	should be prepared to receive and possibly ignore additional
-	whitespace-separated tokens on each input line.
+	In addition to the above kv-pairs Squid also understands the following
+	optional kv-pairs received from URL rewriters:
+	  clt_conn_tag=TAG
+		Associates a TAG with the client TCP connection.
+		The TAG is treated as a regular annotation but persists across
+		future requests on the client connection rather than just the
+		current request. A helper may update the TAG during subsequent
+		requests be returning a new kv-pair.
 
 	When using the concurrency= option the protocol is changed by
 	introducing a query channel tag in front of the request/response.
@@ -4902,6 +4811,12 @@ DOC_START
 		An internal error occured in the helper, preventing
 		a result being identified.
 
+	In addition to the above kv-pairs Squid also understands the following
+	optional kv-pairs received from URL rewriters:
+	  clt_conn_tag=TAG
+		Associates a TAG with the client TCP connection.
+		Please see url_rewrite_program related documentation for this
+		kv-pair
 
 	Helper programs should be prepared to receive and possibly ignore
 	additional whitespace-separated tokens on each input line.
@@ -5268,7 +5183,7 @@ DOC_START
 	downloads.
 
 	When the user aborts a request, Squid will check the
-	quick_abort values to the amount of data transfered until
+	quick_abort values to the amount of data transferred until
 	then.
 
 	If the transfer has less than 'quick_abort_min' KB remaining,
@@ -7626,17 +7541,25 @@ TYPE: onoff
 DEFAULT: on
 LOC: Config.onoff.cache_miss_revalidate
 DOC_START
-	Whether Squid on cache MISS will pass client revalidation requests
-	to the server or tries to fetch new content for caching.
-	This is useful while the cache is mostly empty to more quickly
-	have the cache populated.
+	RFC 7232 defines a conditional request mechanism to prevent
+	response objects being unnecessarily transferred over the network.
+	If that mechanism is used by the client and a cache MISS occurs
+	it can prevent new cache entries being created.
+
+	This option determines whether Squid on cache MISS will pass the
+	client revalidation request to the server or tries to fetch new
+	content for caching. It can be useful while the cache is mostly
+	empty to more quickly have the cache populated by generating
+	non-conditional GETs.
 
 	When set to 'on' (default), Squid will pass all client If-* headers
-	to the server.
+	to the server. This permits server responses without a cacheable
+	payload to be delivered and on MISS no new cache entry is created.
 
 	When set to 'off' and if the request is cacheable, Squid will
 	remove the clients If-Modified-Since and If-None-Match headers from
-	the request sent to the server.
+	the request sent to the server. This requests a 200 status response
+	from the server to create a new cache entry with.
 DOC_END
 
 NAME: always_direct
@@ -95,6 +95,7 @@
 #include "comm/Connection.h"
 #include "comm/ConnOpener.h"
 #include "comm/Loops.h"
+#include "comm/Read.h"
 #include "comm/TcpAcceptor.h"
 #include "comm/Write.h"
 #include "CommCalls.h"
@@ -165,13 +166,13 @@
 class ListeningStartedDialer: public CallDialer, public Ipc::StartListeningCb
 {
 public:
-    typedef void (*Handler)(AnyP::PortCfg *portCfg, const Ipc::FdNoteId note, const Subscription::Pointer &sub);
-    ListeningStartedDialer(Handler aHandler, AnyP::PortCfg *aPortCfg, const Ipc::FdNoteId note, const Subscription::Pointer &aSub):
+    typedef void (*Handler)(AnyP::PortCfgPointer &portCfg, const Ipc::FdNoteId note, const Subscription::Pointer &sub);
+    ListeningStartedDialer(Handler aHandler, AnyP::PortCfgPointer &aPortCfg, const Ipc::FdNoteId note, const Subscription::Pointer &aSub):
             handler(aHandler), portCfg(aPortCfg), portTypeNote(note), sub(aSub) {}
 
     virtual void print(std::ostream &os) const {
         startPrint(os) <<
-        ", " << FdNote(portTypeNote) << " port=" << (void*)portCfg << ')';
+        ", " << FdNote(portTypeNote) << " port=" << (void*)&portCfg << ')';
     }
 
     virtual bool canDial(AsyncCall &) const { return true; }
@@ -181,12 +182,12 @@ class ListeningStartedDialer: public CallDialer, public Ipc::StartListeningCb
     Handler handler;
 
 private:
-    AnyP::PortCfg *portCfg;   ///< from Config.Sockaddr.http
+    AnyP::PortCfgPointer portCfg;   ///< from HttpPortList
     Ipc::FdNoteId portTypeNote;    ///< Type of IPC socket being opened
     Subscription::Pointer sub; ///< The handler to be subscribed for this connetion listener
 };
 
-static void clientListenerConnectionOpened(AnyP::PortCfg *s, const Ipc::FdNoteId portTypeNote, const Subscription::Pointer &sub);
+static void clientListenerConnectionOpened(AnyP::PortCfgPointer &s, const Ipc::FdNoteId portTypeNote, const Subscription::Pointer &sub);
 
 /* our socket-related context */
 
@@ -299,8 +300,8 @@ ClientSocketContext::getConn() const
 }
 
 /**
- * This routine should be called to grow the inbuf and then
- * call comm_read().
+ * This routine should be called to grow the in.buf and then
+ * call Comm::Read().
  */
 void
 ConnStateData::readSomeData()
@@ -315,7 +316,7 @@ ConnStateData::readSomeData()
 
     typedef CommCbMemFunT<ConnStateData, CommIoCbParams> Dialer;
     reader = JobCallback(33, 5, Dialer, this, ConnStateData::clientReadRequest);
-    comm_read(clientConnection, in.buf, reader);
+    Comm::Read(clientConnection, reader);
 }
 
 void
@@ -461,12 +462,12 @@ ClientSocketContext::writeControlMsg(HttpControlMsg &msg)
 
 /// called when we wrote the 1xx response
 void
-ClientSocketContext::wroteControlMsg(const Comm::ConnectionPointer &conn, char *, size_t, comm_err_t errflag, int xerrno)
+ClientSocketContext::wroteControlMsg(const Comm::ConnectionPointer &conn, char *, size_t, Comm::Flag errflag, int xerrno)
 {
-    if (errflag == COMM_ERR_CLOSING)
+    if (errflag == Comm::ERR_CLOSING)
         return;
 
-    if (errflag == COMM_OK) {
+    if (errflag == Comm::OK) {
         ScheduleCallHere(cbControlMsgSent);
         return;
     }
@@ -482,7 +483,7 @@ ClientSocketContext::wroteControlMsg(const Comm::ConnectionPointer &conn, char *
 
 /// wroteControlMsg() wrapper: ClientSocketContext is not an AsyncJob
 void
-ClientSocketContext::WroteControlMsg(const Comm::ConnectionPointer &conn, char *bufnotused, size_t size, comm_err_t errflag, int xerrno, void *data)
+ClientSocketContext::WroteControlMsg(const Comm::ConnectionPointer &conn, char *bufnotused, size_t size, Comm::Flag errflag, int xerrno, void *data)
 {
     ClientSocketContext *context = static_cast<ClientSocketContext*>(data);
     context->wroteControlMsg(conn, bufnotused, size, errflag, xerrno);
@@ -966,8 +967,6 @@ ConnStateData::~ConnStateData()
     if (!flags.swanSang)
         debugs(33, DBG_IMPORTANT, "BUG: ConnStateData was not destroyed properly; " << clientConnection);
 
-    cbdataReferenceDone(port);
-
     if (bodyPipe != NULL)
         stopProducingFor(bodyPipe, false);
 
@@ -1149,7 +1148,7 @@ ClientSocketContext::sendBody(HttpReply * rep, StoreIOBuffer bodyData)
                                              CommIoCbPtrFun(clientWriteComplete, this));
         Comm::Write(clientConnection, &mb, call);
     }  else
-        writeComplete(clientConnection, NULL, 0, COMM_OK);
+        writeComplete(clientConnection, NULL, 0, Comm::OK);
 }
 
 /**
@@ -1599,7 +1598,7 @@ clientSocketRecipient(clientStreamNode * node, ClientHttpRequest * http,
     const bool mustSendLastChunk = http->request->flags.chunkedReply &&
                                    !http->request->flags.streamError && !context->startOfOutput();
     if (responseFinishedOrFailed(rep, receivedData) && !mustSendLastChunk) {
-        context->writeComplete(context->clientConnection, NULL, 0, COMM_OK);
+        context->writeComplete(context->clientConnection, NULL, 0, Comm::OK);
         PROF_stop(clientSocketRecipient);
         return;
     }
@@ -1643,7 +1642,7 @@ clientSocketDetach(clientStreamNode * node, ClientHttpRequest * http)
 }
 
 static void
-clientWriteBodyComplete(const Comm::ConnectionPointer &conn, char *buf, size_t size, comm_err_t errflag, int xerrno, void *data)
+clientWriteBodyComplete(const Comm::ConnectionPointer &conn, char *buf, size_t size, Comm::Flag errflag, int xerrno, void *data)
 {
     debugs(33,7, HERE << "clientWriteBodyComplete schedules clientWriteComplete");
     clientWriteComplete(conn, NULL, size, errflag, xerrno, data);
@@ -1939,7 +1938,7 @@ ClientSocketContext::socketState()
  * no more data to send.
  */
 void
-clientWriteComplete(const Comm::ConnectionPointer &conn, char *bufnotused, size_t size, comm_err_t errflag, int xerrno, void *data)
+clientWriteComplete(const Comm::ConnectionPointer &conn, char *bufnotused, size_t size, Comm::Flag errflag, int xerrno, void *data)
 {
     ClientSocketContext *context = (ClientSocketContext *)data;
     context->writeComplete(conn, bufnotused, size, errflag);
@@ -1995,7 +1994,7 @@ ConnStateData::stopSending(const char *error)
 }
 
 void
-ClientSocketContext::writeComplete(const Comm::ConnectionPointer &conn, char *bufnotused, size_t size, comm_err_t errflag)
+ClientSocketContext::writeComplete(const Comm::ConnectionPointer &conn, char *bufnotused, size_t size, Comm::Flag errflag)
 {
     const StoreEntry *entry = http->storeEntry();
     http->out.size += size;
@@ -2004,9 +2003,9 @@ ClientSocketContext::writeComplete(const Comm::ConnectionPointer &conn, char *bu
            (entry ? entry->objectLen() : 0));
     clientUpdateSocketStats(http->logType, size);
 
-    /* Bail out quickly on COMM_ERR_CLOSING - close handlers will tidy up */
+    /* Bail out quickly on Comm::ERR_CLOSING - close handlers will tidy up */
 
-    if (errflag == COMM_ERR_CLOSING || !Comm::IsConnOpen(conn))
+    if (errflag == Comm::ERR_CLOSING || !Comm::IsConnOpen(conn))
         return;
 
     if (errflag || clientHttpRequestStatus(conn->fd, http)) {
@@ -2361,7 +2360,7 @@ parseHttpRequest(ConnStateData *csd, HttpParser *hp, HttpRequestMethod * method_
     *method_p = HttpRequestMethod(&hp->buf[hp->req.m_start], &hp->buf[hp->req.m_end]+1);
 
     /* deny CONNECT via accelerated ports */
-    if (*method_p == Http::METHOD_CONNECT && csd->port && csd->port->flags.accelSurrogate) {
+    if (*method_p == Http::METHOD_CONNECT && csd->port != NULL && csd->port->flags.accelSurrogate) {
         debugs(33, DBG_IMPORTANT, "WARNING: CONNECT method received on " << csd->port->transport.protocol << " Accelerator port " << csd->port->s.port());
         /* XXX need a way to say "this many character length string" */
         debugs(33, DBG_IMPORTANT, "WARNING: for request: " << hp->buf);
@@ -2485,8 +2484,14 @@ ConnStateData::In::maybeMakeSpaceAvailable()
             debugs(33, 4, "request buffer full: client_request_buffer_max_size=" << Config.maxRequestBufferSize);
             return false;
         }
-        const SBuf::size_type wantCapacity = min(static_cast<SBuf::size_type>(Config.maxRequestBufferSize), haveCapacity*2);
-        buf.reserveCapacity(wantCapacity);
+        if (haveCapacity == 0) {
+            // haveCapacity is based on the SBuf visible window of the MemBlob buffer, which may fill up.
+            // at which point bump the buffer back to default. This allocates a new MemBlob with any un-parsed bytes.
+            buf.reserveCapacity(CLIENT_REQ_BUF_SZ);
+        } else {
+            const SBuf::size_type wantCapacity = min(static_cast<SBuf::size_type>(Config.maxRequestBufferSize), haveCapacity*2);
+            buf.reserveCapacity(wantCapacity);
+        }
         debugs(33, 2, "growing request buffer: available=" << buf.spaceSize() << " used=" << buf.length());
     }
     return (buf.spaceSize() >= 2);
@@ -2515,26 +2520,6 @@ ConnStateData::getConcurrentRequestCount() const
     return result;
 }
 
-int
-ConnStateData::connReadWasError(comm_err_t flag, int size, int xerrno)
-{
-    if (flag != COMM_OK) {
-        debugs(33, 2, "connReadWasError: FD " << clientConnection << ": got flag " << flag);
-        return 1;
-    }
-
-    if (size < 0) {
-        if (!ignoreErrno(xerrno)) {
-            debugs(33, 2, "connReadWasError: FD " << clientConnection << ": " << xstrerr(xerrno));
-            return 1;
-        } else if (in.buf.isEmpty()) {
-            debugs(33, 2, "connReadWasError: FD " << clientConnection << ": no data to process (" << xstrerr(xerrno) << ")");
-        }
-    }
-
-    return 0;
-}
-
 int
 ConnStateData::connFinishedWithConn(int size)
 {
@@ -3147,62 +3132,71 @@ ConnStateData::clientParseRequests()
 void
 ConnStateData::clientReadRequest(const CommIoCbParams &io)
 {
-    debugs(33,5,HERE << io.conn << " size " << io.size);
+    debugs(33,5, io.conn);
     Must(reading());
     reader = NULL;
 
-    /* Bail out quickly on COMM_ERR_CLOSING - close handlers will tidy up */
-
-    if (io.flag == COMM_ERR_CLOSING) {
-        debugs(33,5, HERE << io.conn << " closing Bailout.");
+    /* Bail out quickly on Comm::ERR_CLOSING - close handlers will tidy up */
+    if (io.flag == Comm::ERR_CLOSING) {
+        debugs(33,5, io.conn << " closing Bailout.");
         return;
     }
 
     assert(Comm::IsConnOpen(clientConnection));
     assert(io.conn->fd == clientConnection->fd);
 
     /*
-     * Don't reset the timeout value here.  The timeout value will be
-     * set to Config.Timeout.request by httpAccept() and
-     * clientWriteComplete(), and should apply to the request as a
-     * whole, not individual read() calls.  Plus, it breaks our
-     * lame half-close detection
+     * Don't reset the timeout value here. The value should be
+     * counting Config.Timeout.request and applies to the request
+     * as a whole, not individual read() calls.
+     * Plus, it breaks our lame *HalfClosed() detection
      */
-    if (connReadWasError(io.flag, io.size, io.xerrno)) {
-        notifyAllContexts(io.xerrno);
-        io.conn->close();
+
+    CommIoCbParams rd(this); // will be expanded with ReadNow results
+    rd.conn = io.conn;
+    switch (Comm::ReadNow(rd, in.buf)) {
+    case Comm::INPROGRESS:
+        if (in.buf.isEmpty())
+            debugs(33, 2, io.conn << ": no data to process, " << xstrerr(rd.xerrno));
+        readSomeData();
         return;
-    }
 
-    if (io.flag == COMM_OK) {
-        if (io.size > 0) {
-            kb_incr(&(statCounter.client_http.kbytes_in), io.size);
+    case Comm::OK:
+        kb_incr(&(statCounter.client_http.kbytes_in), rd.size);
+        // may comm_close or setReplyToError
+        if (!handleReadData())
+            return;
 
-            // may comm_close or setReplyToError
-            if (!handleReadData(io.buf2))
-                return;
+        /* Continue to process previously read data */
+        break;
 
-        } else if (io.size == 0) {
-            debugs(33, 5, HERE << io.conn << " closed?");
+    case Comm::ENDFILE: // close detected by 0-byte read
+        debugs(33, 5, io.conn << " closed?");
 
-            if (connFinishedWithConn(io.size)) {
-                clientConnection->close();
-                return;
-            }
+        if (connFinishedWithConn(rd.size)) {
+            clientConnection->close();
+            return;
+        }
 
-            /* It might be half-closed, we can't tell */
-            fd_table[io.conn->fd].flags.socket_eof = true;
+        /* It might be half-closed, we can't tell */
+        fd_table[io.conn->fd].flags.socket_eof = true;
+        commMarkHalfClosed(io.conn->fd);
+        fd_note(io.conn->fd, "half-closed");
 
-            commMarkHalfClosed(io.conn->fd);
+        /* There is one more close check at the end, to detect aborted
+         * (partial) requests. At this point we can't tell if the request
+         * is partial.
+         */
 
-            fd_note(io.conn->fd, "half-closed");
+        /* Continue to process previously read data */
+        break;
 
-            /* There is one more close check at the end, to detect aborted
-             * (partial) requests. At this point we can't tell if the request
-             * is partial.
-             */
-            /* Continue to process previously read data */
-        }
+        // case Comm::COMM_ERROR:
+    default: // no other flags should ever occur
+        debugs(33, 2, io.conn << ": got flag " << rd.flag << "; " << xstrerr(rd.xerrno));
+        notifyAllContexts(rd.xerrno);
+        io.conn->close();
+        return;
     }
 
     /* Process next request */
@@ -3243,7 +3237,7 @@ ConnStateData::clientReadFtpData(const CommIoCbParams &io)
     assert(Comm::IsConnOpen(ftp.dataConn));
     assert(io.conn->fd == ftp.dataConn->fd);
 
-    if (io.flag == COMM_OK && bodyPipe != NULL) {
+    if (io.flag == Comm::OK && bodyPipe != NULL) {
         if (io.size > 0) {
             kb_incr(&(statCounter.client_http.kbytes_in), io.size);
 
@@ -3258,7 +3252,7 @@ ConnStateData::clientReadFtpData(const CommIoCbParams &io)
             if (ftp.uploadAvailSize <= 0)
                 finishDechunkingRequest(true);
         }
-    } else { //not COMM_OK or unexpected read
+    } else { // not Comm::Flags::OK or unexpected read
         debugs(33, 5, HERE << io.conn << " closed");
         FtpCloseDataConnection(this);
         finishDechunkingRequest(false);
@@ -3293,10 +3287,8 @@ ConnStateData::handleFtpRequestData()
  * \retval true  we did not call comm_close or setReplyToError
  */
 bool
-ConnStateData::handleReadData(SBuf *buf)
+ConnStateData::handleReadData()
 {
-    assert(buf == &in.buf); // XXX: make this abort the transaction if this fails
-
     // if we are reading a body, stuff data into the body pipe
     if (bodyPipe != NULL)
         return handleRequestBodyData();
@@ -3511,11 +3503,12 @@ ConnStateData::ConnStateData(const MasterXaction::Pointer &xact):
 
     // store the details required for creating more MasterXaction objects as new requests come in
     clientConnection = xact->tcpClient;
-    port = cbdataReference(xact->squidPort.get());
+    port = xact->squidPort;
     log_addr = xact->tcpClient->remote;
     log_addr.applyMask(Config.Addrs.client_netmask);
 
-    in.buf.reserveCapacity(CLIENT_REQ_BUF_SZ);
+    // ensure a buffer is present for this connection
+    in.maybeMakeSpaceAvailable();
 
     if (port->disable_pmtu_discovery != DISABLE_PMTU_OFF &&
             (transparent() || port->disable_pmtu_discovery == DISABLE_PMTU_ALWAYS)) {
@@ -3569,13 +3562,9 @@ httpAccept(const CommAcceptCbParams &params)
     MasterXaction::Pointer xact = params.xaction;
     AnyP::PortCfgPointer s = xact->squidPort;
 
-    if (!s.valid()) {
-        // it is possible the call or accept() was still queued when the port was reconfigured
-        debugs(33, 2, "HTTP accept failure: port reconfigured.");
-        return;
-    }
+    // NP: it is possible the port was reconfigured when the call or accept() was queued.
 
-    if (params.flag != COMM_OK) {
+    if (params.flag != Comm::OK) {
         // Its possible the call was still queued when the client disconnected
         debugs(33, 2, "httpAccept: " << s->listenConn << ": accept failure: " << xstrerr(params.xerrno));
         return;
@@ -3865,8 +3854,11 @@ httpsSslBumpAccessCheckDone(allow_t answer, void *data)
         // fake a CONNECT request to force connState to tunnel
         static char ip[MAX_IPSTRLEN];
         connState->clientConnection->local.toUrl(ip, sizeof(ip));
-        connState->in.buf.append("CONNECT ").append(ip).append(" HTTP/1.1\r\nHost: ").append(ip).append("\r\n\r\n");
-        bool ret = connState->handleReadData(&connState->in.buf);
+        // Pre-pend this fake request to the TLS bits already in the buffer
+        SBuf retStr;
+        retStr.append("CONNECT ").append(ip).append(" HTTP/1.1\r\nHost: ").append(ip).append("\r\n\r\n");
+        connState->in.buf = retStr.append(connState->in.buf);
+        bool ret = connState->handleReadData();
         if (ret)
             ret = connState->clientParseRequests();
 
@@ -3884,13 +3876,9 @@ httpsAccept(const CommAcceptCbParams &params)
     MasterXaction::Pointer xact = params.xaction;
     const AnyP::PortCfgPointer s = xact->squidPort;
 
-    if (!s.valid()) {
-        // it is possible the call or accept() was still queued when the port was reconfigured
-        debugs(33, 2, "HTTPS accept failure: port reconfigured.");
-        return;
-    }
+    // NP: it is possible the port was reconfigured when the call or accept() was queued.
 
-    if (params.flag != COMM_OK) {
+    if (params.flag != Comm::OK) {
         // Its possible the call was still queued when the client disconnected
         debugs(33, 2, "httpsAccept: " << s->listenConn << ": accept failure: " << xstrerr(params.xerrno));
         return;
@@ -3943,13 +3931,9 @@ ftpAccept(const CommAcceptCbParams &params)
     MasterXaction::Pointer xact = params.xaction;
     AnyP::PortCfgPointer s = xact->squidPort;
 
-    if (!s.valid()) {
-        // it is possible the call or accept() was still queued when the port was reconfigured
-        debugs(33, 2, "FTP accept failure: port reconfigured.");
-        return;
-	}
+    // NP: it is possible the port was reconfigured when the call or accept() was queued.
 
-    if (params.flag != COMM_OK) {
+    if (params.flag != Comm::OK) {
         // Its possible the call was still queued when the client disconnected
         debugs(33, 2, "ftpAccept: " << s->listenConn << ": accept failure: " << xstrerr(params.xerrno));
         return;
@@ -4203,7 +4187,13 @@ ConnStateData::getSslContextDone(SSL_CTX * sslContext, bool isNew)
     if (!httpsCreate(clientConnection, sslContext))
         return;
 
-    // commSetConnTimeout() was called for this request before we switched.
+    // bumped intercepted conns should already have Config.Timeout.request set
+    // but forwarded connections may only have Config.Timeout.lifetime. [Re]set
+    // to make sure the connection does not get stuck on non-SSL clients.
+    typedef CommCbMemFunT<ConnStateData, CommTimeoutCbParams> TimeoutDialer;
+    AsyncCall::Pointer timeoutCall = JobCallback(33, 5, TimeoutDialer,
+                                     this, ConnStateData::requestTimeout);
+    commSetConnTimeout(clientConnection, Config.Timeout.request, timeoutCall);
 
     // Disable the client read handler until CachePeer selection is complete
     Comm::SetSelect(clientConnection->fd, COMM_SELECT_READ, NULL, NULL, 0);
@@ -4312,9 +4302,7 @@ AddOpenedHttpSocket(const Comm::ConnectionPointer &conn)
 static void
 clientHttpConnectionsOpen(void)
 {
-    AnyP::PortCfg *s = NULL;
-
-    for (s = Config.Sockaddr.http; s; s = s->next) {
+    for (AnyP::PortCfgPointer s = HttpPortList; s != NULL; s = s->next) {
         if (MAXTCPLISTENPORTS == NHttpSockets) {
             debugs(1, DBG_IMPORTANT, "WARNING: You have too many 'http_port' lines.");
             debugs(1, DBG_IMPORTANT, "         The limit is " << MAXTCPLISTENPORTS << " HTTP ports.");
@@ -4347,7 +4335,7 @@ clientHttpConnectionsOpen(void)
 
         // setup the subscriptions such that new connections accepted by listenConn are handled by HTTP
         typedef CommCbFunPtrCallT<CommAcceptCbPtrFun> AcceptCall;
-        RefCount<AcceptCall> subCall = commCbCall(5, 5, "httpAccept", CommAcceptCbPtrFun(httpAccept, s));
+        RefCount<AcceptCall> subCall = commCbCall(5, 5, "httpAccept", CommAcceptCbPtrFun(httpAccept, CommAcceptCbParams(NULL)));
         Subscription::Pointer sub = new CallSubscription<AcceptCall>(subCall);
 
         AsyncCall::Pointer listenCall = asyncCall(33,2, "clientListenerConnectionOpened",
@@ -4363,9 +4351,7 @@ clientHttpConnectionsOpen(void)
 static void
 clientHttpsConnectionsOpen(void)
 {
-    AnyP::PortCfg *s;
-
-    for (s = Config.Sockaddr.https; s; s = s->next) {
+    for (AnyP::PortCfgPointer s = HttpsPortList; s != NULL; s = s->next) {
         if (MAXTCPLISTENPORTS == NHttpSockets) {
             debugs(1, DBG_IMPORTANT, "Ignoring 'https_port' lines exceeding the limit.");
             debugs(1, DBG_IMPORTANT, "The limit is " << MAXTCPLISTENPORTS << " HTTPS ports.");
@@ -4402,7 +4388,7 @@ clientHttpsConnectionsOpen(void)
 
         // setup the subscriptions such that new connections accepted by listenConn are handled by HTTPS
         typedef CommCbFunPtrCallT<CommAcceptCbPtrFun> AcceptCall;
-        RefCount<AcceptCall> subCall = commCbCall(5, 5, "httpsAccept", CommAcceptCbPtrFun(httpsAccept, s));
+        RefCount<AcceptCall> subCall = commCbCall(5, 5, "httpsAccept", CommAcceptCbPtrFun(httpsAccept, CommAcceptCbParams(NULL)));
         Subscription::Pointer sub = new CallSubscription<AcceptCall>(subCall);
 
         AsyncCall::Pointer listenCall = asyncCall(33, 2, "clientListenerConnectionOpened",
@@ -4418,9 +4404,7 @@ clientHttpsConnectionsOpen(void)
 static void
 clientFtpConnectionsOpen(void)
 {
-    AnyP::PortCfg *s;
-
-    for (s = Config.Sockaddr.ftp; s; s = s->next) {
+    for (AnyP::PortCfgPointer s = FtpPortList; s != NULL; s = s->next) {
         if (MAXTCPLISTENPORTS == NHttpSockets) {
             debugs(1, DBG_IMPORTANT, "Ignoring 'ftp_port' lines exceeding the limit.");
             debugs(1, DBG_IMPORTANT, "The limit is " << MAXTCPLISTENPORTS << " FTP ports.");
@@ -4435,7 +4419,7 @@ clientFtpConnectionsOpen(void)
 
         // setup the subscriptions such that new connections accepted by listenConn are handled by FTP
         typedef CommCbFunPtrCallT<CommAcceptCbPtrFun> AcceptCall;
-        RefCount<AcceptCall> subCall = commCbCall(5, 5, "ftpAccept", CommAcceptCbPtrFun(ftpAccept, s));
+        RefCount<AcceptCall> subCall = commCbCall(5, 5, "ftpAccept", CommAcceptCbPtrFun(ftpAccept, CommAcceptCbParams(NULL)));
         Subscription::Pointer sub = new CallSubscription<AcceptCall>(subCall);
 
         AsyncCall::Pointer listenCall = asyncCall(33, 2, "clientListenerConnectionOpened",
@@ -4449,16 +4433,17 @@ clientFtpConnectionsOpen(void)
 
 /// process clientHttpConnectionsOpen result
 static void
-clientListenerConnectionOpened(AnyP::PortCfg *s, const Ipc::FdNoteId portTypeNote, const Subscription::Pointer &sub)
+clientListenerConnectionOpened(AnyP::PortCfgPointer &s, const Ipc::FdNoteId portTypeNote, const Subscription::Pointer &sub)
 {
+    Must(s != NULL);
+
     if (!OpenedHttpSocket(s->listenConn, portTypeNote))
         return;
 
-    Must(s);
     Must(Comm::IsConnOpen(s->listenConn));
 
     // TCP: setup a job to handle accept() with subscribed handler
-    AsyncJob::Start(new Comm::TcpAcceptor(s->listenConn, FdNote(portTypeNote), sub));
+    AsyncJob::Start(new Comm::TcpAcceptor(s, FdNote(portTypeNote), sub));
 
     debugs(1, DBG_IMPORTANT, "Accepting " <<
            (s->flags.natIntercept ? "NAT intercepted " : "") <<
@@ -4487,7 +4472,7 @@ clientOpenListenSockets(void)
 void
 clientConnectionsClose(void)
 {
-    for (AnyP::PortCfg *s = Config.Sockaddr.http; s; s = s->next) {
+    for (AnyP::PortCfgPointer s = HttpPortList; s != NULL; s = s->next) {
         if (s->listenConn != NULL) {
             debugs(1, DBG_IMPORTANT, "Closing HTTP port " << s->listenConn->local);
             s->listenConn->close();
@@ -4496,7 +4481,7 @@ clientConnectionsClose(void)
     }
 
 #if USE_OPENSSL
-    for (AnyP::PortCfg *s = Config.Sockaddr.https; s; s = s->next) {
+    for (AnyP::PortCfgPointer s = HttpsPortList; s != NULL; s = s->next) {
         if (s->listenConn != NULL) {
             debugs(1, DBG_IMPORTANT, "Closing HTTPS port " << s->listenConn->local);
             s->listenConn->close();
@@ -4505,7 +4490,7 @@ clientConnectionsClose(void)
     }
 #endif
 
-    for (AnyP::PortCfg *s = Config.Sockaddr.ftp; s; s = s->next) {
+    for (AnyP::PortCfgPointer s = HttpPortList; s != NULL; s = s->next) {
         if (s->listenConn != NULL) {
             debugs(1, DBG_IMPORTANT, "Closing FTP port " << s->listenConn->local);
             s->listenConn->close();
@@ -4617,7 +4602,7 @@ void
 ConnStateData::stopReading()
 {
     if (reading()) {
-        comm_read_cancel(clientConnection->fd, reader);
+        Comm::ReadCancel(clientConnection->fd, reader);
         reader = NULL;
     }
 }
@@ -4833,15 +4818,14 @@ ConnStateData::startPinnedConnectionMonitoring()
     typedef CommCbMemFunT<ConnStateData, CommIoCbParams> Dialer;
     pinning.readHandler = JobCallback(33, 3,
                                       Dialer, this, ConnStateData::clientPinnedConnectionRead);
-    static char unusedBuf[8];
-    comm_read(pinning.serverConnection, unusedBuf, sizeof(unusedBuf), pinning.readHandler);
+    Comm::Read(pinning.serverConnection, pinning.readHandler);
 }
 
 void
 ConnStateData::stopPinnedConnectionMonitoring()
 {
     if (pinning.readHandler != NULL) {
-        comm_read_cancel(pinning.serverConnection->fd, pinning.readHandler);
+        Comm::ReadCancel(pinning.serverConnection->fd, pinning.readHandler);
         pinning.readHandler = NULL;
     }
 }
@@ -4853,7 +4837,7 @@ ConnStateData::clientPinnedConnectionRead(const CommIoCbParams &io)
 {
     pinning.readHandler = NULL; // Comm unregisters handlers before calling
 
-    if (io.flag == COMM_ERR_CLOSING)
+    if (io.flag == Comm::ERR_CLOSING)
         return; // close handler will clean up
 
     // We could use getConcurrentRequestCount(), but this may be faster.
@@ -4972,7 +4956,7 @@ FtpAcceptDataConnection(const CommAcceptCbParams &params)
 {
     ConnStateData *connState = static_cast<ConnStateData *>(params.data);
 
-    if (params.flag != COMM_OK) {
+    if (params.flag != Comm::OK) {
         // Its possible the call was still queued when the client disconnected
         debugs(33, 2, HERE << connState->ftp.dataListenConn << ": accept "
                "failure: " << xstrerr(params.xerrno));
@@ -5030,8 +5014,8 @@ FtpCloseDataConnection(ConnStateData *conn)
     conn->ftp.dataListenConn = NULL;
 
     if (conn->ftp.reader != NULL) {
-        // comm_read_cancel can deal with negative FDs
-        comm_read_cancel(conn->ftp.dataConn->fd, conn->ftp.reader);
+        // Comm::ReadCancel can deal with negative FDs
+        Comm::ReadCancel(conn->ftp.dataConn->fd, conn->ftp.reader);
         conn->ftp.reader = NULL;
     }
 
@@ -5475,7 +5459,7 @@ FtpHandleDataReply(ClientSocketContext *context, const HttpReply *reply, StoreIO
     debugs(33, 7, HERE << data.length);
 
     if (data.length <= 0) {
-        FtpWroteReplyData(conn->clientConnection, NULL, 0, COMM_OK, 0, context);
+        FtpWroteReplyData(conn->clientConnection, NULL, 0, Comm::OK, 0, context);
         return;
     }
 
@@ -5491,15 +5475,15 @@ FtpHandleDataReply(ClientSocketContext *context, const HttpReply *reply, StoreIO
 }
 
 static void
-FtpWroteReplyData(const Comm::ConnectionPointer &conn, char *bufnotused, size_t size, comm_err_t errflag, int xerrno, void *data)
+FtpWroteReplyData(const Comm::ConnectionPointer &conn, char *bufnotused, size_t size, Comm::Flag errflag, int xerrno, void *data)
 {
-    if (errflag == COMM_ERR_CLOSING)
+    if (errflag == Comm::ERR_CLOSING)
         return;
 
     ClientSocketContext *const context = static_cast<ClientSocketContext*>(data);
     ConnStateData *const connState = context->getConn();
 
-    if (errflag != COMM_OK) {
+    if (errflag != Comm::OK) {
         debugs(33, 3, HERE << "FTP reply data writing failed: " <<
                xstrerr(xerrno));
         FtpCloseDataConnection(connState);
@@ -5746,12 +5730,12 @@ FtpPrintReply(MemBuf &mb, const HttpReply *reply, const char *const prefix)
 }
 
 static void
-FtpWroteEarlyReply(const Comm::ConnectionPointer &conn, char *bufnotused, size_t size, comm_err_t errflag, int xerrno, void *data)
+FtpWroteEarlyReply(const Comm::ConnectionPointer &conn, char *bufnotused, size_t size, Comm::Flag errflag, int xerrno, void *data)
 {
-    if (errflag == COMM_ERR_CLOSING)
+    if (errflag == Comm::ERR_CLOSING)
         return;
 
-    if (errflag != COMM_OK) {
+    if (errflag != Comm::OK) {
         debugs(33, 3, HERE << "FTP reply writing failed: " << xstrerr(xerrno));
         conn->close();
         return;
@@ -5769,12 +5753,12 @@ FtpWroteEarlyReply(const Comm::ConnectionPointer &conn, char *bufnotused, size_t
 }
 
 static void
-FtpWroteReply(const Comm::ConnectionPointer &conn, char *bufnotused, size_t size, comm_err_t errflag, int xerrno, void *data)
+FtpWroteReply(const Comm::ConnectionPointer &conn, char *bufnotused, size_t size, Comm::Flag errflag, int xerrno, void *data)
 {
-    if (errflag == COMM_ERR_CLOSING)
+    if (errflag == Comm::ERR_CLOSING)
         return;
 
-    if (errflag != COMM_OK) {
+    if (errflag != Comm::OK) {
         debugs(33, 3, HERE << "FTP reply writing failed: " <<
                xstrerr(xerrno));
         conn->close();
@@ -6179,12 +6163,12 @@ FtpCheckDataConnPost(ClientSocketContext *context)
 }
 
 void
-FtpHandleConnectDone(const Comm::ConnectionPointer &conn, comm_err_t status, int xerrno, void *data)
+FtpHandleConnectDone(const Comm::ConnectionPointer &conn, Comm::Flag status, int xerrno, void *data)
 {
     ClientSocketContext *context = static_cast<ClientSocketContext*>(data);
     context->getConn()->ftp.connector = NULL;
 
-    if (status != COMM_OK) {
+    if (status != Comm::OK) {
         conn->close();
         FtpSetReply(context, 425, "Cannot open data connection.");
         assert(context->http && context->http->storeEntry() != NULL);
@@ -78,6 +78,12 @@ class PortCfg;
  *
  * The individual processing actions are done by other Jobs which we
  * kick off as needed.
+ *
+ * XXX: If an async call ends the ClientHttpRequest job, ClientSocketContext
+ * (and ConnStateData) may not know about it, leading to segfaults and
+ * assertions like areAllContextsForThisConnection(). This is difficult to fix
+ * because ClientHttpRequest lacks a good way to communicate its ongoing
+ * destruction back to the ClientSocketContext which pretends to "own" *http.
  */
 class ClientSocketContext : public RefCountable
 {
@@ -87,11 +93,11 @@ class ClientSocketContext : public RefCountable
     ClientSocketContext(const Comm::ConnectionPointer &aConn, ClientHttpRequest *aReq);
     ~ClientSocketContext();
     bool startOfOutput() const;
-    void writeComplete(const Comm::ConnectionPointer &conn, char *bufnotused, size_t size, comm_err_t errflag);
+    void writeComplete(const Comm::ConnectionPointer &conn, char *bufnotused, size_t size, Comm::Flag errflag);
     void keepaliveNextRequest();
 
     Comm::ConnectionPointer clientConnection; /// details about the client connection socket.
-    ClientHttpRequest *http;	/* we own this */
+    ClientHttpRequest *http;	/* we pretend to own that job */
     HttpReply *reply;
     char reqbuf[HTTP_REQBUF_SZ];
     Pointer next;
@@ -144,7 +150,7 @@ class ClientSocketContext : public RefCountable
 
 protected:
     static IOCB WroteControlMsg;
-    void wroteControlMsg(const Comm::ConnectionPointer &conn, char *bufnotused, size_t size, comm_err_t errflag, int xerrno);
+    void wroteControlMsg(const Comm::ConnectionPointer &conn, char *bufnotused, size_t size, Comm::Flag errflag, int xerrno);
 
 private:
     void prepareReply(HttpReply * rep);
@@ -272,7 +278,7 @@ class ConnStateData : public BodyProducer, public HttpControlMsgSink
     } pinning;
 
     /// Squid listening port details where this connection arrived.
-    AnyP::PortCfg *port;
+    AnyP::PortCfgPointer port;
 
     bool transparent() const;
     bool reading() const;
@@ -293,7 +299,7 @@ class ConnStateData : public BodyProducer, public HttpControlMsgSink
     virtual void noteMoreBodySpaceAvailable(BodyPipe::Pointer);
     virtual void noteBodyConsumerAborted(BodyPipe::Pointer);
 
-    bool handleReadData(SBuf *buf);
+    bool handleReadData();
     bool handleRequestBodyData();
 
     /// forward future client requests using the given server connection
@@ -418,6 +424,10 @@ class ConnStateData : public BodyProducer, public HttpControlMsgSink
 
     void resumeFtpRequest(ClientSocketContext *const context);
 
+    /* clt_conn_tag=tag annotation access */
+    const SBuf &connectionTag() const { return connectionTag_; }
+    void connectionTag(const char *aTag) { connectionTag_ = aTag; }
+
 protected:
     void startDechunkingRequest();
     void abortChunkedRequestBody(const err_type error);
@@ -427,7 +437,6 @@ class ConnStateData : public BodyProducer, public HttpControlMsgSink
     void clientPinnedConnectionRead(const CommIoCbParams &io);
 
 private:
-    int connReadWasError(comm_err_t flag, int size, int xerrno);
     int connFinishedWithConn(int size);
     void clientAfterReadingRequests();
     void processFtpRequest(ClientSocketContext *const context);
@@ -466,6 +475,8 @@ class ConnStateData : public BodyProducer, public HttpControlMsgSink
     AsyncCall::Pointer reader; ///< set when we are reading
     BodyPipe::Pointer bodyPipe; // set when we are reading request body
 
+    SBuf connectionTag_; ///< clt_conn_tag=Tag annotation for client connection
+
     CBDATA_CLASS2(ConnStateData);
 };
 
@@ -1347,7 +1347,7 @@ clientReplyContext::buildReplyHeader()
             if (http->storeEntry()->timestamp <= squid_curtime) {
                 // put X-Cache-Age: instead of Age:
                 char age[64];
-                snprintf(age, sizeof(age), "%ld", (long int) squid_curtime - http->storeEntry()->timestamp);
+                snprintf(age, sizeof(age), "%" PRId64, static_cast<int64_t>(squid_curtime - http->storeEntry()->timestamp));
                 hdr->putExt("X-Cache-Age", age);
             }
         } else if (http->storeEntry()->timestamp <= squid_curtime) {
@@ -164,7 +164,7 @@ ClientHttpRequest::ClientHttpRequest(ConnStateData * aConn) :
     al = new AccessLogEntry;
     al->cache.start_time = current_time;
     al->tcpClient = clientConnection = aConn->clientConnection;
-    al->cache.port =  cbdataReference(aConn->port);
+    al->cache.port = aConn->port;
     al->cache.caddr = aConn->log_addr;
 
 #if USE_OPENSSL
@@ -1239,10 +1239,10 @@ ClientRequestContext::clientRedirectDone(const HelperReply &reply)
 
     // Put helper response Notes into the transaction state record (ALE) eventually
     // do it early to ensure that no matter what the outcome the notes are present.
-    if (http->al != NULL) {
-        NotePairs &notes = SyncNotes(*http->al, *old_request);
-        notes.append(&reply.notes);
-    }
+    if (http->al != NULL)
+        (void)SyncNotes(*http->al, *old_request);
+
+    UpdateRequestNotes(http->getConn(), *old_request, reply.notes);
 
     switch (reply.result) {
     case HelperReply::Unknown:
@@ -1360,10 +1360,10 @@ ClientRequestContext::clientStoreIdDone(const HelperReply &reply)
 
     // Put helper response Notes into the transaction state record (ALE) eventually
     // do it early to ensure that no matter what the outcome the notes are present.
-    if (http->al != NULL) {
-        NotePairs &notes = SyncNotes(*http->al, *old_request);
-        notes.append(&reply.notes);
-    }
+    if (http->al != NULL)
+        (void)SyncNotes(*http->al, *old_request);
+
+    UpdateRequestNotes(http->getConn(), *old_request, reply.notes);
 
     switch (reply.result) {
     case HelperReply::Unknown:
@@ -1524,7 +1524,6 @@ ClientHttpRequest::processRequest()
             return;
         }
 #endif
-        logType = LOG_TCP_MISS;
         getConn()->stopReading(); // tunnels read for themselves
         tunnelStart(this, &out.size, &al->http.code, al);
         return;
@@ -1559,7 +1558,7 @@ ClientHttpRequest::sslBumpNeed(Ssl::BumpMode mode)
 
 // called when comm_write has completed
 static void
-SslBumpEstablish(const Comm::ConnectionPointer &, char *, size_t, comm_err_t errflag, int, void *data)
+SslBumpEstablish(const Comm::ConnectionPointer &, char *, size_t, Comm::Flag errflag, int, void *data)
 {
     ClientHttpRequest *r = static_cast<ClientHttpRequest*>(data);
     debugs(85, 5, HERE << "responded to CONNECT: " << r << " ? " << errflag);
@@ -1569,10 +1568,10 @@ SslBumpEstablish(const Comm::ConnectionPointer &, char *, size_t, comm_err_t err
 }
 
 void
-ClientHttpRequest::sslBumpEstablish(comm_err_t errflag)
+ClientHttpRequest::sslBumpEstablish(Comm::Flag errflag)
 {
-    // Bail out quickly on COMM_ERR_CLOSING - close handlers will tidy up
-    if (errflag == COMM_ERR_CLOSING)
+    // Bail out quickly on Comm::ERR_CLOSING - close handlers will tidy up
+    if (errflag == Comm::ERR_CLOSING)
         return;
 
     if (errflag) {
@@ -1688,6 +1687,13 @@ ClientHttpRequest::doCallouts()
     if (!calloutContext->http->al->request) {
         calloutContext->http->al->request = request;
         HTTPMSGLOCK(calloutContext->http->al->request);
+
+        NotePairs &notes = SyncNotes(*calloutContext->http->al, *calloutContext->http->request);
+        // Make the previously set client connection ID available as annotation.
+        if (ConnStateData *csd = calloutContext->http->getConn()) {
+            if (!csd->connectionTag().isEmpty())
+                notes.add("clt_conn_tag", SBuf(csd->connectionTag()).c_str());
+        }
     }
 
     if (!calloutContext->error) {
@@ -154,7 +154,7 @@ class ClientHttpRequest
     /// set the sslBumpNeeded state
     void sslBumpNeed(Ssl::BumpMode mode);
     void sslBumpStart();
-    void sslBumpEstablish(comm_err_t errflag);
+    void sslBumpEstablish(Comm::Flag errflag);
 #endif
 
 #if USE_ADAPTATION
@@ -39,6 +39,7 @@
 #include "comm/Connection.h"
 #include "comm/IoCallback.h"
 #include "comm/Loops.h"
+#include "comm/Read.h"
 #include "comm/TcpAcceptor.h"
 #include "comm/Write.h"
 #include "CommRead.h"
@@ -80,9 +81,8 @@
  * New C-like simple comm code. This stuff is a mess and doesn't really buy us anything.
  */
 
-static void commStopHalfClosedMonitor(int fd);
 static IOCB commHalfClosedReader;
-static void comm_init_opened(const Comm::ConnectionPointer &conn, tos_t tos, nfmark_t nfmark, const char *note, struct addrinfo *AI);
+static void comm_init_opened(const Comm::ConnectionPointer &conn, const char *note, struct addrinfo *AI);
 static int comm_apply_flags(int new_socket, Ip::Address &addr, int flags, struct addrinfo *AI);
 
 #if USE_DELAY_POOLS
@@ -98,7 +98,7 @@ static bool WillCheckHalfClosed = false; /// true if check is scheduled
 static EVH commHalfClosedCheck;
 static void commPlanHalfClosedCheck();
 
-static comm_err_t commBind(int s, struct addrinfo &);
+static Comm::Flag commBind(int s, struct addrinfo &);
 static void commSetReuseAddr(int);
 static void commSetNoLinger(int);
 #ifdef TCP_NODELAY
@@ -114,116 +114,6 @@ isOpen(const int fd)
     return fd >= 0 && fd_table && fd_table[fd].flags.open != 0;
 }
 
-/**
- * Attempt a read
- *
- * If the read attempt succeeds or fails, call the callback.
- * Else, wait for another IO notification.
- */
-void
-commHandleRead(int fd, void *data)
-{
-    Comm::IoCallback *ccb = (Comm::IoCallback *) data;
-
-    assert(data == COMMIO_FD_READCB(fd));
-    assert(ccb->active());
-    /* Attempt a read */
-    ++ statCounter.syscalls.sock.reads;
-    errno = 0;
-    int retval;
-    if (ccb->buf) {
-        retval = FD_READ_METHOD(fd, ccb->buf, ccb->size);
-        debugs(5, 3, "char FD " << fd << ", size " << ccb->size << ", retval " << retval << ", errno " << errno);
-    } else {
-        assert(ccb->buf2 != NULL);
-        SBuf::size_type sz = ccb->buf2->spaceSize();
-        char *buf = ccb->buf2->rawSpace(sz);
-        retval = FD_READ_METHOD(fd, buf, sz-1); // blocking synchronous read(2)
-        if (retval > 0) {
-            ccb->buf2->append(buf, retval);
-        }
-        debugs(5, 3, "SBuf FD " << fd << ", size " << sz << ", retval " << retval << ", errno " << errno);
-    }
-
-    if (retval < 0 && !ignoreErrno(errno)) {
-        debugs(5, 3, "comm_read_try: scheduling COMM_ERROR");
-        ccb->offset = 0;
-        ccb->finish(COMM_ERROR, errno);
-        return;
-    };
-
-    /* See if we read anything */
-    /* Note - read 0 == socket EOF, which is a valid read */
-    if (retval >= 0) {
-        fd_bytes(fd, retval, FD_READ);
-        ccb->offset = retval;
-        ccb->finish(COMM_OK, errno);
-        return;
-    }
-
-    /* Nope, register for some more IO */
-    Comm::SetSelect(fd, COMM_SELECT_READ, commHandleRead, data, 0);
-}
-
-/**
- * Queue a read. handler/handler_data are called when the read
- * completes, on error, or on file descriptor close.
- */
-void
-comm_read(const Comm::ConnectionPointer &conn, char *buf, int size, AsyncCall::Pointer &callback)
-{
-    debugs(5, 5, "comm_read, queueing read for " << conn << "; asynCall " << callback);
-
-    /* Make sure we are open and not closing */
-    assert(Comm::IsConnOpen(conn));
-    assert(!fd_table[conn->fd].closing());
-    Comm::IoCallback *ccb = COMMIO_FD_READCB(conn->fd);
-
-    // Make sure we are either not reading or just passively monitoring.
-    // Active/passive conflicts are OK and simply cancel passive monitoring.
-    if (ccb->active()) {
-        // if the assertion below fails, we have an active comm_read conflict
-        assert(fd_table[conn->fd].halfClosedReader != NULL);
-        commStopHalfClosedMonitor(conn->fd);
-        assert(!ccb->active());
-    }
-    ccb->conn = conn;
-
-    /* Queue the read */
-    ccb->setCallback(Comm::IOCB_READ, callback, (char *)buf, NULL, size);
-    Comm::SetSelect(conn->fd, COMM_SELECT_READ, commHandleRead, ccb, 0);
-}
-
-/**
- * Queue a read. handler/handler_data are called when the read
- * completes, on error, or on file descriptor close.
- */
-void
-comm_read(const Comm::ConnectionPointer &conn, SBuf &buf, AsyncCall::Pointer &callback)
-{
-    debugs(5, 5, "comm_read, queueing read for " << conn << "; asynCall " << callback);
-
-    /* Make sure we are open and not closing */
-    assert(Comm::IsConnOpen(conn));
-    assert(!fd_table[conn->fd].closing());
-    Comm::IoCallback *ccb = COMMIO_FD_READCB(conn->fd);
-
-    // Make sure we are either not reading or just passively monitoring.
-    // Active/passive conflicts are OK and simply cancel passive monitoring.
-    if (ccb->active()) {
-        // if the assertion below fails, we have an active comm_read conflict
-        assert(fd_table[conn->fd].halfClosedReader != NULL);
-        commStopHalfClosedMonitor(conn->fd);
-        assert(!ccb->active());
-    }
-    ccb->conn = conn;
-    ccb->buf2 = &buf;
-
-    /* Queue the read */
-    ccb->setCallback(Comm::IOCB_READ, callback, NULL, NULL, buf.spaceSize());
-    Comm::SetSelect(conn->fd, COMM_SELECT_READ, commHandleRead, ccb, 0);
-}
-
 /**
  * Empty the read buffers
  *
@@ -245,115 +135,6 @@ comm_empty_os_read_buffers(int fd)
 #endif
 }
 
-/**
- * Return whether the FD has a pending completed callback.
- * NP: does not work.
- */
-int
-comm_has_pending_read_callback(int fd)
-{
-    assert(isOpen(fd));
-    // XXX: We do not know whether there is a read callback scheduled.
-    // This is used for pconn management that should probably be more
-    // tightly integrated into comm to minimize the chance that a
-    // closing pconn socket will be used for a new transaction.
-    return false;
-}
-
-// Does comm check this fd for read readiness?
-// Note that when comm is not monitoring, there can be a pending callback
-// call, which may resume comm monitoring once fired.
-bool
-comm_monitors_read(int fd)
-{
-    assert(isOpen(fd) && COMMIO_FD_READCB(fd));
-    // Being active is usually the same as monitoring because we always
-    // start monitoring the FD when we configure Comm::IoCallback for I/O
-    // and we usually configure Comm::IoCallback for I/O when we starting
-    // monitoring a FD for reading.
-    return COMMIO_FD_READCB(fd)->active();
-}
-
-/**
- * Cancel a pending read. Assert that we have the right parameters,
- * and that there are no pending read events!
- *
- * XXX: We do not assert that there are no pending read events and
- * with async calls it becomes even more difficult.
- * The whole interface should be reworked to do callback->cancel()
- * instead of searching for places where the callback may be stored and
- * updating the state of those places.
- *
- * AHC Don't call the comm handlers?
- */
-void
-comm_read_cancel(int fd, IOCB *callback, void *data)
-{
-    if (!isOpen(fd)) {
-        debugs(5, 4, "comm_read_cancel fails: FD " << fd << " closed");
-        return;
-    }
-
-    Comm::IoCallback *cb = COMMIO_FD_READCB(fd);
-    // TODO: is "active" == "monitors FD"?
-    if (!cb->active()) {
-        debugs(5, 4, "comm_read_cancel fails: FD " << fd << " inactive");
-        return;
-    }
-
-    typedef CommCbFunPtrCallT<CommIoCbPtrFun> Call;
-    Call *call = dynamic_cast<Call*>(cb->callback.getRaw());
-    if (!call) {
-        debugs(5, 4, "comm_read_cancel fails: FD " << fd << " lacks callback");
-        return;
-    }
-
-    call->cancel("old comm_read_cancel");
-
-    typedef CommIoCbParams Params;
-    const Params &params = GetCommParams<Params>(cb->callback);
-
-    /* Ok, we can be reasonably sure we won't lose any data here! */
-    assert(call->dialer.handler == callback);
-    assert(params.data == data);
-
-    /* Delete the callback */
-    cb->cancel("old comm_read_cancel");
-
-    /* And the IO event */
-    Comm::SetSelect(fd, COMM_SELECT_READ, NULL, NULL, 0);
-}
-
-void
-comm_read_cancel(int fd, AsyncCall::Pointer &callback)
-{
-    callback->cancel("comm_read_cancel");
-
-    if (!isOpen(fd)) {
-        debugs(5, 4, "comm_read_cancel fails: FD " << fd << " closed");
-        return;
-    }
-
-    Comm::IoCallback *cb = COMMIO_FD_READCB(fd);
-
-    if (!cb->active()) {
-        debugs(5, 4, "comm_read_cancel fails: FD " << fd << " inactive");
-        return;
-    }
-
-    AsyncCall::Pointer call = cb->callback;
-    assert(call != NULL); // XXX: should never fail (active() checks for callback==NULL)
-
-    /* Ok, we can be reasonably sure we won't lose any data here! */
-    assert(call == callback);
-
-    /* Delete the callback */
-    cb->cancel("comm_read_cancel");
-
-    /* And the IO event */
-    Comm::SetSelect(fd, COMM_SELECT_READ, NULL, NULL, 0);
-}
-
 /**
  * synchronous wrapper around udp socket functions
  */
@@ -438,19 +219,19 @@ comm_local_port(int fd)
     return F->local_addr.port();
 }
 
-static comm_err_t
+static Comm::Flag
 commBind(int s, struct addrinfo &inaddr)
 {
     ++ statCounter.syscalls.sock.binds;
 
     if (bind(s, inaddr.ai_addr, inaddr.ai_addrlen) == 0) {
         debugs(50, 6, "commBind: bind socket FD " << s << " to " << fd_table[s].local_addr);
-        return COMM_OK;
+        return Comm::OK;
     }
 
     debugs(50, 0, "commBind: Cannot bind socket FD " << s << " to " << fd_table[s].local_addr << ": " << xstrerror());
 
-    return COMM_ERROR;
+    return Comm::COMM_ERROR;
 }
 
 /**
@@ -464,7 +245,7 @@ comm_open(int sock_type,
           int flags,
           const char *note)
 {
-    return comm_openex(sock_type, proto, addr, flags, 0, 0, note);
+    return comm_openex(sock_type, proto, addr, flags, note);
 }
 
 void
@@ -477,7 +258,7 @@ comm_open_listener(int sock_type,
     conn->flags |= COMM_DOBIND;
 
     /* attempt native enabled port. */
-    conn->fd = comm_openex(sock_type, proto, conn->local, conn->flags, 0, 0, note);
+    conn->fd = comm_openex(sock_type, proto, conn->local, conn->flags, note);
 }
 
 int
@@ -493,7 +274,7 @@ comm_open_listener(int sock_type,
     flags |= COMM_DOBIND;
 
     /* attempt native enabled port. */
-    sock = comm_openex(sock_type, proto, addr, flags, 0, 0, note);
+    sock = comm_openex(sock_type, proto, addr, flags, note);
 
     return sock;
 }
@@ -568,8 +349,6 @@ comm_openex(int sock_type,
             int proto,
             Ip::Address &addr,
             int flags,
-            tos_t tos,
-            nfmark_t nfmark,
             const char *note)
 {
     int new_socket;
@@ -627,14 +406,6 @@ comm_openex(int sock_type,
 
     debugs(50, 3, "comm_openex: Opened socket " << conn << " : family=" << AI->ai_family << ", type=" << AI->ai_socktype << ", protocol=" << AI->ai_protocol );
 
-    /* set TOS if needed */
-    if (tos)
-        Ip::Qos::setSockTos(conn, tos);
-
-    /* set netfilter mark if needed */
-    if (nfmark)
-        Ip::Qos::setSockNfmark(conn, nfmark);
-
     if ( Ip::EnableIpv6&IPV6_SPECIAL_SPLITSTACK && addr.isIPv6() )
         comm_set_v6only(conn->fd, 1);
 
@@ -643,7 +414,7 @@ comm_openex(int sock_type,
     if ( Ip::EnableIpv6&IPV6_SPECIAL_V4MAPPING && addr.isIPv6() )
         comm_set_v6only(conn->fd, 0);
 
-    comm_init_opened(conn, tos, nfmark, note, AI);
+    comm_init_opened(conn, note, AI);
     new_socket = comm_apply_flags(conn->fd, addr, flags, AI);
 
     Ip::Address::FreeAddrInfo(AI);
@@ -658,8 +429,6 @@ comm_openex(int sock_type,
 /// update FD tables after a local or remote (IPC) comm_openex();
 void
 comm_init_opened(const Comm::ConnectionPointer &conn,
-                 tos_t tos,
-                 nfmark_t nfmark,
                  const char *note,
                  struct addrinfo *AI)
 {
@@ -677,9 +446,6 @@ comm_init_opened(const Comm::ConnectionPointer &conn,
 
     fde *F = &fd_table[conn->fd];
     F->local_addr = conn->local;
-    F->tosToServer = tos;
-
-    F->nfmarkToServer = nfmark;
 
     F->sock_family = AI->ai_family;
 }
@@ -723,14 +489,14 @@ comm_apply_flags(int new_socket,
         if ( addr.isNoAddr() )
             debugs(5,0,"CRITICAL: Squid is attempting to bind() port " << addr << "!!");
 
-        if (commBind(new_socket, *AI) != COMM_OK) {
+        if (commBind(new_socket, *AI) != Comm::OK) {
             comm_close(new_socket);
             return -1;
         }
     }
 
     if (flags & COMM_NONBLOCKING)
-        if (commSetNonBlocking(new_socket) == COMM_ERROR) {
+        if (commSetNonBlocking(new_socket) == Comm::COMM_ERROR) {
             comm_close(new_socket);
             return -1;
         }
@@ -756,7 +522,7 @@ comm_import_opened(const Comm::ConnectionPointer &conn,
     assert(Comm::IsConnOpen(conn));
     assert(AI);
 
-    comm_init_opened(conn, 0, 0, note, AI);
+    comm_init_opened(conn, note, AI);
 
     if (!(conn->flags & COMM_NOCLOEXEC))
         fd_table[conn->fd].flags.close_on_exec = true;
@@ -837,7 +603,7 @@ commUnsetConnTimeout(const Comm::ConnectionPointer &conn)
 int
 comm_connect_addr(int sock, const Ip::Address &address)
 {
-    comm_err_t status = COMM_OK;
+    Comm::Flag status = Comm::OK;
     fde *F = &fd_table[sock];
     int x = 0;
     int err = 0;
@@ -856,7 +622,7 @@ comm_connect_addr(int sock, const Ip::Address &address)
      */
     if (F->sock_family == AF_INET && !address.isIPv4()) {
         errno = ENETUNREACH;
-        return COMM_ERR_PROTOCOL;
+        return Comm::ERR_PROTOCOL;
     }
 
     /* Handle IPv4 over IPv6-only socket case.
@@ -868,7 +634,7 @@ comm_connect_addr(int sock, const Ip::Address &address)
      */
     if (!F->local_addr.isIPv4() && address.isIPv4()) {
         errno = ENETUNREACH;
-        return COMM_ERR_PROTOCOL;
+        return Comm::ERR_PROTOCOL;
     }
 
     address.getAddrInfo(AI, F->sock_family);
@@ -943,21 +709,21 @@ comm_connect_addr(int sock, const Ip::Address &address)
     PROF_stop(comm_connect_addr);
 
     if (errno == 0 || errno == EISCONN)
-        status = COMM_OK;
+        status = Comm::OK;
     else if (ignoreErrno(errno))
-        status = COMM_INPROGRESS;
+        status = Comm::INPROGRESS;
     else if (errno == EAFNOSUPPORT || errno == EINVAL)
-        return COMM_ERR_PROTOCOL;
+        return Comm::ERR_PROTOCOL;
     else
-        return COMM_ERROR;
+        return Comm::COMM_ERROR;
 
     address.toStr(F->ipaddr, MAX_IPSTRLEN);
 
     F->remote_port = address.port(); /* remote_port is HS */
 
-    if (status == COMM_OK) {
+    if (status == Comm::OK) {
         debugs(5, DBG_DATA, "comm_connect_addr: FD " << sock << " connected to " << address);
-    } else if (status == COMM_INPROGRESS) {
+    } else if (status == Comm::INPROGRESS) {
         debugs(5, DBG_DATA, "comm_connect_addr: FD " << sock << " connection pending");
     }
 
@@ -1109,7 +875,7 @@ comm_close_complete(const FdeCbParams &params)
  * + call read handlers with ERR_CLOSING
  * + call closing handlers
  *
- * NOTE: COMM_ERR_CLOSING will NOT be called for CommReads' sitting in a
+ * NOTE: Comm::ERR_CLOSING will NOT be called for CommReads' sitting in a
  * DeferredReadManager.
  */
 void
@@ -1161,11 +927,11 @@ _comm_close(int fd, char const *file, int line)
     // notify read/write handlers after canceling select reservations, if any
     if (COMMIO_FD_WRITECB(fd)->active()) {
         Comm::SetSelect(fd, COMM_SELECT_WRITE, NULL, NULL, 0);
-        COMMIO_FD_WRITECB(fd)->finish(COMM_ERR_CLOSING, errno);
+        COMMIO_FD_WRITECB(fd)->finish(Comm::ERR_CLOSING, errno);
     }
     if (COMMIO_FD_READCB(fd)->active()) {
         Comm::SetSelect(fd, COMM_SELECT_READ, NULL, NULL, 0);
-        COMMIO_FD_READCB(fd)->finish(COMM_ERR_CLOSING, errno);
+        COMMIO_FD_READCB(fd)->finish(Comm::ERR_CLOSING, errno);
     }
 
 #if USE_DELAY_POOLS
@@ -1223,7 +989,7 @@ comm_udp_sendto(int fd,
 
         debugs(50, DBG_IMPORTANT, "comm_udp_sendto: FD " << fd << ", (family=" << fd_table[fd].sock_family << ") " << to_addr << ": " << xstrerror());
 
-    return COMM_ERROR;
+    return Comm::COMM_ERROR;
 }
 
 void
@@ -1348,7 +1114,7 @@ commSetNonBlocking(int fd)
 
         if (ioctl(fd, FIONBIO, &nonblocking) < 0) {
             debugs(50, 0, "commSetNonBlocking: FD " << fd << ": " << xstrerror() << " " << fd_table[fd].type);
-            return COMM_ERROR;
+            return Comm::COMM_ERROR;
         }
 
 #if _SQUID_CYGWIN_
@@ -1359,12 +1125,12 @@ commSetNonBlocking(int fd)
 
         if ((flags = fcntl(fd, F_GETFL, dummy)) < 0) {
             debugs(50, 0, "FD " << fd << ": fcntl F_GETFL: " << xstrerror());
-            return COMM_ERROR;
+            return Comm::COMM_ERROR;
         }
 
         if (fcntl(fd, F_SETFL, flags | SQUID_NONBLOCK) < 0) {
             debugs(50, 0, "commSetNonBlocking: FD " << fd << ": " << xstrerror());
-            return COMM_ERROR;
+            return Comm::COMM_ERROR;
         }
 
 #endif
@@ -1389,13 +1155,13 @@ commUnsetNonBlocking(int fd)
 
     if ((flags = fcntl(fd, F_GETFL, dummy)) < 0) {
         debugs(50, 0, "FD " << fd << ": fcntl F_GETFL: " << xstrerror());
-        return COMM_ERROR;
+        return Comm::COMM_ERROR;
     }
 
     if (fcntl(fd, F_SETFL, flags & (~SQUID_NONBLOCK)) < 0) {
 #endif
         debugs(50, 0, "commUnsetNonBlocking: FD " << fd << ": " << xstrerror());
-        return COMM_ERROR;
+        return Comm::COMM_ERROR;
     }
 
     fd_table[fd].flags.nonblocking = false;
@@ -1830,7 +1596,7 @@ checkTimeouts(void)
             // We have an active write callback and we are timed out
             debugs(5, 5, "checkTimeouts: FD " << fd << " auto write timeout");
             Comm::SetSelect(fd, COMM_SELECT_WRITE, NULL, NULL, 0);
-            COMMIO_FD_WRITECB(fd)->finish(COMM_ERROR, ETIMEDOUT);
+            COMMIO_FD_WRITECB(fd)->finish(Comm::COMM_ERROR, ETIMEDOUT);
         } else if (AlreadyTimedOut(F))
             continue;
 
@@ -1886,7 +1652,7 @@ commHalfClosedCheck(void *)
         if (!fd_table[c->fd].halfClosedReader) { // not reading already
             AsyncCall::Pointer call = commCbCall(5,4, "commHalfClosedReader",
                                                  CommIoCbPtrFun(&commHalfClosedReader, NULL));
-            comm_read(c, NULL, 0, call);
+            Comm::Read(c, call);
             fd_table[c->fd].halfClosedReader = call;
         } else
             c->fd = -1; // XXX: temporary. prevent c replacement erase closing listed FD
@@ -1905,23 +1671,23 @@ commHasHalfClosedMonitor(int fd)
 }
 
 /// stop waiting for possibly half-closed connection to close
-static void
+void
 commStopHalfClosedMonitor(int const fd)
 {
     debugs(5, 5, HERE << "removing FD " << fd << " from " << *TheHalfClosed);
 
     // cancel the read if one was scheduled
     AsyncCall::Pointer reader = fd_table[fd].halfClosedReader;
     if (reader != NULL)
-        comm_read_cancel(fd, reader);
+        Comm::ReadCancel(fd, reader);
     fd_table[fd].halfClosedReader = NULL;
 
     TheHalfClosed->del(fd);
 }
 
 /// I/O handler for the possibly half-closed connection monitoring code
 static void
-commHalfClosedReader(const Comm::ConnectionPointer &conn, char *, size_t size, comm_err_t flag, int, void *)
+commHalfClosedReader(const Comm::ConnectionPointer &conn, char *, size_t size, Comm::Flag flag, int, void *)
 {
     // there cannot be more data coming in on half-closed connections
     assert(size == 0);
@@ -1931,11 +1697,11 @@ commHalfClosedReader(const Comm::ConnectionPointer &conn, char *, size_t size, c
     fd_table[conn->fd].halfClosedReader = NULL; // done reading, for now
 
     // nothing to do if fd is being closed
-    if (flag == COMM_ERR_CLOSING)
+    if (flag == Comm::ERR_CLOSING)
         return;
 
     // if read failed, close the connection
-    if (flag != COMM_OK) {
+    if (flag != Comm::OK) {
         debugs(5, 3, HERE << "closing " << conn);
         conn->close();
         return;
@@ -2092,17 +1858,17 @@ CommSelectEngine::checkEvents(int timeout)
 
     switch (Comm::DoSelect(timeout)) {
 
-    case COMM_OK:
+    case Comm::OK:
 
-    case COMM_TIMEOUT:
+    case Comm::TIMEOUT:
         return 0;
 
-    case COMM_IDLE:
+    case Comm::IDLE:
 
-    case COMM_SHUTDOWN:
+    case Comm::SHUTDOWN:
         return EVENT_IDLE;
 
-    case COMM_ERROR:
+    case Comm::COMM_ERROR:
         return EVENT_ERROR;
 
     default:
@@ -2176,15 +1942,15 @@ comm_open_uds(int sock_type,
         commSetReuseAddr(new_socket);
 
     if (flags & COMM_NONBLOCKING) {
-        if (commSetNonBlocking(new_socket) != COMM_OK) {
+        if (commSetNonBlocking(new_socket) != Comm::OK) {
             comm_close(new_socket);
             PROF_stop(comm_open);
             return -1;
         }
     }
 
     if (flags & COMM_DOBIND) {
-        if (commBind(new_socket, AI) != COMM_OK) {
+        if (commBind(new_socket, AI) != Comm::OK) {
             comm_close(new_socket);
             PROF_stop(comm_open);
             return -1;
@@ -51,7 +51,7 @@ void comm_import_opened(const Comm::ConnectionPointer &, const char *note, struc
 int comm_open_listener(int sock_type, int proto, Ip::Address &addr, int flags, const char *note);
 void comm_open_listener(int sock_type, int proto, Comm::ConnectionPointer &conn, const char *note);
 
-int comm_openex(int, int, Ip::Address &, int, tos_t tos, nfmark_t nfmark, const char *);
+int comm_openex(int, int, Ip::Address &, int, const char *);
 unsigned short comm_local_port(int fd);
 
 int comm_udp_sendto(int sock, const Ip::Address &to, const void *buf, int buflen);
@@ -71,18 +71,11 @@ int ignoreErrno(int);
 void commCloseAllSockets(void);
 void checkTimeouts(void);
 
-//typedef void IOACB(int fd, int nfd, Comm::ConnectionPointer details, comm_err_t flag, int xerrno, void *data);
 void comm_add_close_handler(int fd, CLCB *, void *);
 void comm_add_close_handler(int fd, AsyncCall::Pointer &);
 void comm_remove_close_handler(int fd, CLCB *, void *);
 void comm_remove_close_handler(int fd, AsyncCall::Pointer &);
 
-int comm_has_pending_read_callback(int fd);
-bool comm_monitors_read(int fd);
-void comm_read(const Comm::ConnectionPointer &conn, char *buf, int len, AsyncCall::Pointer &callback);
-void comm_read(const Comm::ConnectionPointer &conn, SBuf &buf, AsyncCall::Pointer &callback);
-void comm_read_cancel(int fd, IOCB *callback, void *data);
-void comm_read_cancel(int fd, AsyncCall::Pointer &callback);
 int comm_udp_recvfrom(int fd, void *buf, size_t len, int flags, Ip::Address &from);
 int comm_udp_recv(int fd, void *buf, size_t len, int flags);
 ssize_t comm_udp_send(int s, const void *buf, size_t len, int flags);
@@ -12,14 +12,13 @@
 #include "fde.h"
 #include "globals.h"
 #include "icmp/net_db.h"
+#include "ip/QosConfig.h"
 #include "ip/tools.h"
 #include "ipcache.h"
 #include "SquidConfig.h"
 #include "SquidTime.h"
 
-#if HAVE_ERRNO_H
-#include <errno.h>
-#endif
+#include <cerrno>
 
 class CachePeer;
 
@@ -64,7 +63,7 @@ Comm::ConnOpener::swanSong()
 {
     if (callback_ != NULL) {
         // inform the still-waiting caller we are dying
-        sendAnswer(COMM_ERR_CONNECT, 0, "Comm::ConnOpener::swanSong");
+        sendAnswer(Comm::ERR_CONNECT, 0, "Comm::ConnOpener::swanSong");
     }
 
     // did we abort with a temporary FD assigned?
@@ -101,7 +100,7 @@ Comm::ConnOpener::getHost() const
  * Pass the results back to the external handler.
  */
 void
-Comm::ConnOpener::sendAnswer(comm_err_t errFlag, int xerrno, const char *why)
+Comm::ConnOpener::sendAnswer(Comm::Flag errFlag, int xerrno, const char *why)
 {
     // only mark the address good/bad AFTER connect is finished.
     if (host_ != NULL) {
@@ -229,8 +228,9 @@ Comm::ConnOpener::start()
         conn_->local.setIPv4();
     }
 
+    conn_->noteStart();
     if (createFd())
-        connect();
+        doConnect();
 }
 
 /// called at the end of Comm::ConnOpener::DelayedConnectRetry event
@@ -241,7 +241,7 @@ Comm::ConnOpener::restart()
     calls_.sleep_ = false;
 
     if (createFd())
-        connect();
+        doConnect();
 }
 
 /// Create a socket for the future connection or return false.
@@ -255,12 +255,25 @@ Comm::ConnOpener::createFd()
     if (callback_ == NULL || callback_->canceled())
         return false;
 
-    temporaryFd_ = comm_openex(SOCK_STREAM, IPPROTO_TCP, conn_->local, conn_->flags, conn_->tos, conn_->nfmark, host_);
+    temporaryFd_ = comm_openex(SOCK_STREAM, IPPROTO_TCP, conn_->local, conn_->flags, host_);
     if (temporaryFd_ < 0) {
-        sendAnswer(COMM_ERR_CONNECT, 0, "Comm::ConnOpener::createFd");
+        sendAnswer(Comm::ERR_CONNECT, 0, "Comm::ConnOpener::createFd");
         return false;
     }
 
+    // Set TOS if needed.
+    if (conn_->tos &&
+            Ip::Qos::setSockTos(temporaryFd_, conn_->tos, conn_->remote.isIPv4() ? AF_INET : AF_INET6) < 0)
+        conn_->tos = 0;
+#if SO_MARK
+    if (conn_->nfmark &&
+            Ip::Qos::setSockNfmark(temporaryFd_, conn_->nfmark) < 0)
+        conn_->nfmark = 0;
+#endif
+
+    fd_table[temporaryFd_].tosToServer = conn_->tos;
+    fd_table[temporaryFd_].nfmarkToServer = conn_->nfmark;
+
     typedef CommCbMemFunT<Comm::ConnOpener, CommCloseCbParams> abortDialer;
     calls_.earlyAbort_ = JobCallback(5, 4, abortDialer, this, Comm::ConnOpener::earlyAbort);
     comm_add_close_handler(temporaryFd_, calls_.earlyAbort_);
@@ -306,12 +319,12 @@ Comm::ConnOpener::connected()
     Must(fd_table[conn_->fd].flags.open);
     fd_table[conn_->fd].local_addr = conn_->local;
 
-    sendAnswer(COMM_OK, 0, "Comm::ConnOpener::connected");
+    sendAnswer(Comm::OK, 0, "Comm::ConnOpener::connected");
 }
 
 /// Make an FD connection attempt.
 void
-Comm::ConnOpener::connect()
+Comm::ConnOpener::doConnect()
 {
     Must(conn_ != NULL);
     Must(temporaryFd_ >= 0);
@@ -320,13 +333,13 @@ Comm::ConnOpener::connect()
 
     switch (comm_connect_addr(temporaryFd_, conn_->remote) ) {
 
-    case COMM_INPROGRESS:
-        debugs(5, 5, HERE << conn_ << ": COMM_INPROGRESS");
+    case Comm::INPROGRESS:
+        debugs(5, 5, HERE << conn_ << ": Comm::INPROGRESS");
         Comm::SetSelect(temporaryFd_, COMM_SELECT_WRITE, Comm::ConnOpener::InProgressConnectRetry, new Pointer(this), 0);
         break;
 
-    case COMM_OK:
-        debugs(5, 5, HERE << conn_ << ": COMM_OK - connected");
+    case Comm::OK:
+        debugs(5, 5, HERE << conn_ << ": Comm::OK - connected");
         connected();
         break;
 
@@ -344,7 +357,7 @@ Comm::ConnOpener::connect()
         } else {
             // send ERROR back to the upper layer.
             debugs(5, 5, HERE << conn_ << ": * - ERR tried too many times already.");
-            sendAnswer(COMM_ERR_CONNECT, xerrno, "Comm::ConnOpener::connect");
+            sendAnswer(Comm::ERR_CONNECT, xerrno, "Comm::ConnOpener::doConnect");
         }
     }
     }
@@ -410,7 +423,7 @@ Comm::ConnOpener::earlyAbort(const CommCloseCbParams &io)
     debugs(5, 3, HERE << io.conn);
     calls_.earlyAbort_ = NULL;
     // NP: is closing or shutdown better?
-    sendAnswer(COMM_ERR_CLOSING, io.xerrno, "Comm::ConnOpener::earlyAbort");
+    sendAnswer(Comm::ERR_CLOSING, io.xerrno, "Comm::ConnOpener::earlyAbort");
 }
 
 /**
@@ -422,11 +435,11 @@ Comm::ConnOpener::timeout(const CommTimeoutCbParams &)
 {
     debugs(5, 5, HERE << conn_ << ": * - ERR took too long to receive response.");
     calls_.timeout_ = NULL;
-    sendAnswer(COMM_TIMEOUT, ETIMEDOUT, "Comm::ConnOpener::timeout");
+    sendAnswer(Comm::TIMEOUT, ETIMEDOUT, "Comm::ConnOpener::timeout");
 }
 
-/* Legacy Wrapper for the retry event after COMM_INPROGRESS
- * XXX: As soon as Comm::SetSelect() accepts Async calls we can use a ConnOpener::connect call
+/* Legacy Wrapper for the retry event after Comm::INPROGRESS
+ * XXX: As soon as Comm::SetSelect() accepts Async calls we can use a ConnOpener::doConnect call
  */
 void
 Comm::ConnOpener::InProgressConnectRetry(int fd, void *data)
@@ -437,7 +450,7 @@ Comm::ConnOpener::InProgressConnectRetry(int fd, void *data)
         // Ew. we are now outside the all AsyncJob protections.
         // get back inside by scheduling another call...
         typedef NullaryMemFunT<Comm::ConnOpener> Dialer;
-        AsyncCall::Pointer call = JobCallback(5, 4, Dialer, cs, Comm::ConnOpener::connect);
+        AsyncCall::Pointer call = JobCallback(5, 4, Dialer, cs, Comm::ConnOpener::doConnect);
         ScheduleCallHere(call);
     }
     delete ptr;
@@ -4,8 +4,8 @@
 #include "base/AsyncCall.h"
 #include "base/AsyncJob.h"
 #include "cbdata.h"
+#include "comm/Flag.h"
 #include "comm/forward.h"
-#include "comm_err_t.h"
 #include "CommCalls.h"
 
 namespace Comm
@@ -40,10 +40,10 @@ class ConnOpener : public AsyncJob
 
     void earlyAbort(const CommCloseCbParams &);
     void timeout(const CommTimeoutCbParams &);
-    void sendAnswer(comm_err_t errFlag, int xerrno, const char *why);
+    void sendAnswer(Comm::Flag errFlag, int xerrno, const char *why);
     static void InProgressConnectRetry(int fd, void *data);
     static void DelayedConnectRetry(void *data);
-    void connect();
+    void doConnect();
     void connected();
     void lookupLocalAddress();
 
@@ -66,7 +66,7 @@ class ConnOpener : public AsyncJob
     int totalTries_;   ///< total number of connection attempts over all destinations so far.
     int failRetries_;  ///< number of retries current destination has been tried.
 
-    /// if we are not done by then, we will call back with COMM_TIMEOUT
+    /// if we are not done by then, we will call back with Comm::TIMEOUT
     time_t deadline_;
 
     /// handles to calls which we may need to cancel.
@@ -22,7 +22,8 @@ Comm::Connection::Connection() :
         tos(0),
         nfmark(0),
         flags(COMM_NONBLOCKING),
-        peer_(NULL)
+        peer_(NULL),
+        startTime_(squid_curtime)
 {
     *rfc931 = 0; // quick init the head. the rest does not matter.
 }
@@ -44,12 +45,12 @@ Comm::Connection::copyDetails() const
 {
     ConnectionPointer c = new Comm::Connection;
 
-    c->local = local;
-    c->remote = remote;
+    c->setAddrs(local, remote);
     c->peerType = peerType;
     c->tos = tos;
     c->nfmark = nfmark;
     c->flags = flags;
+    c->startTime_ = startTime_;
 
     // ensure FD is not open in the new copy.
     c->fd = -1;
@@ -47,6 +47,7 @@
 #include "eui/Eui48.h"
 #include "eui/Eui64.h"
 #endif
+#include "SquidTime.h"
 
 #include <iosfwd>
 #include <ostream>
@@ -103,6 +104,11 @@ class Connection : public RefCountable
     /** determine whether this object describes an active connection or not. */
     bool isOpen() const { return (fd >= 0); }
 
+    /** Alter the stored IP address pair.
+     * WARNING: Does not ensure matching IPv4/IPv6 are supplied.
+     */
+    void setAddrs(const Ip::Address &aLocal, const Ip::Address &aRemote) {local = aLocal; remote = aRemote;}
+
     /** retrieve the CachePeer pointer for use.
      * The caller is responsible for all CBDATA operations regarding the
      * used of the pointer returned.
@@ -114,6 +120,10 @@ class Connection : public RefCountable
      */
     void setPeer(CachePeer * p);
 
+    /** The time the connection started */
+    time_t startTime() const {return startTime_;}
+
+    void noteStart() {startTime_ = squid_curtime;}
 private:
     /** These objects may not be exactly duplicated. Use copyDetails() instead. */
     Connection(const Connection &c);
@@ -153,6 +163,9 @@ class Connection : public RefCountable
 private:
     /** cache_peer data object (if any) */
     CachePeer *peer_;
+
+    /** The time the connection object was created */
+    time_t startTime_;
 };
 
 }; // namespace Comm
@@ -0,0 +1,25 @@
+#ifndef _SQUID_SRC_COMM_FLAG_H
+#define _SQUID_SRC_COMM_FLAG_H
+
+namespace Comm
+{
+
+typedef enum {
+    OK = 0,
+    COMM_ERROR = -1,
+    NOMESSAGE = -3,
+    TIMEOUT = -4,
+    SHUTDOWN = -5,
+    IDLE = -6, /* there are no active fds and no pending callbacks. */
+    INPROGRESS = -7,
+    ERR_CONNECT = -8,
+    ERR_DNS = -9,
+    ERR_CLOSING = -10,
+    ERR_PROTOCOL = -11, /* IPv4 or IPv6 cannot be used on the fd socket */
+    ENDFILE = -12, /**< read(2) returned success, but with 0 bytes */
+    ERR__END__ = -999999 /* Dummy entry to make syntax valid (comma on line above), do not use. New entries added above */
+} Flag;
+
+} // namespace Comm
+
+#endif /* _SQUID_SRC_COMM_FLAG_H */
@@ -89,7 +89,6 @@ void
 Comm::IoCallback::reset()
 {
     conn = NULL;
-    buf2 = NULL; // we do not own this buffer.
     if (freefunc) {
         freefunc(buf);
         buf = NULL;
@@ -104,7 +103,7 @@ Comm::IoCallback::reset()
 
 // Schedule the callback call and clear the callback
 void
-Comm::IoCallback::finish(comm_err_t code, int xerrn)
+Comm::IoCallback::finish(Comm::Flag code, int xerrn)
 {
     debugs(5, 3, HERE << "called for " << conn << " (" << code << ", " << xerrno << ")");
     assert(active());
@@ -121,7 +120,6 @@ Comm::IoCallback::finish(comm_err_t code, int xerrn)
         Params &params = GetCommParams<Params>(callback);
         if (conn != NULL) params.fd = conn->fd; // for legacy write handlers...
         params.conn = conn;
-        params.buf2 = buf2;
         params.buf = buf;
         params.size = offset;
         params.flag = code;
@@ -2,8 +2,8 @@
 #define _SQUID_COMM_IOCALLBACK_H
 
 #include "base/AsyncCall.h"
+#include "comm/Flag.h"
 #include "comm/forward.h"
-#include "comm_err_t.h"
 #include "typedefs.h"
 
 class SBuf;
@@ -25,19 +25,11 @@ class IoCallback
     iocb_type type;
     Comm::ConnectionPointer conn;
     AsyncCall::Pointer callback;
-
-    /// Buffer to store read(2) into when set.
-    // This is a pointer to the Jobs buffer rather than an SBuf using
-    // the same store since we cannot know when or how the Job will
-    // alter its SBuf while we are reading.
-    SBuf *buf2;
-
-    // Legacy c-string buffers used when buf2 is unset.
     char *buf;
     FREE *freefunc;
     int size;
     int offset;
-    comm_err_t errcode;
+    Comm::Flag errcode;
     int xerrno;
 #if USE_DELAY_POOLS
     unsigned int quotaQueueReserv; ///< reservation ID from CommQuotaQueue
@@ -53,7 +45,7 @@ class IoCallback
     void cancel(const char *reason);
 
     /// finish the IO operation imediately and schedule the callback with the current state.
-    void finish(comm_err_t code, int xerrn);
+    void finish(Comm::Flag code, int xerrn);
 
 private:
     void reset();
@@ -1,7 +1,7 @@
 #ifndef _SQUID_SRC_COMM_LOOPS_H
 #define _SQUID_SRC_COMM_LOOPS_H
 
-#include "comm_err_t.h"
+#include "comm/Flag.h"
 
 // for PF
 #include "typedefs.h"
@@ -27,7 +27,7 @@ void ResetSelect(int);
 /** Perform a select() or equivalent call.
  * This is used by the main select loop engine to check for FD with IO available.
  */
-comm_err_t DoSelect(int);
+Comm::Flag DoSelect(int);
 
 void QuickPollRequired(void);
 
@@ -11,6 +11,7 @@ libcomm_la_SOURCES= \
 	ConnOpener.h \
 	Connection.cc \
 	Connection.h \
+	Flag.h \
 	forward.h \
 	IoCallback.cc \
 	IoCallback.h \
@@ -21,6 +22,8 @@ libcomm_la_SOURCES= \
 	ModPoll.cc \
 	ModSelect.cc \
 	ModSelectWin32.cc \
+	Read.cc \
+	Read.h \
 	TcpAcceptor.cc \
 	TcpAcceptor.h \
 	UdpOpenDialer.h \
@@ -336,7 +336,7 @@ Comm::ResetSelect(int fd)
  *
  * @param msec milliseconds to poll for (limited by max_poll_time)
  */
-comm_err_t
+Comm::Flag
 Comm::DoSelect(int msec)
 {
     int num, i;
@@ -366,7 +366,7 @@ Comm::DoSelect(int msec)
         /* error during poll */
         getCurrentTime();
         PROF_stop(comm_check_incoming);
-        return COMM_ERROR;
+        return Comm::COMM_ERROR;
     }
 
     PROF_stop(comm_check_incoming);
@@ -375,7 +375,7 @@ Comm::DoSelect(int msec)
     statCounter.select_fds_hist.count(num);
 
     if (num == 0)
-        return COMM_TIMEOUT; /* no error */
+        return Comm::TIMEOUT; /* no error */
 
     PROF_start(comm_handle_ready_fd);
 
@@ -453,7 +453,7 @@ Comm::DoSelect(int msec)
     }
 
     PROF_stop(comm_handle_ready_fd);
-    return COMM_OK;
+    return Comm::OK;
 }
 
 void
@@ -65,12 +65,10 @@
 
 #define DEBUG_EPOLL 0
 
+#include <cerrno>
 #if HAVE_SYS_EPOLL_H
 #include <sys/epoll.h>
 #endif
-#if HAVE_ERRNO_H
-#include <errno.h>
-#endif
 
 static int kdpfd;
 static int max_poll_time = 1000;
@@ -241,7 +239,7 @@ commIncomingStats(StoreEntry * sentry)
  * comm_setselect and fd_table[] and calls callbacks for IO ready
  * events.
  */
-comm_err_t
+Comm::Flag
 Comm::DoSelect(int msec)
 {
     int num, i,fd;
@@ -269,7 +267,7 @@ Comm::DoSelect(int msec)
 
         PROF_stop(comm_check_incoming);
 
-        return COMM_ERROR;
+        return Comm::COMM_ERROR;
     }
 
     PROF_stop(comm_check_incoming);
@@ -278,7 +276,7 @@ Comm::DoSelect(int msec)
     statCounter.select_fds_hist.count(num);
 
     if (num == 0)
-        return COMM_TIMEOUT;		/* No error.. */
+        return Comm::TIMEOUT;		/* No error.. */
 
     PROF_start(comm_handle_ready_fd);
 
@@ -325,7 +323,7 @@ Comm::DoSelect(int msec)
 
     PROF_stop(comm_handle_ready_fd);
 
-    return COMM_OK;
+    return Comm::OK;
 }
 
 void
@@ -60,12 +60,10 @@
 #include "StatCounters.h"
 #include "Store.h"
 
+#include <cerrno>
 #if HAVE_SYS_EVENT_H
 #include <sys/event.h>
 #endif
-#if HAVE_ERRNO_H
-#include <errno.h>
-#endif
 
 #define KE_LENGTH        128
 
@@ -244,7 +242,7 @@ Comm::ResetSelect(int fd)
  * events.
  */
 
-comm_err_t
+Comm::Flag
 Comm::DoSelect(int msec)
 {
     int num, i;
@@ -273,15 +271,15 @@ Comm::DoSelect(int msec)
 
         getCurrentTime();
 
-        return COMM_ERROR;
+        return Comm::COMM_ERROR;
 
         /* NOTREACHED */
     }
 
     getCurrentTime();
 
     if (num == 0)
-        return COMM_OK;		/* No error.. */
+        return Comm::OK;		/* No error.. */
 
     for (i = 0; i < num; ++i) {
         int fd = (int) ke[i].ident;
@@ -315,7 +313,7 @@ Comm::DoSelect(int msec)
         }
     }
 
-    return COMM_OK;
+    return Comm::OK;
 }
 
 void
@@ -45,12 +45,10 @@
 #include "StatCounters.h"
 #include "Store.h"
 
+#include <cerrno>
 #if HAVE_POLL_H
 #include <poll.h>
 #endif
-#if HAVE_ERRNO_H
-#include <errno.h>
-#endif
 
 /* Needed for poll() on Linux at least */
 #if USE_POLL
@@ -198,7 +196,7 @@ fdIsDns(int fd)
 static int
 fdIsTcpListen(int fd)
 {
-    for (const AnyP::PortCfg *s = Config.Sockaddr.http; s; s = s->next) {
+    for (AnyP::PortCfgPointer s = HttpPortList; s != NULL; s = s->next) {
         if (s->listenConn != NULL && s->listenConn->fd == fd)
             return 1;
     }
@@ -350,7 +348,7 @@ comm_poll_tcp_incoming(void)
 }
 
 /* poll all sockets; call handlers for those that are ready. */
-comm_err_t
+Comm::Flag
 Comm::DoSelect(int msec)
 {
     struct pollfd pfds[SQUID_MAXFD];
@@ -425,9 +423,9 @@ Comm::DoSelect(int msec)
          */
         if (nfds == 0 && npending == 0) {
             if (shutting_down)
-                return COMM_SHUTDOWN;
+                return Comm::SHUTDOWN;
             else
-                return COMM_IDLE;
+                return Comm::IDLE;
         }
 
         for (;;) {
@@ -447,7 +445,7 @@ Comm::DoSelect(int msec)
 
             assert(errno != EINVAL);
 
-            return COMM_ERROR;
+            return Comm::COMM_ERROR;
 
             /* NOTREACHED */
         }
@@ -582,12 +580,12 @@ Comm::DoSelect(int msec)
 
         statCounter.select_time += (current_dtime - start);
 
-        return COMM_OK;
+        return Comm::OK;
     } while (timeout > current_dtime);
 
     debugs(5, 8, "comm_poll: time out: " << squid_curtime << ".");
 
-    return COMM_TIMEOUT;
+    return Comm::TIMEOUT;
 }
 
 static void
@@ -45,12 +45,10 @@
 #include "StatHist.h"
 #include "Store.h"
 
+#include <cerrno>
 #if HAVE_SYS_STAT_H
 #include <sys/stat.h>
 #endif
-#if HAVE_ERRNO_H
-#include <errno.h>
-#endif
 
 static int MAX_POLL_TIME = 1000;	/* see also Comm::QuickPollRequired() */
 
@@ -199,7 +197,7 @@ fdIsDns(int fd)
 static int
 fdIsTcpListener(int fd)
 {
-    for (const AnyP::PortCfg *s = Config.Sockaddr.http; s; s = s->next) {
+    for (AnyP::PortCfgPointer s = HttpPortList; s != NULL; s = s->next) {
         if (s->listenConn != NULL && s->listenConn->fd == fd)
             return 1;
     }
@@ -322,7 +320,7 @@ comm_select_tcp_incoming(void)
 
     // XXX: only poll sockets that won't be deferred. But how do we identify them?
 
-    for (const AnyP::PortCfg *s = Config.Sockaddr.http; s; s = s->next) {
+    for (AnyP::PortCfgPointer s = HttpPortList; s != NULL; s = s->next) {
         if (Comm::IsConnOpen(s->listenConn)) {
             fds[nfds] = s->listenConn->fd;
             ++nfds;
@@ -346,7 +344,7 @@ comm_select_tcp_incoming(void)
 
 #define DEBUG_FDBITS 0
 /* Select on all sockets; call handlers for those that are ready. */
-comm_err_t
+Comm::Flag
 Comm::DoSelect(int msec)
 {
     fd_set readfds;
@@ -442,7 +440,7 @@ Comm::DoSelect(int msec)
 #endif
         if (nreadfds + nwritefds == 0) {
             assert(shutting_down);
-            return COMM_SHUTDOWN;
+            return Comm::SHUTDOWN;
         }
 
         if (msec > MAX_POLL_TIME)
@@ -468,7 +466,7 @@ Comm::DoSelect(int msec)
 
             examine_select(&readfds, &writefds);
 
-            return COMM_ERROR;
+            return Comm::COMM_ERROR;
 
             /* NOTREACHED */
         }
@@ -630,11 +628,11 @@ Comm::DoSelect(int msec)
 
         statCounter.select_time += (current_dtime - start);
 
-        return COMM_OK;
+        return Comm::OK;
     } while (timeout > current_dtime);
     debugs(5, 8, "comm_select: time out: " << squid_curtime);
 
-    return COMM_TIMEOUT;
+    return Comm::TIMEOUT;
 }
 
 static void
@@ -42,9 +42,7 @@
 #include "StatHist.h"
 #include "Store.h"
 
-#if HAVE_ERRNO_H
-#include <errno.h>
-#endif
+#include <cerrno>
 
 static int MAX_POLL_TIME = 1000;	/* see also Comm::QuickPollRequired() */
 
@@ -193,7 +191,7 @@ fdIsDns(int fd)
 static int
 fdIsTcpListener(int fd)
 {
-    for (const AnyP::PortCfg *s = Config.Sockaddr.http; s; s = s->next) {
+    for (AnyP::PortCfgPointer s = HttpPortList; s != NULL; s = s->next) {
         if (s->listenConn != NULL && s->listenConn->fd == fd)
             return 1;
     }
@@ -319,7 +317,7 @@ comm_select_tcp_incoming(void)
 
     // XXX: only poll sockets that won't be deferred. But how do we identify them?
 
-    for (const AnyP::PortCfg *s = Config.Sockaddr.http; s; s = s->next) {
+    for (AnyP::PortCfgPointer s = HttpPortList; s != NULL; s = s->next) {
         if (Comm::IsConnOpen(s->listenConn)) {
             fds[nfds] = s->listenConn->fd;
             ++nfds;
@@ -343,7 +341,7 @@ comm_select_tcp_incoming(void)
 
 #define DEBUG_FDBITS 0
 /* Select on all sockets; call handlers for those that are ready. */
-comm_err_t
+Comm::Flag
 Comm::DoSelect(int msec)
 {
     fd_set readfds;
@@ -436,7 +434,7 @@ Comm::DoSelect(int msec)
 #endif
         if (nreadfds + nwritefds == 0) {
             assert(shutting_down);
-            return COMM_SHUTDOWN;
+            return Comm::SHUTDOWN;
         }
 
         if (msec > MAX_POLL_TIME)
@@ -462,7 +460,7 @@ Comm::DoSelect(int msec)
 
             examine_select(&readfds, &writefds);
 
-            return COMM_ERROR;
+            return Comm::COMM_ERROR;
 
             /* NOTREACHED */
         }
@@ -644,11 +642,11 @@ Comm::DoSelect(int msec)
 
         statCounter.select_time += (current_dtime - start);
 
-        return COMM_OK;
+        return Comm::OK;
     } while (timeout > current_dtime);
     debugs(5, 8, "comm_select: time out: " << squid_curtime);
 
-    return COMM_TIMEOUT;
+    return Comm::TIMEOUT;
 }
 
 static void
@@ -0,0 +1,234 @@
+/*
+ * DEBUG: section 05    Socket Functions
+ */
+#include "squid.h"
+#include "comm.h"
+#include "comm/IoCallback.h"
+#include "comm/Loops.h"
+#include "comm/Read.h"
+#include "comm_internal.h"
+#include "CommCalls.h"
+#include "Debug.h"
+#include "fd.h"
+#include "fde.h"
+#include "SBuf.h"
+#include "StatCounters.h"
+//#include "tools.h"
+
+// Does comm check this fd for read readiness?
+// Note that when comm is not monitoring, there can be a pending callback
+// call, which may resume comm monitoring once fired.
+bool
+Comm::MonitorsRead(int fd)
+{
+    assert(isOpen(fd) && COMMIO_FD_READCB(fd));
+    // Being active is usually the same as monitoring because we always
+    // start monitoring the FD when we configure Comm::IoCallback for I/O
+    // and we usually configure Comm::IoCallback for I/O when we starting
+    // monitoring a FD for reading.
+    return COMMIO_FD_READCB(fd)->active();
+}
+
+void
+Comm::Read(const Comm::ConnectionPointer &conn, AsyncCall::Pointer &callback)
+{
+    // TODO: move comm_read_base() internals into here
+    // when comm_read() char* API is no longer needed
+    comm_read_base(conn, NULL, 0, callback);
+}
+
+/**
+ * Queue a read.
+ * If a buffer is given the callback is scheduled when the read
+ * completes, on error, or on file descriptor close.
+ *
+ * If no buffer (NULL) is given the callback is scheduled when
+ * the socket FD is ready for a read(2)/recv(2).
+ */
+void
+comm_read_base(const Comm::ConnectionPointer &conn, char *buf, int size, AsyncCall::Pointer &callback)
+{
+    debugs(5, 5, "comm_read, queueing read for " << conn << "; asynCall " << callback);
+
+    /* Make sure we are open and not closing */
+    assert(Comm::IsConnOpen(conn));
+    assert(!fd_table[conn->fd].closing());
+    Comm::IoCallback *ccb = COMMIO_FD_READCB(conn->fd);
+
+    // Make sure we are either not reading or just passively monitoring.
+    // Active/passive conflicts are OK and simply cancel passive monitoring.
+    if (ccb->active()) {
+        // if the assertion below fails, we have an active comm_read conflict
+        assert(fd_table[conn->fd].halfClosedReader != NULL);
+        commStopHalfClosedMonitor(conn->fd);
+        assert(!ccb->active());
+    }
+    ccb->conn = conn;
+
+    /* Queue the read */
+    ccb->setCallback(Comm::IOCB_READ, callback, (char *)buf, NULL, size);
+    Comm::SetSelect(conn->fd, COMM_SELECT_READ, Comm::HandleRead, ccb, 0);
+}
+
+Comm::Flag
+Comm::ReadNow(CommIoCbParams &params, SBuf &buf)
+{
+    /* Attempt a read */
+    ++ statCounter.syscalls.sock.reads;
+    const SBuf::size_type sz = buf.spaceSize();
+    char *inbuf = buf.rawSpace(sz);
+    errno = 0;
+    const int retval = FD_READ_METHOD(params.conn->fd, inbuf, sz);
+    params.xerrno = errno;
+
+    debugs(5, 3, params.conn << ", size " << sz << ", retval " << retval << ", errno " << params.xerrno);
+
+    if (retval > 0) { // data read most common case
+        buf.append(inbuf, retval);
+        fd_bytes(params.conn->fd, retval, FD_READ);
+        params.flag = Comm::OK;
+        params.size = retval;
+
+    } else if (retval == 0) { // remote closure (somewhat less) common
+        // Note - read 0 == socket EOF, which is a valid read.
+        params.flag = Comm::ENDFILE;
+
+    } else if (retval < 0) { // connection errors are worst-case
+        debugs(5, 3, params.conn << " Comm::COMM_ERROR: " << xstrerr(params.xerrno));
+        if (ignoreErrno(params.xerrno))
+            params.flag =  Comm::INPROGRESS;
+        else
+            params.flag =  Comm::COMM_ERROR;
+    }
+
+    return params.flag;
+}
+
+/**
+ * Handle an FD which is ready for read(2).
+ *
+ * If there is no provided buffer to fill call the callback.
+ *
+ * Otherwise attempt a read into the provided buffer.
+ * If the read attempt succeeds or fails, call the callback.
+ * Else, wait for another IO notification.
+ */
+void
+Comm::HandleRead(int fd, void *data)
+{
+    Comm::IoCallback *ccb = (Comm::IoCallback *) data;
+
+    assert(data == COMMIO_FD_READCB(fd));
+    assert(ccb->active());
+
+    // Without a buffer, just call back.
+    // The callee may ReadMore() to get the data.
+    if (!ccb->buf) {
+        ccb->finish(Comm::OK, 0);
+        return;
+    }
+
+    /* For legacy callers : Attempt a read */
+    // Keep in sync with Comm::ReadNow()!
+    ++ statCounter.syscalls.sock.reads;
+    errno = 0;
+    int retval = FD_READ_METHOD(fd, ccb->buf, ccb->size);
+    debugs(5, 3, "FD " << fd << ", size " << ccb->size << ", retval " << retval << ", errno " << errno);
+
+    /* See if we read anything */
+    /* Note - read 0 == socket EOF, which is a valid read */
+    if (retval >= 0) {
+        fd_bytes(fd, retval, FD_READ);
+        ccb->offset = retval;
+        ccb->finish(Comm::OK, errno);
+        return;
+
+    } else if (retval < 0 && !ignoreErrno(errno)) {
+        debugs(5, 3, "comm_read_try: scheduling Comm::COMM_ERROR");
+        ccb->offset = 0;
+        ccb->finish(Comm::COMM_ERROR, errno);
+        return;
+    };
+
+    /* Nope, register for some more IO */
+    Comm::SetSelect(fd, COMM_SELECT_READ, Comm::HandleRead, data, 0);
+}
+
+/**
+ * Cancel a pending read. Assert that we have the right parameters,
+ * and that there are no pending read events!
+ *
+ * XXX: We do not assert that there are no pending read events and
+ * with async calls it becomes even more difficult.
+ * The whole interface should be reworked to do callback->cancel()
+ * instead of searching for places where the callback may be stored and
+ * updating the state of those places.
+ *
+ * AHC Don't call the comm handlers?
+ */
+void
+comm_read_cancel(int fd, IOCB *callback, void *data)
+{
+    if (!isOpen(fd)) {
+        debugs(5, 4, "fails: FD " << fd << " closed");
+        return;
+    }
+
+    Comm::IoCallback *cb = COMMIO_FD_READCB(fd);
+    // TODO: is "active" == "monitors FD"?
+    if (!cb->active()) {
+        debugs(5, 4, "fails: FD " << fd << " inactive");
+        return;
+    }
+
+    typedef CommCbFunPtrCallT<CommIoCbPtrFun> Call;
+    Call *call = dynamic_cast<Call*>(cb->callback.getRaw());
+    if (!call) {
+        debugs(5, 4, "fails: FD " << fd << " lacks callback");
+        return;
+    }
+
+    call->cancel("old comm_read_cancel");
+
+    typedef CommIoCbParams Params;
+    const Params &params = GetCommParams<Params>(cb->callback);
+
+    /* Ok, we can be reasonably sure we won't lose any data here! */
+    assert(call->dialer.handler == callback);
+    assert(params.data == data);
+
+    /* Delete the callback */
+    cb->cancel("old comm_read_cancel");
+
+    /* And the IO event */
+    Comm::SetSelect(fd, COMM_SELECT_READ, NULL, NULL, 0);
+}
+
+void
+Comm::ReadCancel(int fd, AsyncCall::Pointer &callback)
+{
+    callback->cancel("comm_read_cancel");
+
+    if (!isOpen(fd)) {
+        debugs(5, 4, "fails: FD " << fd << " closed");
+        return;
+    }
+
+    Comm::IoCallback *cb = COMMIO_FD_READCB(fd);
+
+    if (!cb->active()) {
+        debugs(5, 4, "fails: FD " << fd << " inactive");
+        return;
+    }
+
+    AsyncCall::Pointer call = cb->callback;
+
+    /* Ok, we can be reasonably sure we won't lose any data here! */
+    assert(call == callback);
+
+    /* Delete the callback */
+    cb->cancel("comm_read_cancel");
+
+    /* And the IO event */
+    Comm::SetSelect(fd, COMM_SELECT_READ, NULL, NULL, 0);
+}
@@ -0,0 +1,54 @@
+#ifndef _SQUID_COMM_READ_H
+#define _SQUID_COMM_READ_H
+
+#include "base/AsyncCall.h"
+#include "comm/forward.h"
+#include "CommCalls.h"
+
+class SBuf;
+
+namespace Comm
+{
+
+/**
+ * Start monitoring for read.
+ *
+ * callback is scheduled when the read is possible,
+ * or on file descriptor close.
+ */
+void Read(const Comm::ConnectionPointer &conn, AsyncCall::Pointer &callback);
+
+/// whether the FD socket is being monitored for read
+bool MonitorsRead(int fd);
+
+/**
+ * Perform a read(2) on a connection immediately.
+ *
+ * The returned flag is also placed in params.flag.
+ *
+ * \retval Comm::OK          data has been read and placed in buf, amount in params.size
+ * \retval Comm::COMM_ERROR  an error occured, the code is placed in params.xerrno
+ * \retval Comm::INPROGRESS  unable to read at this time, or a minor error occured
+ * \retval Comm::ENDFILE     0-byte read has occured.
+ *                           Usually indicates the remote end has disconnected.
+ */
+Comm::Flag ReadNow(CommIoCbParams &params, SBuf &buf);
+
+/// Cancel the read pending on FD. No action if none pending.
+void ReadCancel(int fd, AsyncCall::Pointer &callback);
+
+/// callback handler to process an FD which is available for reading
+extern PF HandleRead;
+
+} // namespace Comm
+
+// Legacy API to be removed
+void comm_read_base(const Comm::ConnectionPointer &conn, char *buf, int len, AsyncCall::Pointer &callback);
+inline void comm_read(const Comm::ConnectionPointer &conn, char *buf, int len, AsyncCall::Pointer &callback)
+{
+    assert(buf != NULL);
+    comm_read_base(conn, buf, len, callback);
+}
+void comm_read_cancel(int fd, IOCB *callback, void *data);
+
+#endif /* _SQUID_COMM_READ_H */
@@ -47,15 +47,14 @@
 #include "fde.h"
 #include "globals.h"
 #include "ip/Intercept.h"
+#include "ip/QosConfig.h"
 #include "MasterXaction.h"
 #include "profiler/Profiler.h"
 #include "SquidConfig.h"
 #include "SquidTime.h"
 #include "StatCounters.h"
 
-#if HAVE_ERRNO_H
-#include <errno.h>
-#endif
+#include <cerrno>
 #ifdef HAVE_NETINET_TCP_H
 // required for accept_filter to build.
 #include <netinet/tcp.h>
@@ -68,7 +67,17 @@ Comm::TcpAcceptor::TcpAcceptor(const Comm::ConnectionPointer &newConn, const cha
         errcode(0),
         isLimited(0),
         theCallSub(aSub),
-        conn(newConn)
+        conn(newConn),
+        listenPort_()
+{}
+
+Comm::TcpAcceptor::TcpAcceptor(const AnyP::PortCfgPointer &p, const char *note, const Subscription::Pointer &aSub) :
+        AsyncJob("Comm::TcpAcceptor"),
+        errcode(0),
+        isLimited(0),
+        theCallSub(aSub),
+        conn(p->listenConn),
+        listenPort_(p)
 {}
 
 void
@@ -95,6 +104,8 @@ Comm::TcpAcceptor::start()
 
     setListen();
 
+    conn->noteStart();
+
     // if no error so far start accepting connections.
     if (errcode == 0)
         SetSelect(conn->fd, COMM_SELECT_READ, doAccept, this, 0);
@@ -122,6 +133,12 @@ Comm::TcpAcceptor::swanSong()
 {
     debugs(5,5, HERE);
     unsubscribe("swanSong");
+    if (IsConnOpen(conn)) {
+        if (closer_ != NULL)
+            comm_remove_close_handler(conn->fd, closer_);
+        conn->close();
+    }
+
     conn = NULL;
     AcceptLimiter::Instance().removeDead(this);
     AsyncJob::swanSong();
@@ -182,6 +199,35 @@ Comm::TcpAcceptor::setListen()
         debugs(5, DBG_CRITICAL, "WARNING: accept_filter not supported on your OS");
 #endif
     }
+
+#if 0
+    // Untested code.
+    // Set TOS if needed.
+    // To correctly implement TOS values on listening sockets, probably requires
+    // more work to inherit TOS values to created connection objects.
+    if (conn->tos &&
+            Ip::Qos::setSockTos(conn->fd, conn->tos, conn->remote.isIPv4() ? AF_INET : AF_INET6) < 0)
+        conn->tos = 0;
+#if SO_MARK
+    if (conn->nfmark &&
+            Ip::Qos::setSockNfmark(conn->fd, conn->nfmark) < 0)
+        conn->nfmark = 0;
+#endif
+#endif
+
+    typedef CommCbMemFunT<Comm::TcpAcceptor, CommCloseCbParams> Dialer;
+    closer_ = JobCallback(5, 4, Dialer, this, Comm::TcpAcceptor::handleClosure);
+    comm_add_close_handler(conn->fd, closer_);
+}
+
+/// called when listening descriptor is closed by an external force
+/// such as clientHttpConnectionsClose()
+void
+Comm::TcpAcceptor::handleClosure(const CommCloseCbParams &io)
+{
+    closer_ = NULL;
+    conn = NULL;
+    Must(done());
 }
 
 /**
@@ -243,12 +289,12 @@ Comm::TcpAcceptor::acceptOne()
 
     /* Accept a new connection */
     ConnectionPointer newConnDetails = new Connection();
-    const comm_err_t flag = oldAccept(newConnDetails);
+    const Comm::Flag flag = oldAccept(newConnDetails);
 
     /* Check for errors */
     if (!newConnDetails->isOpen()) {
 
-        if (flag == COMM_NOMESSAGE) {
+        if (flag == Comm::NOMESSAGE) {
             /* register interest again */
             debugs(5, 5, HERE << "try later: " << conn << " handler Subscription: " << theCallSub);
             SetSelect(conn->fd, COMM_SELECT_READ, doAccept, this, 0);
@@ -277,19 +323,19 @@ Comm::TcpAcceptor::acceptNext()
 }
 
 void
-Comm::TcpAcceptor::notify(const comm_err_t flag, const Comm::ConnectionPointer &newConnDetails) const
+Comm::TcpAcceptor::notify(const Comm::Flag flag, const Comm::ConnectionPointer &newConnDetails) const
 {
-    // listener socket handlers just abandon the port with COMM_ERR_CLOSING
+    // listener socket handlers just abandon the port with Comm::ERR_CLOSING
     // it should only happen when this object is deleted...
-    if (flag == COMM_ERR_CLOSING) {
+    if (flag == Comm::ERR_CLOSING) {
         return;
     }
 
     if (theCallSub != NULL) {
         AsyncCall::Pointer call = theCallSub->callback();
         CommAcceptCbParams &params = GetCommParams<CommAcceptCbParams>(call);
         params.xaction = new MasterXaction;
-        params.xaction->squidPort = static_cast<AnyP::PortCfg*>(params.data);
+        params.xaction->squidPort = listenPort_;
         params.fd = conn->fd;
         params.conn = params.xaction->tcpClient = newConnDetails;
         params.flag = flag;
@@ -302,12 +348,12 @@ Comm::TcpAcceptor::notify(const comm_err_t flag, const Comm::ConnectionPointer &
  * accept() and process
  * Wait for an incoming connection on our listener socket.
  *
- * \retval COMM_OK         success. details parameter filled.
- * \retval COMM_NOMESSAGE  attempted accept() but nothing useful came in.
- * \retval COMM_ERROR      an outright failure occured.
+ * \retval Comm::OK         success. details parameter filled.
+ * \retval Comm::NOMESSAGE  attempted accept() but nothing useful came in.
+ * \retval Comm::COMM_ERROR      an outright failure occured.
  *                         Or if this client has too many connections already.
  */
-comm_err_t
+Comm::Flag
 Comm::TcpAcceptor::oldAccept(Comm::ConnectionPointer &details)
 {
     PROF_start(comm_accept);
@@ -326,13 +372,13 @@ Comm::TcpAcceptor::oldAccept(Comm::ConnectionPointer &details)
 
         if (ignoreErrno(errno)) {
             debugs(50, 5, HERE << status() << ": " << xstrerror());
-            return COMM_NOMESSAGE;
+            return Comm::NOMESSAGE;
         } else if (ENFILE == errno || EMFILE == errno) {
             debugs(50, 3, HERE << status() << ": " << xstrerror());
-            return COMM_ERROR;
+            return Comm::COMM_ERROR;
         } else {
             debugs(50, DBG_IMPORTANT, HERE << status() << ": " << xstrerror());
-            return COMM_ERROR;
+            return Comm::COMM_ERROR;
         }
     }
 
@@ -344,7 +390,7 @@ Comm::TcpAcceptor::oldAccept(Comm::ConnectionPointer &details)
         if (clientdbEstablished(details->remote, 0) > Config.client_ip_max_connections) {
             debugs(50, DBG_IMPORTANT, "WARNING: " << details->remote << " attempting more than " << Config.client_ip_max_connections << " connections.");
             Ip::Address::FreeAddrInfo(gai);
-            return COMM_ERROR;
+            return Comm::COMM_ERROR;
         }
     }
 
@@ -354,7 +400,7 @@ Comm::TcpAcceptor::oldAccept(Comm::ConnectionPointer &details)
     if (getsockname(sock, gai->ai_addr, &gai->ai_addrlen) != 0) {
         debugs(50, DBG_IMPORTANT, "ERROR: getsockname() failed to locate local-IP on " << details << ": " << xstrerror());
         Ip::Address::FreeAddrInfo(gai);
-        return COMM_ERROR;
+        return Comm::COMM_ERROR;
     }
     details->local = *gai;
     Ip::Address::FreeAddrInfo(gai);
@@ -383,7 +429,7 @@ Comm::TcpAcceptor::oldAccept(Comm::ConnectionPointer &details)
     // Perform NAT or TPROXY operations to retrieve the real client/dest IP addresses
     if (conn->flags&(COMM_TRANSPARENT|COMM_INTERCEPTION) && !Ip::Interceptor.Lookup(details, conn)) {
         // Failed.
-        return COMM_ERROR;
+        return Comm::COMM_ERROR;
     }
 
 #if USE_SQUID_EUI
@@ -397,5 +443,5 @@ Comm::TcpAcceptor::oldAccept(Comm::ConnectionPointer &details)
 #endif
 
     PROF_stop(comm_accept);
-    return COMM_OK;
+    return Comm::OK;
 }
@@ -1,11 +1,14 @@
 #ifndef SQUID_COMM_TCPACCEPTOR_H
 #define SQUID_COMM_TCPACCEPTOR_H
 
+#include "anyp/forward.h"
 #include "base/AsyncJob.h"
 #include "base/CbcPointer.h"
 #include "base/Subscription.h"
+#include "comm/Flag.h"
 #include "comm/forward.h"
-#include "comm_err_t.h"
+
+class CommCloseCbParams;
 
 namespace Comm
 {
@@ -39,6 +42,7 @@ class TcpAcceptor : public AsyncJob
 
 public:
     TcpAcceptor(const Comm::ConnectionPointer &conn, const char *note, const Subscription::Pointer &aSub);
+    TcpAcceptor(const AnyP::PortCfgPointer &listenPort, const char *note, const Subscription::Pointer &aSub);
 
     /** Subscribe a handler to receive calls back about new connections.
      * Unsubscribes any existing subscribed handler.
@@ -57,7 +61,7 @@ class TcpAcceptor : public AsyncJob
     void acceptNext();
 
     /// Call the subscribed callback handler with details about a new connection.
-    void notify(const comm_err_t flag, const Comm::ConnectionPointer &details) const;
+    void notify(const Comm::Flag flag, const Comm::ConnectionPointer &details) const;
 
     /// errno code of the last accept() or listen() action if one occurred.
     int errcode;
@@ -73,6 +77,12 @@ class TcpAcceptor : public AsyncJob
     /// Reserved for read-only use.
     ConnectionPointer conn;
 
+    /// configuration details of the listening port (if provided)
+    AnyP::PortCfgPointer listenPort_;
+
+    /// listen socket closure handler
+    AsyncCall::Pointer closer_;
+
     /// Method to test if there are enough file descriptors to open a new client connection
     /// if not the accept() will be postponed
     static bool okToAccept();
@@ -81,8 +91,9 @@ class TcpAcceptor : public AsyncJob
     static void doAccept(int fd, void *data);
 
     void acceptOne();
-    comm_err_t oldAccept(Comm::ConnectionPointer &details);
+    Comm::Flag oldAccept(Comm::ConnectionPointer &details);
     void setListen();
+    void handleClosure(const CommCloseCbParams &io);
 
     CBDATA_CLASS2(TcpAcceptor);
 };
@@ -125,18 +125,18 @@ Comm::HandleWrite(int fd, void *data)
         if (nleft != 0)
             debugs(5, DBG_IMPORTANT, "FD " << fd << " write failure: connection closed with " << nleft << " bytes remaining.");
 
-        state->finish(nleft ? COMM_ERROR : COMM_OK, errno);
+        state->finish(nleft ? Comm::COMM_ERROR : Comm::OK, errno);
     } else if (len < 0) {
         /* An error */
         if (fd_table[fd].flags.socket_eof) {
             debugs(50, 2, HERE << "FD " << fd << " write failure: " << xstrerror() << ".");
-            state->finish(nleft ? COMM_ERROR : COMM_OK, errno);
+            state->finish(nleft ? Comm::COMM_ERROR : Comm::OK, errno);
         } else if (ignoreErrno(errno)) {
             debugs(50, 9, HERE << "FD " << fd << " write failure: " << xstrerror() << ".");
             state->selectOrQueueWrite();
         } else {
             debugs(50, 2, HERE << "FD " << fd << " write failure: " << xstrerror() << ".");
-            state->finish(nleft ? COMM_ERROR : COMM_OK, errno);
+            state->finish(nleft ? Comm::COMM_ERROR : Comm::OK, errno);
         }
     } else {
         /* A successful write, continue */
@@ -146,7 +146,7 @@ Comm::HandleWrite(int fd, void *data)
             /* Not done, reinstall the write handler and write some more */
             state->selectOrQueueWrite();
         } else {
-            state->finish(nleft ? COMM_OK : COMM_ERROR, errno);
+            state->finish(nleft ? Comm::OK : Comm::COMM_ERROR, errno);
         }
     }
 
@@ -1,19 +0,0 @@
-#ifndef _SQUID_COMM_COMM_ERR_T_H
-#define _SQUID_COMM_COMM_ERR_T_H
-
-typedef enum {
-    COMM_OK = 0,
-    COMM_ERROR = -1,
-    COMM_NOMESSAGE = -3,
-    COMM_TIMEOUT = -4,
-    COMM_SHUTDOWN = -5,
-    COMM_IDLE = -6, /* there are no active fds and no pending callbacks. */
-    COMM_INPROGRESS = -7,
-    COMM_ERR_CONNECT = -8,
-    COMM_ERR_DNS = -9,
-    COMM_ERR_CLOSING = -10,
-    COMM_ERR_PROTOCOL = -11, /* IPv4 or IPv6 cannot be used on the fd socket */
-    COMM_ERR__END__ = -999999 /* Dummy entry to make syntax valid (comma on line above), do not use. New entries added above */
-} comm_err_t;
-
-#endif /* _SQUID_COMM_COMM_ERR_T_H */
@@ -12,5 +12,6 @@ typedef struct _fd_debug_t fd_debug_t;
 extern fd_debug_t *fdd_table;
 
 bool isOpen(const int fd);
+void commStopHalfClosedMonitor(int fd);
 
 #endif
@@ -5,10 +5,12 @@
 
 #include <vector>
 
+/// Abstraction layer for TCP, UDP, TLS, UDS and filedescriptor sockets.
 namespace Comm
 {
 
 class Connection;
+class ConnOpener;
 
 typedef RefCount<Comm::Connection> ConnectionPointer;
 
@@ -1,19 +0,0 @@
-#ifndef _SQUID_COMM_COMM_ERR_T_H
-#define _SQUID_COMM_COMM_ERR_T_H
-
-typedef enum {
-    COMM_OK = 0,
-    COMM_ERROR = -1,
-    COMM_NOMESSAGE = -3,
-    COMM_TIMEOUT = -4,
-    COMM_SHUTDOWN = -5,
-    COMM_IDLE = -6, /* there are no active fds and no pending callbacks. */
-    COMM_INPROGRESS = -7,
-    COMM_ERR_CONNECT = -8,
-    COMM_ERR_DNS = -9,
-    COMM_ERR_CLOSING = -10,
-    COMM_ERR_PROTOCOL = -11, /* IPv4 or IPv6 cannot be used on the fd socket */
-    COMM_ERR__END__ = -999999 /* Dummy entry to make syntax valid (comma on line above), do not use. New entries added above */
-} comm_err_t;
-
-#endif /* _SQUID_COMM_COMM_ERR_T_H */
@@ -41,9 +41,7 @@
 #include "profiler/Profiler.h"
 #include "StatCounters.h"
 
-#if HAVE_ERRNO_H
-#include <errno.h>
-#endif
+#include <cerrno>
 
 static PF diskHandleRead;
 static PF diskHandleWrite;
@@ -36,6 +36,7 @@
 #include "comm/Connection.h"
 #include "comm/ConnOpener.h"
 #include "comm/Loops.h"
+#include "comm/Read.h"
 #include "comm/Write.h"
 #include "dlink.h"
 #include "event.h"
@@ -60,12 +61,10 @@
 #if HAVE_ARPA_NAMESER_H
 #include <arpa/nameser.h>
 #endif
+#include <cerrno>
 #if HAVE_RESOLV_H
 #include <resolv.h>
 #endif
-#if HAVE_ERRNO_H
-#include <errno.h>
-#endif
 
 #if _SQUID_WINDOWS_
 #define REG_TCPIP_PARA_INTERFACES "SYSTEM\\CurrentControlSet\\Services\\Tcpip\\Parameters\\Interfaces"
@@ -797,18 +796,18 @@ idnsTickleQueue(void)
 }
 
 static void
-idnsSentQueryVC(const Comm::ConnectionPointer &conn, char *buf, size_t size, comm_err_t flag, int xerrno, void *data)
+idnsSentQueryVC(const Comm::ConnectionPointer &conn, char *buf, size_t size, Comm::Flag flag, int xerrno, void *data)
 {
     nsvc * vc = (nsvc *)data;
 
-    if (flag == COMM_ERR_CLOSING)
+    if (flag == Comm::ERR_CLOSING)
         return;
 
     // XXX: irrelevant now that we have conn pointer?
     if (!Comm::IsConnOpen(conn) || fd_table[conn->fd].closing())
         return;
 
-    if (flag != COMM_OK || size <= 0) {
+    if (flag != Comm::OK || size <= 0) {
         conn->close();
         return;
     }
@@ -851,11 +850,11 @@ idnsDoSendQueryVC(nsvc *vc)
 }
 
 static void
-idnsInitVCConnected(const Comm::ConnectionPointer &conn, comm_err_t status, int xerrno, void *data)
+idnsInitVCConnected(const Comm::ConnectionPointer &conn, Comm::Flag status, int xerrno, void *data)
 {
     nsvc * vc = (nsvc *)data;
 
-    if (status != COMM_OK || !conn) {
+    if (status != Comm::OK || !conn) {
         char buf[MAX_IPSTRLEN] = "";
         if (vc->ns < nns)
             nameservers[vc->ns].S.toStr(buf,MAX_IPSTRLEN);
@@ -900,15 +899,12 @@ idnsInitVC(int nsv)
     Comm::ConnectionPointer conn = new Comm::Connection();
 
     if (!Config.Addrs.udp_outgoing.isNoAddr())
-        conn->local = Config.Addrs.udp_outgoing;
+        conn->setAddrs(Config.Addrs.udp_outgoing, nameservers[nsv].S);
     else
-        conn->local = Config.Addrs.udp_incoming;
-
-    conn->remote = nameservers[nsv].S;
+        conn->setAddrs(Config.Addrs.udp_incoming, nameservers[nsv].S);
 
-    if (conn->remote.isIPv4()) {
+    if (conn->remote.isIPv4())
         conn->local.setIPv4();
-    }
 
     AsyncCall::Pointer call = commCbCall(78,3, "idnsInitVCConnected", CommConnectCbPtrFun(idnsInitVCConnected, vc));
 
@@ -1439,14 +1435,14 @@ idnsCheckQueue(void *unused)
 }
 
 static void
-idnsReadVC(const Comm::ConnectionPointer &conn, char *buf, size_t len, comm_err_t flag, int xerrno, void *data)
+idnsReadVC(const Comm::ConnectionPointer &conn, char *buf, size_t len, Comm::Flag flag, int xerrno, void *data)
 {
     nsvc * vc = (nsvc *)data;
 
-    if (flag == COMM_ERR_CLOSING)
+    if (flag == Comm::ERR_CLOSING)
         return;
 
-    if (flag != COMM_OK || len <= 0) {
+    if (flag != Comm::OK || len <= 0) {
         if (Comm::IsConnOpen(conn))
             conn->close();
         return;
@@ -1472,14 +1468,14 @@ idnsReadVC(const Comm::ConnectionPointer &conn, char *buf, size_t len, comm_err_
 }
 
 static void
-idnsReadVCHeader(const Comm::ConnectionPointer &conn, char *buf, size_t len, comm_err_t flag, int xerrno, void *data)
+idnsReadVCHeader(const Comm::ConnectionPointer &conn, char *buf, size_t len, Comm::Flag flag, int xerrno, void *data)
 {
     nsvc * vc = (nsvc *)data;
 
-    if (flag == COMM_ERR_CLOSING)
+    if (flag == Comm::ERR_CLOSING)
         return;
 
-    if (flag != COMM_OK || len <= 0) {
+    if (flag != Comm::OK || len <= 0) {
         if (Comm::IsConnOpen(conn))
             conn->close();
         return;
@@ -682,12 +682,12 @@ errorSend(const Comm::ConnectionPointer &conn, ErrorState * err)
  *     closing the FD, otherwise we do it ourselves.
  */
 static void
-errorSendComplete(const Comm::ConnectionPointer &conn, char *bufnotused, size_t size, comm_err_t errflag, int xerrno, void *data)
+errorSendComplete(const Comm::ConnectionPointer &conn, char *bufnotused, size_t size, Comm::Flag errflag, int xerrno, void *data)
 {
     ErrorState *err = static_cast<ErrorState *>(data);
     debugs(4, 3, HERE << conn << ", size=" << size);
 
-    if (errflag != COMM_ERR_CLOSING) {
+    if (errflag != Comm::ERR_CLOSING) {
         if (err->callback) {
             debugs(4, 3, "errorSendComplete: callback");
             err->callback(conn->fd, err->callback_data, size);
@@ -41,9 +41,7 @@
 #include "globals.h"
 #include "ip/Address.h"
 
-#if HAVE_ERRNO_H
-#include <errno.h>
-#endif
+#include <cerrno>
 
 /* START Legacy includes pattern */
 /* TODO: clean this up so we dont have per-OS requirements.
@@ -59,8 +57,9 @@ struct arpreq {
     struct sockaddr arp_ha;   /* hardware address */
     int arp_flags;            /* flags */
 };
-
-#include <Iphlpapi.h>
+#if HAVE_IPHLPAPI_H
+#include <iphlpapi.h>
+#endif
 #endif
 
 #if HAVE_SYS_PARAM_H
@@ -1534,10 +1534,8 @@ ExternalACLLookup::LookupDone(void *data, void *result)
             // XXX: we have no access to the transaction / AccessLogEntry so cant SyncNotes().
             // workaround by using anything already set in HttpRequest
             // OR use new and rely on a later Sync copying these to AccessLogEntry
-            if (!req->notes)
-                req->notes = new NotePairs;
 
-            req->notes->appendNewOnly(&checklist->extacl_entry->notes);
+            UpdateRequestNotes(checklist->conn(), *req, checklist->extacl_entry->notes);
         }
     }
 
@@ -32,7 +32,7 @@
  */
 
 #include "squid.h"
-#include "comm.h"
+#include "comm/Read.h"
 #include "fde.h"
 #include "globals.h"
 #include "SquidTime.h"
@@ -44,7 +44,7 @@ bool
 fde::readPending(int fdNumber)
 {
     if (type == FD_SOCKET)
-        return comm_monitors_read(fdNumber);
+        return Comm::MonitorsRead(fdNumber);
 
     return read_handler ? true : false ;
 }
@@ -384,7 +384,7 @@ Format::Format::assemble(MemBuf &mb, const AccessLogEntry::Pointer &al, int logS
             // avoid logging a dash if we have reliable info
             const bool interceptedAtKnownPort = al->request ?
                                                 (al->request->flags.interceptTproxy ||
-                                                 al->request->flags.intercepted) && al->cache.port :
+                                                 al->request->flags.intercepted) && al->cache.port != NULL :
                                                 false;
             if (interceptedAtKnownPort) {
                 const bool portAddressConfigured = !al->cache.port->s.isAnyAddr();
@@ -416,7 +416,7 @@ Format::Format::assemble(MemBuf &mb, const AccessLogEntry::Pointer &al, int logS
             break;
 
         case LFT_LOCAL_LISTENING_PORT:
-            if (al->cache.port) {
+            if (al->cache.port != NULL) {
                 outint = al->cache.port->s.port();
                 doint = 1;
             }
@@ -47,7 +47,7 @@ libfs_la_LIBADD =  $(STORE_LIBS_TO_BUILD)
 libfs_la_DEPENDENCIES = $(STORE_LIBS_TO_BUILD)
 
 ## we need our local files too (but avoid -I. at all costs)
-INCLUDES += -I$(srcdir)
+AM_CPPFLAGS += -I$(srcdir)
 
 
 ## targets below to emulate distributed makefiles
@@ -15,9 +15,7 @@
 #include "tools.h"
 #include "typedefs.h"
 
-#if HAVE_ERRNO_H
-#include <errno.h>
-#endif
+#include <cerrno>
 
 CBDATA_NAMESPACED_CLASS_INIT(Rock, Rebuild);
 
@@ -82,13 +80,13 @@ class LoadingEntry
     /* store entry-level information indexed by sfileno */
     uint64_t size; ///< payload seen so far
     uint32_t version; ///< DbCellHeader::version to distinguish same-URL chains
-    uint32_t state:3;  ///< current entry state (one of the State values)
-    uint32_t anchored:1;  ///< whether we loaded the inode slot for this entry
+    uint8_t state:3;  ///< current entry state (one of the State values)
+    uint8_t anchored:1;  ///< whether we loaded the inode slot for this entry
 
     /* db slot-level information indexed by slotId, starting with firstSlot */
-    uint32_t mapped:1;  ///< whether this slot was added to a mapped entry
-    uint32_t freed:1;  ///< whether this slot was marked as free
-    sfileno more:25; ///< another slot in some entry chain (unordered)
+    uint8_t mapped:1;  ///< whether this slot was added to a mapped entry
+    uint8_t freed:1;  ///< whether this slot was marked as free
+    Ipc::StoreMapSliceId more; ///< another slot in some entry chain (unordered)
     bool used() const { return freed || mapped || more != -1; }
 
     /// possible entry states
@@ -101,7 +99,8 @@ Rock::Rebuild::Rebuild(SwapDir *dir): AsyncJob("Rock::Rebuild"),
         sd(dir),
         entries(NULL),
         dbSize(0),
-        dbEntrySize(0),
+        dbSlotSize(0),
+        dbSlotLimit(0),
         dbEntryLimit(0),
         fd(-1),
         dbOffset(0),
@@ -111,8 +110,10 @@ Rock::Rebuild::Rebuild(SwapDir *dir): AsyncJob("Rock::Rebuild"),
     assert(sd);
     memset(&counts, 0, sizeof(counts));
     dbSize = sd->diskOffsetLimit(); // we do not care about the trailer waste
-    dbEntrySize = sd->slotSize;
-    dbEntryLimit = sd->entryLimit();
+    dbSlotSize = sd->slotSize;
+    dbEntryLimit = sd->entryLimitActual();
+    dbSlotLimit = sd->slotLimitActual();
+    assert(dbEntryLimit <= dbSlotLimit);
 }
 
 Rock::Rebuild::~Rebuild()
@@ -150,9 +151,8 @@ Rock::Rebuild::start()
     buf.init(SM_PAGE_SIZE, SM_PAGE_SIZE);
 
     dbOffset = SwapDir::HeaderSize;
-    loadingPos = 0;
 
-    entries = new LoadingEntry[dbEntryLimit];
+    entries = new LoadingEntry[dbSlotLimit];
 
     checkpoint();
 }
@@ -168,7 +168,7 @@ Rock::Rebuild::checkpoint()
 bool
 Rock::Rebuild::doneAll() const
 {
-    return dbOffset >= dbSize && validationPos >= dbEntryLimit &&
+    return loadingPos >= dbSlotLimit && validationPos >= dbSlotLimit &&
            AsyncJob::doneAll();
 }
 
@@ -182,7 +182,7 @@ Rock::Rebuild::Steps(void *data)
 void
 Rock::Rebuild::steps()
 {
-    if (dbOffset < dbSize)
+    if (loadingPos < dbSlotLimit)
         loadingSteps();
     else
         validationSteps();
@@ -203,14 +203,14 @@ Rock::Rebuild::loadingSteps()
     const timeval loopStart = current_time;
 
     int loaded = 0;
-    while (loaded < dbEntryLimit && dbOffset < dbSize) {
+    while (loadingPos < dbSlotLimit) {
         loadOneSlot();
-        dbOffset += dbEntrySize;
+        dbOffset += dbSlotSize;
         ++loadingPos;
         ++loaded;
 
         if (counts.scancount % 1000 == 0)
-            storeRebuildProgress(sd->index, dbEntryLimit, counts.scancount);
+            storeRebuildProgress(sd->index, dbSlotLimit, counts.scancount);
 
         if (opt_foreground_rebuild)
             continue; // skip "few entries at a time" check below
@@ -257,7 +257,7 @@ Rock::Rebuild::loadOneSlot()
         freeSlotIfIdle(slotId, false);
         return;
     }
-    if (!header.sane(dbEntrySize, dbEntryLimit)) {
+    if (!header.sane(dbSlotSize, dbSlotLimit)) {
         debugs(47, DBG_IMPORTANT, "WARNING: cache_dir[" << sd->index << "]: " <<
                "Ignoring malformed cache entry meta data at " << dbOffset);
         freeSlotIfIdle(slotId, true);
@@ -303,7 +303,7 @@ Rock::Rebuild::validationSteps()
     const timeval loopStart = current_time;
 
     int validated = 0;
-    while (validationPos < dbEntryLimit) {
+    while (validationPos < dbSlotLimit) {
         validateOneEntry();
         ++validationPos;
         ++validated;
@@ -55,8 +55,9 @@ class Rebuild: public AsyncJob
     LoadingEntry *entries; ///< store entries being loaded from disk
 
     int64_t dbSize;
-    int dbEntrySize;
-    int dbEntryLimit;
+    int dbSlotSize; ///< the size of a db cell, including the cell header
+    int dbSlotLimit; ///< total number of db cells
+    int dbEntryLimit; ///< maximum number of entries that can be stored in db
 
     int fd; // store db file descriptor
     int64_t dbOffset;
@@ -24,6 +24,7 @@
 
 #include <cstdlib>
 #include <iomanip>
+#include <limits>
 
 #if HAVE_SYS_STAT_H
 #include <sys/stat.h>
@@ -209,11 +210,27 @@ Rock::SwapDir::swappedOut(const StoreEntry &)
 }
 
 int64_t
-Rock::SwapDir::entryLimitAllowed() const
+Rock::SwapDir::slotLimitAbsolute() const
 {
-    const int64_t eLimitLo = map ? map->entryLimit() : 0; // dynamic shrinking unsupported
-    const int64_t eWanted = (maxSize() - HeaderSize)/slotSize;
-    return min(max(eLimitLo, eWanted), entryLimitHigh());
+    // the max value is an invalid one; all values must be below the limit
+    assert(std::numeric_limits<Ipc::StoreMapSliceId>::max() ==
+           std::numeric_limits<SlotId>::max());
+    return std::numeric_limits<SlotId>::max();
+}
+
+int64_t
+Rock::SwapDir::slotLimitActual() const
+{
+    const int64_t sWanted = (maxSize() - HeaderSize)/slotSize;
+    const int64_t sLimitLo = map ? map->sliceLimit() : 0; // dynamic shrinking unsupported
+    const int64_t sLimitHi = slotLimitAbsolute();
+    return min(max(sLimitLo, sWanted), sLimitHi);
+}
+
+int64_t
+Rock::SwapDir::entryLimitActual() const
+{
+    return min(slotLimitActual(), entryLimitAbsolute());
 }
 
 // TODO: encapsulate as a tool
@@ -542,20 +559,35 @@ Rock::SwapDir::validateOptions()
     const int64_t slotSizeRoundingWaste = slotSize;
     const int64_t maxRoundingWaste =
         max(maxSizeRoundingWaste, slotSizeRoundingWaste);
-    const int64_t usableDiskSize = diskOffset(entryLimitAllowed());
-    const int64_t diskWasteSize = maxSize() - usableDiskSize;
-    Must(diskWasteSize >= 0);
-
-    // warn if maximum db size is not reachable due to sfileno limit
-    if (entryLimitAllowed() == entryLimitHigh() &&
-            diskWasteSize >= maxRoundingWaste) {
-        debugs(47, DBG_CRITICAL, "Rock store cache_dir[" << index << "] '" << path << "':");
-        debugs(47, DBG_CRITICAL, "\tmaximum number of entries: " << entryLimitAllowed());
-        debugs(47, DBG_CRITICAL, "\tdb slot size: " << slotSize << " Bytes");
-        debugs(47, DBG_CRITICAL, "\tmaximum db size: " << maxSize() << " Bytes");
-        debugs(47, DBG_CRITICAL, "\tusable db size:  " << usableDiskSize << " Bytes");
-        debugs(47, DBG_CRITICAL, "\tdisk space waste: " << diskWasteSize << " Bytes");
-        debugs(47, DBG_CRITICAL, "WARNING: Rock store config wastes space.");
+
+    // an entry consumes at least one slot; round up to reduce false warnings
+    const int64_t blockSize = static_cast<int64_t>(slotSize);
+    const int64_t maxObjSize = max(blockSize,
+                                   ((maxObjectSize()+blockSize-1)/blockSize)*blockSize);
+
+    // Does the "sfileno*max-size" limit match configured db capacity?
+    const double entriesMayOccupy = entryLimitAbsolute()*static_cast<double>(maxObjSize);
+    if (entriesMayOccupy + maxRoundingWaste < maxSize()) {
+        const int64_t diskWasteSize = maxSize() - static_cast<int64_t>(entriesMayOccupy);
+        debugs(47, DBG_CRITICAL, "WARNING: Rock cache_dir " << path << " wastes disk space due to entry limits:" <<
+               "\n\tconfigured db capacity: " << maxSize() << " bytes" <<
+               "\n\tconfigured db slot size: " << slotSize << " bytes" <<
+               "\n\tconfigured maximum entry size: " << maxObjectSize() << " bytes" <<
+               "\n\tmaximum number of cache_dir entries supported by Squid: " << entryLimitAbsolute() <<
+               "\n\tdisk space all entries may use: " << entriesMayOccupy << " bytes" <<
+               "\n\tdisk space wasted: " << diskWasteSize << " bytes");
+    }
+
+    // Does the "absolute slot count" limit match configured db capacity?
+    const double slotsMayOccupy = slotLimitAbsolute()*static_cast<double>(slotSize);
+    if (slotsMayOccupy + maxRoundingWaste < maxSize()) {
+        const int64_t diskWasteSize = maxSize() - static_cast<int64_t>(entriesMayOccupy);
+        debugs(47, DBG_CRITICAL, "WARNING: Rock cache_dir " << path << " wastes disk space due to slot limits:" <<
+               "\n\tconfigured db capacity: " << maxSize() << " bytes" <<
+               "\n\tconfigured db slot size: " << slotSize << " bytes" <<
+               "\n\tmaximum number of rock cache_dir slots supported by Squid: " << slotLimitAbsolute() <<
+               "\n\tdisk space all slots may use: " << slotsMayOccupy << " bytes" <<
+               "\n\tdisk space wasted: " << diskWasteSize << " bytes");
     }
 }
 
@@ -634,10 +666,10 @@ Rock::SwapDir::createStoreIO(StoreEntry &e, StoreIOState::STFNCB *cbFile, StoreI
 }
 
 int64_t
-Rock::SwapDir::diskOffset(int filen) const
+Rock::SwapDir::diskOffset(const SlotId sid) const
 {
-    assert(filen >= 0);
-    return HeaderSize + slotSize*filen;
+    assert(sid >= 0);
+    return HeaderSize + slotSize*sid;
 }
 
 int64_t
@@ -651,19 +683,7 @@ int64_t
 Rock::SwapDir::diskOffsetLimit() const
 {
     assert(map);
-    return diskOffset(map->entryLimit());
-}
-
-int
-Rock::SwapDir::entryMaxPayloadSize() const
-{
-    return slotSize - sizeof(DbCellHeader);
-}
-
-int
-Rock::SwapDir::entriesNeeded(const int64_t objSize) const
-{
-    return (objSize + entryMaxPayloadSize() - 1) / entryMaxPayloadSize();
+    return diskOffset(map->sliceLimit());
 }
 
 bool
@@ -693,11 +713,11 @@ Rock::SwapDir::useFreeSlot(Ipc::Mem::PageId &pageId)
 bool
 Rock::SwapDir::validSlotId(const SlotId slotId) const
 {
-    return 0 <= slotId && slotId < entryLimitAllowed();
+    return 0 <= slotId && slotId < slotLimitActual();
 }
 
 void
-Rock::SwapDir::noteFreeMapSlice(const sfileno sliceId)
+Rock::SwapDir::noteFreeMapSlice(const Ipc::StoreMapSliceId sliceId)
 {
     Ipc::Mem::PageId pageId;
     pageId.pool = index+1;
@@ -770,8 +790,9 @@ Rock::SwapDir::ioCompletedNotification()
                xstrerror());
 
     debugs(47, 2, "Rock cache_dir[" << index << "] limits: " <<
-           std::setw(12) << maxSize() << " disk bytes and " <<
-           std::setw(7) << map->entryLimit() << " entries");
+           std::setw(12) << maxSize() << " disk bytes, " <<
+           std::setw(7) << map->entryLimit() << " entries, and " <<
+           std::setw(7) << map->sliceLimit() << " slots");
 
     rebuild();
 }
@@ -947,25 +968,27 @@ Rock::SwapDir::statfs(StoreEntry &e) const
                       currentSize() / 1024.0,
                       Math::doublePercent(currentSize(), maxSize()));
 
-    if (map) {
-        const int limit = map->entryLimit();
-        storeAppendPrintf(&e, "Maximum entries: %9d\n", limit);
-        if (limit > 0) {
-            const int entryCount = map->entryCount();
-            storeAppendPrintf(&e, "Current entries: %9d %.2f%%\n",
-                              entryCount, (100.0 * entryCount / limit));
-
-            const unsigned int slotsFree = !freeSlots ? 0 : freeSlots->size();
-            if (slotsFree <= static_cast<const unsigned int>(limit)) {
-                const int usedSlots = limit - static_cast<const int>(slotsFree);
-                storeAppendPrintf(&e, "Used slots:      %9d %.2f%%\n",
-                                  usedSlots, (100.0 * usedSlots / limit));
-            }
-            if (limit < 100) { // XXX: otherwise too expensive to count
-                Ipc::ReadWriteLockStats stats;
-                map->updateStats(stats);
-                stats.dump(e);
-            }
+    const int entryLimit = entryLimitActual();
+    const int slotLimit = slotLimitActual();
+    storeAppendPrintf(&e, "Maximum entries: %9d\n", entryLimit);
+    if (map && entryLimit > 0) {
+        const int entryCount = map->entryCount();
+        storeAppendPrintf(&e, "Current entries: %9d %.2f%%\n",
+                          entryCount, (100.0 * entryCount / entryLimit));
+    }
+
+    storeAppendPrintf(&e, "Maximum slots:   %9d\n", slotLimit);
+    if (map && slotLimit > 0) {
+        const unsigned int slotsFree = !freeSlots ? 0 : freeSlots->size();
+        if (slotsFree <= static_cast<const unsigned int>(slotLimit)) {
+            const int usedSlots = slotLimit - static_cast<const int>(slotsFree);
+            storeAppendPrintf(&e, "Used slots:      %9d %.2f%%\n",
+                              usedSlots, (100.0 * usedSlots / slotLimit));
+        }
+        if (slotLimit < 100) { // XXX: otherwise too expensive to count
+            Ipc::ReadWriteLockStats stats;
+            map->updateStats(stats);
+            stats.dump(e);
         }
     }
 
@@ -984,13 +1007,10 @@ Rock::SwapDir::statfs(StoreEntry &e) const
 
 }
 
-const char *
+SBuf
 Rock::SwapDir::inodeMapPath() const
 {
-    static String inodesPath;
-    inodesPath = path;
-    inodesPath.append("_inodes");
-    return inodesPath.termedBuf();
+    return Ipc::Mem::Segment::Name(SBuf(path), "map");
 }
 
 const char *
@@ -1012,7 +1032,7 @@ void Rock::SwapDirRr::create()
     Must(mapOwners.empty() && freeSlotsOwners.empty());
     for (int i = 0; i < Config.cacheSwap.n_configured; ++i) {
         if (const Rock::SwapDir *const sd = dynamic_cast<Rock::SwapDir *>(INDEXSD(i))) {
-            const int64_t capacity = sd->entryLimitAllowed();
+            const int64_t capacity = sd->slotLimitActual();
 
             SwapDir::DirMap::Owner *const mapOwner =
                 SwapDir::DirMap::Init(sd->inodeMapPath(), capacity);
@@ -1021,8 +1041,7 @@ void Rock::SwapDirRr::create()
             // TODO: somehow remove pool id and counters from PageStack?
             Ipc::Mem::Owner<Ipc::Mem::PageStack> *const freeSlotsOwner =
                 shm_new(Ipc::Mem::PageStack)(sd->freeSlotsPath(),
-                                             i+1, capacity,
-                                             sizeof(DbCellHeader));
+                                             i+1, capacity, 0);
             freeSlotsOwners.push_back(freeSlotsOwner);
 
             // TODO: add method to initialize PageStack with no free pages
@@ -42,12 +42,14 @@ class SwapDir: public ::SwapDir, public IORequestor, public Ipc::StoreMapCleaner
     virtual void parse(int index, char *path);
 
     // temporary path to the shared memory map of first slots of cached entries
-    const char *inodeMapPath() const;
+    SBuf inodeMapPath() const;
     // temporary path to the shared memory stack of free slots
     const char *freeSlotsPath() const;
 
-    int64_t entryLimitHigh() const { return SwapFilenMax; } ///< Core limit
-    int64_t entryLimitAllowed() const;
+    int64_t entryLimitAbsolute() const { return SwapFilenMax+1; } ///< Core limit
+    int64_t entryLimitActual() const; ///< max number of possible entries in db
+    int64_t slotLimitAbsolute() const; ///< Rock store implementation limit
+    int64_t slotLimitActual() const; ///< total number of slots in this db
 
     /// removes a slot from a list of free slots or returns false
     bool useFreeSlot(Ipc::Mem::PageId &pageId);
@@ -61,7 +63,7 @@ class SwapDir: public ::SwapDir, public IORequestor, public Ipc::StoreMapCleaner
     void writeError(StoreEntry &e);
 
     /* StoreMapCleaner API */
-    virtual void noteFreeMapSlice(const sfileno fileno);
+    virtual void noteFreeMapSlice(const Ipc::StoreMapSliceId fileno);
 
     uint64_t slotSize; ///< all db slots are of this size
 
@@ -108,9 +110,6 @@ class SwapDir: public ::SwapDir, public IORequestor, public Ipc::StoreMapCleaner
     void ignoreReferences(StoreEntry &e); ///< delete from repl policy scope
 
     int64_t diskOffsetLimit() const;
-    int entryLimit() const { return map->entryLimit(); }
-    int entryMaxPayloadSize() const;
-    int entriesNeeded(const int64_t objSize) const;
 
     void anchorEntry(StoreEntry &e, const sfileno filen, const Ipc::StoreMapAnchor &anchor);
     bool updateCollapsedWith(StoreEntry &collapsed, const Ipc::StoreMapAnchor &anchor);
@@ -33,6 +33,8 @@
 #include "squid.h"
 #include "acl/FilledChecklist.h"
 #include "comm.h"
+#include "comm/ConnOpener.h"
+#include "comm/Read.h"
 #include "comm/TcpAcceptor.h"
 #include "CommCalls.h"
 #include "compat/strtoll.h"
@@ -67,9 +69,7 @@
 #include "MemObject.h"
 #endif
 
-#if HAVE_ERRNO_H
-#include <errno.h>
-#endif
+#include <cerrno>
 
 /**
  \defgroup ServerProtocolFTPInternal Server-Side FTP Internals
@@ -177,7 +177,7 @@ class FtpStateData : public Ftp::ServerStateData
     void setCurrentOffset(int64_t offset) { currentOffset = offset; }
     int64_t getCurrentOffset() const { return currentOffset; }
 
-    virtual void dataChannelConnected(const Comm::ConnectionPointer &conn, comm_err_t err, int xerrno);
+    virtual void dataChannelConnected(const Comm::ConnectionPointer &conn, Comm::Flag err, int xerrno);
     static PF ftpDataWrite;
     virtual void timeout(const CommTimeoutCbParams &io);
     void ftpAcceptDataConnection(const CommAcceptCbParams &io);
@@ -481,6 +481,9 @@ FtpStateData::listenForDataChannel(const Comm::ConnectionPointer &conn)
         debugs(9, 3, HERE << "Unconnected data socket created on " << conn);
     }
 
+    conn->tos = ctrl.conn->tos;
+    conn->nfmark = ctrl.conn->nfmark;
+
     assert(Comm::IsConnOpen(conn));
     AsyncJob::Start(new Comm::TcpAcceptor(conn, note, sub));
 
@@ -1826,16 +1829,16 @@ ftpReadPasv(FtpStateData * ftpState)
 }
 
 void
-FtpStateData::dataChannelConnected(const Comm::ConnectionPointer &conn, comm_err_t err, int xerrno)
+FtpStateData::dataChannelConnected(const Comm::ConnectionPointer &conn, Comm::Flag err, int xerrno)
 {
     debugs(9, 3, HERE);
     data.opener = NULL;
 
-    if (err != COMM_OK) {
+    if (err != Comm::OK) {
         debugs(9, 2, HERE << "Failed to connect. Retrying via another method.");
 
         // ABORT on timeouts. server may be waiting on a broken TCP link.
-        if (err == COMM_TIMEOUT)
+        if (err == Comm::TIMEOUT)
             writeCommand("ABOR");
 
         // try another connection attempt with some other method
@@ -2023,7 +2026,7 @@ FtpStateData::ftpAcceptDataConnection(const CommAcceptCbParams &io)
         return;
     }
 
-    if (io.flag != COMM_OK) {
+    if (io.flag != Comm::OK) {
         data.listenConn->close();
         data.listenConn = NULL;
         debugs(9, DBG_IMPORTANT, "FTP AcceptDataConnection: " << io.conn << ": " << xstrerr(io.xerrno));
@@ -2066,7 +2069,7 @@ FtpStateData::ftpAcceptDataConnection(const CommAcceptCbParams &io)
         }
     }
 
-    /** On COMM_OK start using the accepted data socket and discard the temporary listen socket. */
+    /** On Comm::OK start using the accepted data socket and discard the temporary listen socket. */
     data.close();
     data.opened(io.conn, dataCloser());
     data.addr(io.conn->remote);
@@ -36,6 +36,7 @@
 #include "hash.h"
 #include "IoStats.h"
 #include "rfc2181.h"
+#include "SBuf.h"
 
 extern char *ConfigFile;	/* NULL */
 extern char *IcpOpcodeStr[];
@@ -52,7 +53,6 @@ extern const char *null_string;	/* "" */
 extern const char *version_string;	/* VERSION */
 extern const char *appname_string;	/* PACKAGE */
 extern char const *visible_appname_string; /* NULL */
-extern char *service_name;        /* xstrdup(APP_SHORTNAME) */
 extern const char *fdTypeStr[];
 extern const char *hier_strings[];
 extern const char *memStatusStr[];
@@ -108,7 +108,7 @@ extern const char *SwapDirType[];
 extern int store_swap_low;	/* 0 */
 extern int store_swap_high;	/* 0 */
 extern size_t store_pages_max;	/* 0 */
-extern int64_t store_maxobjsize;	/* -1 */
+extern int64_t store_maxobjsize;	/* 0 */
 extern hash_table *proxy_auth_username_cache;	/* NULL */
 extern int incoming_sockets_accepted;
 #if _SQUID_WINDOWS_
@@ -31,6 +31,7 @@
 
 #include "squid.h"
 #include "comm.h"
+#include "comm/Read.h"
 #include "comm/Write.h"
 #include "errorpage.h"
 #include "fd.h"
@@ -738,7 +739,7 @@ gopherTimeout(const CommTimeoutCbParams &io)
  * Read until error or connection closed.
  */
 static void
-gopherReadReply(const Comm::ConnectionPointer &conn, char *buf, size_t len, comm_err_t flag, int xerrno, void *data)
+gopherReadReply(const Comm::ConnectionPointer &conn, char *buf, size_t len, Comm::Flag flag, int xerrno, void *data)
 {
     GopherStateData *gopherState = (GopherStateData *)data;
     StoreEntry *entry = gopherState->entry;
@@ -749,9 +750,9 @@ gopherReadReply(const Comm::ConnectionPointer &conn, char *buf, size_t len, comm
     DelayId delayId = entry->mem_obj->mostBytesAllowed();
 #endif
 
-    /* Bail out early on COMM_ERR_CLOSING - close handlers will tidy up for us */
+    /* Bail out early on Comm::ERR_CLOSING - close handlers will tidy up for us */
 
-    if (flag == COMM_ERR_CLOSING) {
+    if (flag == Comm::ERR_CLOSING) {
         return;
     }
 
@@ -768,7 +769,7 @@ gopherReadReply(const Comm::ConnectionPointer &conn, char *buf, size_t len, comm
 
     /* leave one space for \0 in gopherToHTML */
 
-    if (flag == COMM_OK && len > 0) {
+    if (flag == Comm::OK && len > 0) {
 #if USE_DELAY_POOLS
         delayId.bytesIn(len);
 #endif
@@ -779,7 +780,7 @@ gopherReadReply(const Comm::ConnectionPointer &conn, char *buf, size_t len, comm
 
     debugs(10, 5, HERE << conn << " read len=" << len);
 
-    if (flag == COMM_OK && len > 0) {
+    if (flag == Comm::OK && len > 0) {
         AsyncCall::Pointer nil;
         commSetConnTimeout(conn, Config.Timeout.read, nil);
         ++IOStats.Gopher.reads;
@@ -796,7 +797,7 @@ gopherReadReply(const Comm::ConnectionPointer &conn, char *buf, size_t len, comm
         req->hier.bodyBytesRead += len;
     }
 
-    if (flag != COMM_OK) {
+    if (flag != Comm::OK) {
         debugs(50, DBG_IMPORTANT, "gopherReadReply: error reading: " << xstrerror());
 
         if (ignoreErrno(xerrno)) {
@@ -840,7 +841,7 @@ gopherReadReply(const Comm::ConnectionPointer &conn, char *buf, size_t len, comm
  * This will be called when request write is complete. Schedule read of reply.
  */
 static void
-gopherSendComplete(const Comm::ConnectionPointer &conn, char *buf, size_t size, comm_err_t errflag, int xerrno, void *data)
+gopherSendComplete(const Comm::ConnectionPointer &conn, char *buf, size_t size, Comm::Flag errflag, int xerrno, void *data)
 {
     GopherStateData *gopherState = (GopherStateData *) data;
     StoreEntry *entry = gopherState->entry;
@@ -34,6 +34,7 @@
 #include "base/AsyncCbdataCalls.h"
 #include "comm.h"
 #include "comm/Connection.h"
+#include "comm/Read.h"
 #include "comm/Write.h"
 #include "fd.h"
 #include "fde.h"
@@ -886,24 +887,24 @@ helperReturnBuffer(int request_number, helper_server * srv, helper * hlp, char *
 }
 
 static void
-helperHandleRead(const Comm::ConnectionPointer &conn, char *buf, size_t len, comm_err_t flag, int xerrno, void *data)
+helperHandleRead(const Comm::ConnectionPointer &conn, char *buf, size_t len, Comm::Flag flag, int xerrno, void *data)
 {
     char *t = NULL;
     helper_server *srv = (helper_server *)data;
     helper *hlp = srv->parent;
     assert(cbdataReferenceValid(data));
 
-    /* Bail out early on COMM_ERR_CLOSING - close handlers will tidy up for us */
+    /* Bail out early on Comm::ERR_CLOSING - close handlers will tidy up for us */
 
-    if (flag == COMM_ERR_CLOSING) {
+    if (flag == Comm::ERR_CLOSING) {
         return;
     }
 
     assert(conn->fd == srv->readPipe->fd);
 
     debugs(84, 5, "helperHandleRead: " << len << " bytes from " << hlp->id_name << " #" << srv->index);
 
-    if (flag != COMM_OK || len == 0) {
+    if (flag != Comm::OK || len == 0) {
         srv->closePipesSafely();
         return;
     }
@@ -980,17 +981,17 @@ helperHandleRead(const Comm::ConnectionPointer &conn, char *buf, size_t len, com
 }
 
 static void
-helperStatefulHandleRead(const Comm::ConnectionPointer &conn, char *buf, size_t len, comm_err_t flag, int xerrno, void *data)
+helperStatefulHandleRead(const Comm::ConnectionPointer &conn, char *buf, size_t len, Comm::Flag flag, int xerrno, void *data)
 {
     char *t = NULL;
     helper_stateful_server *srv = (helper_stateful_server *)data;
     helper_stateful_request *r;
     statefulhelper *hlp = srv->parent;
     assert(cbdataReferenceValid(data));
 
-    /* Bail out early on COMM_ERR_CLOSING - close handlers will tidy up for us */
+    /* Bail out early on Comm::ERR_CLOSING - close handlers will tidy up for us */
 
-    if (flag == COMM_ERR_CLOSING) {
+    if (flag == Comm::ERR_CLOSING) {
         return;
     }
 
@@ -999,7 +1000,7 @@ helperStatefulHandleRead(const Comm::ConnectionPointer &conn, char *buf, size_t
     debugs(84, 5, "helperStatefulHandleRead: " << len << " bytes from " <<
            hlp->id_name << " #" << srv->index);
 
-    if (flag != COMM_OK || len == 0) {
+    if (flag != Comm::OK || len == 0) {
         srv->closePipesSafely();
         return;
     }
@@ -1278,7 +1279,7 @@ StatefulGetFirstAvailable(statefulhelper * hlp)
 }
 
 static void
-helperDispatchWriteDone(const Comm::ConnectionPointer &conn, char *buf, size_t len, comm_err_t flag, int xerrno, void *data)
+helperDispatchWriteDone(const Comm::ConnectionPointer &conn, char *buf, size_t len, Comm::Flag flag, int xerrno, void *data)
 {
     helper_server *srv = (helper_server *)data;
 
@@ -1287,7 +1288,7 @@ helperDispatchWriteDone(const Comm::ConnectionPointer &conn, char *buf, size_t l
     srv->writebuf = NULL;
     srv->flags.writing = false;
 
-    if (flag != COMM_OK) {
+    if (flag != Comm::OK) {
         /* Helper server has crashed */
         debugs(84, DBG_CRITICAL, "helperDispatch: Helper " << srv->parent->id_name << " #" << srv->index << " has crashed");
         return;
@@ -1353,7 +1354,7 @@ helperDispatch(helper_server * srv, helper_request * r)
 }
 
 static void
-helperStatefulDispatchWriteDone(const Comm::ConnectionPointer &conn, char *buf, size_t len, comm_err_t flag,
+helperStatefulDispatchWriteDone(const Comm::ConnectionPointer &conn, char *buf, size_t len, Comm::Flag flag,
                                 int xerrno, void *data)
 {
     /* nothing! */
@@ -1127,7 +1127,7 @@ HttpStateData::persistentConnStatus() const
  */
 /*
 void
-HttpStateData::ReadReplyWrapper(int fd, char *buf, size_t len, comm_err_t flag, int xerrno, void *data)
+HttpStateData::ReadReplyWrapper(int fd, char *buf, size_t len, Comm::Flag flag, int xerrno, void *data)
 {
     HttpStateData *httpState = static_cast<HttpStateData *>(data);
     assert (fd == httpState->serverConnection->fd);
@@ -1150,8 +1150,8 @@ HttpStateData::readReply(const CommIoCbParams &io)
 
     debugs(11, 5, HERE << io.conn << ": len " << len << ".");
 
-    // Bail out early on COMM_ERR_CLOSING - close handlers will tidy up for us
-    if (io.flag == COMM_ERR_CLOSING) {
+    // Bail out early on Comm::ERR_CLOSING - close handlers will tidy up for us
+    if (io.flag == Comm::ERR_CLOSING) {
         debugs(11, 3, "http socket closing");
         return;
     }
@@ -1162,7 +1162,7 @@ HttpStateData::readReply(const CommIoCbParams &io)
     }
 
     // handle I/O errors
-    if (io.flag != COMM_OK || len < 0) {
+    if (io.flag != Comm::OK || len < 0) {
         debugs(11, 2, HERE << io.conn << ": read failure: " << xstrerror() << ".");
 
         if (ignoreErrno(io.xerrno)) {
@@ -1543,7 +1543,7 @@ HttpStateData::wroteLast(const CommIoCbParams &io)
         kb_incr(&(statCounter.server.http.kbytes_out), io.size);
     }
 
-    if (io.flag == COMM_ERR_CLOSING)
+    if (io.flag == Comm::ERR_CLOSING)
         return;
 
     if (io.flag) {
@@ -42,9 +42,7 @@
 #include "IcmpPinger.h"
 #include "SquidTime.h"
 
-#if HAVE_ERRNO_H
-#include <errno.h>
-#endif
+#include <cerrno>
 
 IcmpPinger::IcmpPinger() : Icmp()
 {
@@ -42,9 +42,7 @@
 #include "SquidIpc.h"
 #include "SquidTime.h"
 
-#if HAVE_ERRNO_H
-#include <errno.h>
-#endif
+#include <cerrno>
 
 // Instance global to be available in main() and elsewhere.
 IcmpSquid icmpEngine;
@@ -114,6 +114,7 @@ testIcmp_LDADD=\
 	$(SQUID_CPPUNIT_LA) \
 	libicmp-core.la \
 	../ip/libip.la \
+	../base/libbase.la \
 	$(COMPAT_LIB) \
 	$(XTRA_LIBS)
 testIcmp_DEPENDENCIES= $(SQUID_CPPUNIT_LA)
@@ -65,9 +65,7 @@
 #include "tools.h"
 #include "wordlist.h"
 
-#if HAVE_ERRNO_H
-#include <errno.h>
-#endif
+#include <cerrno>
 
 static void icpIncomingConnectionOpened(const Comm::ConnectionPointer &conn, int errNo);
 
@@ -35,6 +35,7 @@
 #include "comm.h"
 #include "comm/Connection.h"
 #include "comm/ConnOpener.h"
+#include "comm/Read.h"
 #include "comm/Write.h"
 #include "CommCalls.h"
 #include "globals.h"
@@ -118,14 +119,14 @@ Ident::Timeout(const CommTimeoutCbParams &io)
 }
 
 void
-Ident::ConnectDone(const Comm::ConnectionPointer &conn, comm_err_t status, int xerrno, void *data)
+Ident::ConnectDone(const Comm::ConnectionPointer &conn, Comm::Flag status, int xerrno, void *data)
 {
     IdentStateData *state = (IdentStateData *)data;
 
-    if (status != COMM_OK) {
-        if (status == COMM_TIMEOUT) {
+    if (status != Comm::OK) {
+        if (status == Comm::TIMEOUT)
             debugs(30, 3, "IDENT connection timeout to " << state->conn->remote);
-        }
+        Ident::identCallback(state, NULL);
         return;
     }
 
@@ -160,19 +161,19 @@ Ident::ConnectDone(const Comm::ConnectionPointer &conn, comm_err_t status, int x
 }
 
 void
-Ident::WriteFeedback(const Comm::ConnectionPointer &conn, char *buf, size_t len, comm_err_t flag, int xerrno, void *data)
+Ident::WriteFeedback(const Comm::ConnectionPointer &conn, char *buf, size_t len, Comm::Flag flag, int xerrno, void *data)
 {
     debugs(30, 5, HERE << conn << ": Wrote IDENT request " << len << " bytes.");
 
     // TODO handle write errors better. retry or abort?
-    if (flag != COMM_OK) {
+    if (flag != Comm::OK) {
         debugs(30, 2, HERE << conn << " err-flags=" << flag << " IDENT write error: " << xstrerr(xerrno));
         conn->close();
     }
 }
 
 void
-Ident::ReadReply(const Comm::ConnectionPointer &conn, char *buf, size_t len, comm_err_t flag, int xerrno, void *data)
+Ident::ReadReply(const Comm::ConnectionPointer &conn, char *buf, size_t len, Comm::Flag flag, int xerrno, void *data)
 {
     IdentStateData *state = (IdentStateData *)data;
     char *ident = NULL;
@@ -181,7 +182,7 @@ Ident::ReadReply(const Comm::ConnectionPointer &conn, char *buf, size_t len, com
     assert(buf == state->buf);
     assert(conn->fd == state->conn->fd);
 
-    if (flag != COMM_OK || len <= 0) {
+    if (flag != Comm::OK || len <= 0) {
         state->conn->close();
         return;
     }
@@ -15,6 +15,15 @@
 /* for inet_ntoa() */
 #include <arpa/inet.h>
 #endif
+#if HAVE_WS2TCPIP_H
+// Windows IPv6 definitions
+#include <ws2tcpip.h>
+#endif
+
+// some OS (ie WIndows) define IN6_ADDR_EQUAL instead
+#if !defined(IN6_ARE_ADDR_EQUAL) && _SQUID_WINDOWS_
+#define IN6_ARE_ADDR_EQUAL IN6_ADDR_EQUAL
+#endif
 
 /* Debugging only. Dump the address content when a fatal assert is encountered. */
 #define IASSERT(a,b)  \
@@ -29,7 +38,7 @@
 int
 Ip::Address::cidr() const
 {
-    uint8_t shift,byte;
+    uint8_t shift,ipbyte;
     uint8_t bit,caught;
     int len = 0;
     const uint8_t *ptr= mSocketAddr_.sin6_addr.s6_addr;
@@ -46,20 +55,20 @@ Ip::Address::cidr() const
     }
 
     for (; shift<sizeof(mSocketAddr_.sin6_addr) ; ++shift) {
-        byte= *(ptr+shift);
+        ipbyte= *(ptr+shift);
 
-        if (byte == 0xFF) {
+        if (ipbyte == 0xFF) {
             len += 8;
             continue ;  /* A short-cut */
         }
 
         for (caught = 0 , bit= 7 ; !caught && (bit <= 7); --bit) {
-            caught = ((byte & 0x80) == 0x00);  /* Found a '0' at 'bit' ? */
+            caught = ((ipbyte & 0x80) == 0x00);  /* Found a '0' at 'bit' ? */
 
             if (!caught)
                 ++len;
 
-            byte <<= 1;
+            ipbyte <<= 1;
         }
 
         if (caught)
@@ -36,6 +36,8 @@
 #include "ip/Intercept.h"
 #include "src/tools.h"
 
+#include <cerrno>
+
 #if IPF_TRANSPARENT
 
 #if HAVE_SYS_IOCTL_H
@@ -71,9 +73,6 @@
 #elif HAVE_NETINET_IP_NAT_H
 #include <netinet/ip_nat.h>
 #endif
-#if HAVE_ERRNO_H
-#include <errno.h>
-#endif
 
 #endif /* IPF_TRANSPARENT required headers */
 
@@ -28,6 +28,7 @@ nodist_testIpAddress_SOURCES= \
 	$(top_srcdir)/src/tests/testMain.cc
 testIpAddress_LDADD= \
 	libip.la \
+	../base/libbase.la \
 	$(XTRA_LIBS) \
 	$(COMPAT_LIB) \
 	$(SQUID_CPPUNIT_LA) \
@@ -3,34 +3,29 @@
 #include "Debug.h"
 
 int
-Ip::Qos::setSockTos(const Comm::ConnectionPointer &conn, tos_t tos)
+Ip::Qos::setSockTos(const int fd, tos_t tos, int type)
 {
     // Bug 3731: FreeBSD produces 'invalid option'
     // unless we pass it a 32-bit variable storing 8-bits of data.
     // NP: it is documented as 'int' for all systems, even those like Linux which accept 8-bit char
     //     so we convert to a int before setting.
     int bTos = tos;
 
-    if (conn->remote.isIPv4()) {
+    if (type == AF_INET) {
 #if defined(IP_TOS)
-        int x = setsockopt(conn->fd, IPPROTO_IP, IP_TOS, &bTos, sizeof(bTos));
+        const int x = setsockopt(fd, IPPROTO_IP, IP_TOS, &bTos, sizeof(bTos));
         if (x < 0)
-            debugs(50, 2, "Ip::Qos::setSockTos: setsockopt(IP_TOS) on " << conn << ": " << xstrerror());
-        else
-            conn->tos = tos;
+            debugs(50, 2, "Ip::Qos::setSockTos: setsockopt(IP_TOS) on " << fd << ": " << xstrerror());
         return x;
 #else
         debugs(50, DBG_IMPORTANT, "WARNING: setsockopt(IP_TOS) not supported on this platform");
         return -1;
 #endif
-
-    } else { // if (conn->remote.isIPv6()) {
+    } else { // type == AF_INET6
 #if defined(IPV6_TCLASS)
-        int x = setsockopt(conn->fd, IPPROTO_IPV6, IPV6_TCLASS, &bTos, sizeof(bTos));
+        const int x = setsockopt(fd, IPPROTO_IPV6, IPV6_TCLASS, &bTos, sizeof(bTos));
         if (x < 0)
-            debugs(50, 2, "Ip::Qos::setSockTos: setsockopt(IPV6_TCLASS) on " << conn << ": " << xstrerror());
-        else
-            conn->tos = tos;
+            debugs(50, 2, "Ip::Qos::setSockTos: setsockopt(IPV6_TCLASS) on " << fd << ": " << xstrerror());
         return x;
 #else
         debugs(50, DBG_IMPORTANT, "WARNING: setsockopt(IPV6_TCLASS) not supported on this platform");
@@ -42,14 +37,22 @@ Ip::Qos::setSockTos(const Comm::ConnectionPointer &conn, tos_t tos)
 }
 
 int
-Ip::Qos::setSockNfmark(const Comm::ConnectionPointer &conn, nfmark_t mark)
+Ip::Qos::setSockTos(const Comm::ConnectionPointer &conn, tos_t tos)
+{
+    const int x = Ip::Qos::setSockTos(conn->fd, tos, conn->remote.isIPv4() ? AF_INET : AF_INET6);
+    if (x >= 0)
+        conn->tos = tos;
+
+    return x;
+}
+
+int
+Ip::Qos::setSockNfmark(const int fd, nfmark_t mark)
 {
 #if SO_MARK && USE_LIBCAP
-    int x = setsockopt(conn->fd, SOL_SOCKET, SO_MARK, &mark, sizeof(nfmark_t));
+    const int x = setsockopt(fd, SOL_SOCKET, SO_MARK, &mark, sizeof(nfmark_t));
     if (x < 0)
-        debugs(50, 2, "setSockNfmark: setsockopt(SO_MARK) on " << conn << ": " << xstrerror());
-    else
-        conn->nfmark = mark;
+        debugs(50, 2, "setSockNfmark: setsockopt(SO_MARK) on " << fd << ": " << xstrerror());
     return x;
 #elif USE_LIBCAP
     debugs(50, DBG_IMPORTANT, "WARNING: setsockopt(SO_MARK) not supported on this platform");
@@ -60,6 +63,15 @@ Ip::Qos::setSockNfmark(const Comm::ConnectionPointer &conn, nfmark_t mark)
 #endif
 }
 
+int
+Ip::Qos::setSockNfmark(const Comm::ConnectionPointer &conn, nfmark_t mark)
+{
+    const int x = Ip::Qos::setSockNfmark(conn->fd, mark);
+    if (x >= 0)
+        conn->nfmark = mark;
+    return x;
+}
+
 bool
 Ip::Qos::Config::isHitTosActive() const
 {
@@ -11,11 +11,7 @@
 #include "ip/tools.h"
 #include "Parsing.h"
 
-#if HAVE_ERRNO_H
-#include <errno.h>
-#endif
-
-/* Qos namespace */
+#include <cerrno>
 
 void
 Ip::Qos::getTosFromServer(const Comm::ConnectionPointer &server, fde *clientFde)
@@ -122,13 +122,29 @@ int doNfmarkLocalHit(const Comm::ConnectionPointer &conn);
 */
 _SQUID_INLINE_ int setSockTos(const Comm::ConnectionPointer &conn, tos_t tos);
 
+/**
+* The low level variant of setSockTos function to set TOS value of packets.
+* Avoid if you can use the Connection-based setSockTos().
+* @param fd Descriptor of socket to set the TOS for
+* @param type The socket family, AF_INET or AF_INET6
+*/
+_SQUID_INLINE_ int setSockTos(const int fd, tos_t tos, int type);
+
 /**
 * Function to set the netfilter mark value of packets. Sets the value on the
 * socket which then gets copied to the packets. Called from Ip::Qos::doNfmarkLocalMiss
 * @param conn Descriptor of socket to set the mark for
 */
 _SQUID_INLINE_ int setSockNfmark(const Comm::ConnectionPointer &conn, nfmark_t mark);
 
+/**
+* The low level variant of setSockNfmark function to set the netfilter mark
+* value of packets.
+* Avoid if you can use the Connection-based setSockNfmark().
+* @param fd Descriptor of socket to set the mark for
+*/
+_SQUID_INLINE_ int setSockNfmark(const int fd, nfmark_t mark);
+
 /**
  * QOS configuration class. Contains all the parameters for QOS functions as well
  * as functions to check whether either TOS or MARK QOS is enabled.
@@ -19,6 +19,8 @@
 
 CPPUNIT_TEST_SUITE_REGISTRATION( testIpAddress );
 
+#include "tests/stub_SBuf.cc"
+
 /* so that we don't break POD dependency just for the test */
 struct timeval current_time;
 double current_dtime;
@@ -262,7 +262,7 @@ ipcCreate(int type, const char *prog, const char *const args[], const char *name
         cwfd = crfd = -1;
 
         if (type == IPC_TCP_SOCKET || type == IPC_UDP_SOCKET) {
-            if (comm_connect_addr(pwfd, ChS) == COMM_ERROR)
+            if (comm_connect_addr(pwfd, ChS) == Comm::COMM_ERROR)
                 return ipcCloseAllFD(prfd, pwfd, crfd, cwfd);
         }
 
@@ -334,7 +334,7 @@ ipcCreate(int type, const char *prog, const char *const args[], const char *name
         close(crfd);
         cwfd = crfd = fd;
     } else if (type == IPC_UDP_SOCKET) {
-        if (comm_connect_addr(crfd, PaS) == COMM_ERROR)
+        if (comm_connect_addr(crfd, PaS) == Comm::COMM_ERROR)
             return ipcCloseAllFD(prfd, pwfd, crfd, cwfd);
     }
 
@@ -20,9 +20,8 @@
 #include "snmp/Request.h"
 #include "snmp/Response.h"
 #endif
-#if HAVE_ERRNO_H
-#include <errno.h>
-#endif
+
+#include <cerrno>
 
 CBDATA_NAMESPACED_CLASS_INIT(Ipc, Coordinator);
 Ipc::Coordinator* Ipc::Coordinator::TheInstance = NULL;
@@ -6,9 +6,10 @@
 #include "squid.h"
 #include "comm.h"
 #include "comm/Connection.h"
+#include "comm/Read.h"
 #include "CommCalls.h"
-#include "globals.h"
 #include "ipc/Port.h"
+#include "tools.h"
 
 static const char channelPathPfx[] = DEFAULT_STATEDIR "/";
 static const char coordinatorAddrLabel[] = "-coordinator";
@@ -45,7 +46,7 @@ String Ipc::Port::MakeAddr(const char* processLabel, int id)
 {
     assert(id >= 0);
     String addr = channelPathPfx;
-    addr.append(service_name);
+    addr.append(service_name.c_str());
     addr.append(processLabel);
     addr.append('-');
     addr.append(xitoa(id));
@@ -59,7 +60,7 @@ Ipc::Port::CoordinatorAddr()
     static String coordinatorAddr;
     if (!coordinatorAddr.size()) {
         coordinatorAddr= channelPathPfx;
-        coordinatorAddr.append(service_name);
+        coordinatorAddr.append(service_name.c_str());
         coordinatorAddr.append(coordinatorAddrLabel);
         coordinatorAddr.append(".ipc");
     }
@@ -70,7 +71,7 @@ void Ipc::Port::noteRead(const CommIoCbParams& params)
 {
     debugs(54, 6, HERE << params.conn << " flag " << params.flag <<
            " [" << this << ']');
-    if (params.flag == COMM_OK) {
+    if (params.flag == Comm::OK) {
         assert(params.buf == buf.raw());
         receive(buf);
     }
@@ -11,9 +11,7 @@
 #include "ipc/StartListening.h"
 #include "tools.h"
 
-#if HAVE_ERRNO_H
-#include <errno.h>
-#endif
+#include <cerrno>
 
 Ipc::StartListeningCb::StartListeningCb(): conn(NULL), errNo(0)
 {
@@ -4,38 +4,49 @@
 
 #include "squid.h"
 #include "ipc/StoreMap.h"
+#include "SBuf.h"
 #include "Store.h"
 #include "store_key_md5.h"
 #include "tools.h"
 
-Ipc::StoreMap::Owner *
-Ipc::StoreMap::Init(const char *const path, const int limit, const size_t extrasSize)
+static SBuf
+StoreMapSlicesId(const SBuf &path)
 {
-    assert(limit > 0); // we should not be created otherwise
-    Owner *const owner = shm_new(Shared)(path, limit, extrasSize);
-    debugs(54, 5, HERE << "new map [" << path << "] created: " << limit);
-    return owner;
+    return Ipc::Mem::Segment::Name(path, "slices");
 }
 
-Ipc::StoreMap::Owner *
-Ipc::StoreMap::Init(const char *const path, const int limit)
+static SBuf
+StoreMapAnchorsId(const SBuf &path)
 {
-    return Init(path, limit, 0);
+    return Ipc::Mem::Segment::Name(path, "anchors");
 }
 
-Ipc::StoreMap::StoreMap(const char *const aPath): cleaner(NULL), path(aPath),
-        shared(shm_old(Shared)(aPath))
+Ipc::StoreMap::Owner *
+Ipc::StoreMap::Init(const SBuf &path, const int sliceLimit)
+{
+    assert(sliceLimit > 0); // we should not be created otherwise
+    const int anchorLimit = min(sliceLimit, static_cast<int>(SwapFilenMax));
+    Owner *owner = new Owner;
+    owner->anchors = shm_new(Anchors)(StoreMapAnchorsId(path).c_str(), anchorLimit);
+    owner->slices = shm_new(Slices)(StoreMapSlicesId(path).c_str(), sliceLimit);
+    debugs(54, 5, "created " << path << " with " << anchorLimit << '+' << sliceLimit);
+    return owner;
+}
+
+Ipc::StoreMap::StoreMap(const SBuf &aPath): cleaner(NULL), path(aPath),
+        anchors(shm_old(Anchors)(StoreMapAnchorsId(path).c_str())),
+        slices(shm_old(Slices)(StoreMapSlicesId(path).c_str()))
 {
-    assert(shared->limit > 0); // we should not be created otherwise
-    debugs(54, 5, HERE << "attached map [" << path << "] created: " <<
-           shared->limit);
+    debugs(54, 5, "attached " << path << " with " <<
+           anchors->capacity << '+' << slices->capacity);
+    assert(entryLimit() > 0); // key-to-position mapping requires this
+    assert(entryLimit() <= sliceLimit()); // at least one slice per entry
 }
 
 int
 Ipc::StoreMap::compareVersions(const sfileno fileno, time_t newVersion) const
 {
-    assert(valid(fileno));
-    Anchor &inode = shared->slots[fileno].anchor;
+    const Anchor &inode = anchorAt(fileno);
 
     // note: we do not lock, so comparison may be inacurate
 
@@ -51,8 +62,7 @@ Ipc::StoreMap::compareVersions(const sfileno fileno, time_t newVersion) const
 void
 Ipc::StoreMap::forgetWritingEntry(sfileno fileno)
 {
-    assert(valid(fileno));
-    Anchor &inode = shared->slots[fileno].anchor;
+    Anchor &inode = anchorAt(fileno);
 
     assert(inode.writing());
 
@@ -64,7 +74,7 @@ Ipc::StoreMap::forgetWritingEntry(sfileno fileno)
     inode.rewind();
 
     inode.lock.unlockExclusive();
-    --shared->count;
+    --anchors->count;
 
     debugs(54, 8, "closed entry " << fileno << " for writing " << path);
 }
@@ -87,7 +97,7 @@ Ipc::StoreMap::openForWriting(const cache_key *const key, sfileno &fileno)
 Ipc::StoreMap::Anchor *
 Ipc::StoreMap::openForWritingAt(const sfileno fileno, bool overwriteExisting)
 {
-    Anchor &s = shared->slots[fileno].anchor;
+    Anchor &s = anchorAt(fileno);
     ReadWriteLock &lock = s.lock;
 
     if (lock.lockExclusive()) {
@@ -107,7 +117,7 @@ Ipc::StoreMap::openForWritingAt(const sfileno fileno, bool overwriteExisting)
 
         assert(s.empty());
         s.start = -1; // we have not allocated any slices yet
-        ++shared->count;
+        ++anchors->count;
 
         //s.setKey(key); // XXX: the caller should do that
         debugs(54, 5, "opened entry " << fileno << " for writing " << path);
@@ -122,8 +132,7 @@ Ipc::StoreMap::openForWritingAt(const sfileno fileno, bool overwriteExisting)
 void
 Ipc::StoreMap::startAppending(const sfileno fileno)
 {
-    assert(valid(fileno));
-    Anchor &s = shared->slots[fileno].anchor;
+    Anchor &s = anchorAt(fileno);
     assert(s.writing());
     s.lock.startAppending();
     debugs(54, 5, "restricted entry " << fileno << " to appending " << path);
@@ -132,8 +141,7 @@ Ipc::StoreMap::startAppending(const sfileno fileno)
 void
 Ipc::StoreMap::closeForWriting(const sfileno fileno, bool lockForReading)
 {
-    assert(valid(fileno));
-    Anchor &s = shared->slots[fileno].anchor;
+    Anchor &s = anchorAt(fileno);
     assert(s.writing());
     if (lockForReading) {
         s.lock.switchExclusiveToShared();
@@ -150,43 +158,38 @@ Ipc::StoreMap::closeForWriting(const sfileno fileno, bool lockForReading)
 Ipc::StoreMap::Slice &
 Ipc::StoreMap::writeableSlice(const AnchorId anchorId, const SliceId sliceId)
 {
-    assert(valid(anchorId));
-    assert(shared->slots[anchorId].anchor.writing());
-    assert(valid(sliceId));
-    return shared->slots[sliceId].slice;
+    assert(anchorAt(anchorId).writing());
+    assert(validSlice(sliceId));
+    return sliceAt(sliceId);
 }
 
 const Ipc::StoreMap::Slice &
 Ipc::StoreMap::readableSlice(const AnchorId anchorId, const SliceId sliceId) const
 {
-    assert(valid(anchorId));
-    assert(shared->slots[anchorId].anchor.reading());
-    assert(valid(sliceId));
-    return shared->slots[sliceId].slice;
+    assert(anchorAt(anchorId).reading());
+    assert(validSlice(sliceId));
+    return sliceAt(sliceId);
 }
 
 Ipc::StoreMap::Anchor &
 Ipc::StoreMap::writeableEntry(const AnchorId anchorId)
 {
-    assert(valid(anchorId));
-    assert(shared->slots[anchorId].anchor.writing());
-    return shared->slots[anchorId].anchor;
+    assert(anchorAt(anchorId).writing());
+    return anchorAt(anchorId);
 }
 
 const Ipc::StoreMap::Anchor &
 Ipc::StoreMap::readableEntry(const AnchorId anchorId) const
 {
-    assert(valid(anchorId));
-    assert(shared->slots[anchorId].anchor.reading());
-    return shared->slots[anchorId].anchor;
+    assert(anchorAt(anchorId).reading());
+    return anchorAt(anchorId);
 }
 
 void
 Ipc::StoreMap::abortWriting(const sfileno fileno)
 {
     debugs(54, 5, "aborting entry " << fileno << " for writing " << path);
-    assert(valid(fileno));
-    Anchor &s = shared->slots[fileno].anchor;
+    Anchor &s = anchorAt(fileno);
     assert(s.writing());
     s.lock.appending = false; // locks out any new readers
     if (!s.lock.readers) {
@@ -202,8 +205,7 @@ Ipc::StoreMap::abortWriting(const sfileno fileno)
 const Ipc::StoreMap::Anchor *
 Ipc::StoreMap::peekAtReader(const sfileno fileno) const
 {
-    assert(valid(fileno));
-    const Anchor &s = shared->slots[fileno].anchor;
+    const Anchor &s = anchorAt(fileno);
     if (s.reading())
         return &s; // immediate access by lock holder so no locking
     if (s.writing())
@@ -215,17 +217,15 @@ Ipc::StoreMap::peekAtReader(const sfileno fileno) const
 const Ipc::StoreMap::Anchor &
 Ipc::StoreMap::peekAtEntry(const sfileno fileno) const
 {
-    assert(valid(fileno));
-    return shared->slots[fileno].anchor;
+    return anchorAt(fileno);
 }
 
 void
 Ipc::StoreMap::freeEntry(const sfileno fileno)
 {
     debugs(54, 5, "marking entry " << fileno << " to be freed in " << path);
 
-    assert(valid(fileno));
-    Anchor &s = shared->slots[fileno].anchor;
+    Anchor &s = anchorAt(fileno);
 
     if (s.lock.lockExclusive())
         freeChain(fileno, s, false);
@@ -240,7 +240,7 @@ Ipc::StoreMap::freeEntryByKey(const cache_key *const key)
            << " to be freed in " << path);
 
     const int idx = anchorIndexByKey(key);
-    Anchor &s = shared->slots[idx].anchor;
+    Anchor &s = anchorAt(idx);
     if (s.lock.lockExclusive()) {
         if (s.sameKey(key))
             freeChain(idx, s, true);
@@ -267,7 +267,7 @@ Ipc::StoreMap::freeChain(const sfileno fileno, Anchor &inode, const bool keepLoc
         sfileno sliceId = inode.start;
         debugs(54, 8, "first slice " << sliceId);
         while (sliceId >= 0) {
-            Slice &slice = shared->slots[sliceId].slice;
+            Slice &slice = sliceAt(sliceId);
             const sfileno nextId = slice.next;
             slice.size = 0;
             slice.next = -1;
@@ -282,7 +282,7 @@ Ipc::StoreMap::freeChain(const sfileno fileno, Anchor &inode, const bool keepLoc
 
     if (!keepLocked)
         inode.lock.unlockExclusive();
-    --shared->count;
+    --anchors->count;
     debugs(54, 5, "freed entry " << fileno << " in " << path);
 }
 
@@ -307,8 +307,7 @@ const Ipc::StoreMap::Anchor *
 Ipc::StoreMap::openForReadingAt(const sfileno fileno)
 {
     debugs(54, 5, "opening entry " << fileno << " for reading " << path);
-    assert(valid(fileno));
-    Anchor &s = shared->slots[fileno].anchor;
+    Anchor &s = anchorAt(fileno);
 
     if (!s.lock.lockShared()) {
         debugs(54, 5, "cannot open busy entry " << fileno <<
@@ -337,8 +336,7 @@ Ipc::StoreMap::openForReadingAt(const sfileno fileno)
 void
 Ipc::StoreMap::closeForReading(const sfileno fileno)
 {
-    assert(valid(fileno));
-    Anchor &s = shared->slots[fileno].anchor;
+    Anchor &s = anchorAt(fileno);
     assert(s.reading());
     s.lock.unlockShared();
     debugs(54, 5, "closed entry " << fileno << " for reading " << path);
@@ -352,9 +350,8 @@ Ipc::StoreMap::purgeOne()
     const int searchLimit = min(10000, entryLimit());
     int tries = 0;
     for (; tries < searchLimit; ++tries) {
-        const sfileno fileno = static_cast<sfileno>(++shared->victim % shared->limit);
-        assert(valid(fileno));
-        Anchor &s = shared->slots[fileno].anchor;
+        const sfileno fileno = static_cast<sfileno>(++anchors->victim % entryLimit());
+        Anchor &s = anchorAt(fileno);
         if (s.lock.lockExclusive()) {
             // the caller wants a free slice; empty anchor is not enough
             if (!s.empty() && s.start >= 0) {
@@ -377,47 +374,85 @@ Ipc::StoreMap::importSlice(const SliceId sliceId, const Slice &slice)
     // "get free slice" API. This is not something we can double check
     // reliably because the anchor for the imported slice may not have been
     // imported yet.
-    assert(valid(sliceId));
-    shared->slots[sliceId].slice = slice;
+    assert(validSlice(sliceId));
+    sliceAt(sliceId) = slice;
 }
 
 int
 Ipc::StoreMap::entryLimit() const
 {
-    return shared->limit;
+    return min(sliceLimit(), static_cast<int>(SwapFilenMax+1));
 }
 
 int
 Ipc::StoreMap::entryCount() const
 {
-    return shared->count;
+    return anchors->count;
+}
+
+int
+Ipc::StoreMap::sliceLimit() const
+{
+    return slices->capacity;
 }
 
 void
 Ipc::StoreMap::updateStats(ReadWriteLockStats &stats) const
 {
-    for (int i = 0; i < shared->limit; ++i)
-        shared->slots[i].anchor.lock.updateStats(stats);
+    for (int i = 0; i < anchors->capacity; ++i)
+        anchorAt(i).lock.updateStats(stats);
 }
 
 bool
-Ipc::StoreMap::valid(const int pos) const
+Ipc::StoreMap::validEntry(const int pos) const
 {
     return 0 <= pos && pos < entryLimit();
 }
 
+bool
+Ipc::StoreMap::validSlice(const int pos) const
+{
+    return 0 <= pos && pos < sliceLimit();
+}
+
+Ipc::StoreMap::Anchor&
+Ipc::StoreMap::anchorAt(const sfileno fileno)
+{
+    assert(validEntry(fileno));
+    return anchors->items[fileno];
+}
+
+const Ipc::StoreMap::Anchor&
+Ipc::StoreMap::anchorAt(const sfileno fileno) const
+{
+    return const_cast<StoreMap&>(*this).anchorAt(fileno);
+}
+
 sfileno
 Ipc::StoreMap::anchorIndexByKey(const cache_key *const key) const
 {
     const uint64_t *const k = reinterpret_cast<const uint64_t *>(key);
     // TODO: use a better hash function
-    return (k[0] + k[1]) % shared->limit;
+    return (k[0] + k[1]) % entryLimit();
 }
 
 Ipc::StoreMap::Anchor &
 Ipc::StoreMap::anchorByKey(const cache_key *const key)
 {
-    return shared->slots[anchorIndexByKey(key)].anchor;
+    return anchorAt(anchorIndexByKey(key));
+}
+
+Ipc::StoreMap::Slice&
+Ipc::StoreMap::sliceAt(const SliceId sliceId)
+{
+    assert(validSlice(sliceId));
+    return slices->items[sliceId];
+}
+
+const Ipc::StoreMap::Slice&
+Ipc::StoreMap::sliceAt(const SliceId sliceId) const
+{
+    return const_cast<StoreMap&>(*this).sliceAt(sliceId);
 }
 
 /* Ipc::StoreMapAnchor */
@@ -466,23 +501,35 @@ Ipc::StoreMapAnchor::rewind()
     // but keep the lock
 }
 
-/* Ipc::StoreMap::Shared */
+Ipc::StoreMap::Owner::Owner(): anchors(NULL), slices(NULL)
+{
+}
+
+Ipc::StoreMap::Owner::~Owner()
+{
+    delete anchors;
+    delete slices;
+}
+
+/* Ipc::StoreMapAnchors */
 
-Ipc::StoreMap::Shared::Shared(const int aLimit, const size_t anExtrasSize):
-        limit(aLimit), extrasSize(anExtrasSize), count(0), victim(0),
-        slots(aLimit)
+Ipc::StoreMapAnchors::StoreMapAnchors(const int aCapacity):
+        count(0),
+        victim(0),
+        capacity(aCapacity),
+        items(aCapacity)
 {
 }
 
 size_t
-Ipc::StoreMap::Shared::sharedMemorySize() const
+Ipc::StoreMapAnchors::sharedMemorySize() const
 {
-    return SharedMemorySize(limit, extrasSize);
+    return SharedMemorySize(capacity);
 }
 
 size_t
-Ipc::StoreMap::Shared::SharedMemorySize(const int limit, const size_t extrasSize)
+Ipc::StoreMapAnchors::SharedMemorySize(const int capacity)
 {
-    return sizeof(Shared) + limit * (sizeof(StoreMapSlot) + extrasSize);
+    return sizeof(StoreMapAnchors) + capacity * sizeof(StoreMapAnchor);
 }
 
@@ -4,6 +4,7 @@
 #include "ipc/mem/FlexibleArray.h"
 #include "ipc/mem/Pointer.h"
 #include "ipc/ReadWriteLock.h"
+#include "SBuf.h"
 #include "typedefs.h"
 
 namespace Ipc
@@ -70,62 +71,81 @@ class StoreMapAnchor
 
     /// where the chain of StoreEntry slices begins [app]
     Atomic::WordT<StoreMapSliceId> start;
+};
+
+/// an array of shareable Items
+/// must be the last data member or, if used as a parent class, the last parent
+template <class C>
+class StoreMapItems
+{
+public:
+    typedef C Item;
+    typedef Ipc::Mem::Owner< StoreMapItems<Item> > Owner;
+
+    explicit StoreMapItems(const int aCapacity): capacity(aCapacity), items(aCapacity) {}
 
-#if 0
-    /// possible persistent states
-    typedef enum {
-        Empty, ///< ready for writing, with nothing of value
-        Writeable, ///< transitions from Empty to Readable
-        Readable, ///< ready for reading
-    } State;
-    State state; ///< current state
-#endif
+    size_t sharedMemorySize() const { return SharedMemorySize(capacity); }
+    static size_t SharedMemorySize(const int aCapacity) { return sizeof(StoreMapItems<Item>) + aCapacity*sizeof(Item); }
+
+    const int capacity; ///< total number of items
+    Ipc::Mem::FlexibleArray<Item> items; ///< storage
 };
 
-/// A hack to allocate one shared array for both anchors and slices.
-/// Anchors are indexed by store entry ID and are independent from each other.
-/// Slices are indexed by slice IDs and form entry chains using slice.next.
-class StoreMapSlot
+/// StoreMapSlices indexed by their slice ID.
+typedef StoreMapItems<StoreMapSlice> StoreMapSlices;
+
+/// StoreMapAnchors indexed by entry fileno plus
+/// sharing-safe basic housekeeping info about Store entries
+class StoreMapAnchors
 {
 public:
-    StoreMapAnchor anchor; ///< information about store entry as a whole
-    StoreMapSlice slice; ///< information about one stored entry piece
+    typedef Ipc::Mem::Owner< StoreMapAnchors > Owner;
+
+    explicit StoreMapAnchors(const int aCapacity);
+
+    size_t sharedMemorySize() const;
+    static size_t SharedMemorySize(const int anAnchorLimit);
+
+    Atomic::Word count; ///< current number of entries
+    Atomic::WordT<uint32_t> victim; ///< starting point for purge search
+    const int capacity; ///< total number of anchors
+    Ipc::Mem::FlexibleArray<StoreMapAnchor> items; ///< anchors storage
 };
+// TODO: Find an elegant way to use StoreMapItems in StoreMapAnchors
 
 class StoreMapCleaner;
 
-/// map of StoreMapSlots indexed by their keys, with read/write slice locking
-/// kids extend to store custom data
+/// Manages shared Store index (e.g., locking/unlocking/freeing entries) using
+/// StoreMapAnchors indexed by their keys and
+/// StoreMapSlices indexed by their slide ID.
 class StoreMap
 {
 public:
     typedef StoreMapAnchor Anchor;
+    typedef StoreMapAnchors Anchors;
     typedef sfileno AnchorId;
     typedef StoreMapSlice Slice;
+    typedef StoreMapSlices Slices;
     typedef StoreMapSliceId SliceId;
 
-    /// data shared across maps in different processes
-    class Shared
+public:
+    /// aggregates anchor and slice owners for Init() caller convenience
+    class Owner
     {
     public:
-        Shared(const int aLimit, const size_t anExtrasSize);
-        size_t sharedMemorySize() const;
-        static size_t SharedMemorySize(const int limit, const size_t anExtrasSize);
-
-        const int limit; ///< maximum number of store entries
-        const size_t extrasSize; ///< size of slice extra data
-        Atomic::Word count; ///< current number of entries
-        Atomic::WordT<uint32_t> victim; ///< starting point for purge search
-        Ipc::Mem::FlexibleArray<StoreMapSlot> slots; ///< storage
+        Owner();
+        ~Owner();
+        Anchors::Owner *anchors;
+        Slices::Owner *slices;
+    private:
+        Owner(const Owner &); // not implemented
+        Owner &operator =(const Owner &); // not implemented
     };
 
-public:
-    typedef Mem::Owner<Shared> Owner;
-
     /// initialize shared memory
-    static Owner *Init(const char *const path, const int limit);
+    static Owner *Init(const SBuf &path, const int slotLimit);
 
-    StoreMap(const char *const aPath);
+    StoreMap(const SBuf &aPath);
 
     /// computes map entry position for a given entry key
     sfileno anchorIndexByKey(const cache_key *const key) const;
@@ -186,97 +206,45 @@ class StoreMap
     /// copies slice to its designated position
     void importSlice(const SliceId sliceId, const Slice &slice);
 
-    bool valid(const int n) const; ///< whether n is a valid slice coordinate
+    /* SwapFilenMax limits the number of entries, but not slices or slots */
+    bool validEntry(const int n) const; ///< whether n is a valid slice coordinate
+    bool validSlice(const int n) const; ///< whether n is a valid slice coordinate
     int entryCount() const; ///< number of writeable and readable entries
     int entryLimit() const; ///< maximum entryCount() possible
+    int sliceLimit() const; ///< maximum number of slices possible
 
     /// adds approximate current stats to the supplied ones
     void updateStats(ReadWriteLockStats &stats) const;
 
     StoreMapCleaner *cleaner; ///< notified before a readable entry is freed
 
 protected:
-    static Owner *Init(const char *const path, const int limit, const size_t extrasSize);
-
-    const String path; ///< cache_dir path or similar cache name; for logging
-    Mem::Pointer<Shared> shared;
+    const SBuf path; ///< cache_dir path or similar cache name; for logging
+    Mem::Pointer<StoreMapAnchors> anchors; ///< entry inodes (starting blocks)
+    Mem::Pointer<StoreMapSlices> slices; ///< chained entry pieces positions
 
 private:
+    Anchor &anchorAt(const sfileno fileno);
+    const Anchor &anchorAt(const sfileno fileno) const;
     Anchor &anchorByKey(const cache_key *const key);
 
+    Slice &sliceAt(const SliceId sliceId);
+    const Slice &sliceAt(const SliceId sliceId) const;
     Anchor *openForReading(Slice &s);
 
     void freeChain(const sfileno fileno, Anchor &inode, const bool keepLock);
 };
 
-/// StoreMap with extra slice data
-/// Note: ExtrasT must be POD, it is initialized with zeroes, no
-/// constructors or destructors are called
-template <class ExtrasT>
-class StoreMapWithExtras: public StoreMap
-{
-public:
-    typedef ExtrasT Extras;
-
-    /// initialize shared memory
-    static Owner *Init(const char *const path, const int limit);
-
-    StoreMapWithExtras(const char *const path);
-
-    /// write access to the extras; call openForWriting() first!
-    ExtrasT &extras(const sfileno fileno);
-    /// read-only access to the extras; call openForReading() first!
-    const ExtrasT &extras(const sfileno fileno) const;
-
-protected:
-
-    ExtrasT *sharedExtras; ///< pointer to extras in shared memory
-};
-
 /// API for adjusting external state when dirty map slice is being freed
 class StoreMapCleaner
 {
 public:
     virtual ~StoreMapCleaner() {}
 
     /// adjust slice-linked state before a locked Readable slice is erased
-    virtual void noteFreeMapSlice(const sfileno sliceId) = 0;
+    virtual void noteFreeMapSlice(const StoreMapSliceId sliceId) = 0;
 };
 
-// StoreMapWithExtras implementation
-
-template <class ExtrasT>
-StoreMap::Owner *
-StoreMapWithExtras<ExtrasT>::Init(const char *const path, const int limit)
-{
-    return StoreMap::Init(path, limit, sizeof(Extras));
-}
-
-template <class ExtrasT>
-StoreMapWithExtras<ExtrasT>::StoreMapWithExtras(const char *const aPath):
-        StoreMap(aPath)
-{
-    const size_t sharedSizeWithoutExtras =
-        Shared::SharedMemorySize(entryLimit(), 0);
-    sharedExtras = reinterpret_cast<Extras *>(reinterpret_cast<char *>(shared.getRaw()) + sharedSizeWithoutExtras);
-}
-
-template <class ExtrasT>
-ExtrasT &
-StoreMapWithExtras<ExtrasT>::extras(const sfileno fileno)
-{
-    return const_cast<ExtrasT &>(const_cast<const StoreMapWithExtras *>(this)->extras(fileno));
-}
-
-template <class ExtrasT>
-const ExtrasT &
-StoreMapWithExtras<ExtrasT>::extras(const sfileno fileno) const
-{
-    assert(sharedExtras);
-    assert(valid(fileno));
-    return sharedExtras[fileno];
-}
-
 } // namespace Ipc
 
 // We do not reuse FileMap because we cannot control its size,
@@ -123,7 +123,7 @@ void Ipc::UdsSender::wrote(const CommIoCbParams& params)
 {
     debugs(54, 5, HERE << params.conn << " flag " << params.flag << " retries " << retries << " [" << this << ']');
     writing = false;
-    if (params.flag != COMM_OK && retries-- > 0) {
+    if (params.flag != Comm::OK && retries-- > 0) {
         // perhaps a fresh connection and more time will help?
         conn()->close();
         startSleep();
@@ -9,6 +9,7 @@
 #include "Debug.h"
 #include "fatal.h"
 #include "ipc/mem/Segment.h"
+#include "SBuf.h"
 #include "tools.h"
 
 #include <fcntl.h>
@@ -33,6 +34,15 @@ Ipc::Mem::Segment::reserve(size_t chunkSize)
     return result;
 }
 
+SBuf
+Ipc::Mem::Segment::Name(const SBuf &prefix, const char *suffix)
+{
+    SBuf result = prefix;
+    result.append("_");
+    result.append(suffix);
+    return result;
+}
+
 #if HAVE_SHM
 
 Ipc::Mem::Segment::Segment(const char *const id):
@@ -7,6 +7,8 @@
 #include "base/RunnersRegistry.h"
 #include "SquidString.h"
 
+class SBuf;
+
 namespace Ipc
 {
 
@@ -36,6 +38,9 @@ class Segment
     /// common path of all segment names in path-based environments
     static const char *BasePath;
 
+    /// concatenates parts of a name to form a complete name (or its prefix)
+    static SBuf Name(const SBuf &prefix, const char *suffix);
+
 private:
 
     // not implemented
@@ -43,13 +43,11 @@
 #include "SquidTime.h"
 #include "tools.h"
 
+#include <cerrno>
 #ifndef _MSWSOCK_
 #include <mswsock.h>
 #endif
 #include <process.h>
-#if HAVE_ERRNO_H
-#include <errno.h>
-#endif
 
 struct ipc_params {
     int type;
@@ -265,7 +263,7 @@ ipcCreate(int type, const char *prog, const char *const args[], const char *name
     }
 
     /* NP: tmp_addr was left with eiether empty or aiCS in Ip::Address format */
-    if (comm_connect_addr(pwfd, tmp_addr) == COMM_ERROR) {
+    if (comm_connect_addr(pwfd, tmp_addr) == Comm::COMM_ERROR) {
         CloseHandle((HANDLE) thread);
         return ipcCloseAllFD(prfd, pwfd, -1, -1);
     }
@@ -427,7 +425,7 @@ ipc_thread_1(void *in_params)
         fd_table[fd].flags.ipc = 1;
         cwfd = crfd = fd;
     } else if (type == IPC_UDP_SOCKET) {
-        if (comm_connect_addr(crfd, params->PS) == COMM_ERROR)
+        if (comm_connect_addr(crfd, params->PS) == Comm::COMM_ERROR)
             goto cleanup;
     }
 
@@ -514,14 +512,14 @@ ipc_thread_1(void *in_params)
 
         debugs(54, 3, "ipcCreate: FD " << crfd_ipc << " sockaddr " << CS_ipc);
 
-        if (comm_connect_addr(pwfd_ipc, CS_ipc) == COMM_ERROR) {
+        if (comm_connect_addr(pwfd_ipc, CS_ipc) == Comm::COMM_ERROR) {
             ipcSend(cwfd, err_string, strlen(err_string));
             goto cleanup;
         }
 
         fd = crfd;
 
-        if (comm_connect_addr(crfd_ipc, PS_ipc) == COMM_ERROR) {
+        if (comm_connect_addr(crfd_ipc, PS_ipc) == Comm::COMM_ERROR) {
             ipcSend(cwfd, err_string, strlen(err_string));
             goto cleanup;
         }
@@ -42,9 +42,7 @@
 #include "SquidIpc.h"
 #include "SquidTime.h"
 
-#if HAVE_ERRNO_H
-#include <errno.h>
-#endif
+#include <cerrno>
 
 /* How many buffers to keep before we say we've buffered too much */
 #define	LOGFILE_MAXBUFS		128
@@ -39,9 +39,7 @@
 #include "log/ModStdio.h"
 #include "SquidConfig.h"
 
-#if HAVE_ERRNO_H
-#include <errno.h>
-#endif
+#include <cerrno>
 
 typedef struct {
     int fd;
@@ -40,9 +40,7 @@
 #include "Parsing.h"
 #include "SquidConfig.h"
 
-#if HAVE_ERRNO_H
-#include <errno.h>
-#endif
+#include <cerrno>
 
 /*
  * This logfile UDP module is mostly inspired by a patch by Tim Starling
@@ -58,7 +58,7 @@ Log::TcpLogger::~TcpLogger()
 void
 Log::TcpLogger::start()
 {
-    connect();
+    doConnect();
 }
 
 bool
@@ -231,7 +231,7 @@ Log::TcpLogger::appendChunk(const char *chunk, const size_t len)
 
 /// starts [re]connecting to the remote logger
 void
-Log::TcpLogger::connect()
+Log::TcpLogger::doConnect()
 {
     if (shutting_down)
         return;
@@ -254,7 +254,7 @@ Log::TcpLogger::connect()
 void
 Log::TcpLogger::connectDone(const CommConnectCbParams &params)
 {
-    if (params.flag != COMM_OK) {
+    if (params.flag != Comm::OK) {
         const double delay = 0.5; // seconds
         if (connectFailures++ % 100 == 0) {
             debugs(MY_DEBUG_SECTION, DBG_IMPORTANT, "tcp:" << remote <<
@@ -313,22 +313,22 @@ Log::TcpLogger::delayedReconnect()
     Must(reconnectScheduled);
     Must(!conn);
     reconnectScheduled = false;
-    connect();
+    doConnect();
 }
 
 /// Comm::Write callback
 void
 Log::TcpLogger::writeDone(const CommIoCbParams &io)
 {
     writeScheduled = false;
-    if (io.flag == COMM_ERR_CLOSING) {
+    if (io.flag == Comm::ERR_CLOSING) {
         debugs(MY_DEBUG_SECTION, 7, "closing");
         // do nothing here -- our comm_close_handler will be called to clean up
-    } else if (io.flag != COMM_OK) {
+    } else if (io.flag != Comm::OK) {
         debugs(MY_DEBUG_SECTION, 2, "write failure: " << xstrerr(io.xerrno));
         // keep the first buffer (the one we failed to write)
         disconnect();
-        connect();
+        doConnect();
     } else {
         debugs(MY_DEBUG_SECTION, 5, "write successful");
 
@@ -64,7 +64,7 @@ class TcpLogger : public AsyncJob
     void appendChunk(const char *chunk, const size_t len);
     void writeIfNeeded();
     void writeIfPossible();
-    void connect();
+    void doConnect();
     void disconnect();
 
     /* comm callbacks */
@@ -73,6 +73,7 @@
 #include "MemPool.h"
 #include "mime.h"
 #include "neighbors.h"
+#include "parser/Tokenizer.h"
 #include "pconn.h"
 #include "peer_sourcehash.h"
 #include "peer_userhash.h"
@@ -142,15 +143,13 @@
 #include "snmp_core.h"
 #endif
 
+#include <cerrno>
 #if HAVE_PATHS_H
 #include <paths.h>
 #endif
 #if HAVE_SYS_WAIT_H
 #include <sys/wait.h>
 #endif
-#if HAVE_ERRNO_H
-#include <errno.h>
-#endif
 
 #if USE_WIN32_SERVICE
 #include <process.h>
@@ -508,10 +507,18 @@ mainParseOptions(int argc, char *argv[])
             /** \par n
              * Set global option opt_signal_service (to true).
              * Stores the additional parameter given in global service_name */
-            // XXX: verify that the new name has ONLY alphanumeric characters
-            xfree(service_name);
-            service_name = xstrdup(optarg);
-            opt_signal_service = true;
+            if (optarg && *optarg != '\0') {
+                const SBuf t(optarg);
+                ::Parser::Tokenizer tok(t);
+                const CharacterSet chr = CharacterSet::ALPHA+CharacterSet::DIGIT;
+                if (!tok.prefix(service_name, chr) || !tok.atEnd())
+                    fatalf("Expected alphanumeric service name for the -n option but got: " SQUIDSBUFPH, SQUIDSBUFPRINT(service_name));
+                if (service_name.length() > 32)
+                    fatalf("Service name (-n option) must be limited to 32 characters but got %u", service_name.length());
+                opt_signal_service = true;
+            } else {
+                fatal("A service name is required for the -n option");
+            }
             break;
 
 #if USE_WIN32_SERVICE
@@ -563,7 +570,7 @@ mainParseOptions(int argc, char *argv[])
             /** \par v
              * Display squid version and build information. Then exit. */
             printf("Squid Cache: Version %s\n" ,version_string);
-            printf("Service Name: %s\n", service_name);
+            printf("Service Name: " SQUIDSBUFPH "\n", SQUIDSBUFPRINT(service_name));
             if (strlen(SQUID_BUILD_INFO))
                 printf("%s\n",SQUID_BUILD_INFO);
             printf( "configure options: %s\n", SQUID_CONFIGURE_OPTIONS);
@@ -104,7 +104,7 @@ Mgr::Inquirer::noteWroteHeader(const CommIoCbParams& params)
 {
     debugs(16, 5, HERE);
     writer = NULL;
-    Must(params.flag == COMM_OK);
+    Must(params.flag == Comm::OK);
     Must(params.conn.getRaw() == conn.getRaw());
     Must(params.size != 0);
     // start inquiries at the initial pos
@@ -112,7 +112,7 @@ void
 Mgr::StoreToCommWriter::noteCommWrote(const CommIoCbParams& params)
 {
     debugs(16, 6, HERE);
-    Must(params.flag == COMM_OK);
+    Must(params.flag == Comm::OK);
     Must(clientConnection != NULL && params.fd == clientConnection->fd);
     Must(params.size != 0);
     writeOffset += params.size;
@@ -583,7 +583,7 @@ neighbors_init(void)
             if (0 != strcmp(thisPeer->host, me))
                 continue;
 
-            for (AnyP::PortCfg *s = Config.Sockaddr.http; s; s = s->next) {
+            for (AnyP::PortCfgPointer s = HttpPortList; s != NULL; s = s->next) {
                 if (thisPeer->http_port != s->s.port())
                     continue;
 
@@ -1375,11 +1375,11 @@ peerProbeConnect(CachePeer * p)
 }
 
 static void
-peerProbeConnectDone(const Comm::ConnectionPointer &conn, comm_err_t status, int xerrno, void *data)
+peerProbeConnectDone(const Comm::ConnectionPointer &conn, Comm::Flag status, int xerrno, void *data)
 {
     CachePeer *p = (CachePeer*)data;
 
-    if (status == COMM_OK) {
+    if (status == Comm::OK) {
         peerConnectSucceded(p);
     } else {
         peerConnectFailedSilent(p);
@@ -0,0 +1,49 @@
+include $(top_srcdir)/src/Common.am
+include $(top_srcdir)/src/TestHeaders.am
+
+EXTRA_PROGRAMS = \
+	testTokenizer
+	
+check_PROGRAMS += testTokenizer
+TESTS += testTokenizer
+
+noinst_LTLIBRARIES = libsquid-parser.la
+
+libsquid_parser_la_SOURCES = \
+	Tokenizer.h \
+	Tokenizer.cc
+
+SBUF_SOURCE= \
+	$(top_srcdir)/src/base/CharacterSet.h \
+	$(top_srcdir)/src/SBuf.h \
+	$(top_srcdir)/src/SBuf.cc \
+	$(top_srcdir)/src/MemBlob.h \
+	$(top_srcdir)/src/MemBlob.cc \
+	$(top_srcdir)/src/OutOfBoundsException.h \
+	$(top_srcdir)/src/SBufExceptions.h \
+	$(top_srcdir)/src/SBufExceptions.cc \
+	$(top_srcdir)/src/String.cc \
+	$(top_srcdir)/src/SquidString.h \
+	$(top_srcdir)/src/base/TextException.h \
+	$(top_srcdir)/src/base/TextException.cc
+
+testTokenizer_SOURCES = \
+	$(SBUF_SOURCE) \
+	testTokenizer.h \
+	testTokenizer.cc \
+	Tokenizer.h
+nodist_testTokenizer_SOURCES = \
+	$(top_srcdir)/src/tests/testMain.cc \
+	$(top_srcdir)/src/tests/stub_mem.cc \
+	$(top_srcdir)/src/tests/stub_debug.cc \
+	$(top_srcdir)/src/tests/stub_time.cc \
+	$(top_srcdir)/src/tests/stub_SBufDetailedStats.cc
+testTokenizer_LDFLAGS = $(LIBADD_DL)
+testTokenizer_LDADD = \
+	libsquid-parser.la \
+	$(top_builddir)/lib/libmiscutil.la \
+	$(top_builddir)/src/base/libbase.la \
+	$(SQUID_CPPUNIT_LIBS) \
+	$(SQUID_CPPUNIT_LA) \
+	$(COMPAT_LIB)
+testTokenizer_DEPENDENCIES = $(SQUID_CPPUNIT_LA)
@@ -0,0 +1,161 @@
+#include "squid.h"
+#include "parser/Tokenizer.h"
+
+#include <cerrno>
+#if HAVE_CTYPE_H
+#include <ctype.h>
+#endif
+#if HAVE_STDINT_H
+#include <stdint.h>
+#endif
+#ifndef INT64_MIN
+/* Native 64 bit system without strtoll() */
+#if defined(LONG_MIN) && (SIZEOF_LONG == 8)
+#define INT64_MIN LONG_MIN
+#else
+/* 32 bit system */
+#define INT64_MIN       (-9223372036854775807LL-1LL)
+#endif
+#endif
+
+#ifndef INT64_MAX
+/* Native 64 bit system without strtoll() */
+#if defined(LONG_MAX) && (SIZEOF_LONG == 8)
+#define INT64_MAX LONG_MAX
+#else
+/* 32 bit system */
+#define INT64_MAX       9223372036854775807LL
+#endif
+#endif
+
+bool
+Parser::Tokenizer::token(SBuf &returnedToken, const CharacterSet &delimiters)
+{
+    const SBuf savebuf(buf_);
+    skip(delimiters);
+    const SBuf::size_type tokenLen = buf_.findFirstOf(delimiters); // not found = npos => consume to end
+    if (tokenLen == SBuf::npos && !delimiters['\0']) {
+        // no delimiter found, nor is NUL/EOS/npos acceptible as one
+        buf_ = savebuf;
+        return false;
+    }
+    const SBuf retval = buf_.consume(tokenLen);
+    skip(delimiters);
+    returnedToken = retval;
+    return true;
+}
+
+bool
+Parser::Tokenizer::prefix(SBuf &returnedToken, const CharacterSet &tokenChars, const SBuf::size_type limit)
+{
+    const SBuf::size_type prefixLen = buf_.substr(0,limit).findFirstNotOf(tokenChars);
+    if (prefixLen == 0)
+        return false;
+    returnedToken = buf_.consume(prefixLen);
+    return true;
+}
+
+bool
+Parser::Tokenizer::skip(const CharacterSet &tokenChars)
+{
+    const SBuf::size_type prefixLen = buf_.findFirstNotOf(tokenChars);
+    if (prefixLen == 0)
+        return false;
+    buf_.consume(prefixLen);
+    return true;
+}
+
+bool
+Parser::Tokenizer::skip(const SBuf &tokenToSkip)
+{
+    if (buf_.startsWith(tokenToSkip)) {
+        buf_.consume(tokenToSkip.length());
+        return true;
+    }
+    return false;
+}
+
+bool
+Parser::Tokenizer::skip(const char tokenChar)
+{
+    if (buf_[0] == tokenChar) {
+        buf_.consume(1);
+        return true;
+    }
+    return false;
+}
+
+/* reworked from compat/strtoll.c */
+bool
+Parser::Tokenizer::int64(int64_t & result, int base)
+{
+    if (buf_.isEmpty())
+        return false;
+
+    //fixme: account for buf_.size()
+    bool neg = false;
+    const char *s = buf_.rawContent();
+    const char *end = buf_.rawContent() + buf_.length();
+
+    if (*s == '-') {
+        neg = true;
+        ++s;
+    } else if (*s == '+') {
+        ++s;
+    }
+    if (s >= end) return false;
+    if (( base == 0 || base == 16) && *s == '0' && (s+1 <= end ) &&
+            tolower(*(s+1)) == 'x') {
+        s += 2;
+        base = 16;
+    }
+    if (base == 0) {
+        if ( *s == '0') {
+            base = 8;
+            ++s;
+        } else {
+            base = 10;
+        }
+    }
+    if (s >= end) return false;
+
+    uint64_t cutoff;
+
+    cutoff = neg ? -static_cast<uint64_t>(INT64_MIN) : INT64_MAX;
+    const int cutlim = cutoff % static_cast<int64_t>(base);
+    cutoff /= static_cast<uint64_t>(base);
+
+    int any = 0, c;
+    int64_t acc = 0;
+    for (c = *s++; s <= end; c = *s++) {
+        if (xisdigit(c)) {
+            c -= '0';
+        } else if (xisalpha(c)) {
+            c -= xisupper(c) ? 'A' - 10 : 'a' - 10;
+        } else {
+            break;
+        }
+        if (c >= base)
+            break;
+        if (any < 0 || static_cast<uint64_t>(acc) > cutoff || (static_cast<uint64_t>(acc) == cutoff && c > cutlim))
+            any = -1;
+        else {
+            any = 1;
+            acc *= base;
+            acc += c;
+        }
+    }
+
+    if (any == 0) // nothing was parsed
+        return false;
+    if (any < 0) {
+        acc = neg ? INT64_MIN : INT64_MAX;
+        errno = ERANGE;
+        return false;
+    } else if (neg)
+        acc = -acc;
+
+    result = acc;
+    buf_.consume(s - buf_.rawContent() -1);
+    return true;
+}
@@ -0,0 +1,97 @@
+#ifndef SQUID_PARSER_TOKENIZER_H_
+#define SQUID_PARSER_TOKENIZER_H_
+
+#include "base/CharacterSet.h"
+#include "SBuf.h"
+
+/// Generic protocol-agnostic parsing tools
+namespace Parser
+{
+
+/**
+ * Lexical processor to tokenize a buffer.
+ *
+ * Allows arbitrary delimiters and token character sets to
+ * be provided by callers.
+ *
+ * All methods start from the beginning of the input buffer.
+ * Methods returning true consume bytes from the buffer.
+ * Methods returning false have no side-effects.
+ */
+class Tokenizer
+{
+public:
+    explicit Tokenizer(const SBuf &inBuf) : buf_(inBuf) {}
+
+    // return a copy the current contents of the parse buffer
+    const SBuf buf() const { return buf_; }
+
+    /// whether the end of the buffer has been reached
+    bool atEnd() const { return buf_.isEmpty(); }
+
+    /// the remaining unprocessed section of buffer
+    const SBuf& remaining() const { return buf_; }
+
+    /// reinitialize processing for a new buffer
+    void reset(const SBuf &newBuf) { buf_ = newBuf; }
+
+    /** Basic strtok(3):
+     *  Skips all leading delimiters (if any),
+     *  accumulates all characters up to the next delimiter (a token), and
+     *  skips all trailing delimiters.
+     *
+     *  Want to extract delimiters? Use prefix() instead.
+     *
+     * At least one terminating delimiter is required. \0 may be passed
+     * as a delimiter to treat end of buffer content as the end of token.
+     *
+     * \return false if no terminal delimiter is found.
+     */
+    bool token(SBuf &returnedToken, const CharacterSet &delimiters);
+
+    /** Accumulates all sequential permitted characters up to an optional length limit.
+     *
+     * \retval true one or more characters were found, the sequence (string) is placed in returnedToken
+     * \retval false no characters from the permitted set were found
+     */
+    bool prefix(SBuf &returnedToken, const CharacterSet &tokenChars, SBuf::size_type limit = SBuf::npos);
+
+    /** skips all sequential characters from the set, in any order
+     *
+     * \return whether one or more characters in the set were found
+     */
+    bool skip(const CharacterSet &tokenChars);
+
+    /** skips a given character sequence (string)
+     *
+     * \return whether the exact character sequence was found and skipped
+     */
+    bool skip(const SBuf &tokenToSkip);
+
+    /** skips a given single character
+     *
+     * \return whether the character was found and skipped
+     */
+    bool skip(const char tokenChar);
+
+    /** parse an unsigned int64_t at the beginning of the buffer
+     *
+     * strtoll(3)-alike function: tries to parse unsigned 64-bit integer
+     * at the beginning of the parse buffer, in the base specified by the user
+     * or guesstimated; consumes the parsed characters.
+     *
+     * \param result Output value. Not touched if parsing is unsuccessful.
+     * \param base   Specify base to do the parsing in, with the same restrictions
+     *               as strtoll. Defaults to 0 (meaning guess)
+     *
+     * \return whether the parsing was successful
+     */
+    bool int64(int64_t &result, int base = 0);
+
+private:
+    SBuf buf_; ///< yet unparsed input
+};
+
+} /* namespace Parser */
+
+#endif /* SQUID_PARSER_TOKENIZER_H_ */
@@ -0,0 +1,218 @@
+#include "squid.h"
+#include "base/CharacterSet.h"
+#include "parser/Tokenizer.h"
+#include "testTokenizer.h"
+
+CPPUNIT_TEST_SUITE_REGISTRATION( testTokenizer );
+
+SBuf text("GET http://resource.com/path HTTP/1.1\r\n"
+          "Host: resource.com\r\n"
+          "Cookie: laijkpk3422r j1noin \r\n"
+          "\r\n");
+const CharacterSet alpha("alpha","abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ");
+const CharacterSet whitespace("whitespace"," \r\n");
+const CharacterSet crlf("crlf","\r\n");
+const CharacterSet tab("tab","\t");
+const CharacterSet numbers("numbers","0123456789");
+
+void
+testTokenizer::testTokenizerPrefix()
+{
+    Parser::Tokenizer t(text);
+    SBuf s;
+
+    // successful prefix tokenization
+    CPPUNIT_ASSERT(t.prefix(s,alpha));
+    CPPUNIT_ASSERT_EQUAL(SBuf("GET"),s);
+    CPPUNIT_ASSERT(t.prefix(s,whitespace));
+    CPPUNIT_ASSERT_EQUAL(SBuf(" "),s);
+
+    //no match (first char is not in the prefix set)
+    CPPUNIT_ASSERT(!t.prefix(s,whitespace));
+    CPPUNIT_ASSERT_EQUAL(SBuf(" "),s);
+
+    // one more match to set S to something meaningful
+    CPPUNIT_ASSERT(t.prefix(s,alpha));
+    CPPUNIT_ASSERT_EQUAL(SBuf("http"),s);
+
+    //no match (no characters from the character set in the prefix)
+    CPPUNIT_ASSERT(!t.prefix(s,tab));
+    CPPUNIT_ASSERT_EQUAL(SBuf("http"),s); //output SBuf left untouched
+
+    // match until the end of the sample
+    CharacterSet all(whitespace);
+    all += alpha;
+    all += crlf;
+    all += numbers;
+    all.add(':').add('.').add('/');
+    CPPUNIT_ASSERT(t.prefix(s,all));
+    CPPUNIT_ASSERT_EQUAL(SBuf(),t.remaining());
+}
+
+void
+testTokenizer::testTokenizerSkip()
+{
+    Parser::Tokenizer t(text);
+    SBuf s;
+
+    // first scenario: patterns match
+    // prep for test
+    CPPUNIT_ASSERT(t.prefix(s,alpha));
+    CPPUNIT_ASSERT_EQUAL(SBuf("GET"),s);
+
+    // test skip testing character set
+    CPPUNIT_ASSERT(t.skip(whitespace));
+    // check that skip was right
+    CPPUNIT_ASSERT(t.prefix(s,alpha));
+    CPPUNIT_ASSERT_EQUAL(SBuf("http"),s);
+
+    //check skip prefix
+    CPPUNIT_ASSERT(t.skip(SBuf("://")));
+    // verify
+    CPPUNIT_ASSERT(t.prefix(s,alpha));
+    CPPUNIT_ASSERT_EQUAL(SBuf("resource"),s);
+
+    // no skip
+    CPPUNIT_ASSERT(!t.skip(alpha));
+    CPPUNIT_ASSERT(!t.skip(SBuf("://")));
+    CPPUNIT_ASSERT(!t.skip('a'));
+
+}
+
+void
+testTokenizer::testTokenizerToken()
+{
+    Parser::Tokenizer t(text);
+    SBuf s;
+
+    // first scenario: patterns match
+    CPPUNIT_ASSERT(t.token(s,whitespace));
+    CPPUNIT_ASSERT_EQUAL(SBuf("GET"),s);
+    CPPUNIT_ASSERT(t.token(s,whitespace));
+    CPPUNIT_ASSERT_EQUAL(SBuf("http://resource.com/path"),s);
+    CPPUNIT_ASSERT(t.token(s,whitespace));
+    CPPUNIT_ASSERT_EQUAL(SBuf("HTTP/1.1"),s);
+    CPPUNIT_ASSERT(t.token(s,whitespace));
+    CPPUNIT_ASSERT_EQUAL(SBuf("Host:"),s);
+
+}
+
+void
+testTokenizer::testCharacterSet()
+{
+
+}
+
+void
+testTokenizer::testTokenizerInt64()
+{
+    // successful parse in base 10
+    {
+        int64_t rv;
+        Parser::Tokenizer t(SBuf("1234"));
+        const int64_t benchmark = 1234;
+        CPPUNIT_ASSERT(t.int64(rv, 10));
+        CPPUNIT_ASSERT_EQUAL(benchmark,rv);
+    }
+
+    // successful parse, autodetect base
+    {
+        int64_t rv;
+        Parser::Tokenizer t(SBuf("1234"));
+        const int64_t benchmark = 1234;
+        CPPUNIT_ASSERT(t.int64(rv));
+        CPPUNIT_ASSERT_EQUAL(benchmark,rv);
+    }
+
+    // successful parse, autodetect base
+    {
+        int64_t rv;
+        Parser::Tokenizer t(SBuf("01234"));
+        const int64_t benchmark = 01234;
+        CPPUNIT_ASSERT(t.int64(rv));
+        CPPUNIT_ASSERT_EQUAL(benchmark,rv);
+    }
+
+    // successful parse, autodetect base
+    {
+        int64_t rv;
+        Parser::Tokenizer t(SBuf("0x12f4"));
+        const int64_t benchmark = 0x12f4;
+        CPPUNIT_ASSERT(t.int64(rv));
+        CPPUNIT_ASSERT_EQUAL(benchmark,rv);
+    }
+
+    // API mismatch: don't eat leading space
+    {
+        int64_t rv;
+        Parser::Tokenizer t(SBuf(" 1234"));
+        CPPUNIT_ASSERT(!t.int64(rv));
+    }
+
+    // API mismatch: don't eat multiple leading spaces
+    {
+        int64_t rv;
+        Parser::Tokenizer t(SBuf("  1234"));
+        CPPUNIT_ASSERT(!t.int64(rv));
+    }
+
+    // trailing spaces
+    {
+        int64_t rv;
+        Parser::Tokenizer t(SBuf("1234  foo"));
+        const int64_t benchmark = 1234;
+        CPPUNIT_ASSERT(t.int64(rv));
+        CPPUNIT_ASSERT_EQUAL(benchmark,rv);
+        CPPUNIT_ASSERT_EQUAL(SBuf("  foo"), t.buf());
+    }
+
+    // trailing nonspaces
+    {
+        int64_t rv;
+        Parser::Tokenizer t(SBuf("1234foo"));
+        const int64_t benchmark = 1234;
+        CPPUNIT_ASSERT(t.int64(rv));
+        CPPUNIT_ASSERT_EQUAL(benchmark,rv);
+        CPPUNIT_ASSERT_EQUAL(SBuf("foo"), t.buf());
+    }
+
+    // trailing nonspaces
+    {
+        int64_t rv;
+        Parser::Tokenizer t(SBuf("0x1234foo"));
+        const int64_t benchmark = 0x1234f;
+        CPPUNIT_ASSERT(t.int64(rv));
+        CPPUNIT_ASSERT_EQUAL(benchmark,rv);
+        CPPUNIT_ASSERT_EQUAL(SBuf("oo"), t.buf());
+    }
+
+    // overflow
+    {
+        int64_t rv;
+        Parser::Tokenizer t(SBuf("1029397752385698678762234"));
+        CPPUNIT_ASSERT(!t.int64(rv));
+    }
+
+    // buffered sub-string parsing
+    {
+        int64_t rv;
+        SBuf base("1029397752385698678762234");
+        const int64_t benchmark = 22;
+        Parser::Tokenizer t(base.substr(base.length()-4,2));
+        CPPUNIT_ASSERT_EQUAL(SBuf("22"),t.buf());
+        CPPUNIT_ASSERT(t.int64(rv));
+        CPPUNIT_ASSERT_EQUAL(benchmark,rv);
+    }
+
+    // base-16, prefix
+    {
+        int64_t rv;
+        SBuf base("deadbeefrow");
+        const int64_t benchmark=0xdeadbeef;
+        Parser::Tokenizer t(base);
+        CPPUNIT_ASSERT(t.int64(rv,16));
+        CPPUNIT_ASSERT_EQUAL(benchmark,rv);
+        CPPUNIT_ASSERT_EQUAL(SBuf("row"),t.buf());
+
+    }
+}
@@ -0,0 +1,24 @@
+#ifndef SQUID_TESTTOKENIZER_H_
+#define SQUID_TESTTOKENIZER_H_
+
+#include <cppunit/extensions/HelperMacros.h>
+
+class testTokenizer : public CPPUNIT_NS::TestFixture
+{
+    CPPUNIT_TEST_SUITE( testTokenizer );
+    CPPUNIT_TEST ( testCharacterSet );
+    CPPUNIT_TEST ( testTokenizerPrefix );
+    CPPUNIT_TEST ( testTokenizerSkip );
+    CPPUNIT_TEST ( testTokenizerToken );
+    CPPUNIT_TEST ( testTokenizerInt64 );
+    CPPUNIT_TEST_SUITE_END();
+
+protected:
+    void testTokenizerPrefix();
+    void testTokenizerSkip();
+    void testTokenizerToken();
+    void testCharacterSet();
+    void testTokenizerInt64();
+};
+
+#endif /* SQUID_TESTTOKENIZER_H_ */
@@ -34,6 +34,7 @@
 #include "CachePeer.h"
 #include "comm.h"
 #include "comm/Connection.h"
+#include "comm/Read.h"
 #include "fd.h"
 #include "fde.h"
 #include "globals.h"
@@ -310,13 +311,13 @@ IdleConnList::findAndClose(const Comm::ConnectionPointer &conn)
 }
 
 void
-IdleConnList::Read(const Comm::ConnectionPointer &conn, char *buf, size_t len, comm_err_t flag, int xerrno, void *data)
+IdleConnList::Read(const Comm::ConnectionPointer &conn, char *buf, size_t len, Comm::Flag flag, int xerrno, void *data)
 {
     debugs(48, 3, HERE << len << " bytes from " << conn);
 
-    if (flag == COMM_ERR_CLOSING) {
-        debugs(48, 3, HERE << "COMM_ERR_CLOSING from " << conn);
-        /* Bail out on COMM_ERR_CLOSING - may happen when shutdown aborts our idle FD */
+    if (flag == Comm::ERR_CLOSING) {
+        debugs(48, 3, HERE << "Comm::ERR_CLOSING from " << conn);
+        /* Bail out on Comm::ERR_CLOSING - may happen when shutdown aborts our idle FD */
         return;
     }
 
@@ -3,7 +3,7 @@
 include $(top_srcdir)/src/Common.am
 
 ## we need our local files too (but avoid -I. at all costs)
-INCLUDES += -I$(srcdir)
+AM_CPPFLAGS += -I$(srcdir)
 
 AUTOMAKE_OPTIONS = subdir-objects
 
@@ -31,6 +31,7 @@
  */
 
 #include "squid.h"
+#include "anyp/PortCfg.h"
 #include "comm/Connection.h"
 #include "disk.h"
 #include "event.h"
@@ -81,7 +82,7 @@ send_announce(const ipcache_addrs *ia, const DnsLookupDetails &, void *junk)
     sndbuf[0] = '\0';
     snprintf(tbuf, 256, "cache_version SQUID/%s\n", version_string);
     strcat(sndbuf, tbuf);
-    assert(Config.Sockaddr.http);
+    assert(HttpPortList != NULL);
     snprintf(tbuf, 256, "Running on %s %d %d\n",
              getMyHostname(),
              getMyPort(),
@@ -28,11 +28,14 @@ CBDATA_NAMESPACED_CLASS_INIT(Ssl, PeerConnector);
 Ssl::PeerConnector::PeerConnector(
     HttpRequestPointer &aRequest,
     const Comm::ConnectionPointer &aServerConn,
-    AsyncCall::Pointer &aCallback):
+    AsyncCall::Pointer &aCallback,
+    const time_t timeout):
         AsyncJob("Ssl::PeerConnector"),
         request(aRequest),
         serverConn(aServerConn),
-        callback(aCallback)
+        callback(aCallback),
+        negotiationTimeout(timeout),
+        startTime(squid_curtime)
 {
     // if this throws, the caller's cb dialer is not our CbDialer
     Must(dynamic_cast<CbDialer*>(callback->getDialer()));
@@ -177,6 +180,20 @@ Ssl::PeerConnector::initializeSsl()
     fd_table[fd].write_method = &ssl_write_method;
 }
 
+void
+Ssl::PeerConnector::setReadTimeout()
+{
+    int timeToRead;
+    if (negotiationTimeout) {
+        const int timeUsed = squid_curtime - startTime;
+        const int timeLeft = max(0, static_cast<int>(negotiationTimeout - timeUsed));
+        timeToRead = min(static_cast<int>(::Config.Timeout.read), timeLeft);
+    } else
+        timeToRead = ::Config.Timeout.read;
+    AsyncCall::Pointer nil;
+    commSetConnTimeout(serverConnection(), timeToRead, nil);
+}
+
 void
 Ssl::PeerConnector::negotiateSsl()
 {
@@ -386,6 +403,7 @@ Ssl::PeerConnector::handleNegotiateError(const int ret)
     switch (ssl_error) {
 
     case SSL_ERROR_WANT_READ:
+        setReadTimeout();
         Comm::SetSelect(fd, COMM_SELECT_READ, &NegotiateSsl, this, 0);
         return;
 
@@ -71,14 +71,17 @@ class PeerConnectorAnswer
  * The caller must monitor the connection for closure because this
  * job will not inform the caller about such events.
  \par
- * The caller must monitor the overall connection establishment timeout and
- * close the connection on timeouts. This is probably better than having
- * dedicated (or none at all!) timeouts for peer selection, DNS lookup,
- * TCP handshake, SSL handshake, etc. Some steps may have their own timeout,
- * but not all steps should be forced to have theirs. XXX: Neither tunnel.cc
- * nor forward.cc have a "overall connection establishment" timeout. We need
- * to change their code so that they start monitoring earlier and close on
- * timeouts. This change may need to be discussed on squid-dev.
+ * PeerConnector class curently supports a form of SSL negotiation timeout,
+ * which accounted only when sets the read timeout from SSL peer.
+ * For a complete solution, the caller must monitor the overall connection
+ * establishment timeout and close the connection on timeouts. This is probably
+ * better than having dedicated (or none at all!) timeouts for peer selection,
+ * DNS lookup, TCP handshake, SSL handshake, etc. Some steps may have their
+ * own timeout, but not all steps should be forced to have theirs.
+ * XXX: tunnel.cc and probably other subsystems does not have an "overall
+ * connection establishment" timeout. We need to change their code so that they
+ * start monitoring earlier and close on timeouts. This change may need to be
+ * discussed on squid-dev.
  \par
  * This job never closes the connection, even on errors. If a 3rd-party
  * closes the connection, this job simply quits without informing the caller.
@@ -100,7 +103,7 @@ class PeerConnector: virtual public AsyncJob
 public:
     PeerConnector(HttpRequestPointer &aRequest,
                   const Comm::ConnectionPointer &aServerConn,
-                  AsyncCall::Pointer &aCallback);
+                  AsyncCall::Pointer &aCallback, const time_t timeout = 0);
     virtual ~PeerConnector();
 
 protected:
@@ -121,6 +124,10 @@ class PeerConnector: virtual public AsyncJob
     /// handler to monitor the socket.
     bool prepareSocket();
 
+    /// Sets the read timeout to avoid getting stuck while reading from a
+    /// silent server
+    void setReadTimeout();
+
     void initializeSsl(); ///< Initializes SSL state
 
     /// Performs a single secure connection negotiation step.
@@ -162,6 +169,8 @@ class PeerConnector: virtual public AsyncJob
     Comm::ConnectionPointer serverConn; ///< TCP connection to the peer
     AsyncCall::Pointer callback; ///< we call this with the results
     AsyncCall::Pointer closeHandler; ///< we call this when the connection closed
+    time_t negotiationTimeout; ///< the ssl connection timeout to use
+    time_t startTime; ///< when the peer connector negotiation started
 
     CBDATA_CLASS2(PeerConnector);
 };
@@ -264,11 +264,42 @@ mimicExtensions(Ssl::X509_Pointer & cert, Ssl::X509_Pointer const & mimicCert)
         0
     };
 
+    // key usage bit names
+    enum {
+        DigitalSignature,
+        NonRepudiation,
+        KeyEncipherment, // NSS requires for RSA but not EC
+        DataEncipherment,
+        KeyAgreement,
+        KeyCertificateSign,
+        CRLSign,
+        EncipherOnly,
+        DecipherOnly
+    };
+
+    int mimicAlgo = OBJ_obj2nid(mimicCert.get()->cert_info->key->algor->algorithm);
+
     int nid;
     for (int i = 0; (nid = extensions[i]) != 0; ++i) {
         const int pos = X509_get_ext_by_NID(mimicCert.get(), nid, -1);
-        if (X509_EXTENSION *ext = X509_get_ext(mimicCert.get(), pos))
+        if (X509_EXTENSION *ext = X509_get_ext(mimicCert.get(), pos)) {
+            // Mimic extension exactly.
             X509_add_ext(cert.get(), ext, -1);
+            if ( nid == NID_key_usage && mimicAlgo != NID_rsaEncryption ) {
+                // NSS does not requre the KeyEncipherment flag on EC keys
+                // but it does require it for RSA keys.  Since ssl-bump
+                // substitutes RSA keys for EC ones, we need to ensure that
+                // that the more stringent requirements are met.
+
+                const int p = X509_get_ext_by_NID(cert.get(), NID_key_usage, -1);
+                if ((ext = X509_get_ext(cert.get(), p)) != NULL) {
+                    ASN1_BIT_STRING *keyusage = (ASN1_BIT_STRING *)X509V3_EXT_d2i(ext);
+                    ASN1_BIT_STRING_set_bit(keyusage, KeyEncipherment, 1);
+                    X509_EXTENSION_set_data( ext, (ASN1_OCTET_STRING*)keyusage );
+                    ASN1_BIT_STRING_free(keyusage);
+                }
+            }
+        }
     }
 
     // We could also restrict mimicking of the CA extension to CA:FALSE
@@ -33,9 +33,9 @@ void Ssl::Helper::Init()
 
     // we need to start ssl_crtd only if some port(s) need to bump SSL
     bool found = false;
-    for (AnyP::PortCfg *s = ::Config.Sockaddr.http; !found && s; s = s->next)
+    for (AnyP::PortCfgPointer s = HttpPortList; !found && s != NULL; s = s->next)
         found = s->flags.tunnelSslBumping;
-    for (AnyP::PortCfg *s = ::Config.Sockaddr.https; !found && s; s = s->next)
+    for (AnyP::PortCfgPointer s = HttpsPortList; !found && s != NULL; s = s->next)
         found = s->flags.tunnelSslBumping;
     if (!found)
         return;
@@ -134,9 +134,9 @@ void Ssl::CertValidationHelper::Init()
 
     // we need to start ssl_crtd only if some port(s) need to bump SSL
     bool found = false;
-    for (AnyP::PortCfg *s = ::Config.Sockaddr.http; !found && s; s = s->next)
+    for (AnyP::PortCfgPointer s = HttpPortList; !found && s != NULL; s = s->next)
         found = s->flags.tunnelSslBumping;
-    for (AnyP::PortCfg *s = ::Config.Sockaddr.https; !found && s; s = s->next)
+    for (AnyP::PortCfgPointer s = HttpsPortList; !found && s != NULL; s = s->next)
         found = s->flags.tunnelSslBumping;
     if (!found)
         return;
@@ -51,9 +51,7 @@
 #include "ssl/support.h"
 #include "URL.h"
 
-#if HAVE_ERRNO_H
-#include <errno.h>
-#endif
+#include <cerrno>
 
 static void setSessionCallbacks(SSL_CTX *ctx);
 Ipc::MemMap *SslSessionCache = NULL;
@@ -711,35 +709,29 @@ ssl_free_X509(void *, void *ptr, CRYPTO_EX_DATA *,
 static void
 ssl_initialize(void)
 {
-    static int ssl_initialized = 0;
-
-    if (!ssl_initialized) {
-        ssl_initialized = 1;
-        SSL_load_error_strings();
-        SSLeay_add_ssl_algorithms();
-#if HAVE_OPENSSL_ENGINE_H
-
-        if (Config.SSL.ssl_engine) {
-            ENGINE *e;
+    static bool initialized = false;
+    if (initialized)
+        return;
+    initialized = true;
 
-            if (!(e = ENGINE_by_id(Config.SSL.ssl_engine))) {
-                fatalf("Unable to find SSL engine '%s'\n", Config.SSL.ssl_engine);
-            }
+    SSL_load_error_strings();
+    SSLeay_add_ssl_algorithms();
 
-            if (!ENGINE_set_default(e, ENGINE_METHOD_ALL)) {
-                int ssl_error = ERR_get_error();
-                fatalf("Failed to initialise SSL engine: %s\n",
-                       ERR_error_string(ssl_error, NULL));
-            }
+#if HAVE_OPENSSL_ENGINE_H
+    if (Config.SSL.ssl_engine) {
+        ENGINE *e;
+        if (!(e = ENGINE_by_id(Config.SSL.ssl_engine)))
+            fatalf("Unable to find SSL engine '%s'\n", Config.SSL.ssl_engine);
+
+        if (!ENGINE_set_default(e, ENGINE_METHOD_ALL)) {
+            int ssl_error = ERR_get_error();
+            fatalf("Failed to initialise SSL engine: %s\n", ERR_error_string(ssl_error, NULL));
         }
-
+    }
 #else
-        if (Config.SSL.ssl_engine) {
-            fatalf("Your OpenSSL has no SSL engine support\n");
-        }
-
+    if (Config.SSL.ssl_engine)
+        fatalf("Your OpenSSL has no SSL engine support\n");
 #endif
-    }
 
     ssl_ex_index_server = SSL_get_ex_new_index(0, (void *) "server", NULL, NULL, NULL);
     ssl_ctx_ex_index_dont_verify_domain = SSL_CTX_get_ex_new_index(0, (void *) "dont_verify_domain", NULL, NULL, NULL);
@@ -1782,10 +1774,10 @@ setSessionCallbacks(SSL_CTX *ctx)
 static bool
 isSslServer()
 {
-    if (Config.Sockaddr.https)
+    if (HttpsPortList != NULL)
         return true;
 
-    for (AnyP::PortCfg *s = Config.Sockaddr.http; s; s = s->next) {
+    for (AnyP::PortCfgPointer s = HttpPortList; s != NULL; s = s->next) {
         if (s->flags.tunnelSslBumping)
             return true;
     }
@@ -1816,12 +1808,12 @@ Ssl::initialize_session_cache()
         return;
     }
 
-    for (AnyP::PortCfg *s = ::Config.Sockaddr.https; s; s = s->next) {
+    for (AnyP::PortCfgPointer s = HttpsPortList; s != NULL; s = s->next) {
         if (s->staticSslContext.get() != NULL)
             setSessionCallbacks(s->staticSslContext.get());
     }
 
-    for (AnyP::PortCfg *s = ::Config.Sockaddr.http; s; s = s->next) {
+    for (AnyP::PortCfgPointer s = HttpPortList; s != NULL; s = s->next) {
         if (s->staticSslContext.get() != NULL)
             setSessionCallbacks(s->staticSslContext.get());
     }
@@ -625,13 +625,13 @@ DumpInfo(Mgr::InfoActionData& stats, StoreEntry* sentry)
 
 #if _SQUID_WINDOWS_
     if (WIN32_run_mode == _WIN_SQUID_RUN_MODE_SERVICE) {
-        storeAppendPrintf(sentry,"\nRunning as %s Windows System Service on %s\n",
-                          Service_name, WIN32_OS_string);
+        storeAppendPrintf(sentry,"\nRunning as " SQUIDSBUFPH " Windows System Service on %s\n",
+                          SQUIDBUFPRINT(service_name), WIN32_OS_string);
         storeAppendPrintf(sentry,"Service command line is: %s\n", WIN32_Service_Command_Line);
     } else
         storeAppendPrintf(sentry,"Running on %s\n",WIN32_OS_string);
 #else
-    storeAppendPrintf(sentry,"Service Name: %s\n", service_name);
+    storeAppendPrintf(sentry,"Service Name: " SQUIDSBUFPH "\n", SQUIDSBUFPRINT(service_name));
 #endif
 
     storeAppendPrintf(sentry, "Start Time:\t%s\n",
@@ -95,6 +95,7 @@ mem_hdr::unlink(mem_node *aNode)
         return false;
     }
 
+    debugs(19, 8, this << " removing " << aNode);
     nodes.remove (aNode, NodeCompare);
     delete aNode;
     return true;
@@ -103,6 +104,7 @@ mem_hdr::unlink(mem_node *aNode)
 int64_t
 mem_hdr::freeDataUpto(int64_t target_offset)
 {
+    debugs(19, 8, this << " up to " << target_offset);
     /* keep the last one to avoid change to other part of code */
     SplayNode<mem_node*> const * theStart;
 
@@ -232,7 +234,7 @@ mem_hdr::debugDump() const
     debugs (19, 0, "mem_hdr::debugDump: lowest offset: " << lowestOffset() << " highest offset + 1: " << endOffset() << ".");
     std::ostringstream result;
     PointerPrinter<mem_node *> foo(result, " - ");
-    for_each (getNodes().begin(), getNodes().end(), foo);
+    getNodes().visit(foo);
     debugs (19, 0, "mem_hdr::debugDump: Current available data is: " << result.str() << ".");
 }
 
@@ -269,7 +271,7 @@ mem_hdr::copy(StoreIOBuffer const &target) const
         debugs(19, DBG_IMPORTANT, "memCopy: could not find start of " << target.range() <<
                " in memory.");
         debugDump();
-        fatal("Squid has attempted to read data from memory that is not present. This is an indication of of (pre-3.0) code that hasn't been updated to deal with sparse objects in memory. Squid should coredump.allowing to review the cause. Immediately preceding this message is a dump of the available data in the format [start,end). The [ means from the value, the ) means up to the value. I.e. [1,5) means that there are 4 bytes of data, at offsets 1,2,3,4.\n");
+        fatal_dump("Squid has attempted to read data from memory that is not present. This is an indication of of (pre-3.0) code that hasn't been updated to deal with sparse objects in memory. Squid should coredump.allowing to review the cause. Immediately preceding this message is a dump of the available data in the format [start,end). The [ means from the value, the ) means up to the value. I.e. [1,5) means that there are 4 bytes of data, at offsets 1,2,3,4.\n");
         return 0;
     }
 
@@ -368,7 +370,7 @@ mem_hdr::write (StoreIOBuffer const &writeBuffer)
     if (unionNotEmpty(writeBuffer)) {
         debugs(19, DBG_CRITICAL, "mem_hdr::write: writeBuffer: " << writeBuffer.range());
         debugDump();
-        fatal("Attempt to overwrite already in-memory data. Preceeding this there should be a mem_hdr::write output that lists the attempted write, and the currently present data. Please get a 'backtrace full' from this error - using the generated core, and file a bug report with the squid developers including the last 10 lines of cache.log and the backtrace.\n");
+        fatal_dump("Attempt to overwrite already in-memory data. Preceeding this there should be a mem_hdr::write output that lists the attempted write, and the currently present data. Please get a 'backtrace full' from this error - using the generated core, and file a bug report with the squid developers including the last 10 lines of cache.log and the backtrace.\n");
         PROF_stop(mem_hdr_write);
         return false;
     }
@@ -35,6 +35,7 @@
 #include "CacheDigest.h"
 #include "CacheManager.h"
 #include "comm/Connection.h"
+#include "comm/Read.h"
 #include "ETag.h"
 #include "event.h"
 #include "fde.h"
@@ -940,7 +941,7 @@ StoreEntry::checkTooSmall()
         return 0;
 
     if (STORE_OK == store_status)
-        if (mem_obj->object_sz < 0 ||
+        if (mem_obj->object_sz >= 0 &&
                 mem_obj->object_sz < Config.Store.minObjectSize)
             return 1;
     if (getReply()->content_length > -1)
@@ -949,11 +950,23 @@ StoreEntry::checkTooSmall()
     return 0;
 }
 
-// TODO: remove checks already performed by swapoutPossible()
 // TODO: move "too many open..." checks outside -- we are called too early/late
-int
+bool
 StoreEntry::checkCachable()
 {
+    // XXX: This method is used for both memory and disk caches, but some
+    // checks are specific to disk caches. Move them to mayStartSwapOut().
+
+    // XXX: This method may be called several times, sometimes with different
+    // outcomes, making store_check_cachable_hist counters misleading.
+
+    // check this first to optimize handling of repeated calls for uncachables
+    if (EBIT_TEST(flags, RELEASE_REQUEST)) {
+        debugs(20, 2, "StoreEntry::checkCachable: NO: not cachable");
+        ++store_check_cachable_hist.no.not_entry_cachable; // TODO: rename?
+        return 0; // avoid rerequesting release below
+    }
+
 #if CACHE_ALL_METHODS
 
     if (mem_obj->method != Http::METHOD_GET) {
@@ -964,9 +977,6 @@ StoreEntry::checkCachable()
         if (store_status == STORE_OK && EBIT_TEST(flags, ENTRY_BAD_LENGTH)) {
             debugs(20, 2, "StoreEntry::checkCachable: NO: wrong content-length");
             ++store_check_cachable_hist.no.wrong_content_length;
-        } else if (EBIT_TEST(flags, RELEASE_REQUEST)) {
-            debugs(20, 2, "StoreEntry::checkCachable: NO: not cachable");
-            ++store_check_cachable_hist.no.not_entry_cachable; // TODO: rename?
         } else if (EBIT_TEST(flags, ENTRY_NEGCACHED)) {
             debugs(20, 3, "StoreEntry::checkCachable: NO: negative cached");
             ++store_check_cachable_hist.no.negative_cached;
@@ -1389,6 +1399,30 @@ storeInit(void)
     storeRegisterWithCacheManager();
 }
 
+/// computes maximum size of a cachable object
+/// larger objects are rejected by all (disk and memory) cache stores
+static int64_t
+storeCalcMaxObjSize()
+{
+    int64_t ms = 0; // nothing can be cached without at least one store consent
+
+    // global maximum is at least the disk store maximum
+    for (int i = 0; i < Config.cacheSwap.n_configured; ++i) {
+        assert (Config.cacheSwap.swapDirs[i].getRaw());
+        const int64_t storeMax = dynamic_cast<SwapDir *>(Config.cacheSwap.swapDirs[i].getRaw())->maxObjectSize();
+        if (ms < storeMax)
+            ms = storeMax;
+    }
+
+    // global maximum is at least the memory store maximum
+    // TODO: move this into a memory cache class when we have one
+    const int64_t memMax = static_cast<int64_t>(min(Config.Store.maxInMemObjSize, Config.memMaxSize));
+    if (ms < memMax)
+        ms = memMax;
+
+    return ms;
+}
+
 void
 storeConfigure(void)
 {
@@ -1397,11 +1431,16 @@ storeConfigure(void)
     store_swap_low = (long) (((float) Store::Root().maxSize() *
                               (float) Config.Swap.lowWaterMark) / (float) 100);
     store_pages_max = Config.memMaxSize / sizeof(mem_node);
+
+    store_maxobjsize = storeCalcMaxObjSize();
 }
 
 bool
-StoreEntry::memoryCachable() const
+StoreEntry::memoryCachable()
 {
+    if (!checkCachable())
+        return 0;
+
     if (mem_obj == NULL)
         return 0;
 
@@ -1498,15 +1537,20 @@ StoreEntry::validToSend() const
     if (!mem_obj) // not backed by a memory cache and not collapsed
         return 0;
 
-    if (mem_obj->memCache.index >= 0) // backed by a shared memory cache
-        return 0;
-
     // StoreEntry::storeClientType() assumes DISK_CLIENT here, but there is no
-    // disk cache backing so we should not rely on the store cache at all. This
-    // is wrong for range requests that could feed off nibbled memory (XXX).
-    if (mem_obj->inmem_lo) // in local memory cache, but got nibbled at
+    // disk cache backing that store_client constructor will assert. XXX: This
+    // is wrong for range requests (that could feed off nibbled memory) and for
+    // entries backed by the shared memory cache (that could, in theory, get
+    // nibbled bytes from that cache, but there is no such "memoryIn" code).
+    if (mem_obj->inmem_lo) // in memory cache, but got nibbled at
         return 0;
 
+    // The following check is correct but useless at this position. TODO: Move
+    // it up when the shared memory cache can either replenish locally nibbled
+    // bytes or, better, does not use local RAM copy at all.
+    // if (mem_obj->memCache.index >= 0) // backed by a shared memory cache
+    //    return 1;
+
     return 1;
 }
 
@@ -1859,6 +1903,40 @@ StoreEntry::getSerialisedMetaData()
     return result;
 }
 
+/**
+ * Abandon the transient entry our worker has created if neither the shared
+ * memory cache nor the disk cache wants to store it. Collapsed requests, if
+ * any, should notice and use Plan B instead of getting stuck waiting for us
+ * to start swapping the entry out.
+ */
+void
+StoreEntry::transientsAbandonmentCheck()
+{
+    if (mem_obj && !mem_obj->smpCollapsed && // this worker is responsible
+            mem_obj->xitTable.index >= 0 && // other workers may be interested
+            mem_obj->memCache.index < 0 && // rejected by the shared memory cache
+            mem_obj->swapout.decision == MemObject::SwapOut::swImpossible) {
+        debugs(20, 7, "cannot be shared: " << *this);
+        if (!shutting_down) // Store::Root() is FATALly missing during shutdown
+            Store::Root().transientsAbandon(*this);
+    }
+}
+
+void
+StoreEntry::memOutDecision(const bool willCacheInRam)
+{
+    transientsAbandonmentCheck();
+}
+
+void
+StoreEntry::swapOutDecision(const MemObject::SwapOut::Decision &decision)
+{
+    // Abandon our transient entry if neither shared memory nor disk wants it.
+    assert(mem_obj);
+    mem_obj->swapout.decision = decision;
+    transientsAbandonmentCheck();
+}
+
 void
 StoreEntry::trimMemory(const bool preserveSwappable)
 {
@@ -277,10 +277,8 @@ store_client::moreToSend() const
 
     const int64_t len = entry->objectLen();
 
-    // If we do not know the entry length, then we have to open the swap file,
-    // which is only possible if there is one AND if we are allowed to use it.
-    const bool canSwapIn = entry->swap_filen >= 0 &&
-                           getType() == STORE_DISK_CLIENT;
+    // If we do not know the entry length, then we have to open the swap file.
+    const bool canSwapIn = entry->swap_filen >= 0;
     if (len < 0)
         return canSwapIn;
 
@@ -291,7 +289,7 @@ store_client::moreToSend() const
         return true; // if we lack prefix, we can swap it in
 
     // If we cannot swap in, make sure we have what we want in RAM. Otherwise,
-    // scheduleRead calls scheduleDiskRead which asserts on STORE_MEM_CLIENTs.
+    // scheduleRead calls scheduleDiskRead which asserts without a swap file.
     const MemObject *mem = entry->mem_obj;
     return mem &&
            mem->inmem_lo <= copyInto.offset && copyInto.offset < mem->endOffset();
@@ -381,13 +379,15 @@ store_client::doCopy(StoreEntry *anEntry)
      * if needed.
      */
 
-    if (STORE_DISK_CLIENT == getType() && swapin_sio == NULL)
-        startSwapin();
-    else
-        scheduleRead();
+    if (STORE_DISK_CLIENT == getType() && swapin_sio == NULL) {
+        if (!startSwapin())
+            return; // failure
+    }
+    scheduleRead();
 }
 
-void
+/// opens the swapin "file" if possible; otherwise, fail()s and returns false
+bool
 store_client::startSwapin()
 {
     debugs(90, 3, "store_client::doCopy: Need to open swap in file");
@@ -397,28 +397,22 @@ store_client::startSwapin()
         /* yuck -- this causes a TCP_SWAPFAIL_MISS on the client side */
         fail();
         flags.store_copying = false;
-        return;
+        return false;
     } else if (!flags.disk_io_pending) {
         /* Don't set store_io_pending here */
         storeSwapInStart(this);
 
         if (swapin_sio == NULL) {
             fail();
             flags.store_copying = false;
-            return;
+            return false;
         }
 
-        /*
-         * If the open succeeds we either copy from memory, or
-         * schedule a disk read in the next block.
-         */
-        scheduleRead();
-
-        return;
+        return true;
     } else {
         debugs(90, DBG_IMPORTANT, "WARNING: Averted multiple fd operation (1)");
         flags.store_copying = false;
-        return;
+        return false;
     }
 }
 
@@ -437,11 +431,18 @@ void
 store_client::scheduleDiskRead()
 {
     /* What the client wants is not in memory. Schedule a disk read */
-    assert(STORE_DISK_CLIENT == getType());
+    if (getType() == STORE_DISK_CLIENT) {
+        // we should have called startSwapin() already
+        assert(swapin_sio != NULL);
+    } else if (!swapin_sio && !startSwapin()) {
+        debugs(90, 3, "bailing after swapin start failure for " << *entry);
+        assert(!flags.store_copying);
+        return;
+    }
 
     assert(!flags.disk_io_pending);
 
-    debugs(90, 3, "store_client::doCopy: reading from STORE");
+    debugs(90, 3, "reading " << *entry << " from disk");
 
     fileRead();
 
@@ -207,22 +207,22 @@ SwapDir::objectSizeIsAcceptable(int64_t objsize) const
 static int
 storeDirSelectSwapDirRoundRobin(const StoreEntry * e)
 {
-    static int dirn = 0;
-    int i;
-    int load;
-    RefCount<SwapDir> sd;
-
     // e->objectLen() is negative at this point when we are still STORE_PENDING
     ssize_t objsize = e->mem_obj->expectedReplySize();
     if (objsize != -1)
         objsize += e->mem_obj->swap_hdr_sz;
 
-    for (i = 0; i < Config.cacheSwap.n_configured; ++i) {
-        if (++dirn >= Config.cacheSwap.n_configured)
-            dirn = 0;
+    // Increment the first candidate once per selection (not once per
+    // iteration) to reduce bias when some disk(s) attract more entries.
+    static int firstCandidate = 0;
+    if (++firstCandidate >= Config.cacheSwap.n_configured)
+        firstCandidate = 0;
 
-        sd = dynamic_cast<SwapDir *>(INDEXSD(dirn));
+    for (int i = 0; i < Config.cacheSwap.n_configured; ++i) {
+        const int dirn = (firstCandidate + i) % Config.cacheSwap.n_configured;
+        const SwapDir *sd = dynamic_cast<SwapDir*>(INDEXSD(dirn));
 
+        int load = 0;
         if (!sd->canStore(*e, objsize, load))
             continue;
 
@@ -865,7 +865,7 @@ void StoreController::markForUnlink(StoreEntry &e)
 // move this into [non-shared] memory cache class when we have one
 /// whether e should be kept in local RAM for possible future caching
 bool
-StoreController::keepForLocalMemoryCache(const StoreEntry &e) const
+StoreController::keepForLocalMemoryCache(StoreEntry &e) const
 {
     if (!e.memoryCachable())
         return false;
@@ -1060,7 +1060,7 @@ StoreController::anchorCollapsed(StoreEntry &collapsed, bool &inSync)
     bool found = false;
     if (memStore)
         found = memStore->anchorCollapsed(collapsed, inSync);
-    else if (Config.cacheSwap.n_configured)
+    if (!found && Config.cacheSwap.n_configured)
         found = anchorCollapsedOnDisk(collapsed, inSync);
 
     if (found) {
@@ -44,9 +44,8 @@
 #include "StoreSearch.h"
 #include "SwapDir.h"
 
-#if HAVE_ERRNO_H
-#include <errno.h>
-#endif
+#include <cerrno>
+
 static StoreRebuildData counts;
 
 static struct timeval rebuild_start;
@@ -69,7 +69,7 @@ storeSwapOutStart(StoreEntry * e)
            e->swap_dirn << ", fileno " << std::hex << std::setw(8) << std::setfill('0') <<
            std::uppercase << e->swap_filen);
     e->swap_status = SWAPOUT_WRITING;
-    mem->swapout.decision = MemObject::SwapOut::swStarted;
+    e->swapOutDecision(MemObject::SwapOut::swStarted);
     /* If we start swapping out objects with OutOfBand Metadata,
      * then this code needs changing
      */
@@ -88,7 +88,7 @@ storeSwapOutStart(StoreEntry * e)
 
     if (sio == NULL) {
         e->swap_status = SWAPOUT_NONE;
-        mem->swapout.decision = MemObject::SwapOut::swImpossible;
+        e->swapOutDecision(MemObject::SwapOut::swImpossible);
         delete c;
         xfree((char*)buf);
         storeLog(STORE_LOG_SWAPOUTFAIL, e);
@@ -371,7 +371,7 @@ StoreEntry::mayStartSwapOut()
         return false;
 
     assert(mem_obj);
-    MemObject::SwapOut::Decision &decision = mem_obj->swapout.decision;
+    const MemObject::SwapOut::Decision &decision = mem_obj->swapout.decision;
 
     // if we decided that starting is not possible, do not repeat same checks
     if (decision == MemObject::SwapOut::swImpossible) {
@@ -382,14 +382,14 @@ StoreEntry::mayStartSwapOut()
     // if we swapped out already, do not start over
     if (swap_status == SWAPOUT_DONE) {
         debugs(20, 3, "already did");
-        decision = MemObject::SwapOut::swImpossible;
+        swapOutDecision(MemObject::SwapOut::swImpossible);
         return false;
     }
 
     // if we stared swapping out already, do not start over
     if (decision == MemObject::SwapOut::swStarted) {
         debugs(20, 3, "already started");
-        decision = MemObject::SwapOut::swImpossible;
+        swapOutDecision(MemObject::SwapOut::swImpossible);
         return false;
     }
 
@@ -401,30 +401,30 @@ StoreEntry::mayStartSwapOut()
 
     if (!checkCachable()) {
         debugs(20, 3,  HERE << "not cachable");
-        decision = MemObject::SwapOut::swImpossible;
+        swapOutDecision(MemObject::SwapOut::swImpossible);
         return false;
     }
 
     if (EBIT_TEST(flags, ENTRY_SPECIAL)) {
         debugs(20, 3,  HERE  << url() << " SPECIAL");
-        decision = MemObject::SwapOut::swImpossible;
+        swapOutDecision(MemObject::SwapOut::swImpossible);
         return false;
     }
 
     if (mem_obj->inmem_lo > 0) {
         debugs(20, 3, "storeSwapOut: (inmem_lo > 0)  imem_lo:" <<  mem_obj->inmem_lo);
-        decision = MemObject::SwapOut::swImpossible;
+        swapOutDecision(MemObject::SwapOut::swImpossible);
         return false;
     }
 
     if (!mem_obj->isContiguous()) {
         debugs(20, 3, "storeSwapOut: not Contiguous");
-        decision = MemObject::SwapOut::swImpossible;
+        swapOutDecision(MemObject::SwapOut::swImpossible);
         return false;
     }
 
-    // check cache_dir max-size limit if all cache_dirs have it
-    if (store_maxobjsize >= 0) {
+    // handle store_maxobjsize limit
+    {
         // TODO: add estimated store metadata size to be conservative
 
         // use guaranteed maximum if it is known
@@ -433,7 +433,7 @@ StoreEntry::mayStartSwapOut()
         if (expectedEnd > store_maxobjsize) {
             debugs(20, 3,  HERE << "will not fit: " << expectedEnd <<
                    " > " << store_maxobjsize);
-            decision = MemObject::SwapOut::swImpossible;
+            swapOutDecision(MemObject::SwapOut::swImpossible);
             return false; // known to outgrow the limit eventually
         }
 
@@ -442,7 +442,7 @@ StoreEntry::mayStartSwapOut()
         if (currentEnd > store_maxobjsize) {
             debugs(20, 3,  HERE << "does not fit: " << currentEnd <<
                    " > " << store_maxobjsize);
-            decision = MemObject::SwapOut::swImpossible;
+            swapOutDecision(MemObject::SwapOut::swImpossible);
             return false; // already does not fit and may only get bigger
         }
 
@@ -465,6 +465,6 @@ StoreEntry::mayStartSwapOut()
         }
     }
 
-    decision = MemObject::SwapOut::swPossible;
+    swapOutDecision(MemObject::SwapOut::swPossible);
     return true;
 }
@@ -38,9 +38,7 @@
 #include "CacheDigest.h"
 #include "store_key_md5.h"
 
-#if HAVE_ERRNO_H
-#include <errno.h>
-#endif
+#include <cerrno>
 
 typedef struct {
     int query_count;
@@ -13,6 +13,7 @@ STUB_SOURCE= tests/STUB.h \
 	tests/stub_MemObject.cc \
 	tests/stub_MemStore.cc \
 	tests/stub_Port.cc \
+	tests/stub_SBuf.cc \
 	tests/stub_SBufDetailedStats.cc \
 	tests/stub_StatHist.cc \
 	tests/stub_StoreMeta.cc \
@@ -18,7 +18,7 @@ void MemStore::unlink(StoreEntry &e) STUB
 void MemStore::disconnect(StoreEntry &e) STUB
 void MemStore::reference(StoreEntry &) STUB
 void MemStore::maintain() STUB
-void MemStore::noteFreeMapSlice(const sfileno) STUB
+void MemStore::noteFreeMapSlice(const Ipc::StoreMapSliceId) STUB
 void MemStore::get(String const, STOREGETCLIENT, void *) STUB
 void MemStore::init() STUB
 void MemStore::getStats(StoreInfoStats&) const STUB
@@ -0,0 +1,60 @@
+#include "squid.h"
+
+#define STUB_API "SBuf.cc"
+#include "tests/STUB.h"
+
+#include "SBuf.h"
+
+InstanceIdDefinitions(SBuf, "SBuf");
+
+SBufStats SBuf::stats;
+const SBuf::size_type SBuf::npos;
+const SBuf::size_type SBuf::maxSize;
+
+SBufStats::SBufStats() {}
+std::ostream& SBufStats::dump(std::ostream &os) const STUB_RETVAL(os)
+SBufStats& SBufStats::operator +=(const SBufStats&) STUB_RETVAL(*this)
+
+SBuf::SBuf() {}
+SBuf::SBuf(const SBuf &S) {}
+SBuf::SBuf(const char *S, size_type n) {}
+SBuf::SBuf(const String &S) {}
+SBuf::SBuf(const std::string &s) {}
+SBuf::~SBuf() {}
+SBuf& SBuf::assign(const SBuf &S) STUB_RETVAL(*this)
+SBuf& SBuf::assign(const char *S, size_type n) STUB_RETVAL(*this)
+void clear() STUB
+SBuf& SBuf::append(const SBuf & S) STUB_RETVAL(*this)
+SBuf& SBuf::append(const char * S, size_type Ssize) STUB_RETVAL(*this)
+SBuf& Printf(const char *fmt, ...);
+SBuf& SBuf::appendf(const char *fmt, ...) STUB_RETVAL(*this)
+SBuf& SBuf::vappendf(const char *fmt, va_list vargs) STUB_RETVAL(*this)
+std::ostream& SBuf::print(std::ostream &os) const STUB_RETVAL(os)
+std::ostream& SBuf::dump(std::ostream &os) const STUB_RETVAL(os)
+void SBuf::setAt(size_type pos, char toset) STUB
+int SBuf::compare(const SBuf &S, const SBufCaseSensitive isCaseSensitive, const size_type n) const STUB_RETVAL(-1)
+int SBuf::compare(const char *s, const SBufCaseSensitive isCaseSensitive, const size_type n) const STUB_RETVAL(-1)
+bool SBuf::startsWith(const SBuf &S, const SBufCaseSensitive isCaseSensitive) const STUB_RETVAL(false)
+bool SBuf::operator ==(const SBuf & S) const STUB_RETVAL(false)
+bool SBuf::operator !=(const SBuf & S) const STUB_RETVAL(false)
+SBuf SBuf::consume(size_type n) STUB_RETVAL(*this)
+const SBufStats& SBuf::GetStats() STUB_RETVAL(SBuf::stats)
+SBuf::size_type SBuf::copy(char *dest, size_type n) const STUB_RETVAL(0)
+const char* SBuf::rawContent() const STUB_RETVAL(NULL)
+char *SBuf::rawSpace(size_type minSize) STUB_RETVAL(NULL)
+void SBuf::forceSize(size_type newSize) STUB
+const char* SBuf::c_str() STUB_RETVAL("")
+void SBuf::reserveCapacity(size_type minCapacity) STUB
+SBuf& SBuf::chop(size_type pos, size_type n) STUB_RETVAL(*this)
+SBuf& SBuf::trim(const SBuf &toRemove, bool atBeginning, bool atEnd) STUB_RETVAL(*this)
+SBuf SBuf::substr(size_type pos, size_type n) const STUB_RETVAL(*this)
+SBuf::size_type SBuf::find(char c, size_type startPos) const STUB_RETVAL(SBuf::npos)
+SBuf::size_type SBuf::find(const SBuf & str, size_type startPos) const STUB_RETVAL(SBuf::npos)
+SBuf::size_type SBuf::rfind(char c, size_type endPos) const STUB_RETVAL(SBuf::npos)
+SBuf::size_type SBuf::rfind(const SBuf &str, size_type endPos) const STUB_RETVAL(SBuf::npos)
+SBuf::size_type SBuf::findFirstOf(const CharacterSet &set, size_type startPos) const STUB_RETVAL(SBuf::npos)
+SBuf::size_type SBuf::findFirstNotOf(const CharacterSet &set, size_type startPos) const STUB_RETVAL(SBuf::npos)
+int SBuf::scanf(const char *format, ...) STUB_RETVAL(-1)
+SBuf SBuf::toLower() const STUB_RETVAL(*this)
+SBuf SBuf::toUpper() const STUB_RETVAL(*this)
+String SBuf::toString() const STUB_RETVAL(String(""))
@@ -7,7 +7,7 @@
 //ClientSocketContext::ClientSocketContext(const ConnectionPointer&, ClientHttpRequest*) STUB
 //ClientSocketContext::~ClientSocketContext() STUB
 bool ClientSocketContext::startOfOutput() const STUB_RETVAL(false)
-void ClientSocketContext::writeComplete(const Comm::ConnectionPointer &conn, char *bufnotused, size_t size, comm_err_t errflag) STUB
+void ClientSocketContext::writeComplete(const Comm::ConnectionPointer &conn, char *bufnotused, size_t size, Comm::Flag errflag) STUB
 void ClientSocketContext::keepaliveNextRequest() STUB
 void ClientSocketContext::pullData() STUB
 int64_t ClientSocketContext::getNextRangeOffset() const STUB_RETVAL(0)
@@ -51,9 +51,9 @@ void ConnStateData::stopSending(const char *error) STUB
 void ConnStateData::expectNoForwarding() STUB
 void ConnStateData::noteMoreBodySpaceAvailable(BodyPipe::Pointer) STUB
 void ConnStateData::noteBodyConsumerAborted(BodyPipe::Pointer) STUB
-bool ConnStateData::handleReadData(SBuf *buf) STUB_RETVAL(false)
+bool ConnStateData::handleReadData() STUB_RETVAL(false)
 bool ConnStateData::handleRequestBodyData() STUB_RETVAL(false)
-void ConnStateData::pinConnection(const Comm::ConnectionPointer &pinServerConn, HttpRequest *request, CachePeer *peer, bool auth, bool monitor = true) STUB
+void ConnStateData::pinConnection(const Comm::ConnectionPointer &pinServerConn, HttpRequest *request, CachePeer *peer, bool auth, bool monitor) STUB
 void ConnStateData::unpinConnection(const bool andClose) STUB
 const Comm::ConnectionPointer ConnStateData::validatePinnedConnection(HttpRequest *request, const CachePeer *peer) STUB_RETVAL(NULL)
 void ConnStateData::clientPinnedConnectionClosed(const CommCloseCbParams &io) STUB
@@ -1,37 +1,4 @@
-/*
- * DEBUG: section 84    Helper process maintenance
- * AUTHOR: Robert Collins
- *
- * SQUID Web Proxy Cache          http://www.squid-cache.org/
- * ----------------------------------------------------------
- *
- *  Squid is the result of efforts by numerous individuals from
- *  the Internet community; see the CONTRIBUTORS file for full
- *  details.   Many organizations have provided support for Squid's
- *  development; see the SPONSORS file for full details.  Squid is
- *  Copyrighted (C) 2001 by the Regents of the University of
- *  California; see the COPYRIGHT file for full details.  Squid
- *  incorporates software developed and/or copyrighted by other
- *  sources; see the CREDITS file for full details.
- *
- *  This program is free software; you can redistribute it and/or modify
- *  it under the terms of the GNU General Public License as published by
- *  the Free Software Foundation; either version 2 of the License, or
- *  (at your option) any later version.
- *
- *  This program is distributed in the hope that it will be useful,
- *  but WITHOUT ANY WARRANTY; without even the implied warranty of
- *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
- *  GNU General Public License for more details.
- *
- *  You should have received a copy of the GNU General Public License
- *  along with this program; if not, write to the Free Software
- *  Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111, USA.
- *
- */
-
 #include "squid.h"
-#include "comm.h"
 #include "comm/Connection.h"
 #include "comm/Loops.h"
 #include "fde.h"
@@ -51,15 +18,45 @@ DeferredRead::DeferredRead(DeferrableRead *, void *, CommRead const &) STUB
 void DeferredReadManager::delayRead(DeferredRead const &aRead) STUB
 void DeferredReadManager::kickReads(int const count) STUB
 
-void commSetCloseOnExec(int fd) STUB_NOP
-int ignoreErrno(int ierrno) STUB_RETVAL(-1)
-
-void commUnsetFdTimeout(int fd) STUB
-int commSetNonBlocking(int fd) STUB_RETVAL(COMM_ERROR)
+#include "comm.h"
+bool comm_iocallbackpending(void) STUB_RETVAL(false)
+int commSetNonBlocking(int fd) STUB_RETVAL(Comm::COMM_ERROR)
 int commUnsetNonBlocking(int fd) STUB_RETVAL(-1)
-
-// MinGW needs also a stub of _comm_close()
+void commSetCloseOnExec(int fd) STUB_NOP
+void commSetTcpKeepalive(int fd, int idle, int interval, int timeout) STUB
 void _comm_close(int fd, char const *file, int line) STUB
-int commSetTimeout(int fd, int timeout, AsyncCall::Pointer& callback) STUB_RETVAL(-1)
+void old_comm_reset_close(int fd) STUB
+void comm_reset_close(const Comm::ConnectionPointer &conn) STUB
+#if LINGERING_CLOSE
+void comm_lingering_close(int fd) STUB
+#endif
+int comm_connect_addr(int sock, const Ip::Address &addr) STUB_RETVAL(-1)
+void comm_init(void) STUB
+void comm_exit(void) STUB
+int comm_open(int, int, Ip::Address &, int, const char *note) STUB_RETVAL(-1)
 int comm_open_uds(int sock_type, int proto, struct sockaddr_un* addr, int flags) STUB_RETVAL(-1)
-void comm_write(int fd, const char *buf, int size, AsyncCall::Pointer &callback, FREE * free_func) STUB
+void comm_import_opened(const Comm::ConnectionPointer &, const char *note, struct addrinfo *AI) STUB
+int comm_open_listener(int sock_type, int proto, Ip::Address &addr, int flags, const char *note) STUB_RETVAL(-1)
+void comm_open_listener(int sock_type, int proto, Comm::ConnectionPointer &conn, const char *note) STUB
+int comm_openex(int, int, Ip::Address &, int, tos_t tos, nfmark_t nfmark, const char *) STUB_RETVAL(-1)
+unsigned short comm_local_port(int fd) STUB_RETVAL(0)
+int comm_udp_sendto(int sock, const Ip::Address &to, const void *buf, int buflen) STUB_RETVAL(-1)
+void commCallCloseHandlers(int fd) STUB
+void commUnsetFdTimeout(int fd) STUB
+int commSetTimeout(const Comm::ConnectionPointer &, int, AsyncCall::Pointer&) STUB_RETVAL(-1)
+int commSetConnTimeout(const Comm::ConnectionPointer &conn, int seconds, AsyncCall::Pointer &callback) STUB_RETVAL(-1)
+int commUnsetConnTimeout(const Comm::ConnectionPointer &conn) STUB_RETVAL(-1)
+int ignoreErrno(int ierrno) STUB_RETVAL(-1)
+void commCloseAllSockets(void) STUB
+void checkTimeouts(void) STUB
+void comm_add_close_handler(int fd, CLCB *, void *) STUB
+void comm_add_close_handler(int fd, AsyncCall::Pointer &) STUB
+void comm_remove_close_handler(int fd, CLCB *, void *) STUB
+void comm_remove_close_handler(int fd, AsyncCall::Pointer &)STUB
+int comm_udp_recvfrom(int fd, void *buf, size_t len, int flags, Ip::Address &from) STUB_RETVAL(-1)
+int comm_udp_recv(int fd, void *buf, size_t len, int flags) STUB_RETVAL(-1)
+ssize_t comm_udp_send(int s, const void *buf, size_t len, int flags) STUB_RETVAL(-1)
+bool comm_has_incomplete_write(int) STUB_RETVAL(false)
+void commStartHalfClosedMonitor(int fd) STUB
+bool commHasHalfClosedMonitor(int fd) STUB_RETVAL(false)
+int CommSelectEngine::checkEvents(int timeout) STUB_RETVAL(0)
@@ -4,7 +4,7 @@
 #define STUB_API "event.cc"
 #include "tests/STUB.h"
 
-void eventAdd(const char *name, EVH * func, void *arg, double when, int, bool cbdata) STUB
+void eventAdd(const char *name, EVH * func, void *arg, double when, int, bool cbdata) STUB_NOP
 void eventAddIsh(const char *name, EVH * func, void *arg, double delta_ish, int) STUB
 void eventDelete(EVH * func, void *arg) STUB
 void eventInit(void) STUB
@@ -36,7 +36,7 @@ Comm::ConnOpener::ConnOpener(Comm::ConnectionPointer &, AsyncCall::Pointer &, ti
         void Comm::IoCallback::setCallback(iocb_type, AsyncCall::Pointer &, char *, FREE *, int) STUB
         void Comm::IoCallback::selectOrQueueWrite() STUB
         void Comm::IoCallback::cancel(const char *reason) STUB
-        void Comm::IoCallback::finish(comm_err_t code, int xerrn) STUB
+        void Comm::IoCallback::finish(Comm::Flag code, int xerrn) STUB
         Comm::CbEntry *Comm::iocb_table = NULL;
 void Comm::CallbackTableInit() STUB
 void Comm::CallbackTableDestruct() STUB
@@ -45,15 +45,25 @@ void Comm::CallbackTableDestruct() STUB
 void Comm::SelectLoopInit(void) STUB
 void Comm::SetSelect(int, unsigned int, PF *, void *, time_t) STUB
 void Comm::ResetSelect(int) STUB
-comm_err_t Comm::DoSelect(int) STUB_RETVAL(COMM_ERROR)
+Comm::Flag Comm::DoSelect(int) STUB_RETVAL(Comm::COMM_ERROR)
 void Comm::QuickPollRequired(void) STUB
 
+#include "comm/Read.h"
+void Comm::Read(const Comm::ConnectionPointer &conn, AsyncCall::Pointer &callback) STUB
+bool Comm::MonitorsRead(int fd) STUB_RETVAL(false)
+Comm::Flag Comm::ReadNow(CommIoCbParams &params, SBuf &buf) STUB_RETVAL(Comm::COMM_ERROR)
+void Comm::ReadCancel(int fd, AsyncCall::Pointer &callback) STUB
+//void Comm::HandleRead(int, void*) STUB
+
+void comm_read_base(const Comm::ConnectionPointer &conn, char *buf, int len, AsyncCall::Pointer &callback) STUB
+void comm_read_cancel(int fd, IOCB *callback, void *data) STUB
+
 #include "comm/TcpAcceptor.h"
 //Comm::TcpAcceptor(const Comm::ConnectionPointer &conn, const char *note, const Subscription::Pointer &aSub) STUB
 void Comm::TcpAcceptor::subscribe(const Subscription::Pointer &aSub) STUB
 void Comm::TcpAcceptor::unsubscribe(const char *) STUB
 void Comm::TcpAcceptor::acceptNext() STUB
-void Comm::TcpAcceptor::notify(const comm_err_t flag, const Comm::ConnectionPointer &) const STUB
+void Comm::TcpAcceptor::notify(const Comm::Flag flag, const Comm::ConnectionPointer &) const STUB
 
 #include "comm/Write.h"
 void Comm::Write(const Comm::ConnectionPointer &, const char *, int, AsyncCall::Pointer &, FREE *) STUB
@@ -40,20 +40,47 @@ Ssl::ErrorDetail::ErrorDetail(ErrorDetail const &) STUB
 const String & Ssl::ErrorDetail::toString() const STUB_RETSTATREF(String)
 
 #include "ssl/support.h"
-SSL_CTX *sslCreateServerContext(AnyP::PortCfg &) STUB_RETVAL(NULL)
+namespace Ssl
+{
+//CertError::CertError(ssl_error_t anErr, X509 *aCert) STUB
+//CertError::CertError(CertError const &err) STUB
+CertError & CertError::operator = (const CertError &old) STUB_RETVAL(*this)
+bool CertError::operator == (const CertError &ce) const STUB_RETVAL(false)
+bool CertError::operator != (const CertError &ce) const STUB_RETVAL(false)
+} // namespace Ssl
+SSL_CTX *sslCreateServerContext(AnyP::PortCfg &port) STUB_RETVAL(NULL)
 SSL_CTX *sslCreateClientContext(const char *certfile, const char *keyfile, int version, const char *cipher, const char *options, const char *flags, const char *CAfile, const char *CApath, const char *CRLfile) STUB_RETVAL(NULL)
 int ssl_read_method(int, char *, int) STUB_RETVAL(0)
 int ssl_write_method(int, const char *, int) STUB_RETVAL(0)
-void ssl_shutdown_method(SSL *) STUB
+void ssl_shutdown_method(SSL *ssl) STUB
 const char *sslGetUserEmail(SSL *ssl) STUB_RETVAL(NULL)
-// typedef char const *Ssl::GETATTRIBUTE(X509 *, const char *);
-// Ssl::GETATTRIBUTE Ssl::GetX509UserAttribute;
-// Ssl::GETATTRIBUTE Ssl::GetX509CAAttribute;
+const char *sslGetUserAttribute(SSL *ssl, const char *attribute_name) STUB_RETVAL(NULL)
+const char *sslGetCAAttribute(SSL *ssl, const char *attribute_name) STUB_RETVAL(NULL)
 const char *sslGetUserCertificatePEM(SSL *ssl) STUB_RETVAL(NULL)
 const char *sslGetUserCertificateChainPEM(SSL *ssl) STUB_RETVAL(NULL)
-SSL_CTX * Ssl::generateSslContext(CertificateProperties const &properties, AnyP::PortCfg &) STUB_RETVAL(NULL)
-SSL_CTX * Ssl::generateSslContextUsingPkeyAndCertFromMemory(const char * data, AnyP::PortCfg &) STUB_RETVAL(NULL)
-int Ssl::matchX509CommonNames(X509 *peer_cert, void *check_data, int (*check_func)(void *check_data,  ASN1_STRING *cn_data)) STUB_RETVAL(0)
-int Ssl::asn1timeToString(ASN1_TIME *tm, char *buf, int len) STUB_RETVAL(0)
+namespace Ssl
+{
+//GETX509ATTRIBUTE GetX509UserAttribute;
+//GETX509ATTRIBUTE GetX509CAAttribute;
+//GETX509ATTRIBUTE GetX509Fingerprint;
+const char *BumpModeStr[] = {""};
+long parse_flags(const char *flags) STUB_RETVAL(0)
+long parse_options(const char *options) STUB_RETVAL(0)
+STACK_OF(X509_CRL) *loadCrl(const char *CRLFile, long &flags) STUB_RETVAL(NULL)
+DH *readDHParams(const char *dhfile) STUB_RETVAL(NULL)
+ContextMethod contextMethod(int version) STUB_RETVAL(ContextMethod())
+bool generateUntrustedCert(X509_Pointer & untrustedCert, EVP_PKEY_Pointer & untrustedPkey, X509_Pointer const & cert, EVP_PKEY_Pointer const & pkey) STUB_RETVAL(false)
+SSL_CTX * generateSslContext(CertificateProperties const &properties, AnyP::PortCfg &port) STUB_RETVAL(NULL)
+bool verifySslCertificate(SSL_CTX * sslContext,  CertificateProperties const &properties) STUB_RETVAL(false)
+SSL_CTX * generateSslContextUsingPkeyAndCertFromMemory(const char * data, AnyP::PortCfg &port) STUB_RETVAL(NULL)
+void addChainToSslContext(SSL_CTX *sslContext, STACK_OF(X509) *certList) STUB
+void readCertChainAndPrivateKeyFromFiles(X509_Pointer & cert, EVP_PKEY_Pointer & pkey, X509_STACK_Pointer & chain, char const * certFilename, char const * keyFilename) STUB
+int matchX509CommonNames(X509 *peer_cert, void *check_data, int (*check_func)(void *check_data,  ASN1_STRING *cn_data)) STUB_RETVAL(0)
+bool checkX509ServerValidity(X509 *cert, const char *server) STUB_RETVAL(false)
+int asn1timeToString(ASN1_TIME *tm, char *buf, int len) STUB_RETVAL(0)
+bool setClientSNI(SSL *ssl, const char *fqdn) STUB_RETVAL(false)
+void initialize_session_cache() STUB
+void destruct_session_cache() STUB
+} //namespace Ssl
 
 #endif
@@ -46,11 +46,11 @@ void StoreEntry::purgeMem() STUB
 void StoreEntry::swapOut() STUB
 void StoreEntry::swapOutFileClose(int how) STUB
 const char *StoreEntry::url() const STUB_RETVAL(NULL)
-int StoreEntry::checkCachable() STUB_RETVAL(0)
+bool StoreEntry::checkCachable() STUB_RETVAL(false)
 int StoreEntry::checkNegativeHit() const STUB_RETVAL(0)
 int StoreEntry::locked() const STUB_RETVAL(0)
 int StoreEntry::validToSend() const STUB_RETVAL(0)
-bool StoreEntry::memoryCachable() const STUB_RETVAL(false)
+bool StoreEntry::memoryCachable() STUB_RETVAL(false)
 MemObject *StoreEntry::makeMemObject() STUB_RETVAL(NULL)
 void StoreEntry::createMemObject(const char *, const char *, const HttpRequestMethod &aMethod) STUB
 void StoreEntry::dump(int debug_lvl) const STUB
@@ -1,10 +1,12 @@
 #include "squid.h"
-#include "tools.h"
+// XXX: need src/ to avoid clashes with ip/tools.h in testIpAddress
+#include "src/tools.h"
 
 #define STUB_API "tools.cc"
 #include "tests/STUB.h"
 
 int DebugSignal = -1;
+SBuf service_name(APP_SHORTNAME);
 void releaseServerSockets(void) STUB
 char * dead_msg(void) STUB_RETVAL(NULL)
 void mail_warranty(void) STUB
@@ -22,15 +22,6 @@ MemObject::endOffset() const
     return 0;
 }
 
-#include "ConfigParser.h"
-
-void
-eventAdd(const char *name, EVH * func, void *arg, double when, int, bool cbdata)
-{
-// CALLED as setUp no-op
-//    fatal("eventAdd. Not implemented.");
-}
-
 /* end */
 
 void
@@ -52,6 +52,7 @@
 #include "tools.h"
 #include "wordlist.h"
 
+#include <cerrno>
 #if HAVE_SYS_PRCTL_H
 #include <sys/prctl.h>
 #endif
@@ -67,9 +68,6 @@
 #if HAVE_GRP_H
 #include <grp.h>
 #endif
-#if HAVE_ERRNO_H
-#include <errno.h>
-#endif
 
 #define DEAD_MSG "\
 The Squid Cache (version %s) died.\n\
@@ -84,6 +82,7 @@ Thanks!\n"
 static void mail_warranty(void);
 static void restoreCapabilities(int keep);
 int DebugSignal = -1;
+SBuf service_name(APP_SHORTNAME);
 
 #if _SQUID_LINUX_
 /* Workaround for crappy glic header files */
@@ -479,13 +478,13 @@ getMyHostname(void)
 
     host[0] = '\0';
 
-    if (Config.Sockaddr.http && sa.isAnyAddr())
-        sa = Config.Sockaddr.http->s;
+    if (HttpPortList != NULL && sa.isAnyAddr())
+        sa = HttpPortList->s;
 
 #if USE_OPENSSL
 
-    if (Config.Sockaddr.https && sa.isAnyAddr())
-        sa = Config.Sockaddr.https->s;
+    if (HttpsPortList != NULL && sa.isAnyAddr())
+        sa = HttpsPortList->s;
 
 #endif
 
@@ -1133,30 +1132,30 @@ parseEtcHosts(void)
 int
 getMyPort(void)
 {
-    AnyP::PortCfg *p = NULL;
-    if ((p = Config.Sockaddr.http)) {
+    AnyP::PortCfgPointer p;
+    if ((p = HttpPortList) != NULL) {
         // skip any special interception ports
-        while (p && p->flags.isIntercepted())
+        while (p != NULL && p->flags.isIntercepted())
             p = p->next;
-        if (p)
+        if (p != NULL)
             return p->s.port();
     }
 
 #if USE_OPENSSL
-    if ((p = Config.Sockaddr.https)) {
+    if ((p = HttpsPortList) != NULL) {
         // skip any special interception ports
-        while (p && p->flags.isIntercepted())
+        while (p != NULL && p->flags.isIntercepted())
             p = p->next;
-        if (p)
+        if (p != NULL)
             return p->s.port();
     }
 #endif
 
-    if ((p = Config.Sockaddr.ftp)) {
+    if ((p = FtpPortList) != NULL) {
         // skip any special interception ports
-        while (p && p->flags.isIntercepted())
+        while (p != NULL && p->flags.isIntercepted())
             p = p->next;
-        if (p)
+        if (p != NULL)
             return p->s.port();
     }
 
@@ -34,13 +34,18 @@
 #define SQUID_TOOLS_H_
 
 #include "Packer.h"
+#include "SBuf.h"
 #include "SquidString.h"
 #include "typedefs.h"
 
 class MemBuf;
 
 extern int DebugSignal;
 
+/// The Squid -n parameter service name.
+/// Default is APP_SHORTNAME ('squid').
+extern SBuf service_name;
+
 void kb_incr(kb_t *, size_t);
 void parseEtcHosts(void);
 int getMyPort(void);
@@ -40,6 +40,7 @@
 #include "comm.h"
 #include "comm/Connection.h"
 #include "comm/ConnOpener.h"
+#include "comm/Read.h"
 #include "comm/Write.h"
 #include "errorpage.h"
 #include "fde.h"
@@ -48,6 +49,7 @@
 #include "HttpRequest.h"
 #include "HttpStateFlags.h"
 #include "ip/QosConfig.h"
+#include "LogTags.h"
 #include "MemBuf.h"
 #include "PeerSelectState.h"
 #include "SquidConfig.h"
@@ -86,10 +88,10 @@ class TunnelStateData
     TunnelStateData &operator =(const TunnelStateData &); // do not implement
 
     class Connection;
-    static void ReadClient(const Comm::ConnectionPointer &, char *buf, size_t len, comm_err_t errcode, int xerrno, void *data);
-    static void ReadServer(const Comm::ConnectionPointer &, char *buf, size_t len, comm_err_t errcode, int xerrno, void *data);
-    static void WriteClientDone(const Comm::ConnectionPointer &, char *buf, size_t len, comm_err_t flag, int xerrno, void *data);
-    static void WriteServerDone(const Comm::ConnectionPointer &, char *buf, size_t len, comm_err_t flag, int xerrno, void *data);
+    static void ReadClient(const Comm::ConnectionPointer &, char *buf, size_t len, Comm::Flag errcode, int xerrno, void *data);
+    static void ReadServer(const Comm::ConnectionPointer &, char *buf, size_t len, Comm::Flag errcode, int xerrno, void *data);
+    static void WriteClientDone(const Comm::ConnectionPointer &, char *buf, size_t len, Comm::Flag flag, int xerrno, void *data);
+    static void WriteServerDone(const Comm::ConnectionPointer &, char *buf, size_t len, Comm::Flag flag, int xerrno, void *data);
 
     /// Starts reading peer response to our CONNECT request.
     void readConnectResponse();
@@ -157,7 +159,8 @@ class TunnelStateData
     };
 
     Connection client, server;
-    int *status_ptr;		/* pointer to status for logging */
+    int *status_ptr;        ///< pointer for logging HTTP status
+    LogTags *logTag_ptr;    ///< pointer for logging Squid processing code
     MemBuf *connectRespBuf; ///< accumulates peer CONNECT response when we need it
     bool connectReqWriting; ///< whether we are writing a CONNECT request to a peer
 
@@ -197,16 +200,16 @@ class TunnelStateData
 #endif
 
     CBDATA_CLASS2(TunnelStateData);
-    bool keepGoingAfterRead(size_t len, comm_err_t errcode, int xerrno, Connection &from, Connection &to);
+    bool keepGoingAfterRead(size_t len, Comm::Flag errcode, int xerrno, Connection &from, Connection &to);
     void copy(size_t len, Connection &from, Connection &to, IOCB *);
     void handleConnectResponse(const size_t chunkSize);
-    void readServer(char *buf, size_t len, comm_err_t errcode, int xerrno);
-    void readClient(char *buf, size_t len, comm_err_t errcode, int xerrno);
-    void writeClientDone(char *buf, size_t len, comm_err_t flag, int xerrno);
-    void writeServerDone(char *buf, size_t len, comm_err_t flag, int xerrno);
+    void readServer(char *buf, size_t len, Comm::Flag errcode, int xerrno);
+    void readClient(char *buf, size_t len, Comm::Flag errcode, int xerrno);
+    void writeClientDone(char *buf, size_t len, Comm::Flag flag, int xerrno);
+    void writeServerDone(char *buf, size_t len, Comm::Flag flag, int xerrno);
 
-    static void ReadConnectResponseDone(const Comm::ConnectionPointer &, char *buf, size_t len, comm_err_t errcode, int xerrno, void *data);
-    void readConnectResponseDone(char *buf, size_t len, comm_err_t errcode, int xerrno);
+    static void ReadConnectResponseDone(const Comm::ConnectionPointer &, char *buf, size_t len, Comm::Flag errcode, int xerrno, void *data);
+    void readConnectResponseDone(char *buf, size_t len, Comm::Flag errcode, int xerrno);
 };
 
 static const char *const conn_established = "HTTP/1.1 200 Connection established\r\n\r\n";
@@ -321,7 +324,7 @@ TunnelStateData::Connection::debugLevelForError(int const xerrno) const
 
 /* Read from server side and queue it for writing to the client */
 void
-TunnelStateData::ReadServer(const Comm::ConnectionPointer &c, char *buf, size_t len, comm_err_t errcode, int xerrno, void *data)
+TunnelStateData::ReadServer(const Comm::ConnectionPointer &c, char *buf, size_t len, Comm::Flag errcode, int xerrno, void *data)
 {
     TunnelStateData *tunnelState = (TunnelStateData *)data;
     assert(cbdataReferenceValid(tunnelState));
@@ -331,16 +334,16 @@ TunnelStateData::ReadServer(const Comm::ConnectionPointer &c, char *buf, size_t
 }
 
 void
-TunnelStateData::readServer(char *buf, size_t len, comm_err_t errcode, int xerrno)
+TunnelStateData::readServer(char *buf, size_t len, Comm::Flag errcode, int xerrno)
 {
     debugs(26, 3, HERE << server.conn << ", read " << len << " bytes, err=" << errcode);
 
     /*
-     * Bail out early on COMM_ERR_CLOSING
+     * Bail out early on Comm::ERR_CLOSING
      * - close handlers will tidy up for us
      */
 
-    if (errcode == COMM_ERR_CLOSING)
+    if (errcode == Comm::ERR_CLOSING)
         return;
 
     if (len > 0) {
@@ -355,12 +358,12 @@ TunnelStateData::readServer(char *buf, size_t len, comm_err_t errcode, int xerrn
 
 /// Called when we read [a part of] CONNECT response from the peer
 void
-TunnelStateData::readConnectResponseDone(char *buf, size_t len, comm_err_t errcode, int xerrno)
+TunnelStateData::readConnectResponseDone(char *buf, size_t len, Comm::Flag errcode, int xerrno)
 {
     debugs(26, 3, server.conn << ", read " << len << " bytes, err=" << errcode);
     assert(waitingForConnectResponse());
 
-    if (errcode == COMM_ERR_CLOSING)
+    if (errcode == Comm::ERR_CLOSING)
         return;
 
     if (len > 0) {
@@ -376,7 +379,7 @@ TunnelStateData::readConnectResponseDone(char *buf, size_t len, comm_err_t errco
 
 /* Read from client side and queue it for writing to the server */
 void
-TunnelStateData::ReadConnectResponseDone(const Comm::ConnectionPointer &, char *buf, size_t len, comm_err_t errcode, int xerrno, void *data)
+TunnelStateData::ReadConnectResponseDone(const Comm::ConnectionPointer &, char *buf, size_t len, Comm::Flag errcode, int xerrno, void *data)
 {
     TunnelStateData *tunnelState = (TunnelStateData *)data;
     assert (cbdataReferenceValid (tunnelState));
@@ -467,7 +470,7 @@ TunnelStateData::Connection::error(int const xerrno)
 
 /* Read from client side and queue it for writing to the server */
 void
-TunnelStateData::ReadClient(const Comm::ConnectionPointer &, char *buf, size_t len, comm_err_t errcode, int xerrno, void *data)
+TunnelStateData::ReadClient(const Comm::ConnectionPointer &, char *buf, size_t len, Comm::Flag errcode, int xerrno, void *data)
 {
     TunnelStateData *tunnelState = (TunnelStateData *)data;
     assert (cbdataReferenceValid (tunnelState));
@@ -476,16 +479,16 @@ TunnelStateData::ReadClient(const Comm::ConnectionPointer &, char *buf, size_t l
 }
 
 void
-TunnelStateData::readClient(char *buf, size_t len, comm_err_t errcode, int xerrno)
+TunnelStateData::readClient(char *buf, size_t len, Comm::Flag errcode, int xerrno)
 {
     debugs(26, 3, HERE << client.conn << ", read " << len << " bytes, err=" << errcode);
 
     /*
-     * Bail out early on COMM_ERR_CLOSING
+     * Bail out early on Comm::ERR_CLOSING
      * - close handlers will tidy up for us
      */
 
-    if (errcode == COMM_ERR_CLOSING)
+    if (errcode == Comm::ERR_CLOSING)
         return;
 
     if (len > 0) {
@@ -500,7 +503,7 @@ TunnelStateData::readClient(char *buf, size_t len, comm_err_t errcode, int xerrn
 /// Updates state after reading from client or server.
 /// Returns whether the caller should use the data just read.
 bool
-TunnelStateData::keepGoingAfterRead(size_t len, comm_err_t errcode, int xerrno, Connection &from, Connection &to)
+TunnelStateData::keepGoingAfterRead(size_t len, Comm::Flag errcode, int xerrno, Connection &from, Connection &to)
 {
     debugs(26, 3, HERE << "from={" << from.conn << "}, to={" << to.conn << "}");
 
@@ -553,7 +556,7 @@ TunnelStateData::copy(size_t len, Connection &from, Connection &to, IOCB *comple
 
 /* Writes data from the client buffer to the server side */
 void
-TunnelStateData::WriteServerDone(const Comm::ConnectionPointer &, char *buf, size_t len, comm_err_t flag, int xerrno, void *data)
+TunnelStateData::WriteServerDone(const Comm::ConnectionPointer &, char *buf, size_t len, Comm::Flag flag, int xerrno, void *data)
 {
     TunnelStateData *tunnelState = (TunnelStateData *)data;
     assert (cbdataReferenceValid (tunnelState));
@@ -562,13 +565,13 @@ TunnelStateData::WriteServerDone(const Comm::ConnectionPointer &, char *buf, siz
 }
 
 void
-TunnelStateData::writeServerDone(char *buf, size_t len, comm_err_t flag, int xerrno)
+TunnelStateData::writeServerDone(char *buf, size_t len, Comm::Flag flag, int xerrno)
 {
     debugs(26, 3, HERE  << server.conn << ", " << len << " bytes written, flag=" << flag);
 
     /* Error? */
-    if (flag != COMM_OK) {
-        if (flag != COMM_ERR_CLOSING) {
+    if (flag != Comm::OK) {
+        if (flag != Comm::ERR_CLOSING) {
             debugs(26, 4, HERE << "calling TunnelStateData::server.error(" << xerrno <<")");
             server.error(xerrno); // may call comm_close
         }
@@ -602,7 +605,7 @@ TunnelStateData::writeServerDone(char *buf, size_t len, comm_err_t flag, int xer
 
 /* Writes data from the server buffer to the client side */
 void
-TunnelStateData::WriteClientDone(const Comm::ConnectionPointer &, char *buf, size_t len, comm_err_t flag, int xerrno, void *data)
+TunnelStateData::WriteClientDone(const Comm::ConnectionPointer &, char *buf, size_t len, Comm::Flag flag, int xerrno, void *data)
 {
     TunnelStateData *tunnelState = (TunnelStateData *)data;
     assert (cbdataReferenceValid (tunnelState));
@@ -623,13 +626,13 @@ TunnelStateData::Connection::dataSent(size_t amount)
 }
 
 void
-TunnelStateData::writeClientDone(char *buf, size_t len, comm_err_t flag, int xerrno)
+TunnelStateData::writeClientDone(char *buf, size_t len, Comm::Flag flag, int xerrno)
 {
     debugs(26, 3, HERE << client.conn << ", " << len << " bytes written, flag=" << flag);
 
     /* Error? */
-    if (flag != COMM_OK) {
-        if (flag != COMM_ERR_CLOSING) {
+    if (flag != Comm::OK) {
+        if (flag != Comm::ERR_CLOSING) {
             debugs(26, 4, HERE << "Closing client connection due to comm flags.");
             client.error(xerrno); // may call comm_close
         }
@@ -708,6 +711,7 @@ tunnelStartShoveling(TunnelStateData *tunnelState)
 {
     assert(!tunnelState->waitingForConnectExchange());
     *tunnelState->status_ptr = Http::scOkay;
+    *tunnelState->logTag_ptr = LOG_TCP_TUNNEL;
     if (cbdataReferenceValid(tunnelState)) {
 
         // Shovel any payload already pushed into reply buffer by the server response
@@ -726,7 +730,7 @@ tunnelStartShoveling(TunnelStateData *tunnelState)
             // We just need to ensure the bytes from ConnStateData are in client.buf already to deliver
             memcpy(tunnelState->client.buf, in->buf.rawContent(), in->buf.length());
             // NP: readClient() takes care of buffer length accounting.
-            tunnelState->readClient(tunnelState->client.buf, in->buf.length(), COMM_OK, 0);
+            tunnelState->readClient(tunnelState->client.buf, in->buf.length(), Comm::OK, 0);
             in->buf.consume(); // ConnStateData buffer accounting after the shuffle.
         } else
             tunnelState->copyRead(tunnelState->client, TunnelStateData::ReadClient);
@@ -739,12 +743,12 @@ tunnelStartShoveling(TunnelStateData *tunnelState)
  * Call the tunnelStartShoveling to start the blind pump.
  */
 static void
-tunnelConnectedWriteDone(const Comm::ConnectionPointer &conn, char *buf, size_t size, comm_err_t flag, int xerrno, void *data)
+tunnelConnectedWriteDone(const Comm::ConnectionPointer &conn, char *buf, size_t size, Comm::Flag flag, int xerrno, void *data)
 {
     TunnelStateData *tunnelState = (TunnelStateData *)data;
     debugs(26, 3, HERE << conn << ", flag=" << flag);
 
-    if (flag != COMM_OK) {
+    if (flag != Comm::OK) {
         *tunnelState->status_ptr = Http::scInternalServerError;
         tunnelErrorComplete(conn->fd, data, 0);
         return;
@@ -755,13 +759,13 @@ tunnelConnectedWriteDone(const Comm::ConnectionPointer &conn, char *buf, size_t
 
 /// Called when we are done writing CONNECT request to a peer.
 static void
-tunnelConnectReqWriteDone(const Comm::ConnectionPointer &conn, char *buf, size_t size, comm_err_t flag, int xerrno, void *data)
+tunnelConnectReqWriteDone(const Comm::ConnectionPointer &conn, char *buf, size_t size, Comm::Flag flag, int xerrno, void *data)
 {
     TunnelStateData *tunnelState = (TunnelStateData *)data;
     debugs(26, 3, conn << ", flag=" << flag);
     assert(tunnelState->waitingForConnectRequest());
 
-    if (flag != COMM_OK) {
+    if (flag != Comm::OK) {
         *tunnelState->status_ptr = Http::scInternalServerError;
         tunnelErrorComplete(conn->fd, data, 0);
         return;
@@ -820,17 +824,17 @@ tunnelErrorComplete(int fd/*const Comm::ConnectionPointer &*/, void *data, size_
 }
 
 static void
-tunnelConnectDone(const Comm::ConnectionPointer &conn, comm_err_t status, int xerrno, void *data)
+tunnelConnectDone(const Comm::ConnectionPointer &conn, Comm::Flag status, int xerrno, void *data)
 {
     TunnelStateData *tunnelState = (TunnelStateData *)data;
 
-    if (status != COMM_OK) {
+    if (status != Comm::OK) {
         debugs(26, 4, HERE << conn << ", comm failure recovery.");
         /* At this point only the TCP handshake has failed. no data has been passed.
          * we are allowed to re-try the TCP-level connection to alternate IPs for CONNECT.
          */
         tunnelState->serverDestinations.erase(tunnelState->serverDestinations.begin());
-        if (status != COMM_TIMEOUT && tunnelState->serverDestinations.size() > 0) {
+        if (status != Comm::TIMEOUT && tunnelState->serverDestinations.size() > 0) {
             /* Try another IP of this destination host */
             GetMarkingsToServer(tunnelState->request.getRaw(), *tunnelState->serverDestinations[0]);
             debugs(26, 4, HERE << "retry with : " << tunnelState->serverDestinations[0]);
@@ -929,6 +933,7 @@ tunnelStart(ClientHttpRequest * http, int64_t * size_ptr, int *status_ptr, const
     tunnelState->request = request;
     tunnelState->server.size_ptr = size_ptr;
     tunnelState->status_ptr = status_ptr;
+    tunnelState->logTag_ptr = &http->logType;
     tunnelState->client.conn = http->getConn()->clientConnection;
     tunnelState->http = http;
     tunnelState->al = al;
@@ -33,6 +33,7 @@
 
 #include "squid.h"
 #include "comm.h"
+#include "comm/Read.h"
 #include "comm/Write.h"
 #include "errorpage.h"
 #include "FwdState.h"
@@ -43,16 +44,14 @@
 #include "Store.h"
 #include "tools.h"
 
-#if HAVE_ERRNO_H
-#include <errno.h>
-#endif
+#include <cerrno>
 
 #define WHOIS_PORT 43
 
 class WhoisState
 {
 public:
-    void readReply(const Comm::ConnectionPointer &, char *aBuffer, size_t aBufferLength, comm_err_t flag, int xerrno);
+    void readReply(const Comm::ConnectionPointer &, char *aBuffer, size_t aBufferLength, Comm::Flag flag, int xerrno);
     void setReplyToOK(StoreEntry *sentry);
     StoreEntry *entry;
     HttpRequest::Pointer request;
@@ -73,7 +72,7 @@ static IOCB whoisReadReply;
 /* PUBLIC */
 
 static void
-whoisWriteComplete(const Comm::ConnectionPointer &, char *buf, size_t size, comm_err_t flag, int xerrno, void *data)
+whoisWriteComplete(const Comm::ConnectionPointer &, char *buf, size_t size, Comm::Flag flag, int xerrno, void *data)
 {
     xfree(buf);
 }
@@ -121,7 +120,7 @@ whoisTimeout(const CommTimeoutCbParams &io)
 }
 
 static void
-whoisReadReply(const Comm::ConnectionPointer &conn, char *buf, size_t len, comm_err_t flag, int xerrno, void *data)
+whoisReadReply(const Comm::ConnectionPointer &conn, char *buf, size_t len, Comm::Flag flag, int xerrno, void *data)
 {
     WhoisState *p = (WhoisState *)data;
     p->readReply(conn, buf, len, flag, xerrno);
@@ -137,17 +136,17 @@ WhoisState::setReplyToOK(StoreEntry *sentry)
 }
 
 void
-WhoisState::readReply(const Comm::ConnectionPointer &conn, char *aBuffer, size_t aBufferLength, comm_err_t flag, int xerrno)
+WhoisState::readReply(const Comm::ConnectionPointer &conn, char *aBuffer, size_t aBufferLength, Comm::Flag flag, int xerrno)
 {
-    /* Bail out early on COMM_ERR_CLOSING - close handlers will tidy up for us */
-    if (flag == COMM_ERR_CLOSING)
+    /* Bail out early on Comm::ERR_CLOSING - close handlers will tidy up for us */
+    if (flag == Comm::ERR_CLOSING)
         return;
 
     aBuffer[aBufferLength] = '\0';
     debugs(75, 3, HERE << conn << " read " << aBufferLength << " bytes");
     debugs(75, 5, "{" << aBuffer << "}");
 
-    if (flag != COMM_OK) {
+    if (flag != Comm::OK) {
         debugs(50, 2, HERE  << conn << ": read failure: " << xstrerror() << ".");
 
         if (ignoreErrno(errno)) {