@@ -1,3 +1,36 @@
+Changes to squid-3.1.0.13 (04 Aug 2009):
+
+	- Bug 2723 regression: enable PURGE requests if PURGE method ACL is present.
+	- Fix one more internal profiler error
+	- Language Updates: Italian, Russian
+	- Language Updates: Add many more aliases
+	- Add Copyright document for errors/ content
+	- ... all bug fixes from 3.0.STABLE18
+	- ... and several code polishing cleanups
+
+Changes to squid-3.1.0.12 (27 Jul 2009):
+
+	- Bug 2716: Chunked request Signed/Unsigned build error
+	- Bug 2674: Remove limit on HTTP headers read.
+	- Bug 2620: Invalid HTTP response codes causes segfault
+	- Fix FTP EPSV negotiation parser.
+	- Fix Via string when leak checking is enabled (valgrind etc)
+	- ... and several documentation and testing additions
+
+Changes to squid-3.1.0.11 (19 Jul 2009):
+
+	- Bug 2087: Support adaptation sets and chains
+	- Bug 2459: dns error message broken when error handling delayed
+	- Support ICAP Retry
+	- Support ICAP retries based on the ICAP responses status code
+	- Support logging ICAP
+	- Support logging total DNS wait time
+	- Support logging response times of adaptation transactions
+	- General logging enhancements
+	- Dynamically form chains based on ICAP X-Next-Services header
+	- Support cross-transactional ICAP header exchange
+	- ... and much adaptation polish and improvements
+
 Changes to squid-3.1.0.10 (18 Jul 2009):
 
 	- Bug 2680: Regression Crash after rotate with no helpers running
@@ -6,8 +39,9 @@ Changes to squid-3.1.0.10 (18 Jul 2009):
 	- Bug 422, 2706: RFC 2616 Date header requirements
 	- Bug 1087: ESI processor not quoting attributes correctly.
 	- Bug 1338: File prefetches aborted despite range_offset
-	- Bug 2127: delay pools class 4 crashes with ntlm auth
+	- Bug 2080: wbinfo_group.pl - false positive under certain conditions
 	- Bug 2092: select loop 32-bit call counter overflows
+	- Bug 2127: delay pools class 4 crashes with ntlm auth
 	- Bug 2611: document fast/slow acl types
 	- Bug 2614: Potential loss of adapted body data from eCAP adapters
 	- Bug 2658: Missing TextException copy constructor
@@ -182,6 +216,30 @@ Changes to squid-3.1.0.1 (27 Oct 2008):
 	- Bug #2223: Follow XFF extensions added
 	- ... and many code and documentation cleanups
 
+Changes to squid-3.0.STABLE18 (04 Aug 2009):
+
+	- Bug 2728: regression: assertion failed: !eof
+	- Bug 2732: reply_body_max_size smaller than error page loops
+	            infinitely until out of memory
+	- Bug 2725: pconn failure if domain or client_address are unset
+	- Bug 2648: reserved helpers not shut down after reconfigure/rotate
+	- Bug 2462: make check should tell when cppunit is missing
+	- Remove excess messages about headers < minimum size
+	- Support Libtool 2.2.6
+
+Changes to squid-3.0.STABLE17 (27 Jul 2009):
+
+	- Bug 2680 regression: Crash after rotate with no helpers running
+	- Bug 2710: squid_kerb_auth non-terminated string
+	- Bug 2679: strsep and strtoll detection failure
+	- Bug 2674: Remove limit on HTTP headers read.
+	- Bug 2659: String length overflows on append, leading to segfaults
+	- Bug 2620: Invalid HTTP response codes causes segfault
+	- Bug 2080: wbinfo_group.pl - false positive under certain conditions
+	- Bug 1087: ESI processor not quoting attributes correctly.
+	- Fix: issue with AUFS/UFS/DiskD writing objects to disk cache
+	- Several small build issues with previous release.
+
 Changes to squid-3.0.STABLE16 (15 Jun 2009):
 
 	- Bug 2672: cacheMemMaxSize 32-bit overflow during snmpwalk
@@ -40,3 +40,14 @@ EXTRA_DIST = \
 install-pinger:
 	chown root $(DESTDIR)$(DEFAULT_PINGER)
 	chmod 4711 $(DESTDIR)$(DEFAULT_PINGER)
+
+## hack to insert the test first, before building recursive child directories
+check: have-cppunit check-recursive
+
+have-cppunit:
+	@if test "@SQUID_CPPUNIT_INC@@SQUID_CPPUNIT_LA@@SQUID_CPPUNIT_LIBS@" = "" ; then \
+		echo "FATAL: 'make check' requires cppunit and cppunit development packages. They do not appear to be installed." ; \
+		exit 1 ; \
+	fi
+
+.PHONY: have-cppunit
@@ -9,11 +9,11 @@
 # the command line like "env acver=.. amver=... ./bootstrap.sh"
 acversions="${acver:-2.63 2.62 2.61}"
 amversions="${amver:-1.11 1.10 1.9}"
-ltversions="${ltver:-1.5 1.4}"
+ltversions="${ltver:-2 1.5 1.4}"
 
 check_version()
 {
-  eval $2 --version 2>/dev/null | grep -i "$1.*$3" >/dev/null
+  eval $2 --version 2>/dev/null | grep -i "$1.* $3" >/dev/null
 }
 
 find_version()
@@ -27,5 +27,23 @@
 #endif
 
 
+/*
+ * sys/capability.h is only needed in Linux apparently.
+ *
+ * HACK: LIBCAP_BROKEN Ugly glue to get around linux header madness colliding with glibc
+ */
+#if HAVE_SYS_CAPABILITY_H
+
+#if LIBCAP_BROKEN
+#undef _POSIX_SOURCE
+#define _LINUX_TYPES_H
+#define _LINUX_FS_H
+typedef uint32_t __u32;
+#endif
+
+#include <sys/capability.h>
+#endif /* HAVE_SYS_CAPABILITY_H */
+
+
 #endif /* _SQUID_LINUX_ */
 #endif /* SQUID_OS_LINUX_H */
@@ -4,13 +4,13 @@ dnl  $Id$
 dnl
 dnl
 dnl
-AC_INIT(Squid Web Proxy, 3.HEAD-BZR, http://www.squid-cache.org/bugs/, squid)
-AC_PREREQ(2.52)
-AM_CONFIG_HEADER(include/autoconf.h)
+AC_INIT([Squid Web Proxy],[3.HEAD-BZR],[http://www.squid-cache.org/bugs/],[squid])
+AC_PREREQ(2.61)
+AC_CONFIG_HEADERS([include/autoconf.h])
 AC_CONFIG_AUX_DIR(cfgaux)
 AC_CONFIG_SRCDIR([src/main.cc])
 AM_INIT_AUTOMAKE([tar-ustar nostdinc])
-AC_REVISION($Revision: 1.497 $)dnl
+AC_REVISION($Revision$)dnl
 AC_PREFIX_DEFAULT(/usr/local/squid)
 AM_MAINTAINER_MODE
 
@@ -26,7 +26,7 @@ dnl Check for GNU cc
 AC_PROG_CC
 AM_PROG_CC_C_O
 AC_PROG_CXX
-AC_LANG_CPLUSPLUS
+AC_LANG([C++])
 AC_CANONICAL_HOST
 
 dnl Make the squid top srcdir available to sub-packages as --with-squid=PATH
@@ -37,7 +37,7 @@ ac_configure_args="$new_configure_args"
 use_loadable_modules=1
 AC_MSG_CHECKING(whether to use loadable modules)
 AC_ARG_ENABLE(loadable-modules,
-    AC_HELP_STRING( [--disable-loadable-modules], [do not support loadable modules]) ,
+    AS_HELP_STRING([--disable-loadable-modules],[do not support loadable modules]) ,
     [
         case "${enableval}" in
             yes) use_loadable_modules=yes ;;
@@ -153,16 +153,14 @@ AC_DEFINE_UNQUOTED(SQUID_CONFIGURE_OPTIONS, "$ac_configure_args", [configure com
 
 CACHE_EFFECTIVE_USER="nobody"
 AC_ARG_WITH(default-user,
-  AC_HELP_STRING([--with-default-user=USER],
-                 [System user account for squid permissions. Default: nobody]),
+  AS_HELP_STRING([--with-default-user=USER],[System user account for squid permissions. Default: nobody]),
  [ CACHE_EFFECTIVE_USER="$withval" ]
 )
 AC_SUBST(CACHE_EFFECTIVE_USER)
 
 DEFAULT_LOG_DIR="$localstatedir/logs"
 AC_ARG_WITH(logdir,
-  AC_HELP_STRING([--with-logdir=PATH],
-                 Default location for squid logs. default: $DEFAULT_LOG_DIR),
+  AS_HELP_STRING([--with-logdir=PATH],[Default location for squid logs. default: $DEFAULT_LOG_DIR]),
  [ case $withval in
    yes|no)
      AC_MSG_ERROR( --with-logdir requires a directory PATH. --with-logdir=PATH )
@@ -177,8 +175,7 @@ AC_SUBST(DEFAULT_LOG_DIR)
 
 DEFAULT_PIDFILE="$localstatedir/squid.pid"
 AC_ARG_WITH(pidfile,
-  AC_HELP_STRING([--with-pidfile=PATH],
-                 Default location for squid PID file. default: $DEFAULT_PIDFILE),
+  AS_HELP_STRING([--with-pidfile=PATH],[Default location for squid PID file. default: $DEFAULT_PIDFILE]),
  [ case $withval in
    yes|no)
      AC_MSG_ERROR( --with-pidfile requires a file PATH. --with-pidfile=PATH )
@@ -302,8 +299,7 @@ fi
 SquidInline="yes"
 
 AC_ARG_ENABLE(optimizations,
-  AC_HELP_STRING([--disable-optimizations],
-                 [Don't compile Squid with compiler optimizations enabled.
+  AS_HELP_STRING([--disable-optimizations],[Don't compile Squid with compiler optimizations enabled.
                   Optimization is good for production builds, but not
                   good for debugging. During development, use
                   --disable-optimizations to reduce compilation times
@@ -318,8 +314,7 @@ AC_ARG_ENABLE(optimizations,
 ])
 
 AC_ARG_ENABLE(inline,
-  AC_HELP_STRING([--disable-inline],
-                 [Don't compile trivial methods as inline. Squid
+  AS_HELP_STRING([--disable-inline],[Don't compile trivial methods as inline. Squid
                   is coded with much of the code able to be inlined.
                   Inlining is good for production builds, but not
                   good for development. During development, use
@@ -342,8 +337,7 @@ else
 fi
 
 AC_ARG_ENABLE(debug-cbdata,
-  AC_HELP_STRING([--enable-debug-cbdata],
-                 [Provide some debug information in cbdata]),
+  AS_HELP_STRING([--enable-debug-cbdata],[Provide some debug information in cbdata]),
 [ if test "$enableval" = "yes" ; then
     AC_MSG_NOTICE([cbdata debugging enabled])
     AC_DEFINE(CBDATA_DEBUG,1,[Enable for cbdata debug information])
@@ -373,17 +367,15 @@ dnl   fi
 dnl ])
 
 AC_ARG_ENABLE(xmalloc-statistics,
-  AC_HELP_STRING([--enable-xmalloc-statistics],
-                 [Show malloc statistics in status page]),
+  AS_HELP_STRING([--enable-xmalloc-statistics],[Show malloc statistics in status page]),
 [ if test "$enableval" = "yes" ; then
     AC_MSG_NOTICE([malloc statistics enabled])
     AC_DEFINE(XMALLOC_STATISTICS,1,[Define to have malloc statistics])
   fi
 ])
 
 AC_ARG_ENABLE(async-io,
-  AC_HELP_STRING([--enable-async-io[=N_THREADS]],
-                 [Shorthand for "--with-aufs-threads=N_THREADS --with-pthreads
+  AS_HELP_STRING([--enable-async-io[=N_THREADS]],[Shorthand for "--with-aufs-threads=N_THREADS --with-pthreads
                   --enable-storeio=ufs,aufs"]),
 [ case $enableval in
   yes)
@@ -401,8 +393,7 @@ AC_ARG_ENABLE(async-io,
 ])
 
 AC_ARG_WITH(aufs-threads,
-  AC_HELP_STRING([--with-aufs-threads=N_THREADS],
-	               [Tune the number of worker threads for the aufs object store.]),
+  AS_HELP_STRING([--with-aufs-threads=N_THREADS],[Tune the number of worker threads for the aufs object store.]),
 [ case $withval in
   [[0-9]]*)
     aufs_io_threads=$withval
@@ -419,27 +410,26 @@ if test "$aufs_io_threads"; then
 fi
 
 AC_ARG_WITH(pthreads,
-  AC_HELP_STRING([--with-pthreads],[Use POSIX Threads]))
+  AS_HELP_STRING([--with-pthreads],[Use POSIX Threads]))
 if test "$with_pthreads" = "yes"; then
   AC_MSG_NOTICE([With pthreads])
 fi
 
 AC_ARG_WITH(aio,
-  AC_HELP_STRING([--with-aio],[Use POSIX AIO]))
+  AS_HELP_STRING([--with-aio],[Use POSIX AIO]))
 if test "$with_aio" = "yes"; then
   AC_MSG_NOTICE([With aio])
 fi
 
 
 AC_ARG_WITH(dl,
-  AC_HELP_STRING([--with-dl],[Use dynamic linking]))
+  AS_HELP_STRING([--with-dl],[Use dynamic linking]))
 if test "$with_dl" = "yes"; then
   AC_MSG_NOTICE([With dl])
 fi
 
 AC_ARG_ENABLE(storeio,
-  AC_HELP_STRING([--enable-storeio="list of modules"],
-                 [Build support for the list of store I/O modules.
+  AS_HELP_STRING([--enable-storeio="list of modules"],[Build support for the list of store I/O modules.
                   The default is only to build the "ufs" module.
                   See src/fs for a list of available modules, or
                   Programmers Guide section <not yet written>
@@ -549,8 +539,7 @@ AC_SUBST(STORE_LIBS_TO_ADD)
 AC_SUBST(STORE_TESTS)
 
 AC_ARG_ENABLE(disk-io,
-  AC_HELP_STRING([--enable-disk-io="list of modules"],
-                 [Build support for the list of disk I/O modules.
+  AS_HELP_STRING([--enable-disk-io="list of modules"],[Build support for the list of disk I/O modules.
                   If unset only the "Blocking" module will be built.
                   Set without a value all available modules will be built.
                   See src/DiskIO for a list of available modules, or
@@ -744,8 +733,7 @@ dnl 'lru' removal policy is currently hard-coded by name for tests
 dnl so we must set it as default.
 REPL_POLICIES="lru"
 AC_ARG_ENABLE(removal-policies,
-  AC_HELP_STRING([--enable-removal-policies="list of policies"],
-                 [Build support for the list of removal policies.
+  AS_HELP_STRING([--enable-removal-policies="list of policies"],[Build support for the list of removal policies.
                   The default is only to build the "lru" module.
                   See src/repl for a list of available modules, or
                   Programmers Guide section 9.9 for details on how
@@ -784,7 +772,7 @@ AC_SUBST(REPL_LIBS)
 
 AM_CONDITIONAL(ENABLE_PINGER, false)
 AC_ARG_ENABLE(icmp,
-  AC_HELP_STRING([--enable-icmp],[Enable ICMP pinging and Network Measurement]),
+  AS_HELP_STRING([--enable-icmp],[Enable ICMP pinging and Network Measurement]),
 [ if test "$enableval" = "yes" ; then
     AC_MSG_NOTICE([ICMP enabled])
     AC_DEFINE(USE_ICMP,1,[Define to use Squid's ICMP and Network Measurement features (highly recommended!)])
@@ -794,8 +782,7 @@ AC_ARG_ENABLE(icmp,
 
 AM_CONDITIONAL(USE_DELAY_POOLS, false)
 AC_ARG_ENABLE(delay-pools,
-  AC_HELP_STRING([--enable-delay-pools],
-                 [Enable delay pools to limit bandwidth usage]),
+  AS_HELP_STRING([--enable-delay-pools],[Enable delay pools to limit bandwidth usage]),
 [ if test "$enableval" = "yes" ; then
     AC_MSG_NOTICE([Delay pools enabled])
     AC_DEFINE([DELAY_POOLS],1,[Traffic management via "delay pools".])
@@ -808,8 +795,7 @@ use_adaptation=no
 
 AM_CONDITIONAL(USE_ESI, false)
 AC_ARG_ENABLE(esi,
-  AC_HELP_STRING([--enable-esi],
-                 [Enable ESI for accelerators. Requires libexpat.
+  AS_HELP_STRING([--enable-esi],[Enable ESI for accelerators. Requires libexpat.
                   Enabling ESI will cause squid to follow the
                   Edge Acceleration Specification (www.esi.org).
                   This causes squid to IGNORE client Cache-Control headers.
@@ -838,7 +824,7 @@ fi
 
 AM_CONDITIONAL(USE_ICAP_CLIENT, false)
 AC_ARG_ENABLE(icap-client,
-  AC_HELP_STRING([--enable-icap-client],[Enable the ICAP client.]),
+  AS_HELP_STRING([--enable-icap-client],[Enable the ICAP client.]),
 	      use_icap_client=$enableval, use_icap_client=no)
 if test "$use_icap_client" = "yes" ; then
   AC_DEFINE(ICAP_CLIENT,1,[Enable ICAP client features in Squid])
@@ -854,8 +840,7 @@ AC_SUBST(ICAP_LIBS)
 use_ecap=1
 AC_MSG_CHECKING(whether to support eCAP)
 AC_ARG_ENABLE(ecap,
-  AC_HELP_STRING([--enable-ecap],
-                 [support loadable content adaptation modules]),
+  AS_HELP_STRING([--enable-ecap],[support loadable content adaptation modules]),
     [
         case "${enableval}" in
             yes) use_ecap=yes ;;
@@ -927,8 +912,7 @@ dnl   fi
 dnl ])     
 
 AC_ARG_ENABLE(useragent-log,
-  AC_HELP_STRING([--enable-useragent-log],
-                 [Enable logging of User-Agent header]),
+  AS_HELP_STRING([--enable-useragent-log],[Enable logging of User-Agent header]),
 [ if test "$enableval" = "yes" ; then
     AC_MSG_NOTICE([User-Agent logging enabled])
     AC_DEFINE(USE_USERAGENT_LOG,1,[If you want to log User-Agent request header values, define this.
@@ -938,7 +922,7 @@ AC_ARG_ENABLE(useragent-log,
 ])
 
 AC_ARG_ENABLE(referer-log,
-  AC_HELP_STRING([--enable-referer-log],[Enable logging of Referer header]),
+  AS_HELP_STRING([--enable-referer-log],[Enable logging of Referer header]),
 [ if test "$enableval" = "yes" ; then
     AC_MSG_NOTICE([Referer logging enabled])
     AC_DEFINE(USE_REFERER_LOG,1,[If you want to log Referer request header values, define this.
@@ -949,7 +933,7 @@ AC_ARG_ENABLE(referer-log,
 
 USE_WCCP=1
 AC_ARG_ENABLE(wccp,  
-  AC_HELP_STRING([--disable-wccp],[Disable Web Cache Coordination Protocol]),
+  AS_HELP_STRING([--disable-wccp],[Disable Web Cache Coordination Protocol]),
 [ if test "$enableval" = "no" ; then
     AC_MSG_NOTICE([Web Cache Coordination Protocol disabled])
     USE_WCCP=0
@@ -961,8 +945,7 @@ fi
 
 USE_WCCPv2=1
 AC_ARG_ENABLE(wccpv2,
-  AC_HELP_STRING([--disable-wccpv2],
-                 [Disable Web Cache Coordination V2 Protocol]),
+  AS_HELP_STRING([--disable-wccpv2],[Disable Web Cache Coordination V2 Protocol]),
 [ if test "$enableval" = "no" ; then
     AC_MSG_NOTICE(["Web Cache Coordination V2 Protocol disabled])
     USE_WCCPv2=0
@@ -973,7 +956,7 @@ if test $USE_WCCPv2 = 1; then
 fi
 
 AC_ARG_ENABLE(kill-parent-hack,
-  AC_HELP_STRING([--enable-kill-parent-hack],[Kill parent on shutdown]),
+  AS_HELP_STRING([--enable-kill-parent-hack],[Kill parent on shutdown]),
 [ if test "$enableval" = "yes" ; then
     AC_MSG_NOTICE([Kill parent on shutdown])
     AC_DEFINE(KILL_PARENT_OPT,1,[A dangerous feature which causes Squid to kill its parent process
@@ -984,7 +967,7 @@ AC_ARG_ENABLE(kill-parent-hack,
 
 USE_SNMP=true
 AC_ARG_ENABLE(snmp,
-  AC_HELP_STRING([--disable-snmp],[Disable SNMP monitoring support]),
+  AS_HELP_STRING([--disable-snmp],[Disable SNMP monitoring support]),
 [ if test "$enableval" = "no" ; then
     AC_MSG_NOTICE([SNMP monitoring disabled])
     USE_SNMP=
@@ -1000,8 +983,7 @@ AC_SUBST(SNMPLIB)
 AC_SUBST(makesnmplib)
 
 AC_ARG_ENABLE(cachemgr-hostname,
-  AC_HELP_STRING([--enable-cachemgr-hostname=hostname],
-                 [Make cachemgr.cgi default to this host.
+  AS_HELP_STRING([--enable-cachemgr-hostname=hostname],[Make cachemgr.cgi default to this host.
                   If unspecified, uses the name of the build-host]),
 [  case $enableval in
    yes)
@@ -1021,8 +1003,7 @@ AC_ARG_ENABLE(cachemgr-hostname,
 
 AM_CONDITIONAL(ENABLE_ARP_ACL, false)
 AC_ARG_ENABLE(arp-acl,
-  AC_HELP_STRING([--enable-arp-acl],
-                 [Enable use of ARP ACL lists (ether address)]),
+  AS_HELP_STRING([--enable-arp-acl],[Enable use of ARP ACL lists (ether address)]),
 [  if test "$enableval" = "yes" ; then
      AC_MSG_NOTICE([ARP ACL lists enabled (ether address)])
      case "$host" in
@@ -1055,7 +1036,7 @@ AC_ARG_ENABLE(arp-acl,
 USE_HTCP=true
 AM_CONDITIONAL(ENABLE_HTCP, false)
 AC_ARG_ENABLE(htcp,
-  AC_HELP_STRING([--disable-htcp],[Disable HTCP protocol support]),
+  AS_HELP_STRING([--disable-htcp],[Disable HTCP protocol support]),
 [ if test "$enableval" = "no" ; then
     AC_MSG_NOTICE([HTCP support disabled])
   fi
@@ -1070,7 +1051,7 @@ AM_CONDITIONAL(ENABLE_SSL, false)
 
 dnl Default is to use OpenSSL when available
 AC_ARG_ENABLE(ssl,
-  AC_HELP_STRING([--enable-ssl],[Enable ssl gatewaying support using OpenSSL]),
+  AS_HELP_STRING([--enable-ssl],[Enable ssl gatewaying support using OpenSSL]),
 [ if test "$enableval" != "no"; then
     AC_MSG_NOTICE([SSL gatewaying using OpenSSL enabled])
     AC_DEFINE(USE_SSL,1,[Define this to include code for SSL encryption.])
@@ -1090,8 +1071,7 @@ AC_ARG_ENABLE(ssl,
 
 dnl User may specify OpenSSL is needed from a non-standard location
 AC_ARG_WITH(openssl,
-  AC_HELP_STRING([--with-openssl{=PATH}],
-                 [Compile with the OpenSSL libraries. The path to
+  AS_HELP_STRING([--with-openssl{=PATH}],[Compile with the OpenSSL libraries. The path to
                   the OpenSSL development libraries and headers
                   installation can be specified if outside of the
                   system standard directories]),
@@ -1129,16 +1109,15 @@ AC_SUBST(SSLLIB)
 
 
 AC_ARG_ENABLE(forw-via-db,
-  AC_HELP_STRING([--enable-forw-via-db],[Enable Forw/Via database]),
+  AS_HELP_STRING([--enable-forw-via-db],[Enable Forw/Via database]),
 [ if test "$enableval" = "yes" ; then
     AC_MSG_NOTICE([FORW-VIA enabled])
     AC_DEFINE(FORW_VIA_DB,1,[Enable Forw/Via database])
   fi
 ])
 
 AC_ARG_ENABLE(cache-digests,
-  AC_HELP_STRING([--enable-cache-digests],
-                 [Use Cache Digests.
+  AS_HELP_STRING([--enable-cache-digests],[Use Cache Digests.
                   See http://wiki.squid-cache.org/SquidFaq/CacheDigests]),
 [ if test "$enableval" = "yes" ; then
     AC_MSG_NOTICE([Cache Disgests enabled])
@@ -1148,8 +1127,7 @@ AC_ARG_ENABLE(cache-digests,
 
 dnl Size of COSS memory buffer
 AC_ARG_WITH(coss-membuf-size,
-  AC_HELP_STRING([--with-coss-membuf-size=size],
-                 [COSS membuf size (default 1048576 bytes)]),
+  AS_HELP_STRING([--with-coss-membuf-size=size],[COSS membuf size (default 1048576 bytes)]),
 [  if test -n "$withval" -a "x$withval" != "xno" ; then
       AC_MSG_NOTICE([Setting COSS membuf size to $with_coss_membuf_size bytes])
       AC_DEFINE_UNQUOTED(COSS_MEMBUF_SZ, $with_coss_membuf_size,[Define if you want to set the COSS membuf size])
@@ -1161,7 +1139,7 @@ dnl check for netio plugin stuff
 dnl Enable poll()
 disable_poll=
 AC_ARG_ENABLE(poll,
-  AC_HELP_STRING([--disable-poll],[Disable poll(2) support.]),
+  AS_HELP_STRING([--disable-poll],[Disable poll(2) support.]),
 [
   case "$enableval" in
   yes)
@@ -1178,7 +1156,7 @@ AC_ARG_ENABLE(poll,
 dnl Enable select()
 disable_select=
 AC_ARG_ENABLE(select,
-  AC_HELP_STRING([--disable-select],[Disable select(2) support.]),
+  AS_HELP_STRING([--disable-select],[Disable select(2) support.]),
 [
   case "$enableval" in
   yes)
@@ -1196,7 +1174,7 @@ dnl Enable kqueue()
 dnl kqueue support is still experiemntal and unstable. Not enabled by default.
 disable_kqueue=true
 AC_ARG_ENABLE(kqueue,
-  AC_HELP_STRING([--enable-kqueue],[Enable kqueue(2) support (experimental).]),
+  AS_HELP_STRING([--enable-kqueue],[Enable kqueue(2) support (experimental).]),
 [
   case "$enableval" in
   yes)
@@ -1219,7 +1197,7 @@ dnl Enable epoll()
 disable_epoll=
 force_epoll="no"
 AC_ARG_ENABLE(epoll,
-  AC_HELP_STRING([--disable-epoll],[Disable Linux epoll(2) support.]),
+  AS_HELP_STRING([--disable-epoll],[Disable Linux epoll(2) support.]),
 [
   case "$enableval" in
   yes)
@@ -1258,7 +1236,7 @@ if test -z "$disable_epoll"; then
   dnl Verify that epoll really works
   if test $ac_cv_func_epoll_ctl = yes; then
     AC_CACHE_CHECK(if epoll works, ac_cv_epoll_works,
-      AC_TRY_RUN([
+      AC_RUN_IFELSE([AC_LANG_SOURCE([[
 #include <sys/epoll.h>
 #include <stdlib.h>
 #include <stdio.h>
@@ -1267,11 +1245,11 @@ int main(int argc, char **argv)
     int fd = epoll_create(256);
     if (fd < 0) {
 	perror("epoll_create:");
-	exit(1);
+	return 1;
     }
-    exit(0);
+    return 0;
 }
-      ], [ac_cv_epoll_works=yes], [ac_cv_epoll_works=no]))
+      ]])],[ac_cv_epoll_works=yes],[ac_cv_epoll_works=no],[]))
   fi
 
   if test "$force_epoll" = "yes" && test "$ac_cv_epoll_works" = "no" ; then
@@ -1282,8 +1260,7 @@ fi
 dnl Disable HTTP violations
 http_violations=1
 AC_ARG_ENABLE(http-violations,
-  AC_HELP_STRING([--disable-http-violations],
-                 [This allows you to remove code which is known to
+  AS_HELP_STRING([--disable-http-violations],[This allows you to remove code which is known to
                   violate the HTTP protocol specification.]),
 [ if test "$enableval" = "no" ; then
     AC_MSG_NOTICE([Disabling HTTP Violations])
@@ -1298,8 +1275,7 @@ fi
 
 dnl Enable IPFW Transparent Proxy
 AC_ARG_ENABLE(ipfw-transparent,
-  AC_HELP_STRING([--enable-ipfw-transparent],
-                 [Enable Transparent Proxy support for systems
+  AS_HELP_STRING([--enable-ipfw-transparent],[Enable Transparent Proxy support for systems
                   using FreeBSD IPFW style redirection.]),
 [ if test "$enableval" = "yes" ; then
 	AC_MSG_NOTICE([IPFW Transparent Proxy enabled])
@@ -1312,8 +1288,7 @@ AC_ARG_ENABLE(ipfw-transparent,
 
 dnl Enable IP-Filter Transparent Proxy
 AC_ARG_ENABLE(ipf-transparent,
-  AC_HELP_STRING([--enable-ipf-transparent],
-                 [Enable Transparent Proxy support for systems
+  AS_HELP_STRING([--enable-ipf-transparent],[Enable Transparent Proxy support for systems
                   using IP-Filter network address redirection.]),
 [ if test "$enableval" = "yes" ; then
 	AC_MSG_NOTICE([IP-Filter Transparent Proxy enabled])
@@ -1326,8 +1301,7 @@ AC_ARG_ENABLE(ipf-transparent,
 
 dnl Enable PF Transparent Proxy
 AC_ARG_ENABLE(pf-transparent,
-  AC_HELP_STRING([--enable-pf-transparent],
-                 [Enable Transparent Proxy support for systems
+  AS_HELP_STRING([--enable-pf-transparent],[Enable Transparent Proxy support for systems
                   using PF network address redirection.]),
 [ if test "$enableval" = "yes" ; then
 	AC_MSG_NOTICE([PF Transparent Proxy enabled])
@@ -1340,8 +1314,7 @@ AC_ARG_ENABLE(pf-transparent,
 
 dnl Enable Linux Netfilter Transparent Proxy
 AC_ARG_ENABLE(linux-netfilter,
-  AC_HELP_STRING([--enable-linux-netfilter],
-                 [Enable Transparent Proxy support for Linux (Netfilter)]),
+  AS_HELP_STRING([--enable-linux-netfilter],[Enable Transparent Proxy support for Linux (Netfilter)]),
 [ if test "$enableval" = "yes" ; then
 	AC_MSG_NOTICE([Linux (Netfilter) Transparent Proxy enabled])
 	AC_DEFINE(LINUX_NETFILTER,1,[Enable support for Transparent Proxy on Linux (Netfilter) systems])
@@ -1356,14 +1329,14 @@ buildmodel=""
 needlargefiles=
 
 AC_ARG_WITH(large-files,
-  AC_HELP_STRING([--with-large-files],[Enable support for large files (logs etc).]),
+  AS_HELP_STRING([--with-large-files],[Enable support for large files (logs etc).]),
 [ if test "x$withval" = "xyes"; then
 	needlargefiles=1
   fi
 ])
 
 dnl UNIX Build environment
-dnl AC_HELP_STRING is not suited here because it doesn't allow to specify newlines
+dnl AS_HELP_STRING is not suited here because it doesn't allow to specify newlines
 AC_ARG_WITH(build-environment,
 [  --with-build-environment=model
                           The build environment to use. Normally one of
@@ -1463,8 +1436,7 @@ esac
 
 dnl Enable Linux transparent proxy support for obsolete TPROXY
 AC_ARG_ENABLE(linux-tproxy,
-  AC_HELP_STRING([--enable-linux-tproxy],
-			     [Enable real Transparent Proxy support for Netfilter TPROXY 
+  AS_HELP_STRING([--enable-linux-tproxy],[Enable real Transparent Proxy support for Netfilter TPROXY 
                   (version 2).]),
 [ if test "$enableval" = "yes" ; then
 	AC_MSG_NOTICE(["Linux Netfilter/TPROXY v2 enabled])
@@ -1482,8 +1454,7 @@ AC_ARG_ENABLE(linux-tproxy,
 AM_CONDITIONAL(MAKE_LEAKFINDER, false)
 dnl Enable Leak Finding Functions
 AC_ARG_ENABLE(leakfinder,
-  AC_HELP_STRING([--enable-leakfinder],
-                 [Enable Leak Finding code.  Enabling this alone
+  AS_HELP_STRING([--enable-leakfinder],[Enable Leak Finding code.  Enabling this alone
                   does nothing; you also have to modify the source
 			      code to use the leak finding functions.  Probably
 			      Useful for hackers only.]),
@@ -1497,8 +1468,7 @@ AC_ARG_ENABLE(leakfinder,
 
 follow_xff=1
 AC_ARG_ENABLE(follow-x-forwarded-for,
-  AC_HELP_STRING([--enable-follow-x-forwarded-for],
-                 [Enable support for following the X-Forwarded-For
+  AS_HELP_STRING([--enable-follow-x-forwarded-for],[Enable support for following the X-Forwarded-For
                  HTTP header to try to find the IP address of the
                  original or indirect client when a request has
                  been forwarded through other proxies.]),
@@ -1515,8 +1485,7 @@ fi
 
 use_ident=1
 AC_ARG_ENABLE(ident-lookups,
-  AC_HELP_STRING([--disable-ident-lookups],
-                 [This allows you to remove code that performs Ident (RFC 931) lookups.]),
+  AS_HELP_STRING([--disable-ident-lookups],[This allows you to remove code that performs Ident (RFC 931) lookups.]),
 [ if test "$enableval" = "no" ; then
     AC_MSG_NOTICE([Disabling Ident Lookups])
     use_ident=0
@@ -1531,8 +1500,7 @@ fi
 AM_CONDITIONAL(USE_DNSSERVER, false)
 use_dnsserver=
 AC_ARG_ENABLE(internal-dns,
-  AC_HELP_STRING([--disable-internal-dns],
-                 [Prevents Squid from directly sending and receiving DNS messages, 
+  AS_HELP_STRING([--disable-internal-dns],[Prevents Squid from directly sending and receiving DNS messages, 
                   and instead enables the old external 'dnsserver' processes.]),
 [ if test "$enableval" = "no" ; then
     AC_MSG_WARN([Disabling Internal DNS queries])
@@ -1546,8 +1514,7 @@ fi
 
 dnl Select Default hosts file location
 AC_ARG_ENABLE(default-hostsfile,
-  AC_HELP_STRING([--enable-default-hostsfile=path],
-                 [Select default location for hosts file.
+  AS_HELP_STRING([--enable-default-hostsfile=path],[Select default location for hosts file.
                   See hosts_file directive in squid.conf for details]),
 [
     if test "$enableval" != "none" ; then
@@ -1566,8 +1533,7 @@ AC_SUBST(OPT_DEFAULT_HOSTS)
 
 dnl Select auth schemes modules to build
 AC_ARG_ENABLE(auth,
-  AC_HELP_STRING([--enable-auth="list of auth scheme modules"],
-                 [Build support for the list of authentication schemes.
+  AS_HELP_STRING([--enable-auth="list of auth scheme modules"],[Build support for the list of authentication schemes.
                   The default is to build support for the Basic scheme.
                   See src/auth for a list of available modules, or
                   Programmers Guide section authentication schemes
@@ -1626,8 +1592,7 @@ if test -n "$AUTH_MODULE_basic"; then
 	BASIC_AUTH_HELPERS="all"
 fi
 AC_ARG_ENABLE(basic-auth-helpers,
-  AC_HELP_STRING([--enable-basic-auth-helpers="list of helpers"],
-                 [This option selects which basic scheme proxy_auth
+  AS_HELP_STRING([--enable-basic-auth-helpers="list of helpers"],[This option selects which basic scheme proxy_auth
                   helpers to build and install as part of the normal 
                   build process. For a list of available
                   helpers see the helpers/basic_auth directory.]),
@@ -1677,8 +1642,7 @@ if test -n "$AUTH_MODULE_ntlm"; then
 	NTLM_AUTH_HELPERS="all"
 fi
 AC_ARG_ENABLE(ntlm-auth-helpers,
-  AC_HELP_STRING([--enable-ntlm-auth-helpers="list of helpers"],
-                [This option selects which proxy_auth ntlm helpers
+  AS_HELP_STRING([--enable-ntlm-auth-helpers="list of helpers"],[This option selects which proxy_auth ntlm helpers
                  to build and install as part of the normal build 
                  process. For a list of available helpers see
                  the helpers/ntlm_auth directory.]),
@@ -1720,8 +1684,7 @@ if test -n "$AUTH_MODULE_negotiate"; then
 	NEGOTIATE_AUTH_HELPERS="all"
 fi
 AC_ARG_ENABLE(negotiate-auth-helpers,
-  AC_HELP_STRING([--enable-negotiate-auth-helpers="list of helpers"],
-                 [This option selects which proxy_auth negotiate helpers
+  AS_HELP_STRING([--enable-negotiate-auth-helpers="list of helpers"],[This option selects which proxy_auth negotiate helpers
                   to build and install as part of the normal build 
                   process. For a list of available helpers see
                   the helpers/negotiate_auth directory.]),
@@ -1764,8 +1727,7 @@ if test -n "$AUTH_MODULE_digest"; then
 	DIGEST_AUTH_HELPERS=all
 fi
 AC_ARG_ENABLE(digest-auth-helpers,
-  AC_HELP_STRING([--enable-digest-auth-helpers="list of helpers"],
-                 [This option selects which digest scheme authentication
+  AS_HELP_STRING([--enable-digest-auth-helpers="list of helpers"],[This option selects which digest scheme authentication
                   helpers to build and install as part of the normal build
                   process. For a list of available helpers see the
                   helpers/digest_auth directory.]),
@@ -1804,8 +1766,7 @@ AC_SUBST(DIGEST_AUTH_HELPERS)
 
 dnl Enable "NTLM fail open"
 AC_ARG_ENABLE(ntlm-fail-open,
-  AC_HELP_STRING([--enable-ntlm-fail-open],
-                 [Enable NTLM fail open, where a helper that fails one of the
+  AS_HELP_STRING([--enable-ntlm-fail-open],[Enable NTLM fail open, where a helper that fails one of the
                   Authentication steps can allow squid to still authenticate
                   the user.]),
 [ if test "$enableval" = "yes" ; then
@@ -1816,8 +1777,7 @@ AC_ARG_ENABLE(ntlm-fail-open,
 dnl Select external_acl helpers to build
 EXTERNAL_ACL_HELPERS=all
 AC_ARG_ENABLE(external-acl-helpers,
-  AC_HELP_STRING([--enable-external-acl-helpers="list of helpers"],
-                 [This option selects which external_acl helpers to
+  AS_HELP_STRING([--enable-external-acl-helpers="list of helpers"],[This option selects which external_acl helpers to
                   build and install as part of the normal build
                   process. For a list of available helpers see the
                   helpers/external_acl directory.]),
@@ -1897,8 +1857,7 @@ AC_SUBST(URL_REWRITE_HELPERS)
 
 
 AC_ARG_WITH(valgrind-debug,
-  AC_HELP_STRING([--with-valgrind-debug],
-                 [Include debug instrumentation for use with valgrind]),
+  AS_HELP_STRING([--with-valgrind-debug],[Include debug instrumentation for use with valgrind]),
 [ case $withval in
   yes)
 	valgrind=1
@@ -1922,8 +1881,7 @@ AC_ARG_WITH(valgrind-debug,
 
 dnl Disable "memPools" code
 AC_ARG_ENABLE(mempools,
-  AC_HELP_STRING([--disable-mempools],
-                 [Disable memPools. Note that this option now simply sets the
+  AS_HELP_STRING([--disable-mempools],[Disable memPools. Note that this option now simply sets the
 			      default behaviour. Specific classes can override this at runtime, and
 			      only lib/MemPool.c needs to be altered to change the squid-wide 
 			      default for all classes.]),
@@ -1939,8 +1897,7 @@ AC_ARG_ENABLE(mempools,
 
 dnl Enable WIN32 Service compile mode
 AC_ARG_ENABLE(win32-service,
-  AC_HELP_STRING([--enable-win32-service],
-                 [Compile Squid as a WIN32 Service.
+  AS_HELP_STRING([--enable-win32-service],[Compile Squid as a WIN32 Service.
                   Works only on MS-Windows platforms (NT and up).]),
 [ if test "$enableval" = "yes" ; then
     AC_MSG_NOTICE([Enabling WIN32 run service mode])
@@ -1968,7 +1925,7 @@ fi
 
 dnl Disable "unlinkd" code
 AC_ARG_ENABLE(unlinkd,
-  AC_HELP_STRING([--disable-unlinkd],[Do not use unlinkd]),
+  AS_HELP_STRING([--disable-unlinkd],[Do not use unlinkd]),
 [ if test "$enableval" = "no" ; then
     use_unlinkd=no
   else
@@ -1990,8 +1947,7 @@ fi
 
 dnl Enable backtraces on fatal errors
 AC_ARG_ENABLE(stacktraces,
-  AC_HELP_STRING([--enable-stacktraces],
-                 [Enable automatic call backtrace on fatal errors]),
+  AS_HELP_STRING([--enable-stacktraces],[Enable automatic call backtrace on fatal errors]),
 [ if test "$enableval" = "yes" ; then
     AC_MSG_NOTICE([Enabling automatic stack backtraces on fatal errors])
     AC_DEFINE(PRINT_STACK_TRACE, 1,[Print stacktraces on fatal errors])
@@ -2001,8 +1957,7 @@ AC_ARG_ENABLE(stacktraces,
 AM_CONDITIONAL(ENABLE_XPROF_STATS, false)
 dnl Enable USE_XPROF_STATS
 AC_ARG_ENABLE(cpu-profiling,
-  AC_HELP_STRING([--enable-cpu-profiling],
-                 [Enable instrumentation to try and understand how CPU power 
+  AS_HELP_STRING([--enable-cpu-profiling],[Enable instrumentation to try and understand how CPU power 
                   is spent by squid, by enabling specific probes in selected
                   functions. New probes can only be added by modifying the source code.
                   It is meant to help developers in optimizing performance
@@ -2018,8 +1973,7 @@ AC_ARG_ENABLE(cpu-profiling,
 
 dnl Enable X-Accelerator-Vary for Vary support within an accelerator setup
 AC_ARG_ENABLE(x-accelerator-vary,
-  AC_HELP_STRING([--enable-x-accelerator-vary],
-                 [Enable support for the X-Accelerator-Vary
+  AS_HELP_STRING([--enable-x-accelerator-vary],[Enable support for the X-Accelerator-Vary
                   HTTP header. Can be used to indicate
                   variance within an accelerator setup.
                   Typically used together with other code
@@ -2031,7 +1985,7 @@ AC_ARG_ENABLE(x-accelerator-vary,
 ])
 
 AC_ARG_ENABLE(zph-qos,
-  AC_HELP_STRING([--enable-zph-qos],[Enable ZPH QOS support]),
+  AS_HELP_STRING([--enable-zph-qos],[Enable ZPH QOS support]),
 [ if test "$enableval" = "yes" ; then
     AC_MSG_NOTICE([ZPH QOS enabled])
     AC_DEFINE(USE_ZPH_QOS,1,
@@ -2054,8 +2008,7 @@ AC_ARG_WITH(maxfd,,
     esac
 ])
 AC_ARG_WITH(filedescriptors,
-  AC_HELP_STRING([--with-filedescriptors=NUMBER],
-                 [Force squid to support NUMBER filedescriptors]),
+  AS_HELP_STRING([--with-filedescriptors=NUMBER],[Force squid to support NUMBER filedescriptors]),
 [ 
   case ${withval} in
     [[0-9]]*)
@@ -2081,8 +2034,7 @@ else
 fi
 
 AC_ARG_WITH(cppunit-basedir,
-  AC_HELP_STRING([--with-cppunit-basedir=PATH],
-                 [Path where the cppunit headers are libraries are found 
+  AS_HELP_STRING([--with-cppunit-basedir=PATH],[Path where the cppunit headers are libraries are found 
                   for unit testing.]),
 [ if test -f $withval/include/cppunit/TestCase.h; then
 	AC_MSG_NOTICE([Using cppunit includes from $withval])
@@ -2096,7 +2048,6 @@ AC_ARG_WITH(cppunit-basedir,
 	SQUID_CPPUNIT_LIBS='$(SQUID_CPPUNIT_LA)'
     else
 	AC_MSG_ERROR(Cannot find cppunit at $withval)
-	exit 1
     fi
 ])
 AC_SUBST(SQUID_CPPUNIT_LIBS)
@@ -2257,8 +2208,7 @@ AC_CHECK_HEADERS( \
 	inttypes.h \
 	grp.h \
 	db.h \
-	db_185.h \
-	sys/capability.h
+	db_185.h
 )
 
 AC_CHECK_HEADERS(
@@ -2525,6 +2475,17 @@ AC_CHECK_TYPE(socklen_t,AC_DEFINE(HAVE_SOCKLEN_T,1,[socklen_t is defined by the
 #include <stddef.h>
 #endif])
 
+dnl Check for libcap1 breakage or libcap2 fixed
+AC_CHECK_HEADERS(sys/capability.h)
+libcap_broken=1
+AC_CACHE_CHECK([for operational libcap2], $libcap_broken,
+  AC_LINK_IFELSE([AC_LANG_PROGRAM([[#include <sys/capability.h>]], [[
+                  capget(NULL, NULL);
+                  capset(NULL, NULL);
+                 ]])],[libcap_broken=0],[])
+)
+AC_DEFINE_UNQUOTED([LIBCAP_BROKEN],$libcap_broken,[if libcap2 is available and not clashing with libc])
+
 AC_CHECK_TYPE(mtyp_t,AC_DEFINE(HAVE_MTYP_T,1,[mtyp_t is defined by the system headers]),,[#include <sys/types.h>
 #include <sys/ipc.h>
 #include <sys/msg.h>])
@@ -2539,14 +2500,12 @@ case "$host_os" in
     save_LIBS="$LIBS"
     for curlib in ws2_32 wsock32; do
 	LIBS="$LIBS -l$curlib"
-	AC_TRY_LINK([#include <winsock.h>],
-			[
+	AC_LINK_IFELSE([AC_LANG_PROGRAM([[#include <winsock.h>]], [[
 			socket(0,0,0);
 			select(0,NULL,NULL,NULL,NULL);
 			closesocket(0);
 			gethostname(NULL,0);
-			],
-			have_winsock=yes, have_winsock=no)
+			]])],[have_winsock=yes],[have_winsock=no])
 
 	if test $have_winsock = yes; then
 		ac_cv_func_select='yes'
@@ -2568,17 +2527,15 @@ esac
 
 dnl Ripped from the Samba sources
 AC_CACHE_CHECK([for unix domain sockets],squid_cv_unixsocket, [
-    AC_TRY_COMPILE([
+    AC_COMPILE_IFELSE([AC_LANG_PROGRAM([[
 #include <sys/types.h>
 #include <stdlib.h>
 #include <stddef.h>
 #include <sys/socket.h>
-#include <sys/un.h>],
-[
+#include <sys/un.h>]], [[
   struct sockaddr_un sunaddr; 
   sunaddr.sun_family = AF_UNIX;
-],
-        squid_cv_unixsocket=yes,squid_cv_unixsocket=no)])
+]])],[squid_cv_unixsocket=yes],[squid_cv_unixsocket=no])])
 if test x"$squid_cv_unixsocket" = x"yes"; then
    AC_DEFINE(HAVE_UNIXSOCKET,1,[Do we have unix sockets? (required for the winbind ntlm helper])
 fi
@@ -2631,7 +2588,7 @@ dnl Enable IPv6 support
 AC_MSG_CHECKING([whether to enable IPv6])
 use_ipng=yes
 AC_ARG_ENABLE(ipv6,
-  AC_HELP_STRING([--disable-ipv6],[Disable IPv6 support]),
+  AS_HELP_STRING([--disable-ipv6],[Disable IPv6 support]),
 [ if test "x$enableval" = "xyes" ; then
     AC_MSG_RESULT(yes)
   else
@@ -2651,21 +2608,19 @@ if test "$use_ipng" = "yes"; then
       ;;
   esac
   AC_CACHE_CHECK([if PF_INET6 is available], $use_ipng,
-    AC_TRY_RUN([ /* PF_INET6 available check */
+    AC_RUN_IFELSE([AC_LANG_SOURCE([[ /* PF_INET6 available check */
 #       include <sys/types.h>
 #       include <sys/socket.h>
-        int main() {
+        int main(int argc, char **argv) {
           if (socket(PF_INET6, SOCK_STREAM, 0) < 0)
             return 1;
           else
             return 0;
         }
-      ],
-      [ AC_MSG_RESULT(yes)
+      ]])],[ AC_MSG_RESULT(yes)
         use_ipng=yes
-        SAVED_LIBS="$LIBS" ],
-      [ AC_MSG_RESULT(no)
-        use_ipng=no ])
+        SAVED_LIBS="$LIBS" ],[ AC_MSG_RESULT(no)
+        use_ipng=no ],[])
    )
    LIBS="$SAVED_LIBS"
 fi
@@ -2677,8 +2632,7 @@ if test "$use_ipng" = "yes"; then
 dnl Check for forced split-stack mode
   AC_MSG_CHECKING([for IPv6 split-stack requirement])
   AC_ARG_WITH(ipv6-split-stack,
-    AC_HELP_STRING([--with-ipv6-split-stack],
-		   [Force-Enable experimental split-stack support for Windows XP and *BSD. Requires IPv6.]),
+    AS_HELP_STRING([--with-ipv6-split-stack],[Force-Enable experimental split-stack support for Windows XP and *BSD. Requires IPv6.]),
     [ use_v4mapped="no"
       AC_MSG_RESULT(yes)],
     [ AC_MSG_RESULT(no) ])
@@ -2688,30 +2642,28 @@ dnl Useful for other OS with hybrid-stack defaults turned OFF
 dnl But only usable if it actually works...
   if test "$use_v4mapped" = "yes" ; then
     AC_MSG_CHECKING([for IPv6 v4-mapping ability])
-    AC_TRY_RUN([ /* IPPROTO_V4MAPPED is usable check */
+    AC_RUN_IFELSE([AC_LANG_SOURCE([[ /* IPPROTO_V4MAPPED is usable check */
 #       include <sys/types.h>
 #       include <sys/socket.h>
 #	include <netinet/in.h>
 #if HAVE_NETINET_IN6_H
 #	include <netinet/in6.h>
 #endif
-        int main() {
+        int main(int argc, char **argv) {
           int s = socket(PF_INET6, SOCK_STREAM, 0);
           int tos = 0;
           if (setsockopt(s, IPPROTO_IPV6, IPV6_V6ONLY, (char *) &tos, sizeof(int)) < 0)
             return 1;
           else
             return 0;
         }
-      ],
-      [ AC_MSG_RESULT(yes)
+      ]])],[ AC_MSG_RESULT(yes)
         use_v4mapped=yes
         AC_DEFINE(IPV6_SPECIAL_V4MAPPED, 1, [Enable v4-mapping through v6 sockets])
-      ],
-      [ AC_MSG_RESULT(no)
+      ],[ AC_MSG_RESULT(no)
         AC_DEFINE(IPV6_SPECIAL_V4MAPPED, 0, [Enable v4-mapping through v6 sockets])
         use_v4mapped=no
-      ])
+      ],[])
   fi
 
 dnl if we can't defer v4-mapping to the OS we are forced to split-stack the FD table.
@@ -2729,15 +2681,12 @@ dnl if we can't defer v4-mapping to the OS we are forced to split-stack the FD t
 dnl Check whether this OS defines sin6_len as a member of sockaddr_in6 as a backup to ss_len
 AC_CACHE_CHECK([for sin6_len field in struct sockaddr_in6],
                 ac_cv_have_sin6_len_in_struct_sai, [
-        AC_TRY_COMPILE([
+        AC_COMPILE_IFELSE([AC_LANG_PROGRAM([[
 #include <sys/types.h>
 #include <sys/socket.h>
 #include <netinet/in.h>
-                ],
-                [ struct sockaddr_in6 s; s.sin6_len = 1; ],
-                [ ac_cv_have_sin6_len_in_struct_sai="yes" ],
-                [ ac_cv_have_sin6_len_in_struct_sai="no" ]
-        )
+                ]], [[ struct sockaddr_in6 s; s.sin6_len = 1; ]])],[ ac_cv_have_sin6_len_in_struct_sai="yes" ],[ ac_cv_have_sin6_len_in_struct_sai="no" 
+        ])
   ])
   if test "x$ac_cv_have_sin6_len_in_struct_sai" = "xyes" ; then
     AC_DEFINE(HAVE_SIN6_LEN_IN_SAI, 1, [Does struct sockaddr_in6 have sin6_len? 1: Yes, 0: No])
@@ -2756,15 +2705,12 @@ fi
 dnl Check whether this OS defines ss_len as a member of sockaddr_storage
 AC_CACHE_CHECK([for ss_len field in struct sockaddr_storage],
 		ac_cv_have_ss_len_in_struct_ss, [
-	AC_TRY_COMPILE([
+	AC_COMPILE_IFELSE([AC_LANG_PROGRAM([[
 #include <sys/types.h>
 #include <sys/socket.h>
 #include <netinet/in.h>
-		],
-		[ struct sockaddr_storage s; s.ss_len = 1; ],
-		[ ac_cv_have_ss_len_in_struct_ss="yes" ],
-		[ ac_cv_have_ss_len_in_struct_ss="no" ]
-	)
+		]], [[ struct sockaddr_storage s; s.ss_len = 1; ]])],[ ac_cv_have_ss_len_in_struct_ss="yes" ],[ ac_cv_have_ss_len_in_struct_ss="no" 
+	])
 ])
 if test "x$ac_cv_have_ss_len_in_struct_ss" = "xyes" ; then
 	AC_DEFINE(HAVE_SS_LEN_IN_SS, 1, [Does struct sockaddr_storage have ss_len? 1: Yes, 0: No])
@@ -2775,15 +2721,12 @@ fi
 dnl Check whether this OS defines sin_len as a member of sockaddr_in as a backup to ss_len
 AC_CACHE_CHECK([for sin_len field in struct sockaddr_in],
                 ac_cv_have_sin_len_in_struct_sai, [
-        AC_TRY_COMPILE([
+        AC_COMPILE_IFELSE([AC_LANG_PROGRAM([[
 #include <sys/types.h>
 #include <sys/socket.h>
 #include <netinet/in.h>
-                ],
-                [ struct sockaddr_in s; s.sin_len = 1; ],
-                [ ac_cv_have_sin_len_in_struct_sai="yes" ],
-                [ ac_cv_have_sin_len_in_struct_sai="no" ]
-        )
+                ]], [[ struct sockaddr_in s; s.sin_len = 1; ]])],[ ac_cv_have_sin_len_in_struct_sai="yes" ],[ ac_cv_have_sin_len_in_struct_sai="no" 
+        ])
 ])
 if test "x$ac_cv_have_sin_len_in_struct_sai" = "xyes" ; then
         AC_DEFINE(HAVE_SIN_LEN_IN_SAI, 1, [Does struct sockaddr_in have sin_len? 1: Yes, 0: No])
@@ -2834,7 +2777,7 @@ DBLIB=
 dnl 1.85
 AC_CACHE_CHECK(if dbopen needs -ldb,ac_cv_dbopen_libdb, [
 SAVED_LIBS="$LIBS"; LIBS="$LIBS -ldb"
-  AC_TRY_LINK([
+  AC_LINK_IFELSE([AC_LANG_PROGRAM([[
 #if HAVE_SYS_TYPES_H
 #include <sys/types.h>
 #endif
@@ -2845,10 +2788,7 @@ SAVED_LIBS="$LIBS"; LIBS="$LIBS -ldb"
 #include <db_185.h>
 #elif HAVE_DB_H
 #include <db.h>
-#endif],
-    [dbopen("", 0, 0, DB_HASH, (void *)0L)],
-    ac_cv_dbopen_libdb="yes",
-    ac_cv_dbopen_libdb="no")
+#endif]], [[dbopen("", 0, 0, DB_HASH, (void *)0L)]])],[ac_cv_dbopen_libdb="yes"],[ac_cv_dbopen_libdb="no"])
 LIBS="$SAVED_LIBS"
 ])
 if test $ac_cv_dbopen_libdb = yes; then
@@ -3109,16 +3049,16 @@ dnl to know that setresuid() exists, because RedHat 5.0 declares
 dnl setresuid() but doesn't implement it.
 dnl
 AC_CACHE_CHECK(if setresuid is implemented, ac_cv_func_setresuid,
-  AC_TRY_RUN([
+  AC_RUN_IFELSE([AC_LANG_SOURCE([[
 #include <stdlib.h>
-  int main() {
+  int main(int argc, char **argv) {
     if(setresuid(-1,-1,-1)) {
       perror("setresuid:");
-      exit(1);
+      return 1;
     }
-    exit(0);
+    return 0;
   }
-  ],ac_cv_func_setresuid="yes",ac_cv_func_setresuid="no")
+  ]])],[ac_cv_func_setresuid="yes"],[ac_cv_func_setresuid="no"],[])
 )
 if test "$ac_cv_func_setresuid" = "yes" ; then
   AC_DEFINE(HAVE_SETRESUID,1,[Yay! Another Linux brokenness.  Its not good enough to know that setresuid() exists, because RedHat 5.0 declare setresuid() but doesn't implement it.])
@@ -3129,7 +3069,7 @@ dnl to know that strnstr() exists, because MacOSX 10.4 have a bad
 dnl copy that crashes with a buffer over-run!
 dnl
 AC_CACHE_CHECK(if strnstr is well implemented, ac_cv_func_strnstr,
-  AC_TRY_RUN([
+  AC_RUN_IFELSE([AC_LANG_SOURCE([[
 #include <stdlib.h>
 #include <stdio.h>
 #include <string.h>
@@ -3143,7 +3083,7 @@ int main(int argc, char **argv)
     strnstr(str, "fubar", size);
     return 0;
 }
-  ],ac_cv_func_strnstr="yes",ac_cv_func_strnstr="no")
+  ]])],[ac_cv_func_strnstr="yes"],[ac_cv_func_strnstr="no"],[])
 )
 if test "$ac_cv_func_strnstr" = "yes" ; then
   AC_DEFINE(HAVE_STRNSTR,1,[Yay! We have a working strnstr!])
@@ -3155,22 +3095,20 @@ dnl
 dnl Test for va_copy
 dnl
 AC_CACHE_CHECK(if va_copy is implemented, ac_cv_func_va_copy,
-  AC_TRY_RUN([
+  AC_RUN_IFELSE([AC_LANG_SOURCE([[
       #include <stdarg.h>
       #include <stdlib.h>
-      void f (int i, ...) {
+      int f (int i, ...) {
          va_list args1, args2;
          va_start (args1, i);
          va_copy (args2, args1);
          if (va_arg (args2, int) != 42 || va_arg (args1, int) != 42)
-            exit (1);
+            return 1;
          va_end (args1); va_end (args2);
-      }
-      int main() {
-         f (0, 42);
          return 0;
       }
-      ],ac_cv_func_va_copy="yes",ac_cv_func_va_copy="no")
+      int main(int argc, char **argv) { return f (0, 42); }
+      ]])],[ac_cv_func_va_copy="yes"],[ac_cv_func_va_copy="no"],[])
 )
 if test "$ac_cv_func_va_copy" = "yes" ; then
   AC_DEFINE(HAVE_VA_COPY, 1, [If your system have va_copy])
@@ -3180,22 +3118,20 @@ dnl
 dnl Some systems support __va_copy
 dnl
 AC_CACHE_CHECK(if __va_copy is implemented, ac_cv_func___va_copy,
-  AC_TRY_RUN([
+  AC_RUN_IFELSE([AC_LANG_SOURCE([[
       #include <stdarg.h>
       #include <stdlib.h>
-      void f (int i, ...) {
+      int f (int i, ...) {
          va_list args1, args2;
          va_start (args1, i);
          __va_copy (args2, args1);
          if (va_arg (args2, int) != 42 || va_arg (args1, int) != 42)
-            exit (1);
+            return 1;
          va_end (args1); va_end (args2);
-      }
-      int main() {
-         f (0, 42);
          return 0;
       }
-      ],ac_cv_func___va_copy="yes",ac_cv_func___va_copy="no")
+      int main(int argc, char **argv) { return f (0, 42); }
+      ]])],[ac_cv_func___va_copy="yes"],[ac_cv_func___va_copy="no"],[])
 )
 if test "$ac_cv_func___va_copy" = "yes" ; then
   AC_DEFINE(HAVE___VA_COPY, 1, [Some systems have __va_copy instead of va_copy])
@@ -3308,8 +3244,7 @@ if test "$LINUX_TPROXY2" ; then
 fi
 
 AC_ARG_ENABLE(gnuregex,
-  AC_HELP_STRING([--enable-gnuregex],
-                 [Compile GNUregex.  Unless you have reason to use 
+  AS_HELP_STRING([--enable-gnuregex],[Compile GNUregex.  Unless you have reason to use 
                  this option, you should not enable it.
                  This library file is usually only required on Windows and 
                  very old Unix boxes which do not have their own regex 
@@ -3330,10 +3265,8 @@ if test -z "$USE_GNUREGEX"; then
 if test "$ac_cv_func_regcomp" = "no" || test "$USE_GNUREGEX" = "yes" ; then
 	USE_GNUREGEX="yes"
 else
-	AC_TRY_COMPILE([#include <sys/types.h>
-#include <regex.h>],[regex_t t; regcomp(&t,"",0);],
-		USE_GNUREGEX="no",
-		USE_GNUREGEX="yes")
+	AC_COMPILE_IFELSE([AC_LANG_PROGRAM([[#include <sys/types.h>
+#include <regex.h>]], [[regex_t t; regcomp(&t,"",0);]])],[USE_GNUREGEX="no"],[USE_GNUREGEX="yes"])
 fi
 fi
 AC_MSG_RESULT($USE_GNUREGEX)
@@ -3347,7 +3280,7 @@ AC_SUBST(REGEXLIB)
 
 dnl Not cached since people are likely to tune this
 AC_MSG_CHECKING(Default FD_SETSIZE value)
-AC_TRY_RUN([
+AC_RUN_IFELSE([AC_LANG_SOURCE([[
 #if HAVE_STDIO_H
 #include <stdio.h>
 #endif
@@ -3372,15 +3305,12 @@ AC_TRY_RUN([
 #if HAVE_WINSOCK2_H
 #include <winsock2.h>
 #endif
-main() {
+int main(int argc, char **argv) {
 	FILE *fp = fopen("conftestval", "w");
 	fprintf (fp, "%d\n", FD_SETSIZE);
-	exit(0);
+	return 0;
 }
-],
-DEFAULT_FD_SETSIZE=`cat conftestval`,
-DEFAULT_FD_SETSIZE=256,
-DEFAULT_FD_SETSIZE=256)
+]])],[DEFAULT_FD_SETSIZE=`cat conftestval`],[DEFAULT_FD_SETSIZE=256],[DEFAULT_FD_SETSIZE=256])
 AC_MSG_RESULT($DEFAULT_FD_SETSIZE)
 AC_DEFINE_UNQUOTED(DEFAULT_FD_SETSIZE, $DEFAULT_FD_SETSIZE, [Default FD_SETSIZE value])
 
@@ -3399,14 +3329,14 @@ else
   	LDFLAGS=`echo $LDFLAGS | sed -e "s/-pthread//"`
       fi
   esac
-  AC_TRY_RUN([
+  AC_RUN_IFELSE([AC_LANG_SOURCE([[
 #include <stdio.h>
 #include <unistd.h>
 #include <stdlib.h>
 #include <sys/time.h>	/* needed on FreeBSD */
 #include <sys/param.h>
 #include <sys/resource.h>
-main() {
+int main(int argc, char **argv) {
 	FILE *fp;
 	int i,j;
 #if defined(__CYGWIN32__) || defined (__CYGWIN__)
@@ -3459,12 +3389,9 @@ main() {
 #endif /* IF !DEF CYGWIN */
 	fp = fopen("conftestval", "w");
 	fprintf (fp, "%d\n", i & ~0x3F);
-	exit(0);
+	return 0;
 }
-  ],
-  SQUID_MAXFD=`cat conftestval`,
-  SQUID_MAXFD=256,
-  SQUID_MAXFD=256)
+  ]])],[SQUID_MAXFD=`cat conftestval`],[SQUID_MAXFD=256],[SQUID_MAXFD=256])
   dnl Microsoft MSVCRT.DLL supports 2048 maximum FDs
   case "$host_os" in
   mingw|mingw32)
@@ -3490,7 +3417,7 @@ fi
 
 dnl Not cached since people are likely to tune this
 AC_MSG_CHECKING(Default UDP send buffer size)
-AC_TRY_RUN([
+AC_RUN_IFELSE([AC_LANG_SOURCE([[
 #include <stdlib.h>
 #include <stdio.h>
 #include <sys/types.h>
@@ -3506,7 +3433,7 @@ AC_TRY_RUN([
 #if HAVE_WINSOCK2_H
 #include <winsock2.h>
 #endif
-main ()
+int main(int argc, char **argv)
 {
 	FILE *fp;
         int fd,val=0;
@@ -3517,28 +3444,25 @@ main ()
 #else
         socklen_t len=sizeof(socklen_t);
 #endif
-	if ((fd = socket(AF_INET, SOCK_DGRAM, 0)) < 0) exit(1);
+	if ((fd = socket(AF_INET, SOCK_DGRAM, 0)) < 0) return 1;
 #if (defined(WIN32) || defined(__WIN32__) || defined(__WIN32)) && !(defined(__CYGWIN32__) || defined(__CYGWIN__))
-        if (getsockopt(fd, SOL_SOCKET, SO_SNDBUF, (char *)&val, &len) < 0) exit(1);
+        if (getsockopt(fd, SOL_SOCKET, SO_SNDBUF, (char *)&val, &len) < 0) return 1;
 	WSACleanup();
 #else
-        if (getsockopt(fd, SOL_SOCKET, SO_SNDBUF, &val, &len) < 0) exit(1);
+        if (getsockopt(fd, SOL_SOCKET, SO_SNDBUF, &val, &len) < 0) return 1;
 #endif
-	if (val<=0) exit(1);
+	if (val<=0) return 1;
         fp = fopen("conftestval", "w");
         fprintf (fp, "%d\n", val);
-	exit(0);
+	return 0;
 }
-],
-SQUID_DETECT_UDP_SO_SNDBUF=`cat conftestval`,
-SQUID_DETECT_UDP_SO_SNDBUF=16384,
-SQUID_DETECT_UDP_SO_SNDBUF=16384)
+]])],[SQUID_DETECT_UDP_SO_SNDBUF=`cat conftestval`],[SQUID_DETECT_UDP_SO_SNDBUF=16384],[SQUID_DETECT_UDP_SO_SNDBUF=16384])
 AC_MSG_RESULT($SQUID_DETECT_UDP_SO_SNDBUF)
 AC_DEFINE_UNQUOTED(SQUID_DETECT_UDP_SO_SNDBUF, $SQUID_DETECT_UDP_SO_SNDBUF,[UDP send buffer size])
 
 dnl Not cached since people are likely to tune this
 AC_MSG_CHECKING(Default UDP receive buffer size)
-AC_TRY_RUN([
+AC_RUN_IFELSE([AC_LANG_SOURCE([[
 #include <stdlib.h>
 #include <stdio.h>
 #include <sys/types.h>
@@ -3554,7 +3478,7 @@ AC_TRY_RUN([
 #if HAVE_WINSOCK2_H
 #include <winsock2.h>
 #endif
-main ()
+int main(int argc, char **argv)
 {
 	FILE *fp;
         int fd,val=0;
@@ -3565,28 +3489,25 @@ main ()
 #else
         socklen_t len=sizeof(socklen_t);
 #endif
-	if ((fd = socket(AF_INET, SOCK_DGRAM, 0)) < 0) exit(1);
+	if ((fd = socket(AF_INET, SOCK_DGRAM, 0)) < 0) return 1;
 #if (defined(WIN32) || defined(__WIN32__) || defined(__WIN32)) && !(defined(__CYGWIN32__) || defined(__CYGWIN__))
-        if (getsockopt(fd, SOL_SOCKET, SO_RCVBUF, (char *)&val, &len) < 0) exit(1);
+        if (getsockopt(fd, SOL_SOCKET, SO_RCVBUF, (char *)&val, &len) < 0) return 1;
 	WSACleanup();
 #else
-        if (getsockopt(fd, SOL_SOCKET, SO_RCVBUF, &val, &len) < 0) exit(1);
+        if (getsockopt(fd, SOL_SOCKET, SO_RCVBUF, &val, &len) < 0) return 1;
 #endif
-	if (val <= 0) exit(1);
+	if (val <= 0) return 1;
 	fp = fopen("conftestval", "w"); 
 	fprintf (fp, "%d\n", val);
-	exit(0);
+	return 0;
 }
-],
-SQUID_DETECT_UDP_SO_RCVBUF=`cat conftestval`,
-SQUID_DETECT_UDP_SO_RCVBUF=16384,
-SQUID_DETECT_UDP_SO_RCVBUF=16384)
+]])],[SQUID_DETECT_UDP_SO_RCVBUF=`cat conftestval`],[SQUID_DETECT_UDP_SO_RCVBUF=16384],[SQUID_DETECT_UDP_SO_RCVBUF=16384])
 AC_MSG_RESULT($SQUID_DETECT_UDP_SO_RCVBUF)
 AC_DEFINE_UNQUOTED(SQUID_DETECT_UDP_SO_RCVBUF, $SQUID_DETECT_UDP_SO_RCVBUF,[UDP receive buffer size])
 
 dnl Not cached since people are likely to tune this
 AC_MSG_CHECKING(Default TCP send buffer size)
-AC_TRY_RUN([
+AC_RUN_IFELSE([AC_LANG_SOURCE([[
 #include <stdlib.h>
 #include <stdio.h>
 #include <sys/types.h>
@@ -3602,7 +3523,7 @@ AC_TRY_RUN([
 #if HAVE_WINSOCK2_H
 #include <winsock2.h>
 #endif
-main ()
+int main(int argc, char **argv)
 {
 	FILE *fp;
         int fd,val=0;
@@ -3613,22 +3534,19 @@ main ()
 #else
         socklen_t len=sizeof(socklen_t);
 #endif
-	if ((fd = socket(AF_INET, SOCK_STREAM, 0)) < 0) exit(1);
+	if ((fd = socket(AF_INET, SOCK_STREAM, 0)) < 0) return 1;
 #if (defined(WIN32) || defined(__WIN32__) || defined(__WIN32)) && !(defined(__CYGWIN32__) || defined(__CYGWIN__))
-        if (getsockopt(fd, SOL_SOCKET, SO_SNDBUF, (char *)&val, &len) < 0) exit(1);
+        if (getsockopt(fd, SOL_SOCKET, SO_SNDBUF, (char *)&val, &len) < 0) return 1;
 	WSACleanup();
 #else
-        if (getsockopt(fd, SOL_SOCKET, SO_SNDBUF, &val, &len) < 0) exit(1);
+        if (getsockopt(fd, SOL_SOCKET, SO_SNDBUF, &val, &len) < 0) return 1;
 #endif
-	if (val <= 0) exit(1);
+	if (val <= 0) return 1;
 	fp = fopen("conftestval", "w"); 
 	fprintf (fp, "%d\n", val);
-	exit(0);
+	return 0;
 }
-],
-SQUID_TCP_SO_SNDBUF=`cat conftestval`,
-SQUID_TCP_SO_SNDBUF=16384,
-SQUID_TCP_SO_SNDBUF=16384)
+]])],[SQUID_TCP_SO_SNDBUF=`cat conftestval`],[SQUID_TCP_SO_SNDBUF=16384],[SQUID_TCP_SO_SNDBUF=16384])
 AC_MSG_RESULT($SQUID_TCP_SO_SNDBUF)
 if test $SQUID_TCP_SO_SNDBUF -gt 32768; then
     AC_MSG_NOTICE([Limiting send buffer size to 32K])
@@ -3638,7 +3556,7 @@ AC_DEFINE_UNQUOTED(SQUID_TCP_SO_SNDBUF, $SQUID_TCP_SO_SNDBUF,[TCP send buffer si
 
 dnl Not cached since people are likely to tune this
 AC_MSG_CHECKING(Default TCP receive buffer size)
-AC_TRY_RUN([
+AC_RUN_IFELSE([AC_LANG_SOURCE([[
 #include <stdlib.h>
 #include <stdio.h>
 #include <sys/types.h>
@@ -3654,7 +3572,7 @@ AC_TRY_RUN([
 #if HAVE_WINSOCK2_H
 #include <winsock2.h>
 #endif
-main ()
+int main(int argc, char **argv)
 {
 	FILE *fp;
         int fd,val=0;
@@ -3665,60 +3583,50 @@ main ()
 #else
         socklen_t len=sizeof(socklen_t);
 #endif
-	if ((fd = socket(AF_INET, SOCK_STREAM, 0)) < 0) exit(1);
+	if ((fd = socket(AF_INET, SOCK_STREAM, 0)) < 0) return 1;
 #if (defined(WIN32) || defined(__WIN32__) || defined(__WIN32)) && !(defined(__CYGWIN32__) || defined(__CYGWIN__))
-        if (getsockopt(fd, SOL_SOCKET, SO_RCVBUF, (char *)&val, &len) < 0) exit(1);
+        if (getsockopt(fd, SOL_SOCKET, SO_RCVBUF, (char *)&val, &len) < 0) return 1;
 	WSACleanup();
 #else
-        if (getsockopt(fd, SOL_SOCKET, SO_RCVBUF, &val, &len) < 0) exit(1);
+        if (getsockopt(fd, SOL_SOCKET, SO_RCVBUF, &val, &len) < 0) return 1;
 #endif
-	if (val <= 0) exit(1);
+	if (val <= 0) return 1;
 	fp = fopen("conftestval", "w"); 
 	fprintf (fp, "%d\n", val);
-	exit(0);
+	return 0;
 }
-],
-SQUID_TCP_SO_RCVBUF=`cat conftestval`,
-SQUID_TCP_SO_RCVBUF=16384,
-SQUID_TCP_SO_RCVBUF=16384)
+]])],[SQUID_TCP_SO_RCVBUF=`cat conftestval`],[SQUID_TCP_SO_RCVBUF=16384],[SQUID_TCP_SO_RCVBUF=16384])
 AC_MSG_RESULT($SQUID_TCP_SO_RCVBUF)
 if test $SQUID_TCP_SO_RCVBUF -gt 65535; then
     AC_MSG_NOTICE([Limiting receive buffer size to 64K])
     SQUID_TCP_SO_RCVBUF=65535
 fi
 AC_DEFINE_UNQUOTED(SQUID_TCP_SO_RCVBUF, $SQUID_TCP_SO_RCVBUF,[TCP receive buffer size])
 AC_CACHE_CHECK(if sys_errlist is already defined, ac_cv_needs_sys_errlist,
-  AC_TRY_COMPILE([#include <stdio.h>],[char *s = sys_errlist;],
-    ac_cv_needs_sys_errlist="no",
-    ac_cv_needs_sys_errlist="yes")
+  AC_COMPILE_IFELSE([AC_LANG_PROGRAM([[#include <stdio.h>]], [[char *s = sys_errlist;]])],[ac_cv_needs_sys_errlist="no"],[ac_cv_needs_sys_errlist="yes"])
 )
 if test "$ac_cv_needs_sys_errlist" = "yes" ; then
   AC_DEFINE(NEED_SYS_ERRLIST,1,[If we need to declare sys_errlist[] as external])
 fi
 
 dnl Not cached since people are likely to change this
 AC_MSG_CHECKING(for libresolv _dns_ttl_ hack)
-AC_TRY_LINK(extern int _dns_ttl_;,return _dns_ttl_;,
-[AC_MSG_RESULT(yes)
-AC_DEFINE(LIBRESOLV_DNS_TTL_HACK,1,[If libresolv.a has been hacked to export _dns_ttl_])],
-AC_MSG_RESULT(no))
+AC_LINK_IFELSE([AC_LANG_PROGRAM([[extern int _dns_ttl_;]], [[return _dns_ttl_;]])],[AC_MSG_RESULT(yes)
+AC_DEFINE(LIBRESOLV_DNS_TTL_HACK,1,[If libresolv.a has been hacked to export _dns_ttl_])],[AC_MSG_RESULT(no)])
 
 if test "$ac_cv_header_sys_statvfs_h" = "yes" ; then
 AC_MSG_CHECKING(for working statvfs() interface)
-AC_TRY_COMPILE([
+AC_COMPILE_IFELSE([AC_LANG_PROGRAM([[
 #include <stdlib.h>
 #include <stdio.h>
 #include <sys/types.h>
 #include <sys/statvfs.h>
-],
-[
+]], [[
 struct statvfs sfs;
 sfs.f_blocks = sfs.f_bfree = sfs.f_frsize = 
 sfs.f_files = sfs.f_ffree = 0;
 statvfs("/tmp", &sfs);
-],
-  ac_cv_func_statvfs=yes,
-  ac_cv_func_statvfs=no)
+]])],[ac_cv_func_statvfs=yes],[ac_cv_func_statvfs=no])
 AC_MSG_RESULT($ac_cv_func_statvfs)
 if test "$ac_cv_func_statvfs" = "yes" ; then
   AC_DEFINE(HAVE_STATVFS,1,[If your system has statvfs(), and if it actually works!])
@@ -3727,7 +3635,7 @@ fi
 
 dnl Detect what resolver fields we have available to use...
 AC_CACHE_CHECK(for _res_ext.nsaddr_list, ac_cv_have_res_ext_nsaddr_list,
-AC_TRY_COMPILE([
+AC_COMPILE_IFELSE([AC_LANG_PROGRAM([[
 #if HAVE_SYS_TYPES_H
 #include <sys/types.h>
 #endif
@@ -3743,18 +3651,15 @@ AC_TRY_COMPILE([
 #if HAVE_RESOLV_H
 #include <resolv.h>
 #endif
-],
-[_res_ext.nsaddr_list[[0]].s_addr;],
-ac_cv_have_res_ext_nsaddr_list="yes",
-ac_cv_have_res_ext_nsaddr_list="no"))
+]], [[_res_ext.nsaddr_list[[0]].s_addr;]])],[ac_cv_have_res_ext_nsaddr_list="yes"],[ac_cv_have_res_ext_nsaddr_list="no"]))
 if test "$ac_cv_have_res_ext_nsaddr_list" = "yes" ; then
   AC_DEFINE(_SQUID_RES_NSADDR6_LARRAY,_res_ext.nsaddr_list,[If _res_ext structure has nsaddr_list member])
   AC_DEFINE(_SQUID_RES_NSADDR6_COUNT,ns6count,[Nameserver Counter for IPv6 _res_ext])
 fi
 
 if test "$_SQUID_RES_NSADDR6_LIST" = ""; then
 AC_CACHE_CHECK(for _res._u._ext.nsaddrs, ac_cv_have_res_ext_nsaddrs,
-AC_TRY_COMPILE([
+AC_COMPILE_IFELSE([AC_LANG_PROGRAM([[
 #if HAVE_SYS_TYPES_H
 #include <sys/types.h>
 #endif
@@ -3770,18 +3675,15 @@ AC_TRY_COMPILE([
 #if HAVE_RESOLV_H
 #include <resolv.h>
 #endif
-],
-[_res._u._ext.nsaddrs[[0]]->sin6_addr;],
-ac_cv_have_res_ext_nsaddrs="yes",
-ac_cv_have_res_ext_nsaddrs="no"))
+]], [[_res._u._ext.nsaddrs[[0]]->sin6_addr;]])],[ac_cv_have_res_ext_nsaddrs="yes"],[ac_cv_have_res_ext_nsaddrs="no"]))
 if test "$ac_cv_have_res_ext_nsaddrs" = "yes" ; then
   AC_DEFINE(_SQUID_RES_NSADDR6_LPTR,_res._u._ext.nsaddrs,[If _res structure has _ext.nsaddrs member])
   AC_DEFINE(_SQUID_RES_NSADDR6_COUNT,_res._u._ext.nscount6,[Nameserver Counter for IPv6 _res])
 fi
 fi
 
 AC_CACHE_CHECK(for _res.nsaddr_list, ac_cv_have_res_nsaddr_list,
-AC_TRY_COMPILE([
+AC_COMPILE_IFELSE([AC_LANG_PROGRAM([[
 #if HAVE_SYS_TYPES_H
 #include <sys/types.h>
 #endif
@@ -3797,18 +3699,15 @@ AC_TRY_COMPILE([
 #if HAVE_RESOLV_H
 #include <resolv.h>
 #endif
-],
-[_res.nsaddr_list[[0]];],
-ac_cv_have_res_nsaddr_list="yes",
-ac_cv_have_res_nsaddr_list="no"))
+]], [[_res.nsaddr_list[[0]];]])],[ac_cv_have_res_nsaddr_list="yes"],[ac_cv_have_res_nsaddr_list="no"]))
 if test $ac_cv_have_res_nsaddr_list = "yes" ; then
   AC_DEFINE(_SQUID_RES_NSADDR_LIST,_res.nsaddr_list,[If _res structure has nsaddr_list member])
   AC_DEFINE(_SQUID_RES_NSADDR_COUNT,_res.nscount,[Nameserver counter for IPv4 _res])
 fi
 
 if test "$_SQUID_RES_NSADDR_LIST" = ""; then
 AC_CACHE_CHECK(for _res.ns_list, ac_cv_have_res_ns_list,
-AC_TRY_COMPILE([
+AC_COMPILE_IFELSE([AC_LANG_PROGRAM([[
 #if HAVE_SYS_TYPES_H
 #include <sys/types.h>
 #endif
@@ -3824,10 +3723,7 @@ AC_TRY_COMPILE([
 #if HAVE_RESOLV_H
 #include <resolv.h>
 #endif
-],
-[_res.ns_list[[0]].addr;],
-ac_cv_have_res_ns_list="yes",
-ac_cv_have_res_ns_list="no"))
+]], [[_res.ns_list[[0]].addr;]])],[ac_cv_have_res_ns_list="yes"],[ac_cv_have_res_ns_list="no"]))
 if test $ac_cv_have_res_ns_list = "yes" ; then
   AC_DEFINE(_SQUID_RES_NSADDR_LIST,_res.ns_list,[If _res structure has ns_list member])
   AC_DEFINE(_SQUID_RES_NSADDR_COUNT,_res.nscount,[Nameserver counter for IPv4 _res])
@@ -3837,9 +3733,8 @@ fi
 dnl Squid will usually attempt to translate when packaging or building from VCS 
 use_translation="yes"
 AC_ARG_ENABLE(translation,
- AC_HELP_STRING([--disable-translation],
-		[Prevent Squid generating localized error page templates and manuals.
-		 Which is usually tried, but may not be needed.])
+ AS_HELP_STRING([--disable-translation],[Prevent Squid generating localized error page templates and manuals.
+		 Which is usually tried, but may not be needed.]),
 [ if test "$enableval" = "no" ; then
     use_translation=no
   fi
@@ -3856,8 +3751,7 @@ dnl Squid now has limited locale handling ...
 dnl on error pages
 use_errlocale=yes
 AC_ARG_ENABLE(auto-locale,
- AC_HELP_STRING([--disable-auto-locale],
-		[This prevents Squid providing localized error pages based on the
+ AS_HELP_STRING([--disable-auto-locale],[This prevents Squid providing localized error pages based on the
 		 clients request headers.
 		 When disabled Squid requires explicit language configuration.]),
 [ if test "$enableval" = "no" ; then
@@ -8,26 +8,26 @@ msgstr ""
 "Project-Id-Version: Squid-3\n"
 "Report-Msgid-Bugs-To: FULL NAME <EMAIL@ADDRESS>\n"
 "POT-Creation-Date: 2009-06-07 21:20+1200\n"
-"PO-Revision-Date: 2009-06-10 14:58+0000\n"
-"Last-Translator: MaXeR <Unknown>\n"
+"PO-Revision-Date: 2009-07-22 09:45+0000\n"
+"Last-Translator: Amos Jeffries <Unknown>\n"
 "Language-Team: Arabic <ar@li.org>\n"
 "MIME-Version: 1.0\n"
 "Content-Type: text/plain; charset=UTF-8\n"
 "Content-Transfer-Encoding: 8bit\n"
-"X-Launchpad-Export-Date: 2009-06-14 06:48+0000\n"
+"X-Launchpad-Export-Date: 2009-07-22 09:52+0000\n"
 "X-Generator: Launchpad (build Unknown)\n"
 
 #. type: TH
 #: doc/cachemgr.cgi.8.in:1
 #, no-wrap
 msgid "cachemgr.cgi"
-msgstr ""
+msgstr "cachemgr.cgi"
 
 #. type: TH
 #: doc/cachemgr.cgi.8.in:1 doc/squid.8.in:1
 #, no-wrap
 msgid "@PACKAGE_STRING@"
-msgstr ""
+msgstr "@PACKAGE_STRING@"
 
 #. type: SH
 #: doc/cachemgr.cgi.8.in:4 doc/squid.8.in:4 helpers/basic_auth/NCSA/ncsa_auth.8:14 helpers/basic_auth/PAM/pam_auth.8:3 helpers/basic_auth/squid_radius_auth/squid_radius_auth.8:3 helpers/external_acl/session/squid_session.8:3 helpers/external_acl/unix_group/squid_unix_group.8:3
@@ -49,13 +49,13 @@ msgstr ""
 #. type: Plain text
 #: doc/cachemgr.cgi.8.in:8
 msgid "B<http://your.server/cgi-bin/cachemgr.cgi>"
-msgstr ""
+msgstr "B<http://your.server/cgi-bin/cachemgr.cgi>"
 
 #. type: SH
 #: doc/cachemgr.cgi.8.in:8 doc/squid.8.in:26 helpers/basic_auth/NCSA/ncsa_auth.8:23 helpers/basic_auth/PAM/pam_auth.8:9 helpers/basic_auth/squid_radius_auth/squid_radius_auth.8:13 helpers/external_acl/session/squid_session.8:9 helpers/external_acl/unix_group/squid_unix_group.8:9
 #, no-wrap
 msgid "DESCRIPTION"
-msgstr ""
+msgstr "وصف"
 
 #. type: Plain text
 #: doc/cachemgr.cgi.8.in:13
@@ -75,12 +75,12 @@ msgstr ""
 #. type: Plain text
 #: doc/cachemgr.cgi.8.in:15
 msgid "I<./cachemgr.conf>"
-msgstr ""
+msgstr "I<./cachemgr.conf>"
 
 #. type: Plain text
 #: doc/cachemgr.cgi.8.in:17
 msgid "I<@DEFAULT_CACHEMGR_CONFIG@>"
-msgstr ""
+msgstr "I<@DEFAULT_CACHEMGR_CONFIG@>"
 
 #. type: Plain text
 #: doc/cachemgr.cgi.8.in:22
@@ -131,12 +131,12 @@ msgstr ""
 #: doc/cachemgr.cgi.8.in:39 doc/squid.8.in:178 helpers/basic_auth/NCSA/ncsa_auth.8:35 helpers/basic_auth/PAM/pam_auth.8:89 helpers/basic_auth/squid_radius_auth/squid_radius_auth.8:87 helpers/external_acl/session/squid_session.8:61 helpers/external_acl/unix_group/squid_unix_group.8:63
 #, no-wrap
 msgid "SEE ALSO"
-msgstr ""
+msgstr "قرآءه الكُل"
 
 #. type: Plain text
 #: doc/cachemgr.cgi.8.in:41
 msgid "B<squid>(8)"
-msgstr ""
+msgstr "B<squid>(8)"
 
 #. Could add the following sections:
 #. .SH ENVIRONMENT
@@ -225,7 +225,7 @@ msgstr ""
 #: doc/squid.8.in:69 helpers/basic_auth/NCSA/ncsa_auth.8:29
 #, no-wrap
 msgid "OPTIONS"
-msgstr ""
+msgstr "خيارات"
 
 #. type: IP
 #: doc/squid.8.in:70
@@ -271,7 +271,7 @@ msgstr ""
 #: doc/squid.8.in:82
 #, no-wrap
 msgid "-h"
-msgstr ""
+msgstr "-h"
 
 #. type: Plain text
 #: doc/squid.8.in:84
@@ -282,7 +282,7 @@ msgstr ""
 #: doc/squid.8.in:84
 #, no-wrap
 msgid "-i"
-msgstr ""
+msgstr "-i"
 
 #. type: Plain text
 #: doc/squid.8.in:86
@@ -295,6 +295,7 @@ msgstr ""
 msgid ""
 "-k reconfigure | rotate | shutdown | interrupt | kill | debug | check | parse"
 msgstr ""
+"-k reconfigure | rotate | shutdown | interrupt | kill | debug | check | parse"
 
 #. type: Plain text
 #: doc/squid.8.in:89
@@ -320,7 +321,7 @@ msgstr ""
 #: doc/squid.8.in:93
 #, no-wrap
 msgid "-r"
-msgstr ""
+msgstr "-r"
 
 #. type: Plain text
 #: doc/squid.8.in:95
@@ -331,7 +332,7 @@ msgstr ""
 #: doc/squid.8.in:95
 #, no-wrap
 msgid "-s"
-msgstr ""
+msgstr "-s"
 
 #. type: Plain text
 #: doc/squid.8.in:98
@@ -365,7 +366,7 @@ msgstr ""
 #: doc/squid.8.in:102
 #, no-wrap
 msgid "-v"
-msgstr ""
+msgstr "-v"
 
 #. type: Plain text
 #: doc/squid.8.in:104
@@ -376,7 +377,7 @@ msgstr ""
 #: doc/squid.8.in:104
 #, no-wrap
 msgid "-z"
-msgstr ""
+msgstr "-z"
 
 #. type: Plain text
 #: doc/squid.8.in:106
@@ -387,7 +388,7 @@ msgstr ""
 #: doc/squid.8.in:106
 #, no-wrap
 msgid "-C"
-msgstr ""
+msgstr "-C"
 
 #. type: Plain text
 #: doc/squid.8.in:108
@@ -398,7 +399,7 @@ msgstr ""
 #: doc/squid.8.in:108
 #, no-wrap
 msgid "-F"
-msgstr ""
+msgstr "-F"
 
 #. type: Plain text
 #: doc/squid.8.in:110
@@ -409,7 +410,7 @@ msgstr ""
 #: doc/squid.8.in:110
 #, no-wrap
 msgid "-N"
-msgstr ""
+msgstr "-N"
 
 #. type: Plain text
 #: doc/squid.8.in:112
@@ -431,7 +432,7 @@ msgstr ""
 #: doc/squid.8.in:114
 #, no-wrap
 msgid "-R"
-msgstr ""
+msgstr "-R"
 
 #. type: Plain text
 #: doc/squid.8.in:116
@@ -442,7 +443,7 @@ msgstr ""
 #: doc/squid.8.in:116
 #, no-wrap
 msgid "-S"
-msgstr ""
+msgstr "-S"
 
 #. type: Plain text
 #: doc/squid.8.in:118
@@ -453,7 +454,7 @@ msgstr ""
 #: doc/squid.8.in:118
 #, no-wrap
 msgid "-X"
-msgstr ""
+msgstr "-X"
 
 #. type: Plain text
 #: doc/squid.8.in:120
@@ -464,7 +465,7 @@ msgstr ""
 #: doc/squid.8.in:120
 #, no-wrap
 msgid "-Y"
-msgstr ""
+msgstr "-Y"
 
 #. type: Plain text
 #: doc/squid.8.in:122
@@ -474,7 +475,7 @@ msgstr ""
 #. type: Plain text
 #: doc/squid.8.in:125
 msgid "I<@DEFAULT_CONFIG_FILE@>"
-msgstr ""
+msgstr "I<@DEFAULT_CONFIG_FILE@>"
 
 #. type: Plain text
 #: doc/squid.8.in:131
@@ -487,7 +488,7 @@ msgstr ""
 #. type: Plain text
 #: doc/squid.8.in:134
 msgid "I<*.default files>"
-msgstr ""
+msgstr "I<*.default files>"
 
 #. type: Plain text
 #: doc/squid.8.in:138
@@ -500,7 +501,7 @@ msgstr ""
 #. type: Plain text
 #: doc/squid.8.in:141
 msgid "I<@DEFAULT_CONFIG_FILE@.documented>"
-msgstr ""
+msgstr "I<@DEFAULT_CONFIG_FILE@.documented>"
 
 #. type: Plain text
 #: doc/squid.8.in:147
@@ -515,7 +516,7 @@ msgstr ""
 #. type: Plain text
 #: doc/squid.8.in:150
 msgid "I<cachemgr.conf>"
-msgstr ""
+msgstr "I<cachemgr.conf>"
 
 #. type: Plain text
 #: doc/squid.8.in:152
@@ -525,7 +526,7 @@ msgstr ""
 #. type: Plain text
 #: doc/squid.8.in:155
 msgid "I<msntauth.conf>"
-msgstr ""
+msgstr "I<msntauth.conf>"
 
 #. type: Plain text
 #: doc/squid.8.in:157
@@ -535,7 +536,7 @@ msgstr ""
 #. type: Plain text
 #: doc/squid.8.in:160
 msgid "I<errorpage.css>"
-msgstr ""
+msgstr "I<errorpage.css>"
 
 #. type: Plain text
 #: doc/squid.8.in:164
@@ -548,7 +549,7 @@ msgstr ""
 #. type: Plain text
 #: doc/squid.8.in:167
 msgid "I<@DEFAULT_MIME_TABLE@ (mime_table)>"
-msgstr ""
+msgstr "I<@DEFAULT_MIME_TABLE@ (mime_table)>"
 
 #. type: Plain text
 #: doc/squid.8.in:169
@@ -558,7 +559,7 @@ msgstr ""
 #. type: Plain text
 #: doc/squid.8.in:172
 msgid "I<@DEFAULT_ERROR_DIR@>"
-msgstr ""
+msgstr "I<@DEFAULT_ERROR_DIR@>"
 
 #. type: Plain text
 #: doc/squid.8.in:176
@@ -571,6 +572,8 @@ msgid ""
 "B<cachemgr.cgi>(8), B<pam_auth>(8), B<squid_ldap_auth>(8), "
 "B<squid_ldap_group>(8), B<squid_session>(8), B<squid_unix_group>(8),"
 msgstr ""
+"B<cachemgr.cgi>(8), B<pam_auth>(8), B<squid_ldap_auth>(8), "
+"B<squid_ldap_group>(8), B<squid_session>(8), B<squid_unix_group>(8),"
 
 #. type: Plain text
 #: doc/squid.8.in:188
@@ -583,7 +586,7 @@ msgstr ""
 #: helpers/basic_auth/NCSA/ncsa_auth.8:13
 #, no-wrap
 msgid "ncsa_auth"
-msgstr ""
+msgstr "ncsa_auth"
 
 #. type: TH
 #: helpers/basic_auth/NCSA/ncsa_auth.8:13
@@ -607,7 +610,7 @@ msgstr ""
 #: helpers/basic_auth/NCSA/ncsa_auth.8:21
 #, no-wrap
 msgid "B<ncsa_auth> I<passwdfile> \n"
-msgstr ""
+msgstr "B<ncsa_auth> I<passwdfile> \n"
 
 #. type: Plain text
 #: helpers/basic_auth/NCSA/ncsa_auth.8:25
@@ -644,7 +647,7 @@ msgstr ""
 #. type: Plain text
 #: helpers/basic_auth/NCSA/ncsa_auth.8:33
 msgid "B<ncsa_auth> /etc/squid/squid.pass"
-msgstr ""
+msgstr "B<ncsa_auth> /etc/squid/squid.pass"
 
 #. type: Plain text
 #: helpers/basic_auth/NCSA/ncsa_auth.8:35
@@ -654,13 +657,13 @@ msgstr ""
 #. type: Plain text
 #: helpers/basic_auth/NCSA/ncsa_auth.8:37
 msgid "B<htpasswd>(1), B<squid>(8)"
-msgstr ""
+msgstr "B<htpasswd>(1), B<squid>(8)"
 
 #. type: SH
 #: helpers/basic_auth/NCSA/ncsa_auth.8:37 helpers/basic_auth/PAM/pam_auth.8:70 helpers/basic_auth/squid_radius_auth/squid_radius_auth.8:65 helpers/external_acl/session/squid_session.8:47 helpers/external_acl/unix_group/squid_unix_group.8:41
 #, no-wrap
 msgid "AUTHOR"
-msgstr ""
+msgstr "ترخيص"
 
 #. type: Plain text
 #: helpers/basic_auth/NCSA/ncsa_auth.8:38
@@ -672,7 +675,7 @@ msgstr ""
 #: helpers/basic_auth/PAM/pam_auth.8:1
 #, no-wrap
 msgid "pam_auth"
-msgstr ""
+msgstr "pam_auth"
 
 #. type: TH
 #: helpers/basic_auth/PAM/pam_auth.8:1
@@ -694,7 +697,7 @@ msgstr ""
 #. type: Plain text
 #: helpers/basic_auth/PAM/pam_auth.8:8
 msgid "squid_pam_auth [-n \"service name\"] [-t TTL] [-o] [-1]"
-msgstr ""
+msgstr "squid_pam_auth [-n \"service name\"] [-t TTL] [-o] [-1]"
 
 #. type: Plain text
 #: helpers/basic_auth/PAM/pam_auth.8:13
@@ -707,7 +710,7 @@ msgstr ""
 #: helpers/basic_auth/PAM/pam_auth.8:14
 #, no-wrap
 msgid "B<-s >I<service-name>"
-msgstr ""
+msgstr "B<-s >I<service-name>"
 
 #. type: Plain text
 #: helpers/basic_auth/PAM/pam_auth.8:17
@@ -718,7 +721,7 @@ msgstr ""
 #: helpers/basic_auth/PAM/pam_auth.8:18
 #, no-wrap
 msgid "B<-t >I<TTL>"
-msgstr ""
+msgstr "B<-t >I<TTL>"
 
 #. type: Plain text
 #: helpers/basic_auth/PAM/pam_auth.8:26
@@ -735,7 +738,7 @@ msgstr ""
 #: helpers/basic_auth/PAM/pam_auth.8:27
 #, no-wrap
 msgid "B<-o>"
-msgstr ""
+msgstr "B<-o>"
 
 #. type: Plain text
 #: helpers/basic_auth/PAM/pam_auth.8:31
@@ -789,12 +792,12 @@ msgstr ""
 #. type: Plain text
 #: helpers/basic_auth/PAM/pam_auth.8:59
 msgid "B<chown root pam_auth>"
-msgstr ""
+msgstr "B<chown root pam_auth>"
 
 #. type: Plain text
 #: helpers/basic_auth/PAM/pam_auth.8:61
 msgid "B<chmod u+s pam_auth>"
-msgstr ""
+msgstr "B<chmod u+s pam_auth>"
 
 #. type: Plain text
 #: helpers/basic_auth/PAM/pam_auth.8:69
@@ -818,7 +821,7 @@ msgstr ""
 #: helpers/basic_auth/PAM/pam_auth.8:74
 #, no-wrap
 msgid "COPYRIGHT"
-msgstr ""
+msgstr "حقوق الطبع"
 
 #. type: Plain text
 #: helpers/basic_auth/PAM/pam_auth.8:77
@@ -844,7 +847,7 @@ msgstr ""
 #: helpers/basic_auth/PAM/pam_auth.8:83 helpers/basic_auth/squid_radius_auth/squid_radius_auth.8:81 helpers/external_acl/session/squid_session.8:55 helpers/external_acl/unix_group/squid_unix_group.8:57
 #, no-wrap
 msgid "REPORTING BUGS"
-msgstr ""
+msgstr "تقرير عن ثغرة"
 
 #. type: Plain text
 #: helpers/basic_auth/PAM/pam_auth.8:88 helpers/basic_auth/squid_radius_auth/squid_radius_auth.8:86 helpers/external_acl/session/squid_session.8:60
@@ -863,7 +866,7 @@ msgstr ""
 #: helpers/basic_auth/squid_radius_auth/squid_radius_auth.8:1
 #, no-wrap
 msgid "squid_radius_auth"
-msgstr ""
+msgstr "squid_radius_auth"
 
 #. type: TH
 #: helpers/basic_auth/squid_radius_auth/squid_radius_auth.8:1
@@ -1126,7 +1129,7 @@ msgstr ""
 #: helpers/external_acl/session/squid_session.8:26
 #, no-wrap
 msgid "B<-a>"
-msgstr ""
+msgstr "B<-a>"
 
 #. type: Plain text
 #: helpers/external_acl/session/squid_session.8:30
@@ -1153,21 +1156,23 @@ msgid ""
 "external_acl_type session ttl=300 negative_ttl=0 children=1 concurrency=200 "
 "%LOGIN /usr/local/squid/libexec/squid_session"
 msgstr ""
+"external_acl_type session ttl=300 negative_ttl=0 children=1 concurrency=200 "
+"%LOGIN /usr/local/squid/libexec/squid_session"
 
 #. type: Plain text
 #: helpers/external_acl/session/squid_session.8:41
 msgid "acl session external session"
-msgstr ""
+msgstr "acl session external session"
 
 #. type: Plain text
 #: helpers/external_acl/session/squid_session.8:43
 msgid "http_access deny !session"
-msgstr ""
+msgstr "http_access deny !session"
 
 #. type: Plain text
 #: helpers/external_acl/session/squid_session.8:45
 msgid "deny_info http://your.server/bannerpage?url=%s session"
-msgstr ""
+msgstr "deny_info http://your.server/bannerpage?url=%s session"
 
 #. type: Plain text
 #: helpers/external_acl/session/squid_session.8:47
@@ -1194,13 +1199,13 @@ msgstr ""
 #. type: Plain text
 #: helpers/external_acl/session/squid_session.8:62
 msgid "B<squid>(B<8>)"
-msgstr ""
+msgstr "B<squid>(B<8>)"
 
 #. type: TH
 #: helpers/external_acl/unix_group/squid_unix_group.8:1
 #, no-wrap
 msgid "squid_unix_group"
-msgstr ""
+msgstr "squid_unix_group"
 
 #. type: TH
 #: helpers/external_acl/unix_group/squid_unix_group.8:1
@@ -1246,7 +1251,7 @@ msgstr ""
 #: helpers/external_acl/unix_group/squid_unix_group.8:17
 #, no-wrap
 msgid "B<-p>"
-msgstr ""
+msgstr "B<-p>"
 
 #. type: Plain text
 #: helpers/external_acl/unix_group/squid_unix_group.8:20
@@ -1257,7 +1262,7 @@ msgstr ""
 #: helpers/external_acl/unix_group/squid_unix_group.8:21
 #, no-wrap
 msgid "B<-s>"
-msgstr ""
+msgstr "B<-s>"
 
 #. type: Plain text
 #: helpers/external_acl/unix_group/squid_unix_group.8:24
@@ -1268,7 +1273,7 @@ msgstr ""
 #: helpers/external_acl/unix_group/squid_unix_group.8:25
 #, no-wrap
 msgid "EXAMPLES"
-msgstr ""
+msgstr "أمثلة"
 
 #. type: Plain text
 #: helpers/external_acl/unix_group/squid_unix_group.8:29
@@ -3,10 +3,9 @@
 # This file is distributed under the same license as the PACKAGE package.
 # FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
 #
-#, fuzzy
 msgid ""
 msgstr ""
-"Project-Id-Version: PACKAGE VERSION\n"
+"Project-Id-Version: Squid-3\n"
 "POT-Creation-Date: 2009-06-07 21:20+1200\n"
 "PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
 "Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
@@ -1,6 +1,6 @@
 <!doctype linuxdoc system>
 <article>
-<title>Squid 3.0.STABLE16 release notes</title>
+<title>Squid 3.0.STABLE18 release notes</title>
 <author>Squid Developers</author>
 
 <abstract>
@@ -13,7 +13,7 @@ for Applied Network Research and members of the Web Caching community.
 
 <sect>Notice
 <p>
-The Squid Team are pleased to announce the release of Squid-3.0.STABLE16.
+The Squid Team are pleased to announce the release of Squid-3.0.STABLE18.
 
 This new release is available for download from <url url="http://www.squid-cache.org/Versions/v3/3.0/"> or the <url url="http://www.squid-cache.org/Mirrors/http-mirrors.html" name="mirrors">.
 
@@ -2,10 +2,10 @@
 <HTML>
 <HEAD>
  <META NAME="GENERATOR" CONTENT="LinuxDoc-Tools 0.9.50">
- <TITLE>Squid 3.1.0.10 release notes</TITLE>
+ <TITLE>Squid 3.1.0.11 release notes</TITLE>
 </HEAD>
 <BODY>
-<H1>Squid 3.1.0.10 release notes</H1>
+<H1>Squid 3.1.0.11 release notes</H1>
 
 <H2>Squid Developers</H2>
 <HR>
@@ -32,6 +32,7 @@ <H2><A NAME="toc2">2.</A> <A HREF="#s2">Major new features since Squid-3.0</A></
 <LI><A NAME="toc2.6">2.6</A> <A HREF="#ss2.6">Quality of Service (QoS) Flow support</A>
 <LI><A NAME="toc2.7">2.7</A> <A HREF="#ss2.7">SSL Bump (for HTTPS Filtering and Adaptation)</A>
 <LI><A NAME="toc2.8">2.8</A> <A HREF="#ss2.8">eCAP Adaptation Module support</A>
+<LI><A NAME="toc2.9">2.9</A> <A HREF="#ss2.9">ICAP Bypass and Retry enhancements</A>
 </UL>
 <P>
 <H2><A NAME="toc3">3.</A> <A HREF="#s3">Windows support</A></H2>
@@ -80,7 +81,7 @@ <H2><A NAME="toc7">7.</A> <A HREF="#s7">Regressions since Squid-2.7</A></H2>
 <HR>
 <H2><A NAME="s1">1.</A> <A HREF="#toc1">Notice</A></H2>
 
-<P>The Squid Team are pleased to announce the release of Squid-3.1.0.10 for testing.</P>
+<P>The Squid Team are pleased to announce the release of Squid-3.1.0.11 for testing.</P>
 <P>This new release is available for download from 
 <A HREF="http://www.squid-cache.org/Versions/v3/3.1/">http://www.squid-cache.org/Versions/v3/3.1/</A> or the 
 <A HREF="http://www.squid-cache.org/Mirrors/http-mirrors.html">mirrors</A>.</P>
@@ -115,6 +116,7 @@ <H2><A NAME="s2">2.</A> <A HREF="#toc2">Major new features since Squid-3.0</A></
 <LI>Quality of Service (QoS) Flow support</LI>
 <LI>SSL Bump (for HTTPS Filtering and Adaptation)</LI>
 <LI>eCAP Adaptation Module support</LI>
+<LI>ICAP Bypass and Retry enhancements</LI>
 </UL>
 </P>
 <P>Most user-facing changes are reflected in squid.conf (see below).</P>
@@ -343,6 +345,67 @@ <H2><A NAME="ss2.8">2.8</A> <A HREF="#toc2.8">eCAP Adaptation Module support</A>
 <P>Details in 
 <A HREF="http://wiki.squid-cache.org/Features/eCAP">The Squid wiki</A></P>
 
+<H2><A NAME="ss2.9">2.9</A> <A HREF="#toc2.9">ICAP Bypass and Retry enhancements</A>
+</H2>
+
+<P>Details in 
+<A HREF="http://wiki.squid-cache.org/Features/ICAP">The Squid wiki</A></P>
+
+<P>ICAP is now extended with full bypass and dynamic chain routing to handle multiple
+adaptation services.</P>
+
+<H3>ICAP Adaptation Service Sets and Chains</H3>
+
+<P>An adaptation service set contains similar, interchangeable services. No more
+than one service is successfully applied. If one service is down or fails,
+Squid can use another service. Think "hot standby" or "spare" ICAP servers. </P>
+
+<P>Sets may seem similar to the existing "service bypass" feature, but they allow
+the failed adaptation to be retried and succeed if a replacement service is
+available. The services in a set may be all optional or all essential,
+depending on whether ignoring the entire set is acceptable. The mixture of
+optional and essential services in a set is supported, but yields results that
+may be difficult for a human to anticipate or interpret. Squid warns when it
+detects such a mixture.</P>
+
+<P>When performing adaptations with a set, failures at a service (optional or
+essential, does not matter) are retried with a different service if possible.
+If there are no more replacement services left to try, the failure is treated
+depending on whether the last service tried was optional or essential: Squid
+either tries to ignore the failure and proceed or terminates the master
+transaction.</P>
+
+<P>An adaptation chain is a list of different services applied one after another,
+forming an adaptation pipeline. Services in a chain may be optional or
+essential. When performing adaptations, failures at an optional service are
+ignored as if the service did not exist in the chain.</P>
+
+<P>Request satisfaction terminates the adaptation chain.</P>
+
+<P>When forming a set or chain for a given transaction, optional down services are ignored as if they did not exist.</P>
+
+<P>ICAP and eCAP services can be mixed and matched in an adaptation set or chain.</P>
+
+<H3>Dynamically form adaptation chains based on the ICAP X-Next-Services header.</H3>
+
+<P>If an ICAP service with the routing=1 option in squid.conf returns an ICAP
+X-Next-Services response header during a successful REQMOD or RESPMOD
+transaction, Squid abandons the original adaptation plan and forms a new
+adaptation chain consisting of services identified in the X-Next-Services
+header value (using a comma-separated list of adaptation service names from
+squid.conf).  The dynamically created chain is destroyed once the new plan is
+completed or replaced.</P>
+
+<P>This feature is useful when a custom adaptation service knows which other
+services are applicable to the message being adapted.</P>
+
+<P>Limit adaptation iterations to adaptation_service_iteration_limit to protect
+Squid from infinite adaptation loops caused by ICAP services constantly
+including themselves in the dynamic adaptation chain they request. When the
+limit is exceeded, the master transaction fails. The default limit of 16
+should be large enough to not require an explicit configuration in most
+environments yet may be small enough to limit side-effects of loops.</P>
+
 
 <H2><A NAME="s3">3.</A> <A HREF="#toc3">Windows support</A></H2>
 
@@ -627,29 +690,137 @@ <H2><A NAME="newtags"></A> <A NAME="ss4.1">4.1</A> <A HREF="#toc4.1">New tags</A
 
         It is currently not possible to apply more than one adaptation
         service at the same vectoring point to the same HTTP transaction.
+        
+</PRE>
+</P>
 
-        See also: icap_service and ecap_service
+<DT><B>adaptation_masterx_shared_names</B><DD>
+<P>
+<PRE>
+        For each master transaction (i.e., the HTTP request and response
+        sequence, including all related ICAP and eCAP exchanges), Squid
+        maintains a table of metadata. The table entries are (name, value)
+        pairs shared among eCAP and ICAP exchanges. The table is destroyed
+        with the master transaction.
+
+        This option specifies the table entry names that Squid must accept
+        from and forward to the adaptation transactions.
+
+        An ICAP REQMOD or RESPMOD transaction may set an entry in the 
+        shared table by returning an ICAP header field with a name 
+        specified in adaptation_masterx_shared_names. Squid will store 
+        and forward that ICAP header field to subsequent ICAP 
+        transactions within the same master transaction scope.
+
+        Only one shared entry name is supported at this time.
         
 </PRE>
 </P>
 
-<DT><B>adaptation_service_set</B><DD>
+<DT><B>adaptation_service_chain</B><DD>
 <P>
 <PRE>
-        Defines a named adaptation service set. The set is populated in
-        the order of adaptation_service_set directives in this file.
-        When adaptation ACLs are processed, the first and only the first
-        applicable adaptation service from the set will be used. Thus,
-        the set should group similar, redundant services, rather than a
-        chain of complementary services.
+        Configures a list of complementary services that will be applied
+        one-by-one, forming an adaptation chain or pipeline. This is useful
+        when Squid must perform different adaptations on the same message.
 
-        If you have a single adaptation service, you do not need to
-        define a set containing it because adaptation_access accepts
-        service names.
+            adaptation_service_chain chain_name service_name1 svc_name2 ...
 
-        Example:
-              adaptation_service_set svcBlocker urlFilterPrimary urlFilterBackup
-              adaptation service_set svcLogger loggerLocal loggerRemote
+        The named services are used in the chain declaration order. The first
+        applicable adaptation service from the chain is used first. The next
+        applicable service is applied to the successful adaptation results of
+        the previous service in the chain.
+
+        When adaptation starts, broken services are ignored as if they were
+        not a part of the chain. A broken service is a down optional service.
+
+        Request satisfaction terminates the adaptation chain because Squid
+        does not currently allow declaration of RESPMOD services at the
+        "reqmod_precache" vectoring point (see icap_service or ecap_service).
+
+        The services in a chain must be attached to the same vectoring point
+        (e.g., pre-cache) and use the same adaptation method (e.g., REQMOD).
+
+        A chain may contain a mix of optional and essential services. If an
+        essential adaptation fails (or the failure cannot be bypassed for
+        other reasons), the master transaction fails. Otherwise, the failure
+        is bypassed as if the failed adaptation service was not in the chain.
+        
+</PRE>
+</P>
+
+<DT><B>adaptation_service_iteration_limit</B><DD>
+<P>
+<PRE>
+        Limits the number of iterations allowed when applying adaptation
+        services to a message. If your longest adaptation set or chain
+        may have more than 16 services, increase the limit beyond its
+        default value of 16. If detecting infinite iteration loops sooner
+        is critical, make the iteration limit match the actual number
+        of services in your longest adaptation set or chain.
+
+        Infinite adaptation loops are most likely with routing services.
+        
+</PRE>
+</P>
+
+<DT><B>adaptation_service_set</B><DD>
+<P>
+<PRE>
+        Configures an ordered set of similar, redundant services. This is
+        useful when hot standby or backup adaptation servers are available.
+
+            adaptation_service_set set_name service_name1 service_name2 ...
+
+        The named services are used in the set declaration order. The first
+        applicable adaptation service from the set is used first. The next
+        applicable service is tried if and only if the transaction with the
+        previous service fails and the message waiting to be adapted is still
+        intact.
+
+        When adaptation starts, broken services are ignored as if they were
+        not a part of the set. A broken service is a down optional service.
+
+        The services in a set must be attached to the same vectoring point
+        (e.g., pre-cache) and use the same adaptation method (e.g., REQMOD).
+
+        If all services in a set are optional then adaptation failures are
+        bypassable. If all services in the set are essential, then a
+        transaction failure with one service may still be retried using
+        another service from the set, but when all services fail, the master
+        transaction fails as well.
+
+        A set may contain a mix of optional and essential services, but that
+        is likely to lead to surprising results because broken services become
+        ignored (see above), making previously bypassable failures fatal.
+        Technically, it is the bypassability of the last failed service that
+        matters.
+        
+</PRE>
+</P>
+
+<DT><B>chunked_request_body_max_size</B><DD>
+<P>New option to enable handing of broken HTTP/1.1 clients sending chunk requests.
+<PRE>
+        A broken or confused HTTP/1.1 client may send a chunked HTTP
+        request to Squid. Squid does not have full support for that
+        feature yet. To cope with such requests, Squid buffers the
+        entire request and then dechunks request body to create a
+        plain HTTP/1.0 request with a known content length. The plain
+        request is then used by the rest of Squid code as usual.
+
+        The option value specifies the maximum size of the buffer used
+        to hold the request before the conversion. If the chunked
+        request size exceeds the specified limit, the conversion
+        fails, and the client receives an "unsupported request" error,
+        as if dechunking was disabled.
+
+        Dechunking is enabled by default. To disable conversion of
+        chunked requests, set the maximum to zero.
+
+        Request dechunking feature and this option in particular are a
+        temporary hack. When chunking requests and responses are fully
+        supported, there will be no need to buffer a chunked request.
         
 </PRE>
 </P>
@@ -837,6 +1008,112 @@ <H2><A NAME="newtags"></A> <A NAME="ss4.1">4.1</A> <A HREF="#toc4.1">New tags</A
 <P>Controls how many different forward paths Squid will try
 before giving up. Default: 10</P>
 
+<DT><B>icap_log</B><DD>
+<P>New option to write ICAP log files record ICAP transaction summaries, one line per
+transaction. Similar to access.log.
+<PRE>
+        The icap_log option format is:
+                icap_log &lt;filepath> [&lt;logformat name> [acl acl ...]]
+                icap_log none [acl acl ...]]
+        
+        Please see access_log option documentation for details. The two
+        kinds of logs share the overall configuration approach and many
+        features.
+
+        ICAP processing of a single HTTP message or transaction may
+        require multiple ICAP transactions.  In such cases, multiple
+        ICAP transaction log lines will correspond to a single access
+        log line.
+
+        ICAP log uses logformat codes that make sense for an ICAP
+        transaction. Header-related codes are applied to the HTTP header
+        embedded in an ICAP server response, with the following caveats:
+        For REQMOD, there is no HTTP response header unless the ICAP
+        server performed request satisfaction. For RESPMOD, the HTTP
+        request header is the header sent to the ICAP server. For
+        OPTIONS, there are no HTTP headers.
+
+        The following format codes are also available for ICAP logs:
+
+                icap::&lt;A     ICAP server IP address. Similar to &lt;A.
+
+                icap::&lt;service_name  ICAP service name from the icap_service
+                                option in Squid configuration file.
+
+                icap::ru        ICAP Request-URI. Similar to ru.
+
+                icap::rm        ICAP request method (REQMOD, RESPMOD, or 
+                                OPTIONS). Similar to existing rm.
+
+                icap::>st       Bytes sent to the ICAP server (TCP payload
+                                only; i.e., what Squid writes to the socket).
+
+                icap::&lt;st    Bytes received from the ICAP server (TCP
+                                payload only; i.e., what Squid reads from
+                                the socket).
+
+                icap::tr        Transaction response time (in
+                                milliseconds).  The timer starts when
+                                the ICAP transaction is created and
+                                stops when the transaction is completed.
+                                Similar to tr.
+
+                icap::tio       Transaction I/O time (in milliseconds). The
+                                timer starts when the first ICAP request
+                                byte is scheduled for sending. The timers
+                                stops when the last byte of the ICAP response
+                                is received.
+
+                icap::to        Transaction outcome: ICAP_ERR* for all
+                                transaction errors, ICAP_OPT for OPTION
+                                transactions, ICAP_ECHO for 204
+                                responses, ICAP_MOD for message
+                                modification, and ICAP_SAT for request
+                                satisfaction. Similar to Ss.
+
+                icap::Hs        ICAP response status code. Similar to Hs.
+
+                icap::>h        ICAP request header(s). Similar to >h.
+
+                icap::&lt;h     ICAP response header(s). Similar to &lt;h.
+
+        The default ICAP log format, which can be used without an explicit
+        definition, is called icap_squid:
+
+logformat icap_squid %ts.%03tu %6icap::tr %>a %icap::to/%03icap::Hs %icap::&lt;size %icap::rm %icap::ru% %un -/%icap::&lt;A -
+        
+</PRE>
+</P>
+
+<DT><B>icap_retry</B><DD>
+<P>New option to determine which retriable ICAP transactions are
+retried.
+<PRE>
+        Transactions that received a complete ICAP response
+        and did not have to consume or produce HTTP bodies to receive
+        that response are usually retriable.
+
+                icap_retry allow|deny [!]aclname ...
+
+        Squid automatically retries some ICAP I/O timeouts and errors
+        due to persistent connection race conditions.
+        
+</PRE>
+</P>
+
+<DT><B>icap_retry_limit</B><DD>
+<P>
+<PRE>
+        Limits the number of retries allowed. When set to zero (default),
+        no retries are allowed.
+
+        Communication errors due to persistent connection race
+        conditions are unavoidable, automatically retried, and do not
+        count against this limit.
+        
+</PRE>
+</P>
+
 <DT><B>include</B><DD>
 <P>New option to import entire secondary configuration files into squid.conf.
 <PRE>
@@ -863,6 +1140,15 @@ <H2><A NAME="newtags"></A> <A NAME="ss4.1">4.1</A> <A HREF="#toc4.1">New tags</A
 </PRE>
 </P>
 
+<DT><B>log_icap aclname [aclname ...]</B><DD>
+<P>
+<PRE>
+        This options allows you to control which requests get logged
+        to icap.log. See the icap_log directive for ICAP log details.
+        
+</PRE>
+</P>
+
 <DT><B>log_uses_indirect_client</B><DD>
 <P>Whether to use any result found by follow_x_forwarded_for in access.log.
 Default: ON
@@ -933,8 +1219,6 @@ <H2><A NAME="newtags"></A> <A NAME="ss4.1">4.1</A> <A HREF="#toc4.1">New tags</A
         terminate the transaction. Bypassing validation errors is dangerous
         because an error usually implies that the server cannot be trusted and
         the connection may be insecure.
-
-        See also: sslproxy_flags and DONT_VERIFY_PEER.
         
 </PRE>
 </P>
@@ -1187,9 +1471,102 @@ <H2><A NAME="modifiedtags"></A> <A NAME="ss4.2">4.2</A> <A HREF="#toc4.2">Change
 <DT><B>https_port intercept sslbump connection-auth[=on|off]</B><DD>
 <P>New port options. see http_port.</P>
 
+<DT><B>icap_service bypass=on|off|1|0 routing=on|off|1|0</B><DD>
+<P>New options 'bypass=' and 'routing='.
+<PRE>
+        bypass=on|off|1|0
+                If set to 'on' or '1', the ICAP service is treated as
+                optional. If the service cannot be reached or malfunctions,
+                Squid will try to ignore any errors and process the message as
+                if the service was not enabled. No all ICAP errors can be
+                bypassed.  If set to 0, the ICAP service is treated as
+                essential and all ICAP errors will result in an error page
+                returned to the HTTP client.
+
+                Bypass is off by default: services are treated as essential.
+
+        routing=on|off|1|0
+                If set to 'on' or '1', the ICAP service is allowed to
+                dynamically change the current message adaptation plan by
+                returning a chain of services to be used next. The services
+                are specified using the X-Next-Services ICAP response header
+                value, formatted as a comma-separated list of service names.
+                Each named service should be configured in squid.conf and
+                should have the same method and vectoring point as the current
+                ICAP transaction.  Services violating these rules are ignored.
+                An empty X-Next-Services value results in an empty plan which
+                ends the current adaptation. 
+
+                Routing is not allowed by default: the ICAP X-Next-Services
+                response header is ignored.
+        
+</PRE>
+</P>
+
 <DT><B>logfile_rotate</B><DD>
 <P>No longer controls cache.log rotation. Use debug_options rotate=N instead.</P>
 
+<DT><B>logformat</B><DD>
+<P>New log format tag sets %icap::* %adapt::* for adaptation information.
+%Hs tag deprecated and replaced by request/reply specific &gt;Hs and &lt;Hs
+HTTP request/reply format tags may now be optionally prefixed with http::.
+Old forms will be deprecated in some as yet undecided future release.
+<PRE>
+                dt              Total time spent making DNS lookups (milliseconds)
+
+                [http::]>Hs     HTTP status code sent to the client
+                [http::]&lt;Hs  HTTP status code received from the next hop
+                [http::]>sh     Received HTTP request headers size
+                [http::]&lt;sh  Sent HTTP reply headers size
+                [http::]&lt;pt  Peer response time in milliseconds. The timer starts
+                                when the last request byte is sent to the next hop
+                                and stops when the last response byte is received.
+                [http::]&lt;tt  Total server-side time in milliseconds. The timer 
+                                starts with the first connect request (or write I/O)
+                                sent to the first selected peer. The timer stops
+                                with the last I/O with the last peer.
+
+        If ICAP is enabled, the following two codes become available (as
+        well as ICAP log codes documented with the icap_log option):
+
+                icap::tt        Total ICAP processing time for the HTTP
+                                transaction. The timer ticks when ICAP
+                                ACLs are checked and when ICAP
+                                transaction is in progress.
+
+                icap::&lt;last_h        The header of the last ICAP response
+                                related to the HTTP transaction. Like
+                                &lt;h, accepts an optional header name
+                                argument.  Will not change semantics
+                                when multiple ICAP transactions per HTTP
+                                transaction are supported.
+
+        If adaptation is enabled the following two codes become available:
+
+                adapt::sum_trs Summed adaptation transaction response
+                                times recorded as a comma-separated list in
+                                the order of transaction start time. Each time
+                                value is recorded as an integer number,
+                                representing response time of one or more
+                                adaptation (ICAP or eCAP) transaction in
+                                milliseconds.  When a failed transaction is
+                                being retried or repeated, its time is not
+                                logged individually but added to the
+                                replacement (next) transaction.
+
+                adapt::all_trs All adaptation transaction response times.
+                                Same as adaptation_strs but response times of
+                                individual transactions are never added
+                                together. Instead, all transaction response
+                                times are recorded individually.
+
+        You can prefix adapt::*_trs format codes with adaptation
+        service name in curly braces to record response time(s) specific
+        to that service. For example: %{my_service}adapt::sum_trs
+        
+</PRE>
+</P>
+
 <DT><B>maximum_object_size_in_memory</B><DD>
 <P>Default size limit increased to 512KB.</P>
 
@@ -1,6 +1,6 @@
 <!doctype linuxdoc system>
 <article>
-<title>Squid 3.1.0.10 release notes</title>
+<title>Squid 3.1.0.13 release notes</title>
 <author>Squid Developers</author>
 
 <abstract>
@@ -13,7 +13,7 @@ for Applied Network Research and members of the Web Caching community.
 
 <sect>Notice
 <p>
-The Squid Team are pleased to announce the release of Squid-3.1.0.10 for testing.
+The Squid Team are pleased to announce the release of Squid-3.1.0.13 for testing.
 
 This new release is available for download from <url url="http://www.squid-cache.org/Versions/v3/3.1/"> or the <url url="http://www.squid-cache.org/Mirrors/http-mirrors.html" name="mirrors">.
 
@@ -45,6 +45,7 @@ The most important of these new features are:
 	<item>Quality of Service (QoS) Flow support
 	<item>SSL Bump (for HTTPS Filtering and Adaptation)
 	<item>eCAP Adaptation Module support
+	<item>ICAP Bypass and Retry enhancements
 </itemize>
 
 Most user-facing changes are reflected in squid.conf (see below).
@@ -251,6 +252,65 @@ While decrypted, the traffic can be inspected using ICAP.
 
 <p>Details in <url url="http://wiki.squid-cache.org/Features/eCAP" name="The Squid wiki">
 
+<sect1>ICAP Bypass and Retry enhancements
+
+<p>Details in <url url="http://wiki.squid-cache.org/Features/ICAP" name="The Squid wiki">
+
+<p>ICAP is now extended with full bypass and dynamic chain routing to handle multiple
+  adaptation services.
+
+<sect2>ICAP Adaptation Service Sets and Chains
+
+<p>An adaptation service set contains similar, interchangeable services. No more
+  than one service is successfully applied. If one service is down or fails,
+  Squid can use another service. Think "hot standby" or "spare" ICAP servers. 
+
+<p>Sets may seem similar to the existing "service bypass" feature, but they allow
+  the failed adaptation to be retried and succeed if a replacement service is
+  available. The services in a set may be all optional or all essential,
+  depending on whether ignoring the entire set is acceptable. The mixture of
+  optional and essential services in a set is supported, but yields results that
+  may be difficult for a human to anticipate or interpret. Squid warns when it
+  detects such a mixture.
+
+<p>When performing adaptations with a set, failures at a service (optional or
+  essential, does not matter) are retried with a different service if possible.
+  If there are no more replacement services left to try, the failure is treated
+  depending on whether the last service tried was optional or essential: Squid
+  either tries to ignore the failure and proceed or terminates the master
+  transaction.
+
+<p>An adaptation chain is a list of different services applied one after another,
+  forming an adaptation pipeline. Services in a chain may be optional or
+  essential. When performing adaptations, failures at an optional service are
+  ignored as if the service did not exist in the chain.
+
+<p>Request satisfaction terminates the adaptation chain.
+
+<p>When forming a set or chain for a given transaction, optional down services are ignored as if they did not exist.
+
+<p>ICAP and eCAP services can be mixed and matched in an adaptation set or chain.
+
+<sect2>Dynamically form adaptation chains based on the ICAP X-Next-Services header.
+
+<p>If an ICAP service with the routing=1 option in squid.conf returns an ICAP
+  X-Next-Services response header during a successful REQMOD or RESPMOD
+  transaction, Squid abandons the original adaptation plan and forms a new
+  adaptation chain consisting of services identified in the X-Next-Services
+  header value (using a comma-separated list of adaptation service names from
+  squid.conf).  The dynamically created chain is destroyed once the new plan is
+  completed or replaced.
+
+<p>This feature is useful when a custom adaptation service knows which other
+  services are applicable to the message being adapted.
+
+<p>Limit adaptation iterations to adaptation_service_iteration_limit to protect
+  Squid from infinite adaptation loops caused by ICAP services constantly
+  including themselves in the dynamic adaptation chain they request. When the
+  limit is exceeded, the master transaction fails. The default limit of 16
+  should be large enough to not require an explicit configuration in most
+  environments yet may be small enough to limit side-effects of loops.
+
 
 <sect>Windows support
 <P>This Squid version can run on Windows as a system service using the Cygwin emulation environment, 
@@ -481,26 +541,123 @@ This section gives a thorough account of those changes in three categories:
 
 	It is currently not possible to apply more than one adaptation
 	service at the same vectoring point to the same HTTP transaction.
+	</verb>
 
-	See also: icap_service and ecap_service
+	<tag>adaptation_masterx_shared_names</tag>
+	<verb>
+	For each master transaction (i.e., the HTTP request and response
+	sequence, including all related ICAP and eCAP exchanges), Squid
+	maintains a table of metadata. The table entries are (name, value)
+	pairs shared among eCAP and ICAP exchanges. The table is destroyed
+	with the master transaction.
+
+	This option specifies the table entry names that Squid must accept
+	from and forward to the adaptation transactions.
+
+	An ICAP REQMOD or RESPMOD transaction may set an entry in the 
+	shared table by returning an ICAP header field with a name 
+	specified in adaptation_masterx_shared_names. Squid will store 
+	and forward that ICAP header field to subsequent ICAP 
+	transactions within the same master transaction scope.
+
+	Only one shared entry name is supported at this time.
 	</verb>
 
-	<tag>adaptation_service_set</tag>
+	<tag>adaptation_service_chain</tag>
 	<verb>
-	Defines a named adaptation service set. The set is populated in
-	the order of adaptation_service_set directives in this file.
-	When adaptation ACLs are processed, the first and only the first
-	applicable adaptation service from the set will be used. Thus,
-	the set should group similar, redundant services, rather than a
-	chain of complementary services.
+	Configures a list of complementary services that will be applied
+	one-by-one, forming an adaptation chain or pipeline. This is useful
+	when Squid must perform different adaptations on the same message.
 
-	If you have a single adaptation service, you do not need to
-	define a set containing it because adaptation_access accepts
-	service names.
+	    adaptation_service_chain chain_name service_name1 svc_name2 ...
 
-	Example:
-	      adaptation_service_set svcBlocker urlFilterPrimary urlFilterBackup
-	      adaptation service_set svcLogger loggerLocal loggerRemote
+ 	The named services are used in the chain declaration order. The first
+	applicable adaptation service from the chain is used first. The next
+	applicable service is applied to the successful adaptation results of
+	the previous service in the chain.
+
+	When adaptation starts, broken services are ignored as if they were
+	not a part of the chain. A broken service is a down optional service.
+
+	Request satisfaction terminates the adaptation chain because Squid
+	does not currently allow declaration of RESPMOD services at the
+	"reqmod_precache" vectoring point (see icap_service or ecap_service).
+
+	The services in a chain must be attached to the same vectoring point
+	(e.g., pre-cache) and use the same adaptation method (e.g., REQMOD).
+
+	A chain may contain a mix of optional and essential services. If an
+	essential adaptation fails (or the failure cannot be bypassed for
+	other reasons), the master transaction fails. Otherwise, the failure
+	is bypassed as if the failed adaptation service was not in the chain.
+	</verb>
+
+	<tag>adaptation_service_iteration_limit</tag>
+	<verb>
+	Limits the number of iterations allowed when applying adaptation
+	services to a message. If your longest adaptation set or chain
+	may have more than 16 services, increase the limit beyond its
+	default value of 16. If detecting infinite iteration loops sooner
+	is critical, make the iteration limit match the actual number
+	of services in your longest adaptation set or chain.
+
+	Infinite adaptation loops are most likely with routing services.
+	</verb>
+
+	<tag>adaptation_service_set</tag>
+	<verb>
+	Configures an ordered set of similar, redundant services. This is
+	useful when hot standby or backup adaptation servers are available.
+
+	    adaptation_service_set set_name service_name1 service_name2 ...
+
+ 	The named services are used in the set declaration order. The first
+	applicable adaptation service from the set is used first. The next
+	applicable service is tried if and only if the transaction with the
+	previous service fails and the message waiting to be adapted is still
+	intact.
+
+	When adaptation starts, broken services are ignored as if they were
+	not a part of the set. A broken service is a down optional service.
+
+	The services in a set must be attached to the same vectoring point
+	(e.g., pre-cache) and use the same adaptation method (e.g., REQMOD).
+
+	If all services in a set are optional then adaptation failures are
+	bypassable. If all services in the set are essential, then a
+	transaction failure with one service may still be retried using
+	another service from the set, but when all services fail, the master
+	transaction fails as well.
+
+	A set may contain a mix of optional and essential services, but that
+	is likely to lead to surprising results because broken services become
+	ignored (see above), making previously bypassable failures fatal.
+	Technically, it is the bypassability of the last failed service that
+	matters.
+	</verb>
+
+	<tag>chunked_request_body_max_size</tag>
+	<p>New option to enable handing of broken HTTP/1.1 clients sending chunk requests.
+	<verb>
+	A broken or confused HTTP/1.1 client may send a chunked HTTP
+	request to Squid. Squid does not have full support for that
+	feature yet. To cope with such requests, Squid buffers the
+	entire request and then dechunks request body to create a
+	plain HTTP/1.0 request with a known content length. The plain
+	request is then used by the rest of Squid code as usual.
+
+	The option value specifies the maximum size of the buffer used
+	to hold the request before the conversion. If the chunked
+	request size exceeds the specified limit, the conversion
+	fails, and the client receives an "unsupported request" error,
+	as if dechunking was disabled.
+
+	Dechunking is enabled by default. To disable conversion of
+	chunked requests, set the maximum to zero.
+
+	Request dechunking feature and this option in particular are a
+	temporary hack. When chunking requests and responses are fully
+	supported, there will be no need to buffer a chunked request.
 	</verb>
 
 	<tag>delay_pool_uses_indirect_client</tag>
@@ -668,6 +825,105 @@ This section gives a thorough account of those changes in three categories:
 	<p>Controls how many different forward paths Squid will try
 	before giving up. Default: 10
 
+	<tag>icap_log</tag>
+	<p>New option to write ICAP log files record ICAP transaction summaries, one line per
+        transaction. Similar to access.log.
+	<verb>
+	The icap_log option format is:
+		icap_log <filepath> [<logformat name> [acl acl ...]]
+		icap_log none [acl acl ...]]
+	
+	Please see access_log option documentation for details. The two
+	kinds of logs share the overall configuration approach and many
+	features.
+
+	ICAP processing of a single HTTP message or transaction may
+	require multiple ICAP transactions.  In such cases, multiple
+	ICAP transaction log lines will correspond to a single access
+	log line.
+
+	ICAP log uses logformat codes that make sense for an ICAP
+	transaction. Header-related codes are applied to the HTTP header
+	embedded in an ICAP server response, with the following caveats:
+	For REQMOD, there is no HTTP response header unless the ICAP
+	server performed request satisfaction. For RESPMOD, the HTTP
+	request header is the header sent to the ICAP server. For
+	OPTIONS, there are no HTTP headers.
+
+	The following format codes are also available for ICAP logs:
+
+		icap::<A	ICAP server IP address. Similar to <A.
+
+		icap::<service_name	ICAP service name from the icap_service
+				option in Squid configuration file.
+
+		icap::ru	ICAP Request-URI. Similar to ru.
+
+		icap::rm	ICAP request method (REQMOD, RESPMOD, or 
+				OPTIONS). Similar to existing rm.
+
+		icap::>st	Bytes sent to the ICAP server (TCP payload
+				only; i.e., what Squid writes to the socket).
+
+		icap::<st	Bytes received from the ICAP server (TCP
+				payload only; i.e., what Squid reads from
+				the socket).
+
+		icap::tr 	Transaction response time (in
+				milliseconds).  The timer starts when
+				the ICAP transaction is created and
+				stops when the transaction is completed.
+				Similar to tr.
+
+		icap::tio	Transaction I/O time (in milliseconds). The
+				timer starts when the first ICAP request
+				byte is scheduled for sending. The timers
+				stops when the last byte of the ICAP response
+				is received.
+
+		icap::to 	Transaction outcome: ICAP_ERR* for all
+				transaction errors, ICAP_OPT for OPTION
+				transactions, ICAP_ECHO for 204
+				responses, ICAP_MOD for message
+				modification, and ICAP_SAT for request
+				satisfaction. Similar to Ss.
+
+		icap::Hs	ICAP response status code. Similar to Hs.
+
+		icap::>h	ICAP request header(s). Similar to >h.
+
+		icap::<h	ICAP response header(s). Similar to <h.
+
+	The default ICAP log format, which can be used without an explicit
+	definition, is called icap_squid:
+
+logformat icap_squid %ts.%03tu %6icap::tr %>a %icap::to/%03icap::Hs %icap::<size %icap::rm %icap::ru% %un -/%icap::<A -
+	</verb>
+
+	<tag>icap_retry</tag>
+	<p>New option to determine which retriable ICAP transactions are
+	retried.
+	<verb>
+	Transactions that received a complete ICAP response
+	and did not have to consume or produce HTTP bodies to receive
+	that response are usually retriable.
+
+		icap_retry allow|deny [!]aclname ...
+
+	Squid automatically retries some ICAP I/O timeouts and errors
+	due to persistent connection race conditions.
+	</verb>
+
+	<tag>icap_retry_limit</tag>
+	<verb>
+	Limits the number of retries allowed. When set to zero (default),
+	no retries are allowed.
+
+	Communication errors due to persistent connection race
+	conditions are unavoidable, automatically retried, and do not
+	count against this limit.
+	</verb>
+
 	<tag>include</tag>
 	<p>New option to import entire secondary configuration files into squid.conf.
 	<verb>
@@ -690,6 +946,12 @@ This section gives a thorough account of those changes in three categories:
 	      loadable_modules @DEFAULT_PREFIX@/lib/MinimalAdapter.so
 	</verb>
 
+	<tag>log_icap aclname [aclname ...]</tag>
+	<verb>
+	This options allows you to control which requests get logged
+	to icap.log. See the icap_log directive for ICAP log details.
+	</verb>
+
 	<tag>log_uses_indirect_client</tag>
 	<p>Whether to use any result found by follow_x_forwarded_for in access.log.
 	   Default: ON
@@ -751,8 +1013,6 @@ NOCOMMENT_START
 	terminate the transaction. Bypassing validation errors is dangerous
 	because an error usually implies that the server cannot be trusted and
 	the connection may be insecure.
-
-	See also: sslproxy_flags and DONT_VERIFY_PEER.
 	</verb>
 
 	<tag>qos_flows local-hit= sibling-hit= parent-hit=</tag>
@@ -981,9 +1241,98 @@ NOCOMMENT_START
 	<tag>https_port intercept sslbump connection-auth[=on|off]</tag>
 	<p>New port options. see http_port.
 
+	<tag>icap_service bypass=on|off|1|0 routing=on|off|1|0</tag>
+	<p>New options 'bypass=' and 'routing='.
+	<verb>
+	bypass=on|off|1|0
+		If set to 'on' or '1', the ICAP service is treated as
+		optional. If the service cannot be reached or malfunctions,
+		Squid will try to ignore any errors and process the message as
+		if the service was not enabled. No all ICAP errors can be
+		bypassed.  If set to 0, the ICAP service is treated as
+		essential and all ICAP errors will result in an error page
+		returned to the HTTP client.
+
+		Bypass is off by default: services are treated as essential.
+
+	routing=on|off|1|0
+		If set to 'on' or '1', the ICAP service is allowed to
+		dynamically change the current message adaptation plan by
+		returning a chain of services to be used next. The services
+		are specified using the X-Next-Services ICAP response header
+		value, formatted as a comma-separated list of service names.
+		Each named service should be configured in squid.conf and
+		should have the same method and vectoring point as the current
+		ICAP transaction.  Services violating these rules are ignored.
+		An empty X-Next-Services value results in an empty plan which
+		ends the current adaptation. 
+
+		Routing is not allowed by default: the ICAP X-Next-Services
+		response header is ignored.
+	</verb>
+
 	<tag>logfile_rotate</tag>
 	<p>No longer controls cache.log rotation. Use debug_options rotate=N instead.
 
+	<tag>logformat</tag>
+	<p>New log format tag sets %icap::* %adapt::* for adaptation information.
+	   %Hs tag deprecated and replaced by request/reply specific &gt;Hs and &lt;Hs
+	   HTTP request/reply format tags may now be optionally prefixed with http::.
+	   Old forms will be deprecated in some as yet undecided future release.
+	<verb>
+		dt		Total time spent making DNS lookups (milliseconds)
+
+		[http::]>Hs	HTTP status code sent to the client
+		[http::]<Hs	HTTP status code received from the next hop
+		[http::]>sh	Received HTTP request headers size
+		[http::]<sh	Sent HTTP reply headers size
+		[http::]<pt	Peer response time in milliseconds. The timer starts
+				when the last request byte is sent to the next hop
+				and stops when the last response byte is received.
+		[http::]<tt	Total server-side time in milliseconds. The timer 
+				starts with the first connect request (or write I/O)
+				sent to the first selected peer. The timer stops
+				with the last I/O with the last peer.
+
+	If ICAP is enabled, the following two codes become available (as
+	well as ICAP log codes documented with the icap_log option):
+
+		icap::tt        Total ICAP processing time for the HTTP
+				transaction. The timer ticks when ICAP
+				ACLs are checked and when ICAP
+				transaction is in progress.
+
+		icap::<last_h	The header of the last ICAP response
+				related to the HTTP transaction. Like
+				<h, accepts an optional header name
+				argument.  Will not change semantics
+				when multiple ICAP transactions per HTTP
+				transaction are supported.
+
+	If adaptation is enabled the following two codes become available:
+
+		adapt::sum_trs Summed adaptation transaction response
+				times recorded as a comma-separated list in
+				the order of transaction start time. Each time
+				value is recorded as an integer number,
+				representing response time of one or more
+				adaptation (ICAP or eCAP) transaction in
+				milliseconds.  When a failed transaction is
+				being retried or repeated, its time is not
+				logged individually but added to the
+				replacement (next) transaction.
+
+		adapt::all_trs All adaptation transaction response times.
+				Same as adaptation_strs but response times of
+				individual transactions are never added
+				together. Instead, all transaction response
+				times are recorded individually.
+
+	You can prefix adapt::*_trs format codes with adaptation
+	service name in curly braces to record response time(s) specific
+	to that service. For example: %{my_service}adapt::sum_trs
+	</verb>
+
 	<tag>maximum_object_size_in_memory</tag>
 	<p>Default size limit increased to 512KB.
 
@@ -10,11 +10,13 @@ errordir = $(datadir)/errors
 DEFAULT_ERROR_DIR	= $(errordir)
 DEFAULT_STYLESHEET	= $(sysconfdir)/errorpage.css
 
-# List of automated translations possible:
+## List of automated translations possible:
 TRANSLATIONPO=`ls -1 $(top_srcdir)/errors/*.po | grep -o -E "[a-z\-]+\.po" | sed s/.po//`
 TRANSLATIONDIR=`ls -1 $(srcdir) $(builddir) | sed -e 's%$(srcdir)/%%' -e 's%$(builddir)/%%' -e 's%.po%%' `
 
+## TODO: prevent this loop installing everything twice when srcdir == builddir
 install-data-local:
+	$(mkinstalldirs) $(DESTDIR)$(DEFAULT_ERROR_DIR) ; \
 	for l in $(TRANSLATIONDIR) ; do \
 	  echo "Located $$l for install..."; \
 	  if test -d $(srcdir)/$$l; then \
@@ -32,8 +34,8 @@ install-data-local:
 		done; \
 	  fi \
 	done; \
-	$(INSTALL_DATA) $(srcdir)/TRANSLATORS $(DESTDIR)TRANSLATORS; \
-	$(INSTALL_DATA) $(srcdir)/COPYRIGHT $(DESTDIR)COPYRIGHT; \
+	$(INSTALL_DATA) $(srcdir)/TRANSLATORS $(DESTDIR)$(DEFAULT_ERROR_DIR)/TRANSLATORS; \
+	$(INSTALL_DATA) $(srcdir)/COPYRIGHT $(DESTDIR)$(DEFAULT_ERROR_DIR)/COPYRIGHT; \
 	$(INSTALL_DATA) $(srcdir)/errorpage.css $(DESTDIR)$(DEFAULT_STYLESHEET).default; \
 	if test -f $(DESTDIR)$(DEFAULT_STYLESHEET) ; then \
 		echo "$@ will not overwrite existing $(DESTDIR)$(DEFAULT_STYLESHEET)" ; \
@@ -64,8 +66,8 @@ uninstall-local:
 	done;
 	@$(SHELL) $(top_srcdir)/scripts/remove-cfg.sh "$(RM)" $(DESTDIR)$(DEFAULT_STYLESHEET)
 	rm -f $(DESTDIR)$(DEFAULT_STYLESHEET).default
-	rm -f $(DESTDIR)TRANSLATORS
-	rm -f $(DESTDIR)COPYRIGHT
+	rm -f $(DESTDIR)$(DEFAULT_ERROR_DIR)/TRANSLATORS
+	rm -f $(DESTDIR)$(DEFAULT_ERROR_DIR)/COPYRIGHT
 
 ## Upgrade requires the new files to be pre-installed
 upgrade: install
@@ -3,20 +3,21 @@ az	az-az
 bg	bg-bg
 cs	cs-cz
 da	da-dk
-de	de-de
+de	de-at de-ch de-de de-li de-lu
 el	el-gr
-en	en-au en-ca en-gb en-in en-nz en-sg en-tt en-uk en-za
-es	es-ar es-pe es-es
+en	en-au en-bz en-ca en-gb en-ie en-in en-jm en-nz en-ph en-sg en-tt en-uk en-us en-za en-zw
+es	es-ar es-bo es-cl es-co es-cr es-do es-ec es-es es-gt es-hn es-mx es-ni es-pa es-pe es-pr es-py es-sv es-uy es-ve
 et	et-ee
+fa	fa-fa fa-ir
 fi	fi-fi
-fr	fr-fr
+fr	fr-be fr-ca fr-ch fr-fr fr-lu fr-mc
 he	he-il
 hu	hu-hu
 hy	hy-am
 id	id-id
-it	it-it
+it	it-ch it-it
 ja	ja-jp
-ko	ko-kr
+ko	ko-kp ko-kr
 lt	lt-lt
 lv	lv-lv
 ms	ms-my
@@ -27,7 +28,7 @@ ro	ro-ro
 ru	ru-ru
 sk	sk-sk
 sr	sr-sp
-sv	sv-se
+sv	sv-fi sv-se
 th	th-th
 tr	tr-tr
 uk	uk-ua
@@ -2,62 +2,59 @@ msgid ""
 msgstr ""
 "Project-Id-Version: Squid-3\n"
 "Report-Msgid-Bugs-To: \n"
-"POT-Creation-Date: 2009-06-14 18:15+1300\n"
-"PO-Revision-Date: 2008-11-07 05:16+1300\n"
+"POT-Creation-Date: 2009-06-14 18:16+1300\n"
+"PO-Revision-Date: 2009-07-21 14:27+0000\n"
 "Last-Translator: Francesco Chemolli <kinkie@squid-cache.org>\n"
 "Language-Team: LANGUAGE <LL@li.org>\n"
 "MIME-Version: 1.0\n"
 "Content-Type: text/plain; charset=UTF-8\n"
 "Content-Transfer-Encoding: 8bit\n"
-"X-Generator: Pootle 1.1.0\n"
+"X-Launchpad-Export-Date: 2009-07-22 10:00+0000\n"
+"X-Generator: Launchpad (build Unknown)\n"
 
 #: templates/ERR_FTP_LISTING:6
-msgid "<a href=\"../\">Parent Directory</a> (<a href=\"/\">Root Directory</a>)"
+msgid ""
+"<a href=\"../\">Parent Directory</a> (<a href=\"/\">Root Directory</a>)"
 msgstr ""
-"<a href=\"../\">Directory di Livello Superiore</a> (<a href=\"/\">Directory "
-"Radice</a>)"
+"<a href=\"../\">Directory superiore</a> (<a href=\"/\">Directory radice</a>)"
 
 #: templates/ERR_INVALID_REQ:4
 msgid ""
 "<b>Invalid Request</b> error was encountered while trying to process the "
 "request:"
 msgstr ""
-"<b>Richiesta invalida</b>. C'è stato un errore mentre si cercava di "
-"elaborare la richiesta:"
+"<b>Richiesta non valida</b>. Si è verificato un errore durante "
+"l'elaborazione della richiesta:"
 
 #: templates/ERR_INVALID_RESP:4
 msgid ""
 "<b>Invalid Response</b> error was encountered while trying to process the "
 "request:"
 msgstr ""
-"<b>Risposta non valida</b>. Si è verificato un errore mentre veniva "
-"elaborata la richiesta:"
+"<b>Risposta non valida</b>. Si è verificato un errore durante l'elaborazione "
+"della richiesta:"
 
 #: templates/ERR_READ_TIMEOUT:7
 msgid ""
 "A Timeout occurred while waiting to read data from the network.  The network "
 "or server may be down or congested.  Please retry your request."
 msgstr ""
-"Si è verificato un timeout mentre si attendeva di ricevere dati dalla rete. "
-"La rete o il server potrebbero essere sovraccarichi o indisponibili. Si "
-"prega di ritentare la richiesta tra qualche minuto."
+"Si è verificato un timeout durante la ricezione dei dati dalla rete. La rete "
+"o il server potrebbero essere scollegati o in congestione. Riprovare più "
+"tardi."
 
 #: templates/ERR_URN_RESOLVE:3
 msgid "A URL for the requested URN could not be retrieved"
 msgstr ""
 "Non è stato possibile ottenere una URL corrispondente alla URN richiesta."
 
-#: templates/ERR_ACCESS_DENIED:5
-msgid "Access Denied."
-msgstr "Accesso negato."
-
 #: templates/ERR_ACCESS_DENIED:6
 msgid ""
 "Access control configuration prevents your request from being allowed at "
 "this time.  Please contact your service provider if you feel this is "
 "incorrect."
 msgstr ""
-"Le configurazioni di controllo dell'accesso impediscono di soddisfare la "
+"La configurazione di controllo d'accesso non consente di soddisfare la "
 "richiesta. Si prega di contattare il fornitore del servizio nel caso questo "
 "comportamento sia scorretto."
 
@@ -66,20 +63,20 @@ msgid ""
 "An FTP authentication failure occurred while trying to retrieve the URL: <a "
 "href=\"%U\">%U</a>"
 msgstr ""
-"Le credenziali fornite per l'accesso al server FTP relativo alla URL <a href="
-"\"%U\">%U</a> sono invalide."
+"Le credenziali fornite per l'accesso al server FTP relativo alla URL <a "
+"href=\"%U\">%U</a> sono invalide."
 
 #: templates/ERR_FTP_FAILURE:4
 msgid ""
-"An FTP protocol error occurred while trying to retrieve the URL: <a href=\"%U"
-"\">%U</a>"
+"An FTP protocol error occurred while trying to retrieve the URL: <a "
+"href=\"%U\">%U</a>"
 msgstr ""
-"Si è verificato un errore di protocollo FTP durante il dialogo con il server "
-"mentre si accedeva alla URL <a href=\"%U\">%U</a>."
+"Si è verificato un errore di protocollo FTP durante l'accesso alla URL <a "
+"href=\"%U\">%U</a>."
 
 #: templates/ERR_ICAP_FAILURE:10
 msgid "An Illegal response was received from the ICAP server."
-msgstr "Il server ICAP ha dato una risposta irregolare (illegal response)."
+msgstr "Il server ICAP ha dato una risposta non valida (illegal response)."
 
 #: templates/ERR_READ_ERROR:7
 msgid ""
@@ -97,67 +94,35 @@ msgstr ""
 "Si è verificato un errore durante la ricezione dei dati dalla rete. Si prega "
 "di ritentare la richiesta."
 
-#: templates/ERR_CACHE_ACCESS_DENIED:3 templates/ERR_CACHE_ACCESS_DENIED:5
-msgid "Cache Access Denied."
-msgstr "Accesso alla cache negato."
-
 #: templates/ERR_CACHE_MGR_ACCESS_DENIED:3
 #: templates/ERR_CACHE_MGR_ACCESS_DENIED:5
 msgid "Cache Manager Access Denied."
 msgstr "L'accesso al cache manager è negato."
 
-#: templates/ERR_URN_RESOLVE:5
-msgid "Cannot Resolve URN"
-msgstr "Impossibile risolvere la URN."
-
 #: templates/ERR_LIFETIME_EXP:5
 msgid "Connection Lifetime Expired"
 msgstr "Il timeout di mantenimento della connessione è scaduto."
 
 #: templates/ERR_CONNECT_FAIL:5
 msgid "Connection to %I failed."
-msgstr "La connessione a %I è fallita."
+msgstr "La connessione a %I non è riuscita."
 
 #: templates/ERR_INVALID_REQ:10
 msgid "Content-Length missing for POST or PUT requests."
 msgstr ""
-"Richiesta non valida: una richiesta di tipo POST oppure PUT non contiene il "
-"campo Content-Length."
+"Una richiesta di tipo POST o PUT non contiene il campo Content-Length."
 
 #: templates/ERR_FTP_LISTING:3
 msgid "Directory Content:"
-msgstr "Contenuto della Directory:"
-
-#: templates/ERR_ACCESS_DENIED:2 templates/ERR_CACHE_ACCESS_DENIED:2
-#: templates/ERR_CACHE_MGR_ACCESS_DENIED:2 templates/ERR_CANNOT_FORWARD:2
-#: templates/ERR_CONNECT_FAIL:2 templates/ERR_DNS_FAIL:2 templates/ERR_ESI:2
-#: templates/ERR_FORWARDING_DENIED:2 templates/ERR_FTP_DISABLED:2
-#: templates/ERR_FTP_FAILURE:2 templates/ERR_FTP_FORBIDDEN:2
-#: templates/ERR_FTP_NOT_FOUND:2 templates/ERR_FTP_PUT_ERROR:2
-#: templates/ERR_FTP_UNAVAILABLE:2 templates/ERR_ICAP_FAILURE:2
-#: templates/ERR_INVALID_REQ:2 templates/ERR_INVALID_RESP:2
-#: templates/ERR_INVALID_URL:2 templates/ERR_LIFETIME_EXP:2
-#: templates/ERR_NO_RELAY:2 templates/ERR_ONLY_IF_CACHED_MISS:2
-#: templates/ERR_READ_ERROR:2 templates/ERR_READ_TIMEOUT:2
-#: templates/ERR_SECURE_CONNECT_FAIL:2 templates/ERR_SHUTTING_DOWN:2
-#: templates/ERR_SOCKET_FAILURE:2 templates/ERR_TOO_BIG:2
-#: templates/ERR_UNSUP_HTTPVERSION:2 templates/ERR_UNSUP_REQ:2
-#: templates/ERR_URN_RESOLVE:2 templates/ERR_WRITE_ERROR:2
-#: templates/ERR_ZERO_SIZE_OBJECT:2
-msgid "ERROR"
-msgstr "ERRORE"
-
-#: templates/ERR_CACHE_ACCESS_DENIED:1
-msgid "ERROR: Cache Access Denied"
-msgstr "ERRORE: accesso alla cache negato."
+msgstr "Contenuto della directory:"
 
 #: templates/ERR_CACHE_MGR_ACCESS_DENIED:1
 msgid "ERROR: Cache Manager Access Denied"
 msgstr "ERRORE: l'accesso al Cache Manager è negato."
 
 #: templates/ERR_FTP_PUT_ERROR:1
 msgid "ERROR: FTP upload failed"
-msgstr "ERRORE: l'invio del file via FTP è fallito."
+msgstr "ERRORE: l'invio del file via FTP non ha avuto successo."
 
 #: templates/ERR_ACCESS_DENIED:1 templates/ERR_CANNOT_FORWARD:1
 #: templates/ERR_CONNECT_FAIL:1 templates/ERR_DNS_FAIL:1 templates/ERR_ESI:1
@@ -174,87 +139,47 @@ msgstr "ERRORE: l'invio del file via FTP è fallito."
 #: templates/ERR_UNSUP_REQ:1 templates/ERR_WRITE_ERROR:1
 #: templates/ERR_ZERO_SIZE_OBJECT:1
 msgid "ERROR: The requested URL could not be retrieved"
-msgstr "ERRORE: non è stato possibile accedere alla URL richiesta"
+msgstr "ERRORE: non è possibile accedere alla URL richiesta"
 
 #: templates/ERR_URN_RESOLVE:1
 msgid "ERROR: The requested URN not be retrieved"
-msgstr "ERRORE: non è stato possibile accedere alla URN richiesta"
+msgstr "ERRORE: non è possibile accedere alla URN richiesta"
 
 #: templates/ERR_ESI:5
 msgid "ESI Processing failed."
 msgstr "L'elaborazione ESI è fallita."
 
 #: templates/ERR_FTP_LISTING:4
 msgid "FTP Directory Listing"
-msgstr "Lista della Directory FTP"
-
-#: templates/ERR_FTP_LISTING:1
-msgid "FTP Directory: %U"
-msgstr "Directory FTP: %U"
-
-#: templates/ERR_FTP_LISTING:2
-msgid "FTP Directory: <a href=\"/\">%U</a>/"
-msgstr "Directory FTP: <a href=\"/\">%U</a>/"
+msgstr "Elenco della directory FTP"
 
 #: templates/ERR_FTP_PUT_CREATED:1
 msgid "FTP PUT Successful: File Created"
-msgstr "L'invio dati (PUT) FTP ha avuto successo: il file è stato creato."
+msgstr "Comando FTP PUT eseguito correttamente: il file è stato creato."
 
 #: templates/ERR_FTP_PUT_MODIFIED:1
 msgid "FTP PUT Successful: File Updated"
-msgstr "L'invio dati (PUT) FTP ha avuto successo: il file è stato aggiornato."
+msgstr "Comando FTP PUT eseguito correttamente: il file è stato aggiornato."
 
 #: templates/ERR_FTP_PUT_ERROR:3
 msgid "FTP PUT/upload failed"
-msgstr "L'invio dati (PUT) FTP è fallito."
+msgstr "Comando FTP PUT non riuscito."
 
 #: templates/ERR_FTP_DISABLED:5
 msgid "FTP is Disabled"
-msgstr "Il protocollo FTP non è disponibile (disabilitato)."
+msgstr "Il protocollo FTP è disabilitato."
 
 #: templates/ERR_SECURE_CONNECT_FAIL:5
 msgid "Failed to establish a secure connection to %I"
 msgstr "Non è stato possibile stabilire una connessione sicura verso %I"
 
-#: templates/ERR_FTP_PUT_CREATED:3
-msgid "File created"
-msgstr "Il file è stato creato."
-
-#: templates/ERR_FTP_PUT_MODIFIED:3
-msgid "File updated"
-msgstr "Il file è stato aggiornato."
-
-#: templates/ERR_FORWARDING_DENIED:5
-msgid "Forwarding Denied."
-msgstr "Inoltro negato."
-
-#: templates/ERR_ACCESS_DENIED:8 templates/ERR_CACHE_ACCESS_DENIED:8
-#: templates/ERR_CACHE_MGR_ACCESS_DENIED:8 templates/ERR_CANNOT_FORWARD:8
-#: templates/ERR_CONNECT_FAIL:9 templates/ERR_DNS_FAIL:9 templates/ERR_ESI:9
-#: templates/ERR_FORWARDING_DENIED:8 templates/ERR_FTP_DISABLED:8
-#: templates/ERR_FTP_FAILURE:8 templates/ERR_FTP_FORBIDDEN:8
-#: templates/ERR_FTP_LISTING:7 templates/ERR_FTP_NOT_FOUND:9
-#: templates/ERR_FTP_PUT_CREATED:4 templates/ERR_FTP_PUT_ERROR:9
-#: templates/ERR_FTP_PUT_MODIFIED:4 templates/ERR_FTP_UNAVAILABLE:8
-#: templates/ERR_ICAP_FAILURE:11 templates/ERR_INVALID_REQ:13
-#: templates/ERR_INVALID_RESP:8 templates/ERR_INVALID_URL:13
-#: templates/ERR_LIFETIME_EXP:8 templates/ERR_NO_RELAY:8
-#: templates/ERR_ONLY_IF_CACHED_MISS:8 templates/ERR_READ_ERROR:9
-#: templates/ERR_READ_TIMEOUT:9 templates/ERR_SECURE_CONNECT_FAIL:9
-#: templates/ERR_SHUTTING_DOWN:7 templates/ERR_SOCKET_FAILURE:9
-#: templates/ERR_TOO_BIG:10 templates/ERR_UNSUP_HTTPVERSION:8
-#: templates/ERR_UNSUP_REQ:8 templates/ERR_URN_RESOLVE:8
-#: templates/ERR_WRITE_ERROR:9 templates/ERR_ZERO_SIZE_OBJECT:8
-msgid "Generated %T by %h (%s)"
-msgstr "Generato da %h (%s) il %T."
-
 #: templates/ERR_URN_RESOLVE:6
 msgid "Hey, don't expect too much from URNs on %T :)"
 msgstr "Hey, non ci si deve aspettare granchè dalle URN su %T :)"
 
 #: templates/ERR_ICAP_FAILURE:5
 msgid "ICAP protocol error."
-msgstr "Si è verificato un errore nel dialogo ICAP."
+msgstr "Si è verificato un errore di protocollo ICAP."
 
 #: templates/ERR_TOO_BIG:7
 msgid ""
@@ -280,58 +205,37 @@ msgstr ""
 
 #: templates/ERR_INVALID_URL:10
 msgid "Illegal double-escape in the URL-Path"
-msgstr ""
-"Doppia codifica (\"double-escape\") irregolare nella porzione Path della URL."
-
-#: templates/ERR_INVALID_URL:5
-msgid "Invalid URL"
-msgstr "URL non valida"
-
-#: templates/ERR_INVALID_REQ:8
-msgid "Missing HTTP Identifier (HTTP/1.0)."
-msgstr "L'identificativo del protocollo HTTP è mancante (HTTP/1.0)."
-
-#: templates/ERR_INVALID_REQ:7
-msgid "Missing URL."
-msgstr "URL non specificata."
-
-#: templates/ERR_INVALID_URL:9
-msgid "Missing hostname"
-msgstr "Nome host non specificato."
+msgstr "Doppia codifica (\"double-escape\") non valida nella path della URL."
 
 #: templates/ERR_INVALID_URL:8
 msgid ""
 "Missing or incorrect access protocol (should be <q>http://</q> or similar)"
 msgstr ""
-"Protocollo di accesso mancante o scorretto nella richiesta (dovrebbe essere "
+"Protocollo di accesso mancante o non corretto (dovrebbe essere "
 "<q>http://</q> o simile)."
 
 #: templates/ERR_INVALID_REQ:6
 msgid "Missing or unknown request method."
-msgstr "Metodo non specificato nella richiesta, o sconoscito."
-
-#: templates/ERR_NO_RELAY:5
-msgid "No Wais Relay"
-msgstr "Le funzioni di inoltro Wais non sono implementate."
+msgstr "Metodo della richiesta non specificato o sconoscito."
 
 #: templates/ERR_FTP_PUT_CREATED:2 templates/ERR_FTP_PUT_MODIFIED:2
 msgid "Operation successful"
-msgstr "L'operazione richiesta è stata portata a termine con successo."
+msgstr "Operazione eseguita correttamente"
 
 #: templates/ERR_FTP_LISTING:5
 msgid "Parent Directory"
-msgstr "Directory di Livello Superiore"
+msgstr "Directory superiore"
 
 #: templates/ERR_CACHE_ACCESS_DENIED:7
 msgid ""
 "Please contact the <a href=\"mailto:%w%W\">cache administrator</a> if you "
-"have difficulties authenticating yourself or <a href=\"http://%h/cgi-bin/"
-"chpasswd.cgi\">change</a> your default password."
+"have difficulties authenticating yourself or <a href=\"http://%h/cgi-"
+"bin/chpasswd.cgi\">change</a> your default password."
 msgstr ""
-"Si prega di contattare il <a href=\"mailto:%w%W\">gestore del vostro proxy</"
-"a> se avete diffcoltà nell'identificarvi per l'accesso al servizio, o di <a "
-"href=\"http://%h/cgi-bin/chpasswd.cgi\">cambiare</a> la vostra password "
-"iniziale."
+"Si prega di contattare il <a href=\"mailto:%w%W\">gestore del vostro "
+"proxy</a> se avete diffcoltà nell'identificarvi per l'accesso al servizio, o "
+"di <a href=\"http://%h/cgi-bin/chpasswd.cgi\">cambiare</a> la vostra "
+"password iniziale."
 
 #: templates/ERR_CACHE_MGR_ACCESS_DENIED:7
 msgid ""
@@ -340,63 +244,48 @@ msgid ""
 "administrator, read Squid documentation on cache manager interface and check "
 "cache log for more detailed error messages."
 msgstr ""
-"Si prega di contattare il <a href=\"mailto:%w%W\">gestore del vostro proxy</"
-"a> se avete diffcoltà nell'identificarvi per l'accesso al servizio o, se "
-"<em>siete</em> l'amministratore, di consultare la documentazione di Squid "
+"Si prega di contattare il <a href=\"mailto:%w%W\">gestore del vostro "
+"proxy</a> se avete diffcoltà nell'identificarvi per l'accesso al servizio o, "
+"se <em>siete</em> l'amministratore, di consultare la documentazione di Squid "
 "riguardante l'interfaccia del <em>cache manager</em> e di verificare il log "
 "del servizio alla ricerca informazioni più dettagliate sull'errore."
 
 #: templates/ERR_READ_ERROR:5
 msgid "Read Error"
-msgstr "Errore di lettura."
+msgstr "Errore di lettura"
 
 #: templates/ERR_READ_TIMEOUT:5
 msgid "Read Timeout"
-msgstr "Timeout nella lettura."
-
-#: templates/ERR_INVALID_REQ:9
-msgid "Request is too large."
-msgstr "La richiesta è di dimensioni troppo grandi."
-
-#: templates/ERR_SOCKET_FAILURE:5
-msgid "Socket Failure"
-msgstr "L'operazione di rete (socket) è fallita."
+msgstr "Timeout nella lettura"
 
 #: templates/ERR_INVALID_URL:6
 msgid "Some aspect of the requested URL is incorrect."
-msgstr "Qualche aspetto della URL richiesta non è irregolare."
-
-#: templates/ERR_ICAP_FAILURE:8 templates/ERR_INVALID_REQ:5
-#: templates/ERR_INVALID_URL:7
-msgid "Some possible problems are:"
-msgstr "Alcuni dei possibili problemi sono:"
+msgstr "Qualche aspetto della URL richiesta è scorretto"
 
 #: templates/ERR_CACHE_MGR_ACCESS_DENIED:6
 msgid ""
 "Sorry, you are not currently allowed to request %U from this cache manager "
 "until you have authenticated yourself."
 msgstr ""
-"Non siete autorizzati a richiedere %U da questo cache manager finchè non vi "
-"sarete identificati con successo."
+"Per richiedere %U da questo cache manager è necessario prima identificarsi."
 
 #: templates/ERR_CACHE_ACCESS_DENIED:6
 msgid ""
 "Sorry, you are not currently allowed to request %U from this cache until you "
 "have authenticated yourself."
-msgstr ""
-"Non siete autorizzati a richiedere %U da questa cache finchè non vi sarete "
-"identificati con successo."
+msgstr "Per richiedere %U da questa cache è necessario prima identificarsi."
 
 #: templates/ERR_ZERO_SIZE_OBJECT:6
 msgid "Squid did not receive any data for this request."
-msgstr "Squid non ha ricevuto alcun dato in risposta a questa richiesta."
+msgstr "Squid non ha ricevuto risposta a questa richiesta."
 
-# The translated text is less generous in details than the original, but IMO clearer to the admin and less confusing to the user.
 #: templates/ERR_UNSUP_REQ:6
 msgid ""
 "Squid does not support all request methods for all access protocols. For "
 "example, you can not POST a Gopher request."
-msgstr "Il metodo di accesso non è supportato per questo protocollo."
+msgstr ""
+"Squid non consente di utilizzare qualsiasi tipo di richiesta per qualsiasi "
+"protocollo (a esempio non consente una richiesta POST su protocollo Gopher)."
 
 #: templates/ERR_LIFETIME_EXP:6
 msgid ""
@@ -422,34 +311,7 @@ msgstr "Il comando FTP inviato da Squid era:"
 
 #: templates/ERR_DNS_FAIL:6
 msgid "The DNS server returned:"
-msgstr "Il processo dnsserver ha risposto:"
-
-#: templates/ERR_ESI:6
-msgid "The ESI processor returned:"
-msgstr "Il sistema di gestione delle funzioni ESI ha risposto:"
-
-#: templates/ERR_FTP_UNAVAILABLE:4
-msgid "The FTP server was too busy to retrieve the URL: <a href=\"%U\">%U</a>"
-msgstr ""
-"Il FTP server era sovraccarico e non ha consentito di accedere alla URL: <a "
-"href=\"%U\">%U</a>."
-
-#: templates/ERR_INVALID_RESP:5
-msgid ""
-"The HTTP Response message received from the contacted server could not be "
-"understood or was otherwise malformed. Please contact the site operator."
-msgstr ""
-"Il messaggio di risposta HTTP ricevuto dal server non era comprensibile o "
-"era irregolare. Si prega di contattare il gestore del sito per segnalargli "
-"l'errore."
-
-#: templates/ERR_ICAP_FAILURE:9
-msgid "The ICAP server is not reachable."
-msgstr "Il server ICAP non è raggiungibile."
-
-#: templates/ERR_FTP_NOT_FOUND:4
-msgid "The following URL could not be retrieved: <a href=\"%U\">%U</a>"
-msgstr "Non è stato possibile accedere alla URL: <a href=\"%U\">%U</a>."
+msgstr "Il server DNS ha risposto:"
 
 #: templates/ERR_ACCESS_DENIED:4 templates/ERR_CACHE_ACCESS_DENIED:4
 #: templates/ERR_CACHE_MGR_ACCESS_DENIED:4 templates/ERR_CANNOT_FORWARD:4
@@ -467,23 +329,208 @@ msgid ""
 "The following error was encountered while trying to retrieve the URL: <a "
 "href=\"%U\">%U</a>"
 msgstr ""
-"Mentre si cercava di accedere alla URL <a href=\"%U\">%U</a> si è "
-"manifestato il seguente errore:"
+"Mentre si cercava di accedere alla URL <a href=\"%U\">%U</a> si è presentato "
+"il seguente errore:"
 
 #: templates/ERR_URN_RESOLVE:4
 msgid ""
 "The following error was encountered while trying to retrieve the URN: <a "
 "href=\"%U\">%U</a>"
 msgstr ""
-"Mentre si cercava di accedere alla URN <a href=\"%U\">%U</a> si è "
-"manifestato il seguente errore:"
+"Mentre si cercava di accedere alla URN <a href=\"%U\">%U</a> si è presentato "
+"il seguente errore:"
 
 #: templates/ERR_CONNECT_FAIL:7
-msgid "The remote host or network may be down.  Please try the request again."
+msgid ""
+"The remote host or network may be down.  Please try the request again."
 msgstr ""
 "Il server remoto o un tratto di rete necessario a raggiungerlo potrebbero "
 "essere guasti. Si prega di ritentare la richiesta tra qualche minuto."
 
+#: templates/ERR_NO_RELAY:6
+msgid ""
+"There is no WAIS Relay host defined for this Cache!  Yell at the "
+"administrator."
+msgstr ""
+"Non è stato configurato alcun server di relay per il protocollo WAIS su "
+"questa Cache! Prenditela con l'amministratore."
+
+#: templates/ERR_TOO_BIG:8
+msgid ""
+"These limits have been established by the Internet Service Provider who "
+"operates this cache.  Please contact them directly if you feel this is an "
+"error."
+msgstr ""
+"Questi limiti sono stati imposti dal provider che gestisce questo Proxy. Se "
+"ritenete che questo sia scorretto si prega di contattarlo."
+
+#: templates/ERR_UNSUP_HTTPVERSION:6
+msgid ""
+"This Squid does not accept the HTTP version you are attempting to use."
+msgstr ""
+"Questa installazione di Squid non supporta la versione HTTP che si sta "
+"cercando di utilizzare."
+
+#: templates/ERR_FTP_DISABLED:6
+msgid "This cache does not support FTP."
+msgstr "Questo proxy non supporta il protocollo FTP."
+
+#: templates/ERR_FORWARDING_DENIED:6
+msgid ""
+"This cache will not forward your request because it is trying to enforce a "
+"sibling relationship.  Perhaps the client at %i is a cache which has been "
+"misconfigured."
+msgstr ""
+"Il proxy non inoltrerà questa richiesta, perchè tenta di stabilire una "
+"relazione di parentela. Probabilmente il client all'indirizzo %i è una cache "
+"configurata in modo sbagliato."
+
+#: templates/ERR_ICAP_FAILURE:7
+msgid "This means that some aspect of the ICAP communication failed."
+msgstr ""
+"Questo significa che qualche aspetto della comunicazione ICAP non è stato "
+"completato regolarmente."
+
+#: templates/ERR_UNSUP_HTTPVERSION:3 templates/ERR_UNSUP_HTTPVERSION:5
+msgid "Unsupported HTTP version"
+msgstr "Versione HTTP non supportata"
+
+#: templates/ERR_ACCESS_DENIED:5
+msgid "Access Denied."
+msgstr "Accesso negato."
+
+#: templates/ERR_CACHE_ACCESS_DENIED:3 templates/ERR_CACHE_ACCESS_DENIED:5
+msgid "Cache Access Denied."
+msgstr "Accesso alla cache negato."
+
+#: templates/ERR_URN_RESOLVE:5
+msgid "Cannot Resolve URN"
+msgstr "Impossibile risolvere la URN."
+
+#: templates/ERR_ACCESS_DENIED:2 templates/ERR_CACHE_ACCESS_DENIED:2
+#: templates/ERR_CACHE_MGR_ACCESS_DENIED:2 templates/ERR_CANNOT_FORWARD:2
+#: templates/ERR_CONNECT_FAIL:2 templates/ERR_DNS_FAIL:2 templates/ERR_ESI:2
+#: templates/ERR_FORWARDING_DENIED:2 templates/ERR_FTP_DISABLED:2
+#: templates/ERR_FTP_FAILURE:2 templates/ERR_FTP_FORBIDDEN:2
+#: templates/ERR_FTP_NOT_FOUND:2 templates/ERR_FTP_PUT_ERROR:2
+#: templates/ERR_FTP_UNAVAILABLE:2 templates/ERR_ICAP_FAILURE:2
+#: templates/ERR_INVALID_REQ:2 templates/ERR_INVALID_RESP:2
+#: templates/ERR_INVALID_URL:2 templates/ERR_LIFETIME_EXP:2
+#: templates/ERR_NO_RELAY:2 templates/ERR_ONLY_IF_CACHED_MISS:2
+#: templates/ERR_READ_ERROR:2 templates/ERR_READ_TIMEOUT:2
+#: templates/ERR_SECURE_CONNECT_FAIL:2 templates/ERR_SHUTTING_DOWN:2
+#: templates/ERR_SOCKET_FAILURE:2 templates/ERR_TOO_BIG:2
+#: templates/ERR_UNSUP_HTTPVERSION:2 templates/ERR_UNSUP_REQ:2
+#: templates/ERR_URN_RESOLVE:2 templates/ERR_WRITE_ERROR:2
+#: templates/ERR_ZERO_SIZE_OBJECT:2
+msgid "ERROR"
+msgstr "ERRORE"
+
+#: templates/ERR_CACHE_ACCESS_DENIED:1
+msgid "ERROR: Cache Access Denied"
+msgstr "ERRORE: accesso alla cache negato."
+
+#: templates/ERR_FTP_LISTING:1
+msgid "FTP Directory: %U"
+msgstr "Directory FTP: %U"
+
+#: templates/ERR_FTP_LISTING:2
+msgid "FTP Directory: <a href=\"/\">%U</a>/"
+msgstr "Directory FTP: <a href=\"/\">%U</a>/"
+
+#: templates/ERR_FTP_PUT_CREATED:3
+msgid "File created"
+msgstr "Il file è stato creato."
+
+#: templates/ERR_FTP_PUT_MODIFIED:3
+msgid "File updated"
+msgstr "Il file è stato aggiornato."
+
+#: templates/ERR_FORWARDING_DENIED:5
+msgid "Forwarding Denied."
+msgstr "Inoltro negato."
+
+#: templates/ERR_ACCESS_DENIED:8 templates/ERR_CACHE_ACCESS_DENIED:8
+#: templates/ERR_CACHE_MGR_ACCESS_DENIED:8 templates/ERR_CANNOT_FORWARD:8
+#: templates/ERR_CONNECT_FAIL:9 templates/ERR_DNS_FAIL:9 templates/ERR_ESI:9
+#: templates/ERR_FORWARDING_DENIED:8 templates/ERR_FTP_DISABLED:8
+#: templates/ERR_FTP_FAILURE:8 templates/ERR_FTP_FORBIDDEN:8
+#: templates/ERR_FTP_LISTING:7 templates/ERR_FTP_NOT_FOUND:9
+#: templates/ERR_FTP_PUT_CREATED:4 templates/ERR_FTP_PUT_ERROR:9
+#: templates/ERR_FTP_PUT_MODIFIED:4 templates/ERR_FTP_UNAVAILABLE:8
+#: templates/ERR_ICAP_FAILURE:11 templates/ERR_INVALID_REQ:13
+#: templates/ERR_INVALID_RESP:8 templates/ERR_INVALID_URL:13
+#: templates/ERR_LIFETIME_EXP:8 templates/ERR_NO_RELAY:8
+#: templates/ERR_ONLY_IF_CACHED_MISS:8 templates/ERR_READ_ERROR:9
+#: templates/ERR_READ_TIMEOUT:9 templates/ERR_SECURE_CONNECT_FAIL:9
+#: templates/ERR_SHUTTING_DOWN:7 templates/ERR_SOCKET_FAILURE:9
+#: templates/ERR_TOO_BIG:10 templates/ERR_UNSUP_HTTPVERSION:8
+#: templates/ERR_UNSUP_REQ:8 templates/ERR_URN_RESOLVE:8
+#: templates/ERR_WRITE_ERROR:9 templates/ERR_ZERO_SIZE_OBJECT:8
+msgid "Generated %T by %h (%s)"
+msgstr "Generato da %h (%s) il %T."
+
+#: templates/ERR_INVALID_URL:5
+msgid "Invalid URL"
+msgstr "URL non valida"
+
+#: templates/ERR_INVALID_REQ:8
+msgid "Missing HTTP Identifier (HTTP/1.0)."
+msgstr "L'identificativo del protocollo HTTP è mancante (HTTP/1.0)."
+
+#: templates/ERR_INVALID_REQ:7
+msgid "Missing URL."
+msgstr "URL non specificata."
+
+#: templates/ERR_INVALID_URL:9
+msgid "Missing hostname"
+msgstr "Nome host non specificato."
+
+#: templates/ERR_NO_RELAY:5
+msgid "No Wais Relay"
+msgstr "Le funzioni di inoltro Wais non sono implementate."
+
+#: templates/ERR_INVALID_REQ:9
+msgid "Request is too large."
+msgstr "La richiesta è di dimensioni troppo grandi."
+
+#: templates/ERR_SOCKET_FAILURE:5
+msgid "Socket Failure"
+msgstr "L'operazione di rete (socket) è fallita."
+
+#: templates/ERR_ICAP_FAILURE:8 templates/ERR_INVALID_REQ:5
+#: templates/ERR_INVALID_URL:7
+msgid "Some possible problems are:"
+msgstr "Alcuni dei possibili problemi sono:"
+
+#: templates/ERR_ESI:6
+msgid "The ESI processor returned:"
+msgstr "Il sistema di gestione delle funzioni ESI ha risposto:"
+
+#: templates/ERR_FTP_UNAVAILABLE:4
+msgid ""
+"The FTP server was too busy to retrieve the URL: <a href=\"%U\">%U</a>"
+msgstr ""
+"Il server FTP era sovraccarico e non ha consentito di accedere alla URL: <a "
+"href=\"%U\">%U</a>."
+
+#: templates/ERR_INVALID_RESP:5
+msgid ""
+"The HTTP Response message received from the contacted server could not be "
+"understood or was otherwise malformed. Please contact the site operator."
+msgstr ""
+"Il messaggio di risposta HTTP ricevuto dal server non era comprensibile o "
+"era irregolare. Si prega di contattare il gestore del sito per segnalargli "
+"l'errore."
+
+#: templates/ERR_ICAP_FAILURE:9
+msgid "The ICAP server is not reachable."
+msgstr "Il server ICAP non è raggiungibile."
+
+#: templates/ERR_FTP_NOT_FOUND:4
+msgid "The following URL could not be retrieved: <a href=\"%U\">%U</a>"
+msgstr "Non è stato possibile accedere alla URL: <a href=\"%U\">%U</a>."
+
 #: templates/ERR_TOO_BIG:5
 msgid "The request or reply is too large."
 msgstr "La richesta o la risposta è di dimensioni troppo grandi."
@@ -517,33 +564,6 @@ msgstr "Il server ha risposto:"
 msgid "The system returned: <i>%E</i>"
 msgstr "Il sistema ha risposto: <i>%E</i>"
 
-# The administrator should be congratulated, rather than being yelled at. Wais is not relevant anymore.
-#: templates/ERR_NO_RELAY:6
-msgid ""
-"There is no WAIS Relay host defined for this Cache!  Yell at the "
-"administrator."
-msgstr ""
-"Non è stato configurato alcun server di relay per il protocollo WAIS su "
-"questa Cache."
-
-#: templates/ERR_TOO_BIG:8
-msgid ""
-"These limits have been established by the Internet Service Provider who "
-"operates this cache.  Please contact them directly if you feel this is an "
-"error."
-msgstr ""
-"Questi limiti sono stati imposti dal provider che gestisce questo Proxy. Se "
-"ritenete che questo sia scorretto si prega di rivolgersi alle strutture di "
-"supporto degli utenti corrette."
-
-#: templates/ERR_UNSUP_HTTPVERSION:6
-msgid "This Squid does not accept the HTTP version you are attempting to use."
-msgstr ""
-
-#: templates/ERR_FTP_DISABLED:6
-msgid "This cache does not support FTP."
-msgstr "Questo Proxy non supporta il protocollo FTP."
-
 #: templates/ERR_SHUTTING_DOWN:5
 msgid ""
 "This cache is in the process of shutting down and can not service your "
@@ -552,22 +572,6 @@ msgstr ""
 "Questo Proxy non è in grado di soddisfare la richiesta perchè è in fase di "
 "spegnimento. si prega di riprovare tra qualche minuto."
 
-#: templates/ERR_FORWARDING_DENIED:6
-msgid ""
-"This cache will not forward your request because it is trying to enforce a "
-"sibling relationship.  Perhaps the client at %i is a cache which has been "
-"misconfigured."
-msgstr ""
-"Questo Proxy non può inoltrare la richiesta: il client di indirizzo %i è "
-"noto al Proxy come <em>sibling</em> ma si comporta come client. Potrebbe "
-"essere configurato in maniera sbagliata?"
-
-#: templates/ERR_ICAP_FAILURE:7
-msgid "This means that some aspect of the ICAP communication failed."
-msgstr ""
-"Questo significa che qualche aspetto della comunicazione ICAP non è stato "
-"completato regolarmente."
-
 #: templates/ERR_FTP_PUT_ERROR:7
 msgid ""
 "This means that the FTP server may not have permission or space to store the "
@@ -639,10 +643,6 @@ msgstr ""
 msgid "Unable to forward this request at this time."
 msgstr "Non è possibile inoltrare la richiesta in questo momento."
 
-#: templates/ERR_UNSUP_HTTPVERSION:3 templates/ERR_UNSUP_HTTPVERSION:5
-msgid "Unsupported HTTP version"
-msgstr ""
-
 #: templates/ERR_UNSUP_REQ:5
 msgid "Unsupported Request Method and Protocol"
 msgstr "Metodo e protocollo della richiesta non sono supportati."
@@ -2,52 +2,32 @@ msgid ""
 msgstr ""
 "Project-Id-Version: Squid-3\n"
 "Report-Msgid-Bugs-To: \n"
-"POT-Creation-Date: 2009-06-14 18:15+1300\n"
-"PO-Revision-Date: 2009-05-10 00:26+0000\n"
-"Last-Translator: Maxim S. <Unknown>\n"
+"POT-Creation-Date: 2009-06-14 18:16+1300\n"
+"PO-Revision-Date: 2009-06-14 11:47+0000\n"
+"Last-Translator: Amos Jeffries <Unknown>\n"
 "Language-Team: Squid Developers <squid-dev@squid-cache.org>\n"
 "MIME-Version: 1.0\n"
 "Content-Type: text/plain; charset=UTF-8\n"
 "Content-Transfer-Encoding: 8bit\n"
-"X-Launchpad-Export-Date: 2009-06-06 12:08+0000\n"
+"X-Launchpad-Export-Date: 2009-07-22 09:12+0000\n"
 "X-Generator: Launchpad (build Unknown)\n"
 "Language: ru\n"
-"Plural-Forms: nplurals=3; plural=(n%10==1 && n%100!=11 ? 0 : n%10>=2 && n%"
-"10<=4 && (n%100<10 || n%100>=20) ? 1 : 2);\n"
-
-#: templates/ERR_FTP_LISTING:6
-msgid "<a href=\"../\">Parent Directory</a> (<a href=\"/\">Root Directory</a>)"
-msgstr ""
-"<a href=\"../\">Родительская директория</a> (<a href=\"/\">Корневая "
-"директория</a>)"
 
 #: templates/ERR_INVALID_REQ:4
 msgid ""
 "<b>Invalid Request</b> error was encountered while trying to process the "
 "request:"
-msgstr "Ошибка <b>неверный запрос</b> при обработке запроса:"
+msgstr "Обнаружен <b>недопустимый запрос</b>:"
 
 #: templates/ERR_INVALID_RESP:4
 msgid ""
 "<b>Invalid Response</b> error was encountered while trying to process the "
 "request:"
-msgstr "Ошибка <b>неверный ответ</b> при обработке запроса:"
-
-#: templates/ERR_READ_TIMEOUT:7
-msgid ""
-"A Timeout occurred while waiting to read data from the network.  The network "
-"or server may be down or congested.  Please retry your request."
-msgstr ""
-"Превышено время ожидания ответа во время чтения данных из сети. Сеть или "
-"сервер не работают либо перегружены. Пожалуйста, повторите запрос."
-
-#: templates/ERR_URN_RESOLVE:3
-msgid "A URL for the requested URN could not be retrieved"
-msgstr "URL для запрошенного URN не может быть получен"
+msgstr "Получен <b>недопустимый ответ</b> при попытке обработки запроса:"
 
 #: templates/ERR_ACCESS_DENIED:5
 msgid "Access Denied."
-msgstr "В доступе отказано."
+msgstr "Доступ запрещён."
 
 #: templates/ERR_ACCESS_DENIED:6
 msgid ""
@@ -56,28 +36,372 @@ msgid ""
 "incorrect."
 msgstr ""
 "Настройка контроля доступа не даёт возможности выполнить Ваш запрос в "
-"настоящее время. Пожалуйста, свяжитесь с Вашим поставщиком услуг Интернет, "
-"если Вы считаете это неправильным."
+"настоящее время. Пожалуйста, свяжитесь с Вашим администратором кэша, если Вы "
+"считаете это неправильным."
 
 #: templates/ERR_FTP_FORBIDDEN:4
 msgid ""
 "An FTP authentication failure occurred while trying to retrieve the URL: <a "
 "href=\"%U\">%U</a>"
 msgstr ""
-"Произошла ошибка FTP идентификации при попытке получить URL (унифицированный "
-"указатель информационного ресурса): <a href=\"%U\">%U</a>"
+"Произошла ошибка аутентификации FTP при попытке получить URL: <a "
+"href=\"%U\">%U</a>"
 
 #: templates/ERR_FTP_FAILURE:4
 msgid ""
-"An FTP protocol error occurred while trying to retrieve the URL: <a href=\"%U"
-"\">%U</a>"
+"An FTP protocol error occurred while trying to retrieve the URL: <a "
+"href=\"%U\">%U</a>"
+msgstr ""
+"Произошла ошибка протокола FTP при попытке получить URL: <a "
+"href=\"%U\">%U</a>"
+
+#: templates/ERR_ICAP_FAILURE:10
+msgid "An Illegal response was received from the ICAP server."
+msgstr "Получен недопустимый ответ от сервера ICAP."
+
+#: templates/ERR_WRITE_ERROR:7
+msgid ""
+"An error condition occurred while writing to the network.  Please retry your "
+"request."
+msgstr ""
+"При попытке отправки данных в сеть произошла ошибка. Пожалуйста, повторите "
+"Ваш запрос."
+
+#: templates/ERR_CACHE_ACCESS_DENIED:3 templates/ERR_CACHE_ACCESS_DENIED:5
+msgid "Cache Access Denied."
+msgstr "Доступ к кэшу запрещён."
+
+#: templates/ERR_CACHE_MGR_ACCESS_DENIED:3
+#: templates/ERR_CACHE_MGR_ACCESS_DENIED:5
+msgid "Cache Manager Access Denied."
+msgstr "Доступ к управлению кэшем запрещён."
+
+#: templates/ERR_INVALID_REQ:10
+msgid "Content-Length missing for POST or PUT requests."
+msgstr "В запросе POST или PUT отсутствует заголовок Content-Length."
+
+#: templates/ERR_FTP_LISTING:3
+msgid "Directory Content:"
+msgstr "Содержимое каталога:"
+
+#: templates/ERR_CACHE_ACCESS_DENIED:1
+msgid "ERROR: Cache Access Denied"
+msgstr "ОШИБКА: Доступ к кэшу запрещён"
+
+#: templates/ERR_CACHE_MGR_ACCESS_DENIED:1
+msgid "ERROR: Cache Manager Access Denied"
+msgstr "ОШИБКА: Доступ к управлению кэшем запрещён."
+
+#: templates/ERR_FTP_PUT_ERROR:1
+msgid "ERROR: FTP upload failed"
+msgstr "ОШИБКА: Отправка по FTP не удалась"
+
+#: templates/ERR_FTP_LISTING:4
+msgid "FTP Directory Listing"
+msgstr "Список файлов каталога FTP"
+
+#: templates/ERR_FTP_LISTING:1
+msgid "FTP Directory: %U"
+msgstr "Каталог FTP: %U"
+
+#: templates/ERR_FTP_LISTING:2
+msgid "FTP Directory: <a href=\"/\">%U</a>/"
+msgstr "Каталог FTP: <a href=\"/\">%U</a>/"
+
+#: templates/ERR_FTP_PUT_CREATED:1
+msgid "FTP PUT Successful: File Created"
+msgstr "Команда FTP PUT завершилась успешно: файл создан"
+
+#: templates/ERR_FTP_PUT_MODIFIED:1
+msgid "FTP PUT Successful: File Updated"
+msgstr "Команда FTP PUT завершилась успешно: файл обновлён"
+
+#: templates/ERR_FTP_PUT_ERROR:3
+msgid "FTP PUT/upload failed"
+msgstr "Команда FTP PUT (отправка) завершилась аварийно"
+
+#: templates/ERR_FTP_DISABLED:5
+msgid "FTP is Disabled"
+msgstr "Протокол FTP отключён"
+
+#: templates/ERR_FTP_PUT_MODIFIED:3
+msgid "File updated"
+msgstr "Файл обновлён"
+
+#: templates/ERR_FORWARDING_DENIED:5
+msgid "Forwarding Denied."
+msgstr "Пересылка запрещена."
+
+#: templates/ERR_ICAP_FAILURE:5
+msgid "ICAP protocol error."
+msgstr "Ошибка протокола ICAP."
+
+#: templates/ERR_TOO_BIG:7
+msgid ""
+"If you are making a GET request, then the item you are trying to download is "
+"too large."
+msgstr "Если Вы выполняете запрос GET, то загружаемый объект слишком велик."
+
+#: templates/ERR_TOO_BIG:6
+msgid ""
+"If you are making a POST or PUT request, then the item you are trying to "
+"upload is too large."
+msgstr ""
+"Если Вы выполняете запрос POST или PUT, то отправляемый объект слишком велик."
+
+#: templates/ERR_INVALID_REQ:11 templates/ERR_INVALID_URL:11
+msgid "Illegal character in hostname; underscores are not allowed."
+msgstr ""
+"Недопустимый символ в имени узла (hostname), подчёркивания запрещены."
+
+#: templates/ERR_INVALID_URL:5
+msgid "Invalid URL"
+msgstr "Недопустимый URL"
+
+#: templates/ERR_INVALID_REQ:8
+msgid "Missing HTTP Identifier (HTTP/1.0)."
+msgstr "Отсутствует идентификатор HTTP (HTTP/1.0)."
+
+#: templates/ERR_INVALID_URL:8
+msgid ""
+"Missing or incorrect access protocol (should be <q>http://</q> or similar)"
+msgstr ""
+"Отсутствет или неверено указан протокол (должно быть <q>http://</q> или "
+"похоже)"
+
+#: templates/ERR_FTP_LISTING:5
+msgid "Parent Directory"
+msgstr "Родительский каталог"
+
+#: templates/ERR_CACHE_ACCESS_DENIED:7
+msgid ""
+"Please contact the <a href=\"mailto:%w%W\">cache administrator</a> if you "
+"have difficulties authenticating yourself or <a href=\"http://%h/cgi-"
+"bin/chpasswd.cgi\">change</a> your default password."
+msgstr ""
+"Если у Вас возникли проблемы с аутентификацией, пожалуйста, свяжитесь с <a "
+"href=\"mailto:%w%W\">администратором кэша</a> или <a href=\"http://%h/cgi-"
+"bin/chpasswd.cgi\">смените</a> Ваш пароль по умолчанию."
+
+#: templates/ERR_CACHE_MGR_ACCESS_DENIED:7
+msgid ""
+"Please contact the <a href=\"mailto:%w%W\">cache administrator</a> if you "
+"have difficulties authenticating yourself or, if you <em>are</em> the "
+"administrator, read Squid documentation on cache manager interface and check "
+"cache log for more detailed error messages."
+msgstr ""
+"Если у Вас возникли проблемы с аутентификацией, пожалуйста, свяжитесь с <a "
+"href=\"mailto:%w%W\">администратором кэша</a>, если же <em>Вы - "
+"администратор</em>, прочитайте документацию по интерфейсу управления кэшем и "
+"проверьте файл протокола на предмет более детальных сообщений об ошибках."
+
+#: templates/ERR_READ_ERROR:5
+msgid "Read Error"
+msgstr "Ошибка чтения"
+
+#: templates/ERR_INVALID_URL:6
+msgid "Some aspect of the requested URL is incorrect."
+msgstr "Какая-то часть запрашиваемого URL некорректна"
+
+#: templates/ERR_CACHE_MGR_ACCESS_DENIED:6
+msgid ""
+"Sorry, you are not currently allowed to request %U from this cache manager "
+"until you have authenticated yourself."
+msgstr ""
+"Извините, Вы не можете запросить %U из системы управления кэшем до тех пор, "
+"пока не пройдете аутентификацию."
+
+#: templates/ERR_CACHE_ACCESS_DENIED:6
+msgid ""
+"Sorry, you are not currently allowed to request %U from this cache until you "
+"have authenticated yourself."
+msgstr ""
+"Извините, Вы не можете запросить %U из этого кэша до тех пор, пока не "
+"пройдёте аутентификацию."
+
+#: templates/ERR_UNSUP_REQ:6
+msgid ""
+"Squid does not support all request methods for all access protocols. For "
+"example, you can not POST a Gopher request."
+msgstr ""
+"Squid не поддерживает все методы запросов для всех протоколов. К примеру, "
+"для протокола Gopher Вы не можете выполнить запрос POST."
+
+#: templates/ERR_SOCKET_FAILURE:7
+msgid ""
+"Squid is unable to create a TCP socket, presumably due to excessive load. "
+"Please retry your request."
+msgstr ""
+"Squid не может создать сокет TCP, предположительно из-за большой нагрузки. "
+"Пожалуйста, повторите запрос."
+
+#: templates/ERR_FTP_FAILURE:5 templates/ERR_FTP_FORBIDDEN:5
+#: templates/ERR_FTP_NOT_FOUND:5 templates/ERR_FTP_PUT_ERROR:5
+#: templates/ERR_FTP_UNAVAILABLE:5
+msgid "Squid sent the following FTP command:"
+msgstr "Squid послал следующую команду FTP:"
+
+#: templates/ERR_INVALID_RESP:5
+msgid ""
+"The HTTP Response message received from the contacted server could not be "
+"understood or was otherwise malformed. Please contact the site operator."
+msgstr ""
+"Ответ HTTP, полученный от сервера, не может быть распознан, или он был "
+"неверно сформирован. Пожалуйста, свяжитесь с оператором сайта."
+
+#: templates/ERR_URN_RESOLVE:4
+msgid ""
+"The following error was encountered while trying to retrieve the URN: <a "
+"href=\"%U\">%U</a>"
+msgstr "При получении URN <a href=\"%U\">%U</a> произошла следующая ошибка"
+
+#: templates/ERR_CONNECT_FAIL:7
+msgid ""
+"The remote host or network may be down.  Please try the request again."
+msgstr ""
+"Возможно, удаленный узел или сеть недоступны. Пожалуйста, повторите запрос "
+"позже."
+
+#: templates/ERR_NO_RELAY:6
+msgid ""
+"There is no WAIS Relay host defined for this Cache!  Yell at the "
+"administrator."
+msgstr ""
+"Для этого кэша не определен узел Wais Relay. Обратитесь к администратору."
+
+#: templates/ERR_TOO_BIG:8
+msgid ""
+"These limits have been established by the Internet Service Provider who "
+"operates this cache.  Please contact them directly if you feel this is an "
+"error."
+msgstr ""
+"Эти ограничения установлены администратором, который управляет этим кэшем. "
+"Пожалуйста, свяжитесь с ним, если Вы считаете это неправильным."
+
+#: templates/ERR_FTP_DISABLED:6
+msgid "This cache does not support FTP."
+msgstr "Этот кэш не поддерживает протокол FTP."
+
+#: templates/ERR_SHUTTING_DOWN:5
+msgid ""
+"This cache is in the process of shutting down and can not service your "
+"request at this time.  Please retry your request again soon."
+msgstr ""
+"Этот кэш находится в процессе завершения работы и не может выполнить Ваш "
+"запрос в настоящее время. Пожалуйста, повторите запрос через некторое время."
+
+#: templates/ERR_FORWARDING_DENIED:6
+msgid ""
+"This cache will not forward your request because it is trying to enforce a "
+"sibling relationship.  Perhaps the client at %i is a cache which has been "
+"misconfigured."
+msgstr ""
+"Этот кэш не будет пересылать Ваш запрос потому, что он пытается "
+"принудительно установить братские взаимоотношения (sibling relationship). "
+"Скорее всего, клиент %i - неправильно сконфигурированный кэш."
+
+#: templates/ERR_ICAP_FAILURE:7
+msgid "This means that some aspect of the ICAP communication failed."
+msgstr "Это означает, что какой-то этап связи по протоколу ICAP не удался."
+
+#: templates/ERR_FTP_PUT_ERROR:7
+msgid ""
+"This means that the FTP server may not have permission or space to store the "
+"file. Check the path, permissions, diskspace and try again."
+msgstr ""
+"Это означает, что сервер FTP может не иметь прав или свободного места для "
+"хранения файла. Проверьте путь, права, свободное место и попробуйте снова."
+
+#: templates/ERR_DNS_FAIL:7
+msgid ""
+"This means that the cache was not able to resolve the hostname presented in "
+"the URL. Check if the address is correct."
+msgstr ""
+"Это означает, что кэш не смог распознать имя узла в URL. Проверьте адрес на "
+"корректность."
+
+#: templates/ERR_FTP_NOT_FOUND:7
+msgid ""
+"This might be caused by an FTP URL with an absolute path (which does not "
+"comply with RFC 1738).  If this is the cause, then the file can be found at "
+"<a href=\"%B\">%B</a>."
+msgstr ""
+"Это может быть вызвано FTP URL c абсолютным путём (который не соответствует "
+"RFC 1738). Если эта причина верна, то файл можно найти по адресу <a "
+"href=\"%B\">%B</a>."
+
+#: templates/ERR_SECURE_CONNECT_FAIL:7
+msgid ""
+"This proxy and the remote host failed to negotiate a mutually acceptable "
+"security settings for handling your request. It is possible that the remote "
+"host does not support secure connections, or the proxy is not satisfied with "
+"the host security credentials."
+msgstr ""
+"Для выполнения Вашего запроса этот кэш и удаленный узел не смогли "
+"согласовать взаимоприемлемые параметры безопасности. Возможно, удаленный "
+"узел не поддерживает безопасные соединения или кэш не удовлетворён "
+"удостоверением безопасности узла."
+
+#: templates/ERR_CANNOT_FORWARD:6
+msgid ""
+"This request could not be forwarded to the origin server or to any parent "
+"caches.  The most likely cause for this error is that the cache "
+"administrator does not allow this cache to make direct connections to origin "
+"servers, and all configured parent caches are currently unreachable."
+msgstr ""
+"Этот запрос не может быть перенаправлен ни к первичному серверу, ни к "
+"родительским кэшам. Наиболее вероятная причина этой ошибки в том, что "
+"администратор запретил прямые соединения к первичным серверам, а все "
+"указанные родительские кэши в данный момент недоступны."
+
+#: templates/ERR_DNS_FAIL:5
+msgid "Unable to determine IP address from host name <q>%H</q>"
+msgstr "Невозможно определить IP-адрес по имени узла <q>%H</q>"
+
+#: templates/ERR_CANNOT_FORWARD:5
+msgid "Unable to forward this request at this time."
+msgstr "Невозможно переслать этот запрос в данное время."
+
+#: templates/ERR_FTP_PUT_ERROR:4
+msgid "While trying to PUT the following URL: <a href=\"%U\">%U</a>"
+msgstr "При попытке запроса PUT для следующего URL: <a href=\"%U\">%U</a>"
+
+#: templates/ERR_ONLY_IF_CACHED_MISS:6
+msgid ""
+"You have issued a request with a <q>only-if-cached</q> cache control "
+"directive. The document was not found in the cache, <em>or</em> it required "
+"revalidation prohibited by the <q>only-if-cached</q> directive."
+msgstr ""
+"Вы сделали запрос с директивой управления кэшем <q>only-if-cached</q>. "
+"Документ не был найден в кэше <em>или</em> он требует проверки "
+"достоверности, запрещённой директивой <q>only-if-cached</q>."
+
+#: templates/ERR_INVALID_RESP:6
+msgid ""
+"Your cache administrator may be able to provide you with more details about "
+"the exact nature of the problem if needed."
+msgstr ""
+"Администратор Вашего кэша при необходимости может предоставить Вам более "
+"подробную информацию о действительных причинах проблемы."
+
+#: templates/ERR_FTP_LISTING:6
+msgid ""
+"<a href=\"../\">Parent Directory</a> (<a href=\"/\">Root Directory</a>)"
+msgstr ""
+"<a href=\"../\">Родительская директория</a> (<a href=\"/\">Корневая "
+"директория</a>)"
+
+#: templates/ERR_READ_TIMEOUT:7
+msgid ""
+"A Timeout occurred while waiting to read data from the network.  The network "
+"or server may be down or congested.  Please retry your request."
 msgstr ""
-"Произошла ошибка FTP протокола при попытке получить следующий URL "
-"(унифицированный указатель информационного ресурса): <a href=\"%U\">%U</a>"
+"Превышено время ожидания ответа во время чтения данных из сети. Сеть или "
+"сервер не работают либо перегружены. Пожалуйста, повторите запрос."
 
-#: templates/ERR_ICAP_FAILURE:10
-msgid "An Illegal response was received from the ICAP server."
-msgstr "Получен неверный ответ от ICAP сервера."
+#: templates/ERR_URN_RESOLVE:3
+msgid "A URL for the requested URN could not be retrieved"
+msgstr "URL для запрошенного URN не может быть получен"
 
 #: templates/ERR_READ_ERROR:7
 msgid ""
@@ -87,23 +411,6 @@ msgstr ""
 "При попытке чтения данных из сети произошла ошибка. Пожалуйста, повторите "
 "запрос."
 
-#: templates/ERR_WRITE_ERROR:7
-msgid ""
-"An error condition occurred while writing to the network.  Please retry your "
-"request."
-msgstr ""
-"При попытке записи данных в сеть произошла ошибка. Пожалуйста, повторите "
-"запрос."
-
-#: templates/ERR_CACHE_ACCESS_DENIED:3 templates/ERR_CACHE_ACCESS_DENIED:5
-msgid "Cache Access Denied."
-msgstr "В доступе к кэшу отказано."
-
-#: templates/ERR_CACHE_MGR_ACCESS_DENIED:3
-#: templates/ERR_CACHE_MGR_ACCESS_DENIED:5
-msgid "Cache Manager Access Denied."
-msgstr "В доступе к администратору кэша отказано."
-
 #: templates/ERR_URN_RESOLVE:5
 msgid "Cannot Resolve URN"
 msgstr "Невозможно определить URN"
@@ -116,14 +423,6 @@ msgstr "Время жизни соединения истекло"
 msgid "Connection to %I failed."
 msgstr "Соединение с %I не удалось"
 
-#: templates/ERR_INVALID_REQ:10
-msgid "Content-Length missing for POST or PUT requests."
-msgstr "Упещенный Content-Length в POST или PUT запросе."
-
-#: templates/ERR_FTP_LISTING:3
-msgid "Directory Content:"
-msgstr "Содержимое директории:"
-
 #: templates/ERR_ACCESS_DENIED:2 templates/ERR_CACHE_ACCESS_DENIED:2
 #: templates/ERR_CACHE_MGR_ACCESS_DENIED:2 templates/ERR_CANNOT_FORWARD:2
 #: templates/ERR_CONNECT_FAIL:2 templates/ERR_DNS_FAIL:2 templates/ERR_ESI:2
@@ -143,18 +442,6 @@ msgstr "Содержимое директории:"
 msgid "ERROR"
 msgstr "ОШИБКА"
 
-#: templates/ERR_CACHE_ACCESS_DENIED:1
-msgid "ERROR: Cache Access Denied"
-msgstr "ОШИБКА: В доступе к кешу отказано"
-
-#: templates/ERR_CACHE_MGR_ACCESS_DENIED:1
-msgid "ERROR: Cache Manager Access Denied"
-msgstr "ОШИБКА: В доступе к администратору кеша отказано."
-
-#: templates/ERR_FTP_PUT_ERROR:1
-msgid "ERROR: FTP upload failed"
-msgstr "ОШИБКА: Загрузка по FTP не удалась"
-
 #: templates/ERR_ACCESS_DENIED:1 templates/ERR_CANNOT_FORWARD:1
 #: templates/ERR_CONNECT_FAIL:1 templates/ERR_DNS_FAIL:1 templates/ERR_ESI:1
 #: templates/ERR_FORWARDING_DENIED:1 templates/ERR_FTP_DISABLED:1
@@ -180,34 +467,6 @@ msgstr "ОШИБКА: Запрошенный URN не может быть пол
 msgid "ESI Processing failed."
 msgstr "Обработка ESI не удалась."
 
-#: templates/ERR_FTP_LISTING:4
-msgid "FTP Directory Listing"
-msgstr "Список файлов в FTP директории"
-
-#: templates/ERR_FTP_LISTING:1
-msgid "FTP Directory: %U"
-msgstr "FTP директория: %U"
-
-#: templates/ERR_FTP_LISTING:2
-msgid "FTP Directory: <a href=\"/\">%U</a>/"
-msgstr "FTP директория: <a href=\"/\">%U</a>/"
-
-#: templates/ERR_FTP_PUT_CREATED:1
-msgid "FTP PUT Successful: File Created"
-msgstr "Операция FTP PUT завершилась успешно: файл создан"
-
-#: templates/ERR_FTP_PUT_MODIFIED:1
-msgid "FTP PUT Successful: File Updated"
-msgstr "Операция FTP PUT завершилась успешно: файл обновлен"
-
-#: templates/ERR_FTP_PUT_ERROR:3
-msgid "FTP PUT/upload failed"
-msgstr "Операция FTP PUT (загрузка) не удалась"
-
-#: templates/ERR_FTP_DISABLED:5
-msgid "FTP is Disabled"
-msgstr "FTP отключен"
-
 #: templates/ERR_SECURE_CONNECT_FAIL:5
 msgid "Failed to establish a secure connection to %I"
 msgstr "Не удалось установить безопасное соединение с %I"
@@ -216,14 +475,6 @@ msgstr "Не удалось установить безопасное соеди
 msgid "File created"
 msgstr "Файл создан"
 
-#: templates/ERR_FTP_PUT_MODIFIED:3
-msgid "File updated"
-msgstr "Файл обновлен"
-
-#: templates/ERR_FORWARDING_DENIED:5
-msgid "Forwarding Denied."
-msgstr "В пересылке отказано"
-
 #: templates/ERR_ACCESS_DENIED:8 templates/ERR_CACHE_ACCESS_DENIED:8
 #: templates/ERR_CACHE_MGR_ACCESS_DENIED:8 templates/ERR_CANNOT_FORWARD:8
 #: templates/ERR_CONNECT_FAIL:9 templates/ERR_DNS_FAIL:9 templates/ERR_ESI:9
@@ -248,39 +499,10 @@ msgstr "Создано %T на %h (%s)"
 msgid "Hey, don't expect too much from URNs on %T :)"
 msgstr "Не стоит ожидать чудес от URN-ов на %T :)"
 
-#: templates/ERR_ICAP_FAILURE:5
-msgid "ICAP protocol error."
-msgstr "Ошибка ICAP протокола."
-
-#: templates/ERR_TOO_BIG:7
-msgid ""
-"If you are making a GET request, then the item you are trying to download is "
-"too large."
-msgstr "Если Вы делаете GET запрос, то скачиваемый объект слишком велик."
-
-#: templates/ERR_TOO_BIG:6
-msgid ""
-"If you are making a POST or PUT request, then the item you are trying to "
-"upload is too large."
-msgstr ""
-"Если Вы делаете POST или PUT запросы, то закачиваемый объект слишком велик."
-
-#: templates/ERR_INVALID_REQ:11 templates/ERR_INVALID_URL:11
-msgid "Illegal character in hostname; underscores are not allowed."
-msgstr "Недопустимый символ в имени (hostname), подчеркивания запрещены."
-
 #: templates/ERR_INVALID_URL:10
 msgid "Illegal double-escape in the URL-Path"
 msgstr "Недопустимое двойное экранирование в пути URL (URL-Path)"
 
-#: templates/ERR_INVALID_URL:5
-msgid "Invalid URL"
-msgstr "Неверный URL"
-
-#: templates/ERR_INVALID_REQ:8
-msgid "Missing HTTP Identifier (HTTP/1.0)."
-msgstr "Отсутствует HTTP идентификатор (HTTP/1.0)."
-
 #: templates/ERR_INVALID_REQ:7
 msgid "Missing URL."
 msgstr "Отсутствует URL."
@@ -289,13 +511,6 @@ msgstr "Отсутствует URL."
 msgid "Missing hostname"
 msgstr "Отсутствует имя узла (hostname)"
 
-#: templates/ERR_INVALID_URL:8
-msgid ""
-"Missing or incorrect access protocol (should be <q>http://</q> or similar)"
-msgstr ""
-"Отсутствет или неверено указан протокол (должен быть <q>http://</q> или "
-"похожий)"
-
 #: templates/ERR_INVALID_REQ:6
 msgid "Missing or unknown request method."
 msgstr "Отсутствует или неизвестен метод запроса."
@@ -308,36 +523,6 @@ msgstr "Wais Relay не определен"
 msgid "Operation successful"
 msgstr "Операция завершилась успешно"
 
-#: templates/ERR_FTP_LISTING:5
-msgid "Parent Directory"
-msgstr "Родительская директория"
-
-#: templates/ERR_CACHE_ACCESS_DENIED:7
-msgid ""
-"Please contact the <a href=\"mailto:%w%W\">cache administrator</a> if you "
-"have difficulties authenticating yourself or <a href=\"http://%h/cgi-bin/"
-"chpasswd.cgi\">change</a> your default password."
-msgstr ""
-"Пожалуйста свяжитесь с <a href=\"mailto:%w%W\">администратором кэша</a>, "
-"если у Вас возникли проблемы с аутентификацией, либо <a href=\"http://%h/cgi-"
-"bin/chpasswd.cgi\">смените</a> Ваш пароль по умолчанию."
-
-#: templates/ERR_CACHE_MGR_ACCESS_DENIED:7
-msgid ""
-"Please contact the <a href=\"mailto:%w%W\">cache administrator</a> if you "
-"have difficulties authenticating yourself or, if you <em>are</em> the "
-"administrator, read Squid documentation on cache manager interface and check "
-"cache log for more detailed error messages."
-msgstr ""
-"Пожалуйста свяжитесь с <a href=\"mailto:%w%W\">администратором кэша</a>, "
-"если у Вас возникли проблемы с аутентификацией, если же <em>Вы "
-"администратор</em>, прочитайте документацию по интерфейсу управления кэшем и "
-"просмотрите лог-файл на предмет более детальных сообщений об ошибках."
-
-#: templates/ERR_READ_ERROR:5
-msgid "Read Error"
-msgstr "Ошибка при чтении"
-
 #: templates/ERR_READ_TIMEOUT:5
 msgid "Read Timeout"
 msgstr "Время ожидания при чтении истекло"
@@ -350,64 +535,22 @@ msgstr "Запрос слишком велик."
 msgid "Socket Failure"
 msgstr "Ошибка сокета"
 
-#: templates/ERR_INVALID_URL:6
-msgid "Some aspect of the requested URL is incorrect."
-msgstr "Некоторые параметры URL неверны"
-
 #: templates/ERR_ICAP_FAILURE:8 templates/ERR_INVALID_REQ:5
 #: templates/ERR_INVALID_URL:7
 msgid "Some possible problems are:"
 msgstr "Возможные проблемы:"
 
-#: templates/ERR_CACHE_MGR_ACCESS_DENIED:6
-msgid ""
-"Sorry, you are not currently allowed to request %U from this cache manager "
-"until you have authenticated yourself."
-msgstr ""
-"Извините, Вы не можете запросить %U из системы управления кэша до тех пор, "
-"пока не пройдете идентификацию."
-
-#: templates/ERR_CACHE_ACCESS_DENIED:6
-msgid ""
-"Sorry, you are not currently allowed to request %U from this cache until you "
-"have authenticated yourself."
-msgstr ""
-"Извините, Вы не можете запросить %U из этого кэша до тех пор, пока не "
-"пройдёте идентификацию."
-
 #: templates/ERR_ZERO_SIZE_OBJECT:6
 msgid "Squid did not receive any data for this request."
 msgstr "Squid не получил никаких данных в ответ на этот запрос."
 
-#: templates/ERR_UNSUP_REQ:6
-msgid ""
-"Squid does not support all request methods for all access protocols. For "
-"example, you can not POST a Gopher request."
-msgstr ""
-"Squid не поддерживает все методы запросов для всех протоколов. К примеру, "
-"для Gopher протокола Вы не можете выполнять запрос POST."
-
 #: templates/ERR_LIFETIME_EXP:6
 msgid ""
 "Squid has terminated the request because it has exceeded the maximum "
 "connection lifetime."
 msgstr ""
 "Squid прервал запрос из-за превышения максимального времени соединения."
 
-#: templates/ERR_SOCKET_FAILURE:7
-msgid ""
-"Squid is unable to create a TCP socket, presumably due to excessive load. "
-"Please retry your request."
-msgstr ""
-"Squid не может создать TCP сокет, предположительно из-за большой нагрузки. "
-"Пожалуйста, повторите запрос."
-
-#: templates/ERR_FTP_FAILURE:5 templates/ERR_FTP_FORBIDDEN:5
-#: templates/ERR_FTP_NOT_FOUND:5 templates/ERR_FTP_PUT_ERROR:5
-#: templates/ERR_FTP_UNAVAILABLE:5
-msgid "Squid sent the following FTP command:"
-msgstr "Squid послал следующую FTP комманду:"
-
 #: templates/ERR_DNS_FAIL:6
 msgid "The DNS server returned:"
 msgstr "Сервер DNS ответил:"
@@ -417,17 +560,10 @@ msgid "The ESI processor returned:"
 msgstr "Обработчик ESI ответил:"
 
 #: templates/ERR_FTP_UNAVAILABLE:4
-msgid "The FTP server was too busy to retrieve the URL: <a href=\"%U\">%U</a>"
-msgstr "Сервер FTP слишком нагружен, чтобы получить URL: <a href=\"%U\">%U</a>"
-
-#: templates/ERR_INVALID_RESP:5
 msgid ""
-"The HTTP Response message received from the contacted server could not be "
-"understood or was otherwise malformed. Please contact the site operator."
+"The FTP server was too busy to retrieve the URL: <a href=\"%U\">%U</a>"
 msgstr ""
-"Ответ HTTP (HTTP Response message), полученный от сервера не может быть "
-"обработан или неверно сформирован. Пожалуйста, свяжитесь с оператором "
-"сервера."
+"Сервер FTP слишком нагружен, чтобы получить URL: <a href=\"%U\">%U</a>"
 
 #: templates/ERR_ICAP_FAILURE:9
 msgid "The ICAP server is not reachable."
@@ -454,18 +590,6 @@ msgid ""
 "href=\"%U\">%U</a>"
 msgstr "При получении URL <a href=\"%U\">%U</a> произошла следующая ошибка"
 
-#: templates/ERR_URN_RESOLVE:4
-msgid ""
-"The following error was encountered while trying to retrieve the URN: <a "
-"href=\"%U\">%U</a>"
-msgstr "При получении URN: <a href=\"%U\">%U</a> произошла следующая ошибка"
-
-#: templates/ERR_CONNECT_FAIL:7
-msgid "The remote host or network may be down.  Please try the request again."
-msgstr ""
-"Удаленный узел или сеть могут быть недоступны. Пожалуйста, повторите запрос "
-"позже."
-
 #: templates/ERR_TOO_BIG:5
 msgid "The request or reply is too large."
 msgstr "Запрос или ответ слишком велик."
@@ -499,67 +623,11 @@ msgstr "Сервер ответил:"
 msgid "The system returned: <i>%E</i>"
 msgstr "Система вернула: <i>%E</i>"
 
-#: templates/ERR_NO_RELAY:6
-msgid ""
-"There is no WAIS Relay host defined for this Cache!  Yell at the "
-"administrator."
-msgstr ""
-"Для этого кэша не определен Wais Relay узел. Кричите на администратора."
-
-#: templates/ERR_TOO_BIG:8
-msgid ""
-"These limits have been established by the Internet Service Provider who "
-"operates this cache.  Please contact them directly if you feel this is an "
-"error."
-msgstr ""
-"Эти ограничения установлены вышим интернет провайдером, который управляет "
-"этим кэшем. Пожалуйста, свяжитесь с ними, если Вы считаете это неправильным."
-
 #: templates/ERR_UNSUP_HTTPVERSION:6
-msgid "This Squid does not accept the HTTP version you are attempting to use."
-msgstr ""
-"Данный Squid не принимает версию HTTP, которую вы пытаетесь использовать."
-
-#: templates/ERR_FTP_DISABLED:6
-msgid "This cache does not support FTP."
-msgstr "Этот кэш не поддерживает FTP."
-
-#: templates/ERR_SHUTTING_DOWN:5
-msgid ""
-"This cache is in the process of shutting down and can not service your "
-"request at this time.  Please retry your request again soon."
-msgstr ""
-"Этот кэш в процессе завершения работы и не может выполнить Ваш запрос в "
-"настоящее время. Пожалуйста, повторите запрос через некторое время."
-
-#: templates/ERR_FORWARDING_DENIED:6
-msgid ""
-"This cache will not forward your request because it is trying to enforce a "
-"sibling relationship.  Perhaps the client at %i is a cache which has been "
-"misconfigured."
-msgstr ""
-"Этот кэш не будет пересылать Ваш запрос по причине установки взаимоотношений "
-"типа sibling. Скорее всего клиент %i - неправильно сконфигурированный кэш."
-
-#: templates/ERR_ICAP_FAILURE:7
-msgid "This means that some aspect of the ICAP communication failed."
-msgstr "Это означает, что некоторые аспекты ICAP связи неудались."
-
-#: templates/ERR_FTP_PUT_ERROR:7
-msgid ""
-"This means that the FTP server may not have permission or space to store the "
-"file. Check the path, permissions, diskspace and try again."
-msgstr ""
-"Это означает, что FTP сервер может не иметь прав или свободного места для "
-"хранения файла. Проверьте путь, права, свободное место и повторите снова."
-
-#: templates/ERR_DNS_FAIL:7
 msgid ""
-"This means that the cache was not able to resolve the hostname presented in "
-"the URL. Check if the address is correct."
+"This Squid does not accept the HTTP version you are attempting to use."
 msgstr ""
-"Это означает, что кэш не смог преобразовать имя узла в URL. Проверьте адрес "
-"на правильность."
+"Данный Squid не принимает версию HTTP, которую вы пытаетесь использовать."
 
 #: templates/ERR_ESI:7
 msgid ""
@@ -569,48 +637,6 @@ msgstr ""
 "Это означает, что заместитель не сумел обработать ESI-шаблон. Пожалуйста, "
 "сообщите об этой ошибке веб-мастеру."
 
-#: templates/ERR_FTP_NOT_FOUND:7
-msgid ""
-"This might be caused by an FTP URL with an absolute path (which does not "
-"comply with RFC 1738).  If this is the cause, then the file can be found at "
-"<a href=\"%B\">%B</a>."
-msgstr ""
-"Это может быть вызвано FTP URL c абсолютным путем (который не соответствует "
-"RFC 1738). Если эта причина верна, то файл можно найти на <a href=\"%B\">%B</"
-"a>."
-
-#: templates/ERR_SECURE_CONNECT_FAIL:7
-msgid ""
-"This proxy and the remote host failed to negotiate a mutually acceptable "
-"security settings for handling your request. It is possible that the remote "
-"host does not support secure connections, or the proxy is not satisfied with "
-"the host security credentials."
-msgstr ""
-"При обработке Вашего запроса этот кэш и удаленный узел не смогли выбрать "
-"взаимно удовлетворяющие настройки безопасности. Возможно удаленный узел не "
-"поддерживает безопасные соединения, или кэш не не удовлетворен аттестатом "
-"безопасности узла."
-
-#: templates/ERR_CANNOT_FORWARD:6
-msgid ""
-"This request could not be forwarded to the origin server or to any parent "
-"caches.  The most likely cause for this error is that the cache "
-"administrator does not allow this cache to make direct connections to origin "
-"servers, and all configured parent caches are currently unreachable."
-msgstr ""
-"Этот запрос не может быть перенаправлен ни к первичному серверу, ни к "
-"родительским кэшам. Наиболее вероятная причина этой ошибки в том, что "
-"администратор запретил прямые соединения к первычным серверам, а все "
-"указанные родительские кэши в данный момент недоступны."
-
-#: templates/ERR_DNS_FAIL:5
-msgid "Unable to determine IP address from host name <q>%H</q>"
-msgstr "Невозможно определить IP адрес из имени узла <q>%H</q>"
-
-#: templates/ERR_CANNOT_FORWARD:5
-msgid "Unable to forward this request at this time."
-msgstr "Невозможно перенаправить запрос в данное время."
-
 #: templates/ERR_UNSUP_HTTPVERSION:3 templates/ERR_UNSUP_HTTPVERSION:5
 msgid "Unsupported HTTP version"
 msgstr "Неподдерживаемая версия HTTP"
@@ -627,24 +653,10 @@ msgstr ""
 "Действительный документ не найден в кэше и указана деректива <q>only-if-"
 "cached</q>."
 
-#: templates/ERR_FTP_PUT_ERROR:4
-msgid "While trying to PUT the following URL: <a href=\"%U\">%U</a>"
-msgstr "При попытке PUT следующего URL: <a href=\"%U\">%U</a>"
-
 #: templates/ERR_WRITE_ERROR:5
 msgid "Write Error"
 msgstr "Ошибка записи"
 
-#: templates/ERR_ONLY_IF_CACHED_MISS:6
-msgid ""
-"You have issued a request with a <q>only-if-cached</q> cache control "
-"directive. The document was not found in the cache, <em>or</em> it required "
-"revalidation prohibited by the <q>only-if-cached</q> directive."
-msgstr ""
-"Вы сделали запрос с директивой управления кэшем <q>only-if-cached</q>. "
-"Документ не был найден в кэше <em>или</em> он требует обновления, "
-"запрешенного директивой <q>only-if-cached</q>."
-
 #: templates/ERR_ACCESS_DENIED:7 templates/ERR_CANNOT_FORWARD:7
 #: templates/ERR_CONNECT_FAIL:8 templates/ERR_DNS_FAIL:8
 #: templates/ERR_FORWARDING_DENIED:7 templates/ERR_FTP_DISABLED:7
@@ -662,14 +674,6 @@ msgstr ""
 msgid "Your cache administrator is <a href=\"mailto:%w%W\">%w</a>."
 msgstr "Администратор Вашего кэша: <a href=\"mailto:%w%W\">%w</a>."
 
-#: templates/ERR_INVALID_RESP:6
-msgid ""
-"Your cache administrator may be able to provide you with more details about "
-"the exact nature of the problem if needed."
-msgstr ""
-"Администратор вашего кэша, при необходимости, может предоставить Вам более "
-"подробную информацию о действительных причинах проблемы."
-
 #: templates/ERR_ESI:8
 msgid "Your webmaster is <a href=\"mailto:%w\">%w</a>."
 msgstr "Ваш вебмастер: <a href=\"mailto:%w\">%w</a>."
@@ -14,12 +14,16 @@
  * Origin: Id: crypt.c,v 1.3 1995/05/30 05:42:22 rgrimes Exp
  *
  */
+#include "config.h"
 
+#if HAVE_STRING_H
 #include <string.h>
+#endif
+#if HAVE_STDIO_H
 #include <stdio.h>
-#include "config.h"
-#include "md5.h"
+#endif
 
+#include "md5.h"
 #include "crypt_md5.h"
 
 static unsigned char itoa64[] =	/* 0 ... 63 => ascii - 64 */
@@ -18,6 +18,7 @@
  */
 
 #include "config.h"
+
 #if HAVE_STDIO_H
 #include <stdio.h>
 #endif
@@ -50,6 +50,8 @@ sub check {
         $groupGID = `wbinfo -Y "$groupSID"`;
         chop $groupGID;
         &debug( "User:  -$user-\nGroup: -$group-\nSID:   -$groupSID-\nGID:   -$groupGID-");
+        return 'ERR' if($groupGID eq ""); # Verify if groupGID variable is empty.
+        return 'ERR' if(`wbinfo -r \Q$user\E` eq ""); # Verify if "wbinfo -r" command returns no value.
         return 'OK' if(`wbinfo -r \Q$user\E` =~ /^$groupGID$/m);
         return 'ERR';
 }
@@ -18,7 +18,7 @@
 
 # build results
 	bzr update 2>&1
-	./bootstrap.sh
+	./bootstrap.sh && 
 	./test-builds.sh --cleanup
 
 ) | /usr/sbin/sendmail -t
@@ -320,6 +320,8 @@ httpHeaderInitModule(void)
 
     httpHeaderCalcMask(&RequestHeadersMask, EntityHeadersArr, countof(EntityHeadersArr));
 
+    httpHeaderMaskInit(&HopByHopHeadersMask, 0);
+    
     httpHeaderCalcMask(&HopByHopHeadersMask, HopByHopHeadersArr, countof(HopByHopHeadersArr));
 
     /* init header stats */
@@ -150,51 +150,50 @@ bool HttpMsg::parse(MemBuf *buf, bool eof, http_status *error)
     buf->terminate(); // does not affect content size
 
     // find the end of headers
-    // TODO: Remove? httpReplyParseStep() should do similar checks
     const size_t hdr_len = headersEnd(buf->content(), buf->contentSize());
 
+    // sanity check the start line to see if this is in fact an HTTP message
+    if (!sanityCheckStartLine(buf, hdr_len, error)) {
+        // NP: sanityCheck sets *error and sends debug warnings on syntax errors.
+        // if we have seen the connection close, this is an error too
+        if (eof && *error==HTTP_STATUS_NONE)
+            *error = HTTP_INVALID_HEADER;
+
+        return false;
+    }
+
     // TODO: move to httpReplyParseStep()
     if (hdr_len > Config.maxReplyHeaderSize || (hdr_len <= 0 && (size_t)buf->contentSize() > Config.maxReplyHeaderSize)) {
-        debugs(58, 1, "HttpMsg::parse: Too large reply header (" <<
-               hdr_len << " > " << Config.maxReplyHeaderSize);
+        debugs(58, 1, "HttpMsg::parse: Too large reply header (" << hdr_len << " > " << Config.maxReplyHeaderSize);
         *error = HTTP_HEADER_TOO_LARGE;
         return false;
     }
 
     if (hdr_len <= 0) {
-        debugs(58, 3, "HttpMsg::parse: failed to find end of headers " <<
-               "(eof: " << eof << ") in '" << buf->content() << "'");
+        debugs(58, 3, "HttpMsg::parse: failed to find end of headers (eof: " << eof << ") in '" << buf->content() << "'");
 
         if (eof) // iff we have seen the end, this is an error
             *error = HTTP_INVALID_HEADER;
 
         return false;
     }
 
-    if (!sanityCheckStartLine(buf, error)) {
-        debugs(58,1, HERE << "first line of HTTP message is invalid");
-        *error = HTTP_INVALID_HEADER;
-        return false;
-    }
-
     const int res = httpMsgParseStep(buf->content(), buf->contentSize(), eof);
 
     if (res < 0) { // error
-        debugs(58, 3, "HttpMsg::parse: cannot parse isolated headers " <<
-               "in '" << buf->content() << "'");
+        debugs(58, 3, "HttpMsg::parse: cannot parse isolated headers in '" << buf->content() << "'");
         *error = HTTP_INVALID_HEADER;
         return false;
     }
 
     if (res == 0) {
-        debugs(58, 2, "HttpMsg::parse: strange, need more data near '" <<
-               buf->content() << "'");
+        debugs(58, 2, "HttpMsg::parse: strange, need more data near '" << buf->content() << "'");
+        *error = HTTP_INVALID_HEADER;
         return false; // but this should not happen due to headersEnd() above
     }
 
     assert(res > 0);
-    debugs(58, 9, "HttpMsg::parse success (" << hdr_len << " bytes) " <<
-           "near '" << buf->content() << "'");
+    debugs(58, 9, "HttpMsg::parse success (" << hdr_len << " bytes) near '" << buf->content() << "'");
 
     if (hdr_sz != (int)hdr_len) {
         debugs(58, 1, "internal HttpMsg::parse vs. headersEnd error: " <<
@@ -244,21 +243,20 @@ HttpMsg::httpMsgParseStep(const char *buf, int len, int atEnd)
     const char **parse_end_ptr = &blk_end;
     assert(parse_start);
     assert(pstate < psParsed);
-    int retval;
 
     *parse_end_ptr = parse_start;
 
     PROF_start(HttpMsg_httpMsgParseStep);
 
     if (pstate == psReadyToParseStartLine) {
         if (!httpMsgIsolateStart(&parse_start, &blk_start, &blk_end)) {
-            retval = 0;
-            goto finish;
+            PROF_stop(HttpMsg_httpMsgParseStep);
+            return 0;
         }
 
         if (!parseFirstLine(blk_start, blk_end)) {
-            retval = httpMsgParseError();
-            goto finish;
+            PROF_stop(HttpMsg_httpMsgParseStep);
+            return httpMsgParseError();
         }
 
         *parse_end_ptr = parse_start;
@@ -279,13 +277,15 @@ HttpMsg::httpMsgParseStep(const char *buf, int len, int atEnd)
             if (atEnd) {
                 blk_start = parse_start, blk_end = blk_start + strlen(blk_start);
             } else {
-                retval = 0;
-                goto finish;
+                PROF_stop(HttpMsg_httpMsgParseStep);
+                return 0;
             }
         }
 
-        if (!header.parse(blk_start, blk_end))
+        if (!header.parse(blk_start, blk_end)) {
+            PROF_stop(HttpMsg_httpMsgParseStep);
             return httpMsgParseError();
+        }
 
         hdrCacheInit();
 
@@ -295,10 +295,9 @@ HttpMsg::httpMsgParseStep(const char *buf, int len, int atEnd)
 
         ++pstate;
     }
-    retval = 1;
-finish:
+
     PROF_stop(HttpMsg_httpMsgParseStep);
-    return retval;
+    return 1;
 }
 
 /* handy: resets and returns -1 */
@@ -379,9 +378,8 @@ void HttpMsg::firstLineBuf(MemBuf& mb)
     packerClean(&p);
 }
 
-HttpMsg *
-
 // use HTTPMSGLOCK() instead of calling this directly
+HttpMsg *
 HttpMsg::_lock()
 {
     lock_count++;
@@ -99,7 +99,14 @@ class HttpMsg
     virtual bool inheritProperties(const HttpMsg *aMsg) = 0;
 
 protected:
-    virtual bool sanityCheckStartLine(MemBuf *buf, http_status *error) = 0;
+     /**
+      * Validate the message start line is syntactically correct.
+      * Set HTTP error status according to problems found.
+      *
+      * \retval true   Status line has no serious problems.
+      * \retval false  Status line has a serious problem. Correct response is indicated by error.
+      */
+    virtual bool sanityCheckStartLine(MemBuf *buf, const size_t hdr_len, http_status *error) = 0;
 
     virtual void packFirstLineInto(Packer * p, bool full_uri) const = 0;
 
@@ -437,15 +437,56 @@ HttpReply::bodySize(const HttpRequestMethod& method) const
     return content_length;
 }
 
-bool HttpReply::sanityCheckStartLine(MemBuf *buf, http_status *error)
+/**
+ * Checks the first line of an HTTP Reply is valid.
+ * currently only checks "HTTP/" exists.
+ *
+ * NP: not all error cases are detected yet. Some are left for detection later in parse.
+ */
+bool
+HttpReply::sanityCheckStartLine(MemBuf *buf, const size_t hdr_len, http_status *error)
 {
-    //hack warning: using psize instead of size here due to type mismatches with MemBuf.
-    if (buf->contentSize() >= protoPrefix.psize() && protoPrefix.cmp(buf->content(), protoPrefix.size()) != 0) {
+    // hack warning: using psize instead of size here due to type mismatches with MemBuf.
+
+    // content is long enough to possibly hold a reply
+    // 4 being magic size of a 3-digit number plus space delimiter
+    if ( buf->contentSize() < (protoPrefix.psize() + 4) ) {
+        if (hdr_len > 0) {
+            debugs(58, 3, HERE << "Too small reply header (" << hdr_len << " bytes)");
+            *error = HTTP_INVALID_HEADER;
+        }
+        return false;
+    }
+
+    // catch missing or mismatched protocol identifier
+    if (protoPrefix.cmp(buf->content(), protoPrefix.size()) != 0) {
         debugs(58, 3, "HttpReply::sanityCheckStartLine: missing protocol prefix (" << protoPrefix << ") in '" << buf->content() << "'");
         *error = HTTP_INVALID_HEADER;
         return false;
     }
 
+    // catch missing or negative status value (negative '-' is not a digit)
+    int pos = protoPrefix.psize();
+
+    // skip arbitrary number of digits and a dot in the verion portion
+    while ( pos <= buf->contentSize() && (*(buf->content()+pos) == '.' || xisdigit(*(buf->content()+pos)) ) ) ++pos;
+
+    // catch missing version info
+    if (pos == protoPrefix.psize()) {
+        debugs(58, 3, "HttpReply::sanityCheckStartLine: missing protocol version numbers (ie. " << protoPrefix << "/1.0) in '" << buf->content() << "'");
+        *error = HTTP_INVALID_HEADER;
+        return false;
+    }
+
+    // skip arbitrary number of spaces...
+    while (pos <= buf->contentSize() && (char)*(buf->content()+pos) == ' ') ++pos;
+
+    if (!xisdigit(*(buf->content()+pos))) {
+        debugs(58, 3, "HttpReply::sanityCheckStartLine: missing or invalid status number in '" << buf->content() << "'");
+        *error = HTTP_INVALID_HEADER;
+        return false;
+    }
+
     return true;
 }
 
@@ -68,7 +68,7 @@ class HttpReply: public HttpMsg
      \retval false and sets *error to zero when needs more data
      \retval false and sets *error to a positive http_status code on error
      */
-    virtual bool sanityCheckStartLine(MemBuf *buf, http_status *error);
+    virtual bool sanityCheckStartLine(MemBuf *buf, const size_t hdr_len, http_status *error);
 
     /** \par public, readable; never update these or their .hdr equivalents directly */
     time_t date;
@@ -208,18 +208,30 @@ HttpRequest::clone() const
     return copy;
 }
 
+/**
+ * Checks the first line of an HTTP request is valid
+ * currently just checks the request method is present.
+ *
+ * NP: Other errors are left for detection later in the parse.
+ */
 bool
-HttpRequest::sanityCheckStartLine(MemBuf *buf, http_status *error)
-{
-    /**
-     * Just see if the request buffer starts with a known
-     * HTTP request method.  NOTE this whole function is somewhat
-     * superfluous and could just go away.
-     \todo AYJ: Check for safely removing this function. We now accept 'unknown' request methods in HTTP.
-     */
+HttpRequest::sanityCheckStartLine(MemBuf *buf, const size_t hdr_len, http_status *error)
+{
+    // content is long enough to possibly hold a reply
+    // 2 being magic size of a 1-byte request method plus space delimiter
+    if ( buf->contentSize() < 2 ) {
+        // this is ony a real error if the headers apparently complete.
+        if (hdr_len > 0) {
+            debugs(58, 3, HERE << "Too large request header (" << hdr_len << " bytes)");
+            *error = HTTP_INVALID_HEADER;
+        }
+        return false;
+    }
 
+    /* See if the request buffer starts with a known HTTP request method. */
     if (HttpRequestMethod(buf->content(),NULL) == METHOD_NONE) {
         debugs(73, 3, "HttpRequest::sanityCheckStartLine: did not find HTTP request method");
+        *error = HTTP_INVALID_HEADER;
         return false;
     }
 
@@ -234,7 +234,7 @@ class HttpRequest: public HttpMsg
 protected:
     virtual void packFirstLineInto(Packer * p, bool full_uri) const;
 
-    virtual bool sanityCheckStartLine(MemBuf *buf, http_status *error);
+    virtual bool sanityCheckStartLine(MemBuf *buf, const size_t hdr_len, http_status *error);
 
     virtual void hdrCacheInit();
 
@@ -402,6 +402,7 @@ squid_SOURCES = \
 	MemObject.cc \
 	MemObject.h \
 	mime.cc \
+	mime_header.cc \
 	multicast.cc \
 	neighbors.cc \
 	Packer.cc \
@@ -835,12 +836,16 @@ check_PROGRAMS+= tests/testAuth \
 	tests/testEvent \
 	tests/testEventLoop \
 	tests/test_http_range \
+	tests/testHttpReply \
 	tests/testHttpRequest \
 	tests/testStore \
 	tests/testString \
 	tests/testURL \
 	@STORE_TESTS@
 
+## NP: required to run the above list. check_PROGRAMS only builds the binaries...
+TESTS += $(check_PROGRAMS)
+
 ### Template for new Unit Test Program
 ## - add tests/testX to check_PROGRAMS above.
 ## - copy template below and substitue X for class name
@@ -864,6 +869,61 @@ check_PROGRAMS+= tests/testAuth \
 #tests_testX_DEPENDENCIES= @SQUID_CPPUNIT_LA@ \
 #	$(top_builddir)/lib/libmiscutil.a
 
+
+# - add other component .(h|cc) files needed to link and run tests
+tests_testHttpReply_SOURCES=\
+	tests/testHttpReply.h \
+	tests/testHttpReply.cc \
+	tests/testMain.cc \
+	cbdata.h \
+	cbdata.cc \
+	ETag.cc \
+	HttpBody.cc \
+	HttpHdrCc.cc \
+	HttpHdrContRange.h \
+	HttpHdrContRange.cc \
+	HttpHdrRange.cc \
+	HttpHdrSc.h \
+	HttpHdrSc.cc \
+	HttpHdrScTarget.h \
+	HttpHdrScTarget.cc \
+	HttpHeader.h \
+	HttpHeader.cc \
+	HttpHeaderMask.h \
+	HttpHeaderTools.cc \
+	HttpMsg.h \
+	HttpMsg.cc \
+	HttpReply.h \
+	HttpReply.cc \
+	HttpStatusLine.h \
+	HttpStatusLine.cc \
+	mem.cc \
+	MemBuf.h \
+	MemBuf.cc \
+	mime_header.cc \
+	Packer.h \
+	Packer.cc \
+	tests/stub_cache_manager.cc \
+	tests/stub_StatHist.cc \
+	tests/stub_store.cc \
+	SquidString.h \
+	String.cc \
+	SquidTime.h \
+	time.cc
+nodist_tests_testHttpReply_SOURCES=\
+	$(TESTSOURCES)
+tests_testHttpReply_LDFLAGS = $(LIBADD_DL)
+tests_testHttpReply_LDADD=\
+	acl/libapi.la \
+	acl/libstate.la \
+	auth/libauth.la \
+	ip/libip.la \
+	@SQUID_CPPUNIT_LIBS@ \
+	@SQUID_CPPUNIT_LA@ \
+	-L../lib -lmiscutil
+tests_testHttpReply_DEPENDENCIES= @SQUID_CPPUNIT_LA@ \
+	$(top_builddir)/lib/libmiscutil.a
+
 tests_testAuth_SOURCES = \
 	tests/testAuth.cc tests/testMain.cc  tests/testAuth.h \
 	ConfigParser.cc \
@@ -1055,6 +1115,7 @@ tests_testCacheManager_SOURCES = \
 	MemBuf.cc \
 	MemObject.cc \
 	mime.cc \
+	mime_header.cc \
 	neighbors.cc \
 	Packer.cc \
 	Parsing.cc \
@@ -1224,6 +1285,7 @@ tests_testEvent_SOURCES = \
 	MemBuf.cc \
 	MemObject.cc \
 	mime.cc \
+	mime_header.cc \
 	neighbors.cc \
 	Packer.cc \
 	Parsing.cc \
@@ -1371,6 +1433,7 @@ tests_testEventLoop_SOURCES = \
 	MemBuf.cc \
 	MemObject.cc \
 	mime.cc \
+	mime_header.cc \
 	neighbors.cc \
 	Packer.cc \
 	Parsing.cc \
@@ -1508,6 +1571,7 @@ tests_test_http_range_SOURCES = \
 	mem_node.cc \
 	MemObject.cc \
 	mime.cc \
+	mime_header.cc \
 	multicast.cc \
 	neighbors.cc \
 	Parsing.cc \
@@ -1659,6 +1723,7 @@ tests_testHttpRequest_SOURCES = \
 	MemBuf.cc \
 	MemObject.cc \
 	mime.cc \
+	mime_header.cc \
 	neighbors.cc \
 	Packer.cc \
 	Parsing.cc \
@@ -2010,6 +2075,7 @@ tests_testURL_SOURCES = \
 	MemBuf.cc \
 	MemObject.cc \
 	mime.cc \
+	mime_header.cc \
 	neighbors.cc \
 	Packer.cc \
 	Parsing.cc \
@@ -60,8 +60,6 @@ class MemObject;
 class Store;
 class StoreSearch;
 
-typedef unsigned int ping_status_t;
-
 /**
  \ingroup StoreAPI
  */
@@ -141,24 +139,19 @@ class StoreEntry : public hash_link
     u_short flags;
     /* END OF ON-DISK STORE_META_STD */
 
-sfileno swap_filen:
-    25;
+    sfileno swap_filen:25;
+
+    sdirno swap_dirn:7;
 
-sdirno swap_dirn:
-    7;
     u_short lock_count;		/* Assume < 65536! */
 
-mem_status_t mem_status:
-    3;
+    mem_status_t mem_status:3;
 
-ping_status_t ping_status:
-    3;
+    ping_status_t ping_status:3;
 
-store_status_t store_status:
-    3;
+    store_status_t store_status:3;
 
-swap_status_t swap_status:
-    3;
+    swap_status_t swap_status:3;
 
 public:
     static size_t inUseCount();
@@ -150,6 +150,7 @@ String::clean()
     PROF_start(StringClean);
     assert(this);
 
+    /* TODO if mempools has already closed this will FAIL!! */
     if (defined())
         memFreeString(size_, buf_);
 
@@ -40,6 +40,8 @@
 #include "HttpRequestMethod.h"
 #include "wordlist.h"
 
+int ACLMethodData::ThePurgeCount = 0;
+
 ACLMethodData::ACLMethodData() : values (NULL)
 {}
 
@@ -89,10 +91,8 @@ ACLMethodData::parse()
 
     for (Tail = &values; *Tail; Tail = &((*Tail)->next));
     while ((t = strtokFile())) {
-        if(strcmp(t, "PURGE") == 0) {
-            // we need to use PURGE, can't just blanket-deny it.
-            Config2.onoff.enable_purge = 1;
-        }
+        if(strcmp(t, "PURGE") == 0)
+            ++ThePurgeCount; // configuration code wants to know
         CbDataList<HttpRequestMethod> *q = new CbDataList<HttpRequestMethod> (HttpRequestMethod(t, NULL));
         *(Tail) = q;
         Tail = &q->next;
@@ -57,6 +57,8 @@ class ACLMethodData : public ACLData<HttpRequestMethod>
     virtual ACLData<HttpRequestMethod> *clone() const;
 
     CbDataList<HttpRequestMethod> *values;
+
+    static int ThePurgeCount; ///< PURGE methods seen by parse()
 };
 
 MEMPROXY_CLASS_INLINE(ACLMethodData);
@@ -7,7 +7,7 @@
 #include "adaptation/History.h"
 
 /// impossible services value to identify unset theNextServices
-const static String TheNullServices(",null,");
+const static char *TheNullServices = ",null,";
 
 Adaptation::History::Entry::Entry(const String &sid, const timeval &when):
     service(sid), start(when), theRptm(-1), retried(false)
@@ -61,9 +61,6 @@
 // AYJ: must match re-definition in helpers/negotiate_auth/squid_kerb_auth/squid_kerb_auth.c
 #define MAX_AUTHTOKEN_LEN   32768
 
-static void
-authenticateNegotiateReleaseServer(AuthUserRequest * auth_user_request);
-
 
 /// \ingroup AuthNegotiateInternal
 static void
@@ -382,13 +379,12 @@ NegotiateUser::~NegotiateUser()
     debugs(29, 5, "NegotiateUser::~NegotiateUser: doing nothing to clearNegotiate scheme data for '" << this << "'");
 }
 
-static stateful_helper_callback_t
+static void
 authenticateNegotiateHandleReply(void *data, void *lastserver, char *reply)
 {
     authenticateStateData *r = static_cast<authenticateStateData *>(data);
 
     int valid;
-    stateful_helper_callback_t result = S_HELPER_UNKNOWN;
     char *blob, *arg = NULL;
 
     AuthUserRequest *auth_user_request;
@@ -400,11 +396,10 @@ authenticateNegotiateHandleReply(void *data, void *lastserver, char *reply)
     valid = cbdataReferenceValid(r->data);
 
     if (!valid) {
-        debugs(29, 1, "authenticateNegotiateHandleReply: invalid callback data. Releasing helper '" << lastserver << "'.");
+        debugs(29, 1, "authenticateNegotiateHandleReply: invalid callback data. helper '" << lastserver << "'.");
         cbdataReferenceDone(r->data);
         authenticateStateFree(r);
-        debugs(29, 9, "authenticateNegotiateHandleReply: telling stateful helper : " << S_HELPER_RELEASE);
-        return S_HELPER_RELEASE;
+        return;
     }
 
     if (!reply) {
@@ -454,11 +449,9 @@ authenticateNegotiateHandleReply(void *data, void *lastserver, char *reply)
             negotiate_request->auth_state = AUTHENTICATE_STATE_IN_PROGRESS;
             auth_user_request->denyMessage("Authentication in progress");
             debugs(29, 4, "authenticateNegotiateHandleReply: Need to challenge the client with a server blob '" << blob << "'");
-            result = S_HELPER_RESERVE;
         } else {
             negotiate_request->auth_state = AUTHENTICATE_STATE_FAILED;
             auth_user_request->denyMessage("NTLM authentication requires a persistent connection");
-            result = S_HELPER_RELEASE;
         }
     } else if (strncasecmp(reply, "AF ", 3) == 0 && arg != NULL) {
         /* we're finished, release the helper */
@@ -474,12 +467,10 @@ authenticateNegotiateHandleReply(void *data, void *lastserver, char *reply)
 
         negotiate_request->server_blob = xstrdup(blob);
 
-        authenticateNegotiateReleaseServer(negotiate_request);
+        negotiate_request->releaseAuthServer();
 
         negotiate_request->auth_state = AUTHENTICATE_STATE_DONE;
 
-        result = S_HELPER_RELEASE;
-
         debugs(29, 4, "authenticateNegotiateHandleReply: Successfully validated user via Negotiate. Username '" << blob << "'");
 
         /* connection is authenticated */
@@ -506,7 +497,7 @@ authenticateNegotiateHandleReply(void *data, void *lastserver, char *reply)
         /* set these to now because this is either a new login from an
          * existing user or a new user */
         local_auth_user->expiretime = current_time.tv_sec;
-        authenticateNegotiateReleaseServer(negotiate_request);
+        negotiate_request->releaseAuthServer();
         negotiate_request->auth_state = AUTHENTICATE_STATE_DONE;
 
     } else if (strncasecmp(reply, "NA ", 3) == 0 && arg != NULL) {
@@ -523,9 +514,7 @@ authenticateNegotiateHandleReply(void *data, void *lastserver, char *reply)
 
         negotiate_request->server_blob = xstrdup(blob);
 
-        authenticateNegotiateReleaseServer(negotiate_request);
-
-        result = S_HELPER_RELEASE;
+        negotiate_request->releaseAuthServer();
 
         debugs(29, 4, "authenticateNegotiateHandleReply: Failed validating user via Negotiate. Error returned '" << blob << "'");
     } else if (strncasecmp(reply, "BH ", 3) == 0) {
@@ -537,8 +526,7 @@ authenticateNegotiateHandleReply(void *data, void *lastserver, char *reply)
         auth_user_request->denyMessage(blob);
         negotiate_request->auth_state = AUTHENTICATE_STATE_FAILED;
         safe_free(negotiate_request->server_blob);
-        authenticateNegotiateReleaseServer(negotiate_request);
-        result = S_HELPER_RELEASE;
+        negotiate_request->releaseAuthServer();
         debugs(29, 1, "authenticateNegotiateHandleReply: Error validating user via Negotiate. Error returned '" << reply << "'");
     } else {
         /* protocol error */
@@ -552,8 +540,6 @@ authenticateNegotiateHandleReply(void *data, void *lastserver, char *reply)
     r->handler(r->data, NULL);
     cbdataReferenceDone(r->data);
     authenticateStateFree(r);
-    debugs(29, 9, "authenticateNegotiateHandleReply: telling stateful helper : " << result);
-    return result;
 }
 
 static void
@@ -605,25 +591,20 @@ AuthNegotiateUserRequest::module_start(RH * handler, void *data)
     helperStatefulSubmit(negotiateauthenticators, buf, authenticateNegotiateHandleReply, r, authserver);
 }
 
-/* clear the Negotiate helper of being reserved for future requests */
-static void
-authenticateNegotiateReleaseServer(AuthUserRequest * auth_user_request)
+/**
+ * Atomic action: properly release the Negotiate auth helpers which may have been reserved
+ * for this request connections use.
+ */
+void
+AuthNegotiateUserRequest::releaseAuthServer()
 {
-    AuthNegotiateUserRequest *negotiate_request;
-    assert(auth_user_request->user()->auth_type == AUTH_NEGOTIATE);
-    negotiate_request = dynamic_cast< AuthNegotiateUserRequest *>(auth_user_request);
-    assert(negotiate_request != NULL);
-    debugs(29, 9, "authenticateNegotiateReleaseServer: releasing server '" << negotiate_request->authserver << "'");
-    /* is it possible for the server to be NULL? hno seems to think so.
-     * Let's see what happens, might segfault in helperStatefulReleaseServer
-     * if it does. I leave it like this not to cover possibly problematic
-     * code-paths. Kinkie */
-    /* DPW 2007-05-07
-     * yes, it is possible */
-    if (negotiate_request->authserver) {
-        helperStatefulReleaseServer(negotiate_request->authserver);
-        negotiate_request->authserver = NULL;
+    if (authserver) {
+        debugs(29, 6, HERE << "releasing Negotiate auth server '" << authserver << "'");
+        helperStatefulReleaseServer(authserver);
+        authserver = NULL;
     }
+    else
+        debugs(29, 6, HERE << "No Negotiate auth server to release.");
 }
 
 /* clear any connection related authentication details */
@@ -639,8 +620,7 @@ AuthNegotiateUserRequest::onConnectionClose(ConnStateData *conn)
         return;
     }
 
-    if (authserver != NULL)
-        authenticateNegotiateReleaseServer(this);
+    releaseAuthServer();
 
     /* unlock the connection based lock */
     debugs(29, 9, "AuthNegotiateUserRequest::onConnectionClose: Unlocking auth_user from the connection '" << conn << "'.");
@@ -84,6 +84,8 @@ class AuthNegotiateUserRequest : public AuthUserRequest
 
     /*we need to store the helper server between requests */
     helper_stateful_server *authserver;
+    void releaseAuthServer(void); ///< Release the authserver helper server properly.
+
     /* what connection is this associated with */
     /* ConnStateData * conn;*/
 
@@ -50,9 +50,6 @@
 #include "wordlist.h"
 #include "SquidTime.h"
 
-static void
-authenticateNTLMReleaseServer(AuthUserRequest * auth_user_request);
-
 
 static void
 authenticateStateFree(authenticateStateData * r)
@@ -328,13 +325,12 @@ NTLMUser::~NTLMUser()
     debugs(29, 5, "NTLMUser::~NTLMUser: doing nothing to clearNTLM scheme data for '" << this << "'");
 }
 
-static stateful_helper_callback_t
+static void
 authenticateNTLMHandleReply(void *data, void *lastserver, char *reply)
 {
     authenticateStateData *r = static_cast<authenticateStateData *>(data);
 
     int valid;
-    stateful_helper_callback_t result = S_HELPER_UNKNOWN;
     char *blob;
 
     AuthUserRequest *auth_user_request;
@@ -346,11 +342,10 @@ authenticateNTLMHandleReply(void *data, void *lastserver, char *reply)
     valid = cbdataReferenceValid(r->data);
 
     if (!valid) {
-        debugs(29, 1, "authenticateNTLMHandleReply: invalid callback data. Releasing helper '" << lastserver << "'.");
+        debugs(29, 1, "authenticateNTLMHandleReply: invalid callback data. helper '" << lastserver << "'.");
         cbdataReferenceDone(r->data);
         authenticateStateFree(r);
-        debugs(29, 9, "authenticateNTLMHandleReply: telling stateful helper : " << S_HELPER_RELEASE);
-        return S_HELPER_RELEASE;
+        return;
     }
 
     if (!reply) {
@@ -394,19 +389,16 @@ authenticateNTLMHandleReply(void *data, void *lastserver, char *reply)
             ntlm_request->auth_state = AUTHENTICATE_STATE_IN_PROGRESS;
             auth_user_request->denyMessage("Authentication in progress");
             debugs(29, 4, "authenticateNTLMHandleReply: Need to challenge the client with a server blob '" << blob << "'");
-            result = S_HELPER_RESERVE;
         } else {
             ntlm_request->auth_state = AUTHENTICATE_STATE_FAILED;
             auth_user_request->denyMessage("NTLM authentication requires a persistent connection");
-            result = S_HELPER_RELEASE;
         }
     } else if (strncasecmp(reply, "AF ", 3) == 0) {
         /* we're finished, release the helper */
         ntlm_user->username(blob);
         auth_user_request->denyMessage("Login successful");
         safe_free(ntlm_request->server_blob);
 
-        result = S_HELPER_RELEASE;
         debugs(29, 4, "authenticateNTLMHandleReply: Successfully validated user via NTLM. Username '" << blob << "'");
         /* connection is authenticated */
         debugs(29, 4, "AuthNTLMUserRequest::authenticate: authenticated user " << ntlm_user->username());
@@ -432,15 +424,14 @@ authenticateNTLMHandleReply(void *data, void *lastserver, char *reply)
         /* set these to now because this is either a new login from an
          * existing user or a new user */
         local_auth_user->expiretime = current_time.tv_sec;
-        authenticateNTLMReleaseServer(ntlm_request);
+        ntlm_request->releaseAuthServer();
         ntlm_request->auth_state = AUTHENTICATE_STATE_DONE;
     } else if (strncasecmp(reply, "NA ", 3) == 0) {
         /* authentication failure (wrong password, etc.) */
         auth_user_request->denyMessage(blob);
         ntlm_request->auth_state = AUTHENTICATE_STATE_FAILED;
         safe_free(ntlm_request->server_blob);
-        authenticateNTLMReleaseServer(ntlm_request);
-        result = S_HELPER_RELEASE;
+        ntlm_request->releaseAuthServer();
         debugs(29, 4, "authenticateNTLMHandleReply: Failed validating user via NTLM. Error returned '" << blob << "'");
     } else if (strncasecmp(reply, "BH ", 3) == 0) {
         /* TODO kick off a refresh process. This can occur after a YR or after
@@ -451,8 +442,7 @@ authenticateNTLMHandleReply(void *data, void *lastserver, char *reply)
         auth_user_request->denyMessage(blob);
         ntlm_request->auth_state = AUTHENTICATE_STATE_FAILED;
         safe_free(ntlm_request->server_blob);
-        authenticateNTLMReleaseServer(ntlm_request);
-        result = S_HELPER_RELEASE;
+        ntlm_request->releaseAuthServer();
         debugs(29, 1, "authenticateNTLMHandleReply: Error validating user via NTLM. Error returned '" << reply << "'");
     } else {
         /* protocol error */
@@ -466,8 +456,6 @@ authenticateNTLMHandleReply(void *data, void *lastserver, char *reply)
     r->handler(r->data, NULL);
     cbdataReferenceDone(r->data);
     authenticateStateFree(r);
-    debugs(29, 9, "authenticateNTLMHandleReply: telling stateful helper : " << result);
-    return result;
 }
 
 static void
@@ -519,25 +507,20 @@ AuthNTLMUserRequest::module_start(RH * handler, void *data)
     helperStatefulSubmit(ntlmauthenticators, buf, authenticateNTLMHandleReply, r, authserver);
 }
 
-/* clear the NTLM helper of being reserved for future requests */
-static void
-authenticateNTLMReleaseServer(AuthUserRequest * auth_user_request)
+/**
+ * Atomic action: properly release the NTLM auth helpers which may have been reserved
+ * for this request connections use.
+ */
+void
+AuthNTLMUserRequest::releaseAuthServer()
 {
-    AuthNTLMUserRequest *ntlm_request;
-    assert(auth_user_request->user()->auth_type == AUTH_NTLM);
-    ntlm_request = dynamic_cast< AuthNTLMUserRequest *>(auth_user_request);
-    debugs(29, 9, "authenticateNTLMReleaseServer: releasing server '" << ntlm_request->authserver << "'");
-    /* is it possible for the server to be NULL? hno seems to think so.
-     * Let's see what happens, might segfault in helperStatefulReleaseServer
-     * if it does. I leave it like this not to cover possibly problematic
-     * code-paths. Kinkie */
-    /* DPW 2007-05-07
-     * yes, it is possible */
-    assert(ntlm_request != NULL);
-    if (ntlm_request->authserver) {
-        helperStatefulReleaseServer(ntlm_request->authserver);
-        ntlm_request->authserver = NULL;
+    if (authserver) {
+        debugs(29, 6, HERE << "releasing NTLM auth server '" << authserver << "'");
+	helperStatefulReleaseServer(authserver);
+	authserver = NULL;
     }
+    else
+        debugs(29, 6, HERE << "No NTLM auth server to release.");
 }
 
 /* clear any connection related authentication details */
@@ -553,8 +536,8 @@ AuthNTLMUserRequest::onConnectionClose(ConnStateData *conn)
         return;
     }
 
-    if (authserver != NULL)
-        authenticateNTLMReleaseServer(this);
+    // unlock / un-reserve the helpers
+    releaseAuthServer();
 
     /* unlock the connection based lock */
     debugs(29, 9, "AuthNTLMUserRequest::onConnectionClose: Unlocking auth_user from the connection '" << conn << "'.");
@@ -720,11 +703,8 @@ AuthNTLMUserRequest::~AuthNTLMUserRequest()
     safe_free(server_blob);
     safe_free(client_blob);
 
-    if (authserver != NULL) {
-        debugs(29, 9, "AuthNTLMUserRequest::~AuthNTLMUserRequest: releasing server '" << authserver << "'");
-        helperStatefulReleaseServer(authserver);
-        authserver = NULL;
-    }
+    releaseAuthServer();
+
     if (request) {
         HTTPMSGUNLOCK(request);
         request = NULL;
@@ -753,4 +733,3 @@ AuthNTLMUserRequest::connLastHeader()
 {
     return NULL;
 }
-
@@ -68,8 +68,10 @@ class AuthNTLMUserRequest : public AuthUserRequest
 
     virtual const char * connLastHeader();
 
-    /*we need to store the helper server between requests */
+    /* we need to store the helper server between requests */
     helper_stateful_server *authserver;
+    void releaseAuthServer(void); ///< Release authserver NTLM helpers properly when finished or abandoning.
+
     /* what connection is this associated with */
 //    ConnStateData * conn;
 
@@ -42,6 +42,7 @@
 #include "SwapDir.h"
 #include "ConfigParser.h"
 #include "acl/Acl.h"
+#include "acl/MethodData.h"
 #include "acl/Gadgets.h"
 #include "StoreFileSystem.h"
 #include "Parsing.h"
@@ -389,6 +390,7 @@ parseConfigFile(const char *file_name)
 
     configFreeMemory();
 
+    ACLMethodData::ThePurgeCount = 0;
     default_all();
 
     err_count = parseOneConfigFile(file_name, 0);
@@ -621,10 +623,9 @@ configDoConfigure(void)
 
 #endif
 
-    // we have reconfigured and in the process disabled any need for PURGE.
-    // turn it off now.
-    if(Config2.onoff.enable_purge == 2)
-        Config2.onoff.enable_purge = 0;
+    // we enable runtime PURGE checks if there is at least one PURGE method ACL
+    // TODO: replace with a dedicated "purge" ACL option?
+    Config2.onoff.enable_purge = (ACLMethodData::ThePurgeCount > 0);
 
     Config2.onoff.mangle_request_headers = httpReqHdrManglersConfigured();
 
@@ -2954,7 +2955,7 @@ parse_http_port_specification(http_port_list * s, char *token)
     if (NULL == host) {
         s->s.SetAnyAddr();
         s->s.SetPort(port);
-        debugs(3, 3, "http(s)_port: found Listen on wildcard address: " << s->s);
+        debugs(3, 3, "http(s)_port: found Listen on wildcard address: *:" << s->s.GetPort() );
     } else if ( s->s = host ) { /* check/parse numeric IPA */
         s->s.SetPort(port);
         debugs(3, 3, "http(s)_port: Listen on Host/IP: " << host << " --> " << s->s);
@@ -3136,10 +3137,64 @@ void
 add_http_port(char *portspec)
 {
     http_port_list *s = create_http_port(portspec);
+    // we may need to merge better of the above returns a list with clones
+    assert(s->next == NULL);
     s->next = Config.Sockaddr.http;
     Config.Sockaddr.http = s;
 }
 
+#if IPV6_SPECIAL_SPLITSTACK
+http_port_list *
+clone_http_port_list(http_port_list *a)
+{
+    http_port_list *b = new http_port_list(a->protocol);
+
+    b->s = a->s;
+    if (a->name)
+        b->name = xstrdup(a->name);
+    if (a->defaultsite)
+        b->defaultsite = xstrdup(a->defaultsite);
+
+    b->intercepted = a->intercepted;
+    b->spoof_client_ip = a->spoof_client_ip;
+    b->accel = a->accel;
+    b->allow_direct = a->allow_direct;
+    b->vhost = a->vhost;
+    b->sslBump = a->sslBump;
+    b->vport = a->vport;
+    b->connection_auth_disabled = a->connection_auth_disabled;
+    b->disable_pmtu_discovery = a->disable_pmtu_discovery;
+
+    memcpy( &(b->tcp_keepalive), &(a->tcp_keepalive), sizeof(a->tcp_keepalive));
+
+#if 0
+    // AYJ: 2009-07-18: for now SSL does not clone. Configure separate ports with IPs and SSL settings
+
+#if USE_SSL
+    // XXX: temporary hack to ease move of SSL options to http_port
+    http_port_list &http;
+
+    char *cert;
+    char *key;
+    int version;
+    char *cipher;
+    char *options;
+    char *clientca;
+    char *cafile;
+    char *capath;
+    char *crlfile;
+    char *dhfile;
+    char *sslflags;
+    char *sslcontext;
+    SSL_CTX *sslContext;
+#endif
+
+#endif /*0*/
+
+    return b;
+}
+#endif
+
 static void
 parse_http_port_list(http_port_list ** head)
 {
@@ -3157,6 +3212,15 @@ parse_http_port_list(http_port_list ** head)
         parse_http_port_option(s, token);
     }
 
+#if IPV6_SPECIAL_SPLITSTACK
+    if (s->s.IsAnyAddr()) {
+        // clone the port options from *s to *(s->next)
+        s->next = clone_http_port_list(s);
+        s->next->s.SetIPv4();
+        debugs(3, 3, "http(s)_port: clone wildcard address for split-stack: " << s->s << " and " << s->next->s);
+    }
+#endif
+
     while (*head)
         head = &(*head)->next;
 
@@ -519,11 +519,11 @@ DOC_START
 	acl aclname srcdomain   .foo.com ...
 	  # reverse lookup, from client IP [slow]
 	acl aclname dstdomain   .foo.com ...
-	  # Destination server from URL [slow]
+	  # Destination server from URL [fast]
 	acl aclname srcdom_regex [-i] \.foo\.com ...
 	  # regex matching client name [slow]
 	acl aclname dstdom_regex [-i] \.foo\.com ...
-	  # regex matching server [slow]
+	  # regex matching server [fast]
 	  #
 	  # For dstdomain and dstdom_regex a reverse lookup is tried if a IP
 	  # based URL is used and no match is found. The name "none" is used
@@ -1619,274 +1619,248 @@ DEFAULT: none
 LOC: Config.peers
 DOC_START
 	To specify other caches in a hierarchy, use the format:
-
+	
 		cache_peer hostname type http-port icp-port [options]
-
+	
 	For example,
-
+	
 	#                                        proxy  icp
 	#          hostname             type     port   port  options
 	#          -------------------- -------- ----- -----  -----------
-	cache_peer parent.foo.net       parent    3128  3130  proxy-only default
+	cache_peer parent.foo.net       parent    3128  3130  default
 	cache_peer sib1.foo.net         sibling   3128  3130  proxy-only
 	cache_peer sib2.foo.net         sibling   3128  3130  proxy-only
-
-	      type:  either 'parent', 'sibling', or 'multicast'.
-
-	proxy-port:  The port number where the cache listens for proxy
-		     requests.
-
-	  icp-port:  Used for querying neighbor caches about
-		     objects.  To have a non-ICP neighbor
-		     specify '0' for the ICP port.
-		NOTE: Also requires icp_port option enabled to send/receive
-		      requests via this method.
-
-	    options: proxy-only
-		     weight=n
-		     basetime=n
-		     ttl=n
-		     no-query
-		     background-ping
-		     default
-		     round-robin
-		     weighted-round-robin
-		     carp
-		     userhash
-		     sourcehash
-		     multicast-responder
-		     closest-only
-		     no-digest
-		     no-netdb-exchange
-		     no-delay
-		     login=user:password | PASS | *:password
-		     connect-timeout=nn
-		     connect-fail-limit=nn
-		     digest-url=url
-		     allow-miss
-		     max-conn=n
-		     htcp
-		     htcp-oldsquid
-		     htcp-no-clr
-		     htcp-no-purge-clr
-		     htcp-only-clr
-		     htcp-forward-clr
-		     originserver
-		     name=xxx
-		     forceddomain=name
-		     ssl
-		     sslcert=/path/to/ssl/certificate
-		     sslkey=/path/to/ssl/key
-		     sslversion=1|2|3|4
-		     sslcipher=...
-		     ssloptions=...
-		     front-end-https[=on|auto]
-		     connection-auth[=on|off|auto]
-
-		     use 'proxy-only' to specify objects fetched
-		     from this cache should not be saved locally.
-
-		     use 'weight=n' to affect the selection of a peer
-		     during any weighted peer-selection mechanisms.
-		     The weight must be an integer; default is 1,
-		     larger weights are favored more.
-		     This option does not affect parent selection if a peering
-		     protocol is not in use.
-
-		     use 'basetime=n' to specify a base amount to
-		     be subtracted from round trip times of parents.
-		     It is subtracted before division by weight in calculating
-		     which parent to fectch from. If the rtt is less than the
-		     base time the rtt is set to a minimal value.
-
-		     use 'ttl=n' to specify a IP multicast TTL to use
-		     when sending an ICP queries to this address.
-		     Only useful when sending to a multicast group.
-		     Because we don't accept ICP replies from random
-		     hosts, you must configure other group members as
-		     peers with the 'multicast-responder' option below.
-
-		     use 'no-query' to NOT send ICP queries to this
-		     neighbor.
-
-		     use 'background-ping' to only send ICP queries to this
-		     neighbor infrequently. This is used to keep the neighbor
-		     round trip time updated and is usually used in
-		     conjunction with weighted-round-robin.
-
-		     use 'default' if this is a parent cache which can
-		     be used as a "last-resort" if a peer cannot be located
-		     by any of the peer-selection mechanisms.
-		     If specified more than once, only the first is used.
-
-		     use 'round-robin' to define a set of parents which
-		     should be used in a round-robin fashion in the
-		     absence of any ICP queries.
-
-		     use 'weighted-round-robin' to define a set of parents
-		     which should be used in a round-robin fashion with the
-		     frequency of each parent being based on the round trip
-		     time. Closer parents are used more often.
-		     Usually used for background-ping parents.
-
-		     use 'carp' to define a set of parents which should
-		     be used as a CARP array. The requests will be
-		     distributed among the parents based on the CARP load
-		     balancing hash function based on their weight.
-
-		     use 'userhash' to load-balance amongst a set of parents
-		     based on the client proxy_auth or ident username.
-
-		     use 'sourcehash' to load-balance amongst a set of parents
-		     based on the client source ip.
-
-		     'multicast-responder' indicates the named peer
-		     is a member of a multicast group.  ICP queries will
-		     not be sent directly to the peer, but ICP replies
-		     will be accepted from it.
-
-		     'closest-only' indicates that, for ICP_OP_MISS
-		     replies, we'll only forward CLOSEST_PARENT_MISSes
-		     and never FIRST_PARENT_MISSes.
-
-		     use 'no-digest' to NOT request cache digests from
-		     this neighbor.
-
-		     'no-netdb-exchange' disables requesting ICMP
-		     RTT database (NetDB) from the neighbor.
-
-		     use 'no-delay' to prevent access to this neighbor
-		     from influencing the delay pools.
-
-		     use 'login=user:password' if this is a personal/workgroup
-		     proxy and your parent requires proxy authentication.
-		     Note: The string can include URL escapes (i.e. %20 for
-		     spaces). This also means % must be written as %%.
-
-		     use 'login=PASS' if users must authenticate against
-		     the upstream proxy or in the case of a reverse proxy
-		     configuration, the origin web server.  This will pass
-		     the users credentials as they are to the peer.
-		     This only works for the Basic HTTP authentication scheme.
-		     Note: To combine this with proxy_auth both proxies must
-		     share the same user database as HTTP only allows for
-		     a single login (one for proxy, one for origin server).
-		     Also be warned this will expose your users proxy
-		     password to the peer. USE WITH CAUTION
-
-		     use 'login=*:password' to pass the username to the
-		     upstream cache, but with a fixed password. This is meant
-		     to be used when the peer is in another administrative
-		     domain, but it is still needed to identify each user.
-		     The star can optionally be followed by some extra
-		     information which is added to the username. This can
-		     be used to identify this proxy to the peer, similar to
-		     the login=username:password option above.
-
-		     use 'connect-timeout=nn' to specify a peer
-		     specific connect timeout (also see the
-		     peer_connect_timeout directive)
-
-		     use 'connect-fail-limit=nn' to specify how many times
-		     connecting to a peer must fail before it is marked as
-		     down. Default is 10.
-
-		     use 'digest-url=url' to tell Squid to fetch the cache
-		     digest (if digests are enabled) for this host from
-		     the specified URL rather than the Squid default
-		     location.
-
-		     use 'allow-miss' to disable Squid's use of only-if-cached
-		     when forwarding requests to siblings. This is primarily
-		     useful when icp_hit_stale is used by the sibling. To
-		     extensive use of this option may result in forwarding
-		     loops, and you should avoid having two-way peerings
-		     with this option. (for example to deny peer usage on
-		     requests from peer by denying cache_peer_access if the
-		     source is a peer)
-
-		     use 'max-conn=n' to limit the amount of connections Squid
-		     may open to this peer.
-
-		     use 'htcp' to send HTCP, instead of ICP, queries
-		     to the neighbor.  You probably also want to
-		     set the "icp port" to 4827 instead of 3130.
-		     You MUST also set htcp_access expicitly. The default of
-		     deny all will prevent peer traffic.
-
-		     use 'htcp-oldsquid' to send HTCP to old Squid versions
-		     You MUST also set htcp_access expicitly. The default of
-		     deny all will prevent peer traffic.		     
-
-		     use 'htcp-no-clr' to send HTCP to the neighbor but without
-		     sending any CLR requests.  This cannot be used with
-		     htcp-only-clr.
-		
-		     use 'htcp-no-purge-clr' to send HTCP to the neighbor
-		     including CLRs but only when they do not result from
-		     PURGE requests.
-		
-		     use 'htcp-only-clr' to send HTCP to the neighbor but ONLY
-		     CLR requests.  This cannot be used with htcp-no-clr.
-		
-		     use 'htcp-forward-clr' to forward any HTCP CLR requests
-		     this proxy receives to the peer.
-
-		     'originserver' causes this parent peer to be contacted as
-		     a origin server. Meant to be used in accelerator setups.
-
-		     use 'name=xxx' if you have multiple peers on the same
-		     host but different ports. This name can be used to
-		     differentiate the peers in cache_peer_access and similar
-		     directives. Including the peername ACL type.
-
-		     use 'forceddomain=name' to forcibly set the Host header
-		     of requests forwarded to this peer. Useful in accelerator
-		     setups where the server (peer) expects a certain domain
-		     name and using redirectors to feed this domain name
-		     is not feasible.
-
-		     use 'ssl' to indicate connections to this peer should
-		     be SSL/TLS encrypted.
-
-		     use 'sslcert=/path/to/ssl/certificate' to specify a client
-		     SSL certificate to use when connecting to this peer.
-
-		     use 'sslkey=/path/to/ssl/key' to specify the private SSL
-		     key corresponding to sslcert above. If 'sslkey' is not
-		     specified 'sslcert' is assumed to reference a
-		     combined file containing both the certificate and the key.
-
-		     use sslversion=1|2|3|4 to specify the SSL version to use
-		     when connecting to this peer
-			1 = automatic (default)
-			2 = SSL v2 only
-			3 = SSL v3 only
-			4 = TLS v1 only
-
-		     use sslcipher=... to specify the list of valid SSL ciphers
-		     to use when connecting to this peer.
-
-		     use ssloptions=... to specify various SSL engine options:
-			NO_SSLv2  Disallow the use of SSLv2
-			NO_SSLv3  Disallow the use of SSLv3
-			NO_TLSv1  Disallow the use of TLSv1
-		     See src/ssl_support.c or the OpenSSL documentation for
-		     a more complete list.
-
-		     use sslcafile=... to specify a file containing
-		     additional CA certificates to use when verifying the
-		     peer certificate.
-
-		     use sslcapath=... to specify a directory containing
-		     additional CA certificates to use when verifying the
-		     peer certificate.
-
-		     use sslcrlfile=... to specify a certificate revocation
-		     list file to use when verifying the peer certificate.
-		     
-		     use sslflags=... to specify various flags modifying the
-		     SSL implementation:
+	cache_peer example.com          parent    80       0  no-query default
+	cache_peer cdn.example.com      sibling   3128     0  
+	
+	      type:	either 'parent', 'sibling', or 'multicast'.
+	
+	proxy-port:	The port number where the peer accept HTTP requests.
+			For other Squid proxies this is usually 3128
+			For web servers this is usually 80
+	
+	  icp-port:	Used for querying neighbor caches about objects.
+			Set to 0 if the peer does not support ICP or HTCP.
+			See ICP and HTCP options below for additional details.
+	
+	
+	==== ICP OPTIONS ====
+	
+	You MUST also set icp_port and icp_access explicitly when using these options.
+	The defaults will prevent peer traffic using ICP.
+	
+	
+	no-query	Disable ICP queries to this neighbor.
+	
+	multicast-responder
+			Indicates the named peer is a member of a multicast group.
+			ICP queries will not be sent directly to the peer, but ICP
+			replies will be accepted from it.
+	
+	closest-only	Indicates that, for ICP_OP_MISS replies, we'll only forward
+			CLOSEST_PARENT_MISSes and never FIRST_PARENT_MISSes.
+	
+	background-ping
+			To only send ICP queries to this neighbor infrequently.
+			This is used to keep the neighbor round trip time updated
+			and is usually used in conjunction with weighted-round-robin.
+	
+	
+	==== HTCP OPTIONS ====
+	
+	You MUST also set htcp_port and htcp_access explicitly when using these options.
+	The defaults will prevent peer traffic using HTCP.
+	
+	
+	htcp		Send HTCP, instead of ICP, queries to the neighbor.
+			You probably also want to set the "icp-port" to 4827
+			instead of 3130.
+	
+	htcp-oldsquid	Send HTCP to old Squid versions.
+	
+	htcp-no-clr	Send HTCP to the neighbor but without
+			sending any CLR requests.  This cannot be used with
+			htcp-only-clr.
+	
+	htcp-only-clr	Send HTCP to the neighbor but ONLY CLR requests.
+			This cannot be used with htcp-no-clr.
+	
+	htcp-no-purge-clr
+			Send HTCP to the neighbor including CLRs but only when
+			they do not result from PURGE requests.
+	
+	htcp-forward-clr
+			Forward any HTCP CLR requests this proxy receives to the peer.
+	
+	
+	==== PEER SELECTION METHODS ====
+	
+	The default peer selection method is ICP, with the first responding peer
+	being used as source. These options can be used for better load balancing.
+	
+	
+	default		This is a parent cache which can be used as a "last-resort"
+			if a peer cannot be located by any of the peer-selection methods.
+			If specified more than once, only the first is used.
+	
+	round-robin	Load-Balance parents which should be used in a round-robin
+			fashion in the absence of any ICP queries.
+			weight=N can be used to add bias.
+	
+	weighted-round-robin
+			Load-Balance parents which should be used in a round-robin
+			fashion with the frequency of each parent being based on the
+			round trip time. Closer parents are used more often.
+			Usually used for background-ping parents.
+			weight=N can be used to add bias.
+	
+	carp		Load-Balance parents which should be used as a CARP array.
+			The requests will be distributed among the parents based on the
+			CARP load balancing hash function based on their weight.
+	
+	userhash	Load-balance parents based on the client proxy_auth or ident username.
+	
+	sourcehash	Load-balance parents based on the client source IP.
+	
+	
+	==== PEER SELECTION OPTIONS ====
+	
+	weight=N	use to affect the selection of a peer during any weighted
+			peer-selection mechanisms.
+			The weight must be an integer; default is 1,
+			larger weights are favored more.
+			This option does not affect parent selection if a peering
+			protocol is not in use.
+	
+	basetime=N	Specify a base amount to be subtracted from round trip
+			times of parents.
+			It is subtracted before division by weight in calculating
+			which parent to fectch from. If the rtt is less than the
+			base time the rtt is set to a minimal value.
+	
+	ttl=N		Specify a IP multicast TTL to use when sending an ICP
+			queries to this address.
+			Only useful when sending to a multicast group.
+			Because we don't accept ICP replies from random
+			hosts, you must configure other group members as
+			peers with the 'multicast-responder' option.
+	
+	no-delay	To prevent access to this neighbor from influencing the
+			delay pools.
+	
+	digest-url=URL	Tell Squid to fetch the cache digest (if digests are
+			enabled) for this host from the specified URL rather
+			than the Squid default location.
+	
+	
+	==== ACCELERATOR / REVERSE-PROXY OPTIONS ====
+	
+	originserver	Causes this parent to be contacted as an origin server.
+			Meant to be used in accelerator setups when the peer
+			is a web server.
+	
+	forceddomain=name
+			Set the Host header of requests forwarded to this peer.
+			Useful in accelerator setups where the server (peer)
+			expects a certain domain name but clients may request
+			others. ie example.com or www.example.com
+	
+	no-digest	Disable request of cache digests.
+	
+	no-netdb-exchange
+			Disables requesting ICMP RTT database (NetDB).
+	
+	
+	==== AUTHENTICATION OPTIONS ====
+	
+	login=user:password
+			If this is a personal/workgroup proxy and your parent
+			requires proxy authentication.
+			
+			Note: The string can include URL escapes (i.e. %20 for
+			spaces). This also means % must be written as %%.
+	
+	login=PROXYPASS
+			Send login details received from client to this peer.
+			Authentication is not required, nor changed.
+			
+			Note: This will pass any form of authentication but
+			only Basic auth will work through a proxy unless the
+			connection-auth options are also used.
+	
+	login=PASS	Send login details received from client to this peer.
+			Authentication is not required by this option.
+			If there are no client-provided authentication headers
+			to pass on, but username and password are available
+			from either proxy login or an external ACL user= and
+			password= result tags they may be sent instead.
+			
+			Note: To combine this with proxy_auth both proxies must
+			share the same user database as HTTP only allows for
+			a single login (one for proxy, one for origin server).
+			Also be warned this will expose your users proxy
+			password to the peer. USE WITH CAUTION
+	
+	login=*:password
+			Send the username to the upstream cache, but with a
+			fixed password. This is meant to be used when the peer
+			is in another administrative domain, but it is still
+			needed to identify each user.
+			The star can optionally be followed by some extra
+			information which is added to the username. This can
+			be used to identify this proxy to the peer, similar to
+			the login=username:password option above.
+	
+	connection-auth=on|off
+			Tell Squid that this peer does or not support Microsoft
+			connection oriented authentication, and any such
+			challenges received from there should be ignored.
+			Default is auto to automatically determine the status
+			of the peer.
+	
+	
+	==== SSL / HTTPS / TLS OPTIONS ====
+	
+	ssl		Encrypt connections to this peer with SSL/TLS.
+	
+	sslcert=/path/to/ssl/certificate
+			A client SSL certificate to use when connecting to
+			this peer.
+	
+	sslkey=/path/to/ssl/key
+			The private SSL key corresponding to sslcert above.
+			If 'sslkey' is not specified 'sslcert' is assumed to
+			reference a combined file containing both the
+			certificate and the key.
+	
+	sslversion=1|2|3|4
+			The SSL version to use when connecting to this peer
+				1 = automatic (default)
+				2 = SSL v2 only
+				3 = SSL v3 only
+				4 = TLS v1 only
+	
+	sslcipher=...	The list of valid SSL ciphers to use when connecting
+			to this peer.
+	
+	ssloptions=... 	Specify various SSL engine options:
+				NO_SSLv2  Disallow the use of SSLv2
+				NO_SSLv3  Disallow the use of SSLv3
+				NO_TLSv1  Disallow the use of TLSv1
+			See src/ssl_support.c or the OpenSSL documentation for
+			a more complete list.
+	
+	sslcafile=... 	A file containing additional CA certificates to use
+			when verifying the peer certificate.
+	
+	sslcapath=...	A directory containing additional CA certificates to
+			use when verifying the peer certificate.
+	
+	sslcrlfile=... 	A certificate revocation list file to use when
+			verifying the peer certificate.
+	
+	sslflags=...	Specify various flags modifying the SSL implementation:
+	
 			DONT_VERIFY_PEER
 				Accept certificates even if they fail to
 				verify.
@@ -1896,24 +1870,51 @@ DOC_START
 			DONT_VERIFY_DOMAIN
 				Don't verify the peer certificate
 				matches the server name
-
-		     use ssldomain= to specify the peer name as advertised
-		     in it's certificate. Used for verifying the correctness
-		     of the received peer certificate. If not specified the
-		     peer hostname will be used.
-
-		     use front-end-https to enable the "Front-End-Https: On"
-		     header needed when using Squid as a SSL frontend in front
-		     of Microsoft OWA. See MS KB document Q307347 for details
-		     on this header. If set to auto the header will
-		     only be added if the request is forwarded as a https://
-		     URL.
-
-		     use connection-auth=off to tell Squid that this peer does
-		     not support Microsoft connection oriented authentication,
-		     and any such challenges received from there should be
-		     ignored. Default is auto to automatically determine the
-		     status of the peer.
+	
+	ssldomain= 	The peer name as advertised in it's certificate.
+			Used for verifying the correctness of the received peer
+			certificate. If not specified the peer hostname will be
+			used.
+	
+	front-end-https
+			Enable the "Front-End-Https: On" header needed when
+			using Squid as a SSL frontend in front of Microsoft OWA.
+			See MS KB document Q307347 for details on this header.
+			If set to auto the header will only be added if the
+			request is forwarded as a https:// URL.
+	
+	
+	==== GENERAL OPTIONS ====
+	
+	connect-timeout=N
+			A peer-specific connect timeout.
+			Also see the peer_connect_timeout directive.
+	
+	connect-fail-limit=N
+			How many times connecting to a peer must fail before
+			it is marked as down. Default is 10.
+	
+	allow-miss	Disable Squid's use of only-if-cached when forwarding
+			requests to siblings. This is primarily useful when
+			icp_hit_stale is used by the sibling. To extensive use
+			of this option may result in forwarding loops, and you
+			should avoid having two-way peerings with this option.
+			For example to deny peer usage on requests from peer
+			by denying cache_peer_access if the source is a peer.
+	
+	max-conn=N	Limit the amount of connections Squid may open to this
+			peer. see also 
+	
+	name=xxx	Unique name for the peer.
+			Required if you have multiple peers on the same host
+			but different ports.
+			This name can be used in cache_peer_access and similar
+			directives to dentify the peer.
+			Can be used by outgoing access controls through the
+			peername ACL type.
+	
+	proxy-only	objects fetched from the peer will not be stored locally.
+	
 DOC_END
 
 NAME: cache_peer_domain cache_host_domain
@@ -1931,6 +1931,17 @@ parseHttpRequest(ConnStateData *conn, HttpParser *hp, HttpRequestMethod * method
     /* pre-set these values to make aborting simpler */
     *method_p = METHOD_NONE;
 
+    /* NP: don't be tempted to move this down or remove again.
+     * It's the only DDoS protection old-String has against long URL */
+    if ( hp->bufsiz <= 0) {
+        debugs(33, 5, "Incomplete request, waiting for end of request line");
+        return NULL;
+    }
+    else if ( (size_t)hp->bufsiz >= Config.maxRequestHeaderSize && headersEnd(hp->buf, Config.maxRequestHeaderSize) == 0) {
+        debugs(33, 5, "parseHttpRequest: Too large request");
+        return parseHttpRequestAbort(conn, "error:request-too-large");
+    }
+
     /* Attempt to parse the first line; this'll define the method, url, version and header begin */
     r = HttpParserParseReqLine(hp);
 
@@ -2222,7 +2233,7 @@ connKeepReadingIncompleteRequest(ConnStateData * conn)
     // when we read chunked requests, the entire body is buffered
     // XXX: this check ignores header size and its limits.
     if (conn->in.dechunkingState == ConnStateData::chunkParsing)
-        return conn->in.notYetUsed < Config.maxChunkedRequestBodySize;
+        return ((int64_t)conn->in.notYetUsed) < Config.maxChunkedRequestBodySize;
 
     return conn->in.notYetUsed >= Config.maxRequestHeaderSize ? 0 : 1;
 }
@@ -1403,7 +1403,7 @@ clientReplyContext::buildReplyHeader()
         LOCAL_ARRAY(char, bbuf, MAX_URL + 32);
         String strVia;
         hdr->getList(HDR_VIA, &strVia);
-        snprintf(bbuf, sizeof(bbuf), "%d.%d %s",
+        snprintf(bbuf, MAX_URL + 32, "%d.%d %s",
                  reply->sline.version.major,
                  reply->sline.version.minor,
                  ThisCache);
@@ -1768,6 +1768,7 @@ clientReplyContext::sendBodyTooLargeError()
 {
     IpAddress tmp_noaddr;
     tmp_noaddr.SetNoAddr(); // TODO: make a global const
+    http->logType = LOG_TCP_DENIED_REPLY;
     ErrorState *err = clientBuildError(ERR_TOO_BIG, HTTP_FORBIDDEN, NULL,
                                        http->getConn() != NULL ? http->getConn()->peer : tmp_noaddr,
                                        http->request);
@@ -662,7 +662,7 @@ comm_set_v6only(int fd, int tos)
 {
 #ifdef IPV6_V6ONLY
     if (setsockopt(fd, IPPROTO_IPV6, IPV6_V6ONLY, (char *) &tos, sizeof(int)) < 0) {
-        debugs(50, 1, "comm_open: setsockopt(IPV6_V6ONLY) on FD " << fd << ": " << xstrerror());
+        debugs(50, 1, "comm_open: setsockopt(IPV6_V6ONLY) " << (tos?"ON":"OFF") << " for FD " << fd << ": " << xstrerror());
     }
 #else
     debugs(50, 0, "WARNING: comm_open: setsockopt(IPV6_V6ONLY) not supported on this platform");
@@ -744,7 +744,7 @@ comm_openex(int sock_type,
 #if IPV6_SPECIAL_SPLITSTACK
 
     if ( addr.IsIPv6() )
-        comm_set_v6only(new_socket, tos);
+        comm_set_v6only(new_socket, 1);
 
 #endif
 
@@ -1037,10 +1037,8 @@ ConnectStateData::commResetFD()
         comm_set_tos(fd, F->tos);
 
 #if IPV6_SPECIAL_SPLITSTACK
-
     if ( F->local_addr.IsIPv6() )
-        comm_set_v6only(fd, F->tos);
-
+        comm_set_v6only(fd, 1);
 #endif
 
     copyFDFlags(fd, F);
@@ -346,7 +346,7 @@ idnsParseResolvConf(void)
                 if (NULL == t)
                     continue;
 
-                if (strncmp(t, "ndots:", 6) != 0) {
+                if (strncmp(t, "ndots:", 6) == 0) {
                     ndots = atoi(t + 6);
 
                     if (ndots < 1)
@@ -1366,22 +1366,29 @@ idnsInit(void)
         else
             addr = Config.Addrs.udp_incoming;
 
-        debugs(78, 2, "idnsInit: attempt open DNS socket to: " << addr);
 #if IPV6_SPECIAL_SPLITSTACK
-        if ( addr.IsAnyAddr() || addr.IsIPv6() )
+        IpAddress addr4 = addr;
+
+        if ( addr.IsAnyAddr() || addr.IsIPv6() ) {
+            debugs(78, 2, "idnsInit: attempt open DNS socket to: " << addr);
             DnsSocketB = comm_open_listener(SOCK_DGRAM,
                                             IPPROTO_UDP,
                                             addr,
                                             COMM_NONBLOCKING,
                                             "DNS Socket v6");
+        }
 
-        if ( addr.IsAnyAddr() || addr.IsIPv4() )
+        if ( addr.IsAnyAddr() || addr.IsIPv4() ) {
+            addr4.SetIPv4();
+            debugs(78, 2, "idnsInit: attempt open DNS socket to: " << addr4);
             DnsSocketA = comm_open_listener(SOCK_DGRAM,
                                             IPPROTO_UDP,
-                                            addr,
+                                            addr4,
                                             COMM_NONBLOCKING,
                                             "DNS Socket v4");
+        }
 #else
+        debugs(78, 2, "idnsInit: attempt open DNS socket to: " << addr);
         DnsSocketA = comm_open_listener(SOCK_DGRAM,
                                         IPPROTO_UDP,
                                         addr,
@@ -1403,7 +1410,11 @@ idnsInit(void)
 #endif
         if (DnsSocketA >= 0) {
             port = comm_local_port(DnsSocketA);
+#if IPV6_SPECIAL_SPLITSTACK
+            debugs(78, 1, "DNS Socket created at " << addr4 << ", FD " << DnsSocketA);
+#else
             debugs(78, 1, "DNS Socket created at " << addr << ", FD " << DnsSocketA);
+#endif
         }
     }
 
@@ -216,22 +216,22 @@ typedef enum _mem_status_t {
     IN_MEMORY
 } mem_status_t;
 
-enum {
+typedef enum {
     PING_NONE,
     PING_WAITING,
     PING_DONE
-};
+} ping_status_t;
 
-enum {
+typedef enum {
     STORE_OK,
     STORE_PENDING
-};
+} store_status_t;
 
-enum {
+typedef enum {
     SWAPOUT_NONE,
     SWAPOUT_WRITING,
     SWAPOUT_DONE
-};
+} swap_status_t;
 
 typedef enum {
     STORE_NON_CLIENT,
@@ -370,18 +370,9 @@ typedef enum {
 typedef enum {
     S_HELPER_UNKNOWN,
     S_HELPER_RESERVE,
-    S_HELPER_RELEASE,
-    S_HELPER_DEFER
+    S_HELPER_RELEASE
 } stateful_helper_callback_t;
 
-/* stateful helper reservation info */
-typedef enum {
-    S_HELPER_FREE,		/* available for requests */
-    S_HELPER_RESERVED,		/* in a reserved state - no active request, but state data in the helper shouldn't be disturbed */
-    S_HELPER_DEFERRED		/* available for requests, and at least one more will come from a previous caller with the server pointer */
-} stateful_helper_reserve_t;
-
-
 #if SQUID_SNMP
 enum {
     SNMP_C_VIEW,
@@ -955,24 +955,53 @@ ErrorState::BuildContent()
 
         while ( pos < hdr.size() ) {
 
+            /* skip any initial whitespace. */
+            while (pos < hdr.size() && xisspace(hdr[pos])) pos++;
+
             /*
              * Header value format:
              *  - sequence of whitespace delimited tags
              *  - each tag may suffix with ';'.* which we can ignore.
              *  - IFF a tag contains only two characters we can wildcard ANY translations matching: <it> '-'? .*
              *    with preference given to an exact match.
              */
+            bool invalid_byte = false;
             while (pos < hdr.size() && hdr[pos] != ';' && hdr[pos] != ',' && !xisspace(hdr[pos]) && dt < (dir+256) ) {
-                *dt++ = xtolower(hdr[pos++]);
+                if (!invalid_byte) {
+#if HTTP_VIOLATIONS
+                    // if accepting violations we may as well accept some broken browsers
+                    //  which may send us the right code, wrong ISO formatting.
+                    if (hdr[pos] == '_')
+                        *dt = '-';
+                    else
+#endif
+                    *dt = xtolower(hdr[pos]);
+                    // valid codes only contain A-Z, hyphen (-) and *
+                    if (*dt != '-' && *dt != '*' && (*dt < 'a' || *dt > 'z') )
+                        invalid_byte = true;
+                    else
+                        dt++; // move to next destination byte.
+                }
+                pos++;
             }
             *dt++ = '\0'; // nul-terminated the filename content string before system use.
 
-            debugs(4, 9, HERE << "STATE: dt='" << dt << "', reset='" << reset << "', reset[1]='" << reset[1] << "', pos=" << pos << ", buf='" << hdr.substr(pos,hdr.size()) << "'");
+            debugs(4, 9, HERE << "STATE: dt='" << dt << "', reset='" << reset << "', pos=" << pos << ", buf='" << ((pos < hdr.size()) ? hdr.substr(pos,hdr.size()) : "") << "'");
 
             /* if we found anything we might use, try it. */
-            if (*reset != '\0') {
+            if (*reset != '\0' && !invalid_byte) {
+
+                /* wildcard uses the configured default language */
+                if (reset[0] == '*' && reset[1] == '\0') {
+                    debugs(4, 6, HERE << "Found language '" << reset << "'. Using configured default.");
+                    m = error_text[page_id];
+                    if (!Config.errorDirectory)
+                        err_language = Config.errorDefaultLanguage;
+                    break;
+                }
 
                 debugs(4, 6, HERE << "Found language '" << reset << "', testing for available template in: '" << dir << "'");
+
                 m = errorTryLoadText( err_type_str[page_id], dir, false);
 
                 if (m) {
@@ -994,7 +1023,7 @@ ErrorState::BuildContent()
 
             dt = reset; // reset for next tag testing. we replace the failed name instead of cloning.
 
-            // IFF we terminated the tag on ';' we need to skip the 'q=' bit to the next ',' or end.
+            // IFF we terminated the tag on whitespace or ';' we need to skip to the next ',' or end of header.
             while (pos < hdr.size() && hdr[pos] != ',') pos++;
             if (hdr[pos] == ',') pos++;
         }
@@ -363,17 +363,10 @@ UFSStoreState::writeCompleted(int errflag, size_t len, RefCount<WriteRequest> wr
     }
 
     /*
-     * DPW 2007-04-12
-     * I'm seeing disk files remain open under vanilla UFS storage
-     * because storeClose() gets called before the last write is
-     * complete.  I guess we have to check for the try_closing
-     * flag here.
+     * HNO 2009-07-24
+     * Kick any pending write/close operations alive
      */
-    if (flags.try_closing) {
-        debugs(72, 2, HERE << "UFSStoreState::writeCompleted" <<
-               " flags.try_closing is set");
-        tryClosing();
-    }
+    drainWriteQueue();
 }
 
 void
@@ -532,9 +532,11 @@ FtpStateData::~FtpStateData()
  * Produces filled member varisbles user, password, password_url if anything found.
  */
 void
-FtpStateData::loginParser(const char *login, int escaped)
+FtpStateData::loginParser(const char *login_, int escaped)
 {
+    char *login = xstrdup(login_);
     char *s = NULL;
+
     debugs(9, 4, HERE << ": login='" << login << "', escaped=" << escaped);
     debugs(9, 9, HERE << ": IN : login='" << login << "', escaped=" << escaped << ", user=" << user << ", password=" << password);
 
@@ -564,6 +566,7 @@ FtpStateData::loginParser(const char *login, int escaped)
     }
 
     debugs(9, 9, HERE << ": OUT: login='" << login << "', escaped=" << escaped << ", user=" << user << ", password=" << password);
+    safe_free(login);
 }
 
 void
@@ -2447,9 +2450,13 @@ ftpReadEPSV(FtpStateData* ftpState)
         /* server response with list of supported methods   */
         /*   522 Network protocol not supported, use (1)    */
         /*   522 Network protocol not supported, use (1,2)  */
+        /* TODO: handle the (1,2) case. We might get it back after EPSV ALL 
+         * which means close data + control without self-destructing and re-open from scratch. */
         debugs(9, 5, HERE << "scanning: " << ftpState->ctrl.last_reply);
+        buf = ftpState->ctrl.last_reply;
+        while (buf != NULL && *buf != '\0' && *buf != '\n' && *buf != '(') ++buf;
+        if (buf != NULL && *buf == '\n') ++buf;
 
-        buf = ftpState->ctrl.last_reply + strcspn(ftpState->ctrl.last_reply, "(1,2)");
         if (buf == NULL || *buf == '\0') {
             /* handle broken server (RFC 2428 says MUST specify supported protocols in 522) */
             debugs(9, DBG_IMPORTANT, "Broken FTP Server at " << fd_table[ftpState->ctrl.fd].ipaddr << ". 522 error missing protocol negotiation hints");
@@ -2473,6 +2480,11 @@ ftpReadEPSV(FtpStateData* ftpState)
             ftpSendPassive(ftpState);
 #endif
         }
+        else {
+            /* handle broken server (RFC 2428 says MUST specify supported protocols in 522) */
+            debugs(9, DBG_IMPORTANT, "WARNING: Server at " << fd_table[ftpState->ctrl.fd].ipaddr << " sent unknown protocol negotiation hint: " << buf);
+            ftpSendPassive(ftpState);
+        }
         return;
     }
 
@@ -2588,49 +2600,42 @@ ftpSendPassive(FtpStateData * ftpState)
     }
 
     addr = *AI;
-
     addr.FreeAddrInfo(AI);
 
-    /** Otherwise, Open data channel with the same local address as control channel (on a new random port!) */
-    addr.SetPort(0);
-    int fd = comm_open(SOCK_STREAM,
-                       IPPROTO_TCP,
-                       addr,
-                       COMM_NONBLOCKING,
-                       ftpState->entry->url());
-
-    debugs(9, 3, HERE << "Unconnected data socket created on FD " << fd << " to " << addr);
-
-    if (fd < 0) {
-        ftpFail(ftpState);
-        return;
-    }
-
-    ftpState->data.opened(fd, ftpState->dataCloser());
-
     /** \par
       * Send EPSV (ALL,2,1) or PASV on the control channel.
       *
       *  - EPSV ALL  is used if enabled.
-      *  - EPSV 2    is used if ALL is disabled and IPv6 is available.
-      *  - EPSV 1    is used if EPSV 2 (IPv6) fails or is not available.
+      *  - EPSV 2    is used if ALL is disabled and IPv6 is available and ctrl channel is IPv6.
+      *  - EPSV 1    is used if EPSV 2 (IPv6) fails or is not available or ctrl channel is IPv4.
       *  - PASV      is used if EPSV 1 fails.
       */
     switch (ftpState->state) {
-    case SENT_EPSV_1: /* EPSV options exhausted. Try PASV now. */
-        snprintf(cbuf, 1024, "PASV\r\n");
-        ftpState->state = SENT_PASV;
-        break;
+    case SENT_EPSV_ALL: /* EPSV ALL resulted in a bad response. Try ther EPSV methods. */
+        ftpState->flags.epsv_all_sent = true;
+        if (addr.IsIPv6()) {
+            snprintf(cbuf, 1024, "EPSV 2\r\n");
+            ftpState->state = SENT_EPSV_2;
+            break;
+        }
+        // else fall through to skip EPSV 2
 
     case SENT_EPSV_2: /* EPSV IPv6 failed. Try EPSV IPv4 */
-        snprintf(cbuf, 1024, "EPSV 1\r\n");
-        ftpState->state = SENT_EPSV_1;
-        break;
+        if (addr.IsIPv4()) {
+            snprintf(cbuf, 1024, "EPSV 1\r\n");
+            ftpState->state = SENT_EPSV_1;
+            break;
+        }
+        else if (ftpState->flags.epsv_all_sent) {
+            debugs(9, DBG_IMPORTANT, "FTP does not allow PASV method after 'EPSV ALL' has been sent.");
+            ftpFail(ftpState);
+            return;
+        }
+        // else fall through to skip EPSV 1
 
-    case SENT_EPSV_ALL: /* EPSV ALL resulted in a bad response. Try ther EPSV methods. */
-        ftpState->flags.epsv_all_sent = true;
-        snprintf(cbuf, 1024, "EPSV 2\r\n");
-        ftpState->state = SENT_EPSV_2;
+    case SENT_EPSV_1: /* EPSV options exhausted. Try PASV now. */
+        snprintf(cbuf, 1024, "PASV\r\n");
+        ftpState->state = SENT_PASV;
         break;
 
     default:
@@ -2654,6 +2659,22 @@ ftpSendPassive(FtpStateData * ftpState)
         break;
     }
 
+    /** Otherwise, Open data channel with the same local address as control channel (on a new random port!) */
+    addr.SetPort(0);
+    int fd = comm_open(SOCK_STREAM,
+                       IPPROTO_TCP,
+                       addr,
+                       COMM_NONBLOCKING,
+                       ftpState->entry->url());
+
+    debugs(9, 3, HERE << "Unconnected data socket created on FD " << fd << " to " << addr);
+
+    if (fd < 0) {
+        ftpFail(ftpState);
+        return;
+    }
+
+    ftpState->data.opened(fd, ftpState->dataCloser());
     ftpState->writeCommand(cbuf);
 
     /*
@@ -60,12 +60,10 @@ static void helperDispatch(helper_server * srv, helper_request * r);
 static void helperStatefulDispatch(helper_stateful_server * srv, helper_stateful_request * r);
 static void helperKickQueue(helper * hlp);
 static void helperStatefulKickQueue(statefulhelper * hlp);
+static void helperStatefulServerDone(helper_stateful_server * srv);
 static void helperRequestFree(helper_request * r);
 static void helperStatefulRequestFree(helper_stateful_request * r);
 static void StatefulEnqueue(statefulhelper * hlp, helper_stateful_request * r);
-static helper_stateful_request *StatefulServerDequeue(helper_stateful_server * srv);
-static void StatefulServerEnqueue(helper_stateful_server * srv, helper_stateful_request * r);
-static void helperStatefulServerKickQueue(helper_stateful_server * srv);
 static bool helperStartStats(StoreEntry *sentry, void *hlp, const char *label);
 
 
@@ -256,10 +254,7 @@ helperStatefulOpenServers(statefulhelper * hlp)
         helper_stateful_server *srv = cbdataAlloc(helper_stateful_server);
         srv->hIpc = hIpc;
         srv->pid = pid;
-        srv->flags.reserved = S_HELPER_FREE;
-        srv->deferred_requests = 0;
-        srv->stats.deferbyfunc = 0;
-        srv->stats.deferbycb = 0;
+        srv->flags.reserved = 0;
         srv->stats.submits = 0;
         srv->stats.releases = 0;
         srv->index = k;
@@ -326,10 +321,7 @@ helperSubmit(helper * hlp, const char *buf, HLPCB * callback, void *data)
     debugs(84, 9, "helperSubmit: " << buf);
 }
 
-/**
- * lastserver = "server last used as part of a deferred or reserved
- * request sequence"
- */
+/// lastserver = "server last used as part of a reserved request sequence"
 void
 helperStatefulSubmit(statefulhelper * hlp, const char *buf, HLPSCB * callback, void *data, helper_stateful_server * lastserver)
 {
@@ -354,28 +346,11 @@ helperStatefulSubmit(statefulhelper * hlp, const char *buf, HLPSCB * callback, v
 
     if ((buf != NULL) && lastserver) {
         debugs(84, 5, "StatefulSubmit with lastserver " << lastserver);
-        /* the queue doesn't count for this assert because queued requests
-         * have already gone through here and been tested.
-         * It's legal to have deferred_requests == 0 and queue entries
-         * and status of S_HELPEER_DEFERRED.
-         * BUT:  It's not legal to submit a new request w/lastserver in
-         * that state.
-         */
-        assert(!(lastserver->deferred_requests == 0 &&
-                 lastserver->flags.reserved == S_HELPER_DEFERRED));
-
-        if (lastserver->flags.reserved != S_HELPER_RESERVED) {
-            lastserver->stats.submits++;
-            lastserver->deferred_requests--;
-        }
+        assert(lastserver->flags.reserved);
+        assert(!(lastserver->request));
 
-        if (!(lastserver->request)) {
-            debugs(84, 5, "StatefulSubmit dispatching");
-            helperStatefulDispatch(lastserver, r);
-        } else {
-            debugs(84, 5, "StatefulSubmit queuing");
-            StatefulServerEnqueue(lastserver, r);
-        }
+        debugs(84, 5, "StatefulSubmit dispatching");
+        helperStatefulDispatch(lastserver, r);
     } else {
         helper_stateful_server *srv;
         if ((srv = StatefulGetFirstAvailable(hlp))) {
@@ -387,148 +362,26 @@ helperStatefulSubmit(statefulhelper * hlp, const char *buf, HLPSCB * callback, v
     debugs(84, 9, "helperStatefulSubmit: placeholder: '" << r->placeholder << "', buf '" << buf << "'.");
 }
 
-/**
- * find an available helper and add a deferred request to it
- */
-helper_stateful_server *
-helperStatefulDefer(statefulhelper * hlp)
-{
-    if (hlp == NULL) {
-        debugs(84, 3, "helperStatefulDefer: hlp == NULL");
-        return NULL;
-    }
-
-    debugs(84, 5, "helperStatefulDefer: Running servers " << hlp->n_running);
-
-    if (hlp->n_running == 0) {
-        debugs(84, 1, "helperStatefulDefer: No running servers!. ");
-        return NULL;
-    }
-
-    helper_stateful_server *rv = StatefulGetFirstAvailable(hlp);
-
-    if (rv == NULL) {
-        /*
-         * all currently busy; loop through servers and find server
-         * with the shortest queue
-         */
-
-        for (dlink_node *n = hlp->servers.head; n != NULL; n = n->next) {
-            helper_stateful_server *srv = (helper_stateful_server *)n->data;
-
-            if (srv->flags.reserved == S_HELPER_RESERVED)
-                continue;
-
-            if (!srv->flags.shutdown)
-                continue;
-
-            if ((hlp->IsAvailable != NULL) && (srv->data != NULL) &&
-                    !(hlp->IsAvailable(srv->data)))
-                continue;
-
-            if ((rv != NULL) && (rv->deferred_requests < srv->deferred_requests))
-                continue;
-
-            rv = srv;
-        }
-    }
-
-    if (rv == NULL) {
-        debugs(84, 1, "helperStatefulDefer: None available.");
-        return NULL;
-    }
-
-    /* consistency check:
-     * when the deferred count is 0,
-     *   submits + releases == deferbyfunc + deferbycb
-     * Or in english, when there are no deferred requests, the amount
-     * we have submitted to the queue or cancelled must equal the amount
-     * we have said we wanted to be able to submit or cancel
-     */
-    if (rv->deferred_requests == 0)
-        assert(rv->stats.submits + rv->stats.releases ==
-               rv->stats.deferbyfunc + rv->stats.deferbycb);
-
-    rv->flags.reserved = S_HELPER_DEFERRED;
-
-    rv->deferred_requests++;
-
-    rv->stats.deferbyfunc++;
-
-    return rv;
-}
-
-/**
- * puts this helper back in the queue. the calling app is required to
- * manage the state in the helper.
- */
-void
-helperStatefulReset(helper_stateful_server * srv)
-{
-    statefulhelper *hlp = srv->parent;
-    helper_stateful_request *r = srv->request;
-
-    if (r != NULL) {
-        /* reset attempt DURING an outstaning request */
-        debugs(84, 1, "helperStatefulReset: RESET During request " << hlp->id_name << " ");
-        srv->flags.busy = 0;
-        srv->roffset = 0;
-        helperStatefulRequestFree(r);
-        srv->request = NULL;
-    }
-
-    srv->flags.busy = 0;
-
-    if (srv->queue.head) {
-        srv->flags.reserved = S_HELPER_DEFERRED;
-        helperStatefulServerKickQueue(srv);
-    } else {
-        srv->flags.reserved = S_HELPER_FREE;
-
-        if ((srv->parent->OnEmptyQueue != NULL) && (srv->data))
-            srv->parent->OnEmptyQueue(srv->data);
-
-        helperStatefulKickQueue(hlp);
-    }
-}
-
 /**
  * DPW 2007-05-08
  *
  * helperStatefulReleaseServer tells the helper that whoever was
  * using it no longer needs its services.
- *
- * If the state is S_HELPER_DEFERRED, decrease the deferred count.
- * If the count goes to zero, then it can become S_HELPER_FREE.
- *
- * If the state is S_HELPER_RESERVED, then it should always
- * become S_HELPER_FREE.
  */
 void
 helperStatefulReleaseServer(helper_stateful_server * srv)
 {
     debugs(84, 3, HERE << "srv-" << srv->index << " flags.reserved = " << srv->flags.reserved);
-    if (srv->flags.reserved == S_HELPER_FREE)
+    if (!srv->flags.reserved)
         return;
 
     srv->stats.releases++;
 
-    if (srv->flags.reserved == S_HELPER_DEFERRED) {
-        assert(srv->deferred_requests);
-        srv->deferred_requests--;
-        if (srv->deferred_requests) {
-            debugs(0,0,HERE << "helperStatefulReleaseServer srv->deferred_requests=" << srv->deferred_requests);
-            return;
-        }
-        if (srv->queue.head) {
-            debugs(0,0,HERE << "helperStatefulReleaseServer srv->queue.head not NULL");
-            return;
-        }
-    }
-
-    srv->flags.reserved = S_HELPER_FREE;
+    srv->flags.reserved = 0;
     if (srv->parent->OnEmptyQueue != NULL && srv->data)
         srv->parent->OnEmptyQueue(srv->data);
+
+    helperStatefulServerDone(srv);
 }
 
 /** return a pointer to the stateful routines data area */
@@ -613,12 +466,11 @@ helperStatefulStats(StoreEntry * sentry, statefulhelper * hlp, const char *label
     storeAppendPrintf(sentry, "avg service time: %d msec\n",
                       hlp->stats.avg_svc_time);
     storeAppendPrintf(sentry, "\n");
-    storeAppendPrintf(sentry, "%7s\t%7s\t%7s\t%11s\t%20s\t%s\t%7s\t%7s\t%7s\n",
+    storeAppendPrintf(sentry, "%7s\t%7s\t%7s\t%11s\t%6s\t%7s\t%7s\t%7s\n",
                       "#",
                       "FD",
                       "PID",
                       "# Requests",
-                      "# Deferred Requests",
                       "Flags",
                       "Time",
                       "Offset",
@@ -628,20 +480,18 @@ helperStatefulStats(StoreEntry * sentry, statefulhelper * hlp, const char *label
         helper_stateful_server *srv = (helper_stateful_server *)link->data;
         double tt = 0.001 * tvSubMsec(srv->dispatch_time, srv->flags.busy ? current_time : srv->answer_time);
         double tr = 0.001 * tvSubMsec(srv->dispatch_time, current_time);
-        storeAppendPrintf(sentry, "%7d\t%7d\t%7d\t%11d\t%20d\t%c%c%c%c%c%c\t%7.3f\t%7.3f\t%7d\t%s\n",
+        storeAppendPrintf(sentry, "%7d\t%7d\t%7d\t%11d\t%c%c%c%c%c\t%7.3f\t%7.3f\t%7d\t%s\n",
                           srv->index + 1,
                           srv->rfd,
                           srv->pid,
                           srv->stats.uses,
-                          (int) srv->deferred_requests,
                           srv->flags.busy ? 'B' : ' ',
                           srv->flags.closing ? 'C' : ' ',
-                          srv->flags.reserved == S_HELPER_RESERVED ? 'R' : ' ',
-                          srv->flags.reserved == S_HELPER_DEFERRED ? 'D' : ' ',
+                          srv->flags.reserved ? 'R' : ' ',
                           srv->flags.shutdown ? 'S' : ' ',
                           srv->request ? (srv->request->placeholder ? 'P' : ' ') : ' ',
                           tt < 0.0 ? 0.0 : tt,
-                          srv->flags.reserved == S_HELPER_RESERVED || srv->flags.reserved != S_HELPER_DEFERRED || tr > 0.0 ? tr : 0.0,
+                          srv->flags.reserved || tr > 0.0 ? tr : 0.0,
                           (int) srv->roffset,
                           srv->request ? log_quote(srv->request->buf) : "(none)");
     }
@@ -650,7 +500,6 @@ helperStatefulStats(StoreEntry * sentry, statefulhelper * hlp, const char *label
     storeAppendPrintf(sentry, "   B = BUSY\n");
     storeAppendPrintf(sentry, "   C = CLOSING\n");
     storeAppendPrintf(sentry, "   R = RESERVED\n");
-    storeAppendPrintf(sentry, "   D = DEFERRED\n");
     storeAppendPrintf(sentry, "   S = SHUTDOWN PENDING\n");
     storeAppendPrintf(sentry, "   P = PLACEHOLDER\n");
 }
@@ -758,14 +607,14 @@ helperStatefulShutdown(statefulhelper * hlp)
             continue;
         }
 
-        if (srv->flags.reserved != S_HELPER_FREE) {
-            debugs(84, 3, "helperStatefulShutdown: " << hlp->id_name << " #" << srv->index + 1 << " is RESERVED.");
-            continue;
-        }
-
-        if (srv->deferred_requests) {
-            debugs(84, 3, "helperStatefulShutdown: " << hlp->id_name << " #" << srv->index + 1 << " has DEFERRED requests.");
-            continue;
+        if (srv->flags.reserved) {
+            if (shutting_down) {
+                debugs(84, 3, "helperStatefulShutdown: " << hlp->id_name << " #" << srv->index + 1 << " is RESERVED. Closing anyway.");
+            }
+            else {
+                debugs(84, 3, "helperStatefulShutdown: " << hlp->id_name << " #" << srv->index + 1 << " is RESERVED. Not Shutting Down Yet.");
+                continue;
+            }
         }
 
         srv->flags.closing = 1;
@@ -867,8 +716,6 @@ helperServerFree(int fd, void *data)
     if (!concurrency)
         concurrency = 1;
 
-    assert(srv->rfd == fd);
-
     if (srv->rbuf) {
         memFreeBuf(srv->rbuf_sz, srv->rbuf);
         srv->rbuf = NULL;
@@ -935,7 +782,6 @@ helperStatefulServerFree(int fd, void *data)
     helper_stateful_server *srv = (helper_stateful_server *)data;
     statefulhelper *hlp = srv->parent;
     helper_stateful_request *r;
-    assert(srv->rfd == fd);
 
     if (srv->rbuf) {
         memFreeBuf(srv->rbuf_sz, srv->rbuf);
@@ -1002,7 +848,6 @@ helperHandleRead(int fd, char *buf, size_t len, comm_err_t flag, int xerrno, voi
     char *t = NULL;
     helper_server *srv = (helper_server *)data;
     helper *hlp = srv->parent;
-    assert(fd == srv->rfd);
     assert(cbdataReferenceValid(data));
 
     /* Bail out early on COMM_ERR_CLOSING - close handlers will tidy up for us */
@@ -1011,6 +856,8 @@ helperHandleRead(int fd, char *buf, size_t len, comm_err_t flag, int xerrno, voi
         return;
     }
 
+    assert(fd == srv->rfd);
+
     debugs(84, 5, "helperHandleRead: " << len << " bytes from " << hlp->id_name << " #" << srv->index + 1);
 
     if (flag != COMM_OK || len <= 0) {
@@ -1092,17 +939,21 @@ helperHandleRead(int fd, char *buf, size_t len, comm_err_t flag, int xerrno, voi
         srv->roffset -= (t - srv->rbuf);
         memmove(srv->rbuf, t, srv->roffset + 1);
 
-        if (srv->flags.shutdown) {
+        if (!srv->flags.shutdown) {
+            helperKickQueue(hlp);
+        } else if (!srv->flags.closing && !srv->stats.pending) {
             int wfd = srv->wfd;
             srv->wfd = -1;
+            if (srv->rfd == wfd)
+                srv->rfd = -1;
             srv->flags.closing=1;
             comm_close(wfd);
             return;
-        } else
-            helperKickQueue(hlp);
+        }
     }
 
-    comm_read(fd, srv->rbuf + srv->roffset, srv->rbuf_sz - srv->roffset - 1, helperHandleRead, srv);
+    if (srv->rfd != -1)
+        comm_read(fd, srv->rbuf + srv->roffset, srv->rbuf_sz - srv->roffset - 1, helperHandleRead, srv);
 }
 
 static void
@@ -1112,7 +963,6 @@ helperStatefulHandleRead(int fd, char *buf, size_t len, comm_err_t flag, int xer
     helper_stateful_server *srv = (helper_stateful_server *)data;
     helper_stateful_request *r;
     statefulhelper *hlp = srv->parent;
-    assert(fd == srv->rfd);
     assert(cbdataReferenceValid(data));
 
     /* Bail out early on COMM_ERR_CLOSING - close handlers will tidy up for us */
@@ -1121,6 +971,8 @@ helperStatefulHandleRead(int fd, char *buf, size_t len, comm_err_t flag, int xer
         return;
     }
 
+    assert(fd == srv->rfd);
+
     debugs(84, 5, "helperStatefulHandleRead: " << len << " bytes from " <<
            hlp->id_name << " #" << srv->index + 1);
 
@@ -1149,6 +1001,7 @@ helperStatefulHandleRead(int fd, char *buf, size_t len, comm_err_t flag, int xer
 
     if ((t = strchr(srv->rbuf, '\n'))) {
         /* end of reply found */
+	int called = 1;
         debugs(84, 3, "helperStatefulHandleRead: end of reply found");
 
         if (t > srv->rbuf && t[-1] == '\r')
@@ -1157,58 +1010,10 @@ helperStatefulHandleRead(int fd, char *buf, size_t len, comm_err_t flag, int xer
         *t = '\0';
 
         if (r && cbdataReferenceValid(r->data)) {
-            switch ((r->callback(r->data, srv, srv->rbuf))) {	/*if non-zero reserve helper */
-
-            case S_HELPER_UNKNOWN:
-                fatal("helperStatefulHandleRead: either a non-state aware callback was give to the stateful helper routines, or an uninitialised callback response was received.\n");
-                break;
-
-            case S_HELPER_RELEASE:	/* helper finished with */
-
-                if (!srv->deferred_requests && !srv->queue.head) {
-                    srv->flags.reserved = S_HELPER_FREE;
-
-                    if ((srv->parent->OnEmptyQueue != NULL) && (srv->data))
-                        srv->parent->OnEmptyQueue(srv->data);
-
-                    debugs(84, 5, "StatefulHandleRead: releasing " << hlp->id_name << " #" << srv->index + 1);
-                } else {
-                    srv->flags.reserved = S_HELPER_DEFERRED;
-                    debugs(84, 5, "StatefulHandleRead: outstanding deferred requests on " <<
-                           hlp->id_name << " #" << srv->index + 1 <<
-                           ". reserving for deferred requests.");
-                }
-
-                break;
-
-            case S_HELPER_RESERVE:	/* 'pin' this helper for the caller */
-
-                if (!srv->queue.head) {
-                    assert(srv->deferred_requests == 0);
-                    srv->flags.reserved = S_HELPER_RESERVED;
-                    debugs(84, 5, "StatefulHandleRead: reserving " << hlp->id_name << " #" << srv->index + 1);
-                } else {
-                    fatal("StatefulHandleRead: Callback routine attempted to reserve a stateful helper with deferred requests. This can lead to deadlock.\n");
-                }
-
-                break;
-
-            case S_HELPER_DEFER:
-                /* the helper is still needed, but can
-                 * be used for other requests in the meantime.
-                 */
-                srv->flags.reserved = S_HELPER_DEFERRED;
-                srv->deferred_requests++;
-                srv->stats.deferbycb++;
-                debugs(84, 5, "StatefulHandleRead: reserving " << hlp->id_name << " #" << srv->index + 1 << " for deferred requests.");
-                break;
-
-            default:
-                fatal("helperStatefulHandleRead: unknown stateful helper callback result.\n");
-            }
-
+            r->callback(r->data, srv, srv->rbuf);
         } else {
             debugs(84, 1, "StatefulHandleRead: no callback data registered");
+	    called = 0;
         }
 
         srv->flags.busy = 0;
@@ -1222,22 +1027,14 @@ helperStatefulHandleRead(int fd, char *buf, size_t len, comm_err_t flag, int xer
                        tvSubMsec(srv->dispatch_time, current_time),
                        hlp->stats.replies, REDIRECT_AV_FACTOR);
 
-        if (srv->flags.shutdown
-                && srv->flags.reserved == S_HELPER_FREE
-                && !srv->deferred_requests) {
-            int wfd = srv->wfd;
-            srv->wfd = -1;
-            srv->flags.closing=1;
-            comm_close(wfd);
-        } else {
-            if (srv->queue.head)
-                helperStatefulServerKickQueue(srv);
-            else
-                helperStatefulKickQueue(hlp);
-        }
+	if (called)
+	    helperStatefulServerDone(srv);
+	else
+	    helperStatefulReleaseServer(srv);
     }
 
-    comm_read(srv->rfd, srv->rbuf + srv->roffset, srv->rbuf_sz - srv->roffset - 1,
+    if (srv->rfd != -1)
+        comm_read(srv->rfd, srv->rbuf + srv->roffset, srv->rbuf_sz - srv->roffset - 1,
               helperStatefulHandleRead, srv);
 }
 
@@ -1298,31 +1095,6 @@ StatefulEnqueue(statefulhelper * hlp, helper_stateful_request * r)
 
 }
 
-static void
-StatefulServerEnqueue(helper_stateful_server * srv, helper_stateful_request * r)
-{
-    dlink_node *link = (dlink_node *)memAllocate(MEM_DLINK_NODE);
-    dlinkAddTail(r, link, &srv->queue);
-    /* TODO: warning if the queue on this server is more than X
-     * We don't check the queue size at the moment, because
-     * requests hitting here are deferrable
-     */
-    /*    hlp->stats.queue_size++;
-     * if (hlp->stats.queue_size < hlp->n_running)
-     * return;
-     * if (squid_curtime - hlp->last_queue_warn < 600)
-     * return;
-     * if (shutting_down || reconfiguring)
-     * return;
-     * hlp->last_queue_warn = squid_curtime;
-     * debugs(84, 0, "WARNING: All " << hlp->id_name << " processes are busy.");
-     * debugs(84, 0, "WARNING: " << hlp->stats.queue_size << " pending requests queued");
-     * if (hlp->stats.queue_size > hlp->n_running * 2)
-     * fatalf("Too many queued %s requests", hlp->id_name);
-     * debugs(84, 1, "Consider increasing the number of " << hlp->id_name << " processes in your config file." );  */
-}
-
-
 static helper_request *
 Dequeue(helper * hlp)
 {
@@ -1339,21 +1111,6 @@ Dequeue(helper * hlp)
     return r;
 }
 
-static helper_stateful_request *
-StatefulServerDequeue(helper_stateful_server * srv)
-{
-    dlink_node *link;
-    helper_stateful_request *r = NULL;
-
-    if ((link = srv->queue.head)) {
-        r = (helper_stateful_request *)link->data;
-        dlinkDelete(link, &srv->queue);
-        memFree(link, MEM_DLINK_NODE);
-    }
-
-    return r;
-}
-
 static helper_stateful_request *
 StatefulDequeue(statefulhelper * hlp)
 {
@@ -1427,7 +1184,7 @@ StatefulGetFirstAvailable(statefulhelper * hlp)
         if (srv->flags.busy)
             continue;
 
-        if (srv->flags.reserved == S_HELPER_RESERVED)
+        if (srv->flags.reserved)
             continue;
 
         if (srv->flags.shutdown)
@@ -1540,41 +1297,30 @@ helperStatefulDispatch(helper_stateful_server * srv, helper_stateful_request * r
     if (!cbdataReferenceValid(r->data)) {
         debugs(84, 1, "helperStatefulDispatch: invalid callback data");
         helperStatefulRequestFree(r);
+	helperStatefulReleaseServer(srv);
         return;
     }
 
     debugs(84, 9, "helperStatefulDispatch busying helper " << hlp->id_name << " #" << srv->index + 1);
 
     if (r->placeholder == 1) {
         /* a callback is needed before this request can _use_ a helper. */
-        /* we don't care about releasing/deferring this helper. The request NEVER
+        /* we don't care about releasing this helper. The request NEVER
          * gets to the helper. So we throw away the return code */
         r->callback(r->data, srv, NULL);
         /* throw away the placeholder */
         helperStatefulRequestFree(r);
         /* and push the queue. Note that the callback may have submitted a new
          * request to the helper which is why we test for the request*/
 
-        if (srv->request == NULL) {
-            if (srv->flags.shutdown
-                    && srv->flags.reserved == S_HELPER_FREE
-                    && !srv->deferred_requests) {
-                int wfd = srv->wfd;
-                srv->wfd = -1;
-                srv->flags.closing=1;
-                comm_close(wfd);
-            } else {
-                if (srv->queue.head)
-                    helperStatefulServerKickQueue(srv);
-                else
-                    helperStatefulKickQueue(hlp);
-            }
-        }
+        if (srv->request == NULL)
+            helperStatefulServerDone(srv);
 
         return;
     }
 
     srv->flags.busy = 1;
+    srv->flags.reserved = 1;
     srv->request = r;
     srv->dispatch_time = current_time;
     comm_write(srv->wfd,
@@ -1612,12 +1358,19 @@ helperStatefulKickQueue(statefulhelper * hlp)
 }
 
 static void
-helperStatefulServerKickQueue(helper_stateful_server * srv)
+helperStatefulServerDone(helper_stateful_server * srv)
 {
-    helper_stateful_request *r;
-
-    if ((r = StatefulServerDequeue(srv)))
-        helperStatefulDispatch(srv, r);
+    if (!srv->flags.shutdown) {
+        helperStatefulKickQueue(srv->parent);
+    } else if (!srv->flags.closing && !srv->flags.reserved && !srv->flags.busy) {
+        int wfd = srv->wfd;
+        srv->wfd = -1;
+        if (srv->rfd == wfd)
+            srv->rfd = -1;
+        srv->flags.closing=1;
+        comm_close(wfd);
+        return;
+    }
 }
 
 static void
@@ -51,7 +51,7 @@ typedef struct _helper_flags helper_flags;
 
 typedef struct _helper_stateful_flags helper_stateful_flags;
 
-typedef stateful_helper_callback_t HLPSCB(void *, void *lastserver, char *buf);
+typedef void HLPSCB(void *, void *lastserver, char *buf);
 
 struct _helper {
     wordlist *cmdline;
@@ -152,25 +152,21 @@ struct _helper_stateful_server {
     struct timeval answer_time;
 
     dlink_node link;
-    dlink_list queue;
     statefulhelper *parent;
     helper_stateful_request *request;
 
     struct _helper_stateful_flags {
         unsigned int busy:1;
         unsigned int closing:1;
         unsigned int shutdown:1;
-        stateful_helper_reserve_t reserved;
+        unsigned int reserved:1;
     } flags;
 
     struct {
         int uses;
         int submits;
         int releases;
-        int deferbyfunc;
-        int deferbycb;
     } stats;
-    int deferred_requests;	/* current number of deferred requests */
     void *data;			/* State data used by the calling routines */
     void *hIpc;
 };
@@ -196,7 +192,7 @@ class helper_stateful_request
     MEMPROXY_CLASS(helper_stateful_request);
     char *buf;
     HLPSCB *callback;
-    int placeholder;		/* if 1, this is a dummy request waiting for a stateful helper to become available for deferred requests.*/
+    int placeholder;		/* if 1, this is a dummy request waiting for a stateful helper to become available */
     void *data;
 };
 
@@ -215,10 +211,8 @@ SQUIDCEXTERN helper *helperCreate(const char *);
 SQUIDCEXTERN statefulhelper *helperStatefulCreate(const char *);
 SQUIDCEXTERN void helperFree(helper *);
 SQUIDCEXTERN void helperStatefulFree(statefulhelper *);
-SQUIDCEXTERN void helperStatefulReset(helper_stateful_server * srv);
 SQUIDCEXTERN void helperStatefulReleaseServer(helper_stateful_server * srv);
 SQUIDCEXTERN void *helperStatefulServerGetData(helper_stateful_server * srv);
-SQUIDCEXTERN helper_stateful_server *helperStatefulDefer(statefulhelper *);
 
 
 
@@ -2,7 +2,7 @@
 /*
  * $Id$
  *
- * DEBUG: section 25    MIME Parsing
+ * DEBUG: section 25    MIME Parsing and Internal Icons
  * AUTHOR: Harvest Derived
  *
  * SQUID Web Proxy Cache          http://www.squid-cache.org/
@@ -96,132 +96,6 @@ mimeEntry::operator delete (void *address)
     safe_free (address);
 }
 
-/* returns a pointer to a field-value of the first matching field-name */
-char *
-mime_get_header(const char *mime, const char *name)
-{
-    return mime_get_header_field(mime, name, NULL);
-}
-
-/*
- * returns a pointer to a field-value of the first matching field-name where
- * field-value matches prefix if any
- */
-char *
-mime_get_header_field(const char *mime, const char *name, const char *prefix)
-{
-    LOCAL_ARRAY(char, header, GET_HDR_SZ);
-    const char *p = NULL;
-    char *q = NULL;
-    char got = 0;
-    const int namelen = name ? strlen(name) : 0;
-    const int preflen = prefix ? strlen(prefix) : 0;
-    int l;
-
-    if (NULL == mime)
-        return NULL;
-
-    assert(NULL != name);
-
-    debugs(25, 5, "mime_get_header: looking for '" << name << "'");
-
-    for (p = mime; *p; p += strcspn(p, "\n\r")) {
-        if (strcmp(p, "\r\n\r\n") == 0 || strcmp(p, "\n\n") == 0)
-            return NULL;
-
-        while (xisspace(*p))
-            p++;
-
-        if (strncasecmp(p, name, namelen))
-            continue;
-
-        if (!xisspace(p[namelen]) && p[namelen] != ':')
-            continue;
-
-        l = strcspn(p, "\n\r") + 1;
-
-        if (l > GET_HDR_SZ)
-            l = GET_HDR_SZ;
-
-        xstrncpy(header, p, l);
-
-        debugs(25, 5, "mime_get_header: checking '" << header << "'");
-
-        q = header;
-
-        q += namelen;
-
-        if (*q == ':')
-            q++, got = 1;
-
-        while (xisspace(*q))
-            q++, got = 1;
-
-        if (got && prefix) {
-            /* we could process list entries here if we had strcasestr(). */
-            /* make sure we did not match a part of another field-value */
-            got = !strncasecmp(q, prefix, preflen) && !xisalpha(q[preflen]);
-        }
-
-        if (got) {
-            debugs(25, 5, "mime_get_header: returning '" << q << "'");
-            return q;
-        }
-    }
-
-    return NULL;
-}
-
-size_t
-headersEnd(const char *mime, size_t l)
-{
-    size_t e = 0;
-    int state = 1;
-
-    PROF_start(headersEnd);
-
-    while (e < l && state < 3) {
-        switch (state) {
-
-        case 0:
-
-            if ('\n' == mime[e])
-                state = 1;
-
-            break;
-
-        case 1:
-            if ('\r' == mime[e])
-                state = 2;
-            else if ('\n' == mime[e])
-                state = 3;
-            else
-                state = 0;
-
-            break;
-
-        case 2:
-            if ('\n' == mime[e])
-                state = 3;
-            else
-                state = 0;
-
-            break;
-
-        default:
-            break;
-        }
-
-        e++;
-    }
-    PROF_stop(headersEnd);
-
-    if (3 == state)
-        return e;
-
-    return 0;
-}
-
 static mimeEntry *
 mimeGetEntry(const char *fn, int skip_encodings)
 {
@@ -0,0 +1,164 @@
+
+/*
+ * $Id$
+ *
+ * DEBUG: section 25    MiME Header Parsing
+ * AUTHOR: Harvest Derived
+ *
+ * SQUID Web Proxy Cache          http://www.squid-cache.org/
+ * ----------------------------------------------------------
+ *
+ *  Squid is the result of efforts by numerous individuals from
+ *  the Internet community; see the CONTRIBUTORS file for full
+ *  details.   Many organizations have provided support for Squid's
+ *  development; see the SPONSORS file for full details.  Squid is
+ *  Copyrighted (C) 2001 by the Regents of the University of
+ *  California; see the COPYRIGHT file for full details.  Squid
+ *  incorporates software developed and/or copyrighted by other
+ *  sources; see the CREDITS file for full details.
+ *
+ *  This program is free software; you can redistribute it and/or modify
+ *  it under the terms of the GNU General Public License as published by
+ *  the Free Software Foundation; either version 2 of the License, or
+ *  (at your option) any later version.
+ *
+ *  This program is distributed in the hope that it will be useful,
+ *  but WITHOUT ANY WARRANTY; without even the implied warranty of
+ *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ *  GNU General Public License for more details.
+ *
+ *  You should have received a copy of the GNU General Public License
+ *  along with this program; if not, write to the Free Software
+ *  Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111, USA.
+ *
+ */
+
+#include "squid.h"
+
+#define GET_HDR_SZ 1024
+
+/* returns a pointer to a field-value of the first matching field-name */
+char *
+mime_get_header(const char *mime, const char *name)
+{
+    return mime_get_header_field(mime, name, NULL);
+}
+
+/*
+ * returns a pointer to a field-value of the first matching field-name where
+ * field-value matches prefix if any
+ */
+char *
+mime_get_header_field(const char *mime, const char *name, const char *prefix)
+{
+    LOCAL_ARRAY(char, header, GET_HDR_SZ);
+    const char *p = NULL;
+    char *q = NULL;
+    char got = 0;
+    const int namelen = name ? strlen(name) : 0;
+    const int preflen = prefix ? strlen(prefix) : 0;
+    int l;
+
+    if (NULL == mime)
+        return NULL;
+
+    assert(NULL != name);
+
+    debugs(25, 5, "mime_get_header: looking for '" << name << "'");
+
+    for (p = mime; *p; p += strcspn(p, "\n\r")) {
+        if (strcmp(p, "\r\n\r\n") == 0 || strcmp(p, "\n\n") == 0)
+            return NULL;
+
+        while (xisspace(*p))
+            p++;
+
+        if (strncasecmp(p, name, namelen))
+            continue;
+
+        if (!xisspace(p[namelen]) && p[namelen] != ':')
+            continue;
+
+        l = strcspn(p, "\n\r") + 1;
+
+        if (l > GET_HDR_SZ)
+            l = GET_HDR_SZ;
+
+        xstrncpy(header, p, l);
+
+        debugs(25, 5, "mime_get_header: checking '" << header << "'");
+
+        q = header;
+
+        q += namelen;
+
+        if (*q == ':')
+            q++, got = 1;
+
+        while (xisspace(*q))
+            q++, got = 1;
+
+        if (got && prefix) {
+            /* we could process list entries here if we had strcasestr(). */
+            /* make sure we did not match a part of another field-value */
+            got = !strncasecmp(q, prefix, preflen) && !xisalpha(q[preflen]);
+        }
+
+        if (got) {
+            debugs(25, 5, "mime_get_header: returning '" << q << "'");
+            return q;
+        }
+    }
+
+    return NULL;
+}
+
+size_t
+headersEnd(const char *mime, size_t l)
+{
+    size_t e = 0;
+    int state = 1;
+
+    PROF_start(headersEnd);
+
+    while (e < l && state < 3) {
+        switch (state) {
+
+        case 0:
+
+            if ('\n' == mime[e])
+                state = 1;
+
+            break;
+
+        case 1:
+            if ('\r' == mime[e])
+                state = 2;
+            else if ('\n' == mime[e])
+                state = 3;
+            else
+                state = 0;
+
+            break;
+
+        case 2:
+            if ('\n' == mime[e])
+                state = 3;
+            else
+                state = 0;
+
+            break;
+
+        default:
+            break;
+        }
+
+        e++;
+    }
+    PROF_stop(headersEnd);
+
+    if (3 == state)
+        return e;
+
+    return 0;
+}
@@ -191,7 +191,7 @@ PconnPool::key(const char *host, u_short port, const char *domain, IpAddress &cl
     else
         snprintf(buf, SQUIDHOSTNAMELEN * 3 + 10, "%s:%d", host, (int) port);
 
-    debugs(48,6,"PconnPool::key(" << host << "," << port << "," << domain << "," << client_address << "is {" << buf << "}" );
+    debugs(48,6,"PconnPool::key(" << (host?host:"(no host!)") << "," << port << "," << (domain?domain:"(no domain)") << "," << client_address << "is {" << buf << "}" );
     return buf;
 }
 
@@ -193,7 +193,7 @@ store_client::store_client(StoreEntry *e) : entry (e)
 
     if (getType() == STORE_DISK_CLIENT)
         /* assert we'll be able to get the data we want */
-        /* maybe we should open swapin_fd here */
+        /* maybe we should open swapin_sio here */
         assert(entry->swap_filen > -1 || entry->swapOutAble());
 
 #if STORE_CLIENT_LIST_DEBUG
@@ -70,7 +70,7 @@ httpBodyPackInto(const HttpBody * body, Packer * p)
 }
 
 bool
-HttpReply::sanityCheckStartLine(MemBuf *buf, http_status *error)
+HttpReply::sanityCheckStartLine(MemBuf *buf, const size_t hdr_len, http_status *error)
 {
     fatal ("Not implemented");
     return false;
@@ -56,7 +56,7 @@ HttpRequest::packFirstLineInto(Packer * p, bool full_uri) const
 }
 
 bool
-HttpRequest::sanityCheckStartLine(MemBuf *buf, http_status *error)
+HttpRequest::sanityCheckStartLine(MemBuf *buf, const size_t hdr_len, http_status *error)
 {
     fatal("Not implemented");
     return false;
@@ -0,0 +1,22 @@
+#include "squid.h"
+
+// for StatHist definitions
+#include "protos.h"
+
+void
+statHistDump(const StatHist * H, StoreEntry * sentry, StatHistBinDumper * bd)
+{
+    fatal("statHistDump: Not implemented");
+}
+
+void
+statHistCount(StatHist * H, double val)
+{
+    fatal("statHistCount: Not implemented");
+}
+
+void
+statHistEnumInit(StatHist * H, int last_enum)
+{
+//NO-OP    fatal("statHistEnumInit: Not implemented");
+}
@@ -40,13 +40,13 @@ StorePointer Store::CurrentRoot = NULL;
 extern "C" void
     storeAppendPrintf(StoreEntry * e, const char *fmt,...)
 {
-    fatal("Not implemented");
+    fatal("storeAppendPrintf: Not implemented");
 }
 
 extern "C" void
     storeAppendVPrintf(StoreEntry * e, const char *fmt, va_list vargs)
 {
-    fatal("Not implemented");
+    fatal("storeAppendVPrintf: Not implemented");
 }
 
 #ifndef _USE_INLINE_
@@ -0,0 +1,183 @@
+#include "config.h"
+#include <cppunit/TestAssert.h>
+
+#include "testHttpReply.h"
+#include "HttpReply.h"
+#include "Mem.h"
+
+/* to avoid libsquid.la and its comm stuff */
+#include "TextException.cc"
+
+CPPUNIT_TEST_SUITE_REGISTRATION( testHttpReply );
+
+struct SquidConfig Config;
+
+/* stub functions to link successfully */
+
+#include "Store.h"
+void
+StoreEntry::timestampsSet()
+{
+    fatal("StoreEntry::timestampsSet. Not implemented.");
+}
+
+void
+StoreEntry::setPublicKey()
+{
+    fatal("StoreEntry::setPulicKey. Not implemented.");
+}
+
+#include "MemObject.h"
+int64_t
+MemObject::endOffset() const
+{
+    return 0;
+}
+
+#include "ConfigParser.h"
+void
+ConfigParser::destruct()
+{
+// CALLED as shutdown no-op
+//    fatal("ConfigParser::destruct. Not implemented.");
+}
+
+void
+eventAdd(const char *name, EVH * func, void *arg, double when, int, bool cbdata)
+{
+// CALLED as setUp no-op
+//    fatal("eventAdd. Not implemented.");
+}
+
+/* end */
+
+void
+testHttpReply::setUp()
+{
+    Mem::Init();
+    httpHeaderInitModule();
+}
+
+void
+testHttpReply::testSanityCheckFirstLine()
+{
+    MemBuf input;
+    HttpReply engine;
+    http_status error = HTTP_STATUS_NONE;
+    size_t hdr_len;
+    input.init();
+
+    // a valid status line
+    input.append("HTTP/1.1 200 Okay\n\n", 19);
+    hdr_len = headersEnd(input.content(),input.contentSize());
+    CPPUNIT_ASSERT( 1 && engine.sanityCheckStartLine(&input, hdr_len, &error) );
+    CPPUNIT_ASSERT_EQUAL(error, HTTP_STATUS_NONE);
+    input.reset();
+    error = HTTP_STATUS_NONE;
+
+    input.append("HTTP/1.1    200  Okay     \n\n", 28);
+    hdr_len = headersEnd(input.content(),input.contentSize());
+    CPPUNIT_ASSERT( 2 && engine.sanityCheckStartLine(&input, hdr_len, &error) );
+    CPPUNIT_ASSERT_EQUAL(error, HTTP_STATUS_NONE);
+    input.reset();
+    error = HTTP_STATUS_NONE;
+
+#if TODO // these cases are only checked after parse...
+    // invalid status line
+    input.append("HTTP/1.1 999 Okay\n\n", 19);
+    hdr_len = headersEnd(input.content(),input.contentSize());
+    CPPUNIT_ASSERT( 3 && !engine.sanityCheckStartLine(&input, hdr_len, &error) );
+    CPPUNIT_ASSERT_EQUAL(error, HTTP_INVALID_HEADER);
+    input.reset();
+    error = HTTP_STATUS_NONE;
+
+    input.append("HTTP/1.1    2000  Okay     \n\n", 29);
+    hdr_len = headersEnd(input.content(),input.contentSize());
+    CPPUNIT_ASSERT( 4 && engine.sanityCheckStartLine(&input, hdr_len, &error) );
+    CPPUNIT_ASSERT_EQUAL(error, HTTP_STATUS_NONE);
+    input.reset();
+    error = HTTP_STATUS_NONE;
+#endif
+
+    // empty status line
+    input.append("\n\n", 2);
+    hdr_len = headersEnd(input.content(),input.contentSize());
+    CPPUNIT_ASSERT( 5 && !engine.sanityCheckStartLine(&input, hdr_len, &error) );
+    CPPUNIT_ASSERT_EQUAL(error, HTTP_INVALID_HEADER);
+    input.reset();
+    error = HTTP_STATUS_NONE;
+
+    input.append("      \n\n", 8);
+    hdr_len = headersEnd(input.content(),input.contentSize());
+    CPPUNIT_ASSERT( 6 && !engine.sanityCheckStartLine(&input, hdr_len, &error) );
+    CPPUNIT_ASSERT_EQUAL(error, HTTP_INVALID_HEADER);
+    input.reset();
+    error = HTTP_STATUS_NONE;
+
+    // status line with no message
+    input.append("HTTP/1.1 200\n\n", 14); /* real case seen */
+    hdr_len = headersEnd(input.content(),input.contentSize());
+    CPPUNIT_ASSERT(engine.sanityCheckStartLine(&input, hdr_len, &error) );
+    CPPUNIT_ASSERT_EQUAL(error, HTTP_STATUS_NONE);
+    input.reset();
+    error = HTTP_STATUS_NONE;
+
+    input.append("HTTP/1.1 200 \n\n", 15); /* real case seen */
+    hdr_len = headersEnd(input.content(),input.contentSize());
+    CPPUNIT_ASSERT(engine.sanityCheckStartLine(&input, hdr_len, &error) );
+    CPPUNIT_ASSERT_EQUAL(error, HTTP_STATUS_NONE);
+    input.reset();
+    error = HTTP_STATUS_NONE;
+
+#if FUTURE
+
+    // status line with no status
+    input.append("HTTP/1.1 \n\n", 11);
+    hdr_len = headersEnd(input.content(),input.contentSize());
+    CPPUNIT_ASSERT(!engine.sanityCheckStartLine(&input, hdr_len, &error) );
+    CPPUNIT_ASSERT_EQUAL(error, HTTP_INVALID_HEADER);
+    input.reset();
+    error = HTTP_STATUS_NONE;
+
+    input.append("HTTP/1.1     \n\n", 15);
+    hdr_len = headersEnd(input.content(),input.contentSize());
+    CPPUNIT_ASSERT(!engine.sanityCheckStartLine(&input, hdr_len, &error) );
+    CPPUNIT_ASSERT_EQUAL(error, HTTP_INVALID_HEADER);
+    input.reset();
+    error = HTTP_STATUS_NONE;
+
+    input.append("HTTP/1.1  Okay\n\n", 16); /* real case seen */
+    hdr_len = headersEnd(input.content(),input.contentSize());
+    CPPUNIT_ASSERT(!engine.sanityCheckStartLine(&input, hdr_len, &error) );
+    CPPUNIT_ASSERT_EQUAL(error, HTTP_INVALID_HEADER);
+    input.reset();
+    error = HTTP_STATUS_NONE;
+
+    // status line with nul-byte
+    input.append("HTTP/1.1\0200 Okay\n\n", 19); /* real case seen */
+    hdr_len = headersEnd(input.content(),input.contentSize());
+    CPPUNIT_ASSERT(!engine.sanityCheckStartLine(&input, hdr_len, &error) );
+    CPPUNIT_ASSERT_EQUAL(error, HTTP_INVALID_HEADER);
+    input.reset();
+    error = HTTP_STATUS_NONE;
+
+    // status line with negative status
+    input.append("HTTP/1.1 -000\n\n", 15); /* real case seen */
+    hdr_len = headersEnd(input.content(),input.contentSize());
+    CPPUNIT_ASSERT(!engine.sanityCheckStartLine(&input, hdr_len, &error) );
+    CPPUNIT_ASSERT_EQUAL(error, HTTP_INVALID_HEADER);
+    input.reset();
+    error = HTTP_STATUS_NONE;
+
+    // status line with non-HTTP protocol
+    input.append("ICY/1.1 200 Okay\n\n", 18); /* real case seen */
+    hdr_len = headersEnd(input.content(),input.contentSize());
+    /* NP: for nw ICY is handled as a pass-thru */
+    /*     Squid-3 will ignore it (and mangle the headers as per HTTP). */
+    CPPUNIT_ASSERT(!engine.sanityCheckStartLine(&input, hdr_len, &error) );
+    CPPUNIT_ASSERT_EQUAL(error, HTTP_INVALID_HEADER);
+    input.reset();
+    error = HTTP_STATUS_NONE;
+#endif
+
+}
@@ -0,0 +1,25 @@
+
+#ifndef SQUID_SRC_TEST_HTTP_REPLY_H
+#define SQUID_SRC_TEST_HTTP_REPLY_H
+
+#include <cppunit/extensions/HelperMacros.h>
+
+/*
+ * test HttpReply
+ */
+
+class testHttpReply : public CPPUNIT_NS::TestFixture
+{
+    CPPUNIT_TEST_SUITE( testHttpReply );
+    CPPUNIT_TEST( testSanityCheckFirstLine );
+    CPPUNIT_TEST_SUITE_END();
+
+public:
+    void setUp();
+
+protected:
+    void testSanityCheckFirstLine();
+};
+
+#endif
+
@@ -9,6 +9,13 @@
 
 CPPUNIT_TEST_SUITE_REGISTRATION( testHttpRequest );
 
+/** wrapper for testing HttpRequest object private and protected functions */
+class PrivateHttpRequest : public HttpRequest
+{
+public:
+    bool doSanityCheckStartLine(MemBuf *b, const size_t h, http_status *e) { return sanityCheckStartLine(b,h,e); };
+};
+
 /* stub functions to link successfully */
 void
 shut_down(int)
@@ -26,6 +33,7 @@ void
 testHttpRequest::setUp()
 {
     Mem::Init();
+    httpHeaderInitModule();
 }
 
 /*
@@ -150,3 +158,60 @@ testHttpRequest::testIPv6HostColonBug()
     CPPUNIT_ASSERT_EQUAL(String("http://2000:800::45/foo"), String(url));
     xfree(url);
 }
+
+void
+testHttpRequest::testSanityCheckStartLine()
+{
+    MemBuf input;
+    PrivateHttpRequest engine;
+    http_status error = HTTP_STATUS_NONE;
+    size_t hdr_len;
+    input.init();
+
+    // a valid request line
+    input.append("GET / HTTP/1.1\n\n", 16);
+    hdr_len = headersEnd(input.content(), input.contentSize());
+    CPPUNIT_ASSERT(engine.doSanityCheckStartLine(&input, hdr_len, &error) );
+    CPPUNIT_ASSERT_EQUAL(error, HTTP_STATUS_NONE);
+    input.reset();
+    error = HTTP_STATUS_NONE;
+
+    input.append("GET  /  HTTP/1.1\n\n", 18);
+    hdr_len = headersEnd(input.content(), input.contentSize());
+    CPPUNIT_ASSERT(engine.doSanityCheckStartLine(&input, hdr_len, &error) );
+    CPPUNIT_ASSERT_EQUAL(error, HTTP_STATUS_NONE);
+    input.reset();
+    error = HTTP_STATUS_NONE;
+
+    // strange but valid methods
+    input.append(". / HTTP/1.1\n\n", 14);
+    hdr_len = headersEnd(input.content(), input.contentSize());
+    CPPUNIT_ASSERT(engine.doSanityCheckStartLine(&input, hdr_len, &error) );
+    CPPUNIT_ASSERT_EQUAL(error, HTTP_STATUS_NONE);
+    input.reset();
+    error = HTTP_STATUS_NONE;
+
+    input.append("OPTIONS * HTTP/1.1\n\n", 20);
+    hdr_len = headersEnd(input.content(), input.contentSize());
+    CPPUNIT_ASSERT(engine.doSanityCheckStartLine(&input, hdr_len, &error) );
+    CPPUNIT_ASSERT_EQUAL(error, HTTP_STATUS_NONE);
+    input.reset();
+    error = HTTP_STATUS_NONE;
+
+// TODO no method
+
+// TODO binary code in method
+
+// TODO no URL
+
+// TODO no status (okay)
+
+// TODO non-HTTP protocol
+
+    input.append("      \n\n", 8);
+    hdr_len = headersEnd(input.content(), input.contentSize());
+    CPPUNIT_ASSERT(!engine.doSanityCheckStartLine(&input, hdr_len, &error) );
+    CPPUNIT_ASSERT_EQUAL(error, HTTP_INVALID_HEADER);
+    input.reset();
+    error = HTTP_STATUS_NONE;
+}
@@ -14,6 +14,7 @@ class testHttpRequest : public CPPUNIT_NS::TestFixture
     CPPUNIT_TEST( testCreateFromUrlAndMethod );
     CPPUNIT_TEST( testCreateFromUrl );
     CPPUNIT_TEST( testIPv6HostColonBug );
+    CPPUNIT_TEST( testSanityCheckStartLine );
     CPPUNIT_TEST_SUITE_END();
 
 public:
@@ -23,6 +24,7 @@ class testHttpRequest : public CPPUNIT_NS::TestFixture
     void testCreateFromUrlAndMethod();
     void testCreateFromUrl();
     void testIPv6HostColonBug();
+    void testSanityCheckStartLine();
 };
 
 #endif
@@ -41,17 +41,6 @@
 #include "SquidTime.h"
 #include "ip/IpIntercept.h"
 
-#ifdef _SQUID_LINUX_
-#if HAVE_SYS_CAPABILITY_H
-#undef _POSIX_SOURCE
-/* Ugly glue to get around linux header madness colliding with glibc */
-#define _LINUX_TYPES_H
-#define _LINUX_FS_H
-typedef uint32_t __u32;
-#include <sys/capability.h>
-#endif
-#endif
-
 #if HAVE_SYS_PRCTL_H
 #include <sys/prctl.h>
 #endif
@@ -36,9 +36,6 @@
 #ifndef SQUID_TYPEDEFS_H
 #define SQUID_TYPEDEFS_H
 
-typedef unsigned int store_status_t;
-//MOVED src/Store.h (only use)		typedef unsigned int ping_status_t;
-typedef unsigned int swap_status_t;
 typedef signed int sfileno;
 typedef signed int sdirno;
 
@@ -43,6 +43,7 @@ buildtest() {
     btlayer="bt${layer}"
     log=${btlayer}.log
     echo "TESTING: ${layer}"
+    chmod -R 777 ${btlayer}
     rm -f -r ${btlayer} && mkdir ${btlayer}
     {
 	result=255
@@ -76,6 +77,7 @@ buildtest() {
 
     if test "${cleanup}" = "yes" ; then
 	echo "REMOVE DATA: ${btlayer}"
+	chmod -R 777 ${btlayer}
 	rm -f -r ${btlayer}
     fi
 
@@ -86,7 +88,7 @@ buildtest() {
 	fi
     else
         echo "Build Failed. Last log lines are:"
-        tail -5 ${log}
+        tail -20 ${log}
 	globalResult=1
     fi
 
@@ -0,0 +1,14 @@
+## Special run - to be done before all others...
+#
+## locate the sources and go there...
+topb=`dirname $0`
+topc=`dirname ${topb}`
+cd ${topc}
+
+# echo "DEBUG: top=${top}"
+# echo "DEBUG: topB=${topb}"
+# echo "DEBUG: topC=${topc}"
+
+## Bootstrap the sources in case configure or makefiles changed.
+./bootstrap.sh
+exit $?
@@ -1,5 +1,11 @@
 #!/bin/sh
 while read request; do
+case $request in
+*SLEEP=*)
+	sleep `echo $request | sed -e 's/.*SLEEP=\([^;]*\).*/\1/'`
+	request=`echo $request | sed -e 's/SLEEP=[^;]*;*//'`
+	;;
+esac
 data="`echo $request | cut -c4-`"
 blob="$$.$data-$challenge.`date +%s`"
 case $request in
@@ -1,5 +1,11 @@
 #!/bin/sh
 while read request; do
+case $request in
+*SLEEP=*)
+	sleep `echo $request | sed -e 's/.*SLEEP=\([^;]*\).*/\1/'`
+	request=`echo $request | sed -e 's/SLEEP=[^;]*;*//'`
+	;;
+esac
 data="`echo $request | cut -c4-`"
 blob="$$.$data-$challenge.`date +%s`"
 case $request in
@@ -8,10 +8,11 @@ if [ $# -lt 1 ]; then
     exit 1
 fi
 
-echo "blob		# partial message"
-echo "USER=...		# Success"
-echo "BAD..		# Login failure"
-echo "ERR..		# Failure"
+echo   "blob		# partial message"
+echo   "SLEEP=..	# Delay. Can be combined with the others by using ;"
+echo   "USER=...	# Success"
+echo   "BAD..		# Helper failure"
+echo   "ERR..		# Login Failure"
 
 while read auth; do
 	echo "GET $url HTTP/1.0"
@@ -8,10 +8,11 @@ if [ $# -lt 1 ]; then
     exit 1
 fi
 
-echo "blob		# partial message"
-echo "USER=...		# Success"
-echo "BAD..		# Login failure"
-echo "ERR..		# Failure"
+echo   "blob		# partial message"
+echo   "SLEEP=..	# Delay. Can be combined with the others by using ;"
+echo   "USER=...	# Success"
+echo   "BAD..		# Helper failure"
+echo   "ERR..		# Login Failure"
 
 while read auth; do
 	echo "GET $url HTTP/1.0"
@@ -43,7 +43,7 @@ squidclient -- a simple HTTP web client
 .B squidclient
 is a tool providing a command line interface for retrieving URLs.
 Designed for testing any HTTP 0.9, 1.0, or 1.1 web server or proxy.
-This tool can be combined scripts to perform any basic HTTP operation.
+This tool can be combined with scripts to perform any basic HTTP operation.
 Some additional features for access to the 
 .B Squid
 proxy object cache and management information are provided.