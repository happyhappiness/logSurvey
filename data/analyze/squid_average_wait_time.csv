url,date,title,changes,file_name,reason_for_consistence,is_trivial,old_hunk_file,new_hunk_file,old_loc,new_loc,old_log,new_log,edit_types,edit_words,edit_feature,cluster,wait_time,cluster_size
https://github.com/squid-cache/squid/commit/721dcff0234670725c0d081aae71fa333d463006,29 May 2015,Fix eCAP issues after rev.14093,6,data/crawl/squid/hunk_702.cpp,invoke same log method,non-trivial,data/crawl/squid/old_hunk_702.cpp,data/crawl/squid/new_hunk_702.cpp,3,3,"buf.Printf(""M%d"", static_cast<int>(makingVb));","buf.appendf(""M%d"", static_cast<int>(makingVb));","[""updateLog""]","[[""Printf""], [""appendf""]]",[-403317783590601070],7733,64178.6301369863,438
https://github.com/squid-cache/squid/commit/912864c28eac63534ad0d0615cac8f665f219b94,08 Jan 2017,"Cleanup: remove ip/Qos.cci file

... moving its content to ip/QosConfig.cc

Also, move the stub file to src/tests/stub_libip.cc and update to use
tests/STUB.h interface.",404,data/crawl/squid/hunk_101.cpp,inner similar method,non-trivial,data/crawl/squid/old_hunk_101.cpp,data/crawl/squid/new_hunk_101.cpp,17,-1,"fatal (""Not implemented"");",,"[""removeLog""]","[[""fatal"", ""Not"", ""implemented""], []]",[8889578217720560850],7731,7742373.333333333,162
https://github.com/squid-cache/squid/commit/fa2301d26b90cbd1298eb7740e8827c7746cd9d2,01 Jan 2014,"Initial Large Rock and Collapsed Forwarding support.

Large Rock: Support disk (and shared memory) caching of responses exceeding
one db slot (or one shared memory page) in size. A single db slot/page size is
still limited to 32KB (smaller values can be configured for disk caches using
the newly added cache_dir slot-size option). Removal of old rock cache dir
(followed by squid-z) is required -- the on-disk db structure has changed.

Collapsed Forwarding: Optionally merge concurrent cachable requests for the
same URI earlier: After the request headers have been parsed (as before), but
now _before_ the response headers have been received. Merging of requests
received by different SMP workers is supported. Controlled by the new
collapsed_forwarding directive in squid.conf. Disabled by default because all
but one of the merged requests have to be delayed (until the response headers
are received) for the merging to work, which may be worse than forwarding all
concurrent requests immediately. The overall feature idea and request
eligibility conditions are based on Collapsed Forwarding in Squid2.


Summary of other important changes (merged branch log contains the details):

* Tightened StoreEntry locking. Split StoreEntry::lock() into ""just lock"" and
  ""update entry reference time"" interfaces, addressing an old XXX.  Improved
  entry lock/unlock debugging. Needs more work.

* Adjusted StoreIOState::write() API to allow callers detect write errors.

* Simplified MemObject::write() API to remove an essentially unused callback.

* Mark client streams that sent everything as STREAM_COMPLETE. The old code
  used STREAM_UNPLANNED_COMPLETE if the completed stream was associated with a
  non-persistent connection, which did not make sense to me and, IIRC, led to
  store entry aborts even though the entries were not damaged in any way.

* mem_hdr::hasContigousContentRange() now returns true for empty ranges.

* Support ""appending"" ReadWriteLock state that can be shared by readers and
  the writer. The writer promises not to update key metadata (except growing
  object size and next pointers) and readers promise to be careful when
  reading growing slices.

* Fixed StoreEntry::mayStartSwapOut() logic to handle terminated swapouts.

* Improved STORE_MEM_CLIENT detection and documented known (and mostly old)
  StoreEntry::storeClientType() problems.

* Removed StoreEntry::hidden_mem_obj hack.

* Polished StoreEntry debugging to report more info, less noise. Use e: prefix.

* Added a script to extract store entry(ies) debugging from cache.log.",6196,data/crawl/squid/hunk_1641.cpp,inner similar method,non-trivial,data/crawl/squid/old_hunk_1641.cpp,data/crawl/squid/new_hunk_1641.cpp,-1,147,,"fatal(""not implemented"");","[""addLog""]","[[], [""fatal"", ""not"", ""implemented""]]",[-8889578217720560850],7730,5487312.475247525,101
https://github.com/squid-cache/squid/commit/0bffe3cec1400f4d69724552e77e77878defd8a3,23 May 2016,"Sync with trunk-r14686

- Replaces with newer versions of BinaryTokenizer and HandshakeParser classes
- Modifications to use latest Handshake parser from trunk.
- Get HandshakeParser::serverCertificates, HandshakeParser::parseServerCertificates and HandshakeParser::ParseCertificate implementation from lp:fast-sni branch",6170,data/crawl/squid/hunk_175.cpp,invoke same method,non-trivial,data/crawl/squid/old_hunk_175.cpp,data/crawl/squid/new_hunk_175.cpp,3,4,"fprintf(stderr, ""%s: FATAL: Unable to open file '%s': %s"", program_name, filename, xstrerror());","fprintf(stderr, ""%s: FATAL: Unable to open file '%s': %s"", program_name, filename, xstrerr(xerrno));","[""updateVariable"", ""addVariable""]","[[""xstrerror""], [""xstrerr"", ""xerrno""]]",[-692937571753102809],7729,43200.0,87
https://github.com/squid-cache/squid/commit/c152a4473c4a3d187f67923eb83c5fe6ccd91013,12 Jul 2010,"Helpers: Naming and C++ update for external ACL helpers

 * Also adds the Fake auth helper for testing Basic authentication.
 * Also adds manual pages for most external ACL helpers

TODO: test for and fix any build issues on Windows.",2485,data/crawl/squid/hunk_3152.cpp,check similar variable,trivial,data/crawl/squid/old_hunk_3152.cpp,data/crawl/squid/new_hunk_3152.cpp,10,9,"fprintf(stderr, ""Connected OK\n"");","debug(""Connected OK\n"");","[""updateLog"", ""removeVariable""]","[[""fprintf"", ""stderr""], [""debug""]]",[21637425830572660846],7728,282970.74626865675,67
https://github.com/squid-cache/squid/commit/445d18a460422224933c2d3b964dce27270bb402,18 May 2009,"Move ASN handling for ACL into ACL area.

This removes one possble compile clash, and one empty file.",1279,data/crawl/squid/hunk_3765.cpp,block change,non-trivial,data/crawl/squid/old_hunk_3765.cpp,data/crawl/squid/new_hunk_3765.cpp,-1,500,,"storeAppendPrintf(sentry, ""\n"");","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""\\n""]]",[6080590955771865090],7727,1490251.0344827587,58
https://github.com/squid-cache/squid/commit/5d3aafbed3edd9d4cc50d9f276010c51c6b942fe,20 Feb 2017,Sync with v5 rev.15058,1995,data/crawl/squid/hunk_41.cpp,block change,non-trivial,data/crawl/squid/old_hunk_41.cpp,data/crawl/squid/new_hunk_41.cpp,-1,106,,"storeAppendPrintf(entry, ""\n"");","[""addLog""]","[[], [""storeAppendPrintf"", ""entry"", ""\\n""]]",[3924684621819481232],7726,5620736.0,45
https://github.com/squid-cache/squid/commit/1c8f25bbb056368c4405473ff7304156608e92cc,17 Jun 2011,"Upgrade comm layer Connection handling

The premise underlying this large patch is that instead of copying and
re-copying and re-lookups for the FD related data we can take the
ConnectionDetail class which is generated to store a few bits of IP
information about newly accept()'d connections and make it persist across
the whole of Squid.

It has been renamed from ConnectionDetails to Comm::Connection and has
absorbed a few FD data fields from other classes long the code paths.
Its scope is to hold an FD (or potential FD) plus meta data.

Comm::Connection are valid before, during and after the period when their
particular FD is open. The meta data may be used beforehand to setup the
FD (in the case of peer selection or other TcpAcceptor usage), and it may
remain in use after FD closure until logging or all linked job and call
objects have detected the closure and terminated. A global function
Comm::IsConnOpen() may be used on the pointer objects to detect whether
they point at an active connection.

Most of the patch is simple parameter changes to functions and methods to
pass a ""cont Comm::ConnectionPointer &"" instead of an ""int FD"". Along with
class FD fields being converted to these object pointers.


In order to support this alteration there have been behavioral changes to:

The socket accept() Job
  Comm::TcpAcceptor altered to spawn Comm::Connection objects and to
  operate with one controlling their active/closed state.

FTP data channel handling Calls.
  efficiency improvements making use of Comm::Connection as a feedback
  channel between TcpAcceptor and FtpStateData to cancel the listening
  Job. Most of the underlying logic change is already in trunk to use
  the Subscription API. This just streamlines and fixes some race bugs.

Peer selection
  updated to spawn a set of Comm::Connection objects. To do this it is
  updated to determine *all* peers including DIRECT ones. Doing the DNS
  lookup instead of leaving it to comm_connect() on the other side of
  FwdState. It also absorbs the outgoing address selection from FwdState
  and can now specify details of local+remote ends of an outgoing TCP link.

Forwarding
  updated to handle the new outputs from peer selection and to open sequentially.

pconn handling
  updated to use destination IP/port and hold a Comm::Connection instead
  of domain name indexing an FD. This allows us to maintain idle pools
  and re-use FD more efficiently with virtual-hosted servers. Along
  with maintaining certainty that the pconn selected actually goes to
  the exact destination IP:port needed by forwarding.

comm layer outgoing connections
  now have a control job Comm::ConnOpener to do this. Due to the peer
  selection and forwarding changes this is a much simpler operation.

HTTP / CONNECT tunnel / gopher / whois / FTP
  updated to receive a server and client Comm::Connection object from
  forwarding. To operate on those until they close or are finished with.

SNMP / ICP / HTCP / DNS port listeners
  updated to work with Comm::Connection holding their listening socket
  meta data. This is a side-effect of the ICP and Comm read/write/timeout
  changes.",8518,data/crawl/squid/hunk_2578.cpp,inner similar method,non-trivial,data/crawl/squid/old_hunk_2578.cpp,data/crawl/squid/new_hunk_2578.cpp,-1,10,,"fatal(""pconn.cc required"");","[""addLog""]","[[], [""fatal"", ""pconn"", ""cc"", ""required""]]",[-13636338255685932867],7725,79508.57142857143,42
https://github.com/squid-cache/squid/commit/9e6e0372016a2d16124516049b5b9cd0ae9c52f8,17 May 2008,"Windows port: Added new mswin_check_ad_group external ACL helper

This helper allow the lookup of users's group membership in a Windows
Active Directory domain.
It overcomes the Lan Manager limits of mswin_check_lm_group, but it can be
used only with native Windows Active Directory domains, so mswin_check_lm_group 
will not removed from Squid.",669,data/crawl/squid/hunk_4289.cpp,check similar return value,non-trivial,data/crawl/squid/old_hunk_4289.cpp,data/crawl/squid/new_hunk_4289.cpp,-1,479,,"printf(""ERR\n"");","[""addLog""]","[[], [""printf"", ""ERR\\n""]]",[15522548339914942793],7724,1646236.0975609757,41
https://github.com/squid-cache/squid/commit/15576b6a58a24ed2705d6228d0fde8cfcef26cae,07 Feb 1998,remove brackets from cachemgr output,390,data/crawl/squid/hunk_6814.cpp,use same text,non-trivial,data/crawl/squid/old_hunk_6814.cpp,data/crawl/squid/new_hunk_6814.cpp,8,8,"storeAppendPrintf(sentry, ""{    ICP Requests %d}\n"",
	    c->Icp.n_requests);","storeAppendPrintf(sentry, ""    ICP Requests %d\n"",
	    c->Icp.n_requests);","[""updateContent""]","[[""%d"", ""\\n""], [""%d\\n""]]",[6128436140151560348],7723,0.0,34
https://github.com/squid-cache/squid/commit/ac5de05bed05906909d7ccc894f940438b8a9967,29 Sep 2010,"Bug 3051: integer display overflow

This alters the cachemgr display formatting to use 64-bit integers
instead of 32-bit. Revealing overflows hiding behind display overflows.",302,data/crawl/squid/hunk_3018.cpp,use same variable,non-trivial,data/crawl/squid/old_hunk_3018.cpp,data/crawl/squid/new_hunk_3018.cpp,9,9,"storeAppendPrintf(sentry, ""client_http.kbytes_in = %d\n"",
                      (int) f->client_http.kbytes_in.kb);","storeAppendPrintf(sentry, ""client_http.kbytes_in = %ld\n"",
                      (long)f->client_http.kbytes_in.kb);","[""updateVariable"", ""updateContent""]","[[""%d\\n"", ""int""], [""%ld\\n"", ""long""]]",[5116502832370718979],7722,0.0,29
https://github.com/squid-cache/squid/commit/4ef877d67aaff7156b5611db55b45cb7c57a0120,06 Feb 2009,"Author: Francesco Chemolli <kinkie@squid-cache.org>
String NG : fixes initial merge, take 2

Compared to the retired first attempt it:
 - fixes the issues Tsantilas Christos found out about
 - implements String::find
 - some more users analyzed and fixed.",654,data/crawl/squid/hunk_3920.cpp,invoke same method,trivial,data/crawl/squid/old_hunk_3920.cpp,data/crawl/squid/new_hunk_3920.cpp,3,3,"storeAppendPrintf(entry, "" %s:"", tag.buf());","storeAppendPrintf(entry, "" %s:"", tag.unsafeBuf());","[""updateVariable""]","[[""buf""], [""unsafeBuf""]]",[2412284708412051408],7721,3110.4,25
https://github.com/squid-cache/squid/commit/bb64d87960915b8f4e5ba159049d5c9d5e545e01,30 Dec 2014,Fix 'field precision specifier '.*' expects argument of type 'int',20,data/crawl/squid/hunk_1081.cpp,use same text format,non-trivial,data/crawl/squid/old_hunk_1081.cpp,data/crawl/squid/new_hunk_1081.cpp,3,3,"buf.Printf(""Proxy-Authorization: Basic %.*s\r\n"", resultLen, base64buf);","buf.Printf(""Proxy-Authorization: Basic %.*s\r\n"", (int)resultLen, base64buf);","[""addVariable""]","[[], [""int""]]",[-7555364370854764664],7720,4141843.2,25
https://github.com/squid-cache/squid/commit/ba1b862c8e2fb4ac6002432c2f16041119c02758,29 May 2014,merge from trunk r13423,5144,data/crawl/squid/hunk_1382.cpp,check similar variable,non-trivial,data/crawl/squid/old_hunk_1382.cpp,data/crawl/squid/new_hunk_1382.cpp,-1,4,,"printf(""%u "", requestData->channelId);","[""addLog""]","[[], [""printf"", ""%u"", ""requestData"", ""channelId""]]",[3098921161029892682],7719,23400.0,24
https://github.com/squid-cache/squid/commit/1071ffed56172406d771265af76d8273ffcdb89e,26 May 2015,"Replace Packer object API with Packable API

Majority of thost patch is symbol renaming to unify the
class method names to the Packable API names.

There is effectively no logical change in this patch
despite appearances because it replaces the Packer object
which provides methods which are just wrappers pointing
to static functions which are in turn wrappers pointing
to storage buffer object methods. With direct calls to
those storage object methods (renamed).

We can now interchangebly use MemBuf or StoreEntry objects
with the packInto(Packable *) functions. Or any other
object which inherits and implements the Packable API.

We also gain 0.1% in performance (+2 RPS) by avoiding the
layers of wrapper funcions and Packer object allocate / 
deallocate cycles.",1141,data/crawl/squid/hunk_732.cpp,invoke same log method,non-trivial,data/crawl/squid/old_hunk_732.cpp,data/crawl/squid/new_hunk_732.cpp,5,5,"mb.Printf(""\r\n"");","mb.append(""\r\n"", 2);","[""updateLog"", ""addContent""]","[[""Printf""], [""append"", ""2""]]",[-16152299998899699014],7718,63860.86956521739,23
https://github.com/squid-cache/squid/commit/253caccb08f5a5a23ec0c9b89272145213c09ec0,26 Jan 2006,"The purpose of this change is to add ICAP RESPMOD support for FTP responses.

I created a ""ServerStateData"" class which has common elements of both
HttpStateData and FtpStateData.  It becomes a base class for both
of them.  ICAP now uses the ServerStateData methods.",643,data/crawl/squid/hunk_4884.cpp,invoke same log method,trivial,data/crawl/squid/old_hunk_4884.cpp,data/crawl/squid/new_hunk_4884.cpp,8,10,"storeAppendPrintf(entry, ""<!-- HTML listing generated by Squid %s -->\n"",
                      version_string);","printfReplyBody(""<!-- HTML listing generated by Squid %s -->\n"",
                    version_string);","[""updateLog"", ""removeVariable""]","[[""storeAppendPrintf"", ""entry""], [""printfReplyBody""]]",[-4645287094243982784],7717,0.0,22
https://github.com/squid-cache/squid/commit/5c7a6e90a7d87963e81a67ee8143eeb998ade3a9,06 Oct 2008,"Author: Markus Moeller <markus_moeller@compuserve.com>
Update squid_kerb_auth helper to 1.0.3 release

Also add missing config.test file (empty) so
 --enable-negotiate-auth-helpers=X will build it with Squid.


  squid_kerb_auth 1.0.3 Official ReadMe file:

--------------------------------------------------------------------------------
readme.txt is the squid_kerb_auth read-me file.

Author: Markus Moeller (markus_moeller at compuserve.com)

Copyright (C) 2007 Markus Moeller. All rights reserved.
--------------------------------------------------------------------------------

squid_kerb_auth Read Me

Markus Moeller
May 12, 2007

1 Introduction

squid_kerb_auth is a reference implementation that supports authentication via 
the Negotiate RFC 4559 for proxies. It decodes RFC 2478 SPNEGO GSS-API tokens 
from IE7 either through helper functions or via SPNEGO supporting Kerberos libraries
and RFC 1964 Kerberos tokens from Firefox on Linux. Currently, squid_kerb_auth
 supports Squid 2.6 on Linux. 

squid_auth_kerb requires either MIT or Heimdal Kerberos libraries and header files.

2 Building and Installation

Run ./configure

for help use ./configure --help

Copy the helper squid_kerb_auth to an apropriate directory.

3 Configuration

a) Configure IE or Firefox to point to the squid proxy by using the fqdn. IE and Firefox will use the
fqdn to query for a HTTP/fqdn Kerberos service principal. 

b) Create a keytab which contains the HTTP/fqdn Kerberos service principal and place it into a directory
where the squid run user can read the keytab. 

c) Add the following line to squid.conf

auth_param negotiate program /usr/sbin/squid_kerb_auth 
auth_param negotiate children 10
auth_param negotiate keep_alive on

d) Modify squid startup file

Add the following lines to the squid startup script to point squid to a keytab file which
contains the HTTP/fqdn service principal for the default Kerberos domain. The fqdn must be 
the proxy name set in IE or firefox. You can not use an IP address.

KRB5_KTNAME=/etc/squid/HTTP.keytab
export KRB5_KTNAME

If you use a different Kerberos domain than the machine itself is in you can point squid to 
the seperate Kerberos config file by setting the following environmnet variable in the startup 
script.

KRB5_CONFIG=/etc/krb-squid5.conf
export KRB5_CONFIG

4 Miscellaneous

If squid_kerb_auth doesn't determine for some reason the right service principal you can provide 
it with -s HTTP/fqdn.

If you serve multiple Kerberos realms add a HTTP/fqdn@REALM service principal per realm to the 
HTTP.keytab file and use the -s GSS_C_NO_NAME option with squid_kerb_auth.",1834,data/crawl/squid/hunk_4154.cpp,use same text,non-trivial,data/crawl/squid/old_hunk_4154.cpp,data/crawl/squid/new_hunk_4154.cpp,5,5,"fprintf(stdout, ""NA %s failed: %s\n"",function, buf);","fprintf(stdout, ""BH %s failed: %s\n"",function, buf);","[""updateContent""]","[[""NA""], [""BH""]]",[-1536009228013789],7716,2160.0,22
https://github.com/squid-cache/squid/commit/ac5de05bed05906909d7ccc894f940438b8a9967,29 Sep 2010,"Bug 3051: integer display overflow

This alters the cachemgr display formatting to use 64-bit integers
instead of 32-bit. Revealing overflows hiding behind display overflows.",302,data/crawl/squid/hunk_3014.cpp,use same variable,non-trivial,data/crawl/squid/old_hunk_3014.cpp,data/crawl/squid/new_hunk_3014.cpp,6,6,"storeAppendPrintf(sentry, ""\tPage faults with physical i/o: %d\n"",
                      rusage_pagefaults(&rusage));","storeAppendPrintf(sentry, ""\tPage faults with physical i/o: %ld\n"",
                      (long)rusage_pagefaults(&rusage));","[""updateContent"", ""addVariable""]","[[""%d\\n""], [""%ld\\n"", ""long""]]",[-2438861538484045685],7715,0.0,22
https://github.com/squid-cache/squid/commit/bf3e8d5a0de0f6f59996d1a8fb88402ba2273ede,05 Jun 2015,"SourceLayout: convert helper stats display to Packable API

Requires unifying the classes Helper::Request queues which incidentally
also brings stateful helpers closer to concurrency support",192,data/crawl/squid/hunk_692.cpp,block change,non-trivial,data/crawl/squid/old_hunk_692.cpp,data/crawl/squid/new_hunk_692.cpp,34,-1,"storeAppendPrintf(sentry, ""\n"");",,"[""removeLog""]","[[""storeAppendPrintf"", ""sentry"", ""\\n""], []]",[-6080590955771865090],7714,2983745.4545454546,22
https://github.com/squid-cache/squid/commit/30abd2216c340de83251e6e42e6566de0fd23766,29 May 2007,Rollback String API changes. Delayed to 3.1.,2195,data/crawl/squid/hunk_4558.cpp,invoke same method,trivial,data/crawl/squid/old_hunk_4558.cpp,data/crawl/squid/new_hunk_4558.cpp,3,3,"storeAppendPrintf(entry, "" %s:"", tag.c_str());","storeAppendPrintf(entry, "" %s:"", tag.buf());","[""updateVariable""]","[[""c_str""], [""buf""]]",[-277036821796306822],7713,0.0,21
https://github.com/squid-cache/squid/commit/081edc2de252e852d0a8e02891fb36d7919a92ef,07 Jan 2012,"Cleanup: update most of the existing stub files to use the STUB.h framework

There are still several sections to be done. Including adding library API
stubs. However these are the ones which can be done immediately without 
breaking or re-writing existing unit tests.",2058,data/crawl/squid/hunk_2353.cpp,inner similar method,non-trivial,data/crawl/squid/old_hunk_2353.cpp,data/crawl/squid/new_hunk_2353.cpp,10,-1,"fatal(""pconn.cc required"");",,"[""removeLog""]","[[""fatal"", ""pconn"", ""cc"", ""required""], []]",[13636338255685932867],7712,0.0,21
https://github.com/squid-cache/squid/commit/86c0aed6f3d6225d2769d5eee25eb4d1d7eb1e44,18 May 2007,"Add string API layer for better string handling.

For various reasons listed below we adopt the std::string API (but not the implementation) as the basis for string operations.

This patch reverts the SquidString.h file to provide only the main API and hooks for any string implementation behind the API.

For Release 3.0 the old String (now SqString) will remain the default string core.
That code has been kept in this patch with some minor modifications and bug fixes as listed below.

For Release 3.1 it is expected that a better string core will be developed.

Reasons for these changes:

The initial String implementation was incomplete and non-standard causing some risky operations at points in the code and duplicated some operations.
std::string provides a better known API for string handling which is widely use amongst other string implementations beyond std::string itself and this enables std::string or a derivative to be used in squid at some future date.
String as used previously is a defined alternative to std::string in some systems

This patch:
   - moves the old String class to SqString
   - provides the well-known type of 'string' for general use
   - provides implicit conversion from char* and char[] types
   - migrates custom functions to well-known API:
       buf()           -> c_str()
       clean()         -> clear()
   - removes redundant functions:
       buf(char*)      -> operator=(char*)
       initBuf(char*)  -> operator=(char*)
       reset(char*)    -> operator=(char*)
   - adds well-known API methods for safer string use:
       operator []
       empty()
       operator <<
       strcmp(), strcasecmp(), etc
   - May fix bug #1088 - segmentation fault after append(char*,int)
   - Fixes several unreported char* handling bugs in String/SqString",2203,data/crawl/squid/hunk_4592.cpp,invoke same method,trivial,data/crawl/squid/old_hunk_4592.cpp,data/crawl/squid/new_hunk_4592.cpp,3,3,"storeAppendPrintf(entry, "" %s:"", tag.buf());","storeAppendPrintf(entry, "" %s:"", tag.c_str());","[""updateVariable""]","[[""buf""], [""c_str""]]",[277036821796306822],7711,0.0,20
https://github.com/squid-cache/squid/commit/a98bcbee0005004c1aa26042060eb1dd7dad482b,02 Dec 2009,"Shuffle simple math functions into SquidMath

This unlinks many depencies pulled in by tools.cc through the more
complicated permissions, and death reporting code.",230,data/crawl/squid/hunk_3474.cpp,invoke same method,non-trivial,data/crawl/squid/old_hunk_3474.cpp,data/crawl/squid/new_hunk_3474.cpp,3,3,"storeAppendPrintf(sentry,
                              ""        %-20.20s %7d %3d%%\n"",
                              log_tags[l],
                              c->Icp.result_hist[l],
                              percent(c->Icp.result_hist[l], c->Icp.n_requests));","storeAppendPrintf(sentry, ""        %-20.20s %7d %3d%%\n"",log_tags[l], c->Icp.result_hist[l], Math::intPercent(c->Icp.result_hist[l], c->Icp.n_requests));","[""removeVariable"", ""addVariable""]","[[""percent""], [""Math"", ""intPercent""]]",[-11117553028743557694],7710,0.0,20
https://github.com/squid-cache/squid/commit/1c8f25bbb056368c4405473ff7304156608e92cc,17 Jun 2011,"Upgrade comm layer Connection handling

The premise underlying this large patch is that instead of copying and
re-copying and re-lookups for the FD related data we can take the
ConnectionDetail class which is generated to store a few bits of IP
information about newly accept()'d connections and make it persist across
the whole of Squid.

It has been renamed from ConnectionDetails to Comm::Connection and has
absorbed a few FD data fields from other classes long the code paths.
Its scope is to hold an FD (or potential FD) plus meta data.

Comm::Connection are valid before, during and after the period when their
particular FD is open. The meta data may be used beforehand to setup the
FD (in the case of peer selection or other TcpAcceptor usage), and it may
remain in use after FD closure until logging or all linked job and call
objects have detected the closure and terminated. A global function
Comm::IsConnOpen() may be used on the pointer objects to detect whether
they point at an active connection.

Most of the patch is simple parameter changes to functions and methods to
pass a ""cont Comm::ConnectionPointer &"" instead of an ""int FD"". Along with
class FD fields being converted to these object pointers.


In order to support this alteration there have been behavioral changes to:

The socket accept() Job
  Comm::TcpAcceptor altered to spawn Comm::Connection objects and to
  operate with one controlling their active/closed state.

FTP data channel handling Calls.
  efficiency improvements making use of Comm::Connection as a feedback
  channel between TcpAcceptor and FtpStateData to cancel the listening
  Job. Most of the underlying logic change is already in trunk to use
  the Subscription API. This just streamlines and fixes some race bugs.

Peer selection
  updated to spawn a set of Comm::Connection objects. To do this it is
  updated to determine *all* peers including DIRECT ones. Doing the DNS
  lookup instead of leaving it to comm_connect() on the other side of
  FwdState. It also absorbs the outgoing address selection from FwdState
  and can now specify details of local+remote ends of an outgoing TCP link.

Forwarding
  updated to handle the new outputs from peer selection and to open sequentially.

pconn handling
  updated to use destination IP/port and hold a Comm::Connection instead
  of domain name indexing an FD. This allows us to maintain idle pools
  and re-use FD more efficiently with virtual-hosted servers. Along
  with maintaining certainty that the pconn selected actually goes to
  the exact destination IP:port needed by forwarding.

comm layer outgoing connections
  now have a control job Comm::ConnOpener to do this. Due to the peer
  selection and forwarding changes this is a much simpler operation.

HTTP / CONNECT tunnel / gopher / whois / FTP
  updated to receive a server and client Comm::Connection object from
  forwarding. To operate on those until they close or are finished with.

SNMP / ICP / HTCP / DNS port listeners
  updated to work with Comm::Connection holding their listening socket
  meta data. This is a side-effect of the ICP and Comm read/write/timeout
  changes.",8518,data/crawl/squid/hunk_2572.cpp,inner similar method,non-trivial,data/crawl/squid/old_hunk_2572.cpp,data/crawl/squid/new_hunk_2572.cpp,-1,7,,"fatal(""client_db.cc required"");","[""addLog""]","[[], [""fatal"", ""client_db"", ""cc"", ""required""]]",[-11584999754346286923],7709,76320.0,20
https://github.com/squid-cache/squid/commit/ce66013b40dad272f568df241b6f1fb238cec97f,13 Nov 1997,remove fatal_dump calls,59,data/crawl/squid/hunk_6975.cpp,check similar variable,non-trivial,data/crawl/squid/old_hunk_6975.cpp,data/crawl/squid/new_hunk_6975.cpp,7,-1,fatal_dump(NULL);,,"[""removeLog""]","[[""fatal_dump"", ""NULL""], []]",[12879563083587916188],7708,395772.63157894736,19
https://github.com/squid-cache/squid/commit/0ee4272be86c64bd8eedf6f662f63f61f8203e13,05 Nov 1996,massive const patch from Markus Gyger,1167,data/crawl/squid/hunk_7446.cpp,use same text,non-trivial,data/crawl/squid/old_hunk_7446.cpp,data/crawl/squid/new_hunk_7446.cpp,-1,30,,"storeAppendPrintf(sentry, close_bracket);","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""close_bracket""]]",[14804266055628296458],7707,60564.705882352944,17
https://github.com/squid-cache/squid/commit/4a218c947937e0f0793716970a258980a789f2ce,22 Nov 1996,change to debug_trap,5,data/crawl/squid/hunk_7430.cpp,invoke same log method,non-trivial,data/crawl/squid/old_hunk_7430.cpp,data/crawl/squid/new_hunk_7430.cpp,3,4,"fatal_dump(""Invalid dnsserver output"");","debug_trap(""Invalid dnsserver output"");","[""updateLog""]","[[""fatal_dump""], [""debug_trap""]]",[12404155701656691210],7706,8809.411764705883,17
https://github.com/squid-cache/squid/commit/15576b6a58a24ed2705d6228d0fde8cfcef26cae,07 Feb 1998,remove brackets from cachemgr output,390,data/crawl/squid/hunk_6814.cpp,use same text,non-trivial,data/crawl/squid/old_hunk_6814.cpp,data/crawl/squid/new_hunk_6814.cpp,33,-1,"storeAppendPrintf(sentry, close_bracket);",,"[""removeLog""]","[[""storeAppendPrintf"", ""sentry"", ""close_bracket""], []]",[-14804266055628296458],7705,652997.6470588235,17
https://github.com/squid-cache/squid/commit/9e4ad609cdc6849a20b298e7c2437007109b80fc,05 May 1997,"- DO NOT set the filemap bits for unvalidated entries.  Doing so
  causes lots of race-condition problems, especially when reading
  DIRTY logs.
- Install icpDetectClientClose handler earlier.  Move from access check
  to just after reading the request.
- Log open FD's upon exit.
- Added dnsShutdownRead handler to detect dnsserver shutdowns and
  free up state.
- Added doubleAverage and integerAverage for moving average
  calculations.
- misc prototype cleanup
- misc debug_trap's and fatal_dump's
- Removed some thread splitting for fooStartComplete() because
  the various protcol start routines should never need a swapin
  callback.  The object should already be locked and swapped in.
- queue_length counter for IP cache.
- Make it okay to storeUnlock a pending object, so long as its
  not been DISPATCHED yet.
- fixed hybrid store rebuild code.
- fixed file_open() flags to TRUNC new swaplog's
- Claned up wierd (FILE *) stuff in tools.c, always write to
  debug_log().
- rewrote writePidFile() to use file_open().",505,data/crawl/squid/hunk_7265.cpp,use same variable,non-trivial,data/crawl/squid/old_hunk_7265.cpp,data/crawl/squid/new_hunk_7265.cpp,11,11,"fprintf(f, ""Memory usage for %s via mallinfo():\n"", appname);","fprintf(debug_log, ""Memory usage for %s via mallinfo():\n"", appname);","[""updateVariable""]","[[""f""], [""debug_log""]]",[-1054936003883337168],7704,0.0,15
https://github.com/squid-cache/squid/commit/15576b6a58a24ed2705d6228d0fde8cfcef26cae,07 Feb 1998,remove brackets from cachemgr output,390,data/crawl/squid/hunk_6829.cpp,use same text,non-trivial,data/crawl/squid/old_hunk_6829.cpp,data/crawl/squid/new_hunk_6829.cpp,30,29,"storeAppendPrintf(sentry, ""{\tStorage Swap size:\t%d KB}\n"",
	store_swap_size);","storeAppendPrintf(sentry, ""\tStorage Swap size:\t%d KB\n"",
	store_swap_size);","[""updateContent""]","[[""KB"", ""\\n""], [""KB\\n""]]",[1791130042753803100],7703,0.0,15
https://github.com/squid-cache/squid/commit/9e6e0372016a2d16124516049b5b9cd0ae9c52f8,17 May 2008,"Windows port: Added new mswin_check_ad_group external ACL helper

This helper allow the lookup of users's group membership in a Windows
Active Directory domain.
It overcomes the Lan Manager limits of mswin_check_lm_group, but it can be
used only with native Windows Active Directory domains, so mswin_check_lm_group 
will not removed from Squid.",669,data/crawl/squid/hunk_4289.cpp,block change,non-trivial,data/crawl/squid/old_hunk_4289.cpp,data/crawl/squid/new_hunk_4289.cpp,-1,476,,"printf(""OK\n"");","[""addLog""]","[[], [""printf"", ""OK\\n""]]",[7225515199027138487],7702,2014656.0,15
https://github.com/squid-cache/squid/commit/c152a4473c4a3d187f67923eb83c5fe6ccd91013,12 Jul 2010,"Helpers: Naming and C++ update for external ACL helpers

 * Also adds the Fake auth helper for testing Basic authentication.
 * Also adds manual pages for most external ACL helpers

TODO: test for and fix any build issues on Windows.",2485,data/crawl/squid/hunk_3150.cpp,check similar return value,non-trivial,data/crawl/squid/old_hunk_3150.cpp,data/crawl/squid/new_hunk_3150.cpp,3,3,"fprintf(stderr, ""Could not set LDAP_OPT_PROTOCOL_VERSION %d\n"",
                            version);","fprintf(stderr, ""ERROR: Could not set LDAP_OPT_PROTOCOL_VERSION %d\n"",
                            version);","[""updateContent""]","[[], [""ERROR""]]",[8285138784999380343],7701,86400.0,15
https://github.com/squid-cache/squid/commit/c152a4473c4a3d187f67923eb83c5fe6ccd91013,12 Jul 2010,"Helpers: Naming and C++ update for external ACL helpers

 * Also adds the Fake auth helper for testing Basic authentication.
 * Also adds manual pages for most external ACL helpers

TODO: test for and fix any build issues on Windows.",2485,data/crawl/squid/hunk_3145.cpp,check similar return value,non-trivial,data/crawl/squid/old_hunk_3145.cpp,data/crawl/squid/new_hunk_3145.cpp,3,3,"fprintf(stderr, ""Protocol version should be 2 or 3\n"");","fprintf(stderr, ""FATAL: Protocol version should be 2 or 3\n"");","[""updateContent""]","[[], [""FATAL""]]",[-4947173928198612933],7700,181536.0,15
https://github.com/squid-cache/squid/commit/c152a4473c4a3d187f67923eb83c5fe6ccd91013,12 Jul 2010,"Helpers: Naming and C++ update for external ACL helpers

 * Also adds the Fake auth helper for testing Basic authentication.
 * Also adds manual pages for most external ACL helpers

TODO: test for and fix any build issues on Windows.",2485,data/crawl/squid/hunk_3133.cpp,use same text,trivial,data/crawl/squid/old_hunk_3133.cpp,data/crawl/squid/new_hunk_3133.cpp,3,3,"printf(""ERR\n"");","SEND_ERR("""");","[""updateLog"", ""updateContent""]","[[""printf"", ""ERR\\n""], [""SEND_ERR""]]",[-7889771974565263663],7699,11136.0,15
https://github.com/squid-cache/squid/commit/8621b1ac6e2d63a83a41bd808bd3783dee06e416,18 Jul 2012,"author: Alex Rousskov <rousskov@measurement-factory.com>, Christos Tsantilas <chtsanti@users.sourceforge.net>
SslBump: Support bump-ssl-server-first and mimic SSL server certificates.

Summary: These changes allow Squid working in SslBump mode to peek at
the origin server certificate and mimic peeked server certificate
properties in the generated fake certificate, all prior to establishing
a secure connection with the client:
http://wiki.squid-cache.org/Features/BumpSslServerFirst
http://wiki.squid-cache.org/Features/MimicSslServerCert

The changes are required to bump intercepted SSL connections without
excessive browser warnings. The changes allow to disable bumping of some
intercepted SSL connections, forcing Squid to go into a TCP tunnel mode
for those connections.

The changes also empower end user to examine and either honor or bypass
most origin SSL server certificate errors. Prior to these changes, the
responsibility for ignoring certificate validation errors belonged
exclusively to Squid, necessarily leaving users in the dark if errors
are ignored/bypassed.

Squid can still be configured to emulate old bump-ssl-client-first
behavior.  However, a manual revision of ssl_bump options is required
during upgrade because ssl_bump no longer supports an implicit ""negate
the last one"" rule (and it is risky to let Squid guess what the admin
true intent was or mix old- and new-style rules).

Finally, fake certificate generation has been significantly improved.
The new code guarantees that all identically configured Squids receiving
identical origin server certificates will generate identical fake
certificates, even if those Squid instances are running on different
hosts, at different times, and do not communicate with each other. Such
stable, reproducible certificates are required for distributed,
scalable, or fail-safe Squid deployment.

Overall, the changes are meant to make SslBump more powerful and safer.
The code has been tested in several independent labs.


Specific major changes are highlighted below:

Make bumping algorithm selectable using ACLs. Even though
bump-server-first is an overall better method, bumping the client first
is useful for backward compatibility and possibly for serving internal
Squid objects (such as icons inside Squid error pages).  The following
example bumps special and most other requests only, using the old
bump-client-first approach for the special requests only:

    ssl_bump client-first specialOnes
    ssl_bump server-first mostOthers
    ssl_bump none all

It allow use the old ssl_bump syntax:
   ssl_bump allow/deny acl ...
but warns the user to update squid configuration.

Added sslproxy_cert_adapt squid.conf option to overwrite default mimicking
behavior when generating SSL certificates. See squid.conf.documented.

Added sslproxy_cert_sign squid.conf option to control how generated SSL
certificates are signed. See squid.conf.documented.

Added ssl::certHasExpired, ssl::certNotYetValid, ssl::certDomainMismatch,
ssl::certUntrusted, and ssl::certSelfSign predefined ACLs to squid.conf.

Do not require http[s]_port's key option to be set if cert option is given.
The fixed behavior for bumped connections now matches squid.conf docs.

Generate stable fake certificates by using signing and true certificate
hashes as the serial number and by using the configured CA private key
for all fake certificates.

Use minimal, trusted certificate for serving SSL errors to the client
instead of trying to mimic the broken true certificate (which results
in double error for the user: browser error dialog plus Squid error page).

To mimic ""untrusted"" true certificates, generate an untrusted CA certificate
from the configured trusted CA certificate. This both reduces configuration
effort (compared to a configuration option) and results in identical
untrusted fake certificates given identical Squid configurations.

Intelligent handling of CONNECT denials: Do not connect to origin
servers unless CONNECT is successfully authenticated. Delay errors.Added sslproxy_cert_sign squid.conf option to control how generated SSL
certificates are signed. See squid.conf.documented.

Provide '%I' error page formatting code with enough information to avoid
displaying '[unknown]' on SQUID_X509_V_ERR_DOMAIN_MISMATCH errors.

Set logged status code (%<Hs) to 200 when establishing a bumped tunnel.

Improved error detailing and logging: Forget most retried errors.
During SslBump errors, the error details are now logged with both the
initial CONNECT transaction and the first tunneled HTTP transaction.
Do not report system errors as custom Squid errors. Do not report
system errors that did not necessarily happen during the transaction
being logged.

Check SSL server certificate when reconnecting to the origin server for
bumped requests. Despite pinning, Squid maintains two separate connections
and the server may disconnect while the client is still sending requests. To
minimize deployment problems, we reconnect to the origin server but check
that its certificate (which we mimicked for the client) has not changed
much.

Forward bumped server connection-close signal to the bumped client to
improve the ""dumb tunnel"" appearance of the bumped SSL tunnel.

Allow bumping of CONNECT requests without allow-direct set on http_port.
Previously, that flag was required to allow bumped requests to go direct
because they were (and, sometimes, still are) considered ""accelerated"".

Send SNI information to the server when server-first bumping a non-IP
CONNECT request.

Better helper-to-Squid buffer size management to support large certificates.

Bypass rare OpenSSL certificate serialization failures when composing an
ssl_crtd request by generating the certificate in the Squid process.

When generating certificate CN names, strip [] surrounding host names,
assuming they are for IPv6 addresses. Bracketed CNs confuse browsers.

Disable persistent connections after client-side-detected errors. They cause
""abandoning such and such connection"" warnings, stuck ConnStateData jobs, and
other problems.

HttpRequest::SetHost() must invalidate HttpRequest::canonical ""cache"".

Implement ssl::bump_mode logformat code to log SslBump decisions: prints ""none"",
""client-first"", ""server-first"" or ""-"" for no ssl-bump enabled ports

Synced with trunk (trunk r12216, v3.2.0.18+)

This is a Measurement Factory project.",3561,data/crawl/squid/hunk_2094.cpp,check similar variable,non-trivial,data/crawl/squid/old_hunk_2094.cpp,data/crawl/squid/new_hunk_2094.cpp,-1,65,,"storeAppendPrintf(entry, ""%s "", name);","[""addLog""]","[[], [""storeAppendPrintf"", ""entry"", ""%s"", ""name""]]",[-248933907621281061],7698,4843680.0,15
https://github.com/squid-cache/squid/commit/40fc161851f5809741ddb4774e7c366d23323a97,05 Feb 2017,Sync from v5 r15034,2231,data/crawl/squid/hunk_59.cpp,invoke same log method,non-trivial,data/crawl/squid/old_hunk_59.cpp,data/crawl/squid/new_hunk_59.cpp,3,3,"auth_user_request->denyMessage(""Authentication in progress"");","auth_user_request->setDenyMessage(""Authentication in progress"");","[""updateLog""]","[[""denyMessage""], [""setDenyMessage""]]",[10306481890596025221],7697,4608.0,15
https://github.com/squid-cache/squid/commit/635e6242db4ed619a611a269edec9b280690b109,12 Jan 1999,"IRIX inline IO optimization ( -OPT:fast_io=ON) fubars this:

	fprintf(fopen(""foo"", ""w""), ""%d"", val);",128,data/crawl/squid/hunk_6183.cpp,invoke same method,trivial,data/crawl/squid/old_hunk_6183.cpp,data/crawl/squid/new_hunk_6183.cpp,3,4,"fprintf (fopen(""conftestval"", ""w""), ""%d\n"", FD_SETSIZE);","fprintf (fp, ""%d\n"", FD_SETSIZE);","[""removeVariable"", ""removeContent"", ""addVariable""]","[[""fopen"", ""conftestval"", ""w""], [""fp""]]",[-6413025362998860845],7696,0.0,14
https://github.com/squid-cache/squid/commit/f86504f1cb4c3d6f8b576ef2cff1b6323f2a4c1f,19 Sep 2010,"Author: Chad Naugle <chad.naugle@travimp.com>
ext_edirectory_userip_acl - add omitted new file",2082,data/crawl/squid/hunk_3025.cpp,check similar variable,non-trivial,data/crawl/squid/old_hunk_3025.cpp,data/crawl/squid/new_hunk_3025.cpp,-1,209,,"fputs(dbuf, stderr);","[""addLog""]","[[], [""fputs"", ""dbuf"", ""stderr""]]",[-21040805309855973594],7695,43920.0,14
https://github.com/squid-cache/squid/commit/eb3dea38c796fbf091b023e98e832b053c750453,15 Apr 2011,"negotiate_wrapper_auth: version 1.0.1

A helper to perform Negotaite authentication in both its Negotiate/NTLM
and Negotiate/Kerberos forms.
Makes use of additional Squid helpers after unwrapping the header token.",516,data/crawl/squid/hunk_2654.cpp,block change,non-trivial,data/crawl/squid/old_hunk_2654.cpp,data/crawl/squid/new_hunk_2654.cpp,-1,172,,"fprintf(stderr, ""\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""\\n""]]",[-13913879213697345406],7694,4393542.857142857,14
https://github.com/squid-cache/squid/commit/ee74db84d2cf476c8f4a1d4942eae9f94c677678,09 Jul 2015,c++-ize unlinkd,22,data/crawl/squid/hunk_666.cpp,check similar return value,non-trivial,data/crawl/squid/old_hunk_666.cpp,data/crawl/squid/new_hunk_666.cpp,18,-1,"printf(""ERR\n"");",,"[""removeLog""]","[[""printf"", ""ERR\\n""], []]",[-15522548339914942793],7693,1873542.857142857,14
https://github.com/squid-cache/squid/commit/c70281f8bdba2a5f525ddea764667975bbd79eb3,22 Jul 2008,"Cleanups: shuffle ErrorState functions into methods.

No other changes than namespace moves.",228,data/crawl/squid/hunk_4245.cpp,use same variable,trivial,data/crawl/squid/old_hunk_4245.cpp,data/crawl/squid/new_hunk_4245.cpp,14,12,"str.Printf(""CacheErrorInfo - %s"", errorPageName(err->type));","str.Printf(""CacheErrorInfo - %s"", errorPageName(type));","[""removeVariable"", ""addVariable""]","[[""err""], []]",[3051142320815333018],7692,0.0,13
https://github.com/squid-cache/squid/commit/e08d498ff7b12acd94663bf43f8d86c15b460d5d,23 Feb 2009,Fix: appname is now APP_SHORTNAME,4,data/crawl/squid/hunk_3832.cpp,use same variable,trivial,data/crawl/squid/old_hunk_3832.cpp,data/crawl/squid/new_hunk_3832.cpp,3,3,"fprintf(stderr, ""%s: ERROR: No running copy\n"", appname);","fprintf(stderr, ""%s: ERROR: No running copy\n"", APP_SHORTNAME);","[""updateVariable""]","[[""appname""], [""APP_SHORTNAME""]]",[4784142546648117347],7691,52283.07692307692,13
https://github.com/squid-cache/squid/commit/4dd643d505fb6bc13be7d440e2aa5707036a138e,03 Jun 2013,"Polish: update Ip::Address to follow Squid coding guidelines

* lower-case initial word for camelCase method names
* _ suffix for private variables.
* upper-case for static methods
* InitAddrInfo() and FreeAddrInfo() are static, do not use as methods

Not all methods are camelCased due to meaning irregularities and there
are other guidelines not being followed which also need to be fixed.",1969,data/crawl/squid/hunk_1707.cpp,invoke same method,non-trivial,data/crawl/squid/old_hunk_1707.cpp,data/crawl/squid/new_hunk_1707.cpp,4,4,"buf.Printf(""X-Client-IP: %s\r\n"", client_addr.NtoA(ntoabuf,MAX_IPSTRLEN));","buf.Printf(""X-Client-IP: %s\r\n"", client_addr.toStr(ntoabuf,MAX_IPSTRLEN));","[""updateVariable""]","[[""NtoA""], [""toStr""]]",[11520492049254401423],7690,0.0,13
https://github.com/squid-cache/squid/commit/d5649d9f35c421edf02183b397d058a5e15164c2,05 Jan 1998,fix five-min average stuff,124,data/crawl/squid/hunk_6876.cpp,use same variable,non-trivial,data/crawl/squid/old_hunk_6876.cpp,data/crawl/squid/new_hunk_6876.cpp,75,42,"storeAppendPrintf(sentry, ""client_http.requests = %d\n"", A.client_http.requests);","storeAppendPrintf(sentry, ""client_http.requests = %f/sec\n"",
	XAVG(client_http.requests));","[""removeVariable"", ""updateContent"", ""addVariable""]","[[""%d\\n"", ""A""], [""%f/sec\\n"", ""XAVG""]]",[-11021074611193673368],7689,0.0,12
https://github.com/squid-cache/squid/commit/9838d6c806a6934c01c3e28ff4fdf5b7a175e6b9,04 May 1999,move some store initialization stuff into storeUfsDirInit(),52,data/crawl/squid/hunk_6114.cpp,check similar return value,non-trivial,data/crawl/squid/old_hunk_6114.cpp,data/crawl/squid/new_hunk_6114.cpp,9,-1,fatal(tmp_error_buf);,,"[""removeLog""]","[[""fatal"", ""tmp_error_buf""], []]",[13960320583637834086],7688,648720.0,12
https://github.com/squid-cache/squid/commit/fcc351807bcecc7e20a032afdc38cdc14b8d81ee,27 Dec 2004,"Bug #1149: segfault on mgr:vm_objects

Forward port of 2.5 patch",110,data/crawl/squid/hunk_5084.cpp,invoke same log method,trivial,data/crawl/squid/old_hunk_5084.cpp,data/crawl/squid/new_hunk_5084.cpp,17,17,"storeAppendPrintf(s, ""\t%s %s\n"",
                      RequestMethodStr[method], log_url);","memBufPrintf(mb, ""\t%s %s\n"",
                 RequestMethodStr[method], log_url);","[""updateVariable"", ""updateLog""]","[[""storeAppendPrintf"", ""s""], [""memBufPrintf"", ""mb""]]",[-7876639109950016255],7687,0.0,12
https://github.com/squid-cache/squid/commit/6f0aab861682a3d9c8f72228b0ac01eac5e52526,24 Jan 2006,Started converting ftp.cc to use more C++ class methods,714,data/crawl/squid/hunk_4886.cpp,use same variable,trivial,data/crawl/squid/old_hunk_4886.cpp,data/crawl/squid/new_hunk_4886.cpp,16,15,"storeAppendPrintf(e, ""<!-- HTML listing generated by Squid %s -->\n"",
                      version_string);","storeAppendPrintf(entry, ""<!-- HTML listing generated by Squid %s -->\n"",
                      version_string);","[""updateVariable""]","[[""e""], [""entry""]]",[-1268459155482108395],7686,0.0,12
https://github.com/squid-cache/squid/commit/f24583c1402155d55872879590611869f0669a08,21 May 2006,Fix http_range test to run again.,325,data/crawl/squid/hunk_4816.cpp,inner similar method,non-trivial,data/crawl/squid/old_hunk_4816.cpp,data/crawl/squid/new_hunk_4816.cpp,31,-1,"fatal (""dummy function\n"");",,"[""removeLog""]","[[""fatal"", ""dummy"", ""function\\n""], []]",[-2056731110784074756],7685,0.0,12
https://github.com/squid-cache/squid/commit/fc6df0c3a619d283bcd0f755409d5f3ec9554007,04 Dec 2012,merge from parent SslServerCertValidator r12337,2116,data/crawl/squid/hunk_1818.cpp,use same variable,non-trivial,data/crawl/squid/old_hunk_1818.cpp,data/crawl/squid/new_hunk_1818.cpp,6,6,"printf(""%s\n"", requestData->HHA1);","printf(""OK ha1=\""%s\""\n"", requestData->HHA1);","[""updateContent""]","[[""%s\\n""], [""OK"", ""ha1"", ""\\"", ""%s\\"", ""\\n""]]",[-17318855744961982517],7684,24480.0,12
https://github.com/squid-cache/squid/commit/d1f3d8f885784c89a822c35ddf6537aab3a3b925,06 Aug 2014,merge from trunk r13526,34418,data/crawl/squid/hunk_1278.cpp,use same variable,trivial,data/crawl/squid/old_hunk_1278.cpp,data/crawl/squid/new_hunk_1278.cpp,4,5,"storeAppendPrintf(&e, ""Maximum entries: %9d\n"", limit);","storeAppendPrintf(&e, ""Maximum entries: %9d\n"", entryLimit);","[""updateVariable""]","[[""limit""], [""entryLimit""]]",[8955552442617202755],7683,96480.0,12
https://github.com/squid-cache/squid/commit/627f6d02e9baad40c38bd35ef893fc6bc9a22ca1,21 Nov 1997,"SNMP, cmu derived, heavily modified",5272,data/crawl/squid/hunk_6957.cpp,check similar return value,non-trivial,data/crawl/squid/old_hunk_6957.cpp,data/crawl/squid/new_hunk_6957.cpp,-1,552,,"print_error(""Expected \""{\"""", token, type);","[""addLog""]","[[], [""print_error"", ""Expected"", ""\\"", ""\\"", ""token"", ""type""]]",[23625327351001242289],7682,0.0,11
https://github.com/squid-cache/squid/commit/6ca7324f4760764b0597e7779dcffccd07e058ab,12 Oct 2010,"Author: Chad Naugle <chad.naugle@travimp.com>
eDirectory user-IP ACl string safety updates",400,data/crawl/squid/hunk_2974.cpp,check similar variable,non-trivial,data/crawl/squid/old_hunk_2974.cpp,data/crawl/squid/new_hunk_2974.cpp,18,-1,"fputs(dbuf, stderr);",,"[""removeLog""]","[[""fputs"", ""dbuf"", ""stderr""], []]",[21040805309855973594],7681,12043.636363636364,11
https://github.com/squid-cache/squid/commit/b073fc4bde37d3b0dd2f820f90c801d7dada1338,30 Dec 2011,"Cache Manager migration support

 * Add a little bit of XHR script to the CGI cachemgr front page which
probes each of the managed proxies for http:// and https:// capabilities
and produces web links to their internal managers.

 * Reserve the template name MGR_INDEX for use by cachemgr scripts.
But do not distribute any preset template. This allows manager apps to
provide their own static template with linked scripts and objects.

 * The error page system is updated to create a blanket message
indicating missing template instead of aborting Squid if a template is
not even installed.",122,data/crawl/squid/hunk_2362.cpp,block change,non-trivial,data/crawl/squid/old_hunk_2362.cpp,data/crawl/squid/new_hunk_2362.cpp,-1,31,,"printf("" }}}}\n"");","[""addLog""]","[[], [""printf"", ""\\n""]]",[7249185625612668815],7680,3391985.4545454546,11
https://github.com/squid-cache/squid/commit/a5a5de8779b8904f40f06286f71aa9c0a0febd15,21 Apr 1998,open swapout fd debugging,110,data/crawl/squid/hunk_6450.cpp,use same variable,non-trivial,data/crawl/squid/old_hunk_6450.cpp,data/crawl/squid/new_hunk_6450.cpp,25,11,"storeAppendPrintf(sentry, ""\t%s %s\n"",
		RequestMethodStr[mem->method], mem->log_url);","storeAppendPrintf(s, ""\t%s %s\n"",
	    RequestMethodStr[mem->method], mem->log_url);","[""updateVariable""]","[[""sentry""], [""s""]]",[-887447176678270073],7679,0.0,10
https://github.com/squid-cache/squid/commit/1e5562e38ca48d8bf81a6049de49afbc0547de23,20 May 2003,"Summary: Merge in external acl refactoring and tagged delay pools.
Keywords:

Patches applied:

  * robertc@squid-cache.org--squid/squid--tagged-pools--3.0--patch-5
     Enable class 5 pools.

  * robertc@squid-cache.org--squid/squid--tagged-pools--3.0--patch-4
     Implement tag associated delay pools.

  * robertc@squid-cache.org--squid/squid--tagged-pools--3.0--patch-3
     Refactoring external acl.

  * robertc@squid-cache.org--squid/squid--tagged-pools--3.0--patch-2
     Extract ExternalACLState to separate files.

  * robertc@squid-cache.org--squid/squid--tagged-pools--3.0--patch-1
     Create a tagging method for external acl replies.

  * robertc@squid-cache.org--squid/squid--tagged-pools--3.0--base-0
     tag of robertc@squid-cache.org--squid/squid--HEAD--3.0--patch-171",10400,data/crawl/squid/hunk_5247.cpp,block change,non-trivial,data/crawl/squid/old_hunk_5247.cpp,data/crawl/squid/new_hunk_5247.cpp,-1,114,,"storeAppendPrintf(sentry, ""\n\n"");","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""\\n\\n""]]",[907191344344343430],7678,2017584.0,10
https://github.com/squid-cache/squid/commit/9e6e0372016a2d16124516049b5b9cd0ae9c52f8,17 May 2008,"Windows port: Added new mswin_check_ad_group external ACL helper

This helper allow the lookup of users's group membership in a Windows
Active Directory domain.
It overcomes the Lan Manager limits of mswin_check_lm_group, but it can be
used only with native Windows Active Directory domains, so mswin_check_lm_group 
will not removed from Squid.",669,data/crawl/squid/hunk_4289.cpp,use same variable,non-trivial,data/crawl/squid/old_hunk_4289.cpp,data/crawl/squid/new_hunk_4289.cpp,-1,443,,"fprintf(stderr, ""%s: ERROR: Too large: %s\n"", argv[0], buf);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""%s"", ""ERROR"", ""Too"", ""large"", ""%s\\n"", ""argv[0]"", ""buf""]]",[-8164570441682819975],7677,1367712.0,10
https://github.com/squid-cache/squid/commit/1dcf61eb8b17dc47e6ba3ed0921caa25fc1c232b,30 Jun 2010,"NTLM helpers cleanup pt 3: migrate libsmbval into libntlmauth

Library changes:
* ntlmauth.* files moved to libntlmauth/

* helpers/ntlm_auth/smb_lm/smbval moved to libntlmauth/

* No behaviour changes. Since I can't test the deeper logics.
  Just enough to make the code built with portable types available in Squid

* API shuffled slightly to use less .h and to remove all external uses of
  private *-priv.h definitions.

Library now provides three NTLM backend API:
  libntlmauth/ntlmauth.h  - NTLM packet handling
  libntlmauth/smb.h       - SMB LM credential validation
  libntlmauth/rfcnb.h     - RFCNB (NetBIOS) domain server communications

Helper Changes:

* NTLM helpers tweaked slightly to build with the adjusted libntlmauth API
  and ntlm_smb_lm_auth helper to build as C++

* automake logics updated to obey --disable-auth and --disable-auth-ntlm


NOTE: There will be extra code safety and testing benefits gained by
      converting libntlmauth to C++ as well. But that requries someone who
      can test the code behaviour during the upgrade. For now this wil do.",2475,data/crawl/squid/hunk_3267.cpp,check similar return value,non-trivial,data/crawl/squid/old_hunk_3267.cpp,data/crawl/squid/new_hunk_3267.cpp,-1,74,,"fprintf(stderr, ""[%4.4s]   %-50.50s  %s\n"", addrstr, hexstr, charstr);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""[%4"", ""4s]"", ""%"", ""50"", ""50s"", ""%s\\n"", ""addrstr"", ""hexstr"", ""charstr""]]",[-6288472998734895651],7676,1058112.0,10
https://github.com/squid-cache/squid/commit/ac5de05bed05906909d7ccc894f940438b8a9967,29 Sep 2010,"Bug 3051: integer display overflow

This alters the cachemgr display formatting to use 64-bit integers
instead of 32-bit. Revealing overflows hiding behind display overflows.",302,data/crawl/squid/hunk_3014.cpp,use same variable,non-trivial,data/crawl/squid/old_hunk_3014.cpp,data/crawl/squid/new_hunk_3014.cpp,18,18,"storeAppendPrintf(sentry, ""\tTotal free:            %6d KB %d%%\n"",
                      ms.bytes_free >> 10, Math::intPercent(ms.bytes_free, ms.bytes_total));","storeAppendPrintf(sentry, ""\tTotal free:            %6ld KB %d%%\n"",
                     (long)(ms.bytes_free >> 10), Math::intPercent(ms.bytes_free, ms.bytes_total));","[""updateContent"", ""addVariable""]","[[""%6d""], [""%6ld"", ""long""]]",[16886507379923651671],7675,1472832.0,10
https://github.com/squid-cache/squid/commit/b3a4ba82b557dbacc409928bbdb732237f413da5,06 Oct 2011,"Polished SMP caching code, primarily to stay out of the way in non-SMP mode.

Do not start useless diskers. Do not assume Rock cache_dirs are present.
Do not require IpcIo DiskIO module to build Rock store.
Check IPC I/O pages limits in Rock store only when using a disker.
Warn about Rock cache_dir disk space waste.
Warn if shared memory cache is enabled in non-SMP mode.
Fake shared memory segments if needed (e.g., we are using Rock cache_dirs with
  no POSIX shared memory support) and possible (e.g., no SMP).",357,data/crawl/squid/hunk_2428.cpp,inner similar method,non-trivial,data/crawl/squid/old_hunk_2428.cpp,data/crawl/squid/new_hunk_2428.cpp,-1,6,,"fprintf(stderr, ""Not implemented"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""Not"", ""implemented""]]",[-17868059573967399683],7674,78912.0,10
https://github.com/squid-cache/squid/commit/081edc2de252e852d0a8e02891fb36d7919a92ef,07 Jan 2012,"Cleanup: update most of the existing stub files to use the STUB.h framework

There are still several sections to be done. Including adding library API
stubs. However these are the ones which can be done immediately without 
breaking or re-writing existing unit tests.",2058,data/crawl/squid/hunk_2342.cpp,inner similar method,non-trivial,data/crawl/squid/old_hunk_2342.cpp,data/crawl/squid/new_hunk_2342.cpp,6,-1,"fatal(""client_db.cc required"");",,"[""removeLog""]","[[""fatal"", ""client_db"", ""cc"", ""required""], []]",[11584999754346286923],7673,0.0,10
https://github.com/squid-cache/squid/commit/41b43e709e9b7e1a0781913a9cc1a412c467e8e8,06 May 2013,Bug 3780: cachemgr.cgi: output problem in HTTP Header Statistics,2,data/crawl/squid/hunk_1757.cpp,use same text,non-trivial,data/crawl/squid/old_hunk_1757.cpp,data/crawl/squid/new_hunk_1757.cpp,-1,3,,"storeAppendPrintf(e, ""\n"");","[""addLog""]","[[], [""storeAppendPrintf"", ""e"", ""\\n""]]",[5193143777301589627],7672,1426608.0,10
https://github.com/squid-cache/squid/commit/07721490c3ad87e49ef952c07c6bbb0aa323b09b,27 Apr 2015,"Rename Packable::Printf as Packable::appendf

It performs append semantics not replace semantics, and this also paves
the way for SBuf integration.",451,data/crawl/squid/hunk_795.cpp,invoke same log method,non-trivial,data/crawl/squid/old_hunk_795.cpp,data/crawl/squid/new_hunk_795.cpp,8,8,"p->Printf(""=%d"", (int) maxAge());","p->appendf(""=%d"", maxAge());","[""updateLog"", ""removeVariable""]","[[""Printf"", ""int""], [""appendf""]]",[7152046587264163594],7671,38160.0,10
https://github.com/squid-cache/squid/commit/af845cee67e3dc2a58f93a9ac7d9ce091ea4fa00,11 Sep 2015,"Bug 4292: negotiate_wrapper: Unreleased Resources

FILE* handles need to be closed on exit. Shuffle the processing loop logics
to a static function to avoid code duplication from all the requires close
points.

Also, use the available global flag debug_enabled instead of local variable
to avoid having to pass it down explicitly.",337,data/crawl/squid/hunk_574.cpp,check similar return value,non-trivial,data/crawl/squid/old_hunk_574.cpp,data/crawl/squid/new_hunk_574.cpp,-1,35,,"fprintf(stdout, ""BH input error\n"");","[""addLog""]","[[], [""fprintf"", ""stdout"", ""BH"", ""input"", ""error\\n""]]",[-27673462301926708073],7670,1217664.0,10
https://github.com/squid-cache/squid/commit/c438bcf10742e773a8e602a398c884ea54080336,20 Nov 2016,"C++11: Remove GnuRegex and all -lregex related code

Squid is now exclusively using the STL std::regex API provided on all
operating systems in a portable manner.

We no longer have any need of detecting if the system is providing a
libregex, or user has configured one, or if it actually works, or how
to call it, or use the GnuRegex code as a backup when one of those
complex details goes wrong.",5393,data/crawl/squid/hunk_127.cpp,check similar variable,non-trivial,data/crawl/squid/old_hunk_127.cpp,data/crawl/squid/new_hunk_127.cpp,33,19,"fprintf( debug, ""# match from %d-%d on \""%s\""\n"",
                                          (int)subs[offset].rm_so,
                                          (int)subs[offset].rm_eo,
                                          line+subs[offset].rm_so );","fprintf( debug, ""# match '%s' in \""%s\""\n"", subs[offset].str().c_str(), subs[0].str().c_str());","[""updateVariable"", ""moveVariable"", ""removeVariable"", ""updateContent"", ""addContent"", ""addVariable""]","[[""from"", ""%d"", ""%d"", ""on"", ""int"", ""rm_so"", ""int"", ""subs[offset]"", ""rm_eo"", ""line"", ""subs[offset]"", ""rm_so""], [""%s"", ""in"", ""str"", ""c_str"", ""subs[0]"", ""str"", ""c_str""]]",[18914542953596725113],7669,347040.0,10
https://github.com/squid-cache/squid/commit/50ad1e256824307b27dae0fbb078d65df8e2f816,21 Dec 2016,"Cleanup: Refactor libauth Config object(s)

Refactoring the Auth::Config objects to get v5 building again.

The object storing auth_param settings is renamed to SchemeConfig.

A new Auth::Config object is added. The objects holding auth_param,
auth_schemes and other authenticate_* directives settings are stored
there instead of just auth_params.

Lots of outdated doxygen docs that have more up to date copies elsewhere
are removed. The ""\ingroup AuthAPI"" are left for now since some auth
things are not yet in the Auth:: namespace, but other auth related
groups are dropped completely.

Code parsing and dumping auth_param lines has been de-duplicated. Along
with the keep_alive and utf8 settings, which are shared by multiple
schemes. This allows dropping several virtual methods from NTLM and
Negotiate scheme objects.

An auth/forward.h file is added for predefines. Some initial Auth::
symbols are listed there. It is not complete, but others can be added as
needed later.

Some unnecessary includes have been removed. There are probably more. I
just did the obvious ones related to the new auth/forward.h and
auth/Config.h files at this time.",1335,data/crawl/squid/hunk_103.cpp,use same text,non-trivial,data/crawl/squid/old_hunk_103.cpp,data/crawl/squid/new_hunk_103.cpp,137,-1,"storeAppendPrintf(entry, ""\n"");",,"[""removeLog""]","[[""storeAppendPrintf"", ""entry"", ""\\n""], []]",[-3924684621819481232],7668,5695920.0,10
https://github.com/squid-cache/squid/commit/1df370e38a088aa3c12e0971d7324351325ff724,02 Dec 1997,"make SNMP code #ifdef-able, including config parsing",122,data/crawl/squid/hunk_6889.cpp,inner similar method,non-trivial,data/crawl/squid/old_hunk_6889.cpp,data/crawl/squid/new_hunk_6889.cpp,-1,6,,"storeAppendPrintf(entry, ""%s -- UNIMPLEMENTED\n"", name);","[""addLog""]","[[], [""storeAppendPrintf"", ""entry"", ""%s"", ""UNIMPLEMENTED\\n"", ""name""]]",[-8524465994432361915],7667,31680.0,9
https://github.com/squid-cache/squid/commit/b1218840b92df2ac65c8da509fae0ec7e63a632d,13 Aug 2010,"Author: Markus Moeller <huaraz@moeller.plus.com>
Helper: ext_kerberos_ldap_group_acl: Lookup Kerberos/NTLM group via LDAP",5482,data/crawl/squid/hunk_3094.cpp,check similar return value,non-trivial,data/crawl/squid/old_hunk_3094.cpp,data/crawl/squid/new_hunk_3094.cpp,-1,400,,"fprintf(stdout, ""ERR\n"");","[""addLog""]","[[], [""fprintf"", ""stdout"", ""ERR\\n""]]",[-5640522499396071603],7666,917440.0,9
https://github.com/squid-cache/squid/commit/93bc1434c57ba45489e997fffb3e215592fff273,14 Oct 2011,"SMP shared memory cache stats were not collected.

""Hot Object"" stats were not reported for shared memory cache.

Mean disk object size stats were aggregated inaccurately for SMP.

Moved Store-related stats into a dedicated StoreStats class,
encapsulating memory cache-related (mem), disk cache-related (swap), and
global store (number of objects) stats. Used consistent naming scheme 
and a common parent class to make memory and disk stats more alike.

Moved Store stats collection into corresponding Store classes rather
than forcing GetInfo() in stat.cc to know how to deal with all Store stats.",323,data/crawl/squid/hunk_2420.cpp,inner similar method,non-trivial,data/crawl/squid/old_hunk_2420.cpp,data/crawl/squid/new_hunk_2420.cpp,-1,7,,"fatal (""MemObject.cc required."");","[""addLog""]","[[], [""fatal"", ""MemObject"", ""cc"", ""required""]]",[-5142970086775005695],7665,112480.0,9
https://github.com/squid-cache/squid/commit/ba1b862c8e2fb4ac6002432c2f16041119c02758,29 May 2014,merge from trunk r13423,5144,data/crawl/squid/hunk_1403.cpp,invoke same method,non-trivial,data/crawl/squid/old_hunk_1403.cpp,data/crawl/squid/new_hunk_1403.cpp,3,3,"str.Printf(""%s "" SQUIDSTRINGPH "" %s/%d.%d\n"",
                   RequestMethodStr(request->method),
                   SQUIDSTRINGPRINT(urlpath_or_slash),
                   AnyP::ProtocolType_str[request->http_ver.protocol],
                   request->http_ver.major, request->http_ver.minor);","str.Printf(SQUIDSBUFPH "" "" SQUIDSTRINGPH "" %s/%d.%d\n"",
                   SQUIDSBUFPRINT(request->method.image()),
                   SQUIDSTRINGPRINT(urlpath_or_slash),
                   AnyP::ProtocolType_str[request->http_ver.protocol],
                   request->http_ver.major, request->http_ver.minor);","[""updateVariable"", ""moveVariable"", ""updateContent"", ""addVariable""]","[[""%s"", ""RequestMethodStr""], [""SQUIDSBUFPH"", ""SQUIDSBUFPRINT"", ""image""]]",[5323122395840098553],7664,35520.0,9
https://github.com/squid-cache/squid/commit/c6649f6c62f90053f0bf0f162918a94f1d763b3d,26 Aug 2014,merge from trunk,14018,data/crawl/squid/hunk_1212.cpp,check similar variable,non-trivial,data/crawl/squid/old_hunk_1212.cpp,data/crawl/squid/new_hunk_1212.cpp,-1,456,,"mb.Printf(""%i %s\r\n"", code, msg);","[""addLog""]","[[], [""mb"", ""Printf"", ""%i"", ""%s\\r\\n"", ""code"", ""msg""]]",[27668380407176316555],7663,13920.0,9
https://github.com/squid-cache/squid/commit/af845cee67e3dc2a58f93a9ac7d9ce091ea4fa00,11 Sep 2015,"Bug 4292: negotiate_wrapper: Unreleased Resources

FILE* handles need to be closed on exit. Shuffle the processing loop logics
to a static function to avoid code duplication from all the requires close
points.

Also, use the available global flag debug_enabled instead of local variable
to avoid having to pass it down explicitly.",337,data/crawl/squid/hunk_574.cpp,check similar variable,non-trivial,data/crawl/squid/old_hunk_574.cpp,data/crawl/squid/new_hunk_574.cpp,-1,60,,"fprintf(stdout, ""BH Invalid request\n"");","[""addLog""]","[[], [""fprintf"", ""stdout"", ""BH"", ""Invalid"", ""request\\n""]]",[-14936515258816654011],7662,1277760.0,9
https://github.com/squid-cache/squid/commit/dcfe639004a3c1fc2e9f201de8ba6cd94bd37ec1,03 Dec 1996,"Hi Duane,

        Anthony Baxter and myself have completed the patches for comm.c to
get it to use poll(2) directly rather than select().  This provides a largish
performance increase for systems that implement select() as a library call
(such as Solaris), and also allows systems such as Solaris to bypass the silly
1024 open FD limit which library select() has.  We've tested this code on
running systems and found a smallish increase in overall ability to service
connections, and a respectable drop in CPU usage.  To use, just compile with
the -DUSE_POLL flag in the make options.  Patch applies to 1.1b25 version
of comm.c.  As with all code, there probably are still bugs...",475,data/crawl/squid/hunk_7423.cpp,check similar variable,non-trivial,data/crawl/squid/old_hunk_7423.cpp,data/crawl/squid/new_hunk_7423.cpp,-1,52,,fatal_dump(NULL);,"[""addLog""]","[[], [""fatal_dump"", ""NULL""]]",[-12879563083587916188],7661,56520.0,8
https://github.com/squid-cache/squid/commit/a0f327753bc3041cabaf2e606fa0c878a1854243,05 Mar 1998,"Added more server-side counters and accounting based on patch from
Lincon Dale.  Also removed some '#if 0' code chunks.",404,data/crawl/squid/hunk_6639.cpp,use same variable,trivial,data/crawl/squid/old_hunk_6639.cpp,data/crawl/squid/new_hunk_6639.cpp,3,30,"storeAppendPrintf(sentry, ""server.requests = %f/sec\n"",
	XAVG(server.requests));","storeAppendPrintf(sentry, ""server.other.requests = %f/sec\n"",
	XAVG(server.other.requests));","[""updateContent"", ""addVariable""]","[[], [""other"", ""other""]]",[8623595955817938790],7660,0.0,8
https://github.com/squid-cache/squid/commit/d78185edcc56453d5f839c38433a05a00ddfe9dc,16 May 1998,henrik wants more complaints about creating directories,35,data/crawl/squid/hunk_6420.cpp,check similar return value,non-trivial,data/crawl/squid/old_hunk_6420.cpp,data/crawl/squid/new_hunk_6420.cpp,-1,14,,fatal(tmp_error_buf);,"[""addLog""]","[[], [""fatal"", ""tmp_error_buf""]]",[-13960320583637834086],7659,407340.0,8
https://github.com/squid-cache/squid/commit/c04d4f40ba637c37ac4db8b020861d48d0a548b8,20 Aug 2001,"Resolve any possible conflicts with POSIX AIO

* Use the prefix squidaio_ rather than aio_...
* Some minor cleanups",698,data/crawl/squid/hunk_5790.cpp,use same variable,trivial,data/crawl/squid/old_hunk_5790.cpp,data/crawl/squid/new_hunk_5790.cpp,3,3,"storeAppendPrintf(sentry, ""open\t%d\n"", aio_counts.open);","storeAppendPrintf(sentry, ""open\t%d\n"", squidaio_counts.open);","[""updateVariable""]","[[""aio_counts""], [""squidaio_counts""]]",[-16023929972491634641],7658,0.0,8
https://github.com/squid-cache/squid/commit/fcc351807bcecc7e20a032afdc38cdc14b8d81ee,27 Dec 2004,"Bug #1149: segfault on mgr:vm_objects

Forward port of 2.5 patch",110,data/crawl/squid/hunk_5086.cpp,invoke same log method,non-trivial,data/crawl/squid/old_hunk_5086.cpp,data/crawl/squid/new_hunk_5086.cpp,8,8,"storeAppendPrintf(output, ""\tClient #%d, %p\n"", clientNumber, _callback.callback_data);","memBufPrintf(output, ""\tClient #%d, %p\n"", clientNumber, _callback.callback_data);","[""updateLog""]","[[""storeAppendPrintf""], [""memBufPrintf""]]",[-7890591179051097972],7657,0.0,8
https://github.com/squid-cache/squid/commit/277594848931fd7f19a61dfbd2c923ff06922311,27 Apr 2009,"Remove infinite loop in MSNT auth helper

On one starting error condition the helper enters a read loop     
without exit conditions. Made this exit when read was done
and shutdown helper as per behavior comment by the loop.

Also removes one useless goto.",10,data/crawl/squid/hunk_3771.cpp,check similar variable,non-trivial,data/crawl/squid/old_hunk_3771.cpp,data/crawl/squid/new_hunk_3771.cpp,-1,3,,"puts(""ERR"");","[""addLog""]","[[], [""puts"", ""ERR""]]",[1091395453046515340],7656,1273140.0,8
https://github.com/squid-cache/squid/commit/75aa769bc374a0ebb66d3c41a763d5ca2ed44d4b,11 Jun 2010,"Upgrade ntlm_fake_auth helper and internal libntlmauth

Fake auth helper changes:

 - renames fakeauth to ntlm_fake_auth
 - links ntlm_fake_auth to libntlmauth
 - removes duplicate code provided by libcompat and libntlmauth
 - moves the remaining bits of fakeauth/ntlm.h to ntlm_fake_auth.cc

Library API changes:

 - moves some of the basic NTLM operations into libntlmauth
    * fetch_string UNICODE support
    * make challenge packet
    * validate packet type
    * make challenge nonce
    * unpack user and domain from authenticate packet

 - tweaks libntlmauth to split the make challenge operation so that it
   only generates the challenge object (does not encode blob for sending,
   or hard-code field values any more).

Other related changes:

 - tweaks the smb_lm helper which already linked libntlmauth so that it
   uses the updated API correctly after the above changes.

 - documents libntlmauth and some of ntlm_fake_auth helper",1471,data/crawl/squid/hunk_3308.cpp,check similar return value,non-trivial,data/crawl/squid/old_hunk_3308.cpp,data/crawl/squid/new_hunk_3308.cpp,-1,213,,"fprintf(stderr, ""unknown option: -%c. Exiting\n"", opt);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""unknown"", ""option"", ""%c"", ""Exiting\\n"", ""opt""]]",[-6958397524576261935],7655,3064140.0,8
https://github.com/squid-cache/squid/commit/8eeb87e6acf8bae4bb621128865d4ee4edd20dcf,05 Jul 2010,Update negotiate SSPI helper,313,data/crawl/squid/hunk_3252.cpp,check similar return value,non-trivial,data/crawl/squid/old_hunk_3252.cpp,data/crawl/squid/new_hunk_3252.cpp,64,-1,"fprintf(stderr, ""[%4.4s]   %-50.50s  %s\n"", addrstr, hexstr, charstr);",,"[""removeLog""]","[[""fprintf"", ""stderr"", ""[%4"", ""4s]"", ""%"", ""50"", ""50s"", ""%s\\n"", ""addrstr"", ""hexstr"", ""charstr""], []]",[6288472998734895651],7654,21600.0,8
https://github.com/squid-cache/squid/commit/c152a4473c4a3d187f67923eb83c5fe6ccd91013,12 Jul 2010,"Helpers: Naming and C++ update for external ACL helpers

 * Also adds the Fake auth helper for testing Basic authentication.
 * Also adds manual pages for most external ACL helpers

TODO: test for and fix any build issues on Windows.",2485,data/crawl/squid/hunk_3153.cpp,use same text,trivial,data/crawl/squid/old_hunk_3153.cpp,data/crawl/squid/new_hunk_3153.cpp,3,3,"printf(""OK\n"");","SEND_OK("""");","[""updateLog"", ""updateContent""]","[[""printf"", ""OK\\n""], [""SEND_OK""]]",[-9335956330906339887],7653,9360.0,8
https://github.com/squid-cache/squid/commit/c152a4473c4a3d187f67923eb83c5fe6ccd91013,12 Jul 2010,"Helpers: Naming and C++ update for external ACL helpers

 * Also adds the Fake auth helper for testing Basic authentication.
 * Also adds manual pages for most external ACL helpers

TODO: test for and fix any build issues on Windows.",2485,data/crawl/squid/hunk_3141.cpp,use same text,non-trivial,data/crawl/squid/old_hunk_3141.cpp,data/crawl/squid/new_hunk_3141.cpp,3,3,"fprintf(stderr, ""ERROR: Your LDAP library does not have URI support\n"");","fprintf(stderr, ""FATAL: Your LDAP library does not have URI support\n"");","[""updateContent""]","[[""ERROR""], [""FATAL""]]",[-13232312713197993276],7652,15120.0,8
https://github.com/squid-cache/squid/commit/995eb827aaa64d9bcd4110b756e04051ef9d03e9,02 Mar 2011,merge from trunk,12916,data/crawl/squid/hunk_2734.cpp,inner similar method,non-trivial,data/crawl/squid/old_hunk_2734.cpp,data/crawl/squid/new_hunk_2734.cpp,-1,129,,"mustStop(""exception"");","[""addLog""]","[[], [""mustStop"", ""exception""]]",[-3541540401470368235],7651,2151000.0,8
https://github.com/squid-cache/squid/commit/35a1b223314eddb67b631cb0224d6e03a2360c77,13 Sep 2011,"SMP Caching: Core changes, IPC primitives, Shared memory cache, and Rock Store

Core changes
------------

* Added MemObject::expectedReplySize() and used it instead of object_sz.

When deciding whether an object with a known content length can be
swapped out, do not wait until the object is completely received and its
size (mem_obj->object_sz) becomes known (while asking the store to
recheck in vain with every incoming chunk). Instead, use the known
content length, if any, to make the decision.

This optimizes the common case where the complete object is eventually
received and swapped out, preventing accumulating potentially large
objects in RAM while waiting for the end of the response. Should not
affect objects with unknown content length.

Side-effect1: probably fixes several cases of unknowingly using negative
(unknown) mem_obj->object_sz in calculations. I added a few assertions
to double check some of the remaining object_sz/objectLen() uses.

Side-effect2: When expectedReplySize() is stored on disk as StoreEntry
metadata, it may help to detect truncated entries when the writer
process dies before completing the swapout.


* Removed mem->swapout.memnode in favor of mem->swapout.queue_offset.

The code used swapout.memnode pointer to keep track of the last page
that was swapped out. The code was semi-buggy because it could reset the
pointer to NULL if no new data came in before the call to doPages().
Perhaps the code relied on the assumption that the caller will never
doPages if there is no new data, but I am not sure that assumption was
correct in all cases (it could be that I broke the calling code, of course).

Moreover, the page pointer was kept without any protection from page
disappearing during asynchronous swapout. There were ""Evil hack time""
comments discussing how the page might disappear.

Fortunately, we already have mem->swapout.queue_offset that can be fed
to getBlockContainingLocation to find the page that needs to be swapped
out. There is no need to keep the page pointer around. The
queue_offset-based math is the same so we are not adding any overheads
by using that offset (in fact, we are removing some minor computations).


* Added ""close how?"" parameter to storeClose() and friends.

The old code would follow the same path when closing swapout activity
for an aborted entry and when completing a perfectly healthy swapout. In
non-shared case, that could have been OK because the abort code would
then release the entry, removing any half-written entry from the index
and the disk (but I am not sure that release happened fast enough in
100% of cases).

When the index and disk storage is shared among workers, such
""temporary"" inconsistencies result in truncated responses being
delivered by other workers to the user because once the swapout activity
is closed, other workers can start using the entry.

By adding the ""close how?"" parameter to closing methods we allow the
core and SwapDir-specific code to handle aborted swapouts appropriately.

Since swapin code is ""read only"", we do not currently distinguish
between aborted and fully satisfied readers: The readerGone enum value
applies to both cases. If needed, the SwapDir reading code can make that
distinction by analyzing how much was actually swapped in.


* Moved ""can you store this entry?"" code to virtual SwapDir::canStore().

The old code had some of the tests in SwapDir-specific canStore()
methods and some in storeDirSelect*() methods. This resulted in
inconsistencies, code duplication, and extra calculation overheads.
Making this call virtual allows individual cache_dir types to do custom
access controls.

The same method is used for cache_dir load reporting (if it returns
true). Load management needs more work, but the current code is no worse
than the old one in this aspect, and further improvements are outside
this change scope.


* Minimized from-disk StoreEntry loading/unpacking code duplication.

Moved common (and often rather complex!) code from store modules into
storeRebuildLoadEntry, storeRebuildParseEntry, and storeRebuildKeepEntry.


* Do not set object_sz when the entry is aborted because the true object
size (HTTP reply headers + body) is not known in this case. Setting
object_sz may fool client-side code into believing that the object is
complete.

This addresses an old RBC's complaint.


* When swapout initiation fails, mark swapout decision as
MemObject::SwapOut::swImpossible. This prevents the caller code from trying to
swap out again and again because swap_status becomes SWAPOUT_NONE.

TODO: Consider add SWAPOUT_ERROR, STORE_ERROR, and similar states. It
may solve several problems where the code sees _NONE or _OK and thinks
everything is peachy when in fact there was an error.


* Call haveParsedReplyHeaders() before entry->replaceHttpReply().

HaveParsedReplyHeaders() sets the entry public key and various flags (at 
least). ReplaceHttpReply() packs reply headers, starting swapout process.
It feels natural to adjust the entry _before_ we pack/swap it, but I may be
missing some side-effects here.

The change was necessary because we started calling checkCachable() from
swapoutPossible(). If haveParsedReplyHeaders() is not called before we swap
out checks, the entry will still have the private key and will be declared
impossible to cache.


* Extracted the write-to-store step from StoreEntry::replaceHttpReply().

This allows the caller to set the reply for the entry and then update the
entry and the reply before writing them to store. For example, the server-side
haveParsedReplyHeaders() code needs to set the entry timestamps and make the
entry key public before the entry starts swapping out, but the same code also
needs access to entry->getReply() and such for timestampsSet() and similar
code to work correctly.

TODO: Calls to StoreEntry::replaceHttpReply() do not have to be modified
because replaceHttpReply() does write by default. However, it is likely that
callers other than ServerStateData::setFinalReply() should take advantage of
the new split interface because they call timestampsSet() and such after
replaceHttpReply().


* Moved SwapDir::cur_size and n_disk_objects to specific SwapDirs. Removed
updateSize().  Some cache_dirs maintain their own maps and size statistics,
making the one-size-fits-all SwapDir members inappropriate.

* A new SwapDir public method swappedOut() added. It is called from
storeSwapOutFileClosed() to notify SwapDir that an object was swapped
out.

* Change SwapDir::max_size to bytes, make it protected, use maxSize() instead.

Change SwapDir::cur_size to bytes, make it private, use currentSize() instead.

Store Config.Store.avgObjectSize in bytes to avoid repeated and error-prone
KB<->bytes conversions.


* Change Config.cacheSwap.swapDirs and StoreEntry::store() type to SwapDir.

This allows using SwapDir API without dynamic_cast.


* Always call StoreEntry::abort() instead of setting ENTRY_ABORTED manually.

* Rely on entry->abort() side-effects if ENTRY_ABORTED was set.

* Added or updated comments to better document current code.

* Added operator << for dumping StoreEntry summary into the debugging
log. Needs more work to report more info (and not report yet-unknown info).

* Fixed blocking reads that were sometimes reading from random file offsets.

Core ""disk file"" reading code assumed that if the globally stored disk.offset
matches the desired offset, there is no reason to seek. This was probably done
to reduce seek overhead between consecutive reads. Unfortunately, the disk
writing code did not know about that optimization and left F->disk.offset
unchanged after writing.

This may have worked OK for UFS if it never writes to the file it reads from,
but it does not work for store modules that do both kinds of I/O at different
offsets of the same disk file.

Eventually, implement this optimization correctly or remove disk.offset.


IPC primitives
--------------

To make SMP disk and memory caching non-blocking and correct, worker and
disker processes must asynchronously communicate with each other. We are
adding a collection of classes that support such communication.

At the base of the collection is the AtomicWordT template that uses GCC atomic
primitives such as __sync_add_and_fetch() to perform atomic operations on
integral values in memory shared by multiple Squid kids. AtomicWordT is used
to implement non-blocking shared locks, queues, store tables, and page pools.

To avoid blocking or very long searches, many operations are ""optimistic"" in
nature. For example, it is possible that an atomic store map will refuse to
allocate an entry for two processes even though a blocking implementation
would have allowed one of the processes to get the map slot. We speculate that
such conflict resolution is better than blocking locks when it comes to
caching, especially if the conflicts are rare due to large number of cache
entries, fast operations, and relatively small number of kids.


TODO: Eventually, consider breaking locks left by dead kids.



Shared Memory Cache
-------------------

* Added initial shared memory cache implementation (MemStore).

The shared memory cache keeps its own compact index of cached entries using
extended Ipc::StoreMap class (MemStoreMap). The cache also strives to keep its
Root.get() results out of the store_table except during transit.

Eventually, the non-shared/local memory cache should also be implemented
using a MemStore-like class, I think. This will allow to clearly isolate
local from shared memory cache code.

Allow the user to explicitly disable shared memory caching in SMP mode via
memory_cache_shared to squid.conf. Report whether mem_cache is shared.

Disable shared memory caching by default if atomic operations are not
supported. Prohibit shared memory caching if atomic operations are not
supported.

TODO: Better limits/separation for cache and I/O shared memory pages.
Eventually, support shared memory caching of multi-page entries.


Rock Store
----------

Rock Store uses a single [large] database-style file per cache_dir to store
cached responses and metadata. This part of the design is similar to COSS.
Rock Store does not maintain or rely on swap.state ""log"" for recovery.
Instead, the database is scanned in the background to load entries when Squid
starts. Rock Store maintains its own index of cached entries and avoids global
store_table. All entries must be max-size or smaller.

In SMP mode, each Rock cache_dir is given a dedicated Kid processes called
""disker"". All SMP workers communicate with diskers to store misses and load
hits, using shared memory pages and atomic shared memory queues. Disker blocks
when doing disk I/O but workers do not. Any Diskers:Workers ratio is supported
so that the user can find and configure the optimal number of workers and
diskers for a given number of disks and CPU cores.

In non-SMP mode, should use good old blocking disk I/O, without any diskers,
but this has not been tested recently and probably needs more work.

Feature page: http://wiki.squid-cache.org/Features/RockStore

TODO: Disk rate limit to protect Squid from disk overload. More stats.
Multiple readers? Seek optimization? Remove known max-size requirement?",8765,data/crawl/squid/hunk_2449.cpp,check similar variable,non-trivial,data/crawl/squid/old_hunk_2449.cpp,data/crawl/squid/new_hunk_2449.cpp,-1,156,,"fatal(""Rock Store db creation error"");","[""addLog""]","[[], [""fatal"", ""Rock"", ""Store"", ""db"", ""creation"", ""error""]]",[-1759631197158767042],7650,164880.0,8
https://github.com/squid-cache/squid/commit/cbae7ab934f3ef47708417006498aae458f15283,21 Jun 2014,Support PROXY protocol version 2,100,data/crawl/squid/hunk_1365.cpp,use same variable,non-trivial,data/crawl/squid/old_hunk_1365.cpp,data/crawl/squid/new_hunk_1365.cpp,-1,7,,proxyProtocolError(true);,"[""addLog""]","[[], [""proxyProtocolError"", ""true""]]",[6002347251361972528],7649,0.0,8
https://github.com/squid-cache/squid/commit/3ac5bd881bf4eda91a239a9db7734be91d360822,23 Aug 2014,Sync with trunk rev.13542,101061,data/crawl/squid/hunk_1219.cpp,check similar variable,non-trivial,data/crawl/squid/old_hunk_1219.cpp,data/crawl/squid/new_hunk_1219.cpp,17,-1,"fprintf(tracefp, ""f:%p\n"", s);",,"[""removeLog""]","[[""fprintf"", ""tracefp"", ""f"", ""%p\\n"", ""s""], []]",[4185219475741869808],7648,954540.0,8
https://github.com/squid-cache/squid/commit/efc238716eb68db2888faac60423184a894f5483,18 Jan 2015,"Support rotate=N option on access_log

Add a rotate=N option to access_log directive to set per-log what the
retained log count will be. At present it is only used by the stdio:
logging module, which is also the only one to use logfile_rotate
directive.

If this option is absent (as will be the common case) the log rotation
defaults to using the value of logfile_rotate directive.

Also, add missing dump output of other access_log options if they differ
from the defaults.

The use-cases for this are:

1) Unix fifo logging requires all the stdio: module operations except
that the normal rotate/rename operation is NOT performed on the fifo
socket. It makes more sense to add this option which can also meet case
#2 than to create a whole new module just for fifo.

2) managing only some access_log files with a third-party log manager.
Those specific logs need rotate=0, but the Squid managed logs may
require non-0 values.",88,data/crawl/squid/hunk_1052.cpp,check similar variable,non-trivial,data/crawl/squid/old_hunk_1052.cpp,data/crawl/squid/new_hunk_1052.cpp,3,3,"storeAppendPrintf(entry, ""%s %s"", log->filename, log->logFormat->name);","storeAppendPrintf(entry, ""%s logformat=%s"", log->filename, log->logFormat->name);","[""updateContent""]","[[], [""logformat""]]",[-2095683113656719822],7647,0.0,8
https://github.com/squid-cache/squid/commit/1071ffed56172406d771265af76d8273ffcdb89e,26 May 2015,"Replace Packer object API with Packable API

Majority of thost patch is symbol renaming to unify the
class method names to the Packable API names.

There is effectively no logical change in this patch
despite appearances because it replaces the Packer object
which provides methods which are just wrappers pointing
to static functions which are in turn wrappers pointing
to storage buffer object methods. With direct calls to
those storage object methods (renamed).

We can now interchangebly use MemBuf or StoreEntry objects
with the packInto(Packable *) functions. Or any other
object which inherits and implements the Packable API.

We also gain 0.1% in performance (+2 RPS) by avoiding the
layers of wrapper funcions and Packer object allocate / 
deallocate cycles.",1141,data/crawl/squid/hunk_779.cpp,invoke same log method,non-trivial,data/crawl/squid/old_hunk_779.cpp,data/crawl/squid/new_hunk_779.cpp,17,13,"mb->Printf(""\n"");","mb->append(""\n"", 1);","[""updateLog"", ""addContent""]","[[""Printf""], [""append"", ""1""]]",[-16152299999027699401],7646,58140.0,8
https://github.com/squid-cache/squid/commit/af845cee67e3dc2a58f93a9ac7d9ce091ea4fa00,11 Sep 2015,"Bug 4292: negotiate_wrapper: Unreleased Resources

FILE* handles need to be closed on exit. Shuffle the processing loop logics
to a static function to avoid code duplication from all the requires close
points.

Also, use the available global flag debug_enabled instead of local variable
to avoid having to pass it down explicitly.",337,data/crawl/squid/hunk_574.cpp,check similar variable,non-trivial,data/crawl/squid/old_hunk_574.cpp,data/crawl/squid/new_hunk_574.cpp,-1,65,,"fprintf(stderr, ""%s| %s: Invalid request [%s]\n"", LogTime(),
                        PROGRAM, buf);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""%s"", ""%s"", ""Invalid"", ""request"", ""[%s]\\n"", ""LogTime"", ""PROGRAM"", ""buf""]]",[-20974463790759197551],7645,1891440.0,8
https://github.com/squid-cache/squid/commit/d3b1bee6fff7792f482ff280e8400c6a3e83560f,14 Dec 2015,merge from trunk r14444,9318,data/crawl/squid/hunk_457.cpp,check similar return value,non-trivial,data/crawl/squid/old_hunk_457.cpp,data/crawl/squid/new_hunk_457.cpp,7,-1,"fatal (""Cannot search by url yet\n"");",,"[""removeLog""]","[[""fatal"", ""Cannot"", ""search"", ""by"", ""url"", ""yet\\n""], []]",[17188289028935592274],7644,3502080.0,8
https://github.com/squid-cache/squid/commit/92cfc72f72e0dfd7509337fdee2104d15cb4000f,25 Jan 2016,"Invalid FTP connection handling on blocked content.

FTP client gets stuck after the following chain of events:
 * Client requests a file that will be blocked by ICAP.
 * Squid starts downloading the file from the FTP server
   and sends ""150 Opening..."" to the FTP client.
 * Squid aborts the data connection with the FTP server
   as soon as the ICAP service blocks it.
 * Squid sends ""451 Forbidden"" to the FTP client.
 * The FTP server sends ""500 OOPS: setsockopt: linger"" to Squid.
 * Squid terminates the control connection to the FTP server.
 * Squid establishes a new control connection to the FTP server
   but does not authenticate itself.
 * Further commands from the FTP client do not work any more.

The above and many similar problems exist because Squid handles
FTP client-to-squid and squid-to-FTP server data connections
independently from each other. In many cases, one connection does
not get notified about the problems with the other connection.

This patch:
  - Add Ftp::MasterState::userDataDone to record received
    the FTP client final response status code to sent (or to be send)
    to the client.
  - The Ftp::MasterState::waitForOriginData flag to hold status of the
    squid-to-server side. If the squid-to-server side is not finishes
    yet this is true.
  - Send a control reply to the FTP client only after the data transfered
    on both server and client sides.
  - Split Client::abortTransaction to Client::abortOnData and to
    Client::abortAll()
  - Implement the Ftp::Relay::abortOnData() and Ftp::Relay::Abort()
    (i.e., StoreEntry abort handler) to avoid closing the control
    connection when the data connection is closed unexpectedly.

This is a Measurement Factory project.",221,data/crawl/squid/hunk_378.cpp,invoke same log method,non-trivial,data/crawl/squid/old_hunk_378.cpp,data/crawl/squid/new_hunk_378.cpp,3,3,"abortTransaction(""adaptation failure with a filled entry"");","abortAll(""adaptation failure with a filled entry"");","[""updateLog""]","[[""abortTransaction""], [""abortAll""]]",[9614335523586009905],7643,0.0,8
https://github.com/squid-cache/squid/commit/92cfc72f72e0dfd7509337fdee2104d15cb4000f,25 Jan 2016,"Invalid FTP connection handling on blocked content.

FTP client gets stuck after the following chain of events:
 * Client requests a file that will be blocked by ICAP.
 * Squid starts downloading the file from the FTP server
   and sends ""150 Opening..."" to the FTP client.
 * Squid aborts the data connection with the FTP server
   as soon as the ICAP service blocks it.
 * Squid sends ""451 Forbidden"" to the FTP client.
 * The FTP server sends ""500 OOPS: setsockopt: linger"" to Squid.
 * Squid terminates the control connection to the FTP server.
 * Squid establishes a new control connection to the FTP server
   but does not authenticate itself.
 * Further commands from the FTP client do not work any more.

The above and many similar problems exist because Squid handles
FTP client-to-squid and squid-to-FTP server data connections
independently from each other. In many cases, one connection does
not get notified about the problems with the other connection.

This patch:
  - Add Ftp::MasterState::userDataDone to record received
    the FTP client final response status code to sent (or to be send)
    to the client.
  - The Ftp::MasterState::waitForOriginData flag to hold status of the
    squid-to-server side. If the squid-to-server side is not finishes
    yet this is true.
  - Send a control reply to the FTP client only after the data transfered
    on both server and client sides.
  - Split Client::abortTransaction to Client::abortOnData and to
    Client::abortAll()
  - Implement the Ftp::Relay::abortOnData() and Ftp::Relay::Abort()
    (i.e., StoreEntry abort handler) to avoid closing the control
    connection when the data connection is closed unexpectedly.

This is a Measurement Factory project.",221,data/crawl/squid/hunk_375.cpp,invoke same log method,non-trivial,data/crawl/squid/old_hunk_375.cpp,data/crawl/squid/new_hunk_375.cpp,3,3,abortTransaction(abortReason);,abortOnData(abortReason);,"[""updateLog""]","[[""abortTransaction""], [""abortOnData""]]",[7044889801674964592],7642,0.0,8
https://github.com/squid-cache/squid/commit/50ad1e256824307b27dae0fbb078d65df8e2f816,21 Dec 2016,"Cleanup: Refactor libauth Config object(s)

Refactoring the Auth::Config objects to get v5 building again.

The object storing auth_param settings is renamed to SchemeConfig.

A new Auth::Config object is added. The objects holding auth_param,
auth_schemes and other authenticate_* directives settings are stored
there instead of just auth_params.

Lots of outdated doxygen docs that have more up to date copies elsewhere
are removed. The ""\ingroup AuthAPI"" are left for now since some auth
things are not yet in the Auth:: namespace, but other auth related
groups are dropped completely.

Code parsing and dumping auth_param lines has been de-duplicated. Along
with the keep_alive and utf8 settings, which are shared by multiple
schemes. This allows dropping several virtual methods from NTLM and
Negotiate scheme objects.

An auth/forward.h file is added for predefines. Some initial Auth::
symbols are listed there. It is not complete, but others can be added as
needed later.

Some unnecessary includes have been removed. There are probably more. I
just did the obvious ones related to the new auth/forward.h and
auth/Config.h files at this time.",1335,data/crawl/squid/hunk_103.cpp,check similar variable,non-trivial,data/crawl/squid/old_hunk_103.cpp,data/crawl/squid/new_hunk_103.cpp,134,-1,"storeAppendPrintf(entry, "" %s"", list->key);",,"[""removeLog""]","[[""storeAppendPrintf"", ""entry"", ""%s"", ""list"", ""key""], []]",[-18527958583169795512],7641,216540.0,8
https://github.com/squid-cache/squid/commit/c943f3313a892d71be08ad823a58b1969e56a817,30 Mar 1996,"assign store.c to debugging section 20
fixed storeRebuildFromDisk bug introduced when switched from fdopen(, ""a"")
to fdopen(, ""w"").  Now storeInit() makes a little more sense.",647,data/crawl/squid/hunk_7935.cpp,check similar return value,non-trivial,data/crawl/squid/old_hunk_7935.cpp,data/crawl/squid/new_hunk_7935.cpp,25,22,fatal(tmpbuf);,fatal(tmp_error_buf);,"[""updateVariable""]","[[""tmpbuf""], [""tmp_error_buf""]]",[-10977526806704958013],7640,0.0,7
https://github.com/squid-cache/squid/commit/15576b6a58a24ed2705d6228d0fde8cfcef26cae,07 Feb 1998,remove brackets from cachemgr output,390,data/crawl/squid/hunk_6829.cpp,use same text,non-trivial,data/crawl/squid/old_hunk_6829.cpp,data/crawl/squid/new_hunk_6829.cpp,36,35,"storeAppendPrintf(sentry, ""{\tRequests given to unlinkd:\t%d}\n"",
	Counter.unlink.requests);","storeAppendPrintf(sentry, ""\tRequests given to unlinkd:\t%d\n"",
	Counter.unlink.requests);","[""updateContent""]","[[""\\t%d"", ""\\n""], [""\\t%d\\n""]]",[-1330699662296328616],7639,0.0,7
https://github.com/squid-cache/squid/commit/15576b6a58a24ed2705d6228d0fde8cfcef26cae,07 Feb 1998,remove brackets from cachemgr output,390,data/crawl/squid/hunk_6814.cpp,use same text,non-trivial,data/crawl/squid/old_hunk_6814.cpp,data/crawl/squid/new_hunk_6814.cpp,6,6,"storeAppendPrintf(sentry, ""{Address: %s}\n"", c->key);","storeAppendPrintf(sentry, ""Address: %s\n"", c->key);","[""updateContent""]","[[""%s"", ""\\n""], [""%s\\n""]]",[6128453140213560284],7638,0.0,7
https://github.com/squid-cache/squid/commit/79d4ccdf0a8c242f24a40d774d2c7d4dcdf28047,20 Oct 2001,"SSL update from the ""ssl"" branch at SourceForge

* Several SSL tweaking options
  - SSL version per https_port, no longer a global setting
  - supported chipers, per https_port
  - supported protocols, per https_port
  - connection shutdown method

* Fix the bug reported by Noel Burton-Krahn where SSL connections
  could get hung with data pending in the SSL internal buffers. Mostly
  seen on large POST/PUT requests, but could in theory appear on any
  request larger than 4K.",315,data/crawl/squid/hunk_5753.cpp,use same text,non-trivial,data/crawl/squid/old_hunk_5753.cpp,data/crawl/squid/new_hunk_5753.cpp,3,3,"storeAppendPrintf(e, ""%s %s:%d cert=\""%s\"" key=\""%s\""\n"",
	    n,
	    inet_ntoa(s->s.sin_addr),
	    ntohs(s->s.sin_port),
	    s->cert,
	    s->key);","storeAppendPrintf(e, ""%s %s:%d cert=\""%s\"" key=\""%s\"""",
	    n,
	    inet_ntoa(s->s.sin_addr),
	    ntohs(s->s.sin_port),
	    s->cert,
	    s->key);","[""updateContent""]","[[""\\n""], []]",[-11776070748106360],7637,416571.4285714286,7
https://github.com/squid-cache/squid/commit/653b264eeed1a764bf6bcde2b7704f888cbf9cd7,02 Mar 2003,"David J N Begley <d.begley@uws.edu.au>

 - Netscape API support for LDAP over SSL (-E option)

 - Timeout options (-t and -c)",253,data/crawl/squid/hunk_5298.cpp,use same text,trivial,data/crawl/squid/old_hunk_5298.cpp,data/crawl/squid/new_hunk_5298.cpp,3,3,"fprintf(stderr, ""squid_ldap_auth: ERROR: Unknown search scope '%s'\n"", value);","fprintf(stderr, PROGRAM_NAME "": ERROR: Unknown search scope '%s'\n"", value);","[""updateContent"", ""addVariable""]","[[""squid_ldap_auth""], [""PROGRAM_NAME""]]",[-1507727038595517550],7636,0.0,7
https://github.com/squid-cache/squid/commit/1e5562e38ca48d8bf81a6049de49afbc0547de23,20 May 2003,"Summary: Merge in external acl refactoring and tagged delay pools.
Keywords:

Patches applied:

  * robertc@squid-cache.org--squid/squid--tagged-pools--3.0--patch-5
     Enable class 5 pools.

  * robertc@squid-cache.org--squid/squid--tagged-pools--3.0--patch-4
     Implement tag associated delay pools.

  * robertc@squid-cache.org--squid/squid--tagged-pools--3.0--patch-3
     Refactoring external acl.

  * robertc@squid-cache.org--squid/squid--tagged-pools--3.0--patch-2
     Extract ExternalACLState to separate files.

  * robertc@squid-cache.org--squid/squid--tagged-pools--3.0--patch-1
     Create a tagging method for external acl replies.

  * robertc@squid-cache.org--squid/squid--tagged-pools--3.0--base-0
     tag of robertc@squid-cache.org--squid/squid--HEAD--3.0--patch-171",10400,data/crawl/squid/hunk_5247.cpp,use same text,non-trivial,data/crawl/squid/old_hunk_5247.cpp,data/crawl/squid/new_hunk_5247.cpp,-1,106,,"storeAppendPrintf(sentry, ""\t\tCurrent: "");","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""\\t\\tCurrent""]]",[6528457113049910470],7635,1115177.142857143,7
https://github.com/squid-cache/squid/commit/3e7b6055489b13ca3faa9eef01b42a74971f84e4,20 Mar 2008,"Importing CVS squid3-ecap branch:

lib/Makefile.am
        Added libLtdl to SUBDIRS if USE_LOADABLE_MODULES.


src/ICAP/ICAPModXact.h
src/ICAP/ICAPServiceRep.h

        When USE_ECAP_AS_ICAP_HACK macro is defined, enable a temporary
        hack that uses ICAP class names to implement some of the eCAP
        classes. This is necessary to hide eCAP/ICAP distinction from
        Squid core. Hiding the distinction is necessary to avoid
        numerous conflicts when this branch is merged with async call
        branch changes.
        
        Once the branches are merged, the hack will be removed. Since
        we currently #define eCAP class names to match those of ICAP
        classes, the changes at that time should not be significant:
        remove renaming #defines and adjust autotools meta files to
        allow both ICAP and eCAP co-exist.



configure.in
src/Makefile.am

        Enable eCAP support if loadable module support is enabled.
        Eventually, we may want to control eCAP support directly.
        
        Added eCAP directory to the Makefile. The eCAP directory
        contents will be committed later.



SPONSORS
        Added eCAP sponsor.


src/Makefile.am
        When eCAP is enabled, to support USE_ECAP_AS_ICAP_HACK, ignore
        ICAP files that eCAP overwrites.


configure.in

        Added --enable-ecap option to control eCAP support explicitly.
        Added consistency checks for the combination of --enable-ecap,
        --enable-icap-client, and --disable-loadable-modules options.
        
        Define USE_ECAP_AS_ICAP_HACK macro to enable a temporary hack
        that uses ICAP class names to implement some of the eCAP
        classes. This is necessary to hide eCAP/ICAP distinction from
        Squid core. Hiding the distinction is necessary to avoid
        numerous conflicts when this branch is merged with async call
        branch changes.
        
        Once the branches are merged, the hack will be removed. Since
        we currently #define eCAP class names to match those of ICAP
        classes, the changes at that time should not be significant:
        remove renaming #defines and adjust autotools meta files to
        allow both ICAP and eCAP co-exist.



Makefile.am
acinclude.m4
bootstrap.sh
configure.in
src/Makefile.am

        Added basic support for Libtool ltdl. Libltdl directory is not
        committed yet because I want to investigate whether it can be
        moved from root to lib/. Bootstrap.sh currently strips a large
        copying file from that directory but does not attempt to move
        the directory itself.
        
        The configure options will need to be changed according to
        squid-dev discussion: we should assume that ltdl is always used
        if modules are used, and we should have a --disable-modules
        option.
        
        The code works with a dummy module: Squid was able to load and
        unload using LoadableModule, an ltdl wrapper class from Spicer.
        I have not committed that wrapper yet.

Makefile.am
bootstrap.sh
configure.in
src/Makefile.am

        Moved Libtool libltdl directory to lib/libLtdl to keep all
        3rd-party libs in one place. Will commit the lib/libLtdl
        directory itself soon.
        
        Bootstrap.sh currently moves all files from the generated
        libltdl into lib/libLtdl. A better approach may be to use the
        --ltdl option of libtoolize. Will investigate.
        
        Changed configure options to assume that ltdl is always used if
        modules are used.",48970,data/crawl/squid/hunk_4347.cpp,use same variable,non-trivial,data/crawl/squid/old_hunk_4347.cpp,data/crawl/squid/new_hunk_4347.cpp,-1,1367,,"printf (""vax-dec-bsd\n"");","[""addLog""]","[[], [""printf"", ""vax"", ""dec"", ""bsd\\n""]]",[7042265659612649168],7634,3210377.1428571427,7
https://github.com/squid-cache/squid/commit/52b694c261d85aebcebcb3c74e79fbaf3b3a945a,24 Mar 2008,"Fix IPv4 request regression after last commit.

Sorry guys.",15133,data/crawl/squid/hunk_4341.cpp,use same text,non-trivial,data/crawl/squid/old_hunk_4341.cpp,data/crawl/squid/new_hunk_4341.cpp,3,3,"printf (""arm-acorn-riscix"");","printf (""arm-acorn-riscix\n"");","[""updateContent""]","[[""riscix""], [""riscix\\n""]]",[-3839271978006135108],7633,134537.14285714287,7
https://github.com/squid-cache/squid/commit/80ec8b2147eb7c106fe8a1312683f8aea6ef010d,25 Mar 2008,Bootstrapped,15110,data/crawl/squid/hunk_4339.cpp,use same text,non-trivial,data/crawl/squid/old_hunk_4339.cpp,data/crawl/squid/new_hunk_4339.cpp,3,3,"printf (""arm-acorn-riscix\n"");","printf (""arm-acorn-riscix"");","[""updateContent""]","[[""riscix\\n""], [""riscix""]]",[3839271978006135108],7632,135771.42857142858,7
https://github.com/squid-cache/squid/commit/4ef877d67aaff7156b5611db55b45cb7c57a0120,06 Feb 2009,"Author: Francesco Chemolli <kinkie@squid-cache.org>
String NG : fixes initial merge, take 2

Compared to the retired first attempt it:
 - fixes the issues Tsantilas Christos found out about
 - implements String::find
 - some more users analyzed and fixed.",654,data/crawl/squid/hunk_3929.cpp,invoke same method,non-trivial,data/crawl/squid/old_hunk_3929.cpp,data/crawl/squid/new_hunk_3929.cpp,2,2,"storeAppendPrintf(e, ""%2d\t %-25s\t %5d\t %6.3f\t %6.3f\n"",
                          f->id, f->name.buf(), f->stat.aliveCount,
                          xpercent(f->stat.errCount, f->stat.parsCount),
                          xpercent(f->stat.repCount, f->stat.seenCount));","storeAppendPrintf(e, ""%2d\t %-25s\t %5d\t %6.3f\t %6.3f\n"",
                          f->id, f->name.termedBuf(), f->stat.aliveCount,
                          xpercent(f->stat.errCount, f->stat.parsCount),
                          xpercent(f->stat.repCount, f->stat.seenCount));","[""updateVariable""]","[[""buf""], [""termedBuf""]]",[6611493792027371697],7631,0.0,7
https://github.com/squid-cache/squid/commit/8007180b22cef9ff8c0c12127b5de2f1dbbea82e,18 Feb 2009,"Author: Francesco Chemolli <kinkie@squid-cache.org>
String NG : basic SquidString updates pt 2

- finished the analysis of raw buffer exporting, divided among c-sting
and raw-buf access clients
- general sanitization
- reversal of some wrongly-renamed variables and comments
- implementation of SQUIDSTRINGPRINT and SQUIDSTRINGPH (placeholder) macros and
    psize() function for printf-style calls
- implementation of, and migration to, String::size_type and String::npos
- de-inlining of pos(), rpos(), find() and rfind() calls
- implementation and use of a proper substr() call",544,data/crawl/squid/hunk_3871.cpp,invoke same method,non-trivial,data/crawl/squid/old_hunk_3871.cpp,data/crawl/squid/new_hunk_3871.cpp,5,5,"rep->header.putStr(HDR_X_ACCELERATOR_VARY, vary.unsafeBuf());","rep->header.putStr(HDR_X_ACCELERATOR_VARY, vary.termedBuf());","[""updateVariable""]","[[""unsafeBuf""], [""termedBuf""]]",[4199209083615320289],7630,8022.857142857143,7
https://github.com/squid-cache/squid/commit/08723f8a014d62c38c4fac205f42068c0df7823a,03 Feb 2011,"SMP SNMP

The attached patch implements aggregation of SNMP responses, similar to how 
we aggregate some cache manager stats. 

The code contains changes that allow us to share some of the classes between 
Cache Manager and SNMP code:

  * implement the following base classes under the ipc directory/module:
    - Ipc::Forwarder (ipc/Forwarder{.cc,.h} files)
    - Ipc::Inquirer (ipc/Inquirer{.cc,.h} files)
    - Ipc::Request (ipc/Request{.cc,.h} files)
    - Ipc::Response (ipc/Response{.cc,.h} files)

  * fix the Mgr::Forwarder, Mgr::Inquirer, Mgr::Request and Mgr::Response 
    classes to be implemented as kid classes of the equivalent Icp::* classes.

Also implements for the SNMP the same mechanism used for cache manager: 
The SNMP requests forwarder to coordinator which collects the statistics from 
kids and aggregate them.

This is a Measurement Factory project",3051,data/crawl/squid/hunk_2761.cpp,inner similar method,non-trivial,data/crawl/squid/old_hunk_2761.cpp,data/crawl/squid/new_hunk_2761.cpp,-1,52,,"mustStop(""commClosed"");","[""addLog""]","[[], [""mustStop"", ""commClosed""]]",[-196900071475591971],7629,74468.57142857143,7
https://github.com/squid-cache/squid/commit/995eb827aaa64d9bcd4110b756e04051ef9d03e9,02 Mar 2011,merge from trunk,12916,data/crawl/squid/hunk_2729.cpp,inner similar method,non-trivial,data/crawl/squid/old_hunk_2729.cpp,data/crawl/squid/new_hunk_2729.cpp,3,3,"storeAppendPrintf(sentry, ""FQDNcache Entries: %d\n"",
                      memInUse(MEM_FQDNCACHE_ENTRY));","storeAppendPrintf(sentry, ""FQDNcache Entries In Use: %d\n"",
                      memInUse(MEM_FQDNCACHE_ENTRY));","[""updateContent""]","[[], [""In"", ""Use""]]",[-2607846366279385415],7628,16457.14285714286,7
https://github.com/squid-cache/squid/commit/d1f3d8f885784c89a822c35ddf6537aab3a3b925,06 Aug 2014,merge from trunk r13526,34418,data/crawl/squid/hunk_1299.cpp,invoke same log method,non-trivial,data/crawl/squid/old_hunk_1299.cpp,data/crawl/squid/new_hunk_1299.cpp,3,3,"fatal(""Squid has attempted to read data from memory that is not present. This is an indication of of (pre-3.0) code that hasn't been updated to deal with sparse objects in memory. Squid should coredump.allowing to review the cause. Immediately preceding this message is a dump of the available data in the format [start,end). The [ means from the value, the ) means up to the value. I.e. [1,5) means that there are 4 bytes of data, at offsets 1,2,3,4.\n"");","fatal_dump(""Squid has attempted to read data from memory that is not present. This is an indication of of (pre-3.0) code that hasn't been updated to deal with sparse objects in memory. Squid should coredump.allowing to review the cause. Immediately preceding this message is a dump of the available data in the format [start,end). The [ means from the value, the ) means up to the value. I.e. [1,5) means that there are 4 bytes of data, at offsets 1,2,3,4.\n"");","[""updateLog""]","[[""fatal""], [""fatal_dump""]]",[-3765830668276604274],7627,7230034.285714285,7
https://github.com/squid-cache/squid/commit/3ac5bd881bf4eda91a239a9db7734be91d360822,23 Aug 2014,Sync with trunk rev.13542,101061,data/crawl/squid/hunk_1217.cpp,check similar variable,non-trivial,data/crawl/squid/old_hunk_1217.cpp,data/crawl/squid/new_hunk_1217.cpp,14,-1,"fprintf(tracefp, ""m:%d:%p\n"", sz, p);",,"[""removeLog""]","[[""fprintf"", ""tracefp"", ""m"", ""%d"", ""%p\\n"", ""sz"", ""p""], []]",[4165763358341692610],7626,1085142.857142857,7
https://github.com/squid-cache/squid/commit/3ac5bd881bf4eda91a239a9db7734be91d360822,23 Aug 2014,Sync with trunk rev.13542,101061,data/crawl/squid/hunk_1216.cpp,check similar variable,non-trivial,data/crawl/squid/old_hunk_1216.cpp,data/crawl/squid/new_hunk_1216.cpp,14,-1,"fprintf(tracefp, ""c:%u:%u:%p\n"", (unsigned int) n, (unsigned int) sz, p);",,"[""removeLog""]","[[""fprintf"", ""tracefp"", ""c"", ""%u"", ""%u"", ""%p\\n"", ""unsigned"", ""int"", ""n"", ""unsigned"", ""int"", ""sz"", ""p""], []]",[33602757814329880716],7625,1085142.857142857,7
https://github.com/squid-cache/squid/commit/50ad1e256824307b27dae0fbb078d65df8e2f816,21 Dec 2016,"Cleanup: Refactor libauth Config object(s)

Refactoring the Auth::Config objects to get v5 building again.

The object storing auth_param settings is renamed to SchemeConfig.

A new Auth::Config object is added. The objects holding auth_param,
auth_schemes and other authenticate_* directives settings are stored
there instead of just auth_params.

Lots of outdated doxygen docs that have more up to date copies elsewhere
are removed. The ""\ingroup AuthAPI"" are left for now since some auth
things are not yet in the Auth:: namespace, but other auth related
groups are dropped completely.

Code parsing and dumping auth_param lines has been de-duplicated. Along
with the keep_alive and utf8 settings, which are shared by multiple
schemes. This allows dropping several virtual methods from NTLM and
Negotiate scheme objects.

An auth/forward.h file is added for predefines. Some initial Auth::
symbols are listed there. It is not complete, but others can be added as
needed later.

Some unnecessary includes have been removed. There are probably more. I
just did the obvious ones related to the new auth/forward.h and
auth/Config.h files at this time.",1335,data/crawl/squid/hunk_104.cpp,check similar variable,non-trivial,data/crawl/squid/old_hunk_104.cpp,data/crawl/squid/new_hunk_104.cpp,-1,148,,"storeAppendPrintf(entry, "" %s"", list->key);","[""addLog""]","[[], [""storeAppendPrintf"", ""entry"", ""%s"", ""list"", ""key""]]",[18527958583169795512],7624,3589302.8571428573,7
https://github.com/squid-cache/squid/commit/30a4f2a885dbb469498c0e805e1e8d42244788be,09 Jul 1996,cleanup after big merge,12717,data/crawl/squid/hunk_7740.cpp,use same text,trivial,data/crawl/squid/old_hunk_7740.cpp,data/crawl/squid/new_hunk_7740.cpp,3,3,"storeAppendPrintf(sentry, ""{\n"");","storeAppendPrintf(sentry, open_bracket);","[""removeContent"", ""addVariable""]","[[""\\n""], [""open_bracket""]]",[8910855836114536213],7623,0.0,6
https://github.com/squid-cache/squid/commit/627f6d02e9baad40c38bd35ef893fc6bc9a22ca1,21 Nov 1997,"SNMP, cmu derived, heavily modified",5272,data/crawl/squid/hunk_6957.cpp,check similar variable,non-trivial,data/crawl/squid/old_hunk_6957.cpp,data/crawl/squid/new_hunk_6957.cpp,-1,675,,"print_error(""Warning: This entry is pretty silly"",
				np->label, type);","[""addLog""]","[[], [""print_error"", ""Warning"", ""This"", ""entry"", ""is"", ""pretty"", ""silly"", ""np"", ""label"", ""type""]]",[-3855785183751805220],7622,0.0,6
https://github.com/squid-cache/squid/commit/1df370e38a088aa3c12e0971d7324351325ff724,02 Dec 1997,"make SNMP code #ifdef-able, including config parsing",122,data/crawl/squid/hunk_6891.cpp,check similar return value,non-trivial,data/crawl/squid/old_hunk_6891.cpp,data/crawl/squid/new_hunk_6891.cpp,-1,5,,"printf(""Error on line %d\n"", linenum);","[""addLog""]","[[], [""printf"", ""Error"", ""on"", ""line"", ""%d\\n"", ""linenum""]]",[23449878132933055095],7621,37920.0,6
https://github.com/squid-cache/squid/commit/15576b6a58a24ed2705d6228d0fde8cfcef26cae,07 Feb 1998,remove brackets from cachemgr output,390,data/crawl/squid/hunk_6814.cpp,use same text,non-trivial,data/crawl/squid/old_hunk_6814.cpp,data/crawl/squid/new_hunk_6814.cpp,13,13,"storeAppendPrintf(sentry,
		""{        %-20.20s %7d %3d%%}\n"",
		log_tags[l],
		c->Icp.result_hist[l],
		percent(c->Icp.result_hist[l], c->Icp.n_requests));","storeAppendPrintf(sentry,
		""        %-20.20s %7d %3d%%\n"",
		log_tags[l],
		c->Icp.result_hist[l],
		percent(c->Icp.result_hist[l], c->Icp.n_requests));","[""updateContent""]","[[""%3d%%"", ""\\n""], [""%3d%%\\n""]]",[3520244070347549960],7620,0.0,6
https://github.com/squid-cache/squid/commit/a0f327753bc3041cabaf2e606fa0c878a1854243,05 Mar 1998,"Added more server-side counters and accounting based on patch from
Lincon Dale.  Also removed some '#if 0' code chunks.",404,data/crawl/squid/hunk_6637.cpp,check similar variable,non-trivial,data/crawl/squid/old_hunk_6637.cpp,data/crawl/squid/new_hunk_6637.cpp,-1,17,,"storeAppendPrintf(e, ""(no values recorded yet)\n"");","[""addLog""]","[[], [""storeAppendPrintf"", ""e"", ""no"", ""values"", ""recorded"", ""yet"", ""\\n""]]",[10243070043228460127],7619,0.0,6
https://github.com/squid-cache/squid/commit/6b53c3926e3c3712886d780bc903488591f73fe7,03 May 2000,"hno squid-2.3.DEVEL3.squid.conf_template_update-4.patch
Squid-2.3.DEVEL3: Major update of squid.conf template generation

A major update on how squid.conf is generated from cf.data.pre and
some related changes.

* Default lines are generated from the compiled default settings (less
  duplication in cf.data.pre)
* Non-enabled functions gets a note telling that the directive isn't enabled
  and what configure option (or defined) that is required to enable it.

Some cleanup of how some defines are used..",588,data/crawl/squid/hunk_6060.cpp,use same text,non-trivial,data/crawl/squid/old_hunk_6060.cpp,data/crawl/squid/new_hunk_6060.cpp,-1,27,,"fprintf(fp, ""#\n"");","[""addLog""]","[[], [""fprintf"", ""fp"", ""\\n""]]",[-5179306325123647028],7618,571680.0,6
https://github.com/squid-cache/squid/commit/6708c52c59cd7fe5a6d2a4857c5e0b897a6e5f3c,28 Nov 2002,squid_ldap_group upgrade to version 2.8,367,data/crawl/squid/hunk_5489.cpp,use same text,trivial,data/crawl/squid/old_hunk_5489.cpp,data/crawl/squid/new_hunk_5489.cpp,3,3,"fprintf(stderr, ""squid_ldap_match: ERROR: Unknown search scope '%s'\n"", value);","fprintf(stderr, PROGRAM_NAME "" ERROR: Unknown search scope '%s'\n"", value);","[""updateContent"", ""addVariable""]","[[""squid_ldap_match""], [""PROGRAM_NAME""]]",[2098943339665693782],7617,0.0,6
https://github.com/squid-cache/squid/commit/d3b3ab859857da0851f9c7de916b6df261ba43ae,27 Dec 2002,apply unify io patch to simplify IO code for diskd/aufs/ufs,7586,data/crawl/squid/hunk_5473.cpp,check similar return value,non-trivial,data/crawl/squid/old_hunk_5473.cpp,data/crawl/squid/new_hunk_5473.cpp,-1,641,,"fatal(""storeDirOpenTmpSwapLog: Failed to open swap log."");","[""addLog""]","[[], [""fatal"", ""storeDirOpenTmpSwapLog"", ""Failed"", ""to"", ""open"", ""swap"", ""log""]]",[-7196785520234966959],7616,1771200.0,6
https://github.com/squid-cache/squid/commit/d3b3ab859857da0851f9c7de916b6df261ba43ae,27 Dec 2002,apply unify io patch to simplify IO code for diskd/aufs/ufs,7586,data/crawl/squid/hunk_5473.cpp,check similar return value,non-trivial,data/crawl/squid/old_hunk_5473.cpp,data/crawl/squid/new_hunk_5473.cpp,-1,379,,"fatalf(""Failed to make swap directory %s: %s"",
	    path, xstrerror());","[""addLog""]","[[], [""fatalf"", ""Failed"", ""to"", ""make"", ""swap"", ""directory"", ""%s"", ""%s"", ""path"", ""xstrerror""]]",[-4186603929638388916],7615,1290000.0,6
https://github.com/squid-cache/squid/commit/d3b3ab859857da0851f9c7de916b6df261ba43ae,27 Dec 2002,apply unify io patch to simplify IO code for diskd/aufs/ufs,7586,data/crawl/squid/hunk_5473.cpp,check similar return value,non-trivial,data/crawl/squid/old_hunk_5473.cpp,data/crawl/squid/new_hunk_5473.cpp,-1,369,,"fatalf(""Swap directory %s is not a directory."", path);","[""addLog""]","[[], [""fatalf"", ""Swap"", ""directory"", ""%s"", ""is"", ""not"", ""a"", ""directory"", ""path""]]",[16895851936805237112],7614,1290000.0,6
https://github.com/squid-cache/squid/commit/e40497560cb00f30ce91a4771a5c23ff39418fc8,29 Sep 2003,"Summary: Merge Gerard's AIX signed and datatype size patches.
Keywords:

Patches applied:

 * gerard@eviston.net--squid/squid--aix-fixes--3.0--patch-5
   typecast ntohl() in wccp.cc

 * ports@eviston.net--aix/squid--aix-fixes--3.0--patch-3
   debug() ==> debugs() round 1

 * ports@eviston.net--aix/squid--aix-fixes--3.0--patch-4
   casts and format strings

 * ports@eviston.net--aix/squid--aix-fixes--3.0--patch-5
   debug() => debugs() round 2: peer_digest.cc

 * ports@eviston.net--aix/squid--aix-fixes--3.0--patch-6
   casts in stat.cc

 * ports@eviston.net--aix/squid--aix-fixes--3.0--patch-7
   debug() => debugs() round 3

 * ports@eviston.net--aix/squid--aix-fixes--3.0--patch-8
   cast for ntohl() in wccp.cc

 * ports@eviston.net--aix/squid--aix-fixes--3.0--patch-9
   casts in tools.cc",196,data/crawl/squid/hunk_5172.cpp,use same variable,non-trivial,data/crawl/squid/old_hunk_5172.cpp,data/crawl/squid/new_hunk_5172.cpp,6,6,"storeAppendPrintf(sentry, ""\tOrdinary blocks:       %6d KB %6d blks\n"",
                      mp.uordblks >> 10, mp.ordblks);","storeAppendPrintf(sentry, ""\tOrdinary blocks:       %6ld KB %6ld blks\n"",
                      (long)mp.uordblks >> 10, (long)mp.ordblks);","[""updateContent"", ""addVariable""]","[[""%6d"", ""%6d""], [""%6ld"", ""%6ld"", ""long"", ""long""]]",[33773014759847303342],7613,0.0,6
https://github.com/squid-cache/squid/commit/64ffef5e31e8f777b78433310774cdd6fc4865f1,01 May 2005,"Bug #1267: Cosmetic change to DISKD statistics

This patch align labels and expand OPS and SUCCESS fields of DISKD cachemgr
stats.",16,data/crawl/squid/hunk_5044.cpp,use same text format,non-trivial,data/crawl/squid/old_hunk_5044.cpp,data/crawl/squid/new_hunk_5044.cpp,4,4,"storeAppendPrintf(sentry, ""%7s %7d %7d %7d\n"",
                      ""open"", diskd_stats.open.ops, diskd_stats.open.success, diskd_stats.open.fail);","storeAppendPrintf(sentry, ""%7s %9d %9d %7d\n"",
                      ""open"", diskd_stats.open.ops, diskd_stats.open.success, diskd_stats.open.fail);","[""updateContent""]","[[""%7d"", ""%7d""], [""%9d"", ""%9d""]]",[-4000020],7612,0.0,6
https://github.com/squid-cache/squid/commit/b6b6f46632f4820a1a473fd51f38040945880fe7,04 Jan 2006,"Converted FwdState to a C++ class to take advantage of features
such as refcounting.",1345,data/crawl/squid/hunk_4887.cpp,use same text,non-trivial,data/crawl/squid/old_hunk_4887.cpp,data/crawl/squid/new_hunk_4887.cpp,-1,39,,"storeAppendPrintf(s, ""\n"");","[""addLog""]","[[], [""storeAppendPrintf"", ""s"", ""\\n""]]",[5193143779093595017],7611,1251840.0,6
https://github.com/squid-cache/squid/commit/9c8434f6a8753d321762ff58685cb1ff0364b4a7,14 Sep 2006,"Windows port: split Windows service code into WinSvc.cc, allowing correct execution of make check",1963,data/crawl/squid/hunk_4750.cpp,check similar return value,non-trivial,data/crawl/squid/old_hunk_4750.cpp,data/crawl/squid/new_hunk_4750.cpp,-1,634,,"fprintf(stderr, ""OpenSCManager failed\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""OpenSCManager"", ""failed\\n""]]",[-21828551817829994559],7610,894240.0,6
https://github.com/squid-cache/squid/commit/c99de60701b56be31c01be2045d204ed411e33ca,01 Nov 2006,"	- Many ICAP fixes from Alex Rousskov accumulated on the
	  sourceforge squid3-icap branch since 2006/10, including:

        - Polished ICAP service selection code and implemented bypass of
          optional services. The code implements icap_class
          configuration directive which is currently used as a ""set of
          interchangeable ICAP services"". Squid2 and current squid.conf
          may imply otherwise.

        - Support Transfer-* ICAP OPTIONS response header. If Squid
          knows that a service does not want the URL, Squid will not use
          the service, even if it is an essential service with
          bypass=0. Note that we may make this decision before we know
          what the service wants. Eventually, ACLs should initiate and
          wait for the OPTIONS transaction for yet-unprobed services.

        - When ICAP transactions fail to connect to the service many
          times, the service is suspended until the next OPTIONS
          update. The limit is currently hard-coded to 10. Suspended
          service is a down service and will be skipped by the ACL
          service selection algorithm.

        - Rewrote the code updating ICAP service options. We no longer
          mark the service being updated as ""down"". Only presence of
          valid and fresh options is important. We also try to update
          the options before they expire to avoid any service downtime
          or use of stale options.

        - Report interesting changes in the ICAP service state, some
          with debugging level one to alert the cache administrator.

        - When cloning a request during an ICAP 204 ""No Content"" REQMOD
          response, preserve the client address so that the rest of the
          code has access to it. This change appears to fix Squid Bug
          #1712.

        - After ICAP 100 Continue, expect new ICAP headers instead of
          HTTP headers. Reset ICAP message object to be ready to parse
          ICAP headers again. (Tsantilas Christos
          <chtsanti@users.sourceforge.net>)

        - The ieof HTTP chunk-extension was written after chunk-data
          instead of being written after the chunk-size. (Tsantilas
          Christos <chtsanti@users.sourceforge.net>)

        - Merged common code from the ICAPClientReqmodPrecache and
          ICAPClientReqmodPrecache classes into the newly added
          ICAPClientVector class.  The specific vectors do not have a
          common owner (yet?) because ServerStateData and
          ClientHttpRequest do not have a common base class. Thus,
          ICAPClientVector has to rely on its kids to communicate with
          their owners. However, at least 50% of the logic was common
          and has been moved. Eventually, we may want to create a
          simple ICAPOwner API that ServerStateData and
          ClientHttpRequest can implement and ICAPClientVector can rely
          on. This will make the code simpler and more efficient.  The
          big merge was motivated by a couple of bugs that were found
          in one vector class but that did not exist or behaved
          differently in the other vector, mostly likely due to natural
          diversion of used-to-be identical code.

        - Rewrote communication between a server-side ICAPClient*mod*
          vector and its owner.  When a server-side ICAPClient*mod*
          vector was notifying its owner of more adapted data, the
          owner could delete the vector (by calling icap->ownerAbort)
          if the store entry was not willing to accept the data.  The
          same deletion could happen when a vector was notifying the
          owner of a successful termination. In all those cases, the
          vector did not expect to be deleted and could continue to do
          something, causing segmentation faults.  Now, when more data
          is available, the vector calls its owner and checks the
          return value of the call. If it is false, the vector knows it
          has been deleted and quits. When vector terminates, it calls
          its owner and trusts the owner to always delete the vector.
          The ""check return value and quit"" design is not perfect, but
          we are paying the price for isolating the vectors from their
          owners while using direct calls between them (instead of
          MsgPipe or a similar less efficient indirect approach we use
          elsewhere).

        - Renamed doIcap to startIcap and moved more common code there.
          Changed its return type to bool. We now handle three cases
          when ICAP ACLs call back:  1) No service was selected
          (because there was no applicable service or because all
          applicable services were broken and optional). We proceed as
          if ICAP was not configured.  2) The selected essential
          service is broken. This is a fatal transaction error and we
          return an ""ICAP protocol error"" HTTP error response. We could
          proceed with the ICAP stuff, but it saves a lot of cycles to
          abort early.  3) The selected service is not broken. We
          proceed with the ICAP stuff.  The old code did not detect
          case #2, even though there was code to handle that case (with
          dangerous XXX suggestions that are now gone).  The code
          should probably be polished further to move common ftp/http
          logic from icapAclCheckDone()s into ServerStateData.

        - Make sure there is an accept callback when we are accepting.
          If there is no callback and we accept, we will silently leak
          the accepted FD.  When we are running out of FDs, there is
          often no accept callback.  The old code, when running out of
          FDs, would create lots of ""orphaned"" or ""forgotten"" FDs that
          will eventually get into a CLOSED_WAIT state and remain there
          until Squid quits.  The new code does not call accept() if
          there is no accept callback and does not register the accept
          FD for reading if the AcceptLimiter is deferring, because
          when the AcceptLimiter kicks in, it will register the accept
          FD for reading. There are most likely other places/cases
          where accept FD should not be registered for reading.

        - When an exception is caught, mark the ICAP connection as
          non-reusable so that it is not recycled while a write is
          pending but simply closed instead. Our write callback will
          still be called, unfortunately, because there is no way to
          clear the callback without invalidating its data (i.e., the
          transaction pointer).  This change prevents pconn.cc:253:
          ""!comm_has_incomplete_write(fd)"" assertion from firing when
          things go wrong (e.g., the ICAP server cannot be contacted to
          retrieve OPTIONS).  Not all exceptions caught by the ICAP
          xaction should lead to the ICAP connection termination, but
          it is very difficult if not impossible to reliably detect
          exceptional conditions when it is safe to reuse the ICAP
          connection, and it is probably not worth it anyway.

        - Added Tsantilas Christos <chtsanti@users.sourceforge.net>
          to CONTRIBUTORS for fixing ICAP bugs.

        - Polished debugging.",2091,data/crawl/squid/hunk_4725.cpp,inner similar method,non-trivial,data/crawl/squid/old_hunk_4725.cpp,data/crawl/squid/new_hunk_4725.cpp,-1,112,,stop(notifyOwner);,"[""addLog""]","[[], [""stop"", ""notifyOwner""]]",[-4780997408801844825],7609,165120.0,6
https://github.com/squid-cache/squid/commit/89f77e43f36bdbd636826c94085f9b5d882e473d,24 Jun 2007,"Bug #1948: digest_edir_auth helper, using novell eDirectory universal password

This is a modified version of digets_ldap_auth, with eDirectory special hooks
for retrieving the Universal Password plain text password.",1874,data/crawl/squid/hunk_4545.cpp,check similar return value,non-trivial,data/crawl/squid/old_hunk_4545.cpp,data/crawl/squid/new_hunk_4545.cpp,-1,401,,"fprintf(stderr, ""Could not Activate TLS connection\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""Could"", ""not"", ""Activate"", ""TLS"", ""connection\\n""]]",[-94042995092749779],7608,1223280.0,6
https://github.com/squid-cache/squid/commit/89f77e43f36bdbd636826c94085f9b5d882e473d,24 Jun 2007,"Bug #1948: digest_edir_auth helper, using novell eDirectory universal password

This is a modified version of digets_ldap_auth, with eDirectory special hooks
for retrieving the Universal Password plain text password.",1874,data/crawl/squid/hunk_4545.cpp,check similar return value,non-trivial,data/crawl/squid/old_hunk_4545.cpp,data/crawl/squid/new_hunk_4545.cpp,-1,393,,"fprintf(stderr, ""Could not set LDAP_OPT_PROTOCOL_VERSION %d\n"",
		version);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""Could"", ""not"", ""set"", ""LDAP_OPT_PROTOCOL_VERSION"", ""%d\\n"", ""version""]]",[14165094135550653739],7607,1223280.0,6
https://github.com/squid-cache/squid/commit/89f77e43f36bdbd636826c94085f9b5d882e473d,24 Jun 2007,"Bug #1948: digest_edir_auth helper, using novell eDirectory universal password

This is a modified version of digets_ldap_auth, with eDirectory special hooks
for retrieving the Universal Password plain text password.",1874,data/crawl/squid/hunk_4545.cpp,check similar return value,non-trivial,data/crawl/squid/old_hunk_4545.cpp,data/crawl/squid/new_hunk_4545.cpp,-1,375,,"fprintf(stderr, ""\nUnable to connect to SSL LDAP server: %s port:%d\n"",
		    ldapServer, port);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""\\nUnable"", ""to"", ""connect"", ""to"", ""SSL"", ""LDAP"", ""server"", ""%s"", ""port"", ""%d\\n"", ""ldapServer"", ""port""]]",[3455699060833364420],7606,940800.0,6
https://github.com/squid-cache/squid/commit/89f77e43f36bdbd636826c94085f9b5d882e473d,24 Jun 2007,"Bug #1948: digest_edir_auth helper, using novell eDirectory universal password

This is a modified version of digets_ldap_auth, with eDirectory special hooks
for retrieving the Universal Password plain text password.",1874,data/crawl/squid/hunk_4545.cpp,check similar return value,non-trivial,data/crawl/squid/old_hunk_4545.cpp,data/crawl/squid/new_hunk_4545.cpp,-1,368,,"fprintf(stderr, ""\nUnable to initialise SSL with cert path %s\n"",
		    sslpath);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""\\nUnable"", ""to"", ""initialise"", ""SSL"", ""with"", ""cert"", ""path"", ""%s\\n"", ""sslpath""]]",[8616501409148837831],7605,940800.0,6
https://github.com/squid-cache/squid/commit/89f77e43f36bdbd636826c94085f9b5d882e473d,24 Jun 2007,"Bug #1948: digest_edir_auth helper, using novell eDirectory universal password

This is a modified version of digets_ldap_auth, with eDirectory special hooks
for retrieving the Universal Password plain text password.",1874,data/crawl/squid/hunk_4545.cpp,check similar return value,non-trivial,data/crawl/squid/old_hunk_4545.cpp,data/crawl/squid/new_hunk_4545.cpp,-1,361,,"fprintf(stderr, ""\nUnable to connect to LDAPURI:%s\n"", ldapServer);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""\\nUnable"", ""to"", ""connect"", ""to"", ""LDAPURI"", ""%s\\n"", ""ldapServer""]]",[-968658030135572842],7604,941760.0,6
https://github.com/squid-cache/squid/commit/89f77e43f36bdbd636826c94085f9b5d882e473d,24 Jun 2007,"Bug #1948: digest_edir_auth helper, using novell eDirectory universal password

This is a modified version of digets_ldap_auth, with eDirectory special hooks
for retrieving the Universal Password plain text password.",1874,data/crawl/squid/hunk_4545.cpp,check similar return value,non-trivial,data/crawl/squid/old_hunk_4545.cpp,data/crawl/squid/new_hunk_4545.cpp,-1,230,,"fprintf(stderr, PROGRAM_NAME "": WARNING, SSL error %d (%s)\n"", sslerr, ldapssl_err2string(sslerr));","[""addLog""]","[[], [""fprintf"", ""stderr"", ""PROGRAM_NAME"", ""WARNING"", ""SSL"", ""error"", ""%d"", ""%s"", ""\\n"", ""sslerr"", ""ldapssl_err2string"", ""sslerr""]]",[-8521655138693661446],7603,820080.0,6
https://github.com/squid-cache/squid/commit/3e7b6055489b13ca3faa9eef01b42a74971f84e4,20 Mar 2008,"Importing CVS squid3-ecap branch:

lib/Makefile.am
        Added libLtdl to SUBDIRS if USE_LOADABLE_MODULES.


src/ICAP/ICAPModXact.h
src/ICAP/ICAPServiceRep.h

        When USE_ECAP_AS_ICAP_HACK macro is defined, enable a temporary
        hack that uses ICAP class names to implement some of the eCAP
        classes. This is necessary to hide eCAP/ICAP distinction from
        Squid core. Hiding the distinction is necessary to avoid
        numerous conflicts when this branch is merged with async call
        branch changes.
        
        Once the branches are merged, the hack will be removed. Since
        we currently #define eCAP class names to match those of ICAP
        classes, the changes at that time should not be significant:
        remove renaming #defines and adjust autotools meta files to
        allow both ICAP and eCAP co-exist.



configure.in
src/Makefile.am

        Enable eCAP support if loadable module support is enabled.
        Eventually, we may want to control eCAP support directly.
        
        Added eCAP directory to the Makefile. The eCAP directory
        contents will be committed later.



SPONSORS
        Added eCAP sponsor.


src/Makefile.am
        When eCAP is enabled, to support USE_ECAP_AS_ICAP_HACK, ignore
        ICAP files that eCAP overwrites.


configure.in

        Added --enable-ecap option to control eCAP support explicitly.
        Added consistency checks for the combination of --enable-ecap,
        --enable-icap-client, and --disable-loadable-modules options.
        
        Define USE_ECAP_AS_ICAP_HACK macro to enable a temporary hack
        that uses ICAP class names to implement some of the eCAP
        classes. This is necessary to hide eCAP/ICAP distinction from
        Squid core. Hiding the distinction is necessary to avoid
        numerous conflicts when this branch is merged with async call
        branch changes.
        
        Once the branches are merged, the hack will be removed. Since
        we currently #define eCAP class names to match those of ICAP
        classes, the changes at that time should not be significant:
        remove renaming #defines and adjust autotools meta files to
        allow both ICAP and eCAP co-exist.



Makefile.am
acinclude.m4
bootstrap.sh
configure.in
src/Makefile.am

        Added basic support for Libtool ltdl. Libltdl directory is not
        committed yet because I want to investigate whether it can be
        moved from root to lib/. Bootstrap.sh currently strips a large
        copying file from that directory but does not attempt to move
        the directory itself.
        
        The configure options will need to be changed according to
        squid-dev discussion: we should assume that ltdl is always used
        if modules are used, and we should have a --disable-modules
        option.
        
        The code works with a dummy module: Squid was able to load and
        unload using LoadableModule, an ltdl wrapper class from Spicer.
        I have not committed that wrapper yet.

Makefile.am
bootstrap.sh
configure.in
src/Makefile.am

        Moved Libtool libltdl directory to lib/libLtdl to keep all
        3rd-party libs in one place. Will commit the lib/libLtdl
        directory itself soon.
        
        Bootstrap.sh currently moves all files from the generated
        libltdl into lib/libLtdl. A better approach may be to use the
        --ltdl option of libtoolize. Will investigate.
        
        Changed configure options to assume that ltdl is always used if
        modules are used.",48970,data/crawl/squid/hunk_4347.cpp,check similar return value,non-trivial,data/crawl/squid/old_hunk_4347.cpp,data/crawl/squid/new_hunk_4347.cpp,-1,609,,"puts (""hppa2.0"");","[""addLog""]","[[], [""puts"", ""hppa2"", ""0""]]",[2429724524263534483],7602,1137600.0,6
https://github.com/squid-cache/squid/commit/3e7b6055489b13ca3faa9eef01b42a74971f84e4,20 Mar 2008,"Importing CVS squid3-ecap branch:

lib/Makefile.am
        Added libLtdl to SUBDIRS if USE_LOADABLE_MODULES.


src/ICAP/ICAPModXact.h
src/ICAP/ICAPServiceRep.h

        When USE_ECAP_AS_ICAP_HACK macro is defined, enable a temporary
        hack that uses ICAP class names to implement some of the eCAP
        classes. This is necessary to hide eCAP/ICAP distinction from
        Squid core. Hiding the distinction is necessary to avoid
        numerous conflicts when this branch is merged with async call
        branch changes.
        
        Once the branches are merged, the hack will be removed. Since
        we currently #define eCAP class names to match those of ICAP
        classes, the changes at that time should not be significant:
        remove renaming #defines and adjust autotools meta files to
        allow both ICAP and eCAP co-exist.



configure.in
src/Makefile.am

        Enable eCAP support if loadable module support is enabled.
        Eventually, we may want to control eCAP support directly.
        
        Added eCAP directory to the Makefile. The eCAP directory
        contents will be committed later.



SPONSORS
        Added eCAP sponsor.


src/Makefile.am
        When eCAP is enabled, to support USE_ECAP_AS_ICAP_HACK, ignore
        ICAP files that eCAP overwrites.


configure.in

        Added --enable-ecap option to control eCAP support explicitly.
        Added consistency checks for the combination of --enable-ecap,
        --enable-icap-client, and --disable-loadable-modules options.
        
        Define USE_ECAP_AS_ICAP_HACK macro to enable a temporary hack
        that uses ICAP class names to implement some of the eCAP
        classes. This is necessary to hide eCAP/ICAP distinction from
        Squid core. Hiding the distinction is necessary to avoid
        numerous conflicts when this branch is merged with async call
        branch changes.
        
        Once the branches are merged, the hack will be removed. Since
        we currently #define eCAP class names to match those of ICAP
        classes, the changes at that time should not be significant:
        remove renaming #defines and adjust autotools meta files to
        allow both ICAP and eCAP co-exist.



Makefile.am
acinclude.m4
bootstrap.sh
configure.in
src/Makefile.am

        Added basic support for Libtool ltdl. Libltdl directory is not
        committed yet because I want to investigate whether it can be
        moved from root to lib/. Bootstrap.sh currently strips a large
        copying file from that directory but does not attempt to move
        the directory itself.
        
        The configure options will need to be changed according to
        squid-dev discussion: we should assume that ltdl is always used
        if modules are used, and we should have a --disable-modules
        option.
        
        The code works with a dummy module: Squid was able to load and
        unload using LoadableModule, an ltdl wrapper class from Spicer.
        I have not committed that wrapper yet.

Makefile.am
bootstrap.sh
configure.in
src/Makefile.am

        Moved Libtool libltdl directory to lib/libLtdl to keep all
        3rd-party libs in one place. Will commit the lib/libLtdl
        directory itself soon.
        
        Bootstrap.sh currently moves all files from the generated
        libltdl into lib/libLtdl. A better approach may be to use the
        --ltdl option of libtoolize. Will investigate.
        
        Changed configure options to assume that ltdl is always used if
        modules are used.",48970,data/crawl/squid/hunk_4347.cpp,check similar return value,non-trivial,data/crawl/squid/old_hunk_4347.cpp,data/crawl/squid/new_hunk_4347.cpp,-1,601,,"puts (""hppa1.0"");","[""addLog""]","[[], [""puts"", ""hppa1"", ""0""]]",[2429724524263534486],7601,1137600.0,6
https://github.com/squid-cache/squid/commit/ed08b88c5e248d7683016e4fba2d59b9d561e70f,03 Apr 2008,"Ignore and do not version lib/libLtdl because it is libtool-generated.
Ignore cfgaux because it is libtool-generated (merged from trunk).",23843,data/crawl/squid/hunk_4331.cpp,check similar variable,non-trivial,data/crawl/squid/old_hunk_4331.cpp,data/crawl/squid/new_hunk_4331.cpp,1311,-1,"printf (""vax-dec-bsd\n"");",,"[""removeLog""]","[[""printf"", ""vax"", ""dec"", ""bsd\\n""], []]",[-7042265659612649168],7600,336960.0,6
https://github.com/squid-cache/squid/commit/ed08b88c5e248d7683016e4fba2d59b9d561e70f,03 Apr 2008,"Ignore and do not version lib/libLtdl because it is libtool-generated.
Ignore cfgaux because it is libtool-generated (merged from trunk).",23843,data/crawl/squid/hunk_4331.cpp,check similar return value,non-trivial,data/crawl/squid/old_hunk_4331.cpp,data/crawl/squid/new_hunk_4331.cpp,613,-1,"puts (""hppa2.0"");",,"[""removeLog""]","[[""puts"", ""hppa2"", ""0""], []]",[-2429724524263534483],7599,336960.0,6
https://github.com/squid-cache/squid/commit/ed08b88c5e248d7683016e4fba2d59b9d561e70f,03 Apr 2008,"Ignore and do not version lib/libLtdl because it is libtool-generated.
Ignore cfgaux because it is libtool-generated (merged from trunk).",23843,data/crawl/squid/hunk_4331.cpp,check similar return value,non-trivial,data/crawl/squid/old_hunk_4331.cpp,data/crawl/squid/new_hunk_4331.cpp,605,-1,"puts (""hppa1.0"");",,"[""removeLog""]","[[""puts"", ""hppa1"", ""0""], []]",[-2429724524263534486],7598,336960.0,6
https://github.com/squid-cache/squid/commit/2d51c9088d676bc2c47a4bc01152889d9162ab87,13 Mar 2009,"SourceLayout: acl/, take 1

Moved src/ACL* and a few related files into src/acl/.
Renamed ACL source files from ACLFoo.{cc,cci,h} to Foo.{cc,cci,h}.

Added acl/ libraries, reorganized auth/ libraries, and split ACLChecklist
class to avoid circular dependencies among libraries.

Many targets in src/Makefile.am depended on selected ACL ACL*cc and related
sources.  These targets depend on acl/* libraries now. As a part of this
cleanup, the number of ufsdump sources went from about 160 to about 20.

No functionality changes were intended. Source code changes were kept to the
minimum. All my build tests are successful. However, since I had to move a lot
of files, move some code pieces, and split ACLChecklist, it is possible that
some targets will no longer build in some environments and some authentication
code will break.

Please see individual commit messages for details.",2511,data/crawl/squid/hunk_3808.cpp,check similar return value,non-trivial,data/crawl/squid/old_hunk_3808.cpp,data/crawl/squid/new_hunk_3808.cpp,-1,71,,"fatal(""unexpected authenticateAuthenticate reply\n"");","[""addLog""]","[[], [""fatal"", ""unexpected"", ""authenticateAuthenticate"", ""reply\\n""]]",[-7738081176919200605],7597,2419200.0,6
https://github.com/squid-cache/squid/commit/e41db37b10eb9b0f41876e7287477a17e86d1250,12 Jul 2009,"Author: Markus Moeller <huaraz@moeller.plus.com>
Bug 2710: squid_kerb_auth non-terminated string",38,data/crawl/squid/hunk_3746.cpp,use same variable,non-trivial,data/crawl/squid/old_hunk_3746.cpp,data/crawl/squid/new_hunk_3746.cpp,3,12,"fprintf(stdout, ""AF %s %s\n"",token,(char *)output_token.value);","fprintf(stdout, ""AF %s %s\n"",token,user);","[""updateVariable"", ""removeVariable""]","[[""char"", ""*"", ""output_token"", ""value""], [""user""]]",[305716311373404735],7596,0.0,6
https://github.com/squid-cache/squid/commit/77721eb240367f9d4bd82638f118c811f2e93349,05 Nov 2009,"Author: Markus Moeller huaraz@moeller.plus.com>
Update squid_kerb_auth helper

 * remove sub configure again (too many issues)

Also, by Amso Jeffries
 * naming update to negotiate_kerberos_auth
 * polished helper detection rules in configure",10781,data/crawl/squid/hunk_3545.cpp,check similar return value,non-trivial,data/crawl/squid/old_hunk_3545.cpp,data/crawl/squid/new_hunk_3545.cpp,-1,539,,"fprintf(stderr, ""%s| %s: Not enough memory\n"", LogTime(),
			PROGRAM);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""%s"", ""%s"", ""Not"", ""enough"", ""memory\\n"", ""LogTime"", ""PROGRAM""]]",[-2312750529207102588],7595,981120.0,6
https://github.com/squid-cache/squid/commit/350e2aeca88de2de7eadc3a19c1fbdf0046f2e55,18 Nov 2009,"Fixed some cases of variable shadowing
Fixed shadowing-related bug in http reply handling",72,data/crawl/squid/hunk_3529.cpp,use same variable,trivial,data/crawl/squid/old_hunk_3529.cpp,data/crawl/squid/new_hunk_3529.cpp,8,8,"buf.Printf(""%""PRIu64""<=%""PRIu64, theGetSize, thePutSize);","outputBuffer.Printf(""%""PRIu64""<=%""PRIu64, theGetSize, thePutSize);","[""updateLog""]","[[""buf""], [""outputBuffer""]]",[-6896451894010301071],7594,0.0,6
https://github.com/squid-cache/squid/commit/5d8e63c9ae3b576a7b0c9c7e391c11e733ac8160,09 Feb 2010,"Author: Markus Moeller <huaraz@moeller.plus.com>
squid_kerb_auth logging clarification

add ERROR, WARNING, etc to the logging messages.",52,data/crawl/squid/hunk_3423.cpp,use same variable,trivial,data/crawl/squid/old_hunk_3423.cpp,data/crawl/squid/new_hunk_3423.cpp,7,7,"fprintf(stderr, ""%s| %s: User not authenticated\n"", LogTime(),
                    PROGRAM);","fprintf(stderr, ""%s| %s: INFO: User not authenticated\n"", LogTime(),
                    PROGRAM);","[""updateContent""]","[[], [""INFO""]]",[-6492726066479515808],7593,0.0,6
https://github.com/squid-cache/squid/commit/ac5de05bed05906909d7ccc894f940438b8a9967,29 Sep 2010,"Bug 3051: integer display overflow

This alters the cachemgr display formatting to use 64-bit integers
instead of 32-bit. Revealing overflows hiding behind display overflows.",302,data/crawl/squid/hunk_3013.cpp,use same variable,non-trivial,data/crawl/squid/old_hunk_3013.cpp,data/crawl/squid/new_hunk_3013.cpp,3,3,"storeAppendPrintf(sentry, ""\tRequests given to unlinkd:\t%d\n"",
                      statCounter.unlink.requests);","storeAppendPrintf(sentry, ""\tRequests given to unlinkd:\t%ld\n"",
                      (long)statCounter.unlink.requests);","[""updateContent"", ""addVariable""]","[[""\\t%d\\n""], [""\\t%ld\\n"", ""long""]]",[11325057620674453895],7592,0.0,6
https://github.com/squid-cache/squid/commit/6da430a4640e07dfae7ef7a4451acc2854817014,01 Oct 2010,"Bug 3068: cache_dir capacity and usage overflows

Makes usage calculations use size_t instead of int and updates the
relevant fields storing the cache_dir capacity and usage fields as well.

This fixes Squid filling cache_dir with files >2GB in size.
Also allows Squid to store more than 2TB of data total in one dir.",55,data/crawl/squid/hunk_3003.cpp,use same variable,non-trivial,data/crawl/squid/old_hunk_3003.cpp,data/crawl/squid/new_hunk_3003.cpp,3,3,"storeAppendPrintf(&sentry, ""Maximum Size: %d KB\n"", max_size);","storeAppendPrintf(&sentry, ""Maximum Size: %Zu KB\n"", max_size);","[""updateContent""]","[[""%d""], [""%Zu""]]",[-4775301843675679744],7591,0.0,6
https://github.com/squid-cache/squid/commit/7c16470cc2d053ea2c540459843227dea08e8b40,16 Oct 2010,"basic_msnt_auth helper and NTLM/SMBLIB/RFCNB library polish.

Samba smblib/rfcnb code:
 * Import the latest copy which I could find a download link to.
   This source is from 1997 so I suspect there is something even newer
   we should be using. Time was tight is the only excuse for using
   these sources. Our originals were from 1995 and 1996 depending on the
   helper using it, with a mix of patches.

 * These two directories are in ours sources as lib/smblib and lib/rfcnb.
   Each has its own convenience library. Kept separate with original
   filenames to simplify future upgrades or removal.

 * Samba sources have been diffed and compared function by function
   against the copies previously in our sources. Functionality extensions
   we use have been grafted back on top of the new(er) Samba sources.
  - this was mostly around passing extra Unicode, DC hints and pre-crypted
    passwords to the login checks.
  - some files from libntlmauth have yet to be compared in fine detail,
    that will be completed today before merge.
  - some basic API function and struct definitions had to be moved to the
    API headers to prevent needing to include the *-priv.h private
    definitions externally to the library.

 * the Samba API headers have been wrapped with #ifndef safety wrappers

 * compile errors and include changes required to compile have been
   made (code stays C)

 * duplicate code in helpers/basic_auth/MSNT/* and libntlmauth/* is
   removed.

 * abuse of the smblib-priv.h and rfcnb-priv.h headers and all local
   re-definitions has been erased from our code. Replaced by includes 
   of the library API headers: rfcnb/rfcnb.h  smblib/smblib.h


libntlmauth:
 * smblib/rfcnb bits erased
 * moved to lib/ntlmauth in its much reduced form
 * built as a convenience library instead of full library",14917,data/crawl/squid/hunk_2953.cpp,check similar variable,non-trivial,data/crawl/squid/old_hunk_2953.cpp,data/crawl/squid/new_hunk_2953.cpp,-1,263,,"fprintf(stderr, ""SessSetupAndX response. Action = %i\n"",
            SVAL(SMB_Hdr(pkt), SMB_ssetpr_act_offset));","[""addLog""]","[[], [""fprintf"", ""stderr"", ""SessSetupAndX"", ""response"", ""Action"", ""%i\\n"", ""SVAL"", ""SMB_Hdr"", ""pkt"", ""SMB_ssetpr_act_offset""]]",[-4441335963205359382],7590,3425280.0,6
https://github.com/squid-cache/squid/commit/20efa1c285cf589c5e289fd4f07bf41ef3564fd6,12 Dec 2010,"SourceLayout: cleanup the various log line formatting code

Adds:

* namespace Log::Format for log display functionality. Each line formater
  is a global function inside here. The log format enum is also in here
  along with the display encoding 'gadget' functions.

* namespace Time in SquidTime.h for the related time string display
  functions. Unified the various log pretty-print httpd-style time 
  functions into Time::FormatHttpd(time_t).
 ** care has been taken to preserve the local-static optimization found
    in accessLogTime() to prevent wasted cycles re-printing the same 
    time value more than once per second.

NP: the similar but timezone-missing format is now Time::FormatStrf()
    with the same optimization applied to speed up its callers.

* namespace Math:: to avoid symbol clash with global function Log() and
  namespace Log.

* support for the Apache ""combined"" log format. Was documented earlier as
  being available but not actually present.


Obsoletes:

* forward_log directive and associated experimental code. If needed
  we can easily add another special format to dump the details.
  FWIW they are all available in the squid format anyway (timestamp,
  squid status, source peer). The documented action of dumping every 
  forwarding attempt was not working.

* referer_log and useragent_log directives and matching ./configure options.
 ** shuffled into access_log formats ""referrer"" and ""useragent"" for more
    flexibility with less directives.

* emulate_httpd_log replaced with Apache ""common"" format.

* the ""auto"" pseudo-format becomes obsolete with emulat_httpd_log.
  default is now ""squid"" format in all situations.


Code Shuffles:

* moved the logformat directive parsing into LogConfig object methods.

* shuffled the logformat parsing and token code into src/log/Tokens.h|cc
 ** this is purely to break it out of access_log.cc. namespace and scoping
    needs some work.",5091,data/crawl/squid/hunk_2852.cpp,check similar variable,non-trivial,data/crawl/squid/old_hunk_2852.cpp,data/crawl/squid/new_hunk_2852.cpp,-1,82,,"logfilePrintf(logfile, "" [%s] [%s]\n"", ereq, erep);","[""addLog""]","[[], [""logfilePrintf"", ""logfile"", ""[%s]"", ""[%s]\\n"", ""ereq"", ""erep""]]",[2243749579326389688],7589,3405600.0,6
https://github.com/squid-cache/squid/commit/995eb827aaa64d9bcd4110b756e04051ef9d03e9,02 Mar 2011,merge from trunk,12916,data/crawl/squid/hunk_2734.cpp,inner similar method,non-trivial,data/crawl/squid/old_hunk_2734.cpp,data/crawl/squid/new_hunk_2734.cpp,-1,115,,"mustStop(""error"");","[""addLog""]","[[], [""mustStop"", ""error""]]",[-776500057558850006],7588,27360.0,6
https://github.com/squid-cache/squid/commit/7ff7a211c25688d2d6742acc7bc271f700c9dbe9,08 Aug 2011,Migrate cf_gen.cc from C-style stdio to C++ iostreams.,300,data/crawl/squid/hunk_2492.cpp,invoke same log method,trivial,data/crawl/squid/old_hunk_2492.cpp,data/crawl/squid/new_hunk_2492.cpp,18,-1,"fprintf(fp, ""#if %s\n"", entry->ifdef);",,"[""removeLog""]","[[""fprintf"", ""fp"", ""if"", ""%s\\n"", ""entry"", ""ifdef""], []]",[440416233817151051],7587,3805200.0,6
https://github.com/squid-cache/squid/commit/081edc2de252e852d0a8e02891fb36d7919a92ef,07 Jan 2012,"Cleanup: update most of the existing stub files to use the STUB.h framework

There are still several sections to be done. Including adding library API
stubs. However these are the ones which can be done immediately without 
breaking or re-writing existing unit tests.",2058,data/crawl/squid/hunk_2336.cpp,invoke same log method,trivial,data/crawl/squid/old_hunk_2336.cpp,data/crawl/squid/new_hunk_2336.cpp,172,-1,"fatal (""MemObject.cc required."");",,"[""removeLog""]","[[""fatal"", ""MemObject"", ""cc"", ""required""], []]",[5142970086775005695],7586,0.0,6
https://github.com/squid-cache/squid/commit/4629f000085591c9200fb70a3e46ed2b212e6fb3,05 Oct 2012,Move fatal family of functions to own implementation and stub files.,344,data/crawl/squid/hunk_1973.cpp,use same variable,trivial,data/crawl/squid/old_hunk_1973.cpp,data/crawl/squid/new_hunk_1973.cpp,76,-1,fatal(fatal_str);,,"[""removeLog""]","[[""fatal"", ""fatal_str""], []]",[1353160381696869034],7585,4113600.0,6
https://github.com/squid-cache/squid/commit/4629f000085591c9200fb70a3e46ed2b212e6fb3,05 Oct 2012,Move fatal family of functions to own implementation and stub files.,344,data/crawl/squid/hunk_1969.cpp,,,data/crawl/squid/old_hunk_1969.cpp,data/crawl/squid/new_hunk_1969.cpp,-1,106,,fatal(fatal_str);,"[""addLog""]","[[], [""fatal"", ""fatal_str""]]",[-1353160381696869034],7584,3439440.0,6
https://github.com/squid-cache/squid/commit/fc6df0c3a619d283bcd0f755409d5f3ec9554007,04 Dec 2012,merge from parent SslServerCertValidator r12337,2116,data/crawl/squid/hunk_1836.cpp,use same variable,non-trivial,data/crawl/squid/old_hunk_1836.cpp,data/crawl/squid/new_hunk_1836.cpp,10,11,auth_user_request->denyMessage(blob);,auth_user_request->denyMessage(errNote->firstValue());,"[""removeVariable"", ""addVariable""]","[[""blob""], [""errNote"", ""firstValue""]]",[-11898805055367006084],7583,6720.0,6
https://github.com/squid-cache/squid/commit/fc6df0c3a619d283bcd0f755409d5f3ec9554007,04 Dec 2012,merge from parent SslServerCertValidator r12337,2116,data/crawl/squid/hunk_1824.cpp,check similar return value,non-trivial,data/crawl/squid/old_hunk_1824.cpp,data/crawl/squid/new_hunk_1824.cpp,-1,8,,"fprintf(stderr, ""WARNING: rename '%s' to '%s' failure: %s\n"", path, to, xstrerror());","[""addLog""]","[[], [""fprintf"", ""stderr"", ""WARNING"", ""rename"", ""%s"", ""to"", ""%s"", ""failure"", ""%s\\n"", ""path"", ""to"", ""xstrerror""]]",[-13421638805233913797],7582,15360.0,6
https://github.com/squid-cache/squid/commit/fc6df0c3a619d283bcd0f755409d5f3ec9554007,04 Dec 2012,merge from parent SslServerCertValidator r12337,2116,data/crawl/squid/hunk_1824.cpp,check similar return value,non-trivial,data/crawl/squid/old_hunk_1824.cpp,data/crawl/squid/new_hunk_1824.cpp,-1,4,,"fprintf(stderr, ""WARNING: remove '%s' failure: %s\n"", to, xstrerror());","[""addLog""]","[[], [""fprintf"", ""stderr"", ""WARNING"", ""remove"", ""%s"", ""failure"", ""%s\\n"", ""to"", ""xstrerror""]]",[-20583615695712937023],7581,15360.0,6
https://github.com/squid-cache/squid/commit/73656056cdcface25c015c755e9a3688acd404fc,30 Sep 2013,"Remove COSS

This storage type has been superceded by Rock storage since 3.2.",3034,data/crawl/squid/hunk_1683.cpp,check similar return value,non-trivial,data/crawl/squid/old_hunk_1683.cpp,data/crawl/squid/new_hunk_1683.cpp,653,-1,"fatal(""Failed to open swap log for reading"");",,"[""removeLog""]","[[""fatal"", ""Failed"", ""to"", ""open"", ""swap"", ""log"", ""for"", ""reading""], []]",[16044729424592680332],7580,2488080.0,6
https://github.com/squid-cache/squid/commit/73656056cdcface25c015c755e9a3688acd404fc,30 Sep 2013,"Remove COSS

This storage type has been superceded by Rock storage since 3.2.",3034,data/crawl/squid/hunk_1683.cpp,check similar return value,non-trivial,data/crawl/squid/old_hunk_1683.cpp,data/crawl/squid/new_hunk_1683.cpp,644,-1,"fatal(""storeDirOpenTmpSwapLog: Failed to open swap log."");",,"[""removeLog""]","[[""fatal"", ""storeDirOpenTmpSwapLog"", ""Failed"", ""to"", ""open"", ""swap"", ""log""], []]",[7196785520234966959],7579,2488080.0,6
https://github.com/squid-cache/squid/commit/17852883df926d74fb04fe5d2bbfa281090574a8,01 Oct 2013,"Remove dnsserver and external DNS helper API

The external DNS helper API places limits on Squid DNS lookups per second
low enough to noticably affect the HTTP requests per second which can be
served.

Request for comments about proposed removal 2 years ago produced feedback
stating that the helper was needed for local name resolution. This is
now available since 3.4 mDNS extensions.

A more recent request for reasons for keeping the helper API have
produced only two responses over the period of several months. Both
indicating that the API is no longer necessary for the business cases of
a year or so ago.

As such and because the helper fails to operate sufficiently on several
major operating systems and the API is difficult to maintain it is being
removed as of Squid-3.5.",1269,data/crawl/squid/hunk_1681.cpp,use same text,non-trivial,data/crawl/squid/old_hunk_1681.cpp,data/crawl/squid/new_hunk_1681.cpp,272,-1,"printf(""\n"");",,"[""removeLog""]","[[""printf"", ""\\n""], []]",[-7249185625612668815],7578,2309040.0,6
https://github.com/squid-cache/squid/commit/cf2155f28a0333dc57adb63c537c3ea30cbf0344,24 Jan 2014,"Enable -n command line option for non-Windows Squid builds

This command line option is used on Windows to name the service instance
of Squid being run and/or managed. At this point it still only has
useful effect on Windows, but can now be used by components on other
systems as well.

Show the running instance service name in cacehmgr and -v output.

Also remove _WIN_SQUID_DEFAULT_SERVICE_NAME macro which duplicated the
APP_SHORTNAME macro. This changes the Windows service name from Squid to
squid (lower case) on future Squid-3 for Windows.",112,data/crawl/squid/hunk_1620.cpp,use same constant,non-trivial,data/crawl/squid/old_hunk_1620.cpp,data/crawl/squid/new_hunk_1620.cpp,3,3,"printf(""Service %s deleted successfully.\n"",
                       WIN32_Service_name);","printf(""Service %s deleted successfully.\n"", service_name);","[""updateVariable""]","[[""WIN32_Service_name""], [""service_name""]]",[3676727402390234290],7577,0.0,6
https://github.com/squid-cache/squid/commit/ae61f2a70b4839175e1896fb984276ec9b122686,17 Mar 2014,Remove XMALLOC_TRACE and references to sbrk(2),348,data/crawl/squid/hunk_1576.cpp,use same text,non-trivial,data/crawl/squid/old_hunk_1576.cpp,data/crawl/squid/new_hunk_1576.cpp,185,-1,"fprintf(stderr, ""----------------------\n"");",,"[""removeLog""]","[[""fprintf"", ""stderr"", ""\\n""], []]",[13913879213697345406],7576,2541360.0,6
https://github.com/squid-cache/squid/commit/d1f3d8f885784c89a822c35ddf6537aab3a3b925,06 Aug 2014,merge from trunk r13526,34418,data/crawl/squid/hunk_1278.cpp,use same variable,non-trivial,data/crawl/squid/old_hunk_1278.cpp,data/crawl/squid/new_hunk_1278.cpp,-1,11,,"storeAppendPrintf(&e, ""Maximum slots:   %9d\n"", slotLimit);","[""addLog""]","[[], [""storeAppendPrintf"", ""&e"", ""Maximum"", ""slots"", ""%9d\\n"", ""slotLimit""]]",[20935556611366205784],7575,96480.0,6
https://github.com/squid-cache/squid/commit/d1f3d8f885784c89a822c35ddf6537aab3a3b925,06 Aug 2014,merge from trunk r13526,34418,data/crawl/squid/hunk_1278.cpp,use same variable,non-trivial,data/crawl/squid/old_hunk_1278.cpp,data/crawl/squid/new_hunk_1278.cpp,13,17,"storeAppendPrintf(&e, ""Used slots:      %9d %.2f%%\n"",
                                  usedSlots, (100.0 * usedSlots / limit));","storeAppendPrintf(&e, ""Used slots:      %9d %.2f%%\n"",
                                  usedSlots, (100.0 * usedSlots / slotLimit));","[""updateVariable""]","[[""limit""], [""slotLimit""]]",[7111851765608050760],7574,96480.0,6
https://github.com/squid-cache/squid/commit/c6649f6c62f90053f0bf0f162918a94f1d763b3d,26 Aug 2014,merge from trunk,14018,data/crawl/squid/hunk_1212.cpp,check similar return value,non-trivial,data/crawl/squid/old_hunk_1212.cpp,data/crawl/squid/new_hunk_1212.cpp,-1,994,,"writeCustomReply(451, ""Server error; transfer aborted"");","[""addLog""]","[[], [""writeCustomReply"", ""451"", ""Server"", ""error"", ""transfer"", ""aborted""]]",[-6421079062331928970],7573,13920.0,6
https://github.com/squid-cache/squid/commit/c6649f6c62f90053f0bf0f162918a94f1d763b3d,26 Aug 2014,merge from trunk,14018,data/crawl/squid/hunk_1212.cpp,check similar variable,non-trivial,data/crawl/squid/old_hunk_1212.cpp,data/crawl/squid/new_hunk_1212.cpp,-1,839,,"filteredHeader.putStr(HDR_FTP_PRE, buf);","[""addLog""]","[[], [""filteredHeader"", ""putStr"", ""HDR_FTP_PRE"", ""buf""]]",[4621350245977610158],7572,13920.0,6
https://github.com/squid-cache/squid/commit/c6649f6c62f90053f0bf0f162918a94f1d763b3d,26 Aug 2014,merge from trunk,14018,data/crawl/squid/hunk_1199.cpp,check similar variable,non-trivial,data/crawl/squid/old_hunk_1199.cpp,data/crawl/squid/new_hunk_1199.cpp,-1,666,,"mb.Printf(""PASV%s"", Ftp::crlf);","[""addLog""]","[[], [""mb"", ""Printf"", ""PASV%s"", ""Ftp"", ""crlf""]]",[3588186707584736628],7571,276000.0,6
https://github.com/squid-cache/squid/commit/c6649f6c62f90053f0bf0f162918a94f1d763b3d,26 Aug 2014,merge from trunk,14018,data/crawl/squid/hunk_1199.cpp,check similar return value,non-trivial,data/crawl/squid/old_hunk_1199.cpp,data/crawl/squid/new_hunk_1199.cpp,-1,654,,"mb.Printf(""EPSV 1%s"", Ftp::crlf);","[""addLog""]","[[], [""mb"", ""Printf"", ""EPSV"", ""1%s"", ""Ftp"", ""crlf""]]",[4046860697659007166],7570,276000.0,6
https://github.com/squid-cache/squid/commit/c6649f6c62f90053f0bf0f162918a94f1d763b3d,26 Aug 2014,merge from trunk,14018,data/crawl/squid/hunk_1199.cpp,check similar return value,non-trivial,data/crawl/squid/old_hunk_1199.cpp,data/crawl/squid/new_hunk_1199.cpp,-1,645,,"mb.Printf(""EPSV 2%s"", Ftp::crlf);","[""addLog""]","[[], [""mb"", ""Printf"", ""EPSV"", ""2%s"", ""Ftp"", ""crlf""]]",[2920805185148149333],7569,276000.0,6
https://github.com/squid-cache/squid/commit/07721490c3ad87e49ef952c07c6bbb0aa323b09b,27 Apr 2015,"Rename Packable::Printf as Packable::appendf

It performs append semantics not replace semantics, and this also paves
the way for SBuf integration.",451,data/crawl/squid/hunk_799.cpp,invoke same log method,non-trivial,data/crawl/squid/old_hunk_799.cpp,data/crawl/squid/new_hunk_799.cpp,6,6,"packer->Printf(""-%"" PRId64,  length);","p->appendf(""-%"" PRId64, length);","[""updateLog""]","[[""packer"", ""Printf""], [""p"", ""appendf""]]",[7002479699071699579],7568,38160.0,6
https://github.com/squid-cache/squid/commit/1071ffed56172406d771265af76d8273ffcdb89e,26 May 2015,"Replace Packer object API with Packable API

Majority of thost patch is symbol renaming to unify the
class method names to the Packable API names.

There is effectively no logical change in this patch
despite appearances because it replaces the Packer object
which provides methods which are just wrappers pointing
to static functions which are in turn wrappers pointing
to storage buffer object methods. With direct calls to
those storage object methods (renamed).

We can now interchangebly use MemBuf or StoreEntry objects
with the packInto(Packable *) functions. Or any other
object which inherits and implements the Packable API.

We also gain 0.1% in performance (+2 RPS) by avoiding the
layers of wrapper funcions and Packer object allocate / 
deallocate cycles.",1141,data/crawl/squid/hunk_746.cpp,invoke same log method,non-trivial,data/crawl/squid/old_hunk_746.cpp,data/crawl/squid/new_hunk_746.cpp,3,3,"mb.Printf(""%d"", getMyPort());","mb.appendf(""%u"", getMyPort());","[""updateLog"", ""updateContent""]","[[""Printf"", ""%d""], [""appendf"", ""%u""]]",[-403317783590601055],7567,64800.0,6
https://github.com/squid-cache/squid/commit/1071ffed56172406d771265af76d8273ffcdb89e,26 May 2015,"Replace Packer object API with Packable API

Majority of thost patch is symbol renaming to unify the
class method names to the Packable API names.

There is effectively no logical change in this patch
despite appearances because it replaces the Packer object
which provides methods which are just wrappers pointing
to static functions which are in turn wrappers pointing
to storage buffer object methods. With direct calls to
those storage object methods (renamed).

We can now interchangebly use MemBuf or StoreEntry objects
with the packInto(Packable *) functions. Or any other
object which inherits and implements the Packable API.

We also gain 0.1% in performance (+2 RPS) by avoiding the
layers of wrapper funcions and Packer object allocate / 
deallocate cycles.",1141,data/crawl/squid/hunk_726.cpp,invoke same log method,non-trivial,data/crawl/squid/old_hunk_726.cpp,data/crawl/squid/new_hunk_726.cpp,8,8,"buf.Printf(""Connection: close\r\n"");","buf.append(""Connection: close\r\n"", 19);","[""updateLog"", ""addContent""]","[[""Printf""], [""append"", ""19""]]",[-16146027967618661649],7566,64800.0,6
https://github.com/squid-cache/squid/commit/1071ffed56172406d771265af76d8273ffcdb89e,26 May 2015,"Replace Packer object API with Packable API

Majority of thost patch is symbol renaming to unify the
class method names to the Packable API names.

There is effectively no logical change in this patch
despite appearances because it replaces the Packer object
which provides methods which are just wrappers pointing
to static functions which are in turn wrappers pointing
to storage buffer object methods. With direct calls to
those storage object methods (renamed).

We can now interchangebly use MemBuf or StoreEntry objects
with the packInto(Packable *) functions. Or any other
object which inherits and implements the Packable API.

We also gain 0.1% in performance (+2 RPS) by avoiding the
layers of wrapper funcions and Packer object allocate / 
deallocate cycles.",1141,data/crawl/squid/hunk_719.cpp,invoke same log method,non-trivial,data/crawl/squid/old_hunk_719.cpp,data/crawl/squid/new_hunk_719.cpp,9,8,".Printf(""Encapsulated: "");",".append(""Encapsulated: "", 14);","[""updateLog"", ""addContent""]","[[""Printf""], [""append"", ""14""]]",[-16146027967618661652],7565,64800.0,6
https://github.com/squid-cache/squid/commit/af845cee67e3dc2a58f93a9ac7d9ce091ea4fa00,11 Sep 2015,"Bug 4292: negotiate_wrapper: Unreleased Resources

FILE* handles need to be closed on exit. Shuffle the processing loop logics
to a static function to avoid code duplication from all the requires close
points.

Also, use the available global flag debug_enabled instead of local variable
to avoid having to pass it down explicitly.",337,data/crawl/squid/hunk_580.cpp,check similar variable,non-trivial,data/crawl/squid/old_hunk_580.cpp,data/crawl/squid/new_hunk_580.cpp,37,-1,"fprintf(stdout, ""BH Invalid request\n"");",,"[""removeLog""]","[[""fprintf"", ""stdout"", ""BH"", ""Invalid"", ""request\\n""], []]",[14936515258816654011],7564,1537920.0,6
https://github.com/squid-cache/squid/commit/70df76e30151bb5fd2070a275e2489ee6bdaaea9,19 Feb 2016,"Throw instead of asserting on some String overflows.

Note that Client-caught exceptions result in HTTP 500 (Internal Server
Error) responses with X-Squid-Error set to ""ERR_CANNOT_FORWARD 0"".


Also avoid stuck Client jobs on exceptions. See trunk r8266 for a
similar fix with a detailed discussion. Here, I added doneWithFwd
instead of setting fwd to NULL because we dereference fwd (and store
pointers to things stored in fwd!) in many places. I think it is too
risky to just clear refcounted FwdState pointer (except in the
destructor where doing so is pointless).

Using doneWithFwd correctly is difficult because there are many ways we
can be ""done"" with FwdState, including:

    * calling fwd->complete(),
    * calling fwd->handleUnregisteredServerEnd(), and
    * closing the connection that FwdState monitors for closures.

The latter is especially tricky case because the closing is initiated in
many places, the process is asynchronous, and not all control
connections are monitored by FwdState.

For example, the updated control connection closure handler assumes that
it is being used for either external closures or internal closures
incorrectly used instead of mustStop()/abortAll(). In both cases, either
FwdState is still monitoring the connection (OK) or we forgot to call
one of its ""done"" methods listed above before closing. The latter would
be a bug, but I did not find any signs of it and fixing it would be
outside this change scope anyway.


Also unified String size limit checks [that I could find].",70,data/crawl/squid/hunk_358.cpp,,,data/crawl/squid/old_hunk_358.cpp,data/crawl/squid/new_hunk_358.cpp,-1,8,,mustStop(reason);,"[""addLog""]","[[], [""mustStop"", ""reason""]]",[-12168142237827300475],7563,1865520.0,6
https://github.com/squid-cache/squid/commit/0bffe3cec1400f4d69724552e77e77878defd8a3,23 May 2016,"Sync with trunk-r14686

- Replaces with newer versions of BinaryTokenizer and HandshakeParser classes
- Modifications to use latest Handshake parser from trunk.
- Get HandshakeParser::serverCertificates, HandshakeParser::parseServerCertificates and HandshakeParser::ParseCertificate implementation from lp:fast-sni branch",6170,data/crawl/squid/hunk_171.cpp,use same variable,trivial,data/crawl/squid/old_hunk_171.cpp,data/crawl/squid/new_hunk_171.cpp,3,4,"fatalf(""Aiee! aio_read() returned error (%d)  FIXME and wrap file_read !\n"", errno);","fatalf(""Aiee! aio_read() returned error (%d)  FIXME and wrap file_read !\n"", xerrno);","[""updateVariable""]","[[""errno""], [""xerrno""]]",[-5579466342789487351],7562,43200.0,6
https://github.com/squid-cache/squid/commit/644b0587cc6495cfabfcba76243a71dca0e1a20c,20 Dec 2016,Fix shadowing of member 'type' in SchemeConfig,14,data/crawl/squid/hunk_109.cpp,use same variable,trivial,data/crawl/squid/old_hunk_109.cpp,data/crawl/squid/new_hunk_109.cpp,6,6,"storeAppendPrintf(entry, ""%s %s"", name, type);","storeAppendPrintf(entry, ""%s %s"", name, schemeType);","[""updateVariable""]","[[""type""], [""schemeType""]]",[-6937237504119161965],7561,0.0,6
https://github.com/squid-cache/squid/commit/2c47cf746f00fef15b9a964242f2c46a0c0083d0,04 Apr 1996,avoid using stderr; use debug() or debug_log instead,49,data/crawl/squid/hunk_7876.cpp,use same variable,non-trivial,data/crawl/squid/old_hunk_7876.cpp,data/crawl/squid/new_hunk_7876.cpp,3,3,"fprintf(stderr, ""FATAL: Received Segment Violation...dying.\n"");","fprintf(debug_log, ""FATAL: Received Segment Violation...dying.\n"");","[""updateVariable""]","[[""stderr""], [""debug_log""]]",[7666580819308282657],7560,0.0,5
https://github.com/squid-cache/squid/commit/627f6d02e9baad40c38bd35ef893fc6bc9a22ca1,21 Nov 1997,"SNMP, cmu derived, heavily modified",5272,data/crawl/squid/hunk_6957.cpp,check similar return value,non-trivial,data/crawl/squid/old_hunk_6957.cpp,data/crawl/squid/new_hunk_6957.cpp,-1,1140,,"print_error(""No end to oid"", (char *)NULL, type);","[""addLog""]","[[], [""print_error"", ""No"", ""end"", ""to"", ""oid"", ""char"", ""*"", ""NULL"", ""type""]]",[9551342531087663082],7559,0.0,5
https://github.com/squid-cache/squid/commit/627f6d02e9baad40c38bd35ef893fc6bc9a22ca1,21 Nov 1997,"SNMP, cmu derived, heavily modified",5272,data/crawl/squid/hunk_6957.cpp,check similar return value,non-trivial,data/crawl/squid/old_hunk_6957.cpp,data/crawl/squid/new_hunk_6957.cpp,-1,1047,,"print_error(""Bad DESCRIPTION"", token, type);","[""addLog""]","[[], [""print_error"", ""Bad"", ""DESCRIPTION"", ""token"", ""type""]]",[14155231338761717494],7558,0.0,5
https://github.com/squid-cache/squid/commit/1df370e38a088aa3c12e0971d7324351325ff724,02 Dec 1997,"make SNMP code #ifdef-able, including config parsing",122,data/crawl/squid/hunk_6892.cpp,check similar variable,non-trivial,data/crawl/squid/old_hunk_6892.cpp,data/crawl/squid/new_hunk_6892.cpp,-1,13,,"fprintf(fp, ""#endif\n"");","[""addLog""]","[[], [""fprintf"", ""fp"", ""endif\\n""]]",[2535454387840088139],7557,0.0,5
https://github.com/squid-cache/squid/commit/1df370e38a088aa3c12e0971d7324351325ff724,02 Dec 1997,"make SNMP code #ifdef-able, including config parsing",122,data/crawl/squid/hunk_6892.cpp,check similar variable,non-trivial,data/crawl/squid/old_hunk_6892.cpp,data/crawl/squid/new_hunk_6892.cpp,-1,4,,"fprintf(fp, ""#ifdef %s\n"", entry->ifdef);","[""addLog""]","[[], [""fprintf"", ""fp"", ""ifdef"", ""%s\\n"", ""entry"", ""ifdef""]]",[-593136330113430995],7556,0.0,5
https://github.com/squid-cache/squid/commit/15576b6a58a24ed2705d6228d0fde8cfcef26cae,07 Feb 1998,remove brackets from cachemgr output,390,data/crawl/squid/hunk_6829.cpp,use same text,non-trivial,data/crawl/squid/old_hunk_6829.cpp,data/crawl/squid/new_hunk_6829.cpp,96,95,"storeAppendPrintf(sentry, ""{\tMaximum number of file descriptors:   %4d}\n"",
	Squid_MaxFD);","storeAppendPrintf(sentry, ""\tMaximum number of file descriptors:   %4d\n"",
	Squid_MaxFD);","[""updateContent""]","[[""%4d"", ""\\n""], [""%4d\\n""]]",[-613038733896009100],7555,0.0,5
https://github.com/squid-cache/squid/commit/85269fdf3c2a36641dfae2cf71f495a38c95cc28,22 Feb 1998,"Snmplib for squid, based on v1.8, heavily changed",8289,data/crawl/squid/hunk_6752.cpp,check similar return value,non-trivial,data/crawl/squid/old_hunk_6752.cpp,data/crawl/squid/new_hunk_6752.cpp,356,-1,"print_error(""Bad DESCRIPTION"", token, type);",,"[""removeLog""]","[[""print_error"", ""Bad"", ""DESCRIPTION"", ""token"", ""type""], []]",[-14155231338761717494],7554,0.0,5
https://github.com/squid-cache/squid/commit/505e35db6f84bcad19f8d366753a77955dc842d2,04 Jun 1998,"Replaced 'cache_host_acl' with 'cache_host_access' so its just like the
other ACL access lists.",113,data/crawl/squid/hunk_6370.cpp,use same constant,trivial,data/crawl/squid/old_hunk_6370.cpp,data/crawl/squid/new_hunk_6370.cpp,0,0,"storeAppendPrintf(entry, ""%s %s %s %s%s\n"",
		    name, cp->name,
		    head->allow ? ""Allow"" : ""Deny"",
		    l->op ? """" : ""!"",
		    l->acl->name);","storeAppendPrintf(entry, ""%s %s %s %s%s\n"",
		    name, cp->name,
		    head->allow ? ""Allow"" : ""Deny"",
		    l->op ? null_string : ""!"",
		    l->acl->name);","[""removeContent"", ""addVariable""]","[[], [""null_string""]]",[8748942515781726998],7553,169056.0,5
https://github.com/squid-cache/squid/commit/2b19063a00f246c8226a2c77fa0372a007041d27,05 Jun 1998,use fatal_dump instead of fatal,8,data/crawl/squid/hunk_6368.cpp,check similar return value,non-trivial,data/crawl/squid/old_hunk_6368.cpp,data/crawl/squid/new_hunk_6368.cpp,-1,5,,fatal_dump(tmp_error_buf);,"[""addLog""]","[[], [""fatal_dump"", ""tmp_error_buf""]]",[-17726151251914438360],7552,318816.0,5
https://github.com/squid-cache/squid/commit/75339a46776f1815300c058789302e3c6eed84b3,21 Aug 1998,use #if instead of #ifdef so it works with #define FOO 0,12,data/crawl/squid/hunk_6294.cpp,use same text,non-trivial,data/crawl/squid/old_hunk_6294.cpp,data/crawl/squid/new_hunk_6294.cpp,3,3,"fprintf(fp, ""#ifdef %s\n"", entry->ifdef);","fprintf(fp, ""#if %s\n"", entry->ifdef);","[""updateContent""]","[[""ifdef""], [""if""]]",[152720096296279944],7551,0.0,5
https://github.com/squid-cache/squid/commit/186477c1163c0718cf127587c1ad63a1e61906d9,01 Nov 2000,"DW:
 - Changed occurances of

        struct _foo {
            /* first two items must be same as hash_link */
            char *key;
            foo *next;
            ...
        };

   to

        struct _foo {
            hash_link hash;     /* must be first */
            ...
        };",385,data/crawl/squid/hunk_5953.cpp,use same variable,trivial,data/crawl/squid/old_hunk_5953.cpp,data/crawl/squid/new_hunk_5953.cpp,2,2,"storeAppendPrintf(sentry, ""%20p %10s %d locks %s:%d\n"",
	    c->key,
	    c->valid ? ""VALID"" : ""NOT VALID"",
	    c->locks,
	    c->file, c->line);","storeAppendPrintf(sentry, ""%20p %10s %d locks %s:%d\n"",
	    c->hash.key,
	    c->valid ? ""VALID"" : ""NOT VALID"",
	    c->locks,
	    c->file, c->line);","[""addVariable""]","[[], [""hash""]]",[7799588877615763652],7550,0.0,5
https://github.com/squid-cache/squid/commit/06cdab880bda222625694d783ad75113fcd7671a,14 Nov 2001,"Wrap the Squid radix implementation with a ""squid_"" prefix to protect it
from any collisions with system provided versions..",369,data/crawl/squid/hunk_5725.cpp,check similar variable,non-trivial,data/crawl/squid/old_hunk_5725.cpp,data/crawl/squid/new_hunk_5725.cpp,3,3,"fprintf(stderr, ""rn_delete: inconsistent annotation\n"");","fprintf(stderr, ""squid_rn_delete: inconsistent annotation\n"");","[""updateContent""]","[[""rn_delete""], [""squid_rn_delete""]]",[4868407350708381787],7549,0.0,5
https://github.com/squid-cache/squid/commit/4d6d905e8b4d4271702d50d56863fe37f8f52e42,12 Oct 2002,extract duplicate ufs code to ufscommon.c/h,6553,data/crawl/squid/hunk_5548.cpp,check similar variable,non-trivial,data/crawl/squid/old_hunk_5548.cpp,data/crawl/squid/new_hunk_5548.cpp,-1,1503,,"storeAppendPrintf(sentry, "" READ-ONLY"");","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""READ"", ""ONLY""]]",[61847490146178052],7548,699264.0,5
https://github.com/squid-cache/squid/commit/4d6d905e8b4d4271702d50d56863fe37f8f52e42,12 Oct 2002,extract duplicate ufs code to ufscommon.c/h,6553,data/crawl/squid/hunk_5548.cpp,check similar variable,non-trivial,data/crawl/squid/old_hunk_5548.cpp,data/crawl/squid/new_hunk_5548.cpp,-1,1501,,"storeAppendPrintf(sentry, "" SELECTED"");","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""SELECTED""]]",[2809235622583736885],7547,934272.0,5
https://github.com/squid-cache/squid/commit/4d6d905e8b4d4271702d50d56863fe37f8f52e42,12 Oct 2002,extract duplicate ufs code to ufscommon.c/h,6553,data/crawl/squid/hunk_5548.cpp,,,data/crawl/squid/old_hunk_5548.cpp,data/crawl/squid/new_hunk_5548.cpp,-1,1499,,"storeAppendPrintf(sentry, ""Flags:"");","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""Flags""]]",[12121816957590146942],7546,1153152.0,5
https://github.com/squid-cache/squid/commit/4d6d905e8b4d4271702d50d56863fe37f8f52e42,12 Oct 2002,extract duplicate ufs code to ufscommon.c/h,6553,data/crawl/squid/hunk_5548.cpp,use same variable,non-trivial,data/crawl/squid/old_hunk_5548.cpp,data/crawl/squid/new_hunk_5548.cpp,-1,1483,,"storeAppendPrintf(sentry, ""Percent Used: %0.2f%%\n"",
	100.0 * SD->cur_size / SD->max_size);","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""Percent"", ""Used"", ""%0"", ""2f%%\\n"", ""100"", ""0"", ""*"", ""SD"", ""cur_size"", ""/"", ""SD"", ""max_size""]]",[22852711430526874902],7545,1527552.0,5
https://github.com/squid-cache/squid/commit/4d6d905e8b4d4271702d50d56863fe37f8f52e42,12 Oct 2002,extract duplicate ufs code to ufscommon.c/h,6553,data/crawl/squid/hunk_5548.cpp,,,data/crawl/squid/old_hunk_5548.cpp,data/crawl/squid/new_hunk_5548.cpp,-1,1482,,"storeAppendPrintf(sentry, ""Current Size: %d KB\n"", SD->cur_size);","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""Current"", ""Size"", ""%d"", ""KB\\n"", ""SD"", ""cur_size""]]",[7572611168408590936],7544,1527552.0,5
https://github.com/squid-cache/squid/commit/4d6d905e8b4d4271702d50d56863fe37f8f52e42,12 Oct 2002,extract duplicate ufs code to ufscommon.c/h,6553,data/crawl/squid/hunk_5548.cpp,,,data/crawl/squid/old_hunk_5548.cpp,data/crawl/squid/new_hunk_5548.cpp,-1,1481,,"storeAppendPrintf(sentry, ""Maximum Size: %d KB\n"", SD->max_size);","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""Maximum"", ""Size"", ""%d"", ""KB\\n"", ""SD"", ""max_size""]]",[17079324005041243121],7543,1527552.0,5
https://github.com/squid-cache/squid/commit/4d6d905e8b4d4271702d50d56863fe37f8f52e42,12 Oct 2002,extract duplicate ufs code to ufscommon.c/h,6553,data/crawl/squid/hunk_5548.cpp,,,data/crawl/squid/old_hunk_5548.cpp,data/crawl/squid/new_hunk_5548.cpp,-1,929,,"fatal(""Failed to open swap log for reading"");","[""addLog""]","[[], [""fatal"", ""Failed"", ""to"", ""open"", ""swap"", ""log"", ""for"", ""reading""]]",[-16044729424592680332],7542,1528704.0,5
https://github.com/squid-cache/squid/commit/d3b3ab859857da0851f9c7de916b6df261ba43ae,27 Dec 2002,apply unify io patch to simplify IO code for diskd/aufs/ufs,7586,data/crawl/squid/hunk_5479.cpp,check similar variable,non-trivial,data/crawl/squid/old_hunk_5479.cpp,data/crawl/squid/new_hunk_5479.cpp,816,-1,"storeAppendPrintf(sentry, "" READ-ONLY"");",,"[""removeLog""]","[[""storeAppendPrintf"", ""sentry"", ""READ"", ""ONLY""], []]",[-61847490146178052],7541,1469952.0,5
https://github.com/squid-cache/squid/commit/d3b3ab859857da0851f9c7de916b6df261ba43ae,27 Dec 2002,apply unify io patch to simplify IO code for diskd/aufs/ufs,7586,data/crawl/squid/hunk_5479.cpp,check similar variable,non-trivial,data/crawl/squid/old_hunk_5479.cpp,data/crawl/squid/new_hunk_5479.cpp,814,-1,"storeAppendPrintf(sentry, "" SELECTED"");",,"[""removeLog""]","[[""storeAppendPrintf"", ""sentry"", ""SELECTED""], []]",[-2809235622583736885],7540,1469952.0,5
https://github.com/squid-cache/squid/commit/d3b3ab859857da0851f9c7de916b6df261ba43ae,27 Dec 2002,apply unify io patch to simplify IO code for diskd/aufs/ufs,7586,data/crawl/squid/hunk_5479.cpp,,,data/crawl/squid/old_hunk_5479.cpp,data/crawl/squid/new_hunk_5479.cpp,812,-1,"storeAppendPrintf(sentry, ""Flags:"");",,"[""removeLog""]","[[""storeAppendPrintf"", ""sentry"", ""Flags""], []]",[-12121816957590146942],7539,1469952.0,5
https://github.com/squid-cache/squid/commit/d3b3ab859857da0851f9c7de916b6df261ba43ae,27 Dec 2002,apply unify io patch to simplify IO code for diskd/aufs/ufs,7586,data/crawl/squid/hunk_5479.cpp,use same variable,non-trivial,data/crawl/squid/old_hunk_5479.cpp,data/crawl/squid/new_hunk_5479.cpp,796,-1,"storeAppendPrintf(sentry, ""Percent Used: %0.2f%%\n"",
	100.0 * SD->cur_size / SD->max_size);",,"[""removeLog""]","[[""storeAppendPrintf"", ""sentry"", ""Percent"", ""Used"", ""%0"", ""2f%%\\n"", ""100"", ""0"", ""*"", ""SD"", ""cur_size"", ""/"", ""SD"", ""max_size""], []]",[-22852711430526874902],7538,1469952.0,5
https://github.com/squid-cache/squid/commit/d3b3ab859857da0851f9c7de916b6df261ba43ae,27 Dec 2002,apply unify io patch to simplify IO code for diskd/aufs/ufs,7586,data/crawl/squid/hunk_5479.cpp,,,data/crawl/squid/old_hunk_5479.cpp,data/crawl/squid/new_hunk_5479.cpp,795,-1,"storeAppendPrintf(sentry, ""Current Size: %d KB\n"", SD->cur_size);",,"[""removeLog""]","[[""storeAppendPrintf"", ""sentry"", ""Current"", ""Size"", ""%d"", ""KB\\n"", ""SD"", ""cur_size""], []]",[-7572611168408590936],7537,1469952.0,5
https://github.com/squid-cache/squid/commit/d3b3ab859857da0851f9c7de916b6df261ba43ae,27 Dec 2002,apply unify io patch to simplify IO code for diskd/aufs/ufs,7586,data/crawl/squid/hunk_5479.cpp,,,data/crawl/squid/old_hunk_5479.cpp,data/crawl/squid/new_hunk_5479.cpp,794,-1,"storeAppendPrintf(sentry, ""Maximum Size: %d KB\n"", SD->max_size);",,"[""removeLog""]","[[""storeAppendPrintf"", ""sentry"", ""Maximum"", ""Size"", ""%d"", ""KB\\n"", ""SD"", ""max_size""], []]",[-17079324005041243121],7536,1469952.0,5
https://github.com/squid-cache/squid/commit/d3b3ab859857da0851f9c7de916b6df261ba43ae,27 Dec 2002,apply unify io patch to simplify IO code for diskd/aufs/ufs,7586,data/crawl/squid/hunk_5478.cpp,check similar return value,non-trivial,data/crawl/squid/old_hunk_5478.cpp,data/crawl/squid/new_hunk_5478.cpp,195,-1,"fatalf(""Failed to make swap directory %s: %s"",
	    path, xstrerror());",,"[""removeLog""]","[[""fatalf"", ""Failed"", ""to"", ""make"", ""swap"", ""directory"", ""%s"", ""%s"", ""path"", ""xstrerror""], []]",[4186603929638388916],7535,1469952.0,5
https://github.com/squid-cache/squid/commit/d3b3ab859857da0851f9c7de916b6df261ba43ae,27 Dec 2002,apply unify io patch to simplify IO code for diskd/aufs/ufs,7586,data/crawl/squid/hunk_5464.cpp,use same variable,trivial,data/crawl/squid/old_hunk_5464.cpp,data/crawl/squid/new_hunk_5464.cpp,37,31,"storeAppendPrintf(sentry, ""\n"");","storeAppendPrintf(&sentry, ""\n"");","[""addVariable""]","[[""sentry""], [""&sentry""]]",[3269677785121613405],7534,0.0,5
https://github.com/squid-cache/squid/commit/c99de60701b56be31c01be2045d204ed411e33ca,01 Nov 2006,"	- Many ICAP fixes from Alex Rousskov accumulated on the
	  sourceforge squid3-icap branch since 2006/10, including:

        - Polished ICAP service selection code and implemented bypass of
          optional services. The code implements icap_class
          configuration directive which is currently used as a ""set of
          interchangeable ICAP services"". Squid2 and current squid.conf
          may imply otherwise.

        - Support Transfer-* ICAP OPTIONS response header. If Squid
          knows that a service does not want the URL, Squid will not use
          the service, even if it is an essential service with
          bypass=0. Note that we may make this decision before we know
          what the service wants. Eventually, ACLs should initiate and
          wait for the OPTIONS transaction for yet-unprobed services.

        - When ICAP transactions fail to connect to the service many
          times, the service is suspended until the next OPTIONS
          update. The limit is currently hard-coded to 10. Suspended
          service is a down service and will be skipped by the ACL
          service selection algorithm.

        - Rewrote the code updating ICAP service options. We no longer
          mark the service being updated as ""down"". Only presence of
          valid and fresh options is important. We also try to update
          the options before they expire to avoid any service downtime
          or use of stale options.

        - Report interesting changes in the ICAP service state, some
          with debugging level one to alert the cache administrator.

        - When cloning a request during an ICAP 204 ""No Content"" REQMOD
          response, preserve the client address so that the rest of the
          code has access to it. This change appears to fix Squid Bug
          #1712.

        - After ICAP 100 Continue, expect new ICAP headers instead of
          HTTP headers. Reset ICAP message object to be ready to parse
          ICAP headers again. (Tsantilas Christos
          <chtsanti@users.sourceforge.net>)

        - The ieof HTTP chunk-extension was written after chunk-data
          instead of being written after the chunk-size. (Tsantilas
          Christos <chtsanti@users.sourceforge.net>)

        - Merged common code from the ICAPClientReqmodPrecache and
          ICAPClientReqmodPrecache classes into the newly added
          ICAPClientVector class.  The specific vectors do not have a
          common owner (yet?) because ServerStateData and
          ClientHttpRequest do not have a common base class. Thus,
          ICAPClientVector has to rely on its kids to communicate with
          their owners. However, at least 50% of the logic was common
          and has been moved. Eventually, we may want to create a
          simple ICAPOwner API that ServerStateData and
          ClientHttpRequest can implement and ICAPClientVector can rely
          on. This will make the code simpler and more efficient.  The
          big merge was motivated by a couple of bugs that were found
          in one vector class but that did not exist or behaved
          differently in the other vector, mostly likely due to natural
          diversion of used-to-be identical code.

        - Rewrote communication between a server-side ICAPClient*mod*
          vector and its owner.  When a server-side ICAPClient*mod*
          vector was notifying its owner of more adapted data, the
          owner could delete the vector (by calling icap->ownerAbort)
          if the store entry was not willing to accept the data.  The
          same deletion could happen when a vector was notifying the
          owner of a successful termination. In all those cases, the
          vector did not expect to be deleted and could continue to do
          something, causing segmentation faults.  Now, when more data
          is available, the vector calls its owner and checks the
          return value of the call. If it is false, the vector knows it
          has been deleted and quits. When vector terminates, it calls
          its owner and trusts the owner to always delete the vector.
          The ""check return value and quit"" design is not perfect, but
          we are paying the price for isolating the vectors from their
          owners while using direct calls between them (instead of
          MsgPipe or a similar less efficient indirect approach we use
          elsewhere).

        - Renamed doIcap to startIcap and moved more common code there.
          Changed its return type to bool. We now handle three cases
          when ICAP ACLs call back:  1) No service was selected
          (because there was no applicable service or because all
          applicable services were broken and optional). We proceed as
          if ICAP was not configured.  2) The selected essential
          service is broken. This is a fatal transaction error and we
          return an ""ICAP protocol error"" HTTP error response. We could
          proceed with the ICAP stuff, but it saves a lot of cycles to
          abort early.  3) The selected service is not broken. We
          proceed with the ICAP stuff.  The old code did not detect
          case #2, even though there was code to handle that case (with
          dangerous XXX suggestions that are now gone).  The code
          should probably be polished further to move common ftp/http
          logic from icapAclCheckDone()s into ServerStateData.

        - Make sure there is an accept callback when we are accepting.
          If there is no callback and we accept, we will silently leak
          the accepted FD.  When we are running out of FDs, there is
          often no accept callback.  The old code, when running out of
          FDs, would create lots of ""orphaned"" or ""forgotten"" FDs that
          will eventually get into a CLOSED_WAIT state and remain there
          until Squid quits.  The new code does not call accept() if
          there is no accept callback and does not register the accept
          FD for reading if the AcceptLimiter is deferring, because
          when the AcceptLimiter kicks in, it will register the accept
          FD for reading. There are most likely other places/cases
          where accept FD should not be registered for reading.

        - When an exception is caught, mark the ICAP connection as
          non-reusable so that it is not recycled while a write is
          pending but simply closed instead. Our write callback will
          still be called, unfortunately, because there is no way to
          clear the callback without invalidating its data (i.e., the
          transaction pointer).  This change prevents pconn.cc:253:
          ""!comm_has_incomplete_write(fd)"" assertion from firing when
          things go wrong (e.g., the ICAP server cannot be contacted to
          retrieve OPTIONS).  Not all exceptions caught by the ICAP
          xaction should lead to the ICAP connection termination, but
          it is very difficult if not impossible to reliably detect
          exceptional conditions when it is safe to reuse the ICAP
          connection, and it is probably not worth it anyway.

        - Added Tsantilas Christos <chtsanti@users.sourceforge.net>
          to CONTRIBUTORS for fixing ICAP bugs.

        - Polished debugging.",2091,data/crawl/squid/hunk_4725.cpp,inner similar method,non-trivial,data/crawl/squid/old_hunk_4725.cpp,data/crawl/squid/new_hunk_4725.cpp,-1,18,,stop(notifyNone);,"[""addLog""]","[[], [""stop"", ""notifyNone""]]",[-10998138912094340629],7533,99072.0,5
https://github.com/squid-cache/squid/commit/b7d249f9ddca7cfe73ac27d273901450e81baf31,02 Nov 2006,"Add support for wccpv2 mask assignment

Forwrd port of 2.6 changes.",535,data/crawl/squid/hunk_4713.cpp,check similar return value,non-trivial,data/crawl/squid/old_hunk_4713.cpp,data/crawl/squid/new_hunk_4713.cpp,-1,69,,"fatalf(""Unknown Wccp2 assignment method\n"");","[""addLog""]","[[], [""fatalf"", ""Unknown"", ""Wccp2"", ""assignment"", ""method\\n""]]",[-408584221186559861],7532,0.0,5
https://github.com/squid-cache/squid/commit/5f8252d203092b380f73e997be7097282c793077,06 Apr 2007,"	- ICAP-unrelated improvements from the squid3-icap branch on SF
	  (see further below for ICAP-specific improvements):

	- Replaced BodyReader with BodyPipe. BodyReader was a
	  collection of function pointers augmented with body size
	  calculation logic. BodyReader was used to deliver request
	  body (of a known size) from the client side to the server
	  side. Reference counting was used to communicate abort
	  conditions to the other side (it did not work well because
	  decreasing the reference count does not have any side-effects
	  if the count remains positive). Direct calls between sides
	  sometimes resulted in a call-me-when-I-am-calling-you ""loops""
	  and related bugs.

	  BodyPipe is used to deliver request or response body (possibly
	  of unknown size) from the body producer to the body consumer.
	  A producer can be the client side (for virgin requests), the
	  server side (for virgin replies), or the ICAP side (for
	  adapted messages). A consumer can be the client side (for
	  adapted responses, including responses in a request
	  satisfaction mode), the server side (for adapted requests),
	  and the ICAP side (for virgin requests and responses).

	  BodyPipe uses asynchronous calls for communication between
	  sides to avoid call-me-when-I-am-calling-you ""loops"".

	  BodyPipe has methods to communicate normal termination and
	  abort conditions to the other side. The use of those methods
	  is mandatory. Reference counting is used only as a garbage
	  collection mechanism.

	  BodyPipe is used to read request bodies, including requests
	  for which there is no consumer and the connection is in a
	  'closing' state. BodyPipe can auto-consume body so that a
	  'closing' connection does not have to rely on the body
	  consumer presence when eating up remaining body data.

	  If auto-consumption is turned on and the pipe starts
	  consuming before a real consumer is attached to the pipe, the
	  setConsumerIfNotLate call fails, and the real consumer has to
	  handle the failure.

	  The new BodyPipe approach should make support for HTTP/1.1
	  chunked requests easier. Only a few places in the pipe-related
	  code assume that the request size is known.

	- Removed ClientBody as unused, replaced by BodyReader, then
	  BodyPipe.

	- Moved HttpRequest::body_reader to HttpMsg::body_pipe so that
	  all HTTP message bodies can be communicated via pipes. This
	  is needed for the server side to supply response bodies to
	  ICAP and for the ICAP side to supply adapted message bodies
	  to others.

	- When cleaning HttpRequest or HttpReply, reset body_pipe to
	  NULL instead of asserting that it is already NULL. BodyPipes
	  are owned and maintained by other objects and HttpMsg is used
	  only as a mechanism to pass the pipe pointer from the body
	  producer to the consumer. To maintain guarantees similar to
	  the old code, the BodyPipe destructor asserts that both the
	  producer and the consumer are gone when the pipe is
	  destructed.

	- When appending body data, do not append more than the known
	  body size. This fixes the following assertion when POSTing
	  from IE in my tests: assertion failed: client_side.cc:3205:
	  ""bodySizeLeft() > 0"".

	  I suspect IE or some Javascripts running on IE were appending
	  extra CRLF to a POST, exposing the bug, and triggering the
	  above assertion.

	- WARNING: Ftp-specific BodyPipe changes are untested, but the
	  old code probably did not work well with ICAP either.  More
	  testing is needed.

	- Moved more common server-side code from http.* and ftp.* into
	  Server.*.  Most ICAP-related code is in the Server class now.

	  The code move to the Server class and migration to BodyPipe
	  exposed several FTP/HTTP inconsistencies and bugs. I marked
	  those I could not fix with XXXs.

	- Distinguish the end of communication with the origin server
	  from the end of communication with ICAP. Clean them up
	  separately when possible. Terminate when both are completed
	  (or aborted).

	- Polished persistentConnStatus() to avoid calling
	  statusIfComplete() until really necessary (and appropriate).
	  This makes debugging easier to understand for some.

	- Use auto-consumption feature to consume data from closing
	  connections for which there is no real body consumer.

	- Use BodyPipe for maintaining the ""closing"" state of a
	  connection instead of in.abortedSize. This change ""removes"" a
	  few memory leaks and an assertion, but does need more work,
	  especially when the regular BodyPipe consumer leaves early
	  and does not consume the request body.

	- The client stream code sometimes marks the ""closing""
	  connection as STREAM_UNPLANNED_COMPLETE, leading to a
	  double-close. I do not yet understand why. There is now code
	  to ignore multiple attempts to enter the ""closing"" state.



	- ICAP improvements from the squid3-icap branch on SF, including:

	- Added icap_service_failure_limit squid.conf option. The limit
	  specifies the number of failures that Squid tolerates when
	  establishing a new TCP connection with an ICAP service. If
	  the number of failures exceeds the limit, the ICAP service is
	  not used for new ICAP requests until it is time to refresh
	  its OPTIONS. The per-service failure counter is reset to zero
	  each time Squid fetches new service OPTIONS.

	  A negative value disables the limit.

	  The limit used to be hardcoded to 10.

	  (based on the patch by Axel Westerhold)

	- Added icap_service_revival_delay squid.conf option.  The
	  delay specifies the number of seconds to wait after an ICAP
	  OPTIONS request failure before requesting the options again.
	  The failed ICAP service is considered ""down"" until fresh
	  OPTIONS are fetched.

	  The actual delay cannot be smaller than the [still] hardcoded
	  minimum delay of 60 seconds.

	  (based on the patch by Axel Westerhold)

	- Added icap_client_username_header and
	  icap_client_username_encode squid.conf options to control how
	  the authenticated client username should be sent to the ICAP
	  service. (based on the patch by Axel Westerhold)

	- Handle REQMOD transaction failures where we cannot proceed
	  with the normal request flow.

	- Use ICAPInitiator API to send ""success"" or ""abort"" messages
	  to ICAP transaction initiator. Store virgin and adapted
	  metadata as public fields (if the newly added ICAPInOut type)
	  that the initiator can access when receiving our ""successful
	  adaptation"" message. This keeps messages simple.

	- Using ICAPInitiator API and a ""universal"" BodyPipe API makes
	  it possible to exchange bodies directly with client- or
	  server-side code without ICAPClient* translators, which are
	  now gone along with the ICAPInitXaction function in
	  ICAPClient.

	- Added ICAPInitiator interface that classes initiating ICAP
	  transactions must now support. The API currently has just two
	  methods: one for receiving adapted message headers
	  (indicating a successful ICAP transaction, at least to the
	  point of fetching adapted headers) and one for receiving a
	  notification of an aborted ICAP transaction.

	  Most ICAP initiators (or their close relatives) will also need
	  to implement BodyConsumer and/or BodyProducer APIs to exchange
	  virgin and/or adapted HTTP message bodies with the initiated
	  ICAP transaction. However, that activity is not addressed in
	  this API.  New AsyncCall API is used to declare the callback
	  wrappers.

	- Use BodyPipe instead of MsgPipe for receiving virgin and
	  sending adapted message bodies. BodyPipe is not much
	  different from MsgPipeBody, but it is better to use a
	  ""universal"" class that the rest of Squid code now uses.  One
	  complication is that BodyPipes are currently not created for
	  messages with zero-size bodies. The code had to be changed to
	  not assume that a zero-size body comes with a pipe.

	- Deleted MsgPipe and related classes. Message pipes had two
	  purposes: coordinate HTTP message adaptation (start, get the
	  adapted headers, abort) and exchange HTTP message bodies. The
	  latter is now done via BodyPipe API. The former can be
	  implemented directly in ICAPModXact.

	  Deleted ICAPClient* and related classes as (my) design
	  failure.

	  The original idea behind message pipes and ICAPClient* classes
	  was to isolate ICAP code from the Squid core. The core code
	  was supposed to use ICAPClient* classes for all ICAP-related
	  needs, and ICAPClient* classes were supposed to translate core
	  needs into ""ICAP needs"" and use message pipes to communicate
	  with asynchronously running ICAP transactions. The latter part
	  worked fine, but the former did not.

	  The core code still did a lot of ICAP-specific work on its
	  own. This could be because ICAP processing affects the flow so
	  much or because the core code had not been refactored enough
	  to minimize ICAP interactions.  Whatever the reason, we ended
	  up with a lot of complex code/logic coordinating the core code
	  and ICAPClient* classes. While ICAPClient* classes were
	  ""translating"", they could not hide the key actions or events
	  (such as message body exchange or transaction aborts) from the
	  core. The core code still had to support those actions or
	  handle those events.  Thus, every major action or event was
	  handled twice:  once in the core side code and once in a
	  ICAPClient* class.

	  Removing ICAPClient* ""translation"" step simplified the code
	  and possibly improved performance. As for the ""ICAP
	  separation"" goal, the current exposure to the ICAPModXact
	  class can be hidden by a generic ""Message Adaptation
	  Transaction"" class if we need to support more adaptation
	  protocols. The core code should not be affected much by such a
	  change.

	- ClientHttpRequest: Support the new ICAPInitiator API and talk
	  to ICAPModXact directly instead of using ICAPClient* classes,
	  which are now gone.

	- ConnStateData: Use BodyPipe for delivering virgin request
	  bodies to the server or ICAP side. Implement the BodyProducer
	  interface.  ClientHttpRequest: Use BodyPipe instead of
	  BodyReader when receiving request bodies (from client side or
	  ICAP).  Implement the BodyConsumer interface.  See the first
	  BodyPipe CVS log message for the rationale.

	- Use BodyPipe for delivering virgin reply bodies to ICAP and
	  receiving adapted reply bodies from ICAP. Implement the
	  BodyProducer interface.

	  Use BodyPipe instead of BodyReader when receiving request
	  bodies (from client side or ICAP).  Implement the BodyConsumer
	  interface.

	- Replaced never-failing doIcap() with startIcap() that fails
	  if we cannot select an ICAP service or the selected service
	  is not usable. Rearranged
	  ClientRequestContext::icapAclCheckDone() to bypass ICAP
	  errors when possible.  Now, ClientRequestContext::startIcap()
	  is very similar to Server::startIcap(). Same for
	  icapAclCheckDone().  Made
	  ClientHttpRequest::handleIcapFailure() public because
	  ClientRequestContext::icapAclCheckDone() calls it.

	- Polished TTL handling to make sure we use the default TTL
	  when the ICAP server did not provide an explicit value or if
	  we failed to communicate with the server. The latter case may
	  not have been handled correctly before.

	- The minimum options update gap (currently hard-coded) must be
	  smaller than the default options TTL. Otherwise, we get stale
	  options and down ICAP services around the update time because
	  we cannot update soon enough.

	- Support asynchronous transaction start. This allows for a
	  better handling of startup errors (or at least makes them
	  similar to other transaction errors).

	- Call a swanSong() method upon expected transaction
	  termination (including aborts). This allows for proper and
	  prompt [partial] transaction cleanup, without waiting for the
	  destructor to be called. The destruction may be delayed by
	  refcounting if we have other transaction users waiting for
	  some transaction notifications.

	- Do not reuse a connection if we are still reading or writing
	  (even if no actual I/O is scheduled). The old code would
	  reuse such connections, and read/write leftovers from aborted
	  transactions from/to the ICAP server.

	- Do not send last-chunk in ICAP Preview with a null-body. It is
	  possible that the old code would send the last-chunk under
	  some Preview conditions with null-body, but I am not sure.

	- Fixed HttpStateData memory leak visible when no RESPMOD
	  services are enabled.  ICAPAccessCheck constructor was
	  cbdata-locking HttpStateData, but was not releasing the lock
	  when there was no matching service class, leading to an
	  HttpStateData leak. Furthermore, ICAPAccessCheck would then
	  call HttpStateData back without validating the cbdata
	  pointer, probably calling wrong or invalid HttpStateData.

	- Fixed ""is it too late to bypass?"" conditions in
	  ClientHttpRequest::handleIcapFailure(). We should be able to
	  bypass more often now. However, handleIcapFailure() still has
	  the old bug: it does not check whether the service is
	  optional. The current fix implies that now Squid may bypass
	  essential services more often.

	- Call storeEntry()->complete() when ending request
	  satisfaction. Without this call, we may keep the connection
	  open, which does not work with responses that mark the end of
	  their body by closing a connection. (Christos Tsantilas)

	- Fixed ieof condition detection. Squid was sending last-chunk
	  without ieof bit and was sending two last chunks when doing
	  preview (Tsantilas Christos).

	- When ICAP server wants the entire virgin body and sends 100
	  Continue after Preview, do not stop backing up virgin body
	  data for echoing if we promised to support 204 No Content
	  responses outside of Preview. If we allow 204s, 100 Continue
	  may be followed by a 204 No Content and we will need the
	  entire virgin body to echo back.

	- Rewrote MemBufClaim into a VirginBodyAct class to simplify
	  and clarify code in hope to minimize the number of bugs like
	  the one mentioned above. MemBufClaim was protecting an area
	  of virgin body pipe content and, as a side effect, was
	  providing the transaction with the content pointer for the
	  write or send actions.

	  Now VirginBodyAct just maintains the activity offset and the
	  transaction code uses that to consume virgin body correctly.
	  The size of the area is no longer maintained because it was
	  usually unknown or unused; and when it was known and used
	  (i.e., Preview), it could be taken from the preview state
	  object anyway.  Renamed and documented VirginBodyAct-related
	  methods to clarify the intent.

	- When sending last-chunk in Preview, send ieof extension if we
	  wrote the entire body. The old code would not send ieof if we
	  wrote as many bytes as promised in the Preview header, even
	  if we promised to write everything.  This would mislead
	  compliant ICAP servers that do not look at the Content-Length
	  header and reply with 100 Continue, expecting more body data.

	- Do not reset Preview size to zero when expecting a virgin
	  body of unknown size. A Squid user reported that this change
	  works.

	- Polished debugging: Instead of using pointers, use unique ICAP
	  transaction IDs.  This helps with isolating a transaction in a
	  large log, where pointers may be reused many times. Print
	  connection descriptor like most of the core code does. Other
	  minor improvements.",4655,data/crawl/squid/hunk_4671.cpp,inner similar method,non-trivial,data/crawl/squid/old_hunk_4671.cpp,data/crawl/squid/new_hunk_4671.cpp,82,-1,stop(notifyNone);,,"[""removeLog""]","[[""stop"", ""notifyNone""], []]",[10998138912094340629],7531,89856.0,5
https://github.com/squid-cache/squid/commit/89f77e43f36bdbd636826c94085f9b5d882e473d,24 Jun 2007,"Bug #1948: digest_edir_auth helper, using novell eDirectory universal password

This is a modified version of digets_ldap_auth, with eDirectory special hooks
for retrieving the Universal Password plain text password.",1874,data/crawl/squid/hunk_4545.cpp,check similar return value,non-trivial,data/crawl/squid/old_hunk_4545.cpp,data/crawl/squid/new_hunk_4545.cpp,-1,675,,"fprintf(stderr, PROGRAM_NAME "" ERROR: can not allocate memory\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""PROGRAM_NAME"", ""ERROR"", ""can"", ""not"", ""allocate"", ""memory\\n""]]",[5282042152026651368],7530,984960.0,5
https://github.com/squid-cache/squid/commit/89f77e43f36bdbd636826c94085f9b5d882e473d,24 Jun 2007,"Bug #1948: digest_edir_auth helper, using novell eDirectory universal password

This is a modified version of digets_ldap_auth, with eDirectory special hooks
for retrieving the Universal Password plain text password.",1874,data/crawl/squid/hunk_4545.cpp,check similar return value,non-trivial,data/crawl/squid/old_hunk_4545.cpp,data/crawl/squid/new_hunk_4545.cpp,-1,661,,"fprintf(stderr, PROGRAM_NAME "" ERROR: Secret file %s is empty\n"", filename);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""PROGRAM_NAME"", ""ERROR"", ""Secret"", ""file"", ""%s"", ""is"", ""empty\\n"", ""filename""]]",[-13530033979971404440],7529,984960.0,5
https://github.com/squid-cache/squid/commit/89f77e43f36bdbd636826c94085f9b5d882e473d,24 Jun 2007,"Bug #1948: digest_edir_auth helper, using novell eDirectory universal password

This is a modified version of digets_ldap_auth, with eDirectory special hooks
for retrieving the Universal Password plain text password.",1874,data/crawl/squid/hunk_4545.cpp,check similar return value,non-trivial,data/crawl/squid/old_hunk_4545.cpp,data/crawl/squid/new_hunk_4545.cpp,-1,657,,"fprintf(stderr, PROGRAM_NAME "" ERROR: Can not read secret file %s\n"", filename);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""PROGRAM_NAME"", ""ERROR"", ""Can"", ""not"", ""read"", ""secret"", ""file"", ""%s\\n"", ""filename""]]",[-13528255030028203367],7528,984960.0,5
https://github.com/squid-cache/squid/commit/89f77e43f36bdbd636826c94085f9b5d882e473d,24 Jun 2007,"Bug #1948: digest_edir_auth helper, using novell eDirectory universal password

This is a modified version of digets_ldap_auth, with eDirectory special hooks
for retrieving the Universal Password plain text password.",1874,data/crawl/squid/hunk_4545.cpp,check similar variable,non-trivial,data/crawl/squid/old_hunk_4545.cpp,data/crawl/squid/new_hunk_4545.cpp,-1,571,,"fprintf(stderr, ""TLS (-Z) is incompatible with version %d\n"",
		    version);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""TLS"", ""Z"", ""is"", ""incompatible"", ""with"", ""version"", ""%d\\n"", ""version""]]",[-14722757135422908747],7527,1245024.0,5
https://github.com/squid-cache/squid/commit/89f77e43f36bdbd636826c94085f9b5d882e473d,24 Jun 2007,"Bug #1948: digest_edir_auth helper, using novell eDirectory universal password

This is a modified version of digets_ldap_auth, with eDirectory special hooks
for retrieving the Universal Password plain text password.",1874,data/crawl/squid/hunk_4545.cpp,check similar variable,non-trivial,data/crawl/squid/old_hunk_4545.cpp,data/crawl/squid/new_hunk_4545.cpp,-1,565,,"fprintf(stderr, ""Protocol version should be 2 or 3\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""Protocol"", ""version"", ""should"", ""be"", ""2"", ""or"", ""3\\n""]]",[-2561798031947152765],7526,1245024.0,5
https://github.com/squid-cache/squid/commit/89f77e43f36bdbd636826c94085f9b5d882e473d,24 Jun 2007,"Bug #1948: digest_edir_auth helper, using novell eDirectory universal password

This is a modified version of digets_ldap_auth, with eDirectory special hooks
for retrieving the Universal Password plain text password.",1874,data/crawl/squid/hunk_4545.cpp,check similar variable,non-trivial,data/crawl/squid/old_hunk_4545.cpp,data/crawl/squid/new_hunk_4545.cpp,-1,513,,"fprintf(stderr, PROGRAM_NAME "" ERROR: -E unsupported with this LDAP library\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""PROGRAM_NAME"", ""ERROR"", ""E"", ""unsupported"", ""with"", ""this"", ""LDAP"", ""library\\n""]]",[-14444500455805034374],7525,984096.0,5
https://github.com/squid-cache/squid/commit/89f77e43f36bdbd636826c94085f9b5d882e473d,24 Jun 2007,"Bug #1948: digest_edir_auth helper, using novell eDirectory universal password

This is a modified version of digets_ldap_auth, with eDirectory special hooks
for retrieving the Universal Password plain text password.",1874,data/crawl/squid/hunk_4545.cpp,check similar variable,non-trivial,data/crawl/squid/old_hunk_4545.cpp,data/crawl/squid/new_hunk_4545.cpp,-1,462,,"fprintf(stderr, ""ERROR: Your LDAP library does not have URI support\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""ERROR"", ""Your"", ""LDAP"", ""library"", ""does"", ""not"", ""have"", ""URI"", ""support\\n""]]",[18986198431406661351],7524,984960.0,5
https://github.com/squid-cache/squid/commit/89f77e43f36bdbd636826c94085f9b5d882e473d,24 Jun 2007,"Bug #1948: digest_edir_auth helper, using novell eDirectory universal password

This is a modified version of digets_ldap_auth, with eDirectory special hooks
for retrieving the Universal Password plain text password.",1874,data/crawl/squid/hunk_4545.cpp,check similar return value,non-trivial,data/crawl/squid/old_hunk_4545.cpp,data/crawl/squid/new_hunk_4545.cpp,-1,350,,"fprintf(stderr, PROGRAM_NAME "": ERROR: TLS (-Z) not supported on this platform.\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""PROGRAM_NAME"", ""ERROR"", ""TLS"", ""Z"", ""not"", ""supported"", ""on"", ""this"", ""platform"", ""\\n""]]",[10221048830143577611],7523,493344.0,5
https://github.com/squid-cache/squid/commit/89f77e43f36bdbd636826c94085f9b5d882e473d,24 Jun 2007,"Bug #1948: digest_edir_auth helper, using novell eDirectory universal password

This is a modified version of digets_ldap_auth, with eDirectory special hooks
for retrieving the Universal Password plain text password.",1874,data/crawl/squid/hunk_4545.cpp,inner similar method,non-trivial,data/crawl/squid/old_hunk_4545.cpp,data/crawl/squid/new_hunk_4545.cpp,-1,148,,"fprintf(stderr, ""Connect timeouts not supported in your LDAP library\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""Connect"", ""timeouts"", ""not"", ""supported"", ""in"", ""your"", ""LDAP"", ""library\\n""]]",[5623528979515244551],7522,984096.0,5
https://github.com/squid-cache/squid/commit/9e6e0372016a2d16124516049b5b9cd0ae9c52f8,17 May 2008,"Windows port: Added new mswin_check_ad_group external ACL helper

This helper allow the lookup of users's group membership in a Windows
Active Directory domain.
It overcomes the Lan Manager limits of mswin_check_lm_group, but it can be
used only with native Windows Active Directory domains, so mswin_check_lm_group 
will not removed from Squid.",669,data/crawl/squid/hunk_4289.cpp,,,data/crawl/squid/old_hunk_4289.cpp,data/crawl/squid/new_hunk_4289.cpp,-1,459,,"fprintf(stderr, ""Invalid Request\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""Invalid"", ""Request\\n""]]",[-14949053334177767064],7521,535104.0,5
https://github.com/squid-cache/squid/commit/9a6a600f88aea8c566d3f1d56ea6f607f9c049ac,24 Jun 2008,"Bug #2365: cachemgr.cgi fails to HTML encode config dumps properly
  
log_format and a couple other directives may contain HTML reserved characters
such as < >, and these needs to be HTML quoted in the output.",6,data/crawl/squid/hunk_4285.cpp,use same text format,non-trivial,data/crawl/squid/old_hunk_4285.cpp,data/crawl/squid/new_hunk_4285.cpp,3,3,"printf(""<P>\n%s</P>\n"", msg);","printf(""<P>\n%s</P>\n"", html_quote(msg));","[""addVariable""]","[[], [""html_quote""]]",[2471647707173191164],7520,802944.0,5
https://github.com/squid-cache/squid/commit/4a485f7104182aa3290f670f213feb6d7934b669,14 Jul 2008,"userhash and sourcehash peer seletction methods

these is effectively just copies of carp.cc with changed keying method
to key on the authenticated username respectiely client source address.",544,data/crawl/squid/hunk_4257.cpp,,,data/crawl/squid/old_hunk_4257.cpp,data/crawl/squid/new_hunk_4257.cpp,-1,211,,"storeAppendPrintf(sentry, ""%24s %10s %10s %10s %10s\n"",
                      ""Hostname"",
                      ""Hash"",
                      ""Multiplier"",
                      ""Factor"",
                      ""Actual"");","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""%24s"", ""%10s"", ""%10s"", ""%10s"", ""%10s\\n"", ""Hostname"", ""Hash"", ""Multiplier"", ""Factor"", ""Actual""]]",[57540478511058568957],7519,3198528.0,5
https://github.com/squid-cache/squid/commit/223901927d51abc6759356742b74a1c623818d14,30 Sep 2008,"eCAP support, phase 2: Implemented libecap interfaces, added eCAP
squid.conf options. Link with libecap when eCAP support is enabled.

eCAP code needs polishing and enhancement but appears to work for a few
targeted cases. I am committing this now so that users working on eCAP
modules can test and provide more specific feedback.

These adaptation-specific changes should not have significant effect on
core code.

The libecap library is available at http://www.e-cap.org/",1758,data/crawl/squid/hunk_4187.cpp,,,data/crawl/squid/old_hunk_4187.cpp,data/crawl/squid/new_hunk_4187.cpp,-1,370,,"mustStop(""initiator aborted"");","[""addLog""]","[[], [""mustStop"", ""initiator"", ""aborted""]]",[-8267585922809030933],7518,394848.0,5
https://github.com/squid-cache/squid/commit/2d51c9088d676bc2c47a4bc01152889d9162ab87,13 Mar 2009,"SourceLayout: acl/, take 1

Moved src/ACL* and a few related files into src/acl/.
Renamed ACL source files from ACLFoo.{cc,cci,h} to Foo.{cc,cci,h}.

Added acl/ libraries, reorganized auth/ libraries, and split ACLChecklist
class to avoid circular dependencies among libraries.

Many targets in src/Makefile.am depended on selected ACL ACL*cc and related
sources.  These targets depend on acl/* libraries now. As a part of this
cleanup, the number of ufsdump sources went from about 160 to about 20.

No functionality changes were intended. Source code changes were kept to the
minimum. All my build tests are successful. However, since I had to move a lot
of files, move some code pieces, and split ACLChecklist, it is possible that
some targets will no longer build in some environments and some authentication
code will break.

Please see individual commit messages for details.",2511,data/crawl/squid/hunk_3808.cpp,,,data/crawl/squid/old_hunk_3808.cpp,data/crawl/squid/new_hunk_3808.cpp,-1,17,,"fatal (""requiresRequest SHOULD have been true for this ACL!!"");","[""addLog""]","[[], [""fatal"", ""requiresRequest"", ""SHOULD"", ""have"", ""been"", ""true"", ""for"", ""this"", ""ACL""]]",[13140470785063076799],7517,2554560.0,5
https://github.com/squid-cache/squid/commit/7015d4eb4c0127faad2180b93e996bad6d9935ff,28 Jun 2009,"Author: Francesco Chemolli <kinkie@squid-cache.org>
Bug 2092: Changed select loop call counter to 64-bit

... unsigned long int so that it won't wrap around so easily.",22,data/crawl/squid/hunk_3754.cpp,,,data/crawl/squid/old_hunk_3754.cpp,data/crawl/squid/new_hunk_3754.cpp,3,3,"storeAppendPrintf(sentry, ""Total number of epoll(2) loops: %d\n"", statCounter.select_loops);","storeAppendPrintf(sentry, ""Total number of epoll(2) loops: %ld\n"", statCounter.select_loops);","[""updateContent""]","[[""%d\\n""], [""%ld\\n""]]",[-8409904864072351395],7516,5402880.0,5
https://github.com/squid-cache/squid/commit/a22e6cd3b6e8889984d266816aaea8fcf27ee13d,13 Jul 2009,"Support adaptation sets and chains, including dynamic ICAP chains:

  - Support adaptation service sets and chains
    (adaptation_service_set and adaptation_service_chain)

  - Dynamically form chains based on ICAP X-Next-Services header
    (icap_service routing=on)

  - Support cross-transactional ICAP header exchange
    (adaptation_masterx_shared_names)


An adaptation service set contains similar, interchangeable services. No more
than one service is successfully applied. If one service is down or fails,
Squid can use another service. Think ""hot standby"" or ""spare"" ICAP servers. 

Sets may seem similar to the existing ""service bypass"" feature, but they allow
the failed adaptation to be retried and succeed if a replacement service is
available. The services in a set may be all optional or all essential,
depending on whether ignoring the entire set is acceptable. The mixture of
optional and essential services in a set is supported, but yields results that
may be difficult for a human to anticipate or interpret. Squid warns when it
detects such a mixture.

When performing adaptations with a set, failures at a service (optional or
essential, does not matter) are retried with a different service if possible.
If there are no more replacement services left to try, the failure is treated
depending on whether the last service tried was optional or essential: Squid
either tries to ignore the failure and proceed or terminates the master
transaction.


An adaptation chain is a list of different services applied one after another,
forming an adaptation pipeline. Services in a chain may be optional or
essential. When performing adaptations, failures at an optional service are
ignored as if the service did not exist in the chain.

Request satisfaction terminates the adaptation chain.


When forming a set or chain for a given transaction, optional down services
are ignored as if they did not exist.

ICAP and eCAP services can be mixed and matched in an adaptation set or chain.


Merged from 3p1-plus branch at r9513.


* Implementation notes

The notes below focus on _changes_. Adaptation terminology and current layers
are now being documented in src/adaptation/notes.dox

Service sets and chains are implemented as ServiceGroup class kids. They are
very similar in most code aspects. The primary external difference is that
ServiceSet can ""replace"" a service and ServiceChain can find the ""next""
service.  The internal search code is implemented in ServiceGroup parent and
is parametrized by the kids.

Before the adaptation starts, Squid calculates the adaptation ""plan"", which is
just an iterator into the ServiceGroup. The client- and server-side adaptation
initiators used to deal with Service pointers. They now deal with ServiceGroup
pointers. The only interesting difference is that a ServiceGroup does not have
a notion of being optional or essential. Thus, if adaptation start fails, we
do not know whether the failure can be bypassed. Fortunately, starting an
adaptation does not require anything that depends on the adaptation services,
so we now simply assert that the start succeeds.

If the entire adaptation fails, the callers are notified as before. They are
told whether they can ignore the failure as before. No changes there.

A new Adaptation::Iterator class has been added to execute the adaptation
plan. That class is responsible for iterating the services in a service group
until the plan is exhausted or cannot progress due to a final failure. 


Dynamically form adaptation chains based on the ICAP X-Next-Services header.

If an ICAP service with the routing=1 option in squid.conf returns an ICAP
X-Next-Services response header during a successful REQMOD or RESPMOD
transaction, Squid abandons the original adaptation plan and forms a new
adaptation chain consisting of services identified in the X-Next-Services
header value (using a comma-separated list of adaptation service names from
squid.conf).  The dynamically created chain is destroyed once the new plan is
completed or replaced.

This feature is useful when a custom adaptation service knows which other
services are applicable to the message being adapted.

Limit adaptation iterations to adaptation_service_iteration_limit to protect
Squid from infinite adaptation loops caused by ICAP services constantly
including themselves in the dynamic adaptation chain they request. When the
limit is exceeded, the master transaction fails. The default limit of 16
should be large enough to not require an explicit configuration in most
environments yet may be small enough to limit side-effects of loops.

TODO: Add metadata support to eCAP API and honor X-Next-Services there as
well. Currently, only ICAP services can form dynamic chains but the formed
chains may contain eCAP services.


Other improvements:

Polished adaptation service configuration in squid.conf. Old format with an
anonymous bypass option is deprecated but still supported. Quit with a fatal
message if an adaptation service is misconfigured (debugging level-0 messages
do not seem to work at that stage, but that is probably another, general bug).


Polished HttpRequest::adaptHistory() interface so that the code that knows the
history is needed can force history creation without complex
configuration-time preparations and state. Currently, all adaptation history
users but the logging-related ones know runtime whether the history must be
created (e.g., when a certain ICAP header is received).


Fixed ""canonical"" Request URL maintenance when ICAP clones requests.
TODO: The urlCanonical() must become HttpRequest::canonical(), hiding the
often out-of-sync canonical data member.


Fixed ICAP request parsing (for ICAP logging). We used to parse Request-Line
as if it were the first header. TODO: optimize by parsing only when needed.


Fixed AccessCheck case where a service group disappears during a nb ACL check.
Replaced ""done"" member with an existing AsyncJob mustStop mechanism. Removed
extra async call as unneeded because ACL callbacks are already async.",1718,data/crawl/squid/hunk_3714.cpp,,,data/crawl/squid/old_hunk_3714.cpp,data/crawl/squid/new_hunk_3714.cpp,3,3,"disableBypass(""consumed content"");","disableBypass(""consumed content"", true);","[""addContent""]","[[], [""true""]]",[2314047222236391260],7515,0.0,5
https://github.com/squid-cache/squid/commit/77721eb240367f9d4bd82638f118c811f2e93349,05 Nov 2009,"Author: Markus Moeller huaraz@moeller.plus.com>
Update squid_kerb_auth helper

 * remove sub configure again (too many issues)

Also, by Amso Jeffries
 * naming update to negotiate_kerberos_auth
 * polished helper detection rules in configure",10781,data/crawl/squid/hunk_3545.cpp,,,data/crawl/squid/old_hunk_3545.cpp,data/crawl/squid/new_hunk_3545.cpp,-1,541,,"fprintf(stdout, ""BH Not enough memory\n"");","[""addLog""]","[[], [""fprintf"", ""stdout"", ""BH"", ""Not"", ""enough"", ""memory\\n""]]",[-5566043686881520900],7514,100224.0,5
https://github.com/squid-cache/squid/commit/77721eb240367f9d4bd82638f118c811f2e93349,05 Nov 2009,"Author: Markus Moeller huaraz@moeller.plus.com>
Update squid_kerb_auth helper

 * remove sub configure again (too many issues)

Also, by Amso Jeffries
 * naming update to negotiate_kerberos_auth
 * polished helper detection rules in configure",10781,data/crawl/squid/hunk_3545.cpp,,,data/crawl/squid/old_hunk_3545.cpp,data/crawl/squid/new_hunk_3545.cpp,-1,210,,"fprintf(stderr, ""%s| %s: %s failed: %s\n"", LogTime(), PROGRAM,
		function, buf);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""%s"", ""%s"", ""%s"", ""failed"", ""%s\\n"", ""LogTime"", ""PROGRAM"", ""function"", ""buf""]]",[-13411346457197098932],7513,766944.0,5
https://github.com/squid-cache/squid/commit/18ec8500ce3dc21de9f8325af0f2d5cf93132fcd,17 Nov 2009,Fixed some cases of variable shadowing,106,data/crawl/squid/hunk_3532.cpp,,,data/crawl/squid/old_hunk_3532.cpp,data/crawl/squid/new_hunk_3532.cpp,7,7,"httpHeaderPutStrf(&rep->header, type, ""Basic realm=\""%s\"""", basicAuthRealm);","httpHeaderPutStrf(&rep->header, hdrType, ""Basic realm=\""%s\"""", basicAuthRealm);","[""updateVariable""]","[[""type""], [""hdrType""]]",[-250865384264815883],7512,0.0,5
https://github.com/squid-cache/squid/commit/076df709f55936015ee00327e3b6586e1f9ec9f7,17 Nov 2009,Fixed some cases of variable shadowing,50,data/crawl/squid/hunk_3530.cpp,,,data/crawl/squid/old_hunk_3530.cpp,data/crawl/squid/new_hunk_3530.cpp,4,4,"httpHeaderPutStrf(&rep->header, type, ""Negotiate"");","httpHeaderPutStrf(&rep->header, reqType, ""Negotiate"");","[""updateVariable""]","[[""type""], [""reqType""]]",[-5220649235763027813],7511,0.0,5
https://github.com/squid-cache/squid/commit/e053c141e955538f4b2a06f31ead42b66a3f3abd,18 Nov 2009,Fixed some cases of variable shadowing,180,data/crawl/squid/hunk_3521.cpp,,,data/crawl/squid/old_hunk_3521.cpp,data/crawl/squid/new_hunk_3521.cpp,3,3,"printf(""%s OK message=\""Bye\""\n"", index);","printf(""%s OK message=\""Bye\""\n"", user_key);","[""updateVariable""]","[[""index""], [""user_key""]]",[-624353835239633432],7510,0.0,5
https://github.com/squid-cache/squid/commit/27bc2077cdd539eabfb20ed051980dba4e75b51b,22 Mar 2010,"Compat: shuffle replacement OS function fiels into libcompat

* strerror() is omitted due to an emulator, and multiple
  replacement functions being defined with rather complicated
  interactions.

* the .c parts must also remain in lib/ for now to simplify
  autoconf logics.",612,data/crawl/squid/hunk_3405.cpp,,,data/crawl/squid/old_hunk_3405.cpp,data/crawl/squid/new_hunk_3405.cpp,5,5,"fprintf(stderr,
                ""%s| %s: ERROR: resolving hostname with getaddrinfo: %s failed\n"",
                LogTime(), PROGRAM, xgai_strerror(rc));","fprintf(stderr,
                ""%s| %s: ERROR: resolving hostname with getaddrinfo: %s failed\n"",
                LogTime(), PROGRAM, gai_strerror(rc));","[""updateVariable""]","[[""xgai_strerror""], [""gai_strerror""]]",[-2238227337298578263],7509,0.0,5
https://github.com/squid-cache/squid/commit/4542b25ba0c3d195fcd2f43de2e6ba3167957156,02 Jun 2010,"Bug 2305: Multiple leaks and assertion crashes in authentication.

 * implements proper RefCounting using the RefCount.h classes for
   almost all auth objects in Squid.

 * Restructures auth objects with a simpler structure of duties and scopes.

 * Prunes away several circular and indirectly circular pointer loops

 * Adds an API to auth config for handling the mainRotate() event. To only
   shutdown helpers, fixing the loss of cached credentials on rotate.

 * Adds a username_cache page to cachemgr interface to display the current
   credentials and their TTLs to various revalidation or garbage events.


With this we end up with several global pointers for the auth schemes which
have been built into the current Squid. These are RefCount pointers, fixing
the leak of schemes on shutdown. Schemes are now also permanent structures
for the runtime of Squid, fixing leaks on reconfigure and rotate actions.

These AuthSchemes are responsible for creating auth Config objects for each
auth protocol configured in squid.conf. These config objects are now also
able to be altered with a reconfigure instead of requiring a restart.

Each HTTP request authentication attempt generates AuthUserRequest objects,
which may or may not pointer to an AuthUser set of credentials being checked.
AuthUserRequest is RefCounted instead of locked, fixing several assertion
crashes.

AuthUser is now RefCounted instead of locked. It's children inherit
these properties. This simplifies the object handling a lot and fixes
several assertions.
 * This also means AuthUser no longer needs a back-pointer to all
AuthUserRequest in order to see if its still needed alive, fixing one
circular lock loop and a few possible assertions.
 * The username cache pointers to only AuthUser objects, fixing a second
cirular lock loop and potentially leakage. Also simplifying the hash cache
handling a lot.

Non-Auth code needing a reference to authentication credentials should
hold a pointer to either an AuthUserRequest or AuthUser object. Not any
other auth object.


FUTURE WORK;
 There is still some conditions leading to auth re-challenge when they
 are not expected.
 A fair chunk of classes and enums have been shuffled into separate files
 to keep the scopes clearer. This could be increased in future when
 building the Auth namespace.
 Potential is now present for simpler TTL handling for all auth types.



This work was a collaboration between multiple interested parties over
the last year, with additional developer time and testing funded by
Netspace Online Systems.",5398,data/crawl/squid/hunk_3342.cpp,,,data/crawl/squid/old_hunk_3342.cpp,data/crawl/squid/new_hunk_3342.cpp,-1,388,,auth_user_request->denyMessage(blob);,"[""addLog""]","[[], [""auth_user_request"", ""denyMessage"", ""blob""]]",[4613437229150417116],7508,1454112.0,5
https://github.com/squid-cache/squid/commit/4542b25ba0c3d195fcd2f43de2e6ba3167957156,02 Jun 2010,"Bug 2305: Multiple leaks and assertion crashes in authentication.

 * implements proper RefCounting using the RefCount.h classes for
   almost all auth objects in Squid.

 * Restructures auth objects with a simpler structure of duties and scopes.

 * Prunes away several circular and indirectly circular pointer loops

 * Adds an API to auth config for handling the mainRotate() event. To only
   shutdown helpers, fixing the loss of cached credentials on rotate.

 * Adds a username_cache page to cachemgr interface to display the current
   credentials and their TTLs to various revalidation or garbage events.


With this we end up with several global pointers for the auth schemes which
have been built into the current Squid. These are RefCount pointers, fixing
the leak of schemes on shutdown. Schemes are now also permanent structures
for the runtime of Squid, fixing leaks on reconfigure and rotate actions.

These AuthSchemes are responsible for creating auth Config objects for each
auth protocol configured in squid.conf. These config objects are now also
able to be altered with a reconfigure instead of requiring a restart.

Each HTTP request authentication attempt generates AuthUserRequest objects,
which may or may not pointer to an AuthUser set of credentials being checked.
AuthUserRequest is RefCounted instead of locked, fixing several assertion
crashes.

AuthUser is now RefCounted instead of locked. It's children inherit
these properties. This simplifies the object handling a lot and fixes
several assertions.
 * This also means AuthUser no longer needs a back-pointer to all
AuthUserRequest in order to see if its still needed alive, fixing one
circular lock loop and a few possible assertions.
 * The username cache pointers to only AuthUser objects, fixing a second
cirular lock loop and potentially leakage. Also simplifying the hash cache
handling a lot.

Non-Auth code needing a reference to authentication credentials should
hold a pointer to either an AuthUserRequest or AuthUser object. Not any
other auth object.


FUTURE WORK;
 There is still some conditions leading to auth re-challenge when they
 are not expected.
 A fair chunk of classes and enums have been shuffled into separate files
 to keep the scopes clearer. This could be increased in future when
 building the Auth namespace.
 Potential is now present for simpler TTL handling for all auth types.



This work was a collaboration between multiple interested parties over
the last year, with additional developer time and testing funded by
Netspace Online Systems.",5398,data/crawl/squid/hunk_3326.cpp,,,data/crawl/squid/old_hunk_3326.cpp,data/crawl/squid/new_hunk_3326.cpp,64,-1,"fatal(""unexpected authenticateAuthenticate reply\n"");",,"[""removeLog""]","[[""fatal"", ""unexpected"", ""authenticateAuthenticate"", ""reply\\n""], []]",[7738081176919200605],7507,2803968.0,5
https://github.com/squid-cache/squid/commit/43fed740b24c9b64720ba589782c48694ce55c7d,28 Jun 2010,Pull out the basic helper API definitions for sharing,250,data/crawl/squid/hunk_3285.cpp,,,data/crawl/squid/old_hunk_3285.cpp,data/crawl/squid/new_hunk_3285.cpp,4,-1,"fprintf( stdout, ""ERR\n"" );",,"[""removeLog""]","[[""fprintf"", ""stdout"", ""ERR\\n""], []]",[5640522499396071603],7506,2673216.0,5
https://github.com/squid-cache/squid/commit/56ff468707b9146dc19a5c519fd421dd2b9cfcb9,08 Jul 2010,Helpers: upgrade digest helpers to C++,273,data/crawl/squid/hunk_3220.cpp,,,data/crawl/squid/old_hunk_3220.cpp,data/crawl/squid/new_hunk_3220.cpp,4,3,"printf(""No attribute value found\n"");","debug(""No attribute value found\n"");","[""updateLog""]","[[""printf""], [""debug""]]",[474360991262646625],7505,0.0,5
https://github.com/squid-cache/squid/commit/eb1f6bfa7c19555c72c72c7102cac62d8417ee2f,08 Jul 2010,"Author: Jens-S. V�ckler <voeckler@rvs.uni-hannover.de>
Import squid cache 'purge' tool

Just the original code import for crediting the original author.

TODO:
 - patch to fix build problems in modern systems
 - upgrade to cope with current cache_dir formats
 - bundle and distribute updated tool",3295,data/crawl/squid/hunk_3190.cpp,,,data/crawl/squid/old_hunk_3190.cpp,data/crawl/squid/new_hunk_3190.cpp,-1,125,,"fprintf( debug, ""# match from %d-%d on \""%s\""\n"", 
			      subs[offset].rm_so, subs[offset].rm_eo, 
			      line+subs[offset].rm_so );","[""addLog""]","[[], [""fprintf"", ""debug"", ""match"", ""from"", ""%d"", ""%d"", ""on"", ""\\"", ""%s\\"", ""\\n"", ""subs[offset]"", ""rm_so"", ""subs[offset]"", ""rm_eo"", ""line"", ""subs[offset]"", ""rm_so""]]",[-11309608075672930126],7504,0.0,5
https://github.com/squid-cache/squid/commit/c152a4473c4a3d187f67923eb83c5fe6ccd91013,12 Jul 2010,"Helpers: Naming and C++ update for external ACL helpers

 * Also adds the Fake auth helper for testing Basic authentication.
 * Also adds manual pages for most external ACL helpers

TODO: test for and fix any build issues on Windows.",2485,data/crawl/squid/hunk_3132.cpp,,,data/crawl/squid/old_hunk_3132.cpp,data/crawl/squid/new_hunk_3132.cpp,3,3,"printf(""ERR No such user\n"");","SEND_ERR(""No such user"");","[""updateLog"", ""updateContent""]","[[""printf"", ""ERR"", ""user\\n""], [""SEND_ERR"", ""user""]]",[882446102806684045],7503,9792.0,5
https://github.com/squid-cache/squid/commit/2ccf2eb2159f0ee9847669c101f9ed4143e0b01d,19 Aug 2010,"Bundle the purge and hexd tools with Squid sources.

Fixes the remaining known errors with purge tool building within
Squid source tree.


This adds the auto-tools changes necessary to bundle the tool.",564,data/crawl/squid/hunk_3067.cpp,,,data/crawl/squid/old_hunk_3067.cpp,data/crawl/squid/new_hunk_3067.cpp,-1,87,,"fputs(""   "",stdout);","[""addLog""]","[[], [""fputs"", ""stdout""]]",[-12222144665393643080],7502,883008.0,5
https://github.com/squid-cache/squid/commit/7c16470cc2d053ea2c540459843227dea08e8b40,16 Oct 2010,"basic_msnt_auth helper and NTLM/SMBLIB/RFCNB library polish.

Samba smblib/rfcnb code:
 * Import the latest copy which I could find a download link to.
   This source is from 1997 so I suspect there is something even newer
   we should be using. Time was tight is the only excuse for using
   these sources. Our originals were from 1995 and 1996 depending on the
   helper using it, with a mix of patches.

 * These two directories are in ours sources as lib/smblib and lib/rfcnb.
   Each has its own convenience library. Kept separate with original
   filenames to simplify future upgrades or removal.

 * Samba sources have been diffed and compared function by function
   against the copies previously in our sources. Functionality extensions
   we use have been grafted back on top of the new(er) Samba sources.
  - this was mostly around passing extra Unicode, DC hints and pre-crypted
    passwords to the login checks.
  - some files from libntlmauth have yet to be compared in fine detail,
    that will be completed today before merge.
  - some basic API function and struct definitions had to be moved to the
    API headers to prevent needing to include the *-priv.h private
    definitions externally to the library.

 * the Samba API headers have been wrapped with #ifndef safety wrappers

 * compile errors and include changes required to compile have been
   made (code stays C)

 * duplicate code in helpers/basic_auth/MSNT/* and libntlmauth/* is
   removed.

 * abuse of the smblib-priv.h and rfcnb-priv.h headers and all local
   re-definitions has been erased from our code. Replaced by includes 
   of the library API headers: rfcnb/rfcnb.h  smblib/smblib.h


libntlmauth:
 * smblib/rfcnb bits erased
 * moved to lib/ntlmauth in its much reduced form
 * built as a convenience library instead of full library",14917,data/crawl/squid/hunk_2952.cpp,,,data/crawl/squid/old_hunk_2952.cpp,data/crawl/squid/new_hunk_2952.cpp,-1,215,,"fprintf(stderr, ""Sending packet: "");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""Sending"", ""packet""]]",[-23441903884649910407],7501,1027584.0,5
https://github.com/squid-cache/squid/commit/8822ebee4947bcf883d74aa79a26e896449d0c36,28 Oct 2010,"SMP Cache Manager, Phase2 implementation.

Cache Manager actions are forwarded to Coordinator. Coordinator iterates over
Kids, aggregating their stats if possible and/or allowing each kid to dump
non-aggregatable output directly into response if needed. Non-aggregated
output is wrapped in ""by kidN { ... } by kidN"" markup to ease auto-processing.

Regressions and small output formatting changes are probably unavoidable
because stats are aggregated and passed around as doubles instead of integers
(no more overflows though!) and because many stats collection and formatting
lines had to be touched. These are steps in the right direction though, IMO.


Old code both computed and dumped stats to Store at the same time. To avoid
computing code duplication, we now collect stats in primitive Stats objects
and then either dump those to Store or send them to Coordinator for
aggregation and, eventual Store dump. What stats to collect, when to
aggregate, and when to dump is decided by action-specific Mgr::Action classes.

The Cache Manager menu now consists of ActionProfile objects. ActionProfile
maintains hard-coded information about specific actions. It uses ActionCreator
member to create Action objects when a cache manager request is received.

Added Mgr::ActionParams class to maintain action parameters, including HTTP
request details necessary for Store entry creation (in another strand) and
action-specific parameters (currently just credentials). In Phase3, this class
can be extended to supply more parameters such as kid IDs to which the action
should apply.

Added Mgr::Command that combines hard-coded ActionProfile details with
user-specified ActionParams. This simplifies many interfaces because we no
longer need to supply a long list of parameters, covering various parts of
action config.


Moved Cache Manager registration to Mgr::RegisterAction() globals to reduce
dependency on the CacheManager class, which is a singleton anyway, and which
is unused by most of the registration callers.  On the other hand, without
this change, no legacy (function-based actions) code would have been changed!


Enhanced TypedMsgHdr class to simplify storing and loading non-POD classes.
The caller can now easily handle a non-POD class as a series of put/get calls,
one for each POD member. This was necessary to send Mgr::ActionParams to
Coordinator and back. Will probably be useful for sending other complex
structures as well.


Reconfigure, shutdown, and other ""basic"" actions have been moved to
src/mgr/BasicActions.cc. Mgr::RegisterBasics() registers them.


Most of the Cache Manager code is now in src/mgr/.


Many more polishing touches.


More polishing left for future projects: Move CacheManager to Mgr namespace
and src/mgr/ directory. Use SBuf instead of String for ActionParams and
TypedMsgHdr. Rename Ipc::TypedMsgHdr to Ipc::Msg, Ipc::SocketMsg, or similar
because it maintains more than just msghdr struct. More stats aggregation,
and Phase3 changes.",6354,data/crawl/squid/hunk_2919.cpp,,,data/crawl/squid/old_hunk_2919.cpp,data/crawl/squid/new_hunk_2919.cpp,37,36,"storeAppendPrintf(sentry, ""\tLargest file desc currently in use:   %4d\n"",
                      Biggest_FD);","storeAppendPrintf(sentry, ""\tLargest file desc currently in use:   %4.0f\n"",
                      stats.biggest_fd);","[""removeVariable"", ""updateContent"", ""addVariable""]","[[""%4d\\n"", ""Biggest_FD""], [""%4"", ""0f\\n"", ""stats"", ""biggest_fd""]]",[4215632211798628011],7500,0.0,5
https://github.com/squid-cache/squid/commit/eb3dea38c796fbf091b023e98e832b053c750453,15 Apr 2011,"negotiate_wrapper_auth: version 1.0.1

A helper to perform Negotaite authentication in both its Negotiate/NTLM
and Negotiate/Kerberos forms.
Makes use of additional Squid helpers after unwrapping the header token.",516,data/crawl/squid/hunk_2654.cpp,,,data/crawl/squid/old_hunk_2654.cpp,data/crawl/squid/new_hunk_2654.cpp,-1,98,,"fprintf(stderr, ""-d full debug\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""d"", ""full"", ""debug\\n""]]",[-8556171269710379750],7499,577152.0,5
https://github.com/squid-cache/squid/commit/eb3dea38c796fbf091b023e98e832b053c750453,15 Apr 2011,"negotiate_wrapper_auth: version 1.0.1

A helper to perform Negotaite authentication in both its Negotiate/NTLM
and Negotiate/Kerberos forms.
Makes use of additional Squid helpers after unwrapping the header token.",516,data/crawl/squid/hunk_2654.cpp,,,data/crawl/squid/old_hunk_2654.cpp,data/crawl/squid/new_hunk_2654.cpp,-1,97,,"fprintf(stderr, ""-h help\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""h"", ""help\\n""]]",[-14753409232526306072],7498,577152.0,5
https://github.com/squid-cache/squid/commit/e24f13cdd75215b6b297ef81b44b93daf94b5f20,30 Jun 2011,"Remove the HttpStateData::orig_request member

When FwdServer::_peer is set, HttpStateData constructor creates a new special
HttpRequest, overwriting the request pointer set in the parent (ServerStateData) 
constructor to fwd->request.

This special HttpRequest sets the proper urlpath (which maybe different from
the original HttpRequest), the host (HttpRequest::SetHost/GetHost) to be the
peer hostname and inherits flags, protocol, method. Also sets the
HttpRequest::flags.proxying.

Probably this is originaly done to handle only the differences in urlpath and
the host. But this is has  as result to have two HttpRequests object in
HttpStateData, but their difference is not clear.

This patch removes the HttpStateData::orig_request member and uses only the 
HttpStateData::request member

Bugs fixed with this patch:

- Debugs() and error pages sometimes display the cache_peer hostname as the URL   requested domain name when going to an origin. Regardless of what the virtual
  host name actually is.

- The request_header_access configuration parameter does not work when
  sending requests to parent proxies.

- Squid may cache replies to requests with no-store in headers when uses a
  parent cache.

- parent caches which have been configured as ""sibling"" for specific domains
  using the neighbor_type_domain parameter are not counted.

- Probably many other


This is a Measurement Factory project",271,data/crawl/squid/hunk_2525.cpp,,,data/crawl/squid/old_hunk_2525.cpp,data/crawl/squid/new_hunk_2525.cpp,2,2,"httpHeaderPutStrf(hdr_out, header, ""Basic %s"",
                      old_base64_encode(orig_request->peer_login));","httpHeaderPutStrf(hdr_out, header, ""Basic %s"",
                      old_base64_encode(request->peer_login));","[""updateVariable""]","[[""orig_request""], [""request""]]",[-5422013243546040469],7497,0.0,5
https://github.com/squid-cache/squid/commit/7ff7a211c25688d2d6742acc7bc271f700c9dbe9,08 Aug 2011,Migrate cf_gen.cc from C-style stdio to C++ iostreams.,300,data/crawl/squid/hunk_2497.cpp,,,data/crawl/squid/old_hunk_2497.cpp,data/crawl/squid/new_hunk_2497.cpp,8,-1,"fprintf(fp, ""\n"");",,"[""removeLog""]","[[""fprintf"", ""fp"", ""\\n""], []]",[5179306325123647028],7496,5732064.0,5
https://github.com/squid-cache/squid/commit/7ff7a211c25688d2d6742acc7bc271f700c9dbe9,08 Aug 2011,Migrate cf_gen.cc from C-style stdio to C++ iostreams.,300,data/crawl/squid/hunk_2492.cpp,,,data/crawl/squid/old_hunk_2492.cpp,data/crawl/squid/new_hunk_2492.cpp,25,-1,"fprintf(fp, ""#endif\n"");",,"[""removeLog""]","[[""fprintf"", ""fp"", ""endif\\n""], []]",[-2535454387840088139],7495,0.0,5
https://github.com/squid-cache/squid/commit/7ff7a211c25688d2d6742acc7bc271f700c9dbe9,08 Aug 2011,Migrate cf_gen.cc from C-style stdio to C++ iostreams.,300,data/crawl/squid/hunk_2486.cpp,,,data/crawl/squid/old_hunk_2486.cpp,data/crawl/squid/new_hunk_2486.cpp,3,-1,"printf(""Error on line %d\n"", linenum);",,"[""removeLog""]","[[""printf"", ""Error"", ""on"", ""line"", ""%d\\n"", ""linenum""], []]",[-23449878132933055095],7494,0.0,5
https://github.com/squid-cache/squid/commit/2be46d6709526a1c4454c0f5fa8716efe354b617,21 Sep 2011,"ext_session_acl: version 1.1

 * Add fixed period session support with -T

 * Fix synchronization between multiple helpers accessing the database

 * Fix crash when configured with non-concurrent settings.",80,data/crawl/squid/hunk_2435.cpp,,,data/crawl/squid/old_hunk_2435.cpp,data/crawl/squid/new_hunk_2435.cpp,3,3,"printf(""%s OK message=\""Bye\""\n"", user_key);","printf(""%s OK message=\""Bye\""\n"", channel_id);","[""updateVariable""]","[[""user_key""], [""channel_id""]]",[35040588119375336],7493,0.0,5
https://github.com/squid-cache/squid/commit/081edc2de252e852d0a8e02891fb36d7919a92ef,07 Jan 2012,"Cleanup: update most of the existing stub files to use the STUB.h framework

There are still several sections to be done. Including adding library API
stubs. However these are the ones which can be done immediately without 
breaking or re-writing existing unit tests.",2058,data/crawl/squid/hunk_2357.cpp,,,data/crawl/squid/old_hunk_2357.cpp,data/crawl/squid/new_hunk_2357.cpp,59,-1,"fprintf(stderr, ""Not implemented"");",,"[""removeLog""]","[[""fprintf"", ""stderr"", ""Not"", ""implemented""], []]",[17868059573967399683],7492,0.0,5
https://github.com/squid-cache/squid/commit/4629f000085591c9200fb70a3e46ed2b212e6fb3,05 Oct 2012,Move fatal family of functions to own implementation and stub files.,344,data/crawl/squid/hunk_1969.cpp,,,data/crawl/squid/old_hunk_1969.cpp,data/crawl/squid/new_hunk_1969.cpp,-1,53,,"fprintf(stderr, ""FATAL: %s\n"", message);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""FATAL"", ""%s\\n"", ""message""]]",[-19574497941444277743],7491,5715648.0,5
https://github.com/squid-cache/squid/commit/61017a886b4884845571007b5745664e3d346ebc,28 May 2013,"Improve ACL handling. Support all-of and any-of ACL types.

This commit encapsulated many significant ACL changes, including:

* Expressiveness: Two new boolean ACLs (all-of and any-of) that allow
admins to group ACLs as needed, to express complex conditions more
naturally, with fewer squid.conf lines. Conditions such as ""(a or b) and
(c or d)"" are easily expressed now. Explicit groups of ACLs of different
types can now be configured, named, and used in any ACL expression.

* Correctness and performance: When a slow ACL (that has suspended
checks to wait for an async lookup) is ready to resume checking, Squid
resumes checking from that ACL, instead of rechecking all ACLs for the
same action (or the same squid.conf directive) again.

* Internals: Store ACL-related configurations as an expression tree,
streamlining the code and clearing the way for future math-style/natural
ACL conditions support. The usual boolean operators (and, or, and not)
form intermediate nodes while good old configurable ACLs become tree
leaves. The new all-of and any-of ACLs use the boolean operators (and
also become intermediate nodes, of course).",1943,data/crawl/squid/hunk_1747.cpp,,,data/crawl/squid/old_hunk_1747.cpp,data/crawl/squid/new_hunk_1747.cpp,14,-1,"storeAppendPrintf(entry, ""%s "", name);",,"[""removeLog""]","[[""storeAppendPrintf"", ""entry"", ""%s"", ""name""], []]",[248933907621281061],7490,3757536.0,5
https://github.com/squid-cache/squid/commit/3cc0f4e721ce7550b008a4a9c410883eaa600c2a,10 Aug 2014,"Polishing in response to Amos' squid-dev review dated 2014/08/08.

The PASS value masking code in HttpHeader::packInto() is currently unused
because Squid does not (and cannot) use errorpages for native FTP errors.

It is [still] possible to configure ftp_port with transport=HTTP but it is
not clear what the exact effects of that configuration are, if any.

The ftp_port ftp-track-dirs option no longer accepts on|off values. Off is
still the default. Turn on using a valueless ""ftp-track-dirs"" option.

Other minor polishing touches.",249,data/crawl/squid/hunk_1260.cpp,,,data/crawl/squid/old_hunk_1260.cpp,data/crawl/squid/new_hunk_1260.cpp,18,19,"fatalf(""%s directive does not support protocol=%s\n"", cfg_directive, value);","fatalf(""%s directive does not support protocol="" SQUIDSBUFPH ""\n"", cfg_directive, SQUIDSBUFPRINT(value));","[""addLog"", ""updateLog"", ""addContent"", ""removeContent"", ""addVariable""]","[[""%s\\n""], [""SQUIDSBUFPH"", ""\\n"", ""SQUIDSBUFPRINT""]]",[-1373802741959305100],7489,21024.0,5
https://github.com/squid-cache/squid/commit/3ac5bd881bf4eda91a239a9db7734be91d360822,23 Aug 2014,Sync with trunk rev.13542,101061,data/crawl/squid/hunk_1218.cpp,,,data/crawl/squid/old_hunk_1218.cpp,data/crawl/squid/new_hunk_1218.cpp,14,-1,"fprintf(tracefp, ""r:%p:%p:%d\n"", p, s, sz);",,"[""removeLog""]","[[""fprintf"", ""tracefp"", ""r"", ""%p"", ""%p"", ""%d\\n"", ""p"", ""s"", ""sz""], []]",[4161047314464603172],7488,1478880.0,5
https://github.com/squid-cache/squid/commit/1071ffed56172406d771265af76d8273ffcdb89e,26 May 2015,"Replace Packer object API with Packable API

Majority of thost patch is symbol renaming to unify the
class method names to the Packable API names.

There is effectively no logical change in this patch
despite appearances because it replaces the Packer object
which provides methods which are just wrappers pointing
to static functions which are in turn wrappers pointing
to storage buffer object methods. With direct calls to
those storage object methods (renamed).

We can now interchangebly use MemBuf or StoreEntry objects
with the packInto(Packable *) functions. Or any other
object which inherits and implements the Packable API.

We also gain 0.1% in performance (+2 RPS) by avoiding the
layers of wrapper funcions and Packer object allocate / 
deallocate cycles.",1141,data/crawl/squid/hunk_778.cpp,,,data/crawl/squid/old_hunk_778.cpp,data/crawl/squid/new_hunk_778.cpp,3,3,"buf.Printf(""Stopped, reason:"");","buf.append(""Stopped, reason:"", 16);","[""updateLog"", ""addContent""]","[[""Printf""], [""append"", ""16""]]",[-16146027967618661650],7487,77760.0,5
https://github.com/squid-cache/squid/commit/bf3e8d5a0de0f6f59996d1a8fb88402ba2273ede,05 Jun 2015,"SourceLayout: convert helper stats display to Packable API

Requires unifying the classes Helper::Request queues which incidentally
also brings stateful helpers closer to concurrency support",192,data/crawl/squid/hunk_690.cpp,,,data/crawl/squid/old_hunk_690.cpp,data/crawl/squid/new_hunk_690.cpp,16,11,"storeAppendPrintf(sentry, ""requests sent: %d\n"",
                      hlp->stats.requests);","p->appendf(""  requests sent: %d\n"", stats.requests);","[""addLog"", ""removeVariable"", ""updateContent"", ""removeLog""]","[[""storeAppendPrintf"", ""sentry"", ""hlp""], [""p"", ""appendf""]]",[7194585758806152193],7486,0.0,5
https://github.com/squid-cache/squid/commit/789217a2d102b1c99734afd7d48e4d4210ec009d,04 Aug 2015,"Renamed http_hdr_type to Http::HdrType, fixed some HdrType-int implicit conversions",1702,data/crawl/squid/hunk_602.cpp,,,data/crawl/squid/old_hunk_602.cpp,data/crawl/squid/new_hunk_602.cpp,10,10,"httpHeaderPutStrf(hdr, HDR_CONNECTION, ""Proxy-support"");","httpHeaderPutStrf(hdr, Http::HdrType::CONNECTION, ""Proxy-support"");","[""removeVariable"", ""addVariable""]","[[""HDR_CONNECTION""], [""Http"", ""HdrType"", ""CONNECTION""]]",[13771875659940423964],7485,0.0,5
https://github.com/squid-cache/squid/commit/af845cee67e3dc2a58f93a9ac7d9ce091ea4fa00,11 Sep 2015,"Bug 4292: negotiate_wrapper: Unreleased Resources

FILE* handles need to be closed on exit. Shuffle the processing loop logics
to a static function to avoid code duplication from all the requires close
points.

Also, use the available global flag debug_enabled instead of local variable
to avoid having to pass it down explicitly.",337,data/crawl/squid/hunk_574.cpp,,,data/crawl/squid/old_hunk_574.cpp,data/crawl/squid/new_hunk_574.cpp,-1,71,,"fprintf(stdout, ""BH quit command\n"");","[""addLog""]","[[], [""fprintf"", ""stdout"", ""BH"", ""quit"", ""command\\n""]]",[-2382764984285885200],7484,1111392.0,5
https://github.com/squid-cache/squid/commit/d3b1bee6fff7792f482ff280e8400c6a3e83560f,14 Dec 2015,merge from trunk r14444,9318,data/crawl/squid/hunk_435.cpp,,,data/crawl/squid/old_hunk_435.cpp,data/crawl/squid/new_hunk_435.cpp,117,-1,"fprintf(stderr, PROGRAM_NAME "": WARNING: LDAP search error '%s'\n"", ldap_err2string(rc));",,"[""removeLog""]","[[""fprintf"", ""stderr"", ""PROGRAM_NAME"", ""WARNING"", ""LDAP"", ""search"", ""error"", ""%s"", ""\\n"", ""ldap_err2string"", ""rc""], []]",[10530649752204183237],7483,4050432.0,5
https://github.com/squid-cache/squid/commit/6f9f8f9d10ce1fedbd52f4362c6982d5308a9c4d,01 Aug 2016,"Fetch missing certificates

Many web servers do not have complete certificate chains. Many browsers use
certificate extensions of the server certificate and download the missing
intermediate certificates automatically from the Internet.
This patch add this feature to Squid.

The information for missing issuer certificates provided by the Authority
Information Access X509 extension. This describes the format and the location
of additional information provided by the issuer of the certificate.

This patch:
  - Implements a class Downloader as an independet AsyncJob class. This new
    class can be used by internal squid subsystems to download objects from
    the network.
  - Modify Ssl::PeerConnector class to use new Downloader class to
    retrieve missing certificates from the net. The URIs of missing
    certificates from the Authority Information Access X509 extension.
  - Implements a new basic certificates parser based on openSSL for the
    TLS handshake messages parser.
  - Modify the Ssl::ServerBio class to:
     * Buffer the Server Hello message and not pass it to the openSSL library
       until downloading missing certificates, if any, is finished.
     * Extract server certificates from server hello message.
       This is required to check if there are missing certificates, and if yes
       give the chance to squid to download missing certificates and complete
       certificate chains before pass them for processing to openSSL

TODO:
  - Add support for certs-only CMS message.
    From  RFC 4325:
    ""Where the information is available via HTTP or FTP, accessLocation
    MUST be a uniformResourceIdentifier and the URI MUST point to either
    a single DER encoded certificate as specified in [RFC2585] or a
    collection of certificates in a BER or DER encoded ""certs-only"" CMS
    message as specified in [RFC2797]. ""
    ...
    ""Conforming applications that support HTTP or FTP for accessing
    certificates MUST be able to accept individual DER encoded
    certificates and SHOULD be able to accept ""certs-only"" CMS messages.""

This is a Measurement Factory project",808,data/crawl/squid/hunk_147.cpp,,,data/crawl/squid/old_hunk_147.cpp,data/crawl/squid/new_hunk_147.cpp,-1,227,,"fatal(""unreachable code"");","[""addLog""]","[[], [""fatal"", ""unreachable"", ""code""]]",[-1700840284824413321],7482,345888.0,5
https://github.com/squid-cache/squid/commit/ea5746353c1e72f8f59c0d08906a3d90400b0dac,18 Nov 2016,"TLS: Add ErrorString() function to libsecurity API

To convert library error codes to strings in a library agnostic way.",108,data/crawl/squid/hunk_132.cpp,,,data/crawl/squid/old_hunk_132.cpp,data/crawl/squid/new_hunk_132.cpp,3,3,"fatalf(""Failed to initialise SSL engine: %s\n"", ERR_error_string(ssl_error, NULL));","fatalf(""Failed to initialise SSL engine: %s\n"", Security::ErrorString(ssl_error));","[""removeVariable"", ""addVariable""]","[[""ERR_error_string"", ""NULL""], [""Security"", ""ErrorString""]]",[7639119569518464859],7481,0.0,5
https://github.com/squid-cache/squid/commit/c943f3313a892d71be08ad823a58b1969e56a817,30 Mar 1996,"assign store.c to debugging section 20
fixed storeRebuildFromDisk bug introduced when switched from fdopen(, ""a"")
to fdopen(, ""w"").  Now storeInit() makes a little more sense.",647,data/crawl/squid/hunk_7935.cpp,,,data/crawl/squid/old_hunk_7935.cpp,data/crawl/squid/new_hunk_7935.cpp,51,-1,fatal(tmpbuf);,,"[""removeLog""]","[[""fatal"", ""tmpbuf""], []]",[2982793776932876073],7480,0.0,4
https://github.com/squid-cache/squid/commit/30a4f2a885dbb469498c0e805e1e8d42244788be,09 Jul 1996,cleanup after big merge,12717,data/crawl/squid/hunk_7710.cpp,,,data/crawl/squid/old_hunk_7710.cpp,data/crawl/squid/new_hunk_7710.cpp,-1,20,,"fprintf (fopen(""conftestval"", ""w""), ""%d\n"", val);","[""addLog""]","[[], [""fprintf"", ""fopen"", ""conftestval"", ""w"", ""%d\\n"", ""val""]]",[3619549246778451972],7479,0.0,4
https://github.com/squid-cache/squid/commit/81b795fa81a7ac196b532a343f50be275f1cd429,10 Jul 1996,Added filedesciptor and reply_header entries,22,data/crawl/squid/hunk_7706.cpp,,,data/crawl/squid/old_hunk_7706.cpp,data/crawl/squid/new_hunk_7706.cpp,-1,7,,"printf(""<OPTION VALUE=\""server_list\"">Cache Server List\n"");","[""addLog""]","[[], [""printf"", ""OPTION"", ""VALUE"", ""\\"", ""server_list\\"", ""Cache"", ""Server"", ""List\\n""]]",[-10051900618652627175],7478,720.0,4
https://github.com/squid-cache/squid/commit/56fa4cadbbb17eb8986b36f081f03e6ae766ab44,12 Sep 1996,"- Cleaned up gopher.c; prototypes, make functions static, etc.
- Added READ_DEFERRED entry flag.  Only extend lifetime when
  first entering deferred mode.",321,data/crawl/squid/hunk_7591.cpp,,,data/crawl/squid/old_hunk_7591.cpp,data/crawl/squid/new_hunk_7591.cpp,-1,9,,"storeAppendPrintf(sentry, ""{Read Histogram:}\n"");","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""Read"", ""Histogram"", ""\\n""]]",[-4886403402328369767],7477,46800.0,4
https://github.com/squid-cache/squid/commit/e97f40f4c3e673d5cbc1cd382a4b0c3044810c45,15 Oct 1996,rearrange USE_ICMP defines,451,data/crawl/squid/hunk_7474.cpp,,,data/crawl/squid/old_hunk_7474.cpp,data/crawl/squid/new_hunk_7474.cpp,-1,45,,fatal_dump(xstrerror());,"[""addLog""]","[[], [""fatal_dump"", ""xstrerror""]]",[-6060328181111983635],7476,17280.0,4
https://github.com/squid-cache/squid/commit/582b645678b879c12ec52bebe25ef807dc64de06,30 Apr 1997,massive casting cleanups!,651,data/crawl/squid/hunk_7298.cpp,,,data/crawl/squid/old_hunk_7298.cpp,data/crawl/squid/new_hunk_7298.cpp,6,7,"storeAppendPrintf(data->sentry, ""{%s}\n"", buf);","storeAppendPrintf(ctrl->sentry, ""{%s}\n"", buf);","[""updateVariable""]","[[""data""], [""ctrl""]]",[14292070942582277035],7475,0.0,4
https://github.com/squid-cache/squid/commit/9e4ad609cdc6849a20b298e7c2437007109b80fc,05 May 1997,"- DO NOT set the filemap bits for unvalidated entries.  Doing so
  causes lots of race-condition problems, especially when reading
  DIRTY logs.
- Install icpDetectClientClose handler earlier.  Move from access check
  to just after reading the request.
- Log open FD's upon exit.
- Added dnsShutdownRead handler to detect dnsserver shutdowns and
  free up state.
- Added doubleAverage and integerAverage for moving average
  calculations.
- misc prototype cleanup
- misc debug_trap's and fatal_dump's
- Removed some thread splitting for fooStartComplete() because
  the various protcol start routines should never need a swapin
  callback.  The object should already be locked and swapped in.
- queue_length counter for IP cache.
- Make it okay to storeUnlock a pending object, so long as its
  not been DISPATCHED yet.
- fixed hybrid store rebuild code.
- fixed file_open() flags to TRUNC new swaplog's
- Claned up wierd (FILE *) stuff in tools.c, always write to
  debug_log().
- rewrote writePidFile() to use file_open().",505,data/crawl/squid/hunk_7266.cpp,,,data/crawl/squid/old_hunk_7266.cpp,data/crawl/squid/new_hunk_7266.cpp,3,3,"fprintf(lf, ""CPU Usage: user %d sys %d\n"",
	(int) rusage.ru_utime.tv_sec, (int) rusage.ru_stime.tv_sec);","fprintf(debug_log, ""CPU Usage: user %d sys %d\n"",
	(int) rusage.ru_utime.tv_sec, (int) rusage.ru_stime.tv_sec);","[""updateVariable""]","[[""lf""], [""debug_log""]]",[-1068760073879422601],7474,0.0,4
https://github.com/squid-cache/squid/commit/f53b06f967ce5bdf5b076bba55d41f8d45a3077d,25 Aug 1997,"Configuration cleanup.
	- set up 'DEFAULT_IF_NONE' option for things like http_port
	  and cache_dir where we want to set a default only if there
	  is not one or more given in the config file.
	- Implemented the configuration dump via cachemanager.  All the
	  easy config types have dump functions; the remainder are
	  unimplemented.",220,data/crawl/squid/hunk_7091.cpp,,,data/crawl/squid/old_hunk_7091.cpp,data/crawl/squid/new_hunk_7091.cpp,-1,25,,"fprintf(fp, ""}\n\n"");","[""addLog""]","[[], [""fprintf"", ""fp"", ""\\n\\n""]]",[-10352705936551168688],7473,24480.0,4
https://github.com/squid-cache/squid/commit/f53b06f967ce5bdf5b076bba55d41f8d45a3077d,25 Aug 1997,"Configuration cleanup.
	- set up 'DEFAULT_IF_NONE' option for things like http_port
	  and cache_dir where we want to set a default only if there
	  is not one or more given in the config file.
	- Implemented the configuration dump via cachemanager.  All the
	  easy config types have dump functions; the remainder are
	  unimplemented.",220,data/crawl/squid/hunk_7079.cpp,,,data/crawl/squid/old_hunk_7079.cpp,data/crawl/squid/new_hunk_7079.cpp,6,6,"printf(""%d "", (int) u->i);","storeAppendPrintf(entry, ""%s %d\n"", name, (int) u->i);","[""updateLog"", ""updateContent"", ""addVariable""]","[[""printf"", ""%d""], [""storeAppendPrintf"", ""entry"", ""%s"", ""%d\\n"", ""name""]]",[-1346131251586176808],7472,0.0,4
https://github.com/squid-cache/squid/commit/f0b1933488ce1ce1e84f6497331a6beaf8543cb5,13 Nov 1997,"Ron Gomes fixes.
	- Remove USE_PROXY_AUTH and LOG_FULL_HEADERS from Makefile.in
	- Fixed log_full_hdrs bug
We can't use pathname_stat() for both default_all() and parsing the
config file.  We must check the pathnames only after both the
defaults and the config file have been parsed.  DW also made misc
other fixes to cache_cf.c and friends.",133,data/crawl/squid/hunk_6986.cpp,,,data/crawl/squid/old_hunk_6986.cpp,data/crawl/squid/new_hunk_6986.cpp,23,26,"printf(""WARNING: dns_children was set to a bad value: %d\n"",
	    Config.dnsChildren);","debug(3, 0) (""WARNING: dns_children was set to a bad value: %d\n"",
	    Config.dnsChildren);","[""updateLog"", ""moveLog"", ""addContent""]","[[""printf""], [""debug"", ""3"", ""0""]]",[474361003934684740],7471,0.0,4
https://github.com/squid-cache/squid/commit/f0b1933488ce1ce1e84f6497331a6beaf8543cb5,13 Nov 1997,"Ron Gomes fixes.
	- Remove USE_PROXY_AUTH and LOG_FULL_HEADERS from Makefile.in
	- Fixed log_full_hdrs bug
We can't use pathname_stat() for both default_all() and parsing the
config file.  We must check the pathnames only after both the
defaults and the config file have been parsed.  DW also made misc
other fixes to cache_cf.c and friends.",133,data/crawl/squid/hunk_6986.cpp,,,data/crawl/squid/old_hunk_6986.cpp,data/crawl/squid/new_hunk_6986.cpp,10,-1,"printf(""         Change your configuration file.\n"");",,"[""removeLog""]","[[""printf"", ""Change"", ""your"", ""configuration"", ""file"", ""\\n""], []]",[-10653224935150031867],7470,355320.0,4
https://github.com/squid-cache/squid/commit/ce66013b40dad272f568df241b6f1fb238cec97f,13 Nov 1997,remove fatal_dump calls,59,data/crawl/squid/hunk_6971.cpp,,,data/crawl/squid/old_hunk_6971.cpp,data/crawl/squid/new_hunk_6971.cpp,3,3,"fatal_dump(""file_map_allocate: Exceeded filemap limit"");","fatal(""file_map_allocate: Exceeded filemap limit"");","[""updateLog""]","[[""fatal_dump""], [""fatal""]]",[3765830668276604274],7469,15120.0,4
https://github.com/squid-cache/squid/commit/627f6d02e9baad40c38bd35ef893fc6bc9a22ca1,21 Nov 1997,"SNMP, cmu derived, heavily modified",5272,data/crawl/squid/hunk_6957.cpp,,,data/crawl/squid/old_hunk_6957.cpp,data/crawl/squid/new_hunk_6957.cpp,-1,295,,"printf(""  "");","[""addLog""]","[[], [""printf""]]",[7237409554864562455],7468,105840.0,4
https://github.com/squid-cache/squid/commit/15576b6a58a24ed2705d6228d0fde8cfcef26cae,07 Feb 1998,remove brackets from cachemgr output,390,data/crawl/squid/hunk_6829.cpp,,,data/crawl/squid/old_hunk_6829.cpp,data/crawl/squid/new_hunk_6829.cpp,3,-1,"storeAppendPrintf(sentry, open_bracket);",,"[""removeLog""]","[[""storeAppendPrintf"", ""sentry"", ""open_bracket""], []]",[-14991446791886401303],7467,153000.0,4
https://github.com/squid-cache/squid/commit/15576b6a58a24ed2705d6228d0fde8cfcef26cae,07 Feb 1998,remove brackets from cachemgr output,390,data/crawl/squid/hunk_6826.cpp,,,data/crawl/squid/old_hunk_6826.cpp,data/crawl/squid/new_hunk_6826.cpp,51,50,"storeAppendPrintf(sentry, ""{Keep-Alive Ratio: %d%%}\n"",
	    percent(e->stats.n_keepalives_recv, e->stats.n_keepalives_sent));","storeAppendPrintf(sentry, ""Keep-Alive Ratio: %d%%\n"",
	    percent(e->stats.n_keepalives_recv, e->stats.n_keepalives_sent));","[""updateContent""]","[[""%d%%"", ""\\n""], [""%d%%\\n""]]",[-3075893759996400776],7466,0.0,4
https://github.com/squid-cache/squid/commit/15576b6a58a24ed2705d6228d0fde8cfcef26cae,07 Feb 1998,remove brackets from cachemgr output,390,data/crawl/squid/hunk_6825.cpp,,,data/crawl/squid/old_hunk_6825.cpp,data/crawl/squid/new_hunk_6825.cpp,11,10,"storeAppendPrintf(sentry, ""{%5d-%5d: %9d %2d%%}\n"",
	    i ? (1 << (i - 1)) + 1 : 1,
	    1 << i,
	    IOStats.Http.read_hist[i],
	    percent(IOStats.Http.read_hist[i], IOStats.Http.reads));","storeAppendPrintf(sentry, ""%5d-%5d: %9d %2d%%\n"",
	    i ? (1 << (i - 1)) + 1 : 1,
	    1 << i,
	    IOStats.Http.read_hist[i],
	    percent(IOStats.Http.read_hist[i], IOStats.Http.reads));","[""updateContent""]","[[""%2d%%"", ""\\n""], [""%2d%%\\n""]]",[-318948967552326248],7465,0.0,4
https://github.com/squid-cache/squid/commit/15576b6a58a24ed2705d6228d0fde8cfcef26cae,07 Feb 1998,remove brackets from cachemgr output,390,data/crawl/squid/hunk_6816.cpp,,,data/crawl/squid/old_hunk_6816.cpp,data/crawl/squid/new_hunk_6816.cpp,18,18,"storeAppendPrintf(sentry, ""{dnsserver avg service time: %d msec}\n"",
	FqdncacheStats.avg_svc_time);","storeAppendPrintf(sentry, ""dnsserver avg service time: %d msec\n"",
	FqdncacheStats.avg_svc_time);","[""updateContent""]","[[""msec"", ""\\n""], [""msec\\n""]]",[10844713033967271200],7464,0.0,4
https://github.com/squid-cache/squid/commit/ed7f56150f25fdd768b7c99d0ea052304fe2e98b,20 Feb 1998,"make all the OBJH functions static, etc",302,data/crawl/squid/hunk_6780.cpp,,,data/crawl/squid/old_hunk_6780.cpp,data/crawl/squid/new_hunk_6780.cpp,-1,65,,"storeAppendPrintf(sentry, ""%s "", d->domain);","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""%s"", ""d"", ""domain""]]",[14478533116132914383],7463,483840.0,4
https://github.com/squid-cache/squid/commit/85269fdf3c2a36641dfae2cf71f495a38c95cc28,22 Feb 1998,"Snmplib for squid, based on v1.8, heavily changed",8289,data/crawl/squid/hunk_6754.cpp,,,data/crawl/squid/old_hunk_6754.cpp,data/crawl/squid/new_hunk_6754.cpp,75,169,"fprintf(stderr, ""Couldn't abort session: %s. Exiting\n"", api_errstring(snmp_errno));","snmplib_debug(3, ""Couldn't abort session: %s. Exiting\n"", 
	      api_errstring(snmp_errno));","[""updateLog"", ""removeVariable"", ""addContent""]","[[""fprintf"", ""stderr""], [""snmplib_debug"", ""3""]]",[17748533876247899808],7462,0.0,4
https://github.com/squid-cache/squid/commit/85269fdf3c2a36641dfae2cf71f495a38c95cc28,22 Feb 1998,"Snmplib for squid, based on v1.8, heavily changed",8289,data/crawl/squid/hunk_6752.cpp,,,data/crawl/squid/old_hunk_6752.cpp,data/crawl/squid/new_hunk_6752.cpp,515,-1,"print_error(""No end to oid"", (char *) NULL, type);",,"[""removeLog""]","[[""print_error"", ""No"", ""end"", ""to"", ""oid"", ""char"", ""*"", ""NULL"", ""type""], []]",[-9551342531087663082],7461,0.0,4
https://github.com/squid-cache/squid/commit/85269fdf3c2a36641dfae2cf71f495a38c95cc28,22 Feb 1998,"Snmplib for squid, based on v1.8, heavily changed",8289,data/crawl/squid/hunk_6752.cpp,,,data/crawl/squid/old_hunk_6752.cpp,data/crawl/squid/new_hunk_6752.cpp,513,-1,"print_error(""Warning: This entry is pretty silly"", np->label, type);",,"[""removeLog""]","[[""print_error"", ""Warning"", ""This"", ""entry"", ""is"", ""pretty"", ""silly"", ""np"", ""label"", ""type""], []]",[3855785183751805220],7460,0.0,4
https://github.com/squid-cache/squid/commit/85269fdf3c2a36641dfae2cf71f495a38c95cc28,22 Feb 1998,"Snmplib for squid, based on v1.8, heavily changed",8289,data/crawl/squid/hunk_6748.cpp,,,data/crawl/squid/old_hunk_6748.cpp,data/crawl/squid/new_hunk_6748.cpp,174,120,"fprintf(stderr, ""%s(EOF): On or around line %d\n"", string, Line);","snmplib_debug(0, ""%s(EOF): On or around line %d\n"", string, Line);","[""updateLog"", ""removeVariable"", ""addContent""]","[[""fprintf"", ""stderr""], [""snmplib_debug"", ""0""]]",[17748533875863898655],7459,0.0,4
https://github.com/squid-cache/squid/commit/afb34538f3fbbeaa63e98ee4923ee57b9bad2678,27 Feb 1998,%p for warnings,10,data/crawl/squid/hunk_6672.cpp,,,data/crawl/squid/old_hunk_6672.cpp,data/crawl/squid/new_hunk_6672.cpp,3,3,"fprintf(tracefp, ""m:%d:%x\n"",sz,p);","fprintf(tracefp, ""m:%d:%p\n"",sz,p);","[""updateContent""]","[[""%x\\n""], [""%p\\n""]]",[7999999999816],7458,0.0,4
https://github.com/squid-cache/squid/commit/5f6ac48b7b0af57d697d8c018397911953ca863f,29 Mar 1998,printf errors/warnings,137,data/crawl/squid/hunk_6572.cpp,,,data/crawl/squid/old_hunk_6572.cpp,data/crawl/squid/new_hunk_6572.cpp,2,2,"storeAppendPrintf(sentry, ""\tswapout: %d bytes done, %d queued, FD %d\n"",
	    mem->swapout.done_offset,
	    mem->swapout.queue_offset,
	    mem->swapout.fd);","storeAppendPrintf(sentry, ""\tswapout: %d bytes done, %d queued, FD %d\n"",
	    (int) mem->swapout.done_offset,
	    (int) mem->swapout.queue_offset,
	    mem->swapout.fd);","[""addVariable""]","[[], [""int"", ""int""]]",[-15110728741709529328],7457,0.0,4
https://github.com/squid-cache/squid/commit/6d80b36f5fa3546be4e989741a1165df97e33c14,01 Apr 1998,"- Added cacheDigestClone() method.
- major test_cache_digest updates",608,data/crawl/squid/hunk_6537.cpp,,,data/crawl/squid/old_hunk_6537.cpp,data/crawl/squid/new_hunk_6537.cpp,-1,16,,"fprintf(stderr, ""cannot open %s: %s\n"", fname, strerror(errno));","[""addLog""]","[[], [""fprintf"", ""stderr"", ""cannot"", ""open"", ""%s"", ""%s\\n"", ""fname"", ""strerror"", ""errno""]]",[7895422984797803733],7456,1440.0,4
https://github.com/squid-cache/squid/commit/bd34f258a4b0bc46f2f65ea4b1331881693b9869,03 Apr 1998,"Changed squid/dnsserver communication to single-line replies.  Removed
all the unused cruft.",455,data/crawl/squid/hunk_6521.cpp,,,data/crawl/squid/old_hunk_6521.cpp,data/crawl/squid/new_hunk_6521.cpp,30,-1,"printf(""$end\n"");",,"[""removeLog""]","[[""printf"", ""end\\n""], []]",[-5968934412344492967],7455,0.0,4
https://github.com/squid-cache/squid/commit/071a3ae79623f644f3544044423946dd3a35710b,10 Apr 1998,Cleaned up ICP logging/counting and ICP/CD stats output,269,data/crawl/squid/hunk_6467.cpp,,,data/crawl/squid/old_hunk_6467.cpp,data/crawl/squid/new_hunk_6467.cpp,-1,14,,"storeAppendPrintf(sentry, ""client_http.hit_svc_time histogram:\n"");","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""client_http"", ""hit_svc_time"", ""histogram"", ""\\n""]]",[8195476901053635300],7454,31320.0,4
https://github.com/squid-cache/squid/commit/071a3ae79623f644f3544044423946dd3a35710b,10 Apr 1998,Cleaned up ICP logging/counting and ICP/CD stats output,269,data/crawl/squid/hunk_6467.cpp,,,data/crawl/squid/old_hunk_6467.cpp,data/crawl/squid/new_hunk_6467.cpp,-1,12,,"storeAppendPrintf(sentry, ""client_http.nm_svc_time histogram:\n"");","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""client_http"", ""nm_svc_time"", ""histogram"", ""\\n""]]",[3132268931358861387],7453,31320.0,4
https://github.com/squid-cache/squid/commit/071a3ae79623f644f3544044423946dd3a35710b,10 Apr 1998,Cleaned up ICP logging/counting and ICP/CD stats output,269,data/crawl/squid/hunk_6467.cpp,,,data/crawl/squid/old_hunk_6467.cpp,data/crawl/squid/new_hunk_6467.cpp,-1,10,,"storeAppendPrintf(sentry, ""client_http.miss_svc_time histogram:\n"");","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""client_http"", ""miss_svc_time"", ""histogram"", ""\\n""]]",[12266767035431664052],7452,31320.0,4
https://github.com/squid-cache/squid/commit/f52a7d75fa0fa951a3b0a1481d531c8b34367976,18 Aug 1998,moved from ../src,448,data/crawl/squid/hunk_6306.cpp,,,data/crawl/squid/old_hunk_6306.cpp,data/crawl/squid/new_hunk_6306.cpp,-1,374,,"printf(""done walking hash table...\n"");","[""addLog""]","[[], [""printf"", ""done"", ""walking"", ""hash"", ""table"", ""\\n""]]",[4589393764457364610],7451,123840.0,4
https://github.com/squid-cache/squid/commit/f52a7d75fa0fa951a3b0a1481d531c8b34367976,18 Aug 1998,moved from ../src,448,data/crawl/squid/hunk_6306.cpp,,,data/crawl/squid/old_hunk_6306.cpp,data/crawl/squid/new_hunk_6306.cpp,-1,371,,"printf(""item %5d: key: '%s' item: %p\n"", i++, walker->key,
	    walker->item);","[""addLog""]","[[], [""printf"", ""item"", ""%5d"", ""key"", ""%s"", ""item"", ""%p\\n"", ""i"", ""walker"", ""key"", ""walker"", ""item""]]",[15351615556342527134],7450,123840.0,4
https://github.com/squid-cache/squid/commit/f52a7d75fa0fa951a3b0a1481d531c8b34367976,18 Aug 1998,moved from ../src,448,data/crawl/squid/hunk_6306.cpp,,,data/crawl/squid/old_hunk_6306.cpp,data/crawl/squid/new_hunk_6306.cpp,-1,369,,"printf(""walking hash table...\n"");","[""addLog""]","[[], [""printf"", ""walking"", ""hash"", ""table"", ""\\n""]]",[13408071408817695086],7449,123840.0,4
https://github.com/squid-cache/squid/commit/94439e4e1d1a662f14357ee1e16c4a9af95db94b,08 Jan 2001,"Major rewrite of proxy authentication to support other schemes than
Basic (auth_rewrite branch on SourceForge).
Contributors:
   Andy Doran
   Robert Collins
   Chemolli Francesco
   Henrik Nordstrom

For details about the new API's, see Programmers Guide.

As part of this change everything from auth_modules has been moved to
src/auth/basic/helpers",21209,data/crawl/squid/hunk_5897.cpp,,,data/crawl/squid/old_hunk_5897.cpp,data/crawl/squid/new_hunk_5897.cpp,-1,60,,printf(ERR);,"[""addLog""]","[[], [""printf"", ""ERR""]]",[4186267234049229437],7448,0.0,4
https://github.com/squid-cache/squid/commit/94439e4e1d1a662f14357ee1e16c4a9af95db94b,08 Jan 2001,"Major rewrite of proxy authentication to support other schemes than
Basic (auth_rewrite branch on SourceForge).
Contributors:
   Andy Doran
   Robert Collins
   Chemolli Francesco
   Henrik Nordstrom

For details about the new API's, see Programmers Guide.

As part of this change everything from auth_modules has been moved to
src/auth/basic/helpers",21209,data/crawl/squid/hunk_5890.cpp,,,data/crawl/squid/old_hunk_5890.cpp,data/crawl/squid/new_hunk_5890.cpp,-1,568,,"fprintf(stderr, ""Error receiving response to TCon\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""Error"", ""receiving"", ""response"", ""to"", ""TCon\\n""]]",[-26711466169847032482],7447,0.0,4
https://github.com/squid-cache/squid/commit/94439e4e1d1a662f14357ee1e16c4a9af95db94b,08 Jan 2001,"Major rewrite of proxy authentication to support other schemes than
Basic (auth_rewrite branch on SourceForge).
Contributors:
   Andy Doran
   Robert Collins
   Chemolli Francesco
   Henrik Nordstrom

For details about the new API's, see Programmers Guide.

As part of this change everything from auth_modules has been moved to
src/auth/basic/helpers",21209,data/crawl/squid/hunk_5888.cpp,,,data/crawl/squid/old_hunk_5888.cpp,data/crawl/squid/new_hunk_5888.cpp,-1,181,,"fprintf(fd, ""    %s\n"", outbuf1);","[""addLog""]","[[], [""fprintf"", ""fd"", ""%s\\n"", ""outbuf1""]]",[1103988382793225785],7446,0.0,4
https://github.com/squid-cache/squid/commit/387b9f71d0a3ff9bf0eb26986e4f5b21065b8d73,05 Sep 2002,Upgraded to version 2.2,203,data/crawl/squid/hunk_5593.cpp,,,data/crawl/squid/old_hunk_5593.cpp,data/crawl/squid/new_hunk_5593.cpp,-1,30,,"fprintf(stderr, ""\t-P\t\t\tpersistent LDAP connection\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""\\t"", ""P\\t\\t\\tpersistent"", ""LDAP"", ""connection\\n""]]",[-21473577094276731833],7445,400680.0,4
https://github.com/squid-cache/squid/commit/4d6d905e8b4d4271702d50d56863fe37f8f52e42,12 Oct 2002,extract duplicate ufs code to ufscommon.c/h,6553,data/crawl/squid/hunk_5534.cpp,,,data/crawl/squid/old_hunk_5534.cpp,data/crawl/squid/new_hunk_5534.cpp,180,-1,"fatalf(""Swap directory %s is not a directory."", path);",,"[""removeLog""]","[[""fatalf"", ""Swap"", ""directory"", ""%s"", ""is"", ""not"", ""a"", ""directory"", ""path""], []]",[-16895851936805237112],7444,1357560.0,4
https://github.com/squid-cache/squid/commit/6708c52c59cd7fe5a6d2a4857c5e0b897a6e5f3c,28 Nov 2002,squid_ldap_group upgrade to version 2.8,367,data/crawl/squid/hunk_5495.cpp,,,data/crawl/squid/old_hunk_5495.cpp,data/crawl/squid/new_hunk_5495.cpp,17,99,"printf(""filter %s\n"", filter);","fprintf(stderr, ""filter %s\n"", filter);","[""updateLog"", ""addVariable""]","[[""printf""], [""fprintf"", ""stderr""]]",[-21163064839310014221],7443,599040.0,4
https://github.com/squid-cache/squid/commit/d3b3ab859857da0851f9c7de916b6df261ba43ae,27 Dec 2002,apply unify io patch to simplify IO code for diskd/aufs/ufs,7586,data/crawl/squid/hunk_5479.cpp,,,data/crawl/squid/old_hunk_5479.cpp,data/crawl/squid/new_hunk_5479.cpp,807,-1,"storeAppendPrintf(sentry, ""Filesystem Inodes in use: %d/%d (%d%%)\n"",
	    totl_in - free_in,
	    totl_in,
	    percent(totl_in - free_in, totl_in));",,"[""removeLog""]","[[""storeAppendPrintf"", ""sentry"", ""Filesystem"", ""Inodes"", ""in"", ""use"", ""%d/%d"", ""%d%%"", ""\\n"", ""totl_in"", ""free_in"", ""totl_in"", ""percent"", ""totl_in"", ""free_in"", ""totl_in""], []]",[13174929257738570109],7442,27360.0,4
https://github.com/squid-cache/squid/commit/d3b3ab859857da0851f9c7de916b6df261ba43ae,27 Dec 2002,apply unify io patch to simplify IO code for diskd/aufs/ufs,7586,data/crawl/squid/hunk_5479.cpp,,,data/crawl/squid/old_hunk_5479.cpp,data/crawl/squid/new_hunk_5479.cpp,803,-1,"storeAppendPrintf(sentry, ""Filesystem Space in use: %d/%d KB (%d%%)\n"",
	    totl_kb - free_kb,
	    totl_kb,
	    percent(totl_kb - free_kb, totl_kb));",,"[""removeLog""]","[[""storeAppendPrintf"", ""sentry"", ""Filesystem"", ""Space"", ""in"", ""use"", ""%d/%d"", ""KB"", ""%d%%"", ""\\n"", ""totl_kb"", ""free_kb"", ""totl_kb"", ""percent"", ""totl_kb"", ""free_kb"", ""totl_kb""], []]",[5873967832361889231],7441,27360.0,4
https://github.com/squid-cache/squid/commit/d3b3ab859857da0851f9c7de916b6df261ba43ae,27 Dec 2002,apply unify io patch to simplify IO code for diskd/aufs/ufs,7586,data/crawl/squid/hunk_5478.cpp,,,data/crawl/squid/old_hunk_5478.cpp,data/crawl/squid/new_hunk_5478.cpp,335,-1,fatal(errmsg);,,"[""removeLog""]","[[""fatal"", ""errmsg""], []]",[11940022100866282055],7440,27360.0,4
https://github.com/squid-cache/squid/commit/d3b3ab859857da0851f9c7de916b6df261ba43ae,27 Dec 2002,apply unify io patch to simplify IO code for diskd/aufs/ufs,7586,data/crawl/squid/hunk_5473.cpp,,,data/crawl/squid/old_hunk_5473.cpp,data/crawl/squid/new_hunk_5473.cpp,-1,90,,fatal(errmsg);,"[""addLog""]","[[], [""fatal"", ""errmsg""]]",[-11940022100866282055],7439,669600.0,4
https://github.com/squid-cache/squid/commit/29b17d63a524ac9855a7d286c6313a82050f485a,08 Feb 2003,"Summary: Merge delay class 4 performance enhancements.
Keywords:

Patches applied:

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-31
     Convert ACL.h listed types to SplayNode.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-30
     Make splay trees typesafe, and use in DelayUser class.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-29
     Separate splay usage from global includes.",780,data/crawl/squid/hunk_5424.cpp,,,data/crawl/squid/old_hunk_5424.cpp,data/crawl/squid/new_hunk_5424.cpp,-1,26,,"printf(""%d\n"",a->i);","[""addLog""]","[[], [""printf"", ""%d\\n"", ""a"", ""i""]]",[13382357820073349692],7438,2351160.0,4
https://github.com/squid-cache/squid/commit/59b2d47f54f8988d0dd74430a78b7a8599d819ff,22 Jul 2003,"Summary: Merge disk-factoring.
Keywords:

Patches applied:

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-14
   Merge of robertc@squid-cache.org--squid/squid--HEAD--3.0--patch-283-285

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-13
   Further OOification of the store drivers.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-12
   And more OOification.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-11
   And more OOification of the store drivers.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-10
   And more OOification.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-9
   More store OOification.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-8
   Dist missing files.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-7
   And moe OOification.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-6
   And more OOification.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-5
   More store FS OOification.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-4
   More OOification for the store.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-3
   OO'ing the store layer.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-2
   BUGFIX: array.cc compilation.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-1
   Update to latest HEAD code.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--base-0
   tag of robertc@squid-cache.org--squid/squid--HEAD--3.0--patch-220",3732,data/crawl/squid/hunk_5204.cpp,,,data/crawl/squid/old_hunk_5204.cpp,data/crawl/squid/new_hunk_5204.cpp,-1,102,,"fatal(""msgget failed"");","[""addLog""]","[[], [""fatal"", ""msgget"", ""failed""]]",[-9228573894909806285],7437,846000.0,4
https://github.com/squid-cache/squid/commit/f5691f9c44e06c13e6970ff31f0fe540650f787e,30 Aug 2004,/tmp/cvsZKn66v,12787,data/crawl/squid/hunk_5122.cpp,,,data/crawl/squid/old_hunk_5122.cpp,data/crawl/squid/new_hunk_5122.cpp,3,3,"storeAppendPrintf(entry, ""%s basic realm %s\n"", name, config->basicAuthRealm);","storeAppendPrintf(entry, ""%s basic realm %s\n"", name, basicAuthRealm);","[""removeVariable"", ""addVariable""]","[[""config""], []]",[-1329061548721586620],7436,0.0,4
https://github.com/squid-cache/squid/commit/5bf79e53246bc62348102baf2c51f5d304f089bd,21 Dec 2004,Bug# 103 post merge fix for stat.cc,10,data/crawl/squid/hunk_5098.cpp,,,data/crawl/squid/old_hunk_5098.cpp,data/crawl/squid/new_hunk_5098.cpp,3,3,"storeAppendPrintf(sentry, ""\tHits as % of all requests:\t5min: %3.1f%%, 60min: %3.1f%%\n"",
                      statRequestHitRatio(5),
                      statRequestHitRatio(60));","storeAppendPrintf(sentry, ""\tHits as %% of all requests:\t5min: %3.1f%%, 60min: %3.1f%%\n"",
                      statRequestHitRatio(5),
                      statRequestHitRatio(60));","[""updateContent""]","[[""%""], [""%%""]]",[4736023717028452],7435,0.0,4
https://github.com/squid-cache/squid/commit/0fd205780bbcbdd47190c50e6aba3b71ec17b0df,25 Apr 2005,"Bug #1223: Make the use of the %m error page to return auth info
messages

This patch extends the helper protocols for Basic and Digest to provide
some basic information in error responses, and makes use of the error
response already included in the NTLM helper protocol, making these
messages available as %m in error pages. Can be used if desired to
indicate why a login failed. The exact messages returned is helper
dependent.

Forward port of 2.5 patch.",2,data/crawl/squid/hunk_5045.cpp,,,data/crawl/squid/old_hunk_5045.cpp,data/crawl/squid/new_hunk_5045.cpp,3,3,"printf(""ERR\n"");","printf(""ERR No such user\n"");","[""updateContent""]","[[""ERR\\n""], [""ERR"", ""No"", ""such"", ""user\\n""]]",[-4129791547095036775],7434,360.0,4
https://github.com/squid-cache/squid/commit/6e785d853c1867e4b7aea26b0add938b39897a69,31 Oct 2005,"Windows port: addition of native authentication helpers.

- mswin_auth: 		Basic helper
- mswin_ntlm_auth: 	NTLM helper
- mswin_negotiate_auth: Negotiate helper

Supported build environment:

- Cygwin
- MSYS + MinGW
- MS VisualStudio C++ 2005",2901,data/crawl/squid/hunk_4944.cpp,,,data/crawl/squid/old_hunk_4944.cpp,data/crawl/squid/new_hunk_4944.cpp,-1,156,,"fprintf(stderr, ""Illegal request received: '%s'\n"", buf);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""Illegal"", ""request"", ""received"", ""%s"", ""\\n"", ""buf""]]",[-9451113466944467918],7433,0.0,4
https://github.com/squid-cache/squid/commit/9c05977a2939e40a7b749b10d1f2353f3ad57ba3,21 Aug 2006,Bootstrapped,2768,data/crawl/squid/hunk_4759.cpp,,,data/crawl/squid/old_hunk_4759.cpp,data/crawl/squid/new_hunk_4759.cpp,-1,633,,"fprintf (f, ""%lu\n"", i);","[""addLog""]","[[], [""fprintf"", ""f"", ""%lu\\n"", ""i""]]",[-7469080072603433866],7432,0.0,4
https://github.com/squid-cache/squid/commit/9c05977a2939e40a7b749b10d1f2353f3ad57ba3,21 Aug 2006,Bootstrapped,2768,data/crawl/squid/hunk_4759.cpp,,,data/crawl/squid/old_hunk_4759.cpp,data/crawl/squid/new_hunk_4759.cpp,-1,626,,"fprintf (f, ""%ld\n"", i);","[""addLog""]","[[], [""fprintf"", ""f"", ""%ld\\n"", ""i""]]",[-7469095072533433443],7431,0.0,4
https://github.com/squid-cache/squid/commit/595c79732716913858c8b6c0b301fa4672564616,07 Sep 2006,Windows port: Added Windows threads support to DiskThreads Disk module,1272,data/crawl/squid/hunk_4752.cpp,,,data/crawl/squid/old_hunk_4752.cpp,data/crawl/squid/new_hunk_4752.cpp,-1,276,,"fatal(""Failed to create condition variable"");","[""addLog""]","[[], [""fatal"", ""Failed"", ""to"", ""create"", ""condition"", ""variable""]]",[-18284048235763799555],7430,1530720.0,4
https://github.com/squid-cache/squid/commit/595c79732716913858c8b6c0b301fa4672564616,07 Sep 2006,Windows port: Added Windows threads support to DiskThreads Disk module,1272,data/crawl/squid/hunk_4752.cpp,,,data/crawl/squid/old_hunk_4752.cpp,data/crawl/squid/new_hunk_4752.cpp,-1,268,,"fatal(""Failed to create mutex"");","[""addLog""]","[[], [""fatal"", ""Failed"", ""to"", ""create"", ""mutex""]]",[-18964020235099249029],7429,1530720.0,4
https://github.com/squid-cache/squid/commit/9c8434f6a8753d321762ff58685cb1ff0364b4a7,14 Sep 2006,"Windows port: split Windows service code into WinSvc.cc, allowing correct execution of make check",1963,data/crawl/squid/hunk_4750.cpp,,,data/crawl/squid/old_hunk_4750.cpp,data/crawl/squid/new_hunk_4750.cpp,-1,147,,"fprintf(stderr, ""RegCloseKey %d\n"", (int) rv);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""RegCloseKey"", ""%d\\n"", ""int"", ""rv""]]",[-13964991524264781003],7428,894240.0,4
https://github.com/squid-cache/squid/commit/5f8252d203092b380f73e997be7097282c793077,06 Apr 2007,"	- ICAP-unrelated improvements from the squid3-icap branch on SF
	  (see further below for ICAP-specific improvements):

	- Replaced BodyReader with BodyPipe. BodyReader was a
	  collection of function pointers augmented with body size
	  calculation logic. BodyReader was used to deliver request
	  body (of a known size) from the client side to the server
	  side. Reference counting was used to communicate abort
	  conditions to the other side (it did not work well because
	  decreasing the reference count does not have any side-effects
	  if the count remains positive). Direct calls between sides
	  sometimes resulted in a call-me-when-I-am-calling-you ""loops""
	  and related bugs.

	  BodyPipe is used to deliver request or response body (possibly
	  of unknown size) from the body producer to the body consumer.
	  A producer can be the client side (for virgin requests), the
	  server side (for virgin replies), or the ICAP side (for
	  adapted messages). A consumer can be the client side (for
	  adapted responses, including responses in a request
	  satisfaction mode), the server side (for adapted requests),
	  and the ICAP side (for virgin requests and responses).

	  BodyPipe uses asynchronous calls for communication between
	  sides to avoid call-me-when-I-am-calling-you ""loops"".

	  BodyPipe has methods to communicate normal termination and
	  abort conditions to the other side. The use of those methods
	  is mandatory. Reference counting is used only as a garbage
	  collection mechanism.

	  BodyPipe is used to read request bodies, including requests
	  for which there is no consumer and the connection is in a
	  'closing' state. BodyPipe can auto-consume body so that a
	  'closing' connection does not have to rely on the body
	  consumer presence when eating up remaining body data.

	  If auto-consumption is turned on and the pipe starts
	  consuming before a real consumer is attached to the pipe, the
	  setConsumerIfNotLate call fails, and the real consumer has to
	  handle the failure.

	  The new BodyPipe approach should make support for HTTP/1.1
	  chunked requests easier. Only a few places in the pipe-related
	  code assume that the request size is known.

	- Removed ClientBody as unused, replaced by BodyReader, then
	  BodyPipe.

	- Moved HttpRequest::body_reader to HttpMsg::body_pipe so that
	  all HTTP message bodies can be communicated via pipes. This
	  is needed for the server side to supply response bodies to
	  ICAP and for the ICAP side to supply adapted message bodies
	  to others.

	- When cleaning HttpRequest or HttpReply, reset body_pipe to
	  NULL instead of asserting that it is already NULL. BodyPipes
	  are owned and maintained by other objects and HttpMsg is used
	  only as a mechanism to pass the pipe pointer from the body
	  producer to the consumer. To maintain guarantees similar to
	  the old code, the BodyPipe destructor asserts that both the
	  producer and the consumer are gone when the pipe is
	  destructed.

	- When appending body data, do not append more than the known
	  body size. This fixes the following assertion when POSTing
	  from IE in my tests: assertion failed: client_side.cc:3205:
	  ""bodySizeLeft() > 0"".

	  I suspect IE or some Javascripts running on IE were appending
	  extra CRLF to a POST, exposing the bug, and triggering the
	  above assertion.

	- WARNING: Ftp-specific BodyPipe changes are untested, but the
	  old code probably did not work well with ICAP either.  More
	  testing is needed.

	- Moved more common server-side code from http.* and ftp.* into
	  Server.*.  Most ICAP-related code is in the Server class now.

	  The code move to the Server class and migration to BodyPipe
	  exposed several FTP/HTTP inconsistencies and bugs. I marked
	  those I could not fix with XXXs.

	- Distinguish the end of communication with the origin server
	  from the end of communication with ICAP. Clean them up
	  separately when possible. Terminate when both are completed
	  (or aborted).

	- Polished persistentConnStatus() to avoid calling
	  statusIfComplete() until really necessary (and appropriate).
	  This makes debugging easier to understand for some.

	- Use auto-consumption feature to consume data from closing
	  connections for which there is no real body consumer.

	- Use BodyPipe for maintaining the ""closing"" state of a
	  connection instead of in.abortedSize. This change ""removes"" a
	  few memory leaks and an assertion, but does need more work,
	  especially when the regular BodyPipe consumer leaves early
	  and does not consume the request body.

	- The client stream code sometimes marks the ""closing""
	  connection as STREAM_UNPLANNED_COMPLETE, leading to a
	  double-close. I do not yet understand why. There is now code
	  to ignore multiple attempts to enter the ""closing"" state.



	- ICAP improvements from the squid3-icap branch on SF, including:

	- Added icap_service_failure_limit squid.conf option. The limit
	  specifies the number of failures that Squid tolerates when
	  establishing a new TCP connection with an ICAP service. If
	  the number of failures exceeds the limit, the ICAP service is
	  not used for new ICAP requests until it is time to refresh
	  its OPTIONS. The per-service failure counter is reset to zero
	  each time Squid fetches new service OPTIONS.

	  A negative value disables the limit.

	  The limit used to be hardcoded to 10.

	  (based on the patch by Axel Westerhold)

	- Added icap_service_revival_delay squid.conf option.  The
	  delay specifies the number of seconds to wait after an ICAP
	  OPTIONS request failure before requesting the options again.
	  The failed ICAP service is considered ""down"" until fresh
	  OPTIONS are fetched.

	  The actual delay cannot be smaller than the [still] hardcoded
	  minimum delay of 60 seconds.

	  (based on the patch by Axel Westerhold)

	- Added icap_client_username_header and
	  icap_client_username_encode squid.conf options to control how
	  the authenticated client username should be sent to the ICAP
	  service. (based on the patch by Axel Westerhold)

	- Handle REQMOD transaction failures where we cannot proceed
	  with the normal request flow.

	- Use ICAPInitiator API to send ""success"" or ""abort"" messages
	  to ICAP transaction initiator. Store virgin and adapted
	  metadata as public fields (if the newly added ICAPInOut type)
	  that the initiator can access when receiving our ""successful
	  adaptation"" message. This keeps messages simple.

	- Using ICAPInitiator API and a ""universal"" BodyPipe API makes
	  it possible to exchange bodies directly with client- or
	  server-side code without ICAPClient* translators, which are
	  now gone along with the ICAPInitXaction function in
	  ICAPClient.

	- Added ICAPInitiator interface that classes initiating ICAP
	  transactions must now support. The API currently has just two
	  methods: one for receiving adapted message headers
	  (indicating a successful ICAP transaction, at least to the
	  point of fetching adapted headers) and one for receiving a
	  notification of an aborted ICAP transaction.

	  Most ICAP initiators (or their close relatives) will also need
	  to implement BodyConsumer and/or BodyProducer APIs to exchange
	  virgin and/or adapted HTTP message bodies with the initiated
	  ICAP transaction. However, that activity is not addressed in
	  this API.  New AsyncCall API is used to declare the callback
	  wrappers.

	- Use BodyPipe instead of MsgPipe for receiving virgin and
	  sending adapted message bodies. BodyPipe is not much
	  different from MsgPipeBody, but it is better to use a
	  ""universal"" class that the rest of Squid code now uses.  One
	  complication is that BodyPipes are currently not created for
	  messages with zero-size bodies. The code had to be changed to
	  not assume that a zero-size body comes with a pipe.

	- Deleted MsgPipe and related classes. Message pipes had two
	  purposes: coordinate HTTP message adaptation (start, get the
	  adapted headers, abort) and exchange HTTP message bodies. The
	  latter is now done via BodyPipe API. The former can be
	  implemented directly in ICAPModXact.

	  Deleted ICAPClient* and related classes as (my) design
	  failure.

	  The original idea behind message pipes and ICAPClient* classes
	  was to isolate ICAP code from the Squid core. The core code
	  was supposed to use ICAPClient* classes for all ICAP-related
	  needs, and ICAPClient* classes were supposed to translate core
	  needs into ""ICAP needs"" and use message pipes to communicate
	  with asynchronously running ICAP transactions. The latter part
	  worked fine, but the former did not.

	  The core code still did a lot of ICAP-specific work on its
	  own. This could be because ICAP processing affects the flow so
	  much or because the core code had not been refactored enough
	  to minimize ICAP interactions.  Whatever the reason, we ended
	  up with a lot of complex code/logic coordinating the core code
	  and ICAPClient* classes. While ICAPClient* classes were
	  ""translating"", they could not hide the key actions or events
	  (such as message body exchange or transaction aborts) from the
	  core. The core code still had to support those actions or
	  handle those events.  Thus, every major action or event was
	  handled twice:  once in the core side code and once in a
	  ICAPClient* class.

	  Removing ICAPClient* ""translation"" step simplified the code
	  and possibly improved performance. As for the ""ICAP
	  separation"" goal, the current exposure to the ICAPModXact
	  class can be hidden by a generic ""Message Adaptation
	  Transaction"" class if we need to support more adaptation
	  protocols. The core code should not be affected much by such a
	  change.

	- ClientHttpRequest: Support the new ICAPInitiator API and talk
	  to ICAPModXact directly instead of using ICAPClient* classes,
	  which are now gone.

	- ConnStateData: Use BodyPipe for delivering virgin request
	  bodies to the server or ICAP side. Implement the BodyProducer
	  interface.  ClientHttpRequest: Use BodyPipe instead of
	  BodyReader when receiving request bodies (from client side or
	  ICAP).  Implement the BodyConsumer interface.  See the first
	  BodyPipe CVS log message for the rationale.

	- Use BodyPipe for delivering virgin reply bodies to ICAP and
	  receiving adapted reply bodies from ICAP. Implement the
	  BodyProducer interface.

	  Use BodyPipe instead of BodyReader when receiving request
	  bodies (from client side or ICAP).  Implement the BodyConsumer
	  interface.

	- Replaced never-failing doIcap() with startIcap() that fails
	  if we cannot select an ICAP service or the selected service
	  is not usable. Rearranged
	  ClientRequestContext::icapAclCheckDone() to bypass ICAP
	  errors when possible.  Now, ClientRequestContext::startIcap()
	  is very similar to Server::startIcap(). Same for
	  icapAclCheckDone().  Made
	  ClientHttpRequest::handleIcapFailure() public because
	  ClientRequestContext::icapAclCheckDone() calls it.

	- Polished TTL handling to make sure we use the default TTL
	  when the ICAP server did not provide an explicit value or if
	  we failed to communicate with the server. The latter case may
	  not have been handled correctly before.

	- The minimum options update gap (currently hard-coded) must be
	  smaller than the default options TTL. Otherwise, we get stale
	  options and down ICAP services around the update time because
	  we cannot update soon enough.

	- Support asynchronous transaction start. This allows for a
	  better handling of startup errors (or at least makes them
	  similar to other transaction errors).

	- Call a swanSong() method upon expected transaction
	  termination (including aborts). This allows for proper and
	  prompt [partial] transaction cleanup, without waiting for the
	  destructor to be called. The destruction may be delayed by
	  refcounting if we have other transaction users waiting for
	  some transaction notifications.

	- Do not reuse a connection if we are still reading or writing
	  (even if no actual I/O is scheduled). The old code would
	  reuse such connections, and read/write leftovers from aborted
	  transactions from/to the ICAP server.

	- Do not send last-chunk in ICAP Preview with a null-body. It is
	  possible that the old code would send the last-chunk under
	  some Preview conditions with null-body, but I am not sure.

	- Fixed HttpStateData memory leak visible when no RESPMOD
	  services are enabled.  ICAPAccessCheck constructor was
	  cbdata-locking HttpStateData, but was not releasing the lock
	  when there was no matching service class, leading to an
	  HttpStateData leak. Furthermore, ICAPAccessCheck would then
	  call HttpStateData back without validating the cbdata
	  pointer, probably calling wrong or invalid HttpStateData.

	- Fixed ""is it too late to bypass?"" conditions in
	  ClientHttpRequest::handleIcapFailure(). We should be able to
	  bypass more often now. However, handleIcapFailure() still has
	  the old bug: it does not check whether the service is
	  optional. The current fix implies that now Squid may bypass
	  essential services more often.

	- Call storeEntry()->complete() when ending request
	  satisfaction. Without this call, we may keep the connection
	  open, which does not work with responses that mark the end of
	  their body by closing a connection. (Christos Tsantilas)

	- Fixed ieof condition detection. Squid was sending last-chunk
	  without ieof bit and was sending two last chunks when doing
	  preview (Tsantilas Christos).

	- When ICAP server wants the entire virgin body and sends 100
	  Continue after Preview, do not stop backing up virgin body
	  data for echoing if we promised to support 204 No Content
	  responses outside of Preview. If we allow 204s, 100 Continue
	  may be followed by a 204 No Content and we will need the
	  entire virgin body to echo back.

	- Rewrote MemBufClaim into a VirginBodyAct class to simplify
	  and clarify code in hope to minimize the number of bugs like
	  the one mentioned above. MemBufClaim was protecting an area
	  of virgin body pipe content and, as a side effect, was
	  providing the transaction with the content pointer for the
	  write or send actions.

	  Now VirginBodyAct just maintains the activity offset and the
	  transaction code uses that to consume virgin body correctly.
	  The size of the area is no longer maintained because it was
	  usually unknown or unused; and when it was known and used
	  (i.e., Preview), it could be taken from the preview state
	  object anyway.  Renamed and documented VirginBodyAct-related
	  methods to clarify the intent.

	- When sending last-chunk in Preview, send ieof extension if we
	  wrote the entire body. The old code would not send ieof if we
	  wrote as many bytes as promised in the Preview header, even
	  if we promised to write everything.  This would mislead
	  compliant ICAP servers that do not look at the Content-Length
	  header and reply with 100 Continue, expecting more body data.

	- Do not reset Preview size to zero when expecting a virgin
	  body of unknown size. A Squid user reported that this change
	  works.

	- Polished debugging: Instead of using pointers, use unique ICAP
	  transaction IDs.  This helps with isolating a transaction in a
	  large log, where pointers may be reused many times. Print
	  connection descriptor like most of the core code does. Other
	  minor improvements.",4655,data/crawl/squid/hunk_4673.cpp,,,data/crawl/squid/old_hunk_4673.cpp,data/crawl/squid/new_hunk_4673.cpp,112,-1,stop(notifyOwner);,,"[""removeLog""]","[[""stop"", ""notifyOwner""], []]",[4780997408801844825],7427,112320.0,4
https://github.com/squid-cache/squid/commit/89f77e43f36bdbd636826c94085f9b5d882e473d,24 Jun 2007,"Bug #1948: digest_edir_auth helper, using novell eDirectory universal password

This is a modified version of digets_ldap_auth, with eDirectory special hooks
for retrieving the Universal Password plain text password.",1874,data/crawl/squid/hunk_4545.cpp,,,data/crawl/squid/old_hunk_4545.cpp,data/crawl/squid/new_hunk_4545.cpp,-1,382,,"fprintf(stderr, ""\nUnable to connect to LDAP server:%s port:%d\n"", ldapServer, port);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""\\nUnable"", ""to"", ""connect"", ""to"", ""LDAP"", ""server"", ""%s"", ""port"", ""%d\\n"", ""ldapServer"", ""port""]]",[3824874482844155251],7426,686880.0,4
https://github.com/squid-cache/squid/commit/89f77e43f36bdbd636826c94085f9b5d882e473d,24 Jun 2007,"Bug #1948: digest_edir_auth helper, using novell eDirectory universal password

This is a modified version of digets_ldap_auth, with eDirectory special hooks
for retrieving the Universal Password plain text password.",1874,data/crawl/squid/hunk_4545.cpp,,,data/crawl/squid/old_hunk_4545.cpp,data/crawl/squid/new_hunk_4545.cpp,-1,226,,"fprintf(stderr, PROGRAM_NAME "" WARNING, LDAP search error '%s'\n"", ldap_err2string(rc));","[""addLog""]","[[], [""fprintf"", ""stderr"", ""PROGRAM_NAME"", ""WARNING"", ""LDAP"", ""search"", ""error"", ""%s"", ""\\n"", ""ldap_err2string"", ""rc""]]",[-10530649752204183237],7425,1331640.0,4
https://github.com/squid-cache/squid/commit/8763034115108660e73e6d088c47a6dde8c751c5,27 Aug 2007,"Enable HTCP and SNMP support by default in the binary, but default off in squid.conf",68,data/crawl/squid/hunk_4477.cpp,,,data/crawl/squid/old_hunk_4477.cpp,data/crawl/squid/new_hunk_4477.cpp,-1,4,,"fprintf(fp, ""#%s\n"", line->data);","[""addLog""]","[[], [""fprintf"", ""fp"", ""%s\\n"", ""line"", ""data""]]",[-1893739475219068612],7424,1892520.0,4
https://github.com/squid-cache/squid/commit/e11ffec305e6d947cbe8ed9dd766258f7793a020,22 Sep 2007,Allow the build of digest_ldap_auth when ldap_start_tls_s() is not available,12,data/crawl/squid/hunk_4456.cpp,,,data/crawl/squid/old_hunk_4456.cpp,data/crawl/squid/new_hunk_4456.cpp,-1,11,,"fprintf(stderr, ""TLS not supported with your LDAP library\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""TLS"", ""not"", ""supported"", ""with"", ""your"", ""LDAP"", ""library\\n""]]",[95155891144576559],7423,627840.0,4
https://github.com/squid-cache/squid/commit/cc192b5087ebbd5c214fcacdf26f117e4f15241b,15 Dec 2007,"Import IPv6 support from squid3-ipv6 branch to 3-HEAD.

This patch fully enables squid to handle IPv6 on internally supported
protocols which have IPv6 capability.
see 3.1 Release Notes for full details on the IPv6 changes.
also see squid.conf generated from this point for configuration changes.

TODO: Release-Notes fro 3.1 have yet to be created. The mentioned details
      documentation will come in a later patch.",9997,data/crawl/squid/hunk_4425.cpp,,,data/crawl/squid/old_hunk_4425.cpp,data/crawl/squid/new_hunk_4425.cpp,3,3,"hdr_out->putStr(HDR_HOST, orig_request->host);","hdr_out->putStr(HDR_HOST, orig_request->GetHost());","[""updateVariable"", ""moveVariable"", ""addVariable""]","[[""host""], [""GetHost""]]",[-4546079892751069813],7422,0.0,4
https://github.com/squid-cache/squid/commit/3e7b6055489b13ca3faa9eef01b42a74971f84e4,20 Mar 2008,"Importing CVS squid3-ecap branch:

lib/Makefile.am
        Added libLtdl to SUBDIRS if USE_LOADABLE_MODULES.


src/ICAP/ICAPModXact.h
src/ICAP/ICAPServiceRep.h

        When USE_ECAP_AS_ICAP_HACK macro is defined, enable a temporary
        hack that uses ICAP class names to implement some of the eCAP
        classes. This is necessary to hide eCAP/ICAP distinction from
        Squid core. Hiding the distinction is necessary to avoid
        numerous conflicts when this branch is merged with async call
        branch changes.
        
        Once the branches are merged, the hack will be removed. Since
        we currently #define eCAP class names to match those of ICAP
        classes, the changes at that time should not be significant:
        remove renaming #defines and adjust autotools meta files to
        allow both ICAP and eCAP co-exist.



configure.in
src/Makefile.am

        Enable eCAP support if loadable module support is enabled.
        Eventually, we may want to control eCAP support directly.
        
        Added eCAP directory to the Makefile. The eCAP directory
        contents will be committed later.



SPONSORS
        Added eCAP sponsor.


src/Makefile.am
        When eCAP is enabled, to support USE_ECAP_AS_ICAP_HACK, ignore
        ICAP files that eCAP overwrites.


configure.in

        Added --enable-ecap option to control eCAP support explicitly.
        Added consistency checks for the combination of --enable-ecap,
        --enable-icap-client, and --disable-loadable-modules options.
        
        Define USE_ECAP_AS_ICAP_HACK macro to enable a temporary hack
        that uses ICAP class names to implement some of the eCAP
        classes. This is necessary to hide eCAP/ICAP distinction from
        Squid core. Hiding the distinction is necessary to avoid
        numerous conflicts when this branch is merged with async call
        branch changes.
        
        Once the branches are merged, the hack will be removed. Since
        we currently #define eCAP class names to match those of ICAP
        classes, the changes at that time should not be significant:
        remove renaming #defines and adjust autotools meta files to
        allow both ICAP and eCAP co-exist.



Makefile.am
acinclude.m4
bootstrap.sh
configure.in
src/Makefile.am

        Added basic support for Libtool ltdl. Libltdl directory is not
        committed yet because I want to investigate whether it can be
        moved from root to lib/. Bootstrap.sh currently strips a large
        copying file from that directory but does not attempt to move
        the directory itself.
        
        The configure options will need to be changed according to
        squid-dev discussion: we should assume that ltdl is always used
        if modules are used, and we should have a --disable-modules
        option.
        
        The code works with a dummy module: Squid was able to load and
        unload using LoadableModule, an ltdl wrapper class from Spicer.
        I have not committed that wrapper yet.

Makefile.am
bootstrap.sh
configure.in
src/Makefile.am

        Moved Libtool libltdl directory to lib/libLtdl to keep all
        3rd-party libs in one place. Will commit the lib/libLtdl
        directory itself soon.
        
        Bootstrap.sh currently moves all files from the generated
        libltdl into lib/libLtdl. A better approach may be to use the
        --ltdl option of libtoolize. Will investigate.
        
        Changed configure options to assume that ltdl is always used if
        modules are used.",48970,data/crawl/squid/hunk_4347.cpp,,,data/crawl/squid/old_hunk_4347.cpp,data/crawl/squid/new_hunk_4347.cpp,-1,1379,,"printf (""i860-alliant-bsd\n"");","[""addLog""]","[[], [""printf"", ""i860"", ""alliant"", ""bsd\\n""]]",[15258442327341906774],7421,2809080.0,4
https://github.com/squid-cache/squid/commit/3e7b6055489b13ca3faa9eef01b42a74971f84e4,20 Mar 2008,"Importing CVS squid3-ecap branch:

lib/Makefile.am
        Added libLtdl to SUBDIRS if USE_LOADABLE_MODULES.


src/ICAP/ICAPModXact.h
src/ICAP/ICAPServiceRep.h

        When USE_ECAP_AS_ICAP_HACK macro is defined, enable a temporary
        hack that uses ICAP class names to implement some of the eCAP
        classes. This is necessary to hide eCAP/ICAP distinction from
        Squid core. Hiding the distinction is necessary to avoid
        numerous conflicts when this branch is merged with async call
        branch changes.
        
        Once the branches are merged, the hack will be removed. Since
        we currently #define eCAP class names to match those of ICAP
        classes, the changes at that time should not be significant:
        remove renaming #defines and adjust autotools meta files to
        allow both ICAP and eCAP co-exist.



configure.in
src/Makefile.am

        Enable eCAP support if loadable module support is enabled.
        Eventually, we may want to control eCAP support directly.
        
        Added eCAP directory to the Makefile. The eCAP directory
        contents will be committed later.



SPONSORS
        Added eCAP sponsor.


src/Makefile.am
        When eCAP is enabled, to support USE_ECAP_AS_ICAP_HACK, ignore
        ICAP files that eCAP overwrites.


configure.in

        Added --enable-ecap option to control eCAP support explicitly.
        Added consistency checks for the combination of --enable-ecap,
        --enable-icap-client, and --disable-loadable-modules options.
        
        Define USE_ECAP_AS_ICAP_HACK macro to enable a temporary hack
        that uses ICAP class names to implement some of the eCAP
        classes. This is necessary to hide eCAP/ICAP distinction from
        Squid core. Hiding the distinction is necessary to avoid
        numerous conflicts when this branch is merged with async call
        branch changes.
        
        Once the branches are merged, the hack will be removed. Since
        we currently #define eCAP class names to match those of ICAP
        classes, the changes at that time should not be significant:
        remove renaming #defines and adjust autotools meta files to
        allow both ICAP and eCAP co-exist.



Makefile.am
acinclude.m4
bootstrap.sh
configure.in
src/Makefile.am

        Added basic support for Libtool ltdl. Libltdl directory is not
        committed yet because I want to investigate whether it can be
        moved from root to lib/. Bootstrap.sh currently strips a large
        copying file from that directory but does not attempt to move
        the directory itself.
        
        The configure options will need to be changed according to
        squid-dev discussion: we should assume that ltdl is always used
        if modules are used, and we should have a --disable-modules
        option.
        
        The code works with a dummy module: Squid was able to load and
        unload using LoadableModule, an ltdl wrapper class from Spicer.
        I have not committed that wrapper yet.

Makefile.am
bootstrap.sh
configure.in
src/Makefile.am

        Moved Libtool libltdl directory to lib/libLtdl to keep all
        3rd-party libs in one place. Will commit the lib/libLtdl
        directory itself soon.
        
        Bootstrap.sh currently moves all files from the generated
        libltdl into lib/libLtdl. A better approach may be to use the
        --ltdl option of libtoolize. Will investigate.
        
        Changed configure options to assume that ltdl is always used if
        modules are used.",48970,data/crawl/squid/hunk_4347.cpp,,,data/crawl/squid/old_hunk_4347.cpp,data/crawl/squid/new_hunk_4347.cpp,-1,1374,,"printf (""vax-dec-ultrix\n"");","[""addLog""]","[[], [""printf"", ""vax"", ""dec"", ""ultrix\\n""]]",[3771227756932470676],7420,2809080.0,4
https://github.com/squid-cache/squid/commit/3e7b6055489b13ca3faa9eef01b42a74971f84e4,20 Mar 2008,"Importing CVS squid3-ecap branch:

lib/Makefile.am
        Added libLtdl to SUBDIRS if USE_LOADABLE_MODULES.


src/ICAP/ICAPModXact.h
src/ICAP/ICAPServiceRep.h

        When USE_ECAP_AS_ICAP_HACK macro is defined, enable a temporary
        hack that uses ICAP class names to implement some of the eCAP
        classes. This is necessary to hide eCAP/ICAP distinction from
        Squid core. Hiding the distinction is necessary to avoid
        numerous conflicts when this branch is merged with async call
        branch changes.
        
        Once the branches are merged, the hack will be removed. Since
        we currently #define eCAP class names to match those of ICAP
        classes, the changes at that time should not be significant:
        remove renaming #defines and adjust autotools meta files to
        allow both ICAP and eCAP co-exist.



configure.in
src/Makefile.am

        Enable eCAP support if loadable module support is enabled.
        Eventually, we may want to control eCAP support directly.
        
        Added eCAP directory to the Makefile. The eCAP directory
        contents will be committed later.



SPONSORS
        Added eCAP sponsor.


src/Makefile.am
        When eCAP is enabled, to support USE_ECAP_AS_ICAP_HACK, ignore
        ICAP files that eCAP overwrites.


configure.in

        Added --enable-ecap option to control eCAP support explicitly.
        Added consistency checks for the combination of --enable-ecap,
        --enable-icap-client, and --disable-loadable-modules options.
        
        Define USE_ECAP_AS_ICAP_HACK macro to enable a temporary hack
        that uses ICAP class names to implement some of the eCAP
        classes. This is necessary to hide eCAP/ICAP distinction from
        Squid core. Hiding the distinction is necessary to avoid
        numerous conflicts when this branch is merged with async call
        branch changes.
        
        Once the branches are merged, the hack will be removed. Since
        we currently #define eCAP class names to match those of ICAP
        classes, the changes at that time should not be significant:
        remove renaming #defines and adjust autotools meta files to
        allow both ICAP and eCAP co-exist.



Makefile.am
acinclude.m4
bootstrap.sh
configure.in
src/Makefile.am

        Added basic support for Libtool ltdl. Libltdl directory is not
        committed yet because I want to investigate whether it can be
        moved from root to lib/. Bootstrap.sh currently strips a large
        copying file from that directory but does not attempt to move
        the directory itself.
        
        The configure options will need to be changed according to
        squid-dev discussion: we should assume that ltdl is always used
        if modules are used, and we should have a --disable-modules
        option.
        
        The code works with a dummy module: Squid was able to load and
        unload using LoadableModule, an ltdl wrapper class from Spicer.
        I have not committed that wrapper yet.

Makefile.am
bootstrap.sh
configure.in
src/Makefile.am

        Moved Libtool libltdl directory to lib/libLtdl to keep all
        3rd-party libs in one place. Will commit the lib/libLtdl
        directory itself soon.
        
        Bootstrap.sh currently moves all files from the generated
        libltdl into lib/libLtdl. A better approach may be to use the
        --ltdl option of libtoolize. Will investigate.
        
        Changed configure options to assume that ltdl is always used if
        modules are used.",48970,data/crawl/squid/hunk_4347.cpp,,,data/crawl/squid/old_hunk_4347.cpp,data/crawl/squid/new_hunk_4347.cpp,-1,1351,,exit (0);,"[""addLog""]","[[], [""exit"", ""0""]]",[-4664224508366039323],7419,1514520.0,4
https://github.com/squid-cache/squid/commit/3e7b6055489b13ca3faa9eef01b42a74971f84e4,20 Mar 2008,"Importing CVS squid3-ecap branch:

lib/Makefile.am
        Added libLtdl to SUBDIRS if USE_LOADABLE_MODULES.


src/ICAP/ICAPModXact.h
src/ICAP/ICAPServiceRep.h

        When USE_ECAP_AS_ICAP_HACK macro is defined, enable a temporary
        hack that uses ICAP class names to implement some of the eCAP
        classes. This is necessary to hide eCAP/ICAP distinction from
        Squid core. Hiding the distinction is necessary to avoid
        numerous conflicts when this branch is merged with async call
        branch changes.
        
        Once the branches are merged, the hack will be removed. Since
        we currently #define eCAP class names to match those of ICAP
        classes, the changes at that time should not be significant:
        remove renaming #defines and adjust autotools meta files to
        allow both ICAP and eCAP co-exist.



configure.in
src/Makefile.am

        Enable eCAP support if loadable module support is enabled.
        Eventually, we may want to control eCAP support directly.
        
        Added eCAP directory to the Makefile. The eCAP directory
        contents will be committed later.



SPONSORS
        Added eCAP sponsor.


src/Makefile.am
        When eCAP is enabled, to support USE_ECAP_AS_ICAP_HACK, ignore
        ICAP files that eCAP overwrites.


configure.in

        Added --enable-ecap option to control eCAP support explicitly.
        Added consistency checks for the combination of --enable-ecap,
        --enable-icap-client, and --disable-loadable-modules options.
        
        Define USE_ECAP_AS_ICAP_HACK macro to enable a temporary hack
        that uses ICAP class names to implement some of the eCAP
        classes. This is necessary to hide eCAP/ICAP distinction from
        Squid core. Hiding the distinction is necessary to avoid
        numerous conflicts when this branch is merged with async call
        branch changes.
        
        Once the branches are merged, the hack will be removed. Since
        we currently #define eCAP class names to match those of ICAP
        classes, the changes at that time should not be significant:
        remove renaming #defines and adjust autotools meta files to
        allow both ICAP and eCAP co-exist.



Makefile.am
acinclude.m4
bootstrap.sh
configure.in
src/Makefile.am

        Added basic support for Libtool ltdl. Libltdl directory is not
        committed yet because I want to investigate whether it can be
        moved from root to lib/. Bootstrap.sh currently strips a large
        copying file from that directory but does not attempt to move
        the directory itself.
        
        The configure options will need to be changed according to
        squid-dev discussion: we should assume that ltdl is always used
        if modules are used, and we should have a --disable-modules
        option.
        
        The code works with a dummy module: Squid was able to load and
        unload using LoadableModule, an ltdl wrapper class from Spicer.
        I have not committed that wrapper yet.

Makefile.am
bootstrap.sh
configure.in
src/Makefile.am

        Moved Libtool libltdl directory to lib/libLtdl to keep all
        3rd-party libs in one place. Will commit the lib/libLtdl
        directory itself soon.
        
        Bootstrap.sh currently moves all files from the generated
        libltdl into lib/libLtdl. A better approach may be to use the
        --ltdl option of libtoolize. Will investigate.
        
        Changed configure options to assume that ltdl is always used if
        modules are used.",48970,data/crawl/squid/hunk_4347.cpp,,,data/crawl/squid/old_hunk_4347.cpp,data/crawl/squid/new_hunk_4347.cpp,-1,1348,,"printf (""i386-sequent-ptx2\n"");","[""addLog""]","[[], [""printf"", ""i386"", ""sequent"", ""ptx2\\n""]]",[-6392862029409455855],7418,2809080.0,4
https://github.com/squid-cache/squid/commit/3e7b6055489b13ca3faa9eef01b42a74971f84e4,20 Mar 2008,"Importing CVS squid3-ecap branch:

lib/Makefile.am
        Added libLtdl to SUBDIRS if USE_LOADABLE_MODULES.


src/ICAP/ICAPModXact.h
src/ICAP/ICAPServiceRep.h

        When USE_ECAP_AS_ICAP_HACK macro is defined, enable a temporary
        hack that uses ICAP class names to implement some of the eCAP
        classes. This is necessary to hide eCAP/ICAP distinction from
        Squid core. Hiding the distinction is necessary to avoid
        numerous conflicts when this branch is merged with async call
        branch changes.
        
        Once the branches are merged, the hack will be removed. Since
        we currently #define eCAP class names to match those of ICAP
        classes, the changes at that time should not be significant:
        remove renaming #defines and adjust autotools meta files to
        allow both ICAP and eCAP co-exist.



configure.in
src/Makefile.am

        Enable eCAP support if loadable module support is enabled.
        Eventually, we may want to control eCAP support directly.
        
        Added eCAP directory to the Makefile. The eCAP directory
        contents will be committed later.



SPONSORS
        Added eCAP sponsor.


src/Makefile.am
        When eCAP is enabled, to support USE_ECAP_AS_ICAP_HACK, ignore
        ICAP files that eCAP overwrites.


configure.in

        Added --enable-ecap option to control eCAP support explicitly.
        Added consistency checks for the combination of --enable-ecap,
        --enable-icap-client, and --disable-loadable-modules options.
        
        Define USE_ECAP_AS_ICAP_HACK macro to enable a temporary hack
        that uses ICAP class names to implement some of the eCAP
        classes. This is necessary to hide eCAP/ICAP distinction from
        Squid core. Hiding the distinction is necessary to avoid
        numerous conflicts when this branch is merged with async call
        branch changes.
        
        Once the branches are merged, the hack will be removed. Since
        we currently #define eCAP class names to match those of ICAP
        classes, the changes at that time should not be significant:
        remove renaming #defines and adjust autotools meta files to
        allow both ICAP and eCAP co-exist.



Makefile.am
acinclude.m4
bootstrap.sh
configure.in
src/Makefile.am

        Added basic support for Libtool ltdl. Libltdl directory is not
        committed yet because I want to investigate whether it can be
        moved from root to lib/. Bootstrap.sh currently strips a large
        copying file from that directory but does not attempt to move
        the directory itself.
        
        The configure options will need to be changed according to
        squid-dev discussion: we should assume that ltdl is always used
        if modules are used, and we should have a --disable-modules
        option.
        
        The code works with a dummy module: Squid was able to load and
        unload using LoadableModule, an ltdl wrapper class from Spicer.
        I have not committed that wrapper yet.

Makefile.am
bootstrap.sh
configure.in
src/Makefile.am

        Moved Libtool libltdl directory to lib/libLtdl to keep all
        3rd-party libs in one place. Will commit the lib/libLtdl
        directory itself soon.
        
        Bootstrap.sh currently moves all files from the generated
        libltdl into lib/libLtdl. A better approach may be to use the
        --ltdl option of libtoolize. Will investigate.
        
        Changed configure options to assume that ltdl is always used if
        modules are used.",48970,data/crawl/squid/hunk_4347.cpp,,,data/crawl/squid/old_hunk_4347.cpp,data/crawl/squid/new_hunk_4347.cpp,-1,1338,,"printf (""ns32k-sequent-dynix\n"");","[""addLog""]","[[], [""printf"", ""ns32k"", ""sequent"", ""dynix\\n""]]",[17209887179899307144],7417,2809080.0,4
https://github.com/squid-cache/squid/commit/3e7b6055489b13ca3faa9eef01b42a74971f84e4,20 Mar 2008,"Importing CVS squid3-ecap branch:

lib/Makefile.am
        Added libLtdl to SUBDIRS if USE_LOADABLE_MODULES.


src/ICAP/ICAPModXact.h
src/ICAP/ICAPServiceRep.h

        When USE_ECAP_AS_ICAP_HACK macro is defined, enable a temporary
        hack that uses ICAP class names to implement some of the eCAP
        classes. This is necessary to hide eCAP/ICAP distinction from
        Squid core. Hiding the distinction is necessary to avoid
        numerous conflicts when this branch is merged with async call
        branch changes.
        
        Once the branches are merged, the hack will be removed. Since
        we currently #define eCAP class names to match those of ICAP
        classes, the changes at that time should not be significant:
        remove renaming #defines and adjust autotools meta files to
        allow both ICAP and eCAP co-exist.



configure.in
src/Makefile.am

        Enable eCAP support if loadable module support is enabled.
        Eventually, we may want to control eCAP support directly.
        
        Added eCAP directory to the Makefile. The eCAP directory
        contents will be committed later.



SPONSORS
        Added eCAP sponsor.


src/Makefile.am
        When eCAP is enabled, to support USE_ECAP_AS_ICAP_HACK, ignore
        ICAP files that eCAP overwrites.


configure.in

        Added --enable-ecap option to control eCAP support explicitly.
        Added consistency checks for the combination of --enable-ecap,
        --enable-icap-client, and --disable-loadable-modules options.
        
        Define USE_ECAP_AS_ICAP_HACK macro to enable a temporary hack
        that uses ICAP class names to implement some of the eCAP
        classes. This is necessary to hide eCAP/ICAP distinction from
        Squid core. Hiding the distinction is necessary to avoid
        numerous conflicts when this branch is merged with async call
        branch changes.
        
        Once the branches are merged, the hack will be removed. Since
        we currently #define eCAP class names to match those of ICAP
        classes, the changes at that time should not be significant:
        remove renaming #defines and adjust autotools meta files to
        allow both ICAP and eCAP co-exist.



Makefile.am
acinclude.m4
bootstrap.sh
configure.in
src/Makefile.am

        Added basic support for Libtool ltdl. Libltdl directory is not
        committed yet because I want to investigate whether it can be
        moved from root to lib/. Bootstrap.sh currently strips a large
        copying file from that directory but does not attempt to move
        the directory itself.
        
        The configure options will need to be changed according to
        squid-dev discussion: we should assume that ltdl is always used
        if modules are used, and we should have a --disable-modules
        option.
        
        The code works with a dummy module: Squid was able to load and
        unload using LoadableModule, an ltdl wrapper class from Spicer.
        I have not committed that wrapper yet.

Makefile.am
bootstrap.sh
configure.in
src/Makefile.am

        Moved Libtool libltdl directory to lib/libLtdl to keep all
        3rd-party libs in one place. Will commit the lib/libLtdl
        directory itself soon.
        
        Bootstrap.sh currently moves all files from the generated
        libltdl into lib/libLtdl. A better approach may be to use the
        --ltdl option of libtoolize. Will investigate.
        
        Changed configure options to assume that ltdl is always used if
        modules are used.",48970,data/crawl/squid/hunk_4347.cpp,,,data/crawl/squid/old_hunk_4347.cpp,data/crawl/squid/new_hunk_4347.cpp,-1,1335,,"printf (""i386-sequent-dynix\n"");","[""addLog""]","[[], [""printf"", ""i386"", ""sequent"", ""dynix\\n""]]",[3173292423511830362],7416,2809080.0,4
https://github.com/squid-cache/squid/commit/3e7b6055489b13ca3faa9eef01b42a74971f84e4,20 Mar 2008,"Importing CVS squid3-ecap branch:

lib/Makefile.am
        Added libLtdl to SUBDIRS if USE_LOADABLE_MODULES.


src/ICAP/ICAPModXact.h
src/ICAP/ICAPServiceRep.h

        When USE_ECAP_AS_ICAP_HACK macro is defined, enable a temporary
        hack that uses ICAP class names to implement some of the eCAP
        classes. This is necessary to hide eCAP/ICAP distinction from
        Squid core. Hiding the distinction is necessary to avoid
        numerous conflicts when this branch is merged with async call
        branch changes.
        
        Once the branches are merged, the hack will be removed. Since
        we currently #define eCAP class names to match those of ICAP
        classes, the changes at that time should not be significant:
        remove renaming #defines and adjust autotools meta files to
        allow both ICAP and eCAP co-exist.



configure.in
src/Makefile.am

        Enable eCAP support if loadable module support is enabled.
        Eventually, we may want to control eCAP support directly.
        
        Added eCAP directory to the Makefile. The eCAP directory
        contents will be committed later.



SPONSORS
        Added eCAP sponsor.


src/Makefile.am
        When eCAP is enabled, to support USE_ECAP_AS_ICAP_HACK, ignore
        ICAP files that eCAP overwrites.


configure.in

        Added --enable-ecap option to control eCAP support explicitly.
        Added consistency checks for the combination of --enable-ecap,
        --enable-icap-client, and --disable-loadable-modules options.
        
        Define USE_ECAP_AS_ICAP_HACK macro to enable a temporary hack
        that uses ICAP class names to implement some of the eCAP
        classes. This is necessary to hide eCAP/ICAP distinction from
        Squid core. Hiding the distinction is necessary to avoid
        numerous conflicts when this branch is merged with async call
        branch changes.
        
        Once the branches are merged, the hack will be removed. Since
        we currently #define eCAP class names to match those of ICAP
        classes, the changes at that time should not be significant:
        remove renaming #defines and adjust autotools meta files to
        allow both ICAP and eCAP co-exist.



Makefile.am
acinclude.m4
bootstrap.sh
configure.in
src/Makefile.am

        Added basic support for Libtool ltdl. Libltdl directory is not
        committed yet because I want to investigate whether it can be
        moved from root to lib/. Bootstrap.sh currently strips a large
        copying file from that directory but does not attempt to move
        the directory itself.
        
        The configure options will need to be changed according to
        squid-dev discussion: we should assume that ltdl is always used
        if modules are used, and we should have a --disable-modules
        option.
        
        The code works with a dummy module: Squid was able to load and
        unload using LoadableModule, an ltdl wrapper class from Spicer.
        I have not committed that wrapper yet.

Makefile.am
bootstrap.sh
configure.in
src/Makefile.am

        Moved Libtool libltdl directory to lib/libLtdl to keep all
        3rd-party libs in one place. Will commit the lib/libLtdl
        directory itself soon.
        
        Bootstrap.sh currently moves all files from the generated
        libltdl into lib/libLtdl. A better approach may be to use the
        --ltdl option of libtoolize. Will investigate.
        
        Changed configure options to assume that ltdl is always used if
        modules are used.",48970,data/crawl/squid/hunk_4347.cpp,,,data/crawl/squid/old_hunk_4347.cpp,data/crawl/squid/new_hunk_4347.cpp,-1,1330,,"printf (""i386-pc-bsd\n"");","[""addLog""]","[[], [""printf"", ""i386"", ""pc"", ""bsd\\n""]]",[6236355447578103142],7415,2809080.0,4
https://github.com/squid-cache/squid/commit/3e7b6055489b13ca3faa9eef01b42a74971f84e4,20 Mar 2008,"Importing CVS squid3-ecap branch:

lib/Makefile.am
        Added libLtdl to SUBDIRS if USE_LOADABLE_MODULES.


src/ICAP/ICAPModXact.h
src/ICAP/ICAPServiceRep.h

        When USE_ECAP_AS_ICAP_HACK macro is defined, enable a temporary
        hack that uses ICAP class names to implement some of the eCAP
        classes. This is necessary to hide eCAP/ICAP distinction from
        Squid core. Hiding the distinction is necessary to avoid
        numerous conflicts when this branch is merged with async call
        branch changes.
        
        Once the branches are merged, the hack will be removed. Since
        we currently #define eCAP class names to match those of ICAP
        classes, the changes at that time should not be significant:
        remove renaming #defines and adjust autotools meta files to
        allow both ICAP and eCAP co-exist.



configure.in
src/Makefile.am

        Enable eCAP support if loadable module support is enabled.
        Eventually, we may want to control eCAP support directly.
        
        Added eCAP directory to the Makefile. The eCAP directory
        contents will be committed later.



SPONSORS
        Added eCAP sponsor.


src/Makefile.am
        When eCAP is enabled, to support USE_ECAP_AS_ICAP_HACK, ignore
        ICAP files that eCAP overwrites.


configure.in

        Added --enable-ecap option to control eCAP support explicitly.
        Added consistency checks for the combination of --enable-ecap,
        --enable-icap-client, and --disable-loadable-modules options.
        
        Define USE_ECAP_AS_ICAP_HACK macro to enable a temporary hack
        that uses ICAP class names to implement some of the eCAP
        classes. This is necessary to hide eCAP/ICAP distinction from
        Squid core. Hiding the distinction is necessary to avoid
        numerous conflicts when this branch is merged with async call
        branch changes.
        
        Once the branches are merged, the hack will be removed. Since
        we currently #define eCAP class names to match those of ICAP
        classes, the changes at that time should not be significant:
        remove renaming #defines and adjust autotools meta files to
        allow both ICAP and eCAP co-exist.



Makefile.am
acinclude.m4
bootstrap.sh
configure.in
src/Makefile.am

        Added basic support for Libtool ltdl. Libltdl directory is not
        committed yet because I want to investigate whether it can be
        moved from root to lib/. Bootstrap.sh currently strips a large
        copying file from that directory but does not attempt to move
        the directory itself.
        
        The configure options will need to be changed according to
        squid-dev discussion: we should assume that ltdl is always used
        if modules are used, and we should have a --disable-modules
        option.
        
        The code works with a dummy module: Squid was able to load and
        unload using LoadableModule, an ltdl wrapper class from Spicer.
        I have not committed that wrapper yet.

Makefile.am
bootstrap.sh
configure.in
src/Makefile.am

        Moved Libtool libltdl directory to lib/libLtdl to keep all
        3rd-party libs in one place. Will commit the lib/libLtdl
        directory itself soon.
        
        Bootstrap.sh currently moves all files from the generated
        libltdl into lib/libLtdl. A better approach may be to use the
        --ltdl option of libtoolize. Will investigate.
        
        Changed configure options to assume that ltdl is always used if
        modules are used.",48970,data/crawl/squid/hunk_4347.cpp,,,data/crawl/squid/old_hunk_4347.cpp,data/crawl/squid/new_hunk_4347.cpp,-1,1324,,"printf (""ns32k-encore-bsd\n"");","[""addLog""]","[[], [""printf"", ""ns32k"", ""encore"", ""bsd\\n""]]",[24666701257148115169],7414,2809080.0,4
https://github.com/squid-cache/squid/commit/3e7b6055489b13ca3faa9eef01b42a74971f84e4,20 Mar 2008,"Importing CVS squid3-ecap branch:

lib/Makefile.am
        Added libLtdl to SUBDIRS if USE_LOADABLE_MODULES.


src/ICAP/ICAPModXact.h
src/ICAP/ICAPServiceRep.h

        When USE_ECAP_AS_ICAP_HACK macro is defined, enable a temporary
        hack that uses ICAP class names to implement some of the eCAP
        classes. This is necessary to hide eCAP/ICAP distinction from
        Squid core. Hiding the distinction is necessary to avoid
        numerous conflicts when this branch is merged with async call
        branch changes.
        
        Once the branches are merged, the hack will be removed. Since
        we currently #define eCAP class names to match those of ICAP
        classes, the changes at that time should not be significant:
        remove renaming #defines and adjust autotools meta files to
        allow both ICAP and eCAP co-exist.



configure.in
src/Makefile.am

        Enable eCAP support if loadable module support is enabled.
        Eventually, we may want to control eCAP support directly.
        
        Added eCAP directory to the Makefile. The eCAP directory
        contents will be committed later.



SPONSORS
        Added eCAP sponsor.


src/Makefile.am
        When eCAP is enabled, to support USE_ECAP_AS_ICAP_HACK, ignore
        ICAP files that eCAP overwrites.


configure.in

        Added --enable-ecap option to control eCAP support explicitly.
        Added consistency checks for the combination of --enable-ecap,
        --enable-icap-client, and --disable-loadable-modules options.
        
        Define USE_ECAP_AS_ICAP_HACK macro to enable a temporary hack
        that uses ICAP class names to implement some of the eCAP
        classes. This is necessary to hide eCAP/ICAP distinction from
        Squid core. Hiding the distinction is necessary to avoid
        numerous conflicts when this branch is merged with async call
        branch changes.
        
        Once the branches are merged, the hack will be removed. Since
        we currently #define eCAP class names to match those of ICAP
        classes, the changes at that time should not be significant:
        remove renaming #defines and adjust autotools meta files to
        allow both ICAP and eCAP co-exist.



Makefile.am
acinclude.m4
bootstrap.sh
configure.in
src/Makefile.am

        Added basic support for Libtool ltdl. Libltdl directory is not
        committed yet because I want to investigate whether it can be
        moved from root to lib/. Bootstrap.sh currently strips a large
        copying file from that directory but does not attempt to move
        the directory itself.
        
        The configure options will need to be changed according to
        squid-dev discussion: we should assume that ltdl is always used
        if modules are used, and we should have a --disable-modules
        option.
        
        The code works with a dummy module: Squid was able to load and
        unload using LoadableModule, an ltdl wrapper class from Spicer.
        I have not committed that wrapper yet.

Makefile.am
bootstrap.sh
configure.in
src/Makefile.am

        Moved Libtool libltdl directory to lib/libLtdl to keep all
        3rd-party libs in one place. Will commit the lib/libLtdl
        directory itself soon.
        
        Bootstrap.sh currently moves all files from the generated
        libltdl into lib/libLtdl. A better approach may be to use the
        --ltdl option of libtoolize. Will investigate.
        
        Changed configure options to assume that ltdl is always used if
        modules are used.",48970,data/crawl/squid/hunk_4347.cpp,,,data/crawl/squid/old_hunk_4347.cpp,data/crawl/squid/new_hunk_4347.cpp,-1,1322,,"printf (""ns32k-encore-mach\n"");","[""addLog""]","[[], [""printf"", ""ns32k"", ""encore"", ""mach\\n""]]",[20799389516449904868],7413,2809080.0,4
https://github.com/squid-cache/squid/commit/3e7b6055489b13ca3faa9eef01b42a74971f84e4,20 Mar 2008,"Importing CVS squid3-ecap branch:

lib/Makefile.am
        Added libLtdl to SUBDIRS if USE_LOADABLE_MODULES.


src/ICAP/ICAPModXact.h
src/ICAP/ICAPServiceRep.h

        When USE_ECAP_AS_ICAP_HACK macro is defined, enable a temporary
        hack that uses ICAP class names to implement some of the eCAP
        classes. This is necessary to hide eCAP/ICAP distinction from
        Squid core. Hiding the distinction is necessary to avoid
        numerous conflicts when this branch is merged with async call
        branch changes.
        
        Once the branches are merged, the hack will be removed. Since
        we currently #define eCAP class names to match those of ICAP
        classes, the changes at that time should not be significant:
        remove renaming #defines and adjust autotools meta files to
        allow both ICAP and eCAP co-exist.



configure.in
src/Makefile.am

        Enable eCAP support if loadable module support is enabled.
        Eventually, we may want to control eCAP support directly.
        
        Added eCAP directory to the Makefile. The eCAP directory
        contents will be committed later.



SPONSORS
        Added eCAP sponsor.


src/Makefile.am
        When eCAP is enabled, to support USE_ECAP_AS_ICAP_HACK, ignore
        ICAP files that eCAP overwrites.


configure.in

        Added --enable-ecap option to control eCAP support explicitly.
        Added consistency checks for the combination of --enable-ecap,
        --enable-icap-client, and --disable-loadable-modules options.
        
        Define USE_ECAP_AS_ICAP_HACK macro to enable a temporary hack
        that uses ICAP class names to implement some of the eCAP
        classes. This is necessary to hide eCAP/ICAP distinction from
        Squid core. Hiding the distinction is necessary to avoid
        numerous conflicts when this branch is merged with async call
        branch changes.
        
        Once the branches are merged, the hack will be removed. Since
        we currently #define eCAP class names to match those of ICAP
        classes, the changes at that time should not be significant:
        remove renaming #defines and adjust autotools meta files to
        allow both ICAP and eCAP co-exist.



Makefile.am
acinclude.m4
bootstrap.sh
configure.in
src/Makefile.am

        Added basic support for Libtool ltdl. Libltdl directory is not
        committed yet because I want to investigate whether it can be
        moved from root to lib/. Bootstrap.sh currently strips a large
        copying file from that directory but does not attempt to move
        the directory itself.
        
        The configure options will need to be changed according to
        squid-dev discussion: we should assume that ltdl is always used
        if modules are used, and we should have a --disable-modules
        option.
        
        The code works with a dummy module: Squid was able to load and
        unload using LoadableModule, an ltdl wrapper class from Spicer.
        I have not committed that wrapper yet.

Makefile.am
bootstrap.sh
configure.in
src/Makefile.am

        Moved Libtool libltdl directory to lib/libLtdl to keep all
        3rd-party libs in one place. Will commit the lib/libLtdl
        directory itself soon.
        
        Bootstrap.sh currently moves all files from the generated
        libltdl into lib/libLtdl. A better approach may be to use the
        --ltdl option of libtoolize. Will investigate.
        
        Changed configure options to assume that ltdl is always used if
        modules are used.",48970,data/crawl/squid/hunk_4347.cpp,,,data/crawl/squid/old_hunk_4347.cpp,data/crawl/squid/new_hunk_4347.cpp,-1,1319,,"printf (""ns32k-encore-sysv\n"");","[""addLog""]","[[], [""printf"", ""ns32k"", ""encore"", ""sysv\\n""]]",[27225681863095121744],7412,2809080.0,4
https://github.com/squid-cache/squid/commit/3e7b6055489b13ca3faa9eef01b42a74971f84e4,20 Mar 2008,"Importing CVS squid3-ecap branch:

lib/Makefile.am
        Added libLtdl to SUBDIRS if USE_LOADABLE_MODULES.


src/ICAP/ICAPModXact.h
src/ICAP/ICAPServiceRep.h

        When USE_ECAP_AS_ICAP_HACK macro is defined, enable a temporary
        hack that uses ICAP class names to implement some of the eCAP
        classes. This is necessary to hide eCAP/ICAP distinction from
        Squid core. Hiding the distinction is necessary to avoid
        numerous conflicts when this branch is merged with async call
        branch changes.
        
        Once the branches are merged, the hack will be removed. Since
        we currently #define eCAP class names to match those of ICAP
        classes, the changes at that time should not be significant:
        remove renaming #defines and adjust autotools meta files to
        allow both ICAP and eCAP co-exist.



configure.in
src/Makefile.am

        Enable eCAP support if loadable module support is enabled.
        Eventually, we may want to control eCAP support directly.
        
        Added eCAP directory to the Makefile. The eCAP directory
        contents will be committed later.



SPONSORS
        Added eCAP sponsor.


src/Makefile.am
        When eCAP is enabled, to support USE_ECAP_AS_ICAP_HACK, ignore
        ICAP files that eCAP overwrites.


configure.in

        Added --enable-ecap option to control eCAP support explicitly.
        Added consistency checks for the combination of --enable-ecap,
        --enable-icap-client, and --disable-loadable-modules options.
        
        Define USE_ECAP_AS_ICAP_HACK macro to enable a temporary hack
        that uses ICAP class names to implement some of the eCAP
        classes. This is necessary to hide eCAP/ICAP distinction from
        Squid core. Hiding the distinction is necessary to avoid
        numerous conflicts when this branch is merged with async call
        branch changes.
        
        Once the branches are merged, the hack will be removed. Since
        we currently #define eCAP class names to match those of ICAP
        classes, the changes at that time should not be significant:
        remove renaming #defines and adjust autotools meta files to
        allow both ICAP and eCAP co-exist.



Makefile.am
acinclude.m4
bootstrap.sh
configure.in
src/Makefile.am

        Added basic support for Libtool ltdl. Libltdl directory is not
        committed yet because I want to investigate whether it can be
        moved from root to lib/. Bootstrap.sh currently strips a large
        copying file from that directory but does not attempt to move
        the directory itself.
        
        The configure options will need to be changed according to
        squid-dev discussion: we should assume that ltdl is always used
        if modules are used, and we should have a --disable-modules
        option.
        
        The code works with a dummy module: Squid was able to load and
        unload using LoadableModule, an ltdl wrapper class from Spicer.
        I have not committed that wrapper yet.

Makefile.am
bootstrap.sh
configure.in
src/Makefile.am

        Moved Libtool libltdl directory to lib/libLtdl to keep all
        3rd-party libs in one place. Will commit the lib/libLtdl
        directory itself soon.
        
        Bootstrap.sh currently moves all files from the generated
        libltdl into lib/libLtdl. A better approach may be to use the
        --ltdl option of libtoolize. Will investigate.
        
        Changed configure options to assume that ltdl is always used if
        modules are used.",48970,data/crawl/squid/hunk_4347.cpp,,,data/crawl/squid/old_hunk_4347.cpp,data/crawl/squid/new_hunk_4347.cpp,-1,1311,,"printf (""%s-next-nextstep%d\n"", __ARCHITECTURE__, version);","[""addLog""]","[[], [""printf"", ""%s"", ""next"", ""nextstep%d\\n"", ""__ARCHITECTURE__"", ""version""]]",[8971082284214367716],7411,2809080.0,4
https://github.com/squid-cache/squid/commit/3e7b6055489b13ca3faa9eef01b42a74971f84e4,20 Mar 2008,"Importing CVS squid3-ecap branch:

lib/Makefile.am
        Added libLtdl to SUBDIRS if USE_LOADABLE_MODULES.


src/ICAP/ICAPModXact.h
src/ICAP/ICAPServiceRep.h

        When USE_ECAP_AS_ICAP_HACK macro is defined, enable a temporary
        hack that uses ICAP class names to implement some of the eCAP
        classes. This is necessary to hide eCAP/ICAP distinction from
        Squid core. Hiding the distinction is necessary to avoid
        numerous conflicts when this branch is merged with async call
        branch changes.
        
        Once the branches are merged, the hack will be removed. Since
        we currently #define eCAP class names to match those of ICAP
        classes, the changes at that time should not be significant:
        remove renaming #defines and adjust autotools meta files to
        allow both ICAP and eCAP co-exist.



configure.in
src/Makefile.am

        Enable eCAP support if loadable module support is enabled.
        Eventually, we may want to control eCAP support directly.
        
        Added eCAP directory to the Makefile. The eCAP directory
        contents will be committed later.



SPONSORS
        Added eCAP sponsor.


src/Makefile.am
        When eCAP is enabled, to support USE_ECAP_AS_ICAP_HACK, ignore
        ICAP files that eCAP overwrites.


configure.in

        Added --enable-ecap option to control eCAP support explicitly.
        Added consistency checks for the combination of --enable-ecap,
        --enable-icap-client, and --disable-loadable-modules options.
        
        Define USE_ECAP_AS_ICAP_HACK macro to enable a temporary hack
        that uses ICAP class names to implement some of the eCAP
        classes. This is necessary to hide eCAP/ICAP distinction from
        Squid core. Hiding the distinction is necessary to avoid
        numerous conflicts when this branch is merged with async call
        branch changes.
        
        Once the branches are merged, the hack will be removed. Since
        we currently #define eCAP class names to match those of ICAP
        classes, the changes at that time should not be significant:
        remove renaming #defines and adjust autotools meta files to
        allow both ICAP and eCAP co-exist.



Makefile.am
acinclude.m4
bootstrap.sh
configure.in
src/Makefile.am

        Added basic support for Libtool ltdl. Libltdl directory is not
        committed yet because I want to investigate whether it can be
        moved from root to lib/. Bootstrap.sh currently strips a large
        copying file from that directory but does not attempt to move
        the directory itself.
        
        The configure options will need to be changed according to
        squid-dev discussion: we should assume that ltdl is always used
        if modules are used, and we should have a --disable-modules
        option.
        
        The code works with a dummy module: Squid was able to load and
        unload using LoadableModule, an ltdl wrapper class from Spicer.
        I have not committed that wrapper yet.

Makefile.am
bootstrap.sh
configure.in
src/Makefile.am

        Moved Libtool libltdl directory to lib/libLtdl to keep all
        3rd-party libs in one place. Will commit the lib/libLtdl
        directory itself soon.
        
        Bootstrap.sh currently moves all files from the generated
        libltdl into lib/libLtdl. A better approach may be to use the
        --ltdl option of libtoolize. Will investigate.
        
        Changed configure options to assume that ltdl is always used if
        modules are used.",48970,data/crawl/squid/hunk_4347.cpp,,,data/crawl/squid/old_hunk_4347.cpp,data/crawl/squid/new_hunk_4347.cpp,-1,1301,,"printf (""m68k-hp-bsd\n"");","[""addLog""]","[[], [""printf"", ""m68k"", ""hp"", ""bsd\\n""]]",[4406936890319637595],7410,2809080.0,4
https://github.com/squid-cache/squid/commit/3e7b6055489b13ca3faa9eef01b42a74971f84e4,20 Mar 2008,"Importing CVS squid3-ecap branch:

lib/Makefile.am
        Added libLtdl to SUBDIRS if USE_LOADABLE_MODULES.


src/ICAP/ICAPModXact.h
src/ICAP/ICAPServiceRep.h

        When USE_ECAP_AS_ICAP_HACK macro is defined, enable a temporary
        hack that uses ICAP class names to implement some of the eCAP
        classes. This is necessary to hide eCAP/ICAP distinction from
        Squid core. Hiding the distinction is necessary to avoid
        numerous conflicts when this branch is merged with async call
        branch changes.
        
        Once the branches are merged, the hack will be removed. Since
        we currently #define eCAP class names to match those of ICAP
        classes, the changes at that time should not be significant:
        remove renaming #defines and adjust autotools meta files to
        allow both ICAP and eCAP co-exist.



configure.in
src/Makefile.am

        Enable eCAP support if loadable module support is enabled.
        Eventually, we may want to control eCAP support directly.
        
        Added eCAP directory to the Makefile. The eCAP directory
        contents will be committed later.



SPONSORS
        Added eCAP sponsor.


src/Makefile.am
        When eCAP is enabled, to support USE_ECAP_AS_ICAP_HACK, ignore
        ICAP files that eCAP overwrites.


configure.in

        Added --enable-ecap option to control eCAP support explicitly.
        Added consistency checks for the combination of --enable-ecap,
        --enable-icap-client, and --disable-loadable-modules options.
        
        Define USE_ECAP_AS_ICAP_HACK macro to enable a temporary hack
        that uses ICAP class names to implement some of the eCAP
        classes. This is necessary to hide eCAP/ICAP distinction from
        Squid core. Hiding the distinction is necessary to avoid
        numerous conflicts when this branch is merged with async call
        branch changes.
        
        Once the branches are merged, the hack will be removed. Since
        we currently #define eCAP class names to match those of ICAP
        classes, the changes at that time should not be significant:
        remove renaming #defines and adjust autotools meta files to
        allow both ICAP and eCAP co-exist.



Makefile.am
acinclude.m4
bootstrap.sh
configure.in
src/Makefile.am

        Added basic support for Libtool ltdl. Libltdl directory is not
        committed yet because I want to investigate whether it can be
        moved from root to lib/. Bootstrap.sh currently strips a large
        copying file from that directory but does not attempt to move
        the directory itself.
        
        The configure options will need to be changed according to
        squid-dev discussion: we should assume that ltdl is always used
        if modules are used, and we should have a --disable-modules
        option.
        
        The code works with a dummy module: Squid was able to load and
        unload using LoadableModule, an ltdl wrapper class from Spicer.
        I have not committed that wrapper yet.

Makefile.am
bootstrap.sh
configure.in
src/Makefile.am

        Moved Libtool libltdl directory to lib/libLtdl to keep all
        3rd-party libs in one place. Will commit the lib/libLtdl
        directory itself soon.
        
        Bootstrap.sh currently moves all files from the generated
        libltdl into lib/libLtdl. A better approach may be to use the
        --ltdl option of libtoolize. Will investigate.
        
        Changed configure options to assume that ltdl is always used if
        modules are used.",48970,data/crawl/squid/hunk_4347.cpp,,,data/crawl/squid/old_hunk_4347.cpp,data/crawl/squid/new_hunk_4347.cpp,-1,1286,,"printf (""m68k-sony-newsos%s\n"",
#ifdef NEWSOS4
          ""4""
#else
	  """"
#endif
         );","[""addLog""]","[[], [""printf"", ""m68k"", ""sony"", ""newsos%s\\n"", ""ifdef"", ""NEWSOS4"", ""4"", ""else"", ""endif""]]",[-11037806279510753175],7409,2809080.0,4
https://github.com/squid-cache/squid/commit/3e7b6055489b13ca3faa9eef01b42a74971f84e4,20 Mar 2008,"Importing CVS squid3-ecap branch:

lib/Makefile.am
        Added libLtdl to SUBDIRS if USE_LOADABLE_MODULES.


src/ICAP/ICAPModXact.h
src/ICAP/ICAPServiceRep.h

        When USE_ECAP_AS_ICAP_HACK macro is defined, enable a temporary
        hack that uses ICAP class names to implement some of the eCAP
        classes. This is necessary to hide eCAP/ICAP distinction from
        Squid core. Hiding the distinction is necessary to avoid
        numerous conflicts when this branch is merged with async call
        branch changes.
        
        Once the branches are merged, the hack will be removed. Since
        we currently #define eCAP class names to match those of ICAP
        classes, the changes at that time should not be significant:
        remove renaming #defines and adjust autotools meta files to
        allow both ICAP and eCAP co-exist.



configure.in
src/Makefile.am

        Enable eCAP support if loadable module support is enabled.
        Eventually, we may want to control eCAP support directly.
        
        Added eCAP directory to the Makefile. The eCAP directory
        contents will be committed later.



SPONSORS
        Added eCAP sponsor.


src/Makefile.am
        When eCAP is enabled, to support USE_ECAP_AS_ICAP_HACK, ignore
        ICAP files that eCAP overwrites.


configure.in

        Added --enable-ecap option to control eCAP support explicitly.
        Added consistency checks for the combination of --enable-ecap,
        --enable-icap-client, and --disable-loadable-modules options.
        
        Define USE_ECAP_AS_ICAP_HACK macro to enable a temporary hack
        that uses ICAP class names to implement some of the eCAP
        classes. This is necessary to hide eCAP/ICAP distinction from
        Squid core. Hiding the distinction is necessary to avoid
        numerous conflicts when this branch is merged with async call
        branch changes.
        
        Once the branches are merged, the hack will be removed. Since
        we currently #define eCAP class names to match those of ICAP
        classes, the changes at that time should not be significant:
        remove renaming #defines and adjust autotools meta files to
        allow both ICAP and eCAP co-exist.



Makefile.am
acinclude.m4
bootstrap.sh
configure.in
src/Makefile.am

        Added basic support for Libtool ltdl. Libltdl directory is not
        committed yet because I want to investigate whether it can be
        moved from root to lib/. Bootstrap.sh currently strips a large
        copying file from that directory but does not attempt to move
        the directory itself.
        
        The configure options will need to be changed according to
        squid-dev discussion: we should assume that ltdl is always used
        if modules are used, and we should have a --disable-modules
        option.
        
        The code works with a dummy module: Squid was able to load and
        unload using LoadableModule, an ltdl wrapper class from Spicer.
        I have not committed that wrapper yet.

Makefile.am
bootstrap.sh
configure.in
src/Makefile.am

        Moved Libtool libltdl directory to lib/libLtdl to keep all
        3rd-party libs in one place. Will commit the lib/libLtdl
        directory itself soon.
        
        Bootstrap.sh currently moves all files from the generated
        libltdl into lib/libLtdl. A better approach may be to use the
        --ltdl option of libtoolize. Will investigate.
        
        Changed configure options to assume that ltdl is always used if
        modules are used.",48970,data/crawl/squid/hunk_4347.cpp,,,data/crawl/squid/old_hunk_4347.cpp,data/crawl/squid/new_hunk_4347.cpp,-1,673,,"puts (""unknown-hitachi-hiuxwe2"");","[""addLog""]","[[], [""puts"", ""unknown"", ""hitachi"", ""hiuxwe2""]]",[16275653397761100143],7408,2809080.0,4
https://github.com/squid-cache/squid/commit/3e7b6055489b13ca3faa9eef01b42a74971f84e4,20 Mar 2008,"Importing CVS squid3-ecap branch:

lib/Makefile.am
        Added libLtdl to SUBDIRS if USE_LOADABLE_MODULES.


src/ICAP/ICAPModXact.h
src/ICAP/ICAPServiceRep.h

        When USE_ECAP_AS_ICAP_HACK macro is defined, enable a temporary
        hack that uses ICAP class names to implement some of the eCAP
        classes. This is necessary to hide eCAP/ICAP distinction from
        Squid core. Hiding the distinction is necessary to avoid
        numerous conflicts when this branch is merged with async call
        branch changes.
        
        Once the branches are merged, the hack will be removed. Since
        we currently #define eCAP class names to match those of ICAP
        classes, the changes at that time should not be significant:
        remove renaming #defines and adjust autotools meta files to
        allow both ICAP and eCAP co-exist.



configure.in
src/Makefile.am

        Enable eCAP support if loadable module support is enabled.
        Eventually, we may want to control eCAP support directly.
        
        Added eCAP directory to the Makefile. The eCAP directory
        contents will be committed later.



SPONSORS
        Added eCAP sponsor.


src/Makefile.am
        When eCAP is enabled, to support USE_ECAP_AS_ICAP_HACK, ignore
        ICAP files that eCAP overwrites.


configure.in

        Added --enable-ecap option to control eCAP support explicitly.
        Added consistency checks for the combination of --enable-ecap,
        --enable-icap-client, and --disable-loadable-modules options.
        
        Define USE_ECAP_AS_ICAP_HACK macro to enable a temporary hack
        that uses ICAP class names to implement some of the eCAP
        classes. This is necessary to hide eCAP/ICAP distinction from
        Squid core. Hiding the distinction is necessary to avoid
        numerous conflicts when this branch is merged with async call
        branch changes.
        
        Once the branches are merged, the hack will be removed. Since
        we currently #define eCAP class names to match those of ICAP
        classes, the changes at that time should not be significant:
        remove renaming #defines and adjust autotools meta files to
        allow both ICAP and eCAP co-exist.



Makefile.am
acinclude.m4
bootstrap.sh
configure.in
src/Makefile.am

        Added basic support for Libtool ltdl. Libltdl directory is not
        committed yet because I want to investigate whether it can be
        moved from root to lib/. Bootstrap.sh currently strips a large
        copying file from that directory but does not attempt to move
        the directory itself.
        
        The configure options will need to be changed according to
        squid-dev discussion: we should assume that ltdl is always used
        if modules are used, and we should have a --disable-modules
        option.
        
        The code works with a dummy module: Squid was able to load and
        unload using LoadableModule, an ltdl wrapper class from Spicer.
        I have not committed that wrapper yet.

Makefile.am
bootstrap.sh
configure.in
src/Makefile.am

        Moved Libtool libltdl directory to lib/libLtdl to keep all
        3rd-party libs in one place. Will commit the lib/libLtdl
        directory itself soon.
        
        Bootstrap.sh currently moves all files from the generated
        libltdl into lib/libLtdl. A better approach may be to use the
        --ltdl option of libtoolize. Will investigate.
        
        Changed configure options to assume that ltdl is always used if
        modules are used.",48970,data/crawl/squid/hunk_4347.cpp,,,data/crawl/squid/old_hunk_4347.cpp,data/crawl/squid/new_hunk_4347.cpp,-1,672,,"puts (""m68k-hitachi-hiuxwe2"");","[""addLog""]","[[], [""puts"", ""m68k"", ""hitachi"", ""hiuxwe2""]]",[12535257479151834420],7407,2809080.0,4
https://github.com/squid-cache/squid/commit/3e7b6055489b13ca3faa9eef01b42a74971f84e4,20 Mar 2008,"Importing CVS squid3-ecap branch:

lib/Makefile.am
        Added libLtdl to SUBDIRS if USE_LOADABLE_MODULES.


src/ICAP/ICAPModXact.h
src/ICAP/ICAPServiceRep.h

        When USE_ECAP_AS_ICAP_HACK macro is defined, enable a temporary
        hack that uses ICAP class names to implement some of the eCAP
        classes. This is necessary to hide eCAP/ICAP distinction from
        Squid core. Hiding the distinction is necessary to avoid
        numerous conflicts when this branch is merged with async call
        branch changes.
        
        Once the branches are merged, the hack will be removed. Since
        we currently #define eCAP class names to match those of ICAP
        classes, the changes at that time should not be significant:
        remove renaming #defines and adjust autotools meta files to
        allow both ICAP and eCAP co-exist.



configure.in
src/Makefile.am

        Enable eCAP support if loadable module support is enabled.
        Eventually, we may want to control eCAP support directly.
        
        Added eCAP directory to the Makefile. The eCAP directory
        contents will be committed later.



SPONSORS
        Added eCAP sponsor.


src/Makefile.am
        When eCAP is enabled, to support USE_ECAP_AS_ICAP_HACK, ignore
        ICAP files that eCAP overwrites.


configure.in

        Added --enable-ecap option to control eCAP support explicitly.
        Added consistency checks for the combination of --enable-ecap,
        --enable-icap-client, and --disable-loadable-modules options.
        
        Define USE_ECAP_AS_ICAP_HACK macro to enable a temporary hack
        that uses ICAP class names to implement some of the eCAP
        classes. This is necessary to hide eCAP/ICAP distinction from
        Squid core. Hiding the distinction is necessary to avoid
        numerous conflicts when this branch is merged with async call
        branch changes.
        
        Once the branches are merged, the hack will be removed. Since
        we currently #define eCAP class names to match those of ICAP
        classes, the changes at that time should not be significant:
        remove renaming #defines and adjust autotools meta files to
        allow both ICAP and eCAP co-exist.



Makefile.am
acinclude.m4
bootstrap.sh
configure.in
src/Makefile.am

        Added basic support for Libtool ltdl. Libltdl directory is not
        committed yet because I want to investigate whether it can be
        moved from root to lib/. Bootstrap.sh currently strips a large
        copying file from that directory but does not attempt to move
        the directory itself.
        
        The configure options will need to be changed according to
        squid-dev discussion: we should assume that ltdl is always used
        if modules are used, and we should have a --disable-modules
        option.
        
        The code works with a dummy module: Squid was able to load and
        unload using LoadableModule, an ltdl wrapper class from Spicer.
        I have not committed that wrapper yet.

Makefile.am
bootstrap.sh
configure.in
src/Makefile.am

        Moved Libtool libltdl directory to lib/libLtdl to keep all
        3rd-party libs in one place. Will commit the lib/libLtdl
        directory itself soon.
        
        Bootstrap.sh currently moves all files from the generated
        libltdl into lib/libLtdl. A better approach may be to use the
        --ltdl option of libtoolize. Will investigate.
        
        Changed configure options to assume that ltdl is always used if
        modules are used.",48970,data/crawl/squid/hunk_4347.cpp,,,data/crawl/squid/old_hunk_4347.cpp,data/crawl/squid/new_hunk_4347.cpp,-1,668,,"puts (""hppa-hitachi-hiuxwe2"");","[""addLog""]","[[], [""puts"", ""hppa"", ""hitachi"", ""hiuxwe2""]]",[28655898973806569187],7406,2809080.0,4
https://github.com/squid-cache/squid/commit/3e7b6055489b13ca3faa9eef01b42a74971f84e4,20 Mar 2008,"Importing CVS squid3-ecap branch:

lib/Makefile.am
        Added libLtdl to SUBDIRS if USE_LOADABLE_MODULES.


src/ICAP/ICAPModXact.h
src/ICAP/ICAPServiceRep.h

        When USE_ECAP_AS_ICAP_HACK macro is defined, enable a temporary
        hack that uses ICAP class names to implement some of the eCAP
        classes. This is necessary to hide eCAP/ICAP distinction from
        Squid core. Hiding the distinction is necessary to avoid
        numerous conflicts when this branch is merged with async call
        branch changes.
        
        Once the branches are merged, the hack will be removed. Since
        we currently #define eCAP class names to match those of ICAP
        classes, the changes at that time should not be significant:
        remove renaming #defines and adjust autotools meta files to
        allow both ICAP and eCAP co-exist.



configure.in
src/Makefile.am

        Enable eCAP support if loadable module support is enabled.
        Eventually, we may want to control eCAP support directly.
        
        Added eCAP directory to the Makefile. The eCAP directory
        contents will be committed later.



SPONSORS
        Added eCAP sponsor.


src/Makefile.am
        When eCAP is enabled, to support USE_ECAP_AS_ICAP_HACK, ignore
        ICAP files that eCAP overwrites.


configure.in

        Added --enable-ecap option to control eCAP support explicitly.
        Added consistency checks for the combination of --enable-ecap,
        --enable-icap-client, and --disable-loadable-modules options.
        
        Define USE_ECAP_AS_ICAP_HACK macro to enable a temporary hack
        that uses ICAP class names to implement some of the eCAP
        classes. This is necessary to hide eCAP/ICAP distinction from
        Squid core. Hiding the distinction is necessary to avoid
        numerous conflicts when this branch is merged with async call
        branch changes.
        
        Once the branches are merged, the hack will be removed. Since
        we currently #define eCAP class names to match those of ICAP
        classes, the changes at that time should not be significant:
        remove renaming #defines and adjust autotools meta files to
        allow both ICAP and eCAP co-exist.



Makefile.am
acinclude.m4
bootstrap.sh
configure.in
src/Makefile.am

        Added basic support for Libtool ltdl. Libltdl directory is not
        committed yet because I want to investigate whether it can be
        moved from root to lib/. Bootstrap.sh currently strips a large
        copying file from that directory but does not attempt to move
        the directory itself.
        
        The configure options will need to be changed according to
        squid-dev discussion: we should assume that ltdl is always used
        if modules are used, and we should have a --disable-modules
        option.
        
        The code works with a dummy module: Squid was able to load and
        unload using LoadableModule, an ltdl wrapper class from Spicer.
        I have not committed that wrapper yet.

Makefile.am
bootstrap.sh
configure.in
src/Makefile.am

        Moved Libtool libltdl directory to lib/libLtdl to keep all
        3rd-party libs in one place. Will commit the lib/libLtdl
        directory itself soon.
        
        Bootstrap.sh currently moves all files from the generated
        libltdl into lib/libLtdl. A better approach may be to use the
        --ltdl option of libtoolize. Will investigate.
        
        Changed configure options to assume that ltdl is always used if
        modules are used.",48970,data/crawl/squid/hunk_4347.cpp,,,data/crawl/squid/old_hunk_4347.cpp,data/crawl/squid/new_hunk_4347.cpp,-1,667,,"puts (""hppa2.0-hitachi-hiuxwe2"");","[""addLog""]","[[], [""puts"", ""hppa2"", ""0"", ""hitachi"", ""hiuxwe2""]]",[19143513846723492019],7405,2809080.0,4
https://github.com/squid-cache/squid/commit/3e7b6055489b13ca3faa9eef01b42a74971f84e4,20 Mar 2008,"Importing CVS squid3-ecap branch:

lib/Makefile.am
        Added libLtdl to SUBDIRS if USE_LOADABLE_MODULES.


src/ICAP/ICAPModXact.h
src/ICAP/ICAPServiceRep.h

        When USE_ECAP_AS_ICAP_HACK macro is defined, enable a temporary
        hack that uses ICAP class names to implement some of the eCAP
        classes. This is necessary to hide eCAP/ICAP distinction from
        Squid core. Hiding the distinction is necessary to avoid
        numerous conflicts when this branch is merged with async call
        branch changes.
        
        Once the branches are merged, the hack will be removed. Since
        we currently #define eCAP class names to match those of ICAP
        classes, the changes at that time should not be significant:
        remove renaming #defines and adjust autotools meta files to
        allow both ICAP and eCAP co-exist.



configure.in
src/Makefile.am

        Enable eCAP support if loadable module support is enabled.
        Eventually, we may want to control eCAP support directly.
        
        Added eCAP directory to the Makefile. The eCAP directory
        contents will be committed later.



SPONSORS
        Added eCAP sponsor.


src/Makefile.am
        When eCAP is enabled, to support USE_ECAP_AS_ICAP_HACK, ignore
        ICAP files that eCAP overwrites.


configure.in

        Added --enable-ecap option to control eCAP support explicitly.
        Added consistency checks for the combination of --enable-ecap,
        --enable-icap-client, and --disable-loadable-modules options.
        
        Define USE_ECAP_AS_ICAP_HACK macro to enable a temporary hack
        that uses ICAP class names to implement some of the eCAP
        classes. This is necessary to hide eCAP/ICAP distinction from
        Squid core. Hiding the distinction is necessary to avoid
        numerous conflicts when this branch is merged with async call
        branch changes.
        
        Once the branches are merged, the hack will be removed. Since
        we currently #define eCAP class names to match those of ICAP
        classes, the changes at that time should not be significant:
        remove renaming #defines and adjust autotools meta files to
        allow both ICAP and eCAP co-exist.



Makefile.am
acinclude.m4
bootstrap.sh
configure.in
src/Makefile.am

        Added basic support for Libtool ltdl. Libltdl directory is not
        committed yet because I want to investigate whether it can be
        moved from root to lib/. Bootstrap.sh currently strips a large
        copying file from that directory but does not attempt to move
        the directory itself.
        
        The configure options will need to be changed according to
        squid-dev discussion: we should assume that ltdl is always used
        if modules are used, and we should have a --disable-modules
        option.
        
        The code works with a dummy module: Squid was able to load and
        unload using LoadableModule, an ltdl wrapper class from Spicer.
        I have not committed that wrapper yet.

Makefile.am
bootstrap.sh
configure.in
src/Makefile.am

        Moved Libtool libltdl directory to lib/libLtdl to keep all
        3rd-party libs in one place. Will commit the lib/libLtdl
        directory itself soon.
        
        Bootstrap.sh currently moves all files from the generated
        libltdl into lib/libLtdl. A better approach may be to use the
        --ltdl option of libtoolize. Will investigate.
        
        Changed configure options to assume that ltdl is always used if
        modules are used.",48970,data/crawl/squid/hunk_4347.cpp,,,data/crawl/squid/old_hunk_4347.cpp,data/crawl/squid/new_hunk_4347.cpp,-1,666,,"puts (""hppa1.1-hitachi-hiuxwe2"");","[""addLog""]","[[], [""puts"", ""hppa1"", ""1"", ""hitachi"", ""hiuxwe2""]]",[19143513846851492405],7404,2809080.0,4
https://github.com/squid-cache/squid/commit/3e7b6055489b13ca3faa9eef01b42a74971f84e4,20 Mar 2008,"Importing CVS squid3-ecap branch:

lib/Makefile.am
        Added libLtdl to SUBDIRS if USE_LOADABLE_MODULES.


src/ICAP/ICAPModXact.h
src/ICAP/ICAPServiceRep.h

        When USE_ECAP_AS_ICAP_HACK macro is defined, enable a temporary
        hack that uses ICAP class names to implement some of the eCAP
        classes. This is necessary to hide eCAP/ICAP distinction from
        Squid core. Hiding the distinction is necessary to avoid
        numerous conflicts when this branch is merged with async call
        branch changes.
        
        Once the branches are merged, the hack will be removed. Since
        we currently #define eCAP class names to match those of ICAP
        classes, the changes at that time should not be significant:
        remove renaming #defines and adjust autotools meta files to
        allow both ICAP and eCAP co-exist.



configure.in
src/Makefile.am

        Enable eCAP support if loadable module support is enabled.
        Eventually, we may want to control eCAP support directly.
        
        Added eCAP directory to the Makefile. The eCAP directory
        contents will be committed later.



SPONSORS
        Added eCAP sponsor.


src/Makefile.am
        When eCAP is enabled, to support USE_ECAP_AS_ICAP_HACK, ignore
        ICAP files that eCAP overwrites.


configure.in

        Added --enable-ecap option to control eCAP support explicitly.
        Added consistency checks for the combination of --enable-ecap,
        --enable-icap-client, and --disable-loadable-modules options.
        
        Define USE_ECAP_AS_ICAP_HACK macro to enable a temporary hack
        that uses ICAP class names to implement some of the eCAP
        classes. This is necessary to hide eCAP/ICAP distinction from
        Squid core. Hiding the distinction is necessary to avoid
        numerous conflicts when this branch is merged with async call
        branch changes.
        
        Once the branches are merged, the hack will be removed. Since
        we currently #define eCAP class names to match those of ICAP
        classes, the changes at that time should not be significant:
        remove renaming #defines and adjust autotools meta files to
        allow both ICAP and eCAP co-exist.



Makefile.am
acinclude.m4
bootstrap.sh
configure.in
src/Makefile.am

        Added basic support for Libtool ltdl. Libltdl directory is not
        committed yet because I want to investigate whether it can be
        moved from root to lib/. Bootstrap.sh currently strips a large
        copying file from that directory but does not attempt to move
        the directory itself.
        
        The configure options will need to be changed according to
        squid-dev discussion: we should assume that ltdl is always used
        if modules are used, and we should have a --disable-modules
        option.
        
        The code works with a dummy module: Squid was able to load and
        unload using LoadableModule, an ltdl wrapper class from Spicer.
        I have not committed that wrapper yet.

Makefile.am
bootstrap.sh
configure.in
src/Makefile.am

        Moved Libtool libltdl directory to lib/libLtdl to keep all
        3rd-party libs in one place. Will commit the lib/libLtdl
        directory itself soon.
        
        Bootstrap.sh currently moves all files from the generated
        libltdl into lib/libLtdl. A better approach may be to use the
        --ltdl option of libtoolize. Will investigate.
        
        Changed configure options to assume that ltdl is always used if
        modules are used.",48970,data/crawl/squid/hunk_4347.cpp,,,data/crawl/squid/old_hunk_4347.cpp,data/crawl/squid/new_hunk_4347.cpp,-1,665,,"puts (""hppa1.0-hitachi-hiuxwe2"");","[""addLog""]","[[], [""puts"", ""hppa1"", ""0"", ""hitachi"", ""hiuxwe2""]]",[19143513846723492022],7403,2809080.0,4
https://github.com/squid-cache/squid/commit/3e7b6055489b13ca3faa9eef01b42a74971f84e4,20 Mar 2008,"Importing CVS squid3-ecap branch:

lib/Makefile.am
        Added libLtdl to SUBDIRS if USE_LOADABLE_MODULES.


src/ICAP/ICAPModXact.h
src/ICAP/ICAPServiceRep.h

        When USE_ECAP_AS_ICAP_HACK macro is defined, enable a temporary
        hack that uses ICAP class names to implement some of the eCAP
        classes. This is necessary to hide eCAP/ICAP distinction from
        Squid core. Hiding the distinction is necessary to avoid
        numerous conflicts when this branch is merged with async call
        branch changes.
        
        Once the branches are merged, the hack will be removed. Since
        we currently #define eCAP class names to match those of ICAP
        classes, the changes at that time should not be significant:
        remove renaming #defines and adjust autotools meta files to
        allow both ICAP and eCAP co-exist.



configure.in
src/Makefile.am

        Enable eCAP support if loadable module support is enabled.
        Eventually, we may want to control eCAP support directly.
        
        Added eCAP directory to the Makefile. The eCAP directory
        contents will be committed later.



SPONSORS
        Added eCAP sponsor.


src/Makefile.am
        When eCAP is enabled, to support USE_ECAP_AS_ICAP_HACK, ignore
        ICAP files that eCAP overwrites.


configure.in

        Added --enable-ecap option to control eCAP support explicitly.
        Added consistency checks for the combination of --enable-ecap,
        --enable-icap-client, and --disable-loadable-modules options.
        
        Define USE_ECAP_AS_ICAP_HACK macro to enable a temporary hack
        that uses ICAP class names to implement some of the eCAP
        classes. This is necessary to hide eCAP/ICAP distinction from
        Squid core. Hiding the distinction is necessary to avoid
        numerous conflicts when this branch is merged with async call
        branch changes.
        
        Once the branches are merged, the hack will be removed. Since
        we currently #define eCAP class names to match those of ICAP
        classes, the changes at that time should not be significant:
        remove renaming #defines and adjust autotools meta files to
        allow both ICAP and eCAP co-exist.



Makefile.am
acinclude.m4
bootstrap.sh
configure.in
src/Makefile.am

        Added basic support for Libtool ltdl. Libltdl directory is not
        committed yet because I want to investigate whether it can be
        moved from root to lib/. Bootstrap.sh currently strips a large
        copying file from that directory but does not attempt to move
        the directory itself.
        
        The configure options will need to be changed according to
        squid-dev discussion: we should assume that ltdl is always used
        if modules are used, and we should have a --disable-modules
        option.
        
        The code works with a dummy module: Squid was able to load and
        unload using LoadableModule, an ltdl wrapper class from Spicer.
        I have not committed that wrapper yet.

Makefile.am
bootstrap.sh
configure.in
src/Makefile.am

        Moved Libtool libltdl directory to lib/libLtdl to keep all
        3rd-party libs in one place. Will commit the lib/libLtdl
        directory itself soon.
        
        Bootstrap.sh currently moves all files from the generated
        libltdl into lib/libLtdl. A better approach may be to use the
        --ltdl option of libtoolize. Will investigate.
        
        Changed configure options to assume that ltdl is always used if
        modules are used.",48970,data/crawl/squid/hunk_4347.cpp,,,data/crawl/squid/old_hunk_4347.cpp,data/crawl/squid/new_hunk_4347.cpp,-1,513,,"puts(""powerpc-ibm-aix3.2.5"");","[""addLog""]","[[], [""puts"", ""powerpc"", ""ibm"", ""aix3"", ""2"", ""5""]]",[-2767682009957926458],7402,2809080.0,4
https://github.com/squid-cache/squid/commit/3e7b6055489b13ca3faa9eef01b42a74971f84e4,20 Mar 2008,"Importing CVS squid3-ecap branch:

lib/Makefile.am
        Added libLtdl to SUBDIRS if USE_LOADABLE_MODULES.


src/ICAP/ICAPModXact.h
src/ICAP/ICAPServiceRep.h

        When USE_ECAP_AS_ICAP_HACK macro is defined, enable a temporary
        hack that uses ICAP class names to implement some of the eCAP
        classes. This is necessary to hide eCAP/ICAP distinction from
        Squid core. Hiding the distinction is necessary to avoid
        numerous conflicts when this branch is merged with async call
        branch changes.
        
        Once the branches are merged, the hack will be removed. Since
        we currently #define eCAP class names to match those of ICAP
        classes, the changes at that time should not be significant:
        remove renaming #defines and adjust autotools meta files to
        allow both ICAP and eCAP co-exist.



configure.in
src/Makefile.am

        Enable eCAP support if loadable module support is enabled.
        Eventually, we may want to control eCAP support directly.
        
        Added eCAP directory to the Makefile. The eCAP directory
        contents will be committed later.



SPONSORS
        Added eCAP sponsor.


src/Makefile.am
        When eCAP is enabled, to support USE_ECAP_AS_ICAP_HACK, ignore
        ICAP files that eCAP overwrites.


configure.in

        Added --enable-ecap option to control eCAP support explicitly.
        Added consistency checks for the combination of --enable-ecap,
        --enable-icap-client, and --disable-loadable-modules options.
        
        Define USE_ECAP_AS_ICAP_HACK macro to enable a temporary hack
        that uses ICAP class names to implement some of the eCAP
        classes. This is necessary to hide eCAP/ICAP distinction from
        Squid core. Hiding the distinction is necessary to avoid
        numerous conflicts when this branch is merged with async call
        branch changes.
        
        Once the branches are merged, the hack will be removed. Since
        we currently #define eCAP class names to match those of ICAP
        classes, the changes at that time should not be significant:
        remove renaming #defines and adjust autotools meta files to
        allow both ICAP and eCAP co-exist.



Makefile.am
acinclude.m4
bootstrap.sh
configure.in
src/Makefile.am

        Added basic support for Libtool ltdl. Libltdl directory is not
        committed yet because I want to investigate whether it can be
        moved from root to lib/. Bootstrap.sh currently strips a large
        copying file from that directory but does not attempt to move
        the directory itself.
        
        The configure options will need to be changed according to
        squid-dev discussion: we should assume that ltdl is always used
        if modules are used, and we should have a --disable-modules
        option.
        
        The code works with a dummy module: Squid was able to load and
        unload using LoadableModule, an ltdl wrapper class from Spicer.
        I have not committed that wrapper yet.

Makefile.am
bootstrap.sh
configure.in
src/Makefile.am

        Moved Libtool libltdl directory to lib/libLtdl to keep all
        3rd-party libs in one place. Will commit the lib/libLtdl
        directory itself soon.
        
        Bootstrap.sh currently moves all files from the generated
        libltdl into lib/libLtdl. A better approach may be to use the
        --ltdl option of libtoolize. Will investigate.
        
        Changed configure options to assume that ltdl is always used if
        modules are used.",48970,data/crawl/squid/hunk_4347.cpp,,,data/crawl/squid/old_hunk_4347.cpp,data/crawl/squid/new_hunk_4347.cpp,-1,424,,"printf (""mips-mips-riscos%sbsd\n"", argv[1]);","[""addLog""]","[[], [""printf"", ""mips"", ""mips"", ""riscos%sbsd\\n"", ""argv[1]""]]",[-12615113043110249714],7401,2809080.0,4
https://github.com/squid-cache/squid/commit/3e7b6055489b13ca3faa9eef01b42a74971f84e4,20 Mar 2008,"Importing CVS squid3-ecap branch:

lib/Makefile.am
        Added libLtdl to SUBDIRS if USE_LOADABLE_MODULES.


src/ICAP/ICAPModXact.h
src/ICAP/ICAPServiceRep.h

        When USE_ECAP_AS_ICAP_HACK macro is defined, enable a temporary
        hack that uses ICAP class names to implement some of the eCAP
        classes. This is necessary to hide eCAP/ICAP distinction from
        Squid core. Hiding the distinction is necessary to avoid
        numerous conflicts when this branch is merged with async call
        branch changes.
        
        Once the branches are merged, the hack will be removed. Since
        we currently #define eCAP class names to match those of ICAP
        classes, the changes at that time should not be significant:
        remove renaming #defines and adjust autotools meta files to
        allow both ICAP and eCAP co-exist.



configure.in
src/Makefile.am

        Enable eCAP support if loadable module support is enabled.
        Eventually, we may want to control eCAP support directly.
        
        Added eCAP directory to the Makefile. The eCAP directory
        contents will be committed later.



SPONSORS
        Added eCAP sponsor.


src/Makefile.am
        When eCAP is enabled, to support USE_ECAP_AS_ICAP_HACK, ignore
        ICAP files that eCAP overwrites.


configure.in

        Added --enable-ecap option to control eCAP support explicitly.
        Added consistency checks for the combination of --enable-ecap,
        --enable-icap-client, and --disable-loadable-modules options.
        
        Define USE_ECAP_AS_ICAP_HACK macro to enable a temporary hack
        that uses ICAP class names to implement some of the eCAP
        classes. This is necessary to hide eCAP/ICAP distinction from
        Squid core. Hiding the distinction is necessary to avoid
        numerous conflicts when this branch is merged with async call
        branch changes.
        
        Once the branches are merged, the hack will be removed. Since
        we currently #define eCAP class names to match those of ICAP
        classes, the changes at that time should not be significant:
        remove renaming #defines and adjust autotools meta files to
        allow both ICAP and eCAP co-exist.



Makefile.am
acinclude.m4
bootstrap.sh
configure.in
src/Makefile.am

        Added basic support for Libtool ltdl. Libltdl directory is not
        committed yet because I want to investigate whether it can be
        moved from root to lib/. Bootstrap.sh currently strips a large
        copying file from that directory but does not attempt to move
        the directory itself.
        
        The configure options will need to be changed according to
        squid-dev discussion: we should assume that ltdl is always used
        if modules are used, and we should have a --disable-modules
        option.
        
        The code works with a dummy module: Squid was able to load and
        unload using LoadableModule, an ltdl wrapper class from Spicer.
        I have not committed that wrapper yet.

Makefile.am
bootstrap.sh
configure.in
src/Makefile.am

        Moved Libtool libltdl directory to lib/libLtdl to keep all
        3rd-party libs in one place. Will commit the lib/libLtdl
        directory itself soon.
        
        Bootstrap.sh currently moves all files from the generated
        libltdl into lib/libLtdl. A better approach may be to use the
        --ltdl option of libtoolize. Will investigate.
        
        Changed configure options to assume that ltdl is always used if
        modules are used.",48970,data/crawl/squid/hunk_4347.cpp,,,data/crawl/squid/old_hunk_4347.cpp,data/crawl/squid/new_hunk_4347.cpp,-1,421,,"printf (""mips-mips-riscos%ssvr4\n"", argv[1]);","[""addLog""]","[[], [""printf"", ""mips"", ""mips"", ""riscos%ssvr4\\n"", ""argv[1]""]]",[-6627189546977484297],7400,2809080.0,4
https://github.com/squid-cache/squid/commit/3e7b6055489b13ca3faa9eef01b42a74971f84e4,20 Mar 2008,"Importing CVS squid3-ecap branch:

lib/Makefile.am
        Added libLtdl to SUBDIRS if USE_LOADABLE_MODULES.


src/ICAP/ICAPModXact.h
src/ICAP/ICAPServiceRep.h

        When USE_ECAP_AS_ICAP_HACK macro is defined, enable a temporary
        hack that uses ICAP class names to implement some of the eCAP
        classes. This is necessary to hide eCAP/ICAP distinction from
        Squid core. Hiding the distinction is necessary to avoid
        numerous conflicts when this branch is merged with async call
        branch changes.
        
        Once the branches are merged, the hack will be removed. Since
        we currently #define eCAP class names to match those of ICAP
        classes, the changes at that time should not be significant:
        remove renaming #defines and adjust autotools meta files to
        allow both ICAP and eCAP co-exist.



configure.in
src/Makefile.am

        Enable eCAP support if loadable module support is enabled.
        Eventually, we may want to control eCAP support directly.
        
        Added eCAP directory to the Makefile. The eCAP directory
        contents will be committed later.



SPONSORS
        Added eCAP sponsor.


src/Makefile.am
        When eCAP is enabled, to support USE_ECAP_AS_ICAP_HACK, ignore
        ICAP files that eCAP overwrites.


configure.in

        Added --enable-ecap option to control eCAP support explicitly.
        Added consistency checks for the combination of --enable-ecap,
        --enable-icap-client, and --disable-loadable-modules options.
        
        Define USE_ECAP_AS_ICAP_HACK macro to enable a temporary hack
        that uses ICAP class names to implement some of the eCAP
        classes. This is necessary to hide eCAP/ICAP distinction from
        Squid core. Hiding the distinction is necessary to avoid
        numerous conflicts when this branch is merged with async call
        branch changes.
        
        Once the branches are merged, the hack will be removed. Since
        we currently #define eCAP class names to match those of ICAP
        classes, the changes at that time should not be significant:
        remove renaming #defines and adjust autotools meta files to
        allow both ICAP and eCAP co-exist.



Makefile.am
acinclude.m4
bootstrap.sh
configure.in
src/Makefile.am

        Added basic support for Libtool ltdl. Libltdl directory is not
        committed yet because I want to investigate whether it can be
        moved from root to lib/. Bootstrap.sh currently strips a large
        copying file from that directory but does not attempt to move
        the directory itself.
        
        The configure options will need to be changed according to
        squid-dev discussion: we should assume that ltdl is always used
        if modules are used, and we should have a --disable-modules
        option.
        
        The code works with a dummy module: Squid was able to load and
        unload using LoadableModule, an ltdl wrapper class from Spicer.
        I have not committed that wrapper yet.

Makefile.am
bootstrap.sh
configure.in
src/Makefile.am

        Moved Libtool libltdl directory to lib/libLtdl to keep all
        3rd-party libs in one place. Will commit the lib/libLtdl
        directory itself soon.
        
        Bootstrap.sh currently moves all files from the generated
        libltdl into lib/libLtdl. A better approach may be to use the
        --ltdl option of libtoolize. Will investigate.
        
        Changed configure options to assume that ltdl is always used if
        modules are used.",48970,data/crawl/squid/hunk_4347.cpp,,,data/crawl/squid/old_hunk_4347.cpp,data/crawl/squid/new_hunk_4347.cpp,-1,418,,"printf (""mips-mips-riscos%ssysv\n"", argv[1]);","[""addLog""]","[[], [""printf"", ""mips"", ""mips"", ""riscos%ssysv\\n"", ""argv[1]""]]",[-8018455546522590639],7399,2809080.0,4
https://github.com/squid-cache/squid/commit/223901927d51abc6759356742b74a1c623818d14,30 Sep 2008,"eCAP support, phase 2: Implemented libecap interfaces, added eCAP
squid.conf options. Link with libecap when eCAP support is enabled.

eCAP code needs polishing and enhancement but appears to work for a few
targeted cases. I am committing this now so that users working on eCAP
modules can test and provide more specific feedback.

These adaptation-specific changes should not have significant effect on
core code.

The libecap library is available at http://www.e-cap.org/",1758,data/crawl/squid/hunk_4187.cpp,,,data/crawl/squid/old_hunk_4187.cpp,data/crawl/squid/new_hunk_4187.cpp,-1,115,,x->stop();,"[""addLog""]","[[], [""x"", ""stop""]]",[-1840386892150835003],7398,104040.0,4
https://github.com/squid-cache/squid/commit/37d4da0c0793751c68f1b548ba2842ab59e10128,13 Jan 2009,"SourceLayout: migrate IPAddress into lipip.la

This also makes some small changes to other API inside libip to allow
libbip.la to be built first as a POD library before anything src/ gets built.

Anything added to it from this point on MUST NOT require linkage outside
of libip.la or the planned libcompat.",1431,data/crawl/squid/hunk_4010.cpp,,,data/crawl/squid/old_hunk_4010.cpp,data/crawl/squid/new_hunk_4010.cpp,9,16,"storeAppendPrintf(entry, "" local-hit=%2x"", tos_local_hit);","snprintf(p, 15, "" local-hit=%2x"", tos_local_hit);","[""updateVariable"", ""updateLog"", ""addContent""]","[[""storeAppendPrintf"", ""entry""], [""snprintf"", ""p"", ""15""]]",[-9614446916550611389],7397,2160.0,4
https://github.com/squid-cache/squid/commit/8007180b22cef9ff8c0c12127b5de2f1dbbea82e,18 Feb 2009,"Author: Francesco Chemolli <kinkie@squid-cache.org>
String NG : basic SquidString updates pt 2

- finished the analysis of raw buffer exporting, divided among c-sting
and raw-buf access clients
- general sanitization
- reversal of some wrongly-renamed variables and comments
- implementation of SQUIDSTRINGPRINT and SQUIDSTRINGPH (placeholder) macros and
    psize() function for printf-style calls
- implementation of, and migration to, String::size_type and String::npos
- de-inlining of pos(), rpos(), find() and rfind() calls
- implementation and use of a proper substr() call",544,data/crawl/squid/hunk_3866.cpp,,,data/crawl/squid/old_hunk_3866.cpp,data/crawl/squid/new_hunk_3866.cpp,3,10,"str.Printf(""%s %s HTTP/%d.%d\n"",
                   RequestMethodStr(request->method),
                   request->urlpath.size() ? request->urlpath.unsafeBuf() : ""/"",
                   request->http_ver.major, request->http_ver.minor);","str.Printf(""%s "" SQUIDSTRINGPH "" HTTP/%d.%d\n"",
                   RequestMethodStr(request->method),
                   SQUIDSTRINGPRINT(urlpath_or_slash),
                   request->http_ver.major, request->http_ver.minor);","[""removeVariable"", ""addContent"", ""updateContent"", ""removeContent"", ""addVariable""]","[[""%s"", ""urlpath"", ""size"", ""urlpath"", ""unsafeBuf"", ""/"", ""request"", ""request""], [""SQUIDSTRINGPH"", ""SQUIDSTRINGPRINT"", ""urlpath_or_slash""]]",[-9113466037831026587],7396,5040.0,4
https://github.com/squid-cache/squid/commit/8007180b22cef9ff8c0c12127b5de2f1dbbea82e,18 Feb 2009,"Author: Francesco Chemolli <kinkie@squid-cache.org>
String NG : basic SquidString updates pt 2

- finished the analysis of raw buffer exporting, divided among c-sting
and raw-buf access clients
- general sanitization
- reversal of some wrongly-renamed variables and comments
- implementation of SQUIDSTRINGPRINT and SQUIDSTRINGPH (placeholder) macros and
    psize() function for printf-style calls
- implementation of, and migration to, String::size_type and String::npos
- de-inlining of pos(), rpos(), find() and rfind() calls
- implementation and use of a proper substr() call",544,data/crawl/squid/hunk_3858.cpp,,,data/crawl/squid/old_hunk_3858.cpp,data/crawl/squid/new_hunk_3858.cpp,3,3,"buf.Printf(""Proxy-Authenticate: %.*s\r\n"",
                   vh.size(), vh.rawBuf());","buf.Printf(""Proxy-Authenticate: "" SQUIDSTRINGPH ""\r\n"",SQUIDSTRINGPRINT(vh));","[""removeVariable"", ""updateContent"", ""addContent"", ""addVariable""]","[[""%"", ""*s\\r\\n"", ""size"", ""vh"", ""rawBuf""], [""SQUIDSTRINGPH"", ""\\r\\n"", ""SQUIDSTRINGPRINT""]]",[-19891850880832541083],7395,4320.0,4
https://github.com/squid-cache/squid/commit/ee0b94f4b7d2c3281a98eff2706f8e32d812bee3,26 Aug 2009,"Rework the auth forwarding special cases

The auth forwarding special cases had grown a bit hairy with a lot
of duplicated code between WWW-Auth and Proxy-Auth and far from trivial
to follow code logics.

This change breaks this logic out to a separate function shared
in both modes, selecing mode based on type of peer.

Also moves PROXYPASS back into the land of undocumented features. This
is a feature which most would only get confused by and which can cause
significant security issues if used wrongly.",184,data/crawl/squid/hunk_3626.cpp,,,data/crawl/squid/old_hunk_3626.cpp,data/crawl/squid/new_hunk_3626.cpp,-1,49,,"httpHeaderPutStrf(hdr_out, HDR_PROXY_AUTHORIZATION, ""Basic %s"",
			  base64_encode(loginbuf));","[""addLog""]","[[], [""httpHeaderPutStrf"", ""hdr_out"", ""HDR_PROXY_AUTHORIZATION"", ""Basic"", ""%s"", ""base64_encode"", ""loginbuf""]]",[3447329530469338278],7394,2592720.0,4
https://github.com/squid-cache/squid/commit/a0e95c7e26b33cb3df67c566e0daf382738da3ea,27 Aug 2009,"Cleanup of auth header special case forwarding logics

The code dealing with our special case auth header forwarding/synthesising
had grown quite hairy and partially duplicated from all additions. This
cleans up the code moving this logics to a new function and unifying
WWW & Proxy auth cases.",186,data/crawl/squid/hunk_3623.cpp,,,data/crawl/squid/old_hunk_3623.cpp,data/crawl/squid/new_hunk_3623.cpp,59,-1,"httpHeaderPutStrf(hdr_out, HDR_AUTHORIZATION, ""Basic %s"",
                                  base64_encode(loginbuf));",,"[""removeLog""]","[[""httpHeaderPutStrf"", ""hdr_out"", ""HDR_AUTHORIZATION"", ""Basic"", ""%s"", ""base64_encode"", ""loginbuf""], []]",[-4153229444962023281],7393,720.0,4
https://github.com/squid-cache/squid/commit/a0e95c7e26b33cb3df67c566e0daf382738da3ea,27 Aug 2009,"Cleanup of auth header special case forwarding logics

The code dealing with our special case auth header forwarding/synthesising
had grown quite hairy and partially duplicated from all additions. This
cleans up the code moving this logics to a new function and unifying
WWW & Proxy auth cases.",186,data/crawl/squid/hunk_3623.cpp,,,data/crawl/squid/old_hunk_3623.cpp,data/crawl/squid/new_hunk_3623.cpp,18,-1,"httpHeaderPutStrf(hdr_out, HDR_PROXY_AUTHORIZATION, ""Basic %s"",
                              base64_encode(loginbuf));",,"[""removeLog""]","[[""httpHeaderPutStrf"", ""hdr_out"", ""HDR_PROXY_AUTHORIZATION"", ""Basic"", ""%s"", ""base64_encode"", ""loginbuf""], []]",[-3447329530469338278],7392,720.0,4
https://github.com/squid-cache/squid/commit/668be43137ac65e6953d068152705ac41c675f80,27 Oct 2009,"Use libcap functions instead of raw kernel interface

Rework the Linux capabilities code to use the more stable libcap interface
instead or raw kernel syscalls.

Take two, making sure there is a sufficiently recent libcap-2.09 or later.",116,data/crawl/squid/hunk_3561.cpp,,,data/crawl/squid/old_hunk_3561.cpp,data/crawl/squid/new_hunk_3561.cpp,-1,10,,"IpInterceptor.StopTransparency(""Can't get current capabilities"");","[""addLog""]","[[], [""IpInterceptor"", ""StopTransparency"", ""Can"", ""t"", ""get"", ""current"", ""capabilities""]]",[-12025155075898479786],7391,9360.0,4
https://github.com/squid-cache/squid/commit/77721eb240367f9d4bd82638f118c811f2e93349,05 Nov 2009,"Author: Markus Moeller huaraz@moeller.plus.com>
Update squid_kerb_auth helper

 * remove sub configure again (too many issues)

Also, by Amso Jeffries
 * naming update to negotiate_kerberos_auth
 * polished helper detection rules in configure",10781,data/crawl/squid/hunk_3545.cpp,,,data/crawl/squid/old_hunk_3545.cpp,data/crawl/squid/new_hunk_3545.cpp,-1,553,,"fprintf(stderr, ""%s| %s: continuation needed\n"", LogTime(),
			PROGRAM);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""%s"", ""%s"", ""continuation"", ""needed\\n"", ""LogTime"", ""PROGRAM""]]",[-8607357028711081211],7390,622080.0,4
https://github.com/squid-cache/squid/commit/77721eb240367f9d4bd82638f118c811f2e93349,05 Nov 2009,"Author: Markus Moeller huaraz@moeller.plus.com>
Update squid_kerb_auth helper

 * remove sub configure again (too many issues)

Also, by Amso Jeffries
 * naming update to negotiate_kerberos_auth
 * polished helper detection rules in configure",10781,data/crawl/squid/hunk_3545.cpp,,,data/crawl/squid/old_hunk_3545.cpp,data/crawl/squid/new_hunk_3545.cpp,-1,447,,"fprintf(stderr, ""%s| %s: received type %d NTLM token\n"",
			LogTime(), PROGRAM,
			(int) *((unsigned char *) input_token.value +
			    sizeof ntlmProtocol));","[""addLog""]","[[], [""fprintf"", ""stderr"", ""%s"", ""%s"", ""received"", ""type"", ""%d"", ""NTLM"", ""token\\n"", ""LogTime"", ""PROGRAM"", ""int"", ""*"", ""unsigned"", ""char"", ""*"", ""input_token"", ""value"", ""sizeof"", ""ntlmProtocol""]]",[-30326822607808584511],7389,622080.0,4
https://github.com/squid-cache/squid/commit/5d8e63c9ae3b576a7b0c9c7e391c11e733ac8160,09 Feb 2010,"Author: Markus Moeller <huaraz@moeller.plus.com>
squid_kerb_auth logging clarification

add ERROR, WARNING, etc to the logging messages.",52,data/crawl/squid/hunk_3427.cpp,,,data/crawl/squid/old_hunk_3427.cpp,data/crawl/squid/new_hunk_3427.cpp,11,11,"fprintf(stderr, ""%s| %s: Got '%s' from squid (length: %d).\n"",
                    LogTime(), PROGRAM, buf, length);","fprintf(stderr, ""%s| %s: DEBUG: Got '%s' from squid (length: %d).\n"",
                    LogTime(), PROGRAM, buf, length);","[""updateContent""]","[[], [""DEBUG""]]",[7711770546127209080],7388,0.0,4
https://github.com/squid-cache/squid/commit/d33e847ce7ca7f334ef1dccece5bf6fa42feedf9,19 Apr 2010,"Author: Dhaval Varia <dhavalkvaria@gmail.com>
TCP logging capability

Enable Squid to send log lines to a remote server over TCP.

This permits logging to bypass the failures implicit with UDP packets.

TODO:
 * example daemon to receive the log traffic via TCP
 * handle TCP failures mid-transaction
 * handle full TCP buffers",283,data/crawl/squid/hunk_3392.cpp,,,data/crawl/squid/old_hunk_3392.cpp,data/crawl/squid/new_hunk_3392.cpp,-1,215,,"fatalf(""Cannot open '%s' for writing.\n""
                   ""\tThe parent directory must be writeable by the\n""
                   ""\tuser '%s', which is the cache_effective_user\n""
                   ""\tset in squid.conf."", path, Config.effectiveUser);","[""addLog""]","[[], [""fatalf"", ""Cannot"", ""open"", ""%s"", ""for"", ""writing"", ""\\n"", ""\\tThe"", ""parent"", ""directory"", ""must"", ""be"", ""writeable"", ""by"", ""the\\n"", ""\\tuser"", ""%s"", ""which"", ""is"", ""the"", ""cache_effective_user\\n"", ""\\tset"", ""in"", ""squid"", ""conf"", ""path"", ""Config"", ""effectiveUser""]]",[3071125531774423807],7387,3875400.0,4
https://github.com/squid-cache/squid/commit/d33e847ce7ca7f334ef1dccece5bf6fa42feedf9,19 Apr 2010,"Author: Dhaval Varia <dhavalkvaria@gmail.com>
TCP logging capability

Enable Squid to send log lines to a remote server over TCP.

This permits logging to bypass the failures implicit with UDP packets.

TODO:
 * example daemon to receive the log traffic via TCP
 * handle TCP failures mid-transaction
 * handle full TCP buffers",283,data/crawl/squid/hunk_3392.cpp,,,data/crawl/squid/old_hunk_3392.cpp,data/crawl/squid/new_hunk_3392.cpp,-1,211,,"fatalf(""Cannot open '%s' because\n""
                   ""\tthe parent directory does not exist.\n""
                   ""\tPlease create the directory.\n"", path);","[""addLog""]","[[], [""fatalf"", ""Cannot"", ""open"", ""%s"", ""because\\n"", ""\\tthe"", ""parent"", ""directory"", ""does"", ""not"", ""exist"", ""\\n"", ""\\tPlease"", ""create"", ""the"", ""directory"", ""\\n"", ""path""]]",[1166021827210040158],7386,3875400.0,4
https://github.com/squid-cache/squid/commit/4542b25ba0c3d195fcd2f43de2e6ba3167957156,02 Jun 2010,"Bug 2305: Multiple leaks and assertion crashes in authentication.

 * implements proper RefCounting using the RefCount.h classes for
   almost all auth objects in Squid.

 * Restructures auth objects with a simpler structure of duties and scopes.

 * Prunes away several circular and indirectly circular pointer loops

 * Adds an API to auth config for handling the mainRotate() event. To only
   shutdown helpers, fixing the loss of cached credentials on rotate.

 * Adds a username_cache page to cachemgr interface to display the current
   credentials and their TTLs to various revalidation or garbage events.


With this we end up with several global pointers for the auth schemes which
have been built into the current Squid. These are RefCount pointers, fixing
the leak of schemes on shutdown. Schemes are now also permanent structures
for the runtime of Squid, fixing leaks on reconfigure and rotate actions.

These AuthSchemes are responsible for creating auth Config objects for each
auth protocol configured in squid.conf. These config objects are now also
able to be altered with a reconfigure instead of requiring a restart.

Each HTTP request authentication attempt generates AuthUserRequest objects,
which may or may not pointer to an AuthUser set of credentials being checked.
AuthUserRequest is RefCounted instead of locked, fixing several assertion
crashes.

AuthUser is now RefCounted instead of locked. It's children inherit
these properties. This simplifies the object handling a lot and fixes
several assertions.
 * This also means AuthUser no longer needs a back-pointer to all
AuthUserRequest in order to see if its still needed alive, fixing one
circular lock loop and a few possible assertions.
 * The username cache pointers to only AuthUser objects, fixing a second
cirular lock loop and potentially leakage. Also simplifying the hash cache
handling a lot.

Non-Auth code needing a reference to authentication credentials should
hold a pointer to either an AuthUserRequest or AuthUser object. Not any
other auth object.


FUTURE WORK;
 There is still some conditions leading to auth re-challenge when they
 are not expected.
 A fair chunk of classes and enums have been shuffled into separate files
 to keep the scopes clearer. This could be increased in future when
 building the Auth namespace.
 Potential is now present for simpler TTL handling for all auth types.



This work was a collaboration between multiple interested parties over
the last year, with additional developer time and testing funded by
Netspace Online Systems.",5398,data/crawl/squid/hunk_3342.cpp,,,data/crawl/squid/old_hunk_3342.cpp,data/crawl/squid/new_hunk_3342.cpp,-1,336,,"auth_user_request->denyMessage(""Login successful"");","[""addLog""]","[[], [""auth_user_request"", ""denyMessage"", ""Login"", ""successful""]]",[9105902704882108649],7385,1211760.0,4
https://github.com/squid-cache/squid/commit/4542b25ba0c3d195fcd2f43de2e6ba3167957156,02 Jun 2010,"Bug 2305: Multiple leaks and assertion crashes in authentication.

 * implements proper RefCounting using the RefCount.h classes for
   almost all auth objects in Squid.

 * Restructures auth objects with a simpler structure of duties and scopes.

 * Prunes away several circular and indirectly circular pointer loops

 * Adds an API to auth config for handling the mainRotate() event. To only
   shutdown helpers, fixing the loss of cached credentials on rotate.

 * Adds a username_cache page to cachemgr interface to display the current
   credentials and their TTLs to various revalidation or garbage events.


With this we end up with several global pointers for the auth schemes which
have been built into the current Squid. These are RefCount pointers, fixing
the leak of schemes on shutdown. Schemes are now also permanent structures
for the runtime of Squid, fixing leaks on reconfigure and rotate actions.

These AuthSchemes are responsible for creating auth Config objects for each
auth protocol configured in squid.conf. These config objects are now also
able to be altered with a reconfigure instead of requiring a restart.

Each HTTP request authentication attempt generates AuthUserRequest objects,
which may or may not pointer to an AuthUser set of credentials being checked.
AuthUserRequest is RefCounted instead of locked, fixing several assertion
crashes.

AuthUser is now RefCounted instead of locked. It's children inherit
these properties. This simplifies the object handling a lot and fixes
several assertions.
 * This also means AuthUser no longer needs a back-pointer to all
AuthUserRequest in order to see if its still needed alive, fixing one
circular lock loop and a few possible assertions.
 * The username cache pointers to only AuthUser objects, fixing a second
cirular lock loop and potentially leakage. Also simplifying the hash cache
handling a lot.

Non-Auth code needing a reference to authentication credentials should
hold a pointer to either an AuthUserRequest or AuthUser object. Not any
other auth object.


FUTURE WORK;
 There is still some conditions leading to auth re-challenge when they
 are not expected.
 A fair chunk of classes and enums have been shuffled into separate files
 to keep the scopes clearer. This could be increased in future when
 building the Auth namespace.
 Potential is now present for simpler TTL handling for all auth types.



This work was a collaboration between multiple interested parties over
the last year, with additional developer time and testing funded by
Netspace Online Systems.",5398,data/crawl/squid/hunk_3342.cpp,,,data/crawl/squid/old_hunk_3342.cpp,data/crawl/squid/new_hunk_3342.cpp,-1,327,,"auth_user_request->denyMessage(""NTLM authentication requires a persistent connection"");","[""addLog""]","[[], [""auth_user_request"", ""denyMessage"", ""NTLM"", ""authentication"", ""requires"", ""a"", ""persistent"", ""connection""]]",[-18540693860504430209],7384,725760.0,4
https://github.com/squid-cache/squid/commit/4542b25ba0c3d195fcd2f43de2e6ba3167957156,02 Jun 2010,"Bug 2305: Multiple leaks and assertion crashes in authentication.

 * implements proper RefCounting using the RefCount.h classes for
   almost all auth objects in Squid.

 * Restructures auth objects with a simpler structure of duties and scopes.

 * Prunes away several circular and indirectly circular pointer loops

 * Adds an API to auth config for handling the mainRotate() event. To only
   shutdown helpers, fixing the loss of cached credentials on rotate.

 * Adds a username_cache page to cachemgr interface to display the current
   credentials and their TTLs to various revalidation or garbage events.


With this we end up with several global pointers for the auth schemes which
have been built into the current Squid. These are RefCount pointers, fixing
the leak of schemes on shutdown. Schemes are now also permanent structures
for the runtime of Squid, fixing leaks on reconfigure and rotate actions.

These AuthSchemes are responsible for creating auth Config objects for each
auth protocol configured in squid.conf. These config objects are now also
able to be altered with a reconfigure instead of requiring a restart.

Each HTTP request authentication attempt generates AuthUserRequest objects,
which may or may not pointer to an AuthUser set of credentials being checked.
AuthUserRequest is RefCounted instead of locked, fixing several assertion
crashes.

AuthUser is now RefCounted instead of locked. It's children inherit
these properties. This simplifies the object handling a lot and fixes
several assertions.
 * This also means AuthUser no longer needs a back-pointer to all
AuthUserRequest in order to see if its still needed alive, fixing one
circular lock loop and a few possible assertions.
 * The username cache pointers to only AuthUser objects, fixing a second
cirular lock loop and potentially leakage. Also simplifying the hash cache
handling a lot.

Non-Auth code needing a reference to authentication credentials should
hold a pointer to either an AuthUserRequest or AuthUser object. Not any
other auth object.


FUTURE WORK;
 There is still some conditions leading to auth re-challenge when they
 are not expected.
 A fair chunk of classes and enums have been shuffled into separate files
 to keep the scopes clearer. This could be increased in future when
 building the Auth namespace.
 Potential is now present for simpler TTL handling for all auth types.



This work was a collaboration between multiple interested parties over
the last year, with additional developer time and testing funded by
Netspace Online Systems.",5398,data/crawl/squid/hunk_3336.cpp,,,data/crawl/squid/old_hunk_3336.cpp,data/crawl/squid/new_hunk_3336.cpp,-1,117,,"digest_request->setDenyMessage(""Incorrect password"");","[""addLog""]","[[], [""digest_request"", ""setDenyMessage"", ""Incorrect"", ""password""]]",[3651971687145068688],7383,1342800.0,4
https://github.com/squid-cache/squid/commit/4542b25ba0c3d195fcd2f43de2e6ba3167957156,02 Jun 2010,"Bug 2305: Multiple leaks and assertion crashes in authentication.

 * implements proper RefCounting using the RefCount.h classes for
   almost all auth objects in Squid.

 * Restructures auth objects with a simpler structure of duties and scopes.

 * Prunes away several circular and indirectly circular pointer loops

 * Adds an API to auth config for handling the mainRotate() event. To only
   shutdown helpers, fixing the loss of cached credentials on rotate.

 * Adds a username_cache page to cachemgr interface to display the current
   credentials and their TTLs to various revalidation or garbage events.


With this we end up with several global pointers for the auth schemes which
have been built into the current Squid. These are RefCount pointers, fixing
the leak of schemes on shutdown. Schemes are now also permanent structures
for the runtime of Squid, fixing leaks on reconfigure and rotate actions.

These AuthSchemes are responsible for creating auth Config objects for each
auth protocol configured in squid.conf. These config objects are now also
able to be altered with a reconfigure instead of requiring a restart.

Each HTTP request authentication attempt generates AuthUserRequest objects,
which may or may not pointer to an AuthUser set of credentials being checked.
AuthUserRequest is RefCounted instead of locked, fixing several assertion
crashes.

AuthUser is now RefCounted instead of locked. It's children inherit
these properties. This simplifies the object handling a lot and fixes
several assertions.
 * This also means AuthUser no longer needs a back-pointer to all
AuthUserRequest in order to see if its still needed alive, fixing one
circular lock loop and a few possible assertions.
 * The username cache pointers to only AuthUser objects, fixing a second
cirular lock loop and potentially leakage. Also simplifying the hash cache
handling a lot.

Non-Auth code needing a reference to authentication credentials should
hold a pointer to either an AuthUserRequest or AuthUser object. Not any
other auth object.


FUTURE WORK;
 There is still some conditions leading to auth re-challenge when they
 are not expected.
 A fair chunk of classes and enums have been shuffled into separate files
 to keep the scopes clearer. This could be increased in future when
 building the Auth namespace.
 Potential is now present for simpler TTL handling for all auth types.



This work was a collaboration between multiple interested parties over
the last year, with additional developer time and testing funded by
Netspace Online Systems.",5398,data/crawl/squid/hunk_3326.cpp,,,data/crawl/squid/old_hunk_3326.cpp,data/crawl/squid/new_hunk_3326.cpp,10,-1,"fatal (""requiresRequest SHOULD have been true for this ACL!!"");",,"[""removeLog""]","[[""fatal"", ""requiresRequest"", ""SHOULD"", ""have"", ""been"", ""true"", ""for"", ""this"", ""ACL""], []]",[-13140470785063076799],7382,315360.0,4
https://github.com/squid-cache/squid/commit/c152a4473c4a3d187f67923eb83c5fe6ccd91013,12 Jul 2010,"Helpers: Naming and C++ update for external ACL helpers

 * Also adds the Fake auth helper for testing Basic authentication.
 * Also adds manual pages for most external ACL helpers

TODO: test for and fix any build issues on Windows.",2485,data/crawl/squid/hunk_3161.cpp,,,data/crawl/squid/old_hunk_3161.cpp,data/crawl/squid/new_hunk_3161.cpp,3,3,"fprintf(stderr, ""%s NetServerGetInfo() failed.'\n"", myname);","fprintf(stderr, ""%s: ERROR: NetServerGetInfo() failed.'\n"", program_name);","[""updateVariable"", ""updateContent""]","[[""myname""], [""ERROR"", ""program_name""]]",[3290800548422350724],7381,0.0,4
https://github.com/squid-cache/squid/commit/c152a4473c4a3d187f67923eb83c5fe6ccd91013,12 Jul 2010,"Helpers: Naming and C++ update for external ACL helpers

 * Also adds the Fake auth helper for testing Basic authentication.
 * Also adds manual pages for most external ACL helpers

TODO: test for and fix any build issues on Windows.",2485,data/crawl/squid/hunk_3135.cpp,,,data/crawl/squid/old_hunk_3135.cpp,data/crawl/squid/new_hunk_3135.cpp,3,3,"fprintf(stderr, ""%s Unknown option: -%c. Exiting\n"", myname, opt);","fprintf(stderr, ""%s: FATAL: Unknown option: -%c. Exiting\n"", program_name, opt);","[""updateVariable"", ""updateContent""]","[[""myname""], [""FATAL"", ""program_name""]]",[-9941512164775642552],7380,0.0,4
https://github.com/squid-cache/squid/commit/b1218840b92df2ac65c8da509fae0ec7e63a632d,13 Aug 2010,"Author: Markus Moeller <huaraz@moeller.plus.com>
Helper: ext_kerberos_ldap_group_acl: Lookup Kerberos/NTLM group via LDAP",5482,data/crawl/squid/hunk_3094.cpp,,,data/crawl/squid/old_hunk_3094.cpp,data/crawl/squid/new_hunk_3094.cpp,-1,253,,"fprintf(stderr, ""-i informational messages\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""i"", ""informational"", ""messages\\n""]]",[-15489768886428597982],7379,388800.0,4
https://github.com/squid-cache/squid/commit/2ccf2eb2159f0ee9847669c101f9ed4143e0b01d,19 Aug 2010,"Bundle the purge and hexd tools with Squid sources.

Fixes the remaining known errors with purge tool building within
Squid source tree.


This adds the auto-tools changes necessary to bundle the tool.",564,data/crawl/squid/hunk_3067.cpp,,,data/crawl/squid/old_hunk_3067.cpp,data/crawl/squid/new_hunk_3067.cpp,-1,88,,"printf( "" %s\n"", b2 );","[""addLog""]","[[], [""printf"", ""%s\\n"", ""b2""]]",[13394918869641385055],7378,45360.0,4
https://github.com/squid-cache/squid/commit/2ccf2eb2159f0ee9847669c101f9ed4143e0b01d,19 Aug 2010,"Bundle the purge and hexd tools with Squid sources.

Fixes the remaining known errors with purge tool building within
Squid source tree.


This adds the auto-tools changes necessary to bundle the tool.",564,data/crawl/squid/hunk_3067.cpp,,,data/crawl/squid/old_hunk_3067.cpp,data/crawl/squid/new_hunk_3067.cpp,-1,82,,"printf( ""%02X%c"", ch, ((i==7) ? '-' : ' ' ) );","[""addLog""]","[[], [""printf"", ""%02X%c"", ""ch"", ""i"", ""7""]]",[13012347453533798083],7377,45360.0,4
https://github.com/squid-cache/squid/commit/2ccf2eb2159f0ee9847669c101f9ed4143e0b01d,19 Aug 2010,"Bundle the purge and hexd tools with Squid sources.

Fixes the remaining known errors with purge tool building within
Squid source tree.


This adds the auto-tools changes necessary to bundle the tool.",564,data/crawl/squid/hunk_3067.cpp,,,data/crawl/squid/old_hunk_3067.cpp,data/crawl/squid/new_hunk_3067.cpp,-1,79,,"printf( ""%08X: "", line );","[""addLog""]","[[], [""printf"", ""%08X"", ""line""]]",[19353359119457577028],7376,45360.0,4
https://github.com/squid-cache/squid/commit/2ccf2eb2159f0ee9847669c101f9ed4143e0b01d,19 Aug 2010,"Bundle the purge and hexd tools with Squid sources.

Fixes the remaining known errors with purge tool building within
Squid source tree.


This adds the auto-tools changes necessary to bundle the tool.",564,data/crawl/squid/hunk_3067.cpp,,,data/crawl/squid/old_hunk_3067.cpp,data/crawl/squid/new_hunk_3067.cpp,-1,69,,"fprintf( stderr, ""Usage: %s filename\n"", argv[0] );","[""addLog""]","[[], [""fprintf"", ""stderr"", ""Usage"", ""%s"", ""filename\\n"", ""argv[0]""]]",[-12027015428844307674],7375,45360.0,4
https://github.com/squid-cache/squid/commit/ae919b541678674f5ff5fbc22cdf35a99d33b264,20 Aug 2010,"Kill redundant hexd program from purge.

There is too many other tools for producing a readable hexdump of a file.",151,data/crawl/squid/hunk_3064.cpp,,,data/crawl/squid/old_hunk_3064.cpp,data/crawl/squid/new_hunk_3064.cpp,91,-1,"printf( "" %s\n"", b2 );",,"[""removeLog""]","[[""printf"", ""%s\\n"", ""b2""], []]",[-13394918869641385055],7374,360.0,4
https://github.com/squid-cache/squid/commit/ae919b541678674f5ff5fbc22cdf35a99d33b264,20 Aug 2010,"Kill redundant hexd program from purge.

There is too many other tools for producing a readable hexdump of a file.",151,data/crawl/squid/hunk_3064.cpp,,,data/crawl/squid/old_hunk_3064.cpp,data/crawl/squid/new_hunk_3064.cpp,90,-1,"fputs(""   "",stdout);",,"[""removeLog""]","[[""fputs"", ""stdout""], []]",[12222144665393643080],7373,360.0,4
https://github.com/squid-cache/squid/commit/ae919b541678674f5ff5fbc22cdf35a99d33b264,20 Aug 2010,"Kill redundant hexd program from purge.

There is too many other tools for producing a readable hexdump of a file.",151,data/crawl/squid/hunk_3064.cpp,,,data/crawl/squid/old_hunk_3064.cpp,data/crawl/squid/new_hunk_3064.cpp,85,-1,"printf( ""%02X%c"", ch, ((i==7) ? '-' : ' ' ) );",,"[""removeLog""]","[[""printf"", ""%02X%c"", ""ch"", ""i"", ""7""], []]",[-13012347453533798083],7372,360.0,4
https://github.com/squid-cache/squid/commit/ae919b541678674f5ff5fbc22cdf35a99d33b264,20 Aug 2010,"Kill redundant hexd program from purge.

There is too many other tools for producing a readable hexdump of a file.",151,data/crawl/squid/hunk_3064.cpp,,,data/crawl/squid/old_hunk_3064.cpp,data/crawl/squid/new_hunk_3064.cpp,82,-1,"printf( ""%08X: "", line );",,"[""removeLog""]","[[""printf"", ""%08X"", ""line""], []]",[-19353359119457577028],7371,360.0,4
https://github.com/squid-cache/squid/commit/ae919b541678674f5ff5fbc22cdf35a99d33b264,20 Aug 2010,"Kill redundant hexd program from purge.

There is too many other tools for producing a readable hexdump of a file.",151,data/crawl/squid/hunk_3064.cpp,,,data/crawl/squid/old_hunk_3064.cpp,data/crawl/squid/new_hunk_3064.cpp,72,-1,"fprintf( stderr, ""Usage: %s filename\n"", argv[0] );",,"[""removeLog""]","[[""fprintf"", ""stderr"", ""Usage"", ""%s"", ""filename\\n"", ""argv[0]""], []]",[12027015428844307674],7370,360.0,4
https://github.com/squid-cache/squid/commit/8822ebee4947bcf883d74aa79a26e896449d0c36,28 Oct 2010,"SMP Cache Manager, Phase2 implementation.

Cache Manager actions are forwarded to Coordinator. Coordinator iterates over
Kids, aggregating their stats if possible and/or allowing each kid to dump
non-aggregatable output directly into response if needed. Non-aggregated
output is wrapped in ""by kidN { ... } by kidN"" markup to ease auto-processing.

Regressions and small output formatting changes are probably unavoidable
because stats are aggregated and passed around as doubles instead of integers
(no more overflows though!) and because many stats collection and formatting
lines had to be touched. These are steps in the right direction though, IMO.


Old code both computed and dumped stats to Store at the same time. To avoid
computing code duplication, we now collect stats in primitive Stats objects
and then either dump those to Store or send them to Coordinator for
aggregation and, eventual Store dump. What stats to collect, when to
aggregate, and when to dump is decided by action-specific Mgr::Action classes.

The Cache Manager menu now consists of ActionProfile objects. ActionProfile
maintains hard-coded information about specific actions. It uses ActionCreator
member to create Action objects when a cache manager request is received.

Added Mgr::ActionParams class to maintain action parameters, including HTTP
request details necessary for Store entry creation (in another strand) and
action-specific parameters (currently just credentials). In Phase3, this class
can be extended to supply more parameters such as kid IDs to which the action
should apply.

Added Mgr::Command that combines hard-coded ActionProfile details with
user-specified ActionParams. This simplifies many interfaces because we no
longer need to supply a long list of parameters, covering various parts of
action config.


Moved Cache Manager registration to Mgr::RegisterAction() globals to reduce
dependency on the CacheManager class, which is a singleton anyway, and which
is unused by most of the registration callers.  On the other hand, without
this change, no legacy (function-based actions) code would have been changed!


Enhanced TypedMsgHdr class to simplify storing and loading non-POD classes.
The caller can now easily handle a non-POD class as a series of put/get calls,
one for each POD member. This was necessary to send Mgr::ActionParams to
Coordinator and back. Will probably be useful for sending other complex
structures as well.


Reconfigure, shutdown, and other ""basic"" actions have been moved to
src/mgr/BasicActions.cc. Mgr::RegisterBasics() registers them.


Most of the Cache Manager code is now in src/mgr/.


Many more polishing touches.


More polishing left for future projects: Move CacheManager to Mgr namespace
and src/mgr/ directory. Use SBuf instead of String for ActionParams and
TypedMsgHdr. Rename Ipc::TypedMsgHdr to Ipc::Msg, Ipc::SocketMsg, or similar
because it maintains more than just msghdr struct. More stats aggregation,
and Phase3 changes.",6354,data/crawl/squid/hunk_2921.cpp,,,data/crawl/squid/old_hunk_2921.cpp,data/crawl/squid/new_hunk_2921.cpp,119,206,"storeAppendPrintf(sentry, ""page_faults = %f/sec\n"",
                      XAVG(page_faults));","storeAppendPrintf(sentry, ""page_faults = %f/sec\n"",
                      stats.page_faults);","[""removeVariable"", ""addVariable""]","[[""XAVG""], [""stats""]]",[1848561580698048512],7369,0.0,4
https://github.com/squid-cache/squid/commit/995eb827aaa64d9bcd4110b756e04051ef9d03e9,02 Mar 2011,merge from trunk,12916,data/crawl/squid/hunk_2736.cpp,,,data/crawl/squid/old_hunk_2736.cpp,data/crawl/squid/new_hunk_2736.cpp,-1,5,,"storeAppendPrintf(sentry, ""IPcache Entries Cached:  %d\n"",
                      ipcacheCount());","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""IPcache"", ""Entries"", ""Cached"", ""%d\\n"", ""ipcacheCount""]]",[22122026386024735270],7368,14400.0,4
https://github.com/squid-cache/squid/commit/995eb827aaa64d9bcd4110b756e04051ef9d03e9,02 Mar 2011,merge from trunk,12916,data/crawl/squid/hunk_2723.cpp,,,data/crawl/squid/old_hunk_2723.cpp,data/crawl/squid/new_hunk_2723.cpp,-1,20,,"mustStop(""Listener socket closed"");","[""addLog""]","[[], [""mustStop"", ""Listener"", ""socket"", ""closed""]]",[-5749801543235549026],7367,163080.0,4
https://github.com/squid-cache/squid/commit/995eb827aaa64d9bcd4110b756e04051ef9d03e9,02 Mar 2011,merge from trunk,12916,data/crawl/squid/hunk_2722.cpp,,,data/crawl/squid/old_hunk_2722.cpp,data/crawl/squid/new_hunk_2722.cpp,-1,21,,"fatal(""FATAL: error while accepting new client connection: [unkown]\n"");","[""addLog""]","[[], [""fatal"", ""FATAL"", ""error"", ""while"", ""accepting"", ""new"", ""client"", ""connection"", ""[unkown]\\n""]]",[13602788282184694618],7366,163080.0,4
https://github.com/squid-cache/squid/commit/1c8f25bbb056368c4405473ff7304156608e92cc,17 Jun 2011,"Upgrade comm layer Connection handling

The premise underlying this large patch is that instead of copying and
re-copying and re-lookups for the FD related data we can take the
ConnectionDetail class which is generated to store a few bits of IP
information about newly accept()'d connections and make it persist across
the whole of Squid.

It has been renamed from ConnectionDetails to Comm::Connection and has
absorbed a few FD data fields from other classes long the code paths.
Its scope is to hold an FD (or potential FD) plus meta data.

Comm::Connection are valid before, during and after the period when their
particular FD is open. The meta data may be used beforehand to setup the
FD (in the case of peer selection or other TcpAcceptor usage), and it may
remain in use after FD closure until logging or all linked job and call
objects have detected the closure and terminated. A global function
Comm::IsConnOpen() may be used on the pointer objects to detect whether
they point at an active connection.

Most of the patch is simple parameter changes to functions and methods to
pass a ""cont Comm::ConnectionPointer &"" instead of an ""int FD"". Along with
class FD fields being converted to these object pointers.


In order to support this alteration there have been behavioral changes to:

The socket accept() Job
  Comm::TcpAcceptor altered to spawn Comm::Connection objects and to
  operate with one controlling their active/closed state.

FTP data channel handling Calls.
  efficiency improvements making use of Comm::Connection as a feedback
  channel between TcpAcceptor and FtpStateData to cancel the listening
  Job. Most of the underlying logic change is already in trunk to use
  the Subscription API. This just streamlines and fixes some race bugs.

Peer selection
  updated to spawn a set of Comm::Connection objects. To do this it is
  updated to determine *all* peers including DIRECT ones. Doing the DNS
  lookup instead of leaving it to comm_connect() on the other side of
  FwdState. It also absorbs the outgoing address selection from FwdState
  and can now specify details of local+remote ends of an outgoing TCP link.

Forwarding
  updated to handle the new outputs from peer selection and to open sequentially.

pconn handling
  updated to use destination IP/port and hold a Comm::Connection instead
  of domain name indexing an FD. This allows us to maintain idle pools
  and re-use FD more efficiently with virtual-hosted servers. Along
  with maintaining certainty that the pconn selected actually goes to
  the exact destination IP:port needed by forwarding.

comm layer outgoing connections
  now have a control job Comm::ConnOpener to do this. Due to the peer
  selection and forwarding changes this is a much simpler operation.

HTTP / CONNECT tunnel / gopher / whois / FTP
  updated to receive a server and client Comm::Connection object from
  forwarding. To operate on those until they close or are finished with.

SNMP / ICP / HTCP / DNS port listeners
  updated to work with Comm::Connection holding their listening socket
  meta data. This is a side-effect of the ICP and Comm read/write/timeout
  changes.",8518,data/crawl/squid/hunk_2580.cpp,,,data/crawl/squid/old_hunk_2580.cpp,data/crawl/squid/new_hunk_2580.cpp,-1,7,,"fatal(""tools.cc required"");","[""addLog""]","[[], [""fatal"", ""tools"", ""cc"", ""required""]]",[-3614026982818920886],7365,76320.0,4
https://github.com/squid-cache/squid/commit/1c8f25bbb056368c4405473ff7304156608e92cc,17 Jun 2011,"Upgrade comm layer Connection handling

The premise underlying this large patch is that instead of copying and
re-copying and re-lookups for the FD related data we can take the
ConnectionDetail class which is generated to store a few bits of IP
information about newly accept()'d connections and make it persist across
the whole of Squid.

It has been renamed from ConnectionDetails to Comm::Connection and has
absorbed a few FD data fields from other classes long the code paths.
Its scope is to hold an FD (or potential FD) plus meta data.

Comm::Connection are valid before, during and after the period when their
particular FD is open. The meta data may be used beforehand to setup the
FD (in the case of peer selection or other TcpAcceptor usage), and it may
remain in use after FD closure until logging or all linked job and call
objects have detected the closure and terminated. A global function
Comm::IsConnOpen() may be used on the pointer objects to detect whether
they point at an active connection.

Most of the patch is simple parameter changes to functions and methods to
pass a ""cont Comm::ConnectionPointer &"" instead of an ""int FD"". Along with
class FD fields being converted to these object pointers.


In order to support this alteration there have been behavioral changes to:

The socket accept() Job
  Comm::TcpAcceptor altered to spawn Comm::Connection objects and to
  operate with one controlling their active/closed state.

FTP data channel handling Calls.
  efficiency improvements making use of Comm::Connection as a feedback
  channel between TcpAcceptor and FtpStateData to cancel the listening
  Job. Most of the underlying logic change is already in trunk to use
  the Subscription API. This just streamlines and fixes some race bugs.

Peer selection
  updated to spawn a set of Comm::Connection objects. To do this it is
  updated to determine *all* peers including DIRECT ones. Doing the DNS
  lookup instead of leaving it to comm_connect() on the other side of
  FwdState. It also absorbs the outgoing address selection from FwdState
  and can now specify details of local+remote ends of an outgoing TCP link.

Forwarding
  updated to handle the new outputs from peer selection and to open sequentially.

pconn handling
  updated to use destination IP/port and hold a Comm::Connection instead
  of domain name indexing an FD. This allows us to maintain idle pools
  and re-use FD more efficiently with virtual-hosted servers. Along
  with maintaining certainty that the pconn selected actually goes to
  the exact destination IP:port needed by forwarding.

comm layer outgoing connections
  now have a control job Comm::ConnOpener to do this. Due to the peer
  selection and forwarding changes this is a much simpler operation.

HTTP / CONNECT tunnel / gopher / whois / FTP
  updated to receive a server and client Comm::Connection object from
  forwarding. To operate on those until they close or are finished with.

SNMP / ICP / HTCP / DNS port listeners
  updated to work with Comm::Connection holding their listening socket
  meta data. This is a side-effect of the ICP and Comm read/write/timeout
  changes.",8518,data/crawl/squid/hunk_2542.cpp,,,data/crawl/squid/old_hunk_2542.cpp,data/crawl/squid/new_hunk_2542.cpp,4,4,"buf.Printf(""FD %d"", connection);","buf.Printf(""FD %d"", connection->fd);","[""removeVariable"", ""addVariable""]","[[], [""fd""]]",[13056078438117844],7364,268560.0,4
https://github.com/squid-cache/squid/commit/7ff7a211c25688d2d6742acc7bc271f700c9dbe9,08 Aug 2011,Migrate cf_gen.cc from C-style stdio to C++ iostreams.,300,data/crawl/squid/hunk_2497.cpp,,,data/crawl/squid/old_hunk_2497.cpp,data/crawl/squid/new_hunk_2497.cpp,21,-1,"fprintf(fp, ""#%s\n"", line->data);",,"[""removeLog""]","[[""fprintf"", ""fp"", ""%s\\n"", ""line"", ""data""], []]",[1893739475219068612],7363,0.0,4
https://github.com/squid-cache/squid/commit/35a1b223314eddb67b631cb0224d6e03a2360c77,13 Sep 2011,"SMP Caching: Core changes, IPC primitives, Shared memory cache, and Rock Store

Core changes
------------

* Added MemObject::expectedReplySize() and used it instead of object_sz.

When deciding whether an object with a known content length can be
swapped out, do not wait until the object is completely received and its
size (mem_obj->object_sz) becomes known (while asking the store to
recheck in vain with every incoming chunk). Instead, use the known
content length, if any, to make the decision.

This optimizes the common case where the complete object is eventually
received and swapped out, preventing accumulating potentially large
objects in RAM while waiting for the end of the response. Should not
affect objects with unknown content length.

Side-effect1: probably fixes several cases of unknowingly using negative
(unknown) mem_obj->object_sz in calculations. I added a few assertions
to double check some of the remaining object_sz/objectLen() uses.

Side-effect2: When expectedReplySize() is stored on disk as StoreEntry
metadata, it may help to detect truncated entries when the writer
process dies before completing the swapout.


* Removed mem->swapout.memnode in favor of mem->swapout.queue_offset.

The code used swapout.memnode pointer to keep track of the last page
that was swapped out. The code was semi-buggy because it could reset the
pointer to NULL if no new data came in before the call to doPages().
Perhaps the code relied on the assumption that the caller will never
doPages if there is no new data, but I am not sure that assumption was
correct in all cases (it could be that I broke the calling code, of course).

Moreover, the page pointer was kept without any protection from page
disappearing during asynchronous swapout. There were ""Evil hack time""
comments discussing how the page might disappear.

Fortunately, we already have mem->swapout.queue_offset that can be fed
to getBlockContainingLocation to find the page that needs to be swapped
out. There is no need to keep the page pointer around. The
queue_offset-based math is the same so we are not adding any overheads
by using that offset (in fact, we are removing some minor computations).


* Added ""close how?"" parameter to storeClose() and friends.

The old code would follow the same path when closing swapout activity
for an aborted entry and when completing a perfectly healthy swapout. In
non-shared case, that could have been OK because the abort code would
then release the entry, removing any half-written entry from the index
and the disk (but I am not sure that release happened fast enough in
100% of cases).

When the index and disk storage is shared among workers, such
""temporary"" inconsistencies result in truncated responses being
delivered by other workers to the user because once the swapout activity
is closed, other workers can start using the entry.

By adding the ""close how?"" parameter to closing methods we allow the
core and SwapDir-specific code to handle aborted swapouts appropriately.

Since swapin code is ""read only"", we do not currently distinguish
between aborted and fully satisfied readers: The readerGone enum value
applies to both cases. If needed, the SwapDir reading code can make that
distinction by analyzing how much was actually swapped in.


* Moved ""can you store this entry?"" code to virtual SwapDir::canStore().

The old code had some of the tests in SwapDir-specific canStore()
methods and some in storeDirSelect*() methods. This resulted in
inconsistencies, code duplication, and extra calculation overheads.
Making this call virtual allows individual cache_dir types to do custom
access controls.

The same method is used for cache_dir load reporting (if it returns
true). Load management needs more work, but the current code is no worse
than the old one in this aspect, and further improvements are outside
this change scope.


* Minimized from-disk StoreEntry loading/unpacking code duplication.

Moved common (and often rather complex!) code from store modules into
storeRebuildLoadEntry, storeRebuildParseEntry, and storeRebuildKeepEntry.


* Do not set object_sz when the entry is aborted because the true object
size (HTTP reply headers + body) is not known in this case. Setting
object_sz may fool client-side code into believing that the object is
complete.

This addresses an old RBC's complaint.


* When swapout initiation fails, mark swapout decision as
MemObject::SwapOut::swImpossible. This prevents the caller code from trying to
swap out again and again because swap_status becomes SWAPOUT_NONE.

TODO: Consider add SWAPOUT_ERROR, STORE_ERROR, and similar states. It
may solve several problems where the code sees _NONE or _OK and thinks
everything is peachy when in fact there was an error.


* Call haveParsedReplyHeaders() before entry->replaceHttpReply().

HaveParsedReplyHeaders() sets the entry public key and various flags (at 
least). ReplaceHttpReply() packs reply headers, starting swapout process.
It feels natural to adjust the entry _before_ we pack/swap it, but I may be
missing some side-effects here.

The change was necessary because we started calling checkCachable() from
swapoutPossible(). If haveParsedReplyHeaders() is not called before we swap
out checks, the entry will still have the private key and will be declared
impossible to cache.


* Extracted the write-to-store step from StoreEntry::replaceHttpReply().

This allows the caller to set the reply for the entry and then update the
entry and the reply before writing them to store. For example, the server-side
haveParsedReplyHeaders() code needs to set the entry timestamps and make the
entry key public before the entry starts swapping out, but the same code also
needs access to entry->getReply() and such for timestampsSet() and similar
code to work correctly.

TODO: Calls to StoreEntry::replaceHttpReply() do not have to be modified
because replaceHttpReply() does write by default. However, it is likely that
callers other than ServerStateData::setFinalReply() should take advantage of
the new split interface because they call timestampsSet() and such after
replaceHttpReply().


* Moved SwapDir::cur_size and n_disk_objects to specific SwapDirs. Removed
updateSize().  Some cache_dirs maintain their own maps and size statistics,
making the one-size-fits-all SwapDir members inappropriate.

* A new SwapDir public method swappedOut() added. It is called from
storeSwapOutFileClosed() to notify SwapDir that an object was swapped
out.

* Change SwapDir::max_size to bytes, make it protected, use maxSize() instead.

Change SwapDir::cur_size to bytes, make it private, use currentSize() instead.

Store Config.Store.avgObjectSize in bytes to avoid repeated and error-prone
KB<->bytes conversions.


* Change Config.cacheSwap.swapDirs and StoreEntry::store() type to SwapDir.

This allows using SwapDir API without dynamic_cast.


* Always call StoreEntry::abort() instead of setting ENTRY_ABORTED manually.

* Rely on entry->abort() side-effects if ENTRY_ABORTED was set.

* Added or updated comments to better document current code.

* Added operator << for dumping StoreEntry summary into the debugging
log. Needs more work to report more info (and not report yet-unknown info).

* Fixed blocking reads that were sometimes reading from random file offsets.

Core ""disk file"" reading code assumed that if the globally stored disk.offset
matches the desired offset, there is no reason to seek. This was probably done
to reduce seek overhead between consecutive reads. Unfortunately, the disk
writing code did not know about that optimization and left F->disk.offset
unchanged after writing.

This may have worked OK for UFS if it never writes to the file it reads from,
but it does not work for store modules that do both kinds of I/O at different
offsets of the same disk file.

Eventually, implement this optimization correctly or remove disk.offset.


IPC primitives
--------------

To make SMP disk and memory caching non-blocking and correct, worker and
disker processes must asynchronously communicate with each other. We are
adding a collection of classes that support such communication.

At the base of the collection is the AtomicWordT template that uses GCC atomic
primitives such as __sync_add_and_fetch() to perform atomic operations on
integral values in memory shared by multiple Squid kids. AtomicWordT is used
to implement non-blocking shared locks, queues, store tables, and page pools.

To avoid blocking or very long searches, many operations are ""optimistic"" in
nature. For example, it is possible that an atomic store map will refuse to
allocate an entry for two processes even though a blocking implementation
would have allowed one of the processes to get the map slot. We speculate that
such conflict resolution is better than blocking locks when it comes to
caching, especially if the conflicts are rare due to large number of cache
entries, fast operations, and relatively small number of kids.


TODO: Eventually, consider breaking locks left by dead kids.



Shared Memory Cache
-------------------

* Added initial shared memory cache implementation (MemStore).

The shared memory cache keeps its own compact index of cached entries using
extended Ipc::StoreMap class (MemStoreMap). The cache also strives to keep its
Root.get() results out of the store_table except during transit.

Eventually, the non-shared/local memory cache should also be implemented
using a MemStore-like class, I think. This will allow to clearly isolate
local from shared memory cache code.

Allow the user to explicitly disable shared memory caching in SMP mode via
memory_cache_shared to squid.conf. Report whether mem_cache is shared.

Disable shared memory caching by default if atomic operations are not
supported. Prohibit shared memory caching if atomic operations are not
supported.

TODO: Better limits/separation for cache and I/O shared memory pages.
Eventually, support shared memory caching of multi-page entries.


Rock Store
----------

Rock Store uses a single [large] database-style file per cache_dir to store
cached responses and metadata. This part of the design is similar to COSS.
Rock Store does not maintain or rely on swap.state ""log"" for recovery.
Instead, the database is scanned in the background to load entries when Squid
starts. Rock Store maintains its own index of cached entries and avoids global
store_table. All entries must be max-size or smaller.

In SMP mode, each Rock cache_dir is given a dedicated Kid processes called
""disker"". All SMP workers communicate with diskers to store misses and load
hits, using shared memory pages and atomic shared memory queues. Disker blocks
when doing disk I/O but workers do not. Any Diskers:Workers ratio is supported
so that the user can find and configure the optimal number of workers and
diskers for a given number of disks and CPU cores.

In non-SMP mode, should use good old blocking disk I/O, without any diskers,
but this has not been tested recently and probably needs more work.

Feature page: http://wiki.squid-cache.org/Features/RockStore

TODO: Disk rate limit to protect Squid from disk overload. More stats.
Multiple readers? Seek optimization? Remove known max-size requirement?",8765,data/crawl/squid/hunk_2449.cpp,,,data/crawl/squid/old_hunk_2449.cpp,data/crawl/squid/new_hunk_2449.cpp,-1,708,,"storeAppendPrintf(&e, ""\n"");","[""addLog""]","[[], [""storeAppendPrintf"", ""&e"", ""\\n""]]",[5198007793595594540],7362,164880.0,4
https://github.com/squid-cache/squid/commit/b46ae5259f2c1a194bf35e1ab76f039deafc10b9,21 Oct 2011,Polished more fatal messages.,23,data/crawl/squid/hunk_2404.cpp,,,data/crawl/squid/old_hunk_2404.cpp,data/crawl/squid/new_hunk_2404.cpp,3,3,"fatal(""Ipc::Mem::Segment::create failed to ftruncate"");","fatalf(""Ipc::Mem::Segment::create failed to ftruncate(%s): %s\n"",
               theName.termedBuf(), xstrerror());","[""updateLog"", ""updateContent"", ""addVariable""]","[[""fatal""], [""fatalf"", ""%s"", ""%s\\n"", ""theName"", ""termedBuf"", ""xstrerror""]]",[18788859735329310263],7361,0.0,4
https://github.com/squid-cache/squid/commit/71cae3894fd0c52dd4b4bfedb3ac1323eb619a73,18 Jul 2012,merge from trunk (r12216 v3.2.0.18+),2062,data/crawl/squid/hunk_2138.cpp,,,data/crawl/squid/old_hunk_2138.cpp,data/crawl/squid/new_hunk_2138.cpp,-1,4,,"abortTransaction(""store entry aborted while storing reply"");","[""addLog""]","[[], [""abortTransaction"", ""store"", ""entry"", ""aborted"", ""while"", ""storing"", ""reply""]]",[-22610546794415874701],7360,5760.0,4
https://github.com/squid-cache/squid/commit/71cae3894fd0c52dd4b4bfedb3ac1323eb619a73,18 Jul 2012,merge from trunk (r12216 v3.2.0.18+),2062,data/crawl/squid/hunk_2137.cpp,,,data/crawl/squid/old_hunk_2137.cpp,data/crawl/squid/new_hunk_2137.cpp,-1,3,,"abortTransaction(""store entry aborted while reading reply"");","[""addLog""]","[[], [""abortTransaction"", ""store"", ""entry"", ""aborted"", ""while"", ""reading"", ""reply""]]",[-26778743856181259603],7359,5760.0,4
https://github.com/squid-cache/squid/commit/71cae3894fd0c52dd4b4bfedb3ac1323eb619a73,18 Jul 2012,merge from trunk (r12216 v3.2.0.18+),2062,data/crawl/squid/hunk_2128.cpp,,,data/crawl/squid/old_hunk_2128.cpp,data/crawl/squid/new_hunk_2128.cpp,-1,11,,"storeAppendPrintf(entry, ""%s "", hwa->fieldValue.c_str());","[""addLog""]","[[], [""storeAppendPrintf"", ""entry"", ""%s"", ""hwa"", ""fieldValue"", ""c_str""]]",[-6959451586058577596],7358,720.0,4
https://github.com/squid-cache/squid/commit/71cae3894fd0c52dd4b4bfedb3ac1323eb619a73,18 Jul 2012,merge from trunk (r12216 v3.2.0.18+),2062,data/crawl/squid/hunk_2128.cpp,,,data/crawl/squid/old_hunk_2128.cpp,data/crawl/squid/new_hunk_2128.cpp,-1,10,,"storeAppendPrintf(entry, ""%s "", hwa->fieldName.c_str());","[""addLog""]","[[], [""storeAppendPrintf"", ""entry"", ""%s"", ""hwa"", ""fieldName"", ""c_str""]]",[-9879850199040563429],7357,720.0,4
https://github.com/squid-cache/squid/commit/71cae3894fd0c52dd4b4bfedb3ac1323eb619a73,18 Jul 2012,merge from trunk (r12216 v3.2.0.18+),2062,data/crawl/squid/hunk_2122.cpp,,,data/crawl/squid/old_hunk_2122.cpp,data/crawl/squid/new_hunk_2122.cpp,10,-1,"fatal(""AclLookupProxyAuthDone: Old code floating around somewhere.\nMake clean and if that doesn't work, report a bug to the squid developers.\n"");",,"[""removeLog""]","[[""fatal"", ""AclLookupProxyAuthDone"", ""Old"", ""code"", ""floating"", ""around"", ""somewhere"", ""\\nMake"", ""clean"", ""and"", ""if"", ""that"", ""doesn"", ""t"", ""work"", ""report"", ""a"", ""bug"", ""to"", ""the"", ""squid"", ""developers"", ""\\n""], []]",[-31539841372898536781],7356,3708000.0,4
https://github.com/squid-cache/squid/commit/86660d64fb95f949de9820e44233a273e97ebf91,06 Sep 2012,"Bug fix: TLS/SSL Options does not apply to the dynamically generated certificates

The TLS/SSL options configured with http_port configuration parameter does not
used to generate SSL_CTX context objects used to establish SSL connections.
This is means that certificate based authentication, or SSL version selection
and other SSL/TLS http_port options does not work for ssl-bumped connection.
This patch fixes this problem.

This is a Measurement Factory project",526,data/crawl/squid/hunk_2061.cpp,,,data/crawl/squid/old_hunk_2061.cpp,data/crawl/squid/new_hunk_2061.cpp,-1,30,,"fatalf(""%s_port %s initialization error"", protocol,  s.ToURL(buf, sizeof(buf)));","[""addLog""]","[[], [""fatalf"", ""%s_port"", ""%s"", ""initialization"", ""error"", ""protocol"", ""s"", ""ToURL"", ""buf"", ""sizeof"", ""buf""]]",[11835393429186752141],7355,146520.0,4
https://github.com/squid-cache/squid/commit/e166785ad679d33acc445d2d96facc065bc63a35,29 Oct 2012,"Support OK/ERR/BH response codes from any helper

Updates the helper reponse callback API from using char* buffer to a
HelperReply object storing teh response code, a blob buffer, and 
pointer to the responding helper 'server' (if stateful).

* the helper I/O read handler is updated to parse the result code off
the start of the helper response as is currently done for channel-ID.
The callback handlers are altered to use the HelperReply::status instead
of parsing it off themselves individually.

* the remaining I/O read buffer is stored in a MemBuf and callbacks are
updated to use it via the method other().

* the responding helper-server is stored into the HelperReply object and
stateful helper callbacks are combined into the same API as stateless.
The callback handlers are updated to use HelperReply::lastserver instead
of function parameter.

After this patch the helper response format is:
  [channel-ID] SP [result] [ [SP] blob] <terminator>

'SP' being one octet \0x20 character.

The behavour changes expected from this is that all helpers are now able
to send OK/ERR/BH states. Although the handlers for some helpers will
deal with the new states as unknown response. None of the bundled
helpers have yet been altered to make use of this changed potential.

TODO:
* implement key=value parser for the blob area of the format, and update
handlers to use the HelperReply API to retrieve them.
* upgrade helpers to make use of new response format",558,data/crawl/squid/hunk_1955.cpp,,,data/crawl/squid/old_hunk_1955.cpp,data/crawl/squid/new_hunk_1955.cpp,-1,11,,"fatalf(""authenticateNegotiateHandleReply: *** Unsupported helper response ***, '%s'\n"", reply.other().content());","[""addLog""]","[[], [""fatalf"", ""authenticateNegotiateHandleReply"", ""***"", ""Unsupported"", ""helper"", ""response"", ""***"", ""%s"", ""\\n"", ""reply"", ""other"", ""content""]]",[3708139154972262716],7354,28800.0,4
https://github.com/squid-cache/squid/commit/e166785ad679d33acc445d2d96facc065bc63a35,29 Oct 2012,"Support OK/ERR/BH response codes from any helper

Updates the helper reponse callback API from using char* buffer to a
HelperReply object storing teh response code, a blob buffer, and 
pointer to the responding helper 'server' (if stateful).

* the helper I/O read handler is updated to parse the result code off
the start of the helper response as is currently done for channel-ID.
The callback handlers are altered to use the HelperReply::status instead
of parsing it off themselves individually.

* the remaining I/O read buffer is stored in a MemBuf and callbacks are
updated to use it via the method other().

* the responding helper-server is stored into the HelperReply object and
stateful helper callbacks are combined into the same API as stateless.
The callback handlers are updated to use HelperReply::lastserver instead
of function parameter.

After this patch the helper response format is:
  [channel-ID] SP [result] [ [SP] blob] <terminator>

'SP' being one octet \0x20 character.

The behavour changes expected from this is that all helpers are now able
to send OK/ERR/BH states. Although the handlers for some helpers will
deal with the new states as unknown response. None of the bundled
helpers have yet been altered to make use of this changed potential.

TODO:
* implement key=value parser for the blob area of the format, and update
handlers to use the HelperReply API to retrieve them.
* upgrade helpers to make use of new response format",558,data/crawl/squid/hunk_1953.cpp,,,data/crawl/squid/old_hunk_1953.cpp,data/crawl/squid/new_hunk_1953.cpp,9,9,r->auth_user_request->setDenyMessage(t);,r->auth_user_request->setDenyMessage(reply.other().content());,"[""removeVariable"", ""addVariable""]","[[""t""], [""reply"", ""other"", ""content""]]",[-6050016541010723673],7353,28800.0,4
https://github.com/squid-cache/squid/commit/fc6df0c3a619d283bcd0f755409d5f3ec9554007,04 Dec 2012,merge from parent SslServerCertValidator r12337,2116,data/crawl/squid/hunk_1838.cpp,,,data/crawl/squid/old_hunk_1838.cpp,data/crawl/squid/new_hunk_1838.cpp,-1,4,,"storeAppendPrintf(sentry, "" protocol=2.5"");","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""protocol"", ""2"", ""5""]]",[12354729488681892469],7352,23400.0,4
https://github.com/squid-cache/squid/commit/fc6df0c3a619d283bcd0f755409d5f3ec9554007,04 Dec 2012,merge from parent SslServerCertValidator r12337,2116,data/crawl/squid/hunk_1836.cpp,,,data/crawl/squid/old_hunk_1836.cpp,data/crawl/squid/new_hunk_1836.cpp,-1,37,,"auth_user_request->denyMessage(""NTLM Authentication failed with no reason given"");","[""addLog""]","[[], [""auth_user_request"", ""denyMessage"", ""NTLM"", ""Authentication"", ""failed"", ""with"", ""no"", ""reason"", ""given""]]",[-21254742995402587156],7351,26640.0,4
https://github.com/squid-cache/squid/commit/fc6df0c3a619d283bcd0f755409d5f3ec9554007,04 Dec 2012,merge from parent SslServerCertValidator r12337,2116,data/crawl/squid/hunk_1836.cpp,,,data/crawl/squid/old_hunk_1836.cpp,data/crawl/squid/new_hunk_1836.cpp,-1,33,,"auth_user_request->denyMessage(""Internal Error"");","[""addLog""]","[[], [""auth_user_request"", ""denyMessage"", ""Internal"", ""Error""]]",[5082695339119143889],7350,26640.0,4
https://github.com/squid-cache/squid/commit/fc6df0c3a619d283bcd0f755409d5f3ec9554007,04 Dec 2012,merge from parent SslServerCertValidator r12337,2116,data/crawl/squid/hunk_1836.cpp,,,data/crawl/squid/old_hunk_1836.cpp,data/crawl/squid/new_hunk_1836.cpp,-1,13,,"auth_user_request->denyMessage(""NTLM Authentication denied with no reason given"");","[""addLog""]","[[], [""auth_user_request"", ""denyMessage"", ""NTLM"", ""Authentication"", ""denied"", ""with"", ""no"", ""reason"", ""given""]]",[-13243614487407290766],7349,26640.0,4
https://github.com/squid-cache/squid/commit/fc6df0c3a619d283bcd0f755409d5f3ec9554007,04 Dec 2012,merge from parent SslServerCertValidator r12337,2116,data/crawl/squid/hunk_1834.cpp,,,data/crawl/squid/old_hunk_1834.cpp,data/crawl/squid/new_hunk_1834.cpp,-1,42,,"auth_user_request->denyMessage(""Negotiate Authentication failed with no reason given"");","[""addLog""]","[[], [""auth_user_request"", ""denyMessage"", ""Negotiate"", ""Authentication"", ""failed"", ""with"", ""no"", ""reason"", ""given""]]",[-20419471422409429170],7348,26640.0,4
https://github.com/squid-cache/squid/commit/fc6df0c3a619d283bcd0f755409d5f3ec9554007,04 Dec 2012,merge from parent SslServerCertValidator r12337,2116,data/crawl/squid/hunk_1834.cpp,,,data/crawl/squid/old_hunk_1834.cpp,data/crawl/squid/new_hunk_1834.cpp,34,38,auth_user_request->denyMessage(blob);,"auth_user_request->denyMessage(""Internal Error"");","[""removeVariable"", ""addContent""]","[[""blob""], [""Internal"", ""Error""]]",[469258109968726773],7347,26640.0,4
https://github.com/squid-cache/squid/commit/fc6df0c3a619d283bcd0f755409d5f3ec9554007,04 Dec 2012,merge from parent SslServerCertValidator r12337,2116,data/crawl/squid/hunk_1833.cpp,,,data/crawl/squid/old_hunk_1833.cpp,data/crawl/squid/new_hunk_1833.cpp,27,16,"auth_user_request->denyMessage(""NTLM authentication requires a persistent connection"");","auth_user_request->denyMessage(""Negotiate authentication requires a persistent connection"");","[""updateContent""]","[[""NTLM""], [""Negotiate""]]",[835271572993157986],7346,76320.0,4
https://github.com/squid-cache/squid/commit/fc6df0c3a619d283bcd0f755409d5f3ec9554007,04 Dec 2012,merge from parent SslServerCertValidator r12337,2116,data/crawl/squid/hunk_1827.cpp,,,data/crawl/squid/old_hunk_1827.cpp,data/crawl/squid/new_hunk_1827.cpp,5,5,"fprintf(stderr, ""%s| %s: INFO: User %s authenticated\n"", LogTime(),
                        PROGRAM, user);","fprintf(stderr, ""%s| %s: INFO: User %s authenticated\n"", LogTime(),
                        PROGRAM, rfc1738_escape(user));","[""addVariable""]","[[], [""rfc1738_escape""]]",[2496725644890865050],7345,0.0,4
https://github.com/squid-cache/squid/commit/fa2301d26b90cbd1298eb7740e8827c7746cd9d2,01 Jan 2014,"Initial Large Rock and Collapsed Forwarding support.

Large Rock: Support disk (and shared memory) caching of responses exceeding
one db slot (or one shared memory page) in size. A single db slot/page size is
still limited to 32KB (smaller values can be configured for disk caches using
the newly added cache_dir slot-size option). Removal of old rock cache dir
(followed by squid-z) is required -- the on-disk db structure has changed.

Collapsed Forwarding: Optionally merge concurrent cachable requests for the
same URI earlier: After the request headers have been parsed (as before), but
now _before_ the response headers have been received. Merging of requests
received by different SMP workers is supported. Controlled by the new
collapsed_forwarding directive in squid.conf. Disabled by default because all
but one of the merged requests have to be delayed (until the response headers
are received) for the merging to work, which may be worse than forwarding all
concurrent requests immediately. The overall feature idea and request
eligibility conditions are based on Collapsed Forwarding in Squid2.


Summary of other important changes (merged branch log contains the details):

* Tightened StoreEntry locking. Split StoreEntry::lock() into ""just lock"" and
  ""update entry reference time"" interfaces, addressing an old XXX.  Improved
  entry lock/unlock debugging. Needs more work.

* Adjusted StoreIOState::write() API to allow callers detect write errors.

* Simplified MemObject::write() API to remove an essentially unused callback.

* Mark client streams that sent everything as STREAM_COMPLETE. The old code
  used STREAM_UNPLANNED_COMPLETE if the completed stream was associated with a
  non-persistent connection, which did not make sense to me and, IIRC, led to
  store entry aborts even though the entries were not damaged in any way.

* mem_hdr::hasContigousContentRange() now returns true for empty ranges.

* Support ""appending"" ReadWriteLock state that can be shared by readers and
  the writer. The writer promises not to update key metadata (except growing
  object size and next pointers) and readers promise to be careful when
  reading growing slices.

* Fixed StoreEntry::mayStartSwapOut() logic to handle terminated swapouts.

* Improved STORE_MEM_CLIENT detection and documented known (and mostly old)
  StoreEntry::storeClientType() problems.

* Removed StoreEntry::hidden_mem_obj hack.

* Polished StoreEntry debugging to report more info, less noise. Use e: prefix.

* Added a script to extract store entry(ies) debugging from cache.log.",6196,data/crawl/squid/hunk_1641.cpp,,,data/crawl/squid/old_hunk_1641.cpp,data/crawl/squid/new_hunk_1641.cpp,-1,77,,"storeAppendPrintf(&e, ""Maximum entries: %9d\n"", limit);","[""addLog""]","[[], [""storeAppendPrintf"", ""&e"", ""Maximum"", ""entries"", ""%9d\\n"", ""limit""]]",[26042438292031601741],7344,469080.0,4
https://github.com/squid-cache/squid/commit/ae61f2a70b4839175e1896fb984276ec9b122686,17 Mar 2014,Remove XMALLOC_TRACE and references to sbrk(2),348,data/crawl/squid/hunk_1576.cpp,,,data/crawl/squid/old_hunk_1576.cpp,data/crawl/squid/new_hunk_1576.cpp,162,-1,"fprintf(stderr, ""----- Memory map ----\n"");",,"[""removeLog""]","[[""fprintf"", ""stderr"", ""Memory"", ""map"", ""\\n""], []]",[591730028667204742],7343,5904000.0,4
https://github.com/squid-cache/squid/commit/4795daa2059af1e226cea497a3612a900af9afc5,12 Apr 2014,Use SBufList instead of wordlist to collect data for mgr:config,529,data/crawl/squid/hunk_1530.cpp,,,data/crawl/squid/old_hunk_1530.cpp,data/crawl/squid/new_hunk_1530.cpp,-1,8,,"rv.Printf(""%d-"", status1);","[""addLog""]","[[], [""rv"", ""Printf"", ""%d"", ""status1""]]",[84807196141561062],7342,720.0,4
https://github.com/squid-cache/squid/commit/ba1b862c8e2fb4ac6002432c2f16041119c02758,29 May 2014,merge from trunk r13423,5144,data/crawl/squid/hunk_1421.cpp,,,data/crawl/squid/old_hunk_1421.cpp,data/crawl/squid/new_hunk_1421.cpp,-1,521,,"buf.Printf(""Stopped, reason:"");","[""addLog""]","[[], [""buf"", ""Printf"", ""Stopped"", ""reason""]]",[2846851238253798841],7341,2468520.0,4
https://github.com/squid-cache/squid/commit/ba1b862c8e2fb4ac6002432c2f16041119c02758,29 May 2014,merge from trunk r13423,5144,data/crawl/squid/hunk_1418.cpp,,,data/crawl/squid/old_hunk_1418.cpp,data/crawl/squid/new_hunk_1418.cpp,-1,31,,"notifyManager(""pop"");","[""addLog""]","[[], [""notifyManager"", ""pop""]]",[9036858764262246947],7340,28800.0,4
https://github.com/squid-cache/squid/commit/ba1b862c8e2fb4ac6002432c2f16041119c02758,29 May 2014,merge from trunk r13423,5144,data/crawl/squid/hunk_1418.cpp,,,data/crawl/squid/old_hunk_1418.cpp,data/crawl/squid/new_hunk_1418.cpp,-1,18,,"notifyManager(""pop failure"");","[""addLog""]","[[], [""notifyManager"", ""pop"", ""failure""]]",[5056153533980692852],7339,28800.0,4
https://github.com/squid-cache/squid/commit/ba1b862c8e2fb4ac6002432c2f16041119c02758,29 May 2014,merge from trunk r13423,5144,data/crawl/squid/hunk_1418.cpp,,,data/crawl/squid/old_hunk_1418.cpp,data/crawl/squid/new_hunk_1418.cpp,-1,5,,"notifyManager(""push"");","[""addLog""]","[[], [""notifyManager"", ""push""]]",[10170405422719313165],7338,28800.0,4
https://github.com/squid-cache/squid/commit/ba1b862c8e2fb4ac6002432c2f16041119c02758,29 May 2014,merge from trunk r13423,5144,data/crawl/squid/hunk_1416.cpp,,,data/crawl/squid/old_hunk_1416.cpp,data/crawl/squid/new_hunk_1416.cpp,-1,4,,"parent_->notifyManager(""idle conn closure"");","[""addLog""]","[[], [""parent_"", ""notifyManager"", ""idle"", ""conn"", ""closure""]]",[12613105253019535517],7337,28800.0,4
https://github.com/squid-cache/squid/commit/ba1b862c8e2fb4ac6002432c2f16041119c02758,29 May 2014,merge from trunk r13423,5144,data/crawl/squid/hunk_1415.cpp,,,data/crawl/squid/old_hunk_1415.cpp,data/crawl/squid/new_hunk_1415.cpp,-1,4,,"storeAppendPrintf(sentry, "" standby=%d"", p->standby.limit);","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""standby"", ""%d"", ""p"", ""standby"", ""limit""]]",[-1407114076367375992],7336,28800.0,4
https://github.com/squid-cache/squid/commit/ba1b862c8e2fb4ac6002432c2f16041119c02758,29 May 2014,merge from trunk r13423,5144,data/crawl/squid/hunk_1406.cpp,,,data/crawl/squid/old_hunk_1406.cpp,data/crawl/squid/new_hunk_1406.cpp,9,10,"fatal(""unknown external_acl format error"");","fatalf(""ERROR: unknown external_acl_type format %u"", (uint8_t)format->type);","[""updateLog"", ""updateContent"", ""addVariable""]","[[""fatal"", ""external_acl"", ""error""], [""fatalf"", ""ERROR"", ""external_acl_type"", ""%u"", ""uint8_t"", ""format"", ""type""]]",[25799921375167280930],7335,21240.0,4
https://github.com/squid-cache/squid/commit/ba1b862c8e2fb4ac6002432c2f16041119c02758,29 May 2014,merge from trunk r13423,5144,data/crawl/squid/hunk_1401.cpp,,,data/crawl/squid/old_hunk_1401.cpp,data/crawl/squid/new_hunk_1401.cpp,-1,4,,"fatalf(""ERROR: cache_peer %s max-conn=%d is lower than its standby=%d\n"", p->host, p->max_conn, p->standby.limit);","[""addLog""]","[[], [""fatalf"", ""ERROR"", ""cache_peer"", ""%s"", ""max"", ""conn"", ""%d"", ""is"", ""lower"", ""than"", ""its"", ""standby"", ""%d\\n"", ""p"", ""host"", ""p"", ""max_conn"", ""p"", ""standby"", ""limit""]]",[29364651481153957321],7334,28800.0,4
https://github.com/squid-cache/squid/commit/ba1b862c8e2fb4ac6002432c2f16041119c02758,29 May 2014,merge from trunk r13423,5144,data/crawl/squid/hunk_1391.cpp,,,data/crawl/squid/old_hunk_1391.cpp,data/crawl/squid/new_hunk_1391.cpp,-1,4,,"closeServerConnection(""~FwdState"");","[""addLog""]","[[], [""closeServerConnection"", ""FwdState""]]",[-4006801213804189218],7333,28800.0,4
https://github.com/squid-cache/squid/commit/ba1b862c8e2fb4ac6002432c2f16041119c02758,29 May 2014,merge from trunk r13423,5144,data/crawl/squid/hunk_1390.cpp,,,data/crawl/squid/old_hunk_1390.cpp,data/crawl/squid/new_hunk_1390.cpp,-1,46,,"fwd->closeServerConnection(""store entry aborted"");","[""addLog""]","[[], [""fwd"", ""closeServerConnection"", ""store"", ""entry"", ""aborted""]]",[-17743666038846039931],7332,28800.0,4
https://github.com/squid-cache/squid/commit/ba1b862c8e2fb4ac6002432c2f16041119c02758,29 May 2014,merge from trunk r13423,5144,data/crawl/squid/hunk_1389.cpp,,,data/crawl/squid/old_hunk_1389.cpp,data/crawl/squid/new_hunk_1389.cpp,11,11,"storeAppendPrintf(sentry, ""check_callback\t%d\t-\n"", squidaio_counts.check_callback);","storeAppendPrintf(sentry, ""  check_callback\t%"" PRIu64 ""\t-\n"", squidaio_counts.check_callback);","[""updateContent"", ""addContent"", ""addVariable""]","[[""check_callback\\t%d\\t""], [""check_callback\\t%"", ""PRIu64"", ""\\t""]]",[13077690418461584331],7331,15840.0,4
https://github.com/squid-cache/squid/commit/ba1b862c8e2fb4ac6002432c2f16041119c02758,29 May 2014,merge from trunk r13423,5144,data/crawl/squid/hunk_1389.cpp,,,data/crawl/squid/old_hunk_1389.cpp,data/crawl/squid/new_hunk_1389.cpp,10,10,"storeAppendPrintf(sentry, ""unlink\t%d\t%d\n"", squidaio_counts.unlink_start, squidaio_counts.unlink_finish);","storeAppendPrintf(sentry, ""  unlink\t%"" PRIu64 ""\t%"" PRIu64 ""\n"", squidaio_counts.unlink_start, squidaio_counts.unlink_finish);","[""updateContent"", ""addContent"", ""addVariable""]","[[""unlink\\t%d\\t%d\\n""], [""unlink\\t%"", ""PRIu64"", ""\\t%"", ""PRIu64"", ""\\n""]]",[28793593602667734210],7330,15840.0,4
https://github.com/squid-cache/squid/commit/ba1b862c8e2fb4ac6002432c2f16041119c02758,29 May 2014,merge from trunk r13423,5144,data/crawl/squid/hunk_1389.cpp,,,data/crawl/squid/old_hunk_1389.cpp,data/crawl/squid/new_hunk_1389.cpp,9,9,"storeAppendPrintf(sentry, ""stat\t%d\t%d\n"", squidaio_counts.stat_start, squidaio_counts.stat_finish);","storeAppendPrintf(sentry, ""  stat\t%"" PRIu64 ""\t%"" PRIu64 ""\n"", squidaio_counts.stat_start, squidaio_counts.stat_finish);","[""updateContent"", ""addContent"", ""addVariable""]","[[""stat\\t%d\\t%d\\n""], [""stat\\t%"", ""PRIu64"", ""\\t%"", ""PRIu64"", ""\\n""]]",[7585794040815471036],7329,15840.0,4
https://github.com/squid-cache/squid/commit/ba1b862c8e2fb4ac6002432c2f16041119c02758,29 May 2014,merge from trunk r13423,5144,data/crawl/squid/hunk_1389.cpp,,,data/crawl/squid/old_hunk_1389.cpp,data/crawl/squid/new_hunk_1389.cpp,8,8,"storeAppendPrintf(sentry, ""read\t%d\t%d\n"", squidaio_counts.read_start, squidaio_counts.read_finish);","storeAppendPrintf(sentry, ""  read\t%"" PRIu64 ""\t%"" PRIu64 ""\n"", squidaio_counts.read_start, squidaio_counts.read_finish);","[""updateContent"", ""addContent"", ""addVariable""]","[[""read\\t%d\\t%d\\n""], [""read\\t%"", ""PRIu64"", ""\\t%"", ""PRIu64"", ""\\n""]]",[16358681470435711100],7328,15840.0,4
https://github.com/squid-cache/squid/commit/ba1b862c8e2fb4ac6002432c2f16041119c02758,29 May 2014,merge from trunk r13423,5144,data/crawl/squid/hunk_1389.cpp,,,data/crawl/squid/old_hunk_1389.cpp,data/crawl/squid/new_hunk_1389.cpp,7,7,"storeAppendPrintf(sentry, ""write\t%d\t%d\n"", squidaio_counts.write_start, squidaio_counts.write_finish);","storeAppendPrintf(sentry, ""  write\t%"" PRIu64 ""\t%"" PRIu64 ""\n"", squidaio_counts.write_start, squidaio_counts.write_finish);","[""updateContent"", ""addContent"", ""addVariable""]","[[""write\\t%d\\t%d\\n""], [""write\\t%"", ""PRIu64"", ""\\t%"", ""PRIu64"", ""\\n""]]",[18762541978395181280],7327,15840.0,4
https://github.com/squid-cache/squid/commit/ba1b862c8e2fb4ac6002432c2f16041119c02758,29 May 2014,merge from trunk r13423,5144,data/crawl/squid/hunk_1389.cpp,,,data/crawl/squid/old_hunk_1389.cpp,data/crawl/squid/new_hunk_1389.cpp,6,6,"storeAppendPrintf(sentry, ""cancel\t%d\t-\n"", squidaio_counts.cancel);","storeAppendPrintf(sentry, ""  cancel\t%"" PRIu64 ""\t-\n"", squidaio_counts.cancel);","[""updateContent"", ""addContent"", ""addVariable""]","[[""cancel\\t%d\\t""], [""cancel\\t%"", ""PRIu64"", ""\\t""]]",[13802078768900448067],7326,15840.0,4
https://github.com/squid-cache/squid/commit/ba1b862c8e2fb4ac6002432c2f16041119c02758,29 May 2014,merge from trunk r13423,5144,data/crawl/squid/hunk_1389.cpp,,,data/crawl/squid/old_hunk_1389.cpp,data/crawl/squid/new_hunk_1389.cpp,5,5,"storeAppendPrintf(sentry, ""close\t%d\t%d\n"", squidaio_counts.close_start, squidaio_counts.close_finish);","storeAppendPrintf(sentry, ""  close\t%"" PRIu64 ""\t%"" PRIu64 ""\n"", squidaio_counts.close_start, squidaio_counts.close_finish);","[""updateContent"", ""addContent"", ""addVariable""]","[[""close\\t%d\\t%d\\n""], [""close\\t%"", ""PRIu64"", ""\\t%"", ""PRIu64"", ""\\n""]]",[11133942527068290366],7325,15840.0,4
https://github.com/squid-cache/squid/commit/ba1b862c8e2fb4ac6002432c2f16041119c02758,29 May 2014,merge from trunk r13423,5144,data/crawl/squid/hunk_1389.cpp,,,data/crawl/squid/old_hunk_1389.cpp,data/crawl/squid/new_hunk_1389.cpp,4,4,"storeAppendPrintf(sentry, ""open\t%d\t%d\n"", squidaio_counts.open_start, squidaio_counts.open_finish);","storeAppendPrintf(sentry, ""  open\t%"" PRIu64 ""\t%"" PRIu64 ""\n"", squidaio_counts.open_start, squidaio_counts.open_finish);","[""updateContent"", ""addContent"", ""addVariable""]","[[""open\\t%d\\t%d\\n""], [""open\\t%"", ""PRIu64"", ""\\t%"", ""PRIu64"", ""\\n""]]",[11931890377534102028],7324,15840.0,4
https://github.com/squid-cache/squid/commit/ba1b862c8e2fb4ac6002432c2f16041119c02758,29 May 2014,merge from trunk r13423,5144,data/crawl/squid/hunk_1388.cpp,,,data/crawl/squid/old_hunk_1388.cpp,data/crawl/squid/new_hunk_1388.cpp,-1,10,,"fprintf(stdout, ""%"" PRId64 "" ERR\n"", channelId);","[""addLog""]","[[], [""fprintf"", ""stdout"", ""%"", ""PRId64"", ""ERR\\n"", ""channelId""]]",[6318793926672518033],7323,23400.0,4
https://github.com/squid-cache/squid/commit/ba1b862c8e2fb4ac6002432c2f16041119c02758,29 May 2014,merge from trunk r13423,5144,data/crawl/squid/hunk_1388.cpp,,,data/crawl/squid/old_hunk_1388.cpp,data/crawl/squid/new_hunk_1388.cpp,4,7,"fprintf(stdout,""\n"");","fprintf(stdout,""ERR\n"");","[""updateContent""]","[[""\\n""], [""ERR\\n""]]",[8273362714302273978],7322,23400.0,4
https://github.com/squid-cache/squid/commit/d1f3d8f885784c89a822c35ddf6537aab3a3b925,06 Aug 2014,merge from trunk r13526,34418,data/crawl/squid/hunk_1287.cpp,,,data/crawl/squid/old_hunk_1287.cpp,data/crawl/squid/new_hunk_1287.cpp,22,-1,"storeAppendPrintf(entry, ""%s basic children %d startup=%d idle=%d concurrency=%d\n"", name, authenticateChildren.n_max, authenticateChildren.n_startup, authenticateChildren.n_idle, authenticateChildren.concurrency);",,"[""removeLog""]","[[""storeAppendPrintf"", ""entry"", ""%s"", ""basic"", ""children"", ""%d"", ""startup"", ""%d"", ""idle"", ""%d"", ""concurrency"", ""%d\\n"", ""name"", ""authenticateChildren"", ""n_max"", ""authenticateChildren"", ""n_startup"", ""authenticateChildren"", ""n_idle"", ""authenticateChildren"", ""concurrency""], []]",[-41838630015929548659],7321,25920.0,4
https://github.com/squid-cache/squid/commit/d1f3d8f885784c89a822c35ddf6537aab3a3b925,06 Aug 2014,merge from trunk r13526,34418,data/crawl/squid/hunk_1285.cpp,,,data/crawl/squid/old_hunk_1285.cpp,data/crawl/squid/new_hunk_1285.cpp,-1,19,,"storeAppendPrintf(entry, ""%s %s children %d startup=%d idle=%d concurrency=%d\n"",
                      name, scheme->type(),
                      authenticateChildren.n_max, authenticateChildren.n_startup,
                      authenticateChildren.n_idle, authenticateChildren.concurrency);","[""addLog""]","[[], [""storeAppendPrintf"", ""entry"", ""%s"", ""%s"", ""children"", ""%d"", ""startup"", ""%d"", ""idle"", ""%d"", ""concurrency"", ""%d\\n"", ""name"", ""scheme"", ""type"", ""authenticateChildren"", ""n_max"", ""authenticateChildren"", ""n_startup"", ""authenticateChildren"", ""n_idle"", ""authenticateChildren"", ""concurrency""]]",[48453486322322680081],7320,25920.0,4
https://github.com/squid-cache/squid/commit/154ea56667e82cf7217580817f9088397a86a694,13 Aug 2014,"Rearrange PROXY/1.0 parser

Add a first pass to confirm LF line terminator and wait for more bytes if
missing.",46,data/crawl/squid/hunk_1229.cpp,,,data/crawl/squid/old_hunk_1229.cpp,data/crawl/squid/new_hunk_1229.cpp,9,25,"proxyProtocolError(tok.atEnd() ? ""PROXY/1.0 error: missing TCP version"" : NULL);","proxyProtocolError(""PROXY/1.0 error: missing TCP version"");","[""moveContent"", ""removeVariable""]","[[""tok"", ""atEnd"", ""NULL""], []]",[13399002909542979497],7319,0.0,4
https://github.com/squid-cache/squid/commit/c6649f6c62f90053f0bf0f162918a94f1d763b3d,26 Aug 2014,merge from trunk,14018,data/crawl/squid/hunk_1214.cpp,,,data/crawl/squid/old_hunk_1214.cpp,data/crawl/squid/new_hunk_1214.cpp,-1,167,,"rep->header.putStr(HDR_CONNECTION, ""keep-alive"");","[""addLog""]","[[], [""rep"", ""header"", ""putStr"", ""HDR_CONNECTION"", ""keep"", ""alive""]]",[-6436086023878567355],7318,1548360.0,4
https://github.com/squid-cache/squid/commit/c6649f6c62f90053f0bf0f162918a94f1d763b3d,26 Aug 2014,merge from trunk,14018,data/crawl/squid/hunk_1214.cpp,,,data/crawl/squid/old_hunk_1214.cpp,data/crawl/squid/new_hunk_1214.cpp,-1,125,,"stopReceiving(""virgin request body consumer aborted"");","[""addLog""]","[[], [""stopReceiving"", ""virgin"", ""request"", ""body"", ""consumer"", ""aborted""]]",[-7986465492880148666],7317,1060200.0,4
https://github.com/squid-cache/squid/commit/c6649f6c62f90053f0bf0f162918a94f1d763b3d,26 Aug 2014,merge from trunk,14018,data/crawl/squid/hunk_1212.cpp,,,data/crawl/squid/old_hunk_1212.cpp,data/crawl/squid/new_hunk_1212.cpp,-1,1578,,"header.putStr(HDR_FTP_ARGUMENTS, """");","[""addLog""]","[[], [""header"", ""putStr"", ""HDR_FTP_ARGUMENTS""]]",[-7630026048812294592],7316,305280.0,4
https://github.com/squid-cache/squid/commit/c6649f6c62f90053f0bf0f162918a94f1d763b3d,26 Aug 2014,merge from trunk,14018,data/crawl/squid/hunk_1212.cpp,,,data/crawl/squid/old_hunk_1212.cpp,data/crawl/squid/new_hunk_1212.cpp,-1,1576,,"header.putStr(HDR_FTP_COMMAND, ""PASV"");","[""addLog""]","[[], [""header"", ""putStr"", ""HDR_FTP_COMMAND"", ""PASV""]]",[1357199028149208865],7315,305280.0,4
https://github.com/squid-cache/squid/commit/c6649f6c62f90053f0bf0f162918a94f1d763b3d,26 Aug 2014,merge from trunk,14018,data/crawl/squid/hunk_1212.cpp,,,data/crawl/squid/old_hunk_1212.cpp,data/crawl/squid/new_hunk_1212.cpp,-1,411,,"mb.Printf(""150 Data connection opened.\r\n"");","[""addLog""]","[[], [""mb"", ""Printf"", ""150"", ""Data"", ""connection"", ""opened"", ""\\r\\n""]]",[-5488740528201876078],7314,222120.0,4
https://github.com/squid-cache/squid/commit/c6649f6c62f90053f0bf0f162918a94f1d763b3d,26 Aug 2014,merge from trunk,14018,data/crawl/squid/hunk_1191.cpp,,,data/crawl/squid/old_hunk_1191.cpp,data/crawl/squid/new_hunk_1191.cpp,-1,3,,"csd->abortRequestParsing(""error:request-too-large"");","[""addLog""]","[[], [""csd"", ""abortRequestParsing"", ""error"", ""request"", ""too"", ""large""]]",[2217293304187969653],7313,5040.0,4
https://github.com/squid-cache/squid/commit/c6649f6c62f90053f0bf0f162918a94f1d763b3d,26 Aug 2014,merge from trunk,14018,data/crawl/squid/hunk_1186.cpp,,,data/crawl/squid/old_hunk_1186.cpp,data/crawl/squid/new_hunk_1186.cpp,17,-1,"fatalf(""http(s)_port protocol=%s is not supported\n"", aProtocol);",,"[""removeLog""]","[[""fatalf"", ""http"", ""s"", ""_port"", ""protocol"", ""%s"", ""is"", ""not"", ""supported\\n"", ""aProtocol""], []]",[-39699959897722009250],7312,7200.0,4
https://github.com/squid-cache/squid/commit/ee74db84d2cf476c8f4a1d4942eae9f94c677678,09 Jul 2015,c++-ize unlinkd,22,data/crawl/squid/hunk_666.cpp,,,data/crawl/squid/old_hunk_666.cpp,data/crawl/squid/new_hunk_666.cpp,20,-1,"printf(""OK\n"");",,"[""removeLog""]","[[""printf"", ""OK\\n""], []]",[-7225515199027138487],7311,2216160.0,4
https://github.com/squid-cache/squid/commit/858c5afb99c9594aaf3169f905da635ef8d74f96,13 Jul 2015,"Cleanup: Shuffle Squid result codes (aka log tags) into class LogTags

This begins the migration of result codes from enumeration to a
set of flags whih can combine into much more flexible logging of
transation activity than hard-coded labels enumerating every
individual code path.

The existing ABORTED and TIMEDOUT state flags are also moved into
the new class as an example of how such flags would operate.",284,data/crawl/squid/hunk_647.cpp,,,data/crawl/squid/old_hunk_647.cpp,data/crawl/squid/new_hunk_647.cpp,3,3,"storeAppendPrintf(sentry, ""        %-20.20s %7d %3d%%\n"",LogTags_str[l], c->Icp.result_hist[l], Math::intPercent(c->Icp.result_hist[l], c->Icp.n_requests));","storeAppendPrintf(sentry, ""        %-20.20s %7d %3d%%\n"", LogTags(l).c_str(), c->Icp.result_hist[l], Math::intPercent(c->Icp.result_hist[l], c->Icp.n_requests));","[""moveVariable"", ""removeVariable"", ""addVariable""]","[[""LogTags_str[l]""], [""LogTags"", ""l"", ""c_str""]]",[-2018681310503768858],7310,23040.0,4
https://github.com/squid-cache/squid/commit/789217a2d102b1c99734afd7d48e4d4210ec009d,04 Aug 2015,"Renamed http_hdr_type to Http::HdrType, fixed some HdrType-int implicit conversions",1702,data/crawl/squid/hunk_617.cpp,,,data/crawl/squid/old_hunk_617.cpp,data/crawl/squid/new_hunk_617.cpp,10,10,"hdr_out->putStr(HDR_HOST, request->peer_domain);","hdr_out->putStr(Http::HdrType::HOST, request->peer_domain);","[""removeVariable"", ""addVariable""]","[[""HDR_HOST""], [""Http"", ""HdrType"", ""HOST""]]",[26551869338292852740],7309,0.0,4
https://github.com/squid-cache/squid/commit/789217a2d102b1c99734afd7d48e4d4210ec009d,04 Aug 2015,"Renamed http_hdr_type to Http::HdrType, fixed some HdrType-int implicit conversions",1702,data/crawl/squid/hunk_607.cpp,,,data/crawl/squid/old_hunk_607.cpp,data/crawl/squid/new_hunk_607.cpp,3,3,"reply->header.putStr(HDR_FTP_PRE, httpHeaderQuoteString(W->key).c_str());","reply->header.putStr(Http::HdrType::FTP_PRE, httpHeaderQuoteString(W->key).c_str());","[""removeVariable"", ""addVariable""]","[[""HDR_FTP_PRE""], [""Http"", ""HdrType"", ""FTP_PRE""]]",[2250285213106812856],7308,0.0,4
https://github.com/squid-cache/squid/commit/af845cee67e3dc2a58f93a9ac7d9ce091ea4fa00,11 Sep 2015,"Bug 4292: negotiate_wrapper: Unreleased Resources

FILE* handles need to be closed on exit. Shuffle the processing loop logics
to a static function to avoid code duplication from all the requires close
points.

Also, use the available global flag debug_enabled instead of local variable
to avoid having to pass it down explicitly.",337,data/crawl/squid/hunk_580.cpp,,,data/crawl/squid/old_hunk_580.cpp,data/crawl/squid/new_hunk_580.cpp,42,-1,"fprintf(stderr, ""%s| %s: Invalid request [%s]\n"", LogTime(),
                        PROGRAM, buf);",,"[""removeLog""]","[[""fprintf"", ""stderr"", ""%s"", ""%s"", ""Invalid"", ""request"", ""[%s]\\n"", ""LogTime"", ""PROGRAM"", ""buf""], []]",[20974463790759197551],7307,1537920.0,4
https://github.com/squid-cache/squid/commit/af845cee67e3dc2a58f93a9ac7d9ce091ea4fa00,11 Sep 2015,"Bug 4292: negotiate_wrapper: Unreleased Resources

FILE* handles need to be closed on exit. Shuffle the processing loop logics
to a static function to avoid code duplication from all the requires close
points.

Also, use the available global flag debug_enabled instead of local variable
to avoid having to pass it down explicitly.",337,data/crawl/squid/hunk_580.cpp,,,data/crawl/squid/old_hunk_580.cpp,data/crawl/squid/new_hunk_580.cpp,12,-1,"fprintf(stdout, ""BH input error\n"");",,"[""removeLog""]","[[""fprintf"", ""stdout"", ""BH"", ""input"", ""error\\n""], []]",[27673462301926708073],7306,1537920.0,4
https://github.com/squid-cache/squid/commit/af845cee67e3dc2a58f93a9ac7d9ce091ea4fa00,11 Sep 2015,"Bug 4292: negotiate_wrapper: Unreleased Resources

FILE* handles need to be closed on exit. Shuffle the processing loop logics
to a static function to avoid code duplication from all the requires close
points.

Also, use the available global flag debug_enabled instead of local variable
to avoid having to pass it down explicitly.",337,data/crawl/squid/hunk_574.cpp,,,data/crawl/squid/old_hunk_574.cpp,data/crawl/squid/new_hunk_574.cpp,-1,83,,"fprintf(stderr, ""%s| %s: Invalid negotiate request [%s]\n"",
                        LogTime(), PROGRAM, buf);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""%s"", ""%s"", ""Invalid"", ""negotiate"", ""request"", ""[%s]\\n"", ""LogTime"", ""PROGRAM"", ""buf""]]",[-24305751704748737954],7305,1891440.0,4
https://github.com/squid-cache/squid/commit/af845cee67e3dc2a58f93a9ac7d9ce091ea4fa00,11 Sep 2015,"Bug 4292: negotiate_wrapper: Unreleased Resources

FILE* handles need to be closed on exit. Shuffle the processing loop logics
to a static function to avoid code duplication from all the requires close
points.

Also, use the available global flag debug_enabled instead of local variable
to avoid having to pass it down explicitly.",337,data/crawl/squid/hunk_574.cpp,,,data/crawl/squid/old_hunk_574.cpp,data/crawl/squid/new_hunk_574.cpp,-1,58,,"fprintf(stderr, ""%s| %s: Invalid request\n"", LogTime(),
                        PROGRAM);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""%s"", ""%s"", ""Invalid"", ""request\\n"", ""LogTime"", ""PROGRAM""]]",[-11683222101142235699],7304,1891440.0,4
https://github.com/squid-cache/squid/commit/af845cee67e3dc2a58f93a9ac7d9ce091ea4fa00,11 Sep 2015,"Bug 4292: negotiate_wrapper: Unreleased Resources

FILE* handles need to be closed on exit. Shuffle the processing loop logics
to a static function to avoid code duplication from all the requires close
points.

Also, use the available global flag debug_enabled instead of local variable
to avoid having to pass it down explicitly.",337,data/crawl/squid/hunk_574.cpp,,,data/crawl/squid/old_hunk_574.cpp,data/crawl/squid/new_hunk_574.cpp,-1,50,,"fprintf(stderr, ""%s| %s: Oversized message\n"", LogTime(),
                        PROGRAM);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""%s"", ""%s"", ""Oversized"", ""message\\n"", ""LogTime"", ""PROGRAM""]]",[-10148544130211447693],7303,1891440.0,4
https://github.com/squid-cache/squid/commit/af845cee67e3dc2a58f93a9ac7d9ce091ea4fa00,11 Sep 2015,"Bug 4292: negotiate_wrapper: Unreleased Resources

FILE* handles need to be closed on exit. Shuffle the processing loop logics
to a static function to avoid code duplication from all the requires close
points.

Also, use the available global flag debug_enabled instead of local variable
to avoid having to pass it down explicitly.",337,data/crawl/squid/hunk_574.cpp,,,data/crawl/squid/old_hunk_574.cpp,data/crawl/squid/new_hunk_574.cpp,-1,30,,"fprintf(stderr,
                            ""%s| %s: fgets() failed! dying..... errno=%d (%s)\n"",
                            LogTime(), PROGRAM, ferror(stdin),
                            strerror(ferror(stdin)));","[""addLog""]","[[], [""fprintf"", ""stderr"", ""%s"", ""%s"", ""fgets"", ""failed"", ""dying"", ""errno"", ""%d"", ""%s"", ""\\n"", ""LogTime"", ""PROGRAM"", ""ferror"", ""stdin"", ""strerror"", ""ferror"", ""stdin""]]",[-20226450349386740227],7302,1891440.0,4
https://github.com/squid-cache/squid/commit/d3b1bee6fff7792f482ff280e8400c6a3e83560f,14 Dec 2015,merge from trunk r14444,9318,data/crawl/squid/hunk_475.cpp,,,data/crawl/squid/old_hunk_475.cpp,data/crawl/squid/new_hunk_475.cpp,-1,228,,"fatal(""'store_avg_object_size' should be larger than 0."");","[""addLog""]","[[], [""fatal"", ""store_avg_object_size"", ""should"", ""be"", ""larger"", ""than"", ""0""]]",[4169576952635120669],7301,1132920.0,4
https://github.com/squid-cache/squid/commit/d3b1bee6fff7792f482ff280e8400c6a3e83560f,14 Dec 2015,merge from trunk r14444,9318,data/crawl/squid/hunk_475.cpp,,,data/crawl/squid/old_hunk_475.cpp,data/crawl/squid/new_hunk_475.cpp,-1,225,,"fatal(""'store_objects_per_bucket' should be larger than 0."");","[""addLog""]","[[], [""fatal"", ""store_objects_per_bucket"", ""should"", ""be"", ""larger"", ""than"", ""0""]]",[-12300532009220373221],7300,1132920.0,4
https://github.com/squid-cache/squid/commit/d3b1bee6fff7792f482ff280e8400c6a3e83560f,14 Dec 2015,merge from trunk r14444,9318,data/crawl/squid/hunk_475.cpp,,,data/crawl/squid/old_hunk_475.cpp,data/crawl/squid/new_hunk_475.cpp,-1,173,,"fatal (""too much io\n"");","[""addLog""]","[[], [""fatal"", ""too"", ""much"", ""io\\n""]]",[-21256136546020748691],7299,4871880.0,4
https://github.com/squid-cache/squid/commit/d3b1bee6fff7792f482ff280e8400c6a3e83560f,14 Dec 2015,merge from trunk r14444,9318,data/crawl/squid/hunk_441.cpp,,,data/crawl/squid/old_hunk_441.cpp,data/crawl/squid/new_hunk_441.cpp,14,-1,"fatal(""No Store Root has been set"");",,"[""removeLog""]","[[""fatal"", ""No"", ""Store"", ""Root"", ""has"", ""been"", ""set""], []]",[14073623743529683832],7298,748440.0,4
https://github.com/squid-cache/squid/commit/48c5f8e9d92304dad9caa0322c0b583408b346a3,30 Jan 2016,"SourceLayout: merge helpers/ into src/

* Move helpers/basic_auth/ into src/auth/basic/

* Move helpers/digest_auth/ into src/auth/digest/

* Move helpers/external_acl/ into src/acl/external/

* Move helpers/log_daemon/ into src/log/

* Move helpers/negotiate_auth/ into src/auth/negotiate/

* Move helpers/ntlm_auth/ into src/auth/ntlm/

* Move helpers/storeid_rewrite/ into src/store/id_rewriters/

* Move helpers/url_rewrite/ into src/http/url_rewriters/

* Rename helpers/defines.h to src/helper/protocol_defines.h",2256,data/crawl/squid/hunk_373.cpp,,,data/crawl/squid/old_hunk_373.cpp,data/crawl/squid/new_hunk_373.cpp,3,3,"fprintf(stderr, ""Usage: basic_yp_auth <domainname> <nis map for password>\n"");","fprintf(stderr, ""Usage: basic_nis_auth <domainname> <nis map for password>\n"");","[""updateContent""]","[[""basic_yp_auth""], [""basic_nis_auth""]]",[-5123814034601454],7297,0.0,4
https://github.com/squid-cache/squid/commit/898d1a09e1d9e8f39de5d34df6793197c0fc8dc4,31 Jan 2016,"SourceLayout: rename ClientSocketContext to Http::Stream

 ... and provided through http/libsquid-http.la.

The name is chosen to match the RFC7540 HTTP/2 ""stream"" terminology.
Which defines a stream as a bi-directional transaction, including request,
reply and all related 1xx informational and/or control messages.

That same word ""stream"" is also used in RFC7230 briefly to describe the
same ""transaction"" scope and details. But not formalized until RFC7540.

Http::Stream's may be initiated by a client HTTP request, Squid internally,
or in HTTP/2 a server PUSH_PROMISE frame.

There are no logic changes in this. Just symbol renaming and move.",1958,data/crawl/squid/hunk_369.cpp,,,data/crawl/squid/old_hunk_369.cpp,data/crawl/squid/new_hunk_369.cpp,-1,97,,"initiateClose(""STREAM_FAILED"");","[""addLog""]","[[], [""initiateClose"", ""STREAM_FAILED""]]",[-774983655038102417],7296,1935000.0,4
https://github.com/squid-cache/squid/commit/0bffe3cec1400f4d69724552e77e77878defd8a3,23 May 2016,"Sync with trunk-r14686

- Replaces with newer versions of BinaryTokenizer and HandshakeParser classes
- Modifications to use latest Handshake parser from trunk.
- Get HandshakeParser::serverCertificates, HandshakeParser::parseServerCertificates and HandshakeParser::ParseCertificate implementation from lp:fast-sni branch",6170,data/crawl/squid/hunk_187.cpp,,,data/crawl/squid/old_hunk_187.cpp,data/crawl/squid/new_hunk_187.cpp,-1,65,,"_db_print(""%s\n"", Current->buf.str().c_str());","[""addLog""]","[[], [""_db_print"", ""%s\\n"", ""Current"", ""buf"", ""str"", ""c_str""]]",[8314283759339014326],7295,2160.0,4
https://github.com/squid-cache/squid/commit/0bffe3cec1400f4d69724552e77e77878defd8a3,23 May 2016,"Sync with trunk-r14686

- Replaces with newer versions of BinaryTokenizer and HandshakeParser classes
- Modifications to use latest Handshake parser from trunk.
- Get HandshakeParser::serverCertificates, HandshakeParser::parseServerCertificates and HandshakeParser::ParseCertificate implementation from lp:fast-sni branch",6170,data/crawl/squid/hunk_187.cpp,,,data/crawl/squid/old_hunk_187.cpp,data/crawl/squid/new_hunk_187.cpp,34,-1,"_db_print(""%s\n"", CurrentDebug->str().c_str());",,"[""removeLog""]","[[""_db_print"", ""%s\\n"", ""CurrentDebug"", ""str"", ""c_str""], []]",[-6980861486925073934],7294,2026080.0,4
https://github.com/squid-cache/squid/commit/c2afddd8f98c17c7a9e03d504b97847065d744e1,30 Nov 2016,"Revert C++11 std::regex changes

CentOS 7 (and thus probably also RHEL 7) still have difficulty using
GCC 5+ compiler necessary for this C++11 code to be used reliably.

see http://lists.squid-cache.org/pipermail/squid-dev/2015-July/002884.html",5399,data/crawl/squid/hunk_120.cpp,,,data/crawl/squid/old_hunk_120.cpp,data/crawl/squid/new_hunk_120.cpp,36,50,"fprintf( debug, ""# match '%s' in \""%s\""\n"", subs[offset].str().c_str(), subs[0].str().c_str());","fprintf( debug, ""# match from %d-%d on \""%s\""\n"",
                                      (int)subs[offset].rm_so,
                                      (int)subs[offset].rm_eo,
                                      line+subs[offset].rm_so );","[""updateVariable"", ""moveVariable"", ""removeVariable"", ""updateContent"", ""removeContent"", ""addVariable""]","[[""%s"", ""in"", ""str"", ""c_str"", ""subs[0]"", ""str"", ""c_str""], [""from"", ""%d"", ""%d"", ""on"", ""int"", ""rm_so"", ""int"", ""subs[offset]"", ""rm_eo"", ""line"", ""subs[offset]"", ""rm_so""]]",[-18914542953596725113],7293,0.0,4
https://github.com/squid-cache/squid/commit/b2b09838674dab260d6727026697da81afee70b4,20 Dec 2016,De-duplicate shared auth parameters keep_alive and utf8,144,data/crawl/squid/hunk_110.cpp,,,data/crawl/squid/old_hunk_110.cpp,data/crawl/squid/new_hunk_110.cpp,4,6,"storeAppendPrintf(entry, ""%s %s"", name, scheme->type());","storeAppendPrintf(entry, ""%s %s"", name, type);","[""removeVariable"", ""addVariable""]","[[""scheme""], []]",[4226706071475375301],7292,0.0,4
https://github.com/squid-cache/squid/commit/40fc161851f5809741ddb4774e7c366d23323a97,05 Feb 2017,Sync from v5 r15034,2231,data/crawl/squid/hunk_61.cpp,,,data/crawl/squid/old_hunk_61.cpp,data/crawl/squid/new_hunk_61.cpp,11,5,"auth_user_request->denyMessage(""Negotiate Authentication denied with no reason given"");","auth_user_request->denyMessageFromHelper(""Negotiate"", reply);","[""updateLog"", ""updateContent"", ""addVariable""]","[[""denyMessage"", ""Authentication"", ""denied"", ""with"", ""no"", ""reason"", ""given""], [""denyMessageFromHelper"", ""reply""]]",[6858755942896812863],7291,4320.0,4
https://github.com/squid-cache/squid/commit/40fc161851f5809741ddb4774e7c366d23323a97,05 Feb 2017,Sync from v5 r15034,2231,data/crawl/squid/hunk_58.cpp,,,data/crawl/squid/old_hunk_58.cpp,data/crawl/squid/new_hunk_58.cpp,5,5,digest_request->setDenyMessage(msgNote);,digest_request->setDenyMessage(msgNote.c_str());,"[""removeVariable"", ""addVariable""]","[[], [""c_str""]]",[604061038622547682],7290,2160.0,4
https://github.com/squid-cache/squid/commit/ccff960108dab2ce4bff860f2dc34def2f8ca1ae,28 Mar 1996,make pid_filename a config option and create writePidFile() in tools.c,226,data/crawl/squid/hunk_7949.cpp,,,data/crawl/squid/old_hunk_7949.cpp,data/crawl/squid/new_hunk_7949.cpp,12,-1,"fprintf(stderr, ""         messages will be sent to 'stderr'.\n"");",,"[""removeLog""]","[[""fprintf"", ""stderr"", ""messages"", ""will"", ""be"", ""sent"", ""to"", ""stderr"", ""\\n""], []]",[25988502163877975932],7289,0.0,3
https://github.com/squid-cache/squid/commit/6eb42caec6c6db2142568d6dd4426e89e6c16f8f,04 Apr 1996,major code cleanup/unification/rewrite,624,data/crawl/squid/hunk_7891.cpp,,,data/crawl/squid/old_hunk_7891.cpp,data/crawl/squid/new_hunk_7891.cpp,3,3,"fatal_dump(""destroy_StoreEntry: NULL Entry\n"");","fatal_dump(""destroy_StoreEntry: NULL Entry"");","[""updateContent""]","[[""Entry\\n""], [""Entry""]]",[-5374594766037945752],7288,0.0,3
https://github.com/squid-cache/squid/commit/b8de7ebe12756b6d6a09a0b034952c1e11325c95,16 Apr 1996,"change ""cached"" to ""squid"" in lots of places",640,data/crawl/squid/hunk_7838.cpp,,,data/crawl/squid/old_hunk_7838.cpp,data/crawl/squid/new_hunk_7838.cpp,3,3,"printf(""         Change your cached.conf file.\n"");","printf(""         Change your configuration file.\n"");","[""updateContent""]","[[""cached"", ""conf""], [""configuration""]]",[-5312941622082004259],7287,0.0,3
https://github.com/squid-cache/squid/commit/c30c5a739f6b27a74c8750c6b4aa01daad7c813e,19 Apr 1996,use storeAppendPrintf() instead of sprintf();storeAppend(),371,data/crawl/squid/hunk_7824.cpp,,,data/crawl/squid/old_hunk_7824.cpp,data/crawl/squid/new_hunk_7824.cpp,-1,32,,"storeAppendPrintf(sentry, ""{\t\t%s}\n"", p->key);","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""\\t\\t%s"", ""\\n"", ""p"", ""key""]]",[16559813076352035363],7286,0.0,3
https://github.com/squid-cache/squid/commit/30a4f2a885dbb469498c0e805e1e8d42244788be,09 Jul 1996,cleanup after big merge,12717,data/crawl/squid/hunk_7753.cpp,,,data/crawl/squid/old_hunk_7753.cpp,data/crawl/squid/new_hunk_7753.cpp,12,9,"storeAppendPrintf(sentry, ""{\tLargest file desc currently in use:\t%d}\n"",
	fdstat_biggest_fd());","storeAppendPrintf(sentry, ""{\tLargest file desc currently in use:   %4d}\n"",
	fdstat_biggest_fd());","[""updateContent""]","[[""\\t%d""], [""%4d""]]",[391083725521778503],7285,0.0,3
https://github.com/squid-cache/squid/commit/30a4f2a885dbb469498c0e805e1e8d42244788be,09 Jul 1996,cleanup after big merge,12717,data/crawl/squid/hunk_7745.cpp,,,data/crawl/squid/old_hunk_7745.cpp,data/crawl/squid/new_hunk_7745.cpp,3,3,"storeAppendPrintf(data->sentry, ""}\n"");","storeAppendPrintf(data->sentry, close_bracket);","[""removeContent"", ""addVariable""]","[[""\\n""], [""close_bracket""]]",[8723675099856431368],7284,0.0,3
https://github.com/squid-cache/squid/commit/d51e52f5fef6a82ca1a7cf1be5e55f2c1d16b3ce,10 Jul 1996,"mucho cleanup, mostly separate filedescriptor output into separate function",248,data/crawl/squid/hunk_7700.cpp,,,data/crawl/squid/old_hunk_7700.cpp,data/crawl/squid/new_hunk_7700.cpp,-1,65,,"storeAppendPrintf(sentry, ""%31s %s}\n"", """", fd_note(i, NULL));","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""%31s"", ""%s"", ""\\n"", ""fd_note"", ""i"", ""NULL""]]",[2238263000112151173],7283,0.0,3
https://github.com/squid-cache/squid/commit/d2af947760f5e7a92ab3bf260744c55ce19ac073,11 Jul 1996,redirector up to snuff,639,data/crawl/squid/hunk_7697.cpp,,,data/crawl/squid/old_hunk_7697.cpp,data/crawl/squid/new_hunk_7697.cpp,-1,102,,"storeAppendPrintf(sentry, open_bracket);","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""open_bracket""]]",[14991446791886401303],7282,1440.0,3
https://github.com/squid-cache/squid/commit/5ec2f9233ae75cbe5b24b4a746fd5253df0aa89b,26 Jul 1996,"removed {http,ftp,gopher}_stop stoplists",103,data/crawl/squid/hunk_7664.cpp,,,data/crawl/squid/old_hunk_7664.cpp,data/crawl/squid/new_hunk_7664.cpp,7,-1,"storeAppendPrintf(sentry, ""{\t\t%s}\n"", p->key);",,"[""removeLog""]","[[""storeAppendPrintf"", ""sentry"", ""\\t\\t%s"", ""\\n"", ""p"", ""key""], []]",[-16559813076352035363],7281,0.0,3
https://github.com/squid-cache/squid/commit/0ba3d12b9654e990d602a7da992b7facbf43ebc0,07 Oct 1996,Can't use inaddrFromHostent on ipcache entries with multiple addresses,7,data/crawl/squid/hunk_7499.cpp,,,data/crawl/squid/old_hunk_7499.cpp,data/crawl/squid/new_hunk_7499.cpp,-1,4,,"storeAppendPrintf(sentry, "" %15s"", inet_ntoa(addr));","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""%15s"", ""inet_ntoa"", ""addr""]]",[16086344755803639427],7280,66720.0,3
https://github.com/squid-cache/squid/commit/e5f6c5c2bf496abccc6c5fc3ef1b36c339c85ba2,10 Oct 1996,"-Replaced use of hostent in IP cache.  Now use home-grown ipcache_addrs with
 list of in_addr's
-Changed comm_connect() to comm_nbconnect() and removed all *ConnInProgress()
 stuff.  Now all (most?) completed connections go through a single function.
-Added ipcacheCycleAddr() to round-robin IP addresses
-Added ipcacheRemoveBadAddr() to remove bad addresses from failed connect's.
-Other junk",1078,data/crawl/squid/hunk_7490.cpp,,,data/crawl/squid/old_hunk_7490.cpp,data/crawl/squid/new_hunk_7490.cpp,13,-1,"storeAppendPrintf(sentry, "" %15s"", inet_ntoa(addr));",,"[""removeLog""]","[[""storeAppendPrintf"", ""sentry"", ""%15s"", ""inet_ntoa"", ""addr""], []]",[-16086344755803639427],7279,31200.0,3
https://github.com/squid-cache/squid/commit/429fdbecbf36ca7f145bc760181a892136c54445,28 Apr 1997,merge 1.1.8->1.1.10; just get it to compile,2206,data/crawl/squid/hunk_7318.cpp,,,data/crawl/squid/old_hunk_7318.cpp,data/crawl/squid/new_hunk_7318.cpp,-1,4,,"fatal_dump(""Invalid IP address"");","[""addLog""]","[[], [""fatal_dump"", ""Invalid"", ""IP"", ""address""]]",[-25587333007482150697],7278,120000.0,3
https://github.com/squid-cache/squid/commit/5c5783a22a160a1b243bb783941c938781ff14b7,30 Apr 1997,"Massive changes
lose FD lifetimes, use timeouts only
move some stuff to fd.c",849,data/crawl/squid/hunk_7288.cpp,,,data/crawl/squid/old_hunk_7288.cpp,data/crawl/squid/new_hunk_7288.cpp,31,32,"storeAppendPrintf(sentry, ""%31s %s}\n"", null_string, fd_note(i, NULL));","storeAppendPrintf(sentry, ""%31s %s}\n"", null_string, f->desc);","[""removeVariable"", ""addVariable""]","[[""fd_note"", ""i"", ""NULL""], [""f"", ""desc""]]",[1173293591823174329],7277,0.0,3
https://github.com/squid-cache/squid/commit/4f92c80c2de644e024a477c30ff9643e1029b1d6,01 May 1997,more random massive changes,386,data/crawl/squid/hunk_7279.cpp,,,data/crawl/squid/old_hunk_7279.cpp,data/crawl/squid/new_hunk_7279.cpp,51,-1,"storeAppendPrintf(sentry, ""%31s %s}\n"", null_string, f->desc);",,"[""removeLog""]","[[""storeAppendPrintf"", ""sentry"", ""%31s"", ""%s"", ""\\n"", ""null_string"", ""f"", ""desc""], []]",[-12160499107717052500],7276,0.0,3
https://github.com/squid-cache/squid/commit/934b03fcac83ff55159329b6723b9d6a1d5bd194,27 Jun 1997,adding,2145,data/crawl/squid/hunk_7162.cpp,,,data/crawl/squid/old_hunk_7162.cpp,data/crawl/squid/new_hunk_7162.cpp,-1,302,,"fprintf(fp, ""\t%s = xstrdup(\""%s\"");\n"",
		entry->loc, entry->default_value);","[""addLog""]","[[], [""fprintf"", ""fp"", ""\\t%s"", ""xstrdup"", ""\\"", ""%s\\"", ""\\n"", ""entry"", ""loc"", ""entry"", ""default_value""]]",[-6895646199655884782],7275,0.0,3
https://github.com/squid-cache/squid/commit/270b86af848681f97dab32924f8eb092ebb64d9a,27 Jun 1997,"Max Okumoto configuration file patch.  Config goop will be generated
from a single file.  Still needs work.",1886,data/crawl/squid/hunk_7159.cpp,,,data/crawl/squid/old_hunk_7159.cpp,data/crawl/squid/new_hunk_7159.cpp,-1,302,,"printf(""%d"", var);","[""addLog""]","[[], [""printf"", ""%d"", ""var""]]",[3494803623616240280],7274,0.0,3
https://github.com/squid-cache/squid/commit/f1dc9b308900a8d2a3375c1ddfc7ff95c1afb8a4,07 Jul 1997,finish mega config hacking on kite,1637,data/crawl/squid/hunk_7132.cpp,,,data/crawl/squid/old_hunk_7132.cpp,data/crawl/squid/new_hunk_7132.cpp,-1,22,,"fatal_dump(""cache_dir pathname is too long"");","[""addLog""]","[[], [""fatal_dump"", ""cache_dir"", ""pathname"", ""is"", ""too"", ""long""]]",[-3692931254316650243],7273,189120.0,3
https://github.com/squid-cache/squid/commit/f53b06f967ce5bdf5b076bba55d41f8d45a3077d,25 Aug 1997,"Configuration cleanup.
	- set up 'DEFAULT_IF_NONE' option for things like http_port
	  and cache_dir where we want to set a default only if there
	  is not one or more given in the config file.
	- Implemented the configuration dump via cachemanager.  All the
	  easy config types have dump functions; the remainder are
	  unimplemented.",220,data/crawl/squid/hunk_7074.cpp,,,data/crawl/squid/old_hunk_7074.cpp,data/crawl/squid/new_hunk_7074.cpp,5,5,"printf(""%s"", inet_ntoa(addr));","storeAppendPrintf(entry, ""%s %s\n"", name, inet_ntoa(addr));","[""updateLog"", ""updateContent"", ""addVariable""]","[[""printf""], [""storeAppendPrintf"", ""entry"", ""%s\\n"", ""name""]]",[-1346114251524176872],7272,0.0,3
https://github.com/squid-cache/squid/commit/f0b1933488ce1ce1e84f6497331a6beaf8543cb5,13 Nov 1997,"Ron Gomes fixes.
	- Remove USE_PROXY_AUTH and LOG_FULL_HEADERS from Makefile.in
	- Fixed log_full_hdrs bug
We can't use pathname_stat() for both default_all() and parsing the
config file.  We must check the pathnames only after both the
defaults and the config file have been parsed.  DW also made misc
other fixes to cache_cf.c and friends.",133,data/crawl/squid/hunk_6986.cpp,,,data/crawl/squid/old_hunk_6986.cpp,data/crawl/squid/new_hunk_6986.cpp,9,-1,"printf(""         This will cause serious problems with your cache!!!\n"");",,"[""removeLog""]","[[""printf"", ""This"", ""will"", ""cause"", ""serious"", ""problems"", ""with"", ""your"", ""cache"", ""\\n""], []]",[6661567269603525748],7271,356640.0,3
https://github.com/squid-cache/squid/commit/8a5e92cee75bac210733c2f5bd98d585c9759fd9,13 Nov 1997,remove fatal_dump calls,19,data/crawl/squid/hunk_6982.cpp,,,data/crawl/squid/old_hunk_6982.cpp,data/crawl/squid/new_hunk_6982.cpp,4,-1,"fatal_dump(""cache_dir pathname is too long"");",,"[""removeLog""]","[[""fatal_dump"", ""cache_dir"", ""pathname"", ""is"", ""too"", ""long""], []]",[3692931254316650243],7270,157920.0,3
https://github.com/squid-cache/squid/commit/627f6d02e9baad40c38bd35ef893fc6bc9a22ca1,21 Nov 1997,"SNMP, cmu derived, heavily modified",5272,data/crawl/squid/hunk_6958.cpp,,,data/crawl/squid/old_hunk_6958.cpp,data/crawl/squid/new_hunk_6958.cpp,-1,293,,"fprintf(stderr, ""Couldn't abort session: %s. Exiting\n"", api_errstring(snmp_errno));","[""addLog""]","[[], [""fprintf"", ""stderr"", ""Couldn"", ""t"", ""abort"", ""session"", ""%s"", ""Exiting\\n"", ""api_errstring"", ""snmp_errno""]]",[-3556889371496085440],7269,0.0,3
https://github.com/squid-cache/squid/commit/627f6d02e9baad40c38bd35ef893fc6bc9a22ca1,21 Nov 1997,"SNMP, cmu derived, heavily modified",5272,data/crawl/squid/hunk_6957.cpp,,,data/crawl/squid/old_hunk_6957.cpp,data/crawl/squid/new_hunk_6957.cpp,-1,812,,"print_error(""Expected integer"", token, type);","[""addLog""]","[[], [""print_error"", ""Expected"", ""integer"", ""token"", ""type""]]",[20396393434689223760],7268,0.0,3
https://github.com/squid-cache/squid/commit/627f6d02e9baad40c38bd35ef893fc6bc9a22ca1,21 Nov 1997,"SNMP, cmu derived, heavily modified",5272,data/crawl/squid/hunk_6956.cpp,,,data/crawl/squid/old_hunk_6956.cpp,data/crawl/squid/new_hunk_6956.cpp,-1,150,,"fprintf(stderr, ""object identifier too long\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""object"", ""identifier"", ""too"", ""long\\n""]]",[-16428620954377002349],7267,0.0,3
https://github.com/squid-cache/squid/commit/da2d50d1b7f6df01b5276ca63e22f9c35cd65774,21 Nov 1997,gindent,23717,data/crawl/squid/hunk_6944.cpp,,,data/crawl/squid/old_hunk_6944.cpp,data/crawl/squid/new_hunk_6944.cpp,-1,12,,"printf(""Description== \""%.50s\""\n"", quoted_string_buffer);","[""addLog""]","[[], [""printf"", ""Description"", ""\\"", ""%"", ""50s\\"", ""\\n"", ""quoted_string_buffer""]]",[4929498204986278236],7266,0.0,3
https://github.com/squid-cache/squid/commit/85491f8d52977b0523d6c6a68550c80d54c631fe,05 Dec 1997,Initial URN support,802,data/crawl/squid/hunk_6886.cpp,,,data/crawl/squid/old_hunk_6886.cpp,data/crawl/squid/new_hunk_6886.cpp,-1,777,,"fatal_dump(""Invalid $message"");","[""addLog""]","[[], [""fatal_dump"", ""Invalid"", ""message""]]",[-23689232014450983535],7265,226080.0,3
https://github.com/squid-cache/squid/commit/85491f8d52977b0523d6c6a68550c80d54c631fe,05 Dec 1997,Initial URN support,802,data/crawl/squid/hunk_6886.cpp,,,data/crawl/squid/old_hunk_6886.cpp,data/crawl/squid/new_hunk_6886.cpp,-1,774,,"fatal_dump(""Invalid $fail"");","[""addLog""]","[[], [""fatal_dump"", ""Invalid"", ""fail""]]",[-17352137429592844529],7264,226080.0,3
https://github.com/squid-cache/squid/commit/a7c05555fdb0ef180d8df2e68d53acc400bf2984,31 Jan 1998,"	- Combined various interprocess communication setup functions
	  into ipcCreate().
	- Removed some leftover ICP_HIT_OBJ things.
	- Removed cacheinfo and proto_count() and friends; these are to
	  be replaced in functionality by StatCounters and 5/60 minute
	  average views via cachemgr.
Changes to squid-1.2.beta11 (Jan 6, 1998):",997,data/crawl/squid/hunk_6856.cpp,,,data/crawl/squid/old_hunk_6856.cpp,data/crawl/squid/new_hunk_6856.cpp,11,-1,"fatal(""Cannot open logfile."");",,"[""removeLog""]","[[""fatal"", ""Cannot"", ""open"", ""logfile""], []]",[-2958952059222500357],7263,107520.0,3
https://github.com/squid-cache/squid/commit/a7c05555fdb0ef180d8df2e68d53acc400bf2984,31 Jan 1998,"	- Combined various interprocess communication setup functions
	  into ipcCreate().
	- Removed some leftover ICP_HIT_OBJ things.
	- Removed cacheinfo and proto_count() and friends; these are to
	  be replaced in functionality by StatCounters and 5/60 minute
	  average views via cachemgr.
Changes to squid-1.2.beta11 (Jan 6, 1998):",997,data/crawl/squid/hunk_6855.cpp,,,data/crawl/squid/old_hunk_6855.cpp,data/crawl/squid/new_hunk_6855.cpp,-1,11,,"fatal(""Cannot open logfile."");","[""addLog""]","[[], [""fatal"", ""Cannot"", ""open"", ""logfile""]]",[2958952059222500357],7262,107520.0,3
https://github.com/squid-cache/squid/commit/15576b6a58a24ed2705d6228d0fde8cfcef26cae,07 Feb 1998,remove brackets from cachemgr output,390,data/crawl/squid/hunk_6829.cpp,,,data/crawl/squid/old_hunk_6829.cpp,data/crawl/squid/new_hunk_6829.cpp,65,64,"storeAppendPrintf(sentry, ""{\tOrdinary blocks:       %6d KB %6d blks}\n"",
	mp.uordblks >> 10, mp.ordblks);","storeAppendPrintf(sentry, ""\tOrdinary blocks:       %6d KB %6d blks\n"",
	mp.uordblks >> 10, mp.ordblks);","[""updateContent""]","[[""blks"", ""\\n""], [""blks\\n""]]",[-1191985278751827136],7261,0.0,3
https://github.com/squid-cache/squid/commit/15576b6a58a24ed2705d6228d0fde8cfcef26cae,07 Feb 1998,remove brackets from cachemgr output,390,data/crawl/squid/hunk_6829.cpp,,,data/crawl/squid/old_hunk_6829.cpp,data/crawl/squid/new_hunk_6829.cpp,12,11,"storeAppendPrintf(sentry, ""{\tNumber of HTTP requests received:\t%u}\n"",
	Counter.client_http.requests);","storeAppendPrintf(sentry, ""\tNumber of HTTP requests received:\t%u\n"",
	Counter.client_http.requests);","[""updateContent""]","[[""\\t%u"", ""\\n""], [""\\t%u\\n""]]",[-1330684662102328312],7260,0.0,3
https://github.com/squid-cache/squid/commit/15576b6a58a24ed2705d6228d0fde8cfcef26cae,07 Feb 1998,remove brackets from cachemgr output,390,data/crawl/squid/hunk_6823.cpp,,,data/crawl/squid/old_hunk_6823.cpp,data/crawl/squid/new_hunk_6823.cpp,14,13,"storeAppendPrintf(sentry, ""{    %-22.22s %7.1f %5.1f}\n"",
		p->peername,
		p->rtt,
		p->hops);","storeAppendPrintf(sentry, ""    %-22.22s %7.1f %5.1f\n"",
		p->peername,
		p->rtt,
		p->hops);","[""updateContent""]","[[""1f"", ""\\n""], [""1f\\n""]]",[641379475350173300],7259,0.0,3
https://github.com/squid-cache/squid/commit/15576b6a58a24ed2705d6228d0fde8cfcef26cae,07 Feb 1998,remove brackets from cachemgr output,390,data/crawl/squid/hunk_6815.cpp,,,data/crawl/squid/old_hunk_6815.cpp,data/crawl/squid/new_hunk_6815.cpp,30,30,"storeAppendPrintf(sentry, ""{    Last Dispatched: %0.3f seconds ago}\n"",
	    0.001 * tvSubMsec(dns->dispatch_time, current_time));","storeAppendPrintf(sentry, ""    Last Dispatched: %0.3f seconds ago\n"",
	    0.001 * tvSubMsec(dns->dispatch_time, current_time));","[""updateContent""]","[[""ago"", ""\\n""], [""ago\\n""]]",[-9755500214657285284],7258,0.0,3
https://github.com/squid-cache/squid/commit/5ba18ba6fb69dbc520c465c8754d0af534492919,20 Feb 1998,move function to the non-PUBLIC area,59,data/crawl/squid/hunk_6778.cpp,,,data/crawl/squid/old_hunk_6778.cpp,data/crawl/squid/new_hunk_6778.cpp,-1,28,,"storeAppendPrintf(e, ""\t%4d  %9d\n"", i, server_pconn_hist[i]);","[""addLog""]","[[], [""storeAppendPrintf"", ""e"", ""\\t%4d"", ""%9d\\n"", ""i"", ""server_pconn_hist[i]""]]",[4661309132147493222],7257,186240.0,3
https://github.com/squid-cache/squid/commit/5ba18ba6fb69dbc520c465c8754d0af534492919,20 Feb 1998,move function to the non-PUBLIC area,59,data/crawl/squid/hunk_6778.cpp,,,data/crawl/squid/old_hunk_6778.cpp,data/crawl/squid/new_hunk_6778.cpp,-1,18,,"storeAppendPrintf(e,
        ""\n""
        ""Server-side persistent connection counts:\n""
        ""\n""
        ""\treq/\n""
        ""\tconn      count\n""
        ""\t----  ---------\n"");","[""addLog""]","[[], [""storeAppendPrintf"", ""e"", ""\\n"", ""Server"", ""side"", ""persistent"", ""connection"", ""counts"", ""\\n"", ""\\n"", ""\\treq/\\n"", ""\\tconn"", ""count\\n"", ""\\t"", ""\\n""]]",[11180452350504215011],7256,186240.0,3
https://github.com/squid-cache/squid/commit/85269fdf3c2a36641dfae2cf71f495a38c95cc28,22 Feb 1998,"Snmplib for squid, based on v1.8, heavily changed",8289,data/crawl/squid/hunk_6752.cpp,,,data/crawl/squid/old_hunk_6752.cpp,data/crawl/squid/new_hunk_6752.cpp,400,-1,"printf(""Description== \""%.50s\""\n"", quoted_string_buffer);",,"[""removeLog""]","[[""printf"", ""Description"", ""\\"", ""%"", ""50s\\"", ""\\n"", ""quoted_string_buffer""], []]",[-4929498204986278236],7255,0.0,3
https://github.com/squid-cache/squid/commit/7395afb806a3a4c008b8464637ac03974a994359,23 Feb 1998,"- Cache Manager got new Web interface (cachemgr.cgi). New .cgi script forwards
  basic authentication from browser to squid.  Cachemgr.cgi now recognizes
  ""action protection"" types described below.

- Added better recognition of available protection for actions in Cache
  Manager. Actions are classified as ""public"" (no password needed),
  ""protected"" (must specify a valid password), ""disabled"" (those with a
  ""disable"" password in squid.conf), and ""hidden"" (actions that require a
  password, but do not have corresponding cachemgr_passwd entry in squid.conf).",442,data/crawl/squid/hunk_6737.cpp,,,data/crawl/squid/old_hunk_6737.cpp,data/crawl/squid/new_hunk_6737.cpp,-1,32,,"fputs(buf, stdout);","[""addLog""]","[[], [""fputs"", ""buf"", ""stdout""]]",[-11895120448567402220],7254,0.0,3
https://github.com/squid-cache/squid/commit/2961668b4fedc47880a17526c867402b1e1594db,25 Feb 1998,Changed %f to %lf.,16,data/crawl/squid/hunk_6708.cpp,,,data/crawl/squid/old_hunk_6708.cpp,data/crawl/squid/new_hunk_6708.cpp,3,3,"storeAppendPrintf(sentry, ""%2d\t %-20s\t %5d\t %6.2f\n"",
	    id, name, count, xdiv(count, HeaderParsedCount));","storeAppendPrintf(sentry, ""%2d\t %-20s\t %5d\t %6.2lf\n"",
	    id, name, count, xdiv(count, HeaderParsedCount));","[""updateContent""]","[[""2f\\n""], [""2lf\\n""]]",[-7691326309081763623],7253,0.0,3
https://github.com/squid-cache/squid/commit/7021844c42212902ee9a10ba7097201a6d66a1c5,03 Mar 1998,"- Added ""mem_pools_limit"" configuration option. Semantics of
  ""mem_pools"" option has also changed a bit to reflect new memory
  management policy.
- Reorganized memory pools. Squid now allocates memory in big chunks
  and distributes that memory among ""frequently allocated"" objects.
- memAllocate() has now only one parameter. Objects are always reset
  with 0s.

- HttpHeader.c: fixed warnings generated by some compilers on member to union
  conversions. Tested using DEC cc only.
- cachmgr.c now tries to interpret strings containing '\t' as table rows and
  format them using html table attributes.",742,data/crawl/squid/hunk_6652.cpp,,,data/crawl/squid/old_hunk_6652.cpp,data/crawl/squid/new_hunk_6652.cpp,3,3,"storeAppendPrintf(e, ""\t<h3>Field type distribution</h3>\n"");","storeAppendPrintf(e, ""<h3>Field type distribution</h3>\n"");","[""updateContent""]","[[""\\t""], []]",[-11776070748106338],7252,0.0,3
https://github.com/squid-cache/squid/commit/7021844c42212902ee9a10ba7097201a6d66a1c5,03 Mar 1998,"- Added ""mem_pools_limit"" configuration option. Semantics of
  ""mem_pools"" option has also changed a bit to reflect new memory
  management policy.
- Reorganized memory pools. Squid now allocates memory in big chunks
  and distributes that memory among ""frequently allocated"" objects.
- memAllocate() has now only one parameter. Objects are always reset
  with 0s.

- HttpHeader.c: fixed warnings generated by some compilers on member to union
  conversions. Tested using DEC cc only.
- cachmgr.c now tries to interpret strings containing '\t' as table rows and
  format them using html table attributes.",742,data/crawl/squid/hunk_6649.cpp,,,data/crawl/squid/old_hunk_6649.cpp,data/crawl/squid/new_hunk_6649.cpp,3,3,"storeAppendPrintf(sentry, ""%2d\t %-20s\t %5d\t %6.2lf\n"",
	    id, name, count, xdiv(count, HeaderParsedCount));","storeAppendPrintf(sentry, ""%2d\t %-20s\t %5d\t %6.2f\n"",
	    id, name, count, xdiv(count, HeaderParsedCount));","[""updateContent""]","[[""2lf\\n""], [""2f\\n""]]",[7691326309081763623],7251,0.0,3
https://github.com/squid-cache/squid/commit/76e3f5c2d11436b883d0f9591f7b47e5bdb8d9f9,31 Mar 1998,- Adding more stuff to test_cache_digest,171,data/crawl/squid/hunk_6563.cpp,,,data/crawl/squid/old_hunk_6563.cpp,data/crawl/squid/new_hunk_6563.cpp,-1,74,,"fprintf(stderr, ""%s scanning\n"", fname);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""%s"", ""scanning\\n"", ""fname""]]",[-3659830878210560945],7250,960.0,3
https://github.com/squid-cache/squid/commit/bd34f258a4b0bc46f2f65ea4b1331881693b9869,03 Apr 1998,"Changed squid/dnsserver communication to single-line replies.  Removed
all the unused cruft.",455,data/crawl/squid/hunk_6522.cpp,,,data/crawl/squid/old_hunk_6522.cpp,data/crawl/squid/new_hunk_6522.cpp,28,-1,"fatal_dump(""Invalid $message"");",,"[""removeLog""]","[[""fatal_dump"", ""Invalid"", ""message""], []]",[23689232014450983535],7249,113280.0,3
https://github.com/squid-cache/squid/commit/26b164ac83cf389215621005dbe69a664c08ac20,09 Apr 1998,"- added peer_digest.o
- a lot of digest related coding and fixes
- new stats (mgr:digest_stats)",233,data/crawl/squid/hunk_6483.cpp,,,data/crawl/squid/old_hunk_6483.cpp,data/crawl/squid/new_hunk_6483.cpp,-1,41,,"storeAppendPrintf(sentry, ""icp.kbytes_recv = %d\n"",
	(int) f->icp.kbytes_recv.kb);","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""icp"", ""kbytes_recv"", ""%d\\n"", ""int"", ""f"", ""icp"", ""kbytes_recv"", ""kb""]]",[6902633323381723445],7248,44640.0,3
https://github.com/squid-cache/squid/commit/26b164ac83cf389215621005dbe69a664c08ac20,09 Apr 1998,"- added peer_digest.o
- a lot of digest related coding and fixes
- new stats (mgr:digest_stats)",233,data/crawl/squid/hunk_6483.cpp,,,data/crawl/squid/old_hunk_6483.cpp,data/crawl/squid/new_hunk_6483.cpp,-1,39,,"storeAppendPrintf(sentry, ""icp.kbytes_sent = %d\n"",
	(int) f->icp.kbytes_sent.kb);","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""icp"", ""kbytes_sent"", ""%d\\n"", ""int"", ""f"", ""icp"", ""kbytes_sent"", ""kb""]]",[4902379322301722921],7247,44640.0,3
https://github.com/squid-cache/squid/commit/26b164ac83cf389215621005dbe69a664c08ac20,09 Apr 1998,"- added peer_digest.o
- a lot of digest related coding and fixes
- new stats (mgr:digest_stats)",233,data/crawl/squid/hunk_6483.cpp,,,data/crawl/squid/old_hunk_6483.cpp,data/crawl/squid/new_hunk_6483.cpp,-1,35,,"storeAppendPrintf(sentry, ""icp.pkts_recv = %d\n"",
	f->icp.pkts_recv);","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""icp"", ""pkts_recv"", ""%d\\n"", ""f"", ""icp"", ""pkts_recv""]]",[4165807127523989432],7246,44640.0,3
https://github.com/squid-cache/squid/commit/26b164ac83cf389215621005dbe69a664c08ac20,09 Apr 1998,"- added peer_digest.o
- a lot of digest related coding and fixes
- new stats (mgr:digest_stats)",233,data/crawl/squid/hunk_6483.cpp,,,data/crawl/squid/old_hunk_6483.cpp,data/crawl/squid/new_hunk_6483.cpp,-1,33,,"storeAppendPrintf(sentry, ""icp.pkts_sent = %d\n"",
	f->icp.pkts_sent);","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""icp"", ""pkts_sent"", ""%d\\n"", ""f"", ""icp"", ""pkts_sent""]]",[2165521125979986932],7245,44640.0,3
https://github.com/squid-cache/squid/commit/071a3ae79623f644f3544044423946dd3a35710b,10 Apr 1998,Cleaned up ICP logging/counting and ICP/CD stats output,269,data/crawl/squid/hunk_6467.cpp,,,data/crawl/squid/old_hunk_6467.cpp,data/crawl/squid/new_hunk_6467.cpp,-1,32,,"storeAppendPrintf(sentry, ""dns.svc_time histogram:\n"");","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""dns"", ""svc_time"", ""histogram"", ""\\n""]]",[653227546511370233],7244,26880.0,3
https://github.com/squid-cache/squid/commit/071a3ae79623f644f3544044423946dd3a35710b,10 Apr 1998,Cleaned up ICP logging/counting and ICP/CD stats output,269,data/crawl/squid/hunk_6467.cpp,,,data/crawl/squid/old_hunk_6467.cpp,data/crawl/squid/new_hunk_6467.cpp,-1,30,,"storeAppendPrintf(sentry, ""icp.reply_svc_time histogram:\n"");","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""icp"", ""reply_svc_time"", ""histogram"", ""\\n""]]",[-8726389353641440357],7243,21120.0,3
https://github.com/squid-cache/squid/commit/071a3ae79623f644f3544044423946dd3a35710b,10 Apr 1998,Cleaned up ICP logging/counting and ICP/CD stats output,269,data/crawl/squid/hunk_6467.cpp,,,data/crawl/squid/old_hunk_6467.cpp,data/crawl/squid/new_hunk_6467.cpp,-1,8,,"storeAppendPrintf(sentry, ""client_http.all_svc_time histogram:\n"");","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""client_http"", ""all_svc_time"", ""histogram"", ""\\n""]]",[1431764734794782766],7242,41760.0,3
https://github.com/squid-cache/squid/commit/95e36d02e1eca338ecbf4ca7cafc4c46797c2d41,31 Jul 1998,Luyers new DELAY_POOLS code,972,data/crawl/squid/hunk_6314.cpp,,,data/crawl/squid/old_hunk_6314.cpp,data/crawl/squid/new_hunk_6314.cpp,-1,210,,"storeAppendPrintf(sentry, ""\n\tAggregate:\n"");","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""\\n\\tAggregate"", ""\\n""]]",[9574720658453296260],7241,0.0,3
https://github.com/squid-cache/squid/commit/447e176bc0560af9b837d744877f154af7fe92c9,14 Aug 1998,Luyers finished delay pools patch,540,data/crawl/squid/hunk_6311.cpp,,,data/crawl/squid/old_hunk_6311.cpp,data/crawl/squid/new_hunk_6311.cpp,-1,19,,"storeAppendPrintf(sentry, ""\n\tAggregate:\n\tDisabled.\n"");","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""\\n\\tAggregate"", ""\\n\\tDisabled"", ""\\n""]]",[8874407868546681546],7240,0.0,3
https://github.com/squid-cache/squid/commit/1994bb24d88bc770a6f568674423a87199681ca8,27 Aug 1998,HTCP progress,56,data/crawl/squid/hunk_6293.cpp,,,data/crawl/squid/old_hunk_6293.cpp,data/crawl/squid/new_hunk_6293.cpp,13,-1,"storeAppendPrintf(sentry, ""!%s "", d->domain);",,"[""removeLog""]","[[""storeAppendPrintf"", ""sentry"", ""%s"", ""d"", ""domain""], []]",[-14478533116132914383],7239,90240.0,3
https://github.com/squid-cache/squid/commit/59715b38e9e43d20a1092ee0d67c316365726e95,30 Jan 1999,luyer's mega delay pools rewrite -- without ugly delayPoolsReconfigure(),1419,data/crawl/squid/hunk_6162.cpp,,,data/crawl/squid/old_hunk_6162.cpp,data/crawl/squid/new_hunk_6162.cpp,208,-1,"storeAppendPrintf(sentry, ""\n\tAggregate:\n\tDisabled.\n"");",,"[""removeLog""]","[[""storeAppendPrintf"", ""sentry"", ""\\n\\tAggregate"", ""\\n\\tDisabled"", ""\\n""], []]",[-8874407868546681546],7238,0.0,3
https://github.com/squid-cache/squid/commit/59715b38e9e43d20a1092ee0d67c316365726e95,30 Jan 1999,luyer's mega delay pools rewrite -- without ugly delayPoolsReconfigure(),1419,data/crawl/squid/hunk_6162.cpp,,,data/crawl/squid/old_hunk_6162.cpp,data/crawl/squid/new_hunk_6162.cpp,200,-1,"storeAppendPrintf(sentry, ""\n\tAggregate:\n"");",,"[""removeLog""]","[[""storeAppendPrintf"", ""sentry"", ""\\n\\tAggregate"", ""\\n""], []]",[-9574720658453296260],7237,0.0,3
https://github.com/squid-cache/squid/commit/b6a2f15e25349145c5f0f4737d4f5ef1cd8b6ad2,15 Apr 1999,SQUID_2_2 branch merge,3534,data/crawl/squid/hunk_6145.cpp,,,data/crawl/squid/old_hunk_6145.cpp,data/crawl/squid/new_hunk_6145.cpp,-1,27,,"fatal_dump(""Cannot cd to swap directory?"");","[""addLog""]","[[], [""fatal_dump"", ""Cannot"", ""cd"", ""to"", ""swap"", ""directory""]]",[-10293767358945213303],7236,532800.0,3
https://github.com/squid-cache/squid/commit/cd748f27e5282c445ef4e13a0e2eabd19b6b906f,03 May 2000,"MODIO_1 commit. This change (including documentation) implements a more
modular storage directory system, which leaves object replacement and IO
up to the storage modules.

There is a lot of repeated code in the FS modules and some tidying up
is in the pipeline.

The documentation for this new API is in doc/Programming-Guide/prog-guide.sgml .",14498,data/crawl/squid/hunk_6044.cpp,,,data/crawl/squid/old_hunk_6044.cpp,data/crawl/squid/new_hunk_6044.cpp,-1,1637,,"storeAppendPrintf(sentry, ""Filesystem Inodes in use: %d/%d (%d%%)\n"",
            sfs.f_files - sfs.f_ffree, sfs.f_files,
            percent(sfs.f_files - sfs.f_ffree, sfs.f_files));","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""Filesystem"", ""Inodes"", ""in"", ""use"", ""%d/%d"", ""%d%%"", ""\\n"", ""sfs"", ""f_files"", ""sfs"", ""f_ffree"", ""sfs"", ""f_files"", ""percent"", ""sfs"", ""f_files"", ""sfs"", ""f_ffree"", ""sfs"", ""f_files""]]",[-1857087631882639425],7235,565440.0,3
https://github.com/squid-cache/squid/commit/6a566b9c9fa4d40f154a60497e332bc9067b4fc8,09 Jun 2000,"Modular policy implementation. See programmers guide for API details.

This also includes Adrians improved store I/O callback handler model.",3040,data/crawl/squid/hunk_6000.cpp,,,data/crawl/squid/old_hunk_6000.cpp,data/crawl/squid/new_hunk_6000.cpp,-1,8,,"storeAppendPrintf(sentry, ""Storage Replacement Threshold:\t%f\n"",
	heap_peepminkey(sd.repl.heap.heap));","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""Storage"", ""Replacement"", ""Threshold"", ""\\t%f\\n"", ""heap_peepminkey"", ""sd"", ""repl"", ""heap"", ""heap""]]",[13864888633352626769],7234,0.0,3
https://github.com/squid-cache/squid/commit/0c2bd4faac3ec8e8dc65cac855af5e9767752320,15 Mar 2001,fix delaypools/delay-pools typo and remove references to HEAP_REPLACEMENT,51,data/crawl/squid/hunk_5843.cpp,,,data/crawl/squid/old_hunk_5843.cpp,data/crawl/squid/new_hunk_5843.cpp,8,-1,"storeAppendPrintf(sentry, ""Storage Replacement Threshold:\t%f\n"",
	heap_peepminkey(sd.repl.heap.heap));",,"[""removeLog""]","[[""storeAppendPrintf"", ""sentry"", ""Storage"", ""Replacement"", ""Threshold"", ""\\t%f\\n"", ""heap_peepminkey"", ""sd"", ""repl"", ""heap"", ""heap""], []]",[-13864888633352626769],7233,0.0,3
https://github.com/squid-cache/squid/commit/4e2c57a0431489369bd9869aff83772eee1c0ef9,30 Mar 2002,SASL auth helper by Ian Castle,173,data/crawl/squid/hunk_5688.cpp,,,data/crawl/squid/old_hunk_5688.cpp,data/crawl/squid/new_hunk_5688.cpp,-1,48,,"fprintf( stderr, ""error %d %s\n"", rc, sasl_errstring(rc, NULL, NULL ));","[""addLog""]","[[], [""fprintf"", ""stderr"", ""error"", ""%d"", ""%s\\n"", ""rc"", ""sasl_errstring"", ""rc"", ""NULL"", ""NULL""]]",[-839464069439094152],7232,0.0,3
https://github.com/squid-cache/squid/commit/eb7d6bd6cbfc077ca677fa41253a29a1f1f9c6fb,15 Jul 2002,"Cleanup of Gopher HTML code to use a common header format, and the
standard Squid signature.",59,data/crawl/squid/hunk_5624.cpp,,,data/crawl/squid/old_hunk_5624.cpp,data/crawl/squid/new_hunk_5624.cpp,-1,33,,"storeAppendPrintf(e, ""</PRE>\n"");","[""addLog""]","[[], [""storeAppendPrintf"", ""e"", ""/PRE"", ""\\n""]]",[-2456542899871621207],7231,900480.0,3
https://github.com/squid-cache/squid/commit/eb7d6bd6cbfc077ca677fa41253a29a1f1f9c6fb,15 Jul 2002,"Cleanup of Gopher HTML code to use a common header format, and the
standard Squid signature.",59,data/crawl/squid/hunk_5624.cpp,,,data/crawl/squid/old_hunk_5624.cpp,data/crawl/squid/new_hunk_5624.cpp,-1,16,,"storeAppendPrintf(e, ""<HR>\n"");","[""addLog""]","[[], [""storeAppendPrintf"", ""e"", ""HR"", ""\\n""]]",[5206455857277709763],7230,900480.0,3
https://github.com/squid-cache/squid/commit/332dafa28099995ae4baee1de763dc42eef698ac,15 Oct 2002,fix c++ compilers that put the vtable at the beginning of structs,6897,data/crawl/squid/hunk_5503.cpp,,,data/crawl/squid/old_hunk_5503.cpp,data/crawl/squid/new_hunk_5503.cpp,3,3,"storeAppendPrintf(s, ""KEY %s\n"", storeKeyText((const cache_key *)e->hash.key));","storeAppendPrintf(s, ""KEY %s\n"", e->getMD5Text());","[""updateVariable"", ""moveVariable"", ""removeVariable"", ""addVariable""]","[[""storeKeyText"", ""const"", ""cache_key"", ""*"", ""hash"", ""key""], [""getMD5Text""]]",[-6891533447135810742],7229,0.0,3
https://github.com/squid-cache/squid/commit/b67e2c8c4da9890e0f3d27d501edf6a0c0fdf1c9,05 Feb 2003,"Summary: Merge from delay-class-4
Keywords:

Patches applied:

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-23
     Merge from HEAD, and shutdown delaypools at shutdown.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-22
     Merge from HEAD.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-21
     Implement class 4 delay pools

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-20
     Fix make dist.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-19
     Document finished aspects of delay pools.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-18
     Merge from HEAD.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-17
     Fixs to handle HEAD changes.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-16
     Merge from head.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-15
     Merge from HEAD

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-14
     Merge from HEAD

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-13
     Separate out code for DelayBucket and DelayId.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-12
     More class split outs.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-11
     More class splitting

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-10
     Splitting classes out to one per file.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-9
     Starting consolidation of delay pools hierarchy.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-8
     Snapshot

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-7
     Finally got composite structure sorted - class one and two delay pools in it.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-6
     snapshotting more refactoring.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-5
     More refactoring - no functionality changes.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-4
     Another refactoring snapshot.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-3
     Snapshot of delay pools refactoring.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-2
     Refactor delay pools code to not cause globals recompiles on most changes.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-20
     Fix make dist.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-21
     Implement class 4 delay pools

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-22
     Merge from HEAD.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-23
     Merge from HEAD, and shutdown delaypools at shutdown.",12710,data/crawl/squid/hunk_5432.cpp,,,data/crawl/squid/old_hunk_5432.cpp,data/crawl/squid/new_hunk_5432.cpp,717,-1,"storeAppendPrintf(sentry, ""\t\tCurrent: "");",,"[""removeLog""]","[[""storeAppendPrintf"", ""sentry"", ""\\t\\tCurrent""], []]",[-6528457113049910470],7228,704160.0,3
https://github.com/squid-cache/squid/commit/23087cb8461e0bcfbdd7d0a9556e78147691ed0f,22 Apr 2003,"Summary: Add a RFC 1738 test program.
Keywords:

Add a RFC 1738 test program.

Summary: Make splay check silent.
Keywords:

Make splay check silent.",179,data/crawl/squid/hunk_5262.cpp,,,data/crawl/squid/old_hunk_5262.cpp,data/crawl/squid/new_hunk_5262.cpp,7,-1,"printf(""%d\n"", A->i);",,"[""removeLog""]","[[""printf"", ""%d\\n"", ""A"", ""i""], []]",[-13382357820073349692],7227,72960.0,3
https://github.com/squid-cache/squid/commit/7684c4b1a8b1fa0a54c1b6269d5dc5ae72bd4ed3,07 Jul 2003,"Custom log formats, and selective access logging. See logformat
and cache_access_log directives",1422,data/crawl/squid/hunk_5231.cpp,,,data/crawl/squid/old_hunk_5231.cpp,data/crawl/squid/new_hunk_5231.cpp,-1,11,,"logfilePrintf(logfile, ""\n"");","[""addLog""]","[[], [""logfilePrintf"", ""logfile"", ""\\n""]]",[3058783768913786027],7226,1160640.0,3
https://github.com/squid-cache/squid/commit/1a2248431aee8579727981a35527c2663852fc5d,28 Aug 2003,"ported COSS enhancements from squid-2.5 code (dated ~ July 25-29, 2003).",564,data/crawl/squid/hunk_5180.cpp,,,data/crawl/squid/old_hunk_5180.cpp,data/crawl/squid/new_hunk_5180.cpp,-1,8,,"storeAppendPrintf(sentry, ""\n                   OPS     SUCCESS        FAIL\n"");","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""\\n"", ""OPS"", ""SUCCESS"", ""FAIL\\n""]]",[8741072292188538015],7225,1074720.0,3
https://github.com/squid-cache/squid/commit/fa85aa89ff5cf6c07cae814e2346f0dca05baec7,24 Aug 2004,merge in cppunit test support. see lib/tests for examples of use,103307,data/crawl/squid/hunk_5144.cpp,,,data/crawl/squid/old_hunk_5144.cpp,data/crawl/squid/new_hunk_5144.cpp,-1,1307,,"printf (""i386-sequent-ptx\n"");","[""addLog""]","[[], [""printf"", ""i386"", ""sequent"", ""ptx\\n""]]",[-2966281485289467054],7224,1994400.0,3
https://github.com/squid-cache/squid/commit/fa85aa89ff5cf6c07cae814e2346f0dca05baec7,24 Aug 2004,merge in cppunit test support. see lib/tests for examples of use,103307,data/crawl/squid/hunk_5144.cpp,,,data/crawl/squid/old_hunk_5144.cpp,data/crawl/squid/new_hunk_5144.cpp,-1,1305,,"printf (""i386-sequent-ptx1\n"");","[""addLog""]","[[], [""printf"", ""i386"", ""sequent"", ""ptx1\\n""]]",[-6392863029535456224],7223,1994400.0,3
https://github.com/squid-cache/squid/commit/fa85aa89ff5cf6c07cae814e2346f0dca05baec7,24 Aug 2004,merge in cppunit test support. see lib/tests for examples of use,103307,data/crawl/squid/hunk_5144.cpp,,,data/crawl/squid/old_hunk_5144.cpp,data/crawl/squid/new_hunk_5144.cpp,-1,1251,,"printf (""arm-acorn-riscix"");","[""addLog""]","[[], [""printf"", ""arm"", ""acorn"", ""riscix""]]",[9551449641104062770],7222,1994400.0,3
https://github.com/squid-cache/squid/commit/d8f10d6ad810fec71d79f63336da847228441bfb,22 Dec 2004,Bug #1118: Squid sends requests to redirectors with shutdown flag on,63,data/crawl/squid/hunk_5092.cpp,,,data/crawl/squid/old_hunk_5092.cpp,data/crawl/squid/new_hunk_5092.cpp,3,-1,"storeAppendPrintf(sentry, ""   A = ALIVE\n"");",,"[""removeLog""]","[[""storeAppendPrintf"", ""sentry"", ""A"", ""ALIVE\\n""], []]",[-7650467745663906056],7221,2174400.0,3
https://github.com/squid-cache/squid/commit/2fe7eff994f9cb87b4211714d77c200b5ebbcb97,17 Sep 2005,"Finish turning MemBuf into a full-fledged class.  Almost all of the
former standalone functions are now methods of MemBuf class.  The next
step may be to merge init() and clean() methods into the constructor
and destructor.",763,data/crawl/squid/hunk_4973.cpp,,,data/crawl/squid/old_hunk_4973.cpp,data/crawl/squid/new_hunk_4973.cpp,-1,3,,".Printf(""\r\n"");","[""addLog""]","[[], [""Printf"", ""\\r\\n""]]",[2075766014185147191],7220,0.0,3
https://github.com/squid-cache/squid/commit/2fe7eff994f9cb87b4211714d77c200b5ebbcb97,17 Sep 2005,"Finish turning MemBuf into a full-fledged class.  Almost all of the
former standalone functions are now methods of MemBuf class.  The next
step may be to merge init() and clean() methods into the constructor
and destructor.",763,data/crawl/squid/hunk_4972.cpp,,,data/crawl/squid/old_hunk_4972.cpp,data/crawl/squid/new_hunk_4972.cpp,-1,36,,"str.Printf(""\r\n"");","[""addLog""]","[[], [""str"", ""Printf"", ""\\r\\n""]]",[1706590592177356461],7219,0.0,3
https://github.com/squid-cache/squid/commit/6bf4f823fa73dbe9e91d9e3600c313e15347d5d9,23 Oct 2005,"Negotiate authentication scheme support.

Originally written for Squid-2.5 by Henrik, ported to Squid-3 by Kinkie
and bugfixed by Henrik.",2492,data/crawl/squid/hunk_4951.cpp,,,data/crawl/squid/old_hunk_4951.cpp,data/crawl/squid/new_hunk_4951.cpp,-1,308,,"httpHeaderPutStrf(&rep->header, type, ""NEGOTIATE"");","[""addLog""]","[[], [""httpHeaderPutStrf"", ""&rep"", ""header"", ""type"", ""NEGOTIATE""]]",[-7254889620896197845],7218,0.0,3
https://github.com/squid-cache/squid/commit/6e785d853c1867e4b7aea26b0add938b39897a69,31 Oct 2005,"Windows port: addition of native authentication helpers.

- mswin_auth: 		Basic helper
- mswin_ntlm_auth: 	NTLM helper
- mswin_negotiate_auth: Negotiate helper

Supported build environment:

- Cygwin
- MSYS + MinGW
- MS VisualStudio C++ 2005",2901,data/crawl/squid/hunk_4944.cpp,,,data/crawl/squid/old_hunk_4944.cpp,data/crawl/squid/new_hunk_4944.cpp,-1,202,,"printf(""TT %s\n"",c);","[""addLog""]","[[], [""printf"", ""TT"", ""%s\\n"", ""c""]]",[13397222896155443925],7217,0.0,3
https://github.com/squid-cache/squid/commit/6e785d853c1867e4b7aea26b0add938b39897a69,31 Oct 2005,"Windows port: addition of native authentication helpers.

- mswin_auth: 		Basic helper
- mswin_ntlm_auth: 	NTLM helper
- mswin_negotiate_auth: Negotiate helper

Supported build environment:

- Cygwin
- MSYS + MinGW
- MS VisualStudio C++ 2005",2901,data/crawl/squid/hunk_4940.cpp,,,data/crawl/squid/old_hunk_4940.cpp,data/crawl/squid/new_hunk_4940.cpp,-1,123,,"fprintf(stderr, ""FATAL, can't initialize SSPI, exiting.\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""FATAL"", ""can"", ""t"", ""initialize"", ""SSPI"", ""exiting"", ""\\n""]]",[-17337122093854703499],7216,0.0,3
https://github.com/squid-cache/squid/commit/781ce8ff40f9cd5e6f5c4ec84ff2a978cff98ab0,07 Dec 2005,"Turned pconn.cc into C++ classes.  There are now separate persistent
connection pools for client-side, server-side, and now ICAP.

Accounting for persistent connection use still sucks because HTTP
(http.c) and ICAP state structures don't have any way to keep track
of how many times a given TCP connection was used.  So we'll keep
abusing fd_entry[] for this purpose.",566,data/crawl/squid/hunk_4902.cpp,,,data/crawl/squid/old_hunk_4902.cpp,data/crawl/squid/new_hunk_4902.cpp,171,-1,"storeAppendPrintf(e,
                      ""\n""
                      ""Server-side persistent connection counts:\n""
                      ""\n""
                      ""\treq/\n""
                      ""\tconn      count\n""
                      ""\t----  ---------\n"");",,"[""removeLog""]","[[""storeAppendPrintf"", ""e"", ""\\n"", ""Server"", ""side"", ""persistent"", ""connection"", ""counts"", ""\\n"", ""\\n"", ""\\treq/\\n"", ""\\tconn"", ""count\\n"", ""\\t"", ""\\n""], []]",[-11180452350504215011],7215,1366560.0,3
https://github.com/squid-cache/squid/commit/781ce8ff40f9cd5e6f5c4ec84ff2a978cff98ab0,07 Dec 2005,"Turned pconn.cc into C++ classes.  There are now separate persistent
connection pools for client-side, server-side, and now ICAP.

Accounting for persistent connection use still sucks because HTTP
(http.c) and ICAP state structures don't have any way to keep track
of how many times a given TCP connection was used.  So we'll keep
abusing fd_entry[] for this purpose.",566,data/crawl/squid/hunk_4902.cpp,,,data/crawl/squid/old_hunk_4902.cpp,data/crawl/squid/new_hunk_4902.cpp,168,-1,"storeAppendPrintf(e, ""\t%4d  %9d\n"", i, client_pconn_hist[i]);",,"[""removeLog""]","[[""storeAppendPrintf"", ""e"", ""\\t%4d"", ""%9d\\n"", ""i"", ""client_pconn_hist[i]""], []]",[-3068874400049008290],7214,1366560.0,3
https://github.com/squid-cache/squid/commit/663c0a384e7af8c593647fc04a89cb7051ac6cdf,14 Jun 2006,"Partial Windows native port merge:

- Native Windows comm_select() implementation",945,data/crawl/squid/hunk_4804.cpp,,,data/crawl/squid/old_hunk_4804.cpp,data/crawl/squid/new_hunk_4804.cpp,-1,874,,"storeAppendPrintf(sentry, ""Histogram of events per incoming socket type\n"");","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""Histogram"", ""of"", ""events"", ""per"", ""incoming"", ""socket"", ""type\\n""]]",[1151672113808383658],7213,1985760.0,3
https://github.com/squid-cache/squid/commit/663c0a384e7af8c593647fc04a89cb7051ac6cdf,14 Jun 2006,"Partial Windows native port merge:

- Native Windows comm_select() implementation",945,data/crawl/squid/hunk_4804.cpp,,,data/crawl/squid/old_hunk_4804.cpp,data/crawl/squid/new_hunk_4804.cpp,-1,871,,"storeAppendPrintf(sentry, ""Current incoming_http_interval: %d\n"",
                      incoming_http_interval >> INCOMING_FACTOR);","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""Current"", ""incoming_http_interval"", ""%d\\n"", ""incoming_http_interval"", ""INCOMING_FACTOR""]]",[-4932119534106571314],7212,1985760.0,3
https://github.com/squid-cache/squid/commit/663c0a384e7af8c593647fc04a89cb7051ac6cdf,14 Jun 2006,"Partial Windows native port merge:

- Native Windows comm_select() implementation",945,data/crawl/squid/hunk_4804.cpp,,,data/crawl/squid/old_hunk_4804.cpp,data/crawl/squid/new_hunk_4804.cpp,-1,869,,"storeAppendPrintf(sentry, ""Current incoming_dns_interval: %d\n"",
                      incoming_dns_interval >> INCOMING_FACTOR);","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""Current"", ""incoming_dns_interval"", ""%d\\n"", ""incoming_dns_interval"", ""INCOMING_FACTOR""]]",[1872844249140019602],7211,1727520.0,3
https://github.com/squid-cache/squid/commit/663c0a384e7af8c593647fc04a89cb7051ac6cdf,14 Jun 2006,"Partial Windows native port merge:

- Native Windows comm_select() implementation",945,data/crawl/squid/hunk_4804.cpp,,,data/crawl/squid/old_hunk_4804.cpp,data/crawl/squid/new_hunk_4804.cpp,-1,867,,"storeAppendPrintf(sentry, ""Current incoming_icp_interval: %d\n"",
                      incoming_icp_interval >> INCOMING_FACTOR);","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""Current"", ""incoming_icp_interval"", ""%d\\n"", ""incoming_icp_interval"", ""INCOMING_FACTOR""]]",[-14564787219605550420],7210,1985760.0,3
https://github.com/squid-cache/squid/commit/9c8434f6a8753d321762ff58685cb1ff0364b4a7,14 Sep 2006,"Windows port: split Windows service code into WinSvc.cc, allowing correct execution of make check",1963,data/crawl/squid/hunk_4751.cpp,,,data/crawl/squid/old_hunk_4751.cpp,data/crawl/squid/new_hunk_4751.cpp,595,-1,"fprintf(stderr, ""OpenSCManager failed\n"");",,"[""removeLog""]","[[""fprintf"", ""stderr"", ""OpenSCManager"", ""failed\\n""], []]",[21828551817829994559],7209,0.0,3
https://github.com/squid-cache/squid/commit/c99de60701b56be31c01be2045d204ed411e33ca,01 Nov 2006,"	- Many ICAP fixes from Alex Rousskov accumulated on the
	  sourceforge squid3-icap branch since 2006/10, including:

        - Polished ICAP service selection code and implemented bypass of
          optional services. The code implements icap_class
          configuration directive which is currently used as a ""set of
          interchangeable ICAP services"". Squid2 and current squid.conf
          may imply otherwise.

        - Support Transfer-* ICAP OPTIONS response header. If Squid
          knows that a service does not want the URL, Squid will not use
          the service, even if it is an essential service with
          bypass=0. Note that we may make this decision before we know
          what the service wants. Eventually, ACLs should initiate and
          wait for the OPTIONS transaction for yet-unprobed services.

        - When ICAP transactions fail to connect to the service many
          times, the service is suspended until the next OPTIONS
          update. The limit is currently hard-coded to 10. Suspended
          service is a down service and will be skipped by the ACL
          service selection algorithm.

        - Rewrote the code updating ICAP service options. We no longer
          mark the service being updated as ""down"". Only presence of
          valid and fresh options is important. We also try to update
          the options before they expire to avoid any service downtime
          or use of stale options.

        - Report interesting changes in the ICAP service state, some
          with debugging level one to alert the cache administrator.

        - When cloning a request during an ICAP 204 ""No Content"" REQMOD
          response, preserve the client address so that the rest of the
          code has access to it. This change appears to fix Squid Bug
          #1712.

        - After ICAP 100 Continue, expect new ICAP headers instead of
          HTTP headers. Reset ICAP message object to be ready to parse
          ICAP headers again. (Tsantilas Christos
          <chtsanti@users.sourceforge.net>)

        - The ieof HTTP chunk-extension was written after chunk-data
          instead of being written after the chunk-size. (Tsantilas
          Christos <chtsanti@users.sourceforge.net>)

        - Merged common code from the ICAPClientReqmodPrecache and
          ICAPClientReqmodPrecache classes into the newly added
          ICAPClientVector class.  The specific vectors do not have a
          common owner (yet?) because ServerStateData and
          ClientHttpRequest do not have a common base class. Thus,
          ICAPClientVector has to rely on its kids to communicate with
          their owners. However, at least 50% of the logic was common
          and has been moved. Eventually, we may want to create a
          simple ICAPOwner API that ServerStateData and
          ClientHttpRequest can implement and ICAPClientVector can rely
          on. This will make the code simpler and more efficient.  The
          big merge was motivated by a couple of bugs that were found
          in one vector class but that did not exist or behaved
          differently in the other vector, mostly likely due to natural
          diversion of used-to-be identical code.

        - Rewrote communication between a server-side ICAPClient*mod*
          vector and its owner.  When a server-side ICAPClient*mod*
          vector was notifying its owner of more adapted data, the
          owner could delete the vector (by calling icap->ownerAbort)
          if the store entry was not willing to accept the data.  The
          same deletion could happen when a vector was notifying the
          owner of a successful termination. In all those cases, the
          vector did not expect to be deleted and could continue to do
          something, causing segmentation faults.  Now, when more data
          is available, the vector calls its owner and checks the
          return value of the call. If it is false, the vector knows it
          has been deleted and quits. When vector terminates, it calls
          its owner and trusts the owner to always delete the vector.
          The ""check return value and quit"" design is not perfect, but
          we are paying the price for isolating the vectors from their
          owners while using direct calls between them (instead of
          MsgPipe or a similar less efficient indirect approach we use
          elsewhere).

        - Renamed doIcap to startIcap and moved more common code there.
          Changed its return type to bool. We now handle three cases
          when ICAP ACLs call back:  1) No service was selected
          (because there was no applicable service or because all
          applicable services were broken and optional). We proceed as
          if ICAP was not configured.  2) The selected essential
          service is broken. This is a fatal transaction error and we
          return an ""ICAP protocol error"" HTTP error response. We could
          proceed with the ICAP stuff, but it saves a lot of cycles to
          abort early.  3) The selected service is not broken. We
          proceed with the ICAP stuff.  The old code did not detect
          case #2, even though there was code to handle that case (with
          dangerous XXX suggestions that are now gone).  The code
          should probably be polished further to move common ftp/http
          logic from icapAclCheckDone()s into ServerStateData.

        - Make sure there is an accept callback when we are accepting.
          If there is no callback and we accept, we will silently leak
          the accepted FD.  When we are running out of FDs, there is
          often no accept callback.  The old code, when running out of
          FDs, would create lots of ""orphaned"" or ""forgotten"" FDs that
          will eventually get into a CLOSED_WAIT state and remain there
          until Squid quits.  The new code does not call accept() if
          there is no accept callback and does not register the accept
          FD for reading if the AcceptLimiter is deferring, because
          when the AcceptLimiter kicks in, it will register the accept
          FD for reading. There are most likely other places/cases
          where accept FD should not be registered for reading.

        - When an exception is caught, mark the ICAP connection as
          non-reusable so that it is not recycled while a write is
          pending but simply closed instead. Our write callback will
          still be called, unfortunately, because there is no way to
          clear the callback without invalidating its data (i.e., the
          transaction pointer).  This change prevents pconn.cc:253:
          ""!comm_has_incomplete_write(fd)"" assertion from firing when
          things go wrong (e.g., the ICAP server cannot be contacted to
          retrieve OPTIONS).  Not all exceptions caught by the ICAP
          xaction should lead to the ICAP connection termination, but
          it is very difficult if not impossible to reliably detect
          exceptional conditions when it is safe to reuse the ICAP
          connection, and it is probably not worth it anyway.

        - Added Tsantilas Christos <chtsanti@users.sourceforge.net>
          to CONTRIBUTORS for fixing ICAP bugs.

        - Polished debugging.",2091,data/crawl/squid/hunk_4725.cpp,,,data/crawl/squid/old_hunk_4725.cpp,data/crawl/squid/new_hunk_4725.cpp,-1,96,,stop(notifyIcap);,"[""addLog""]","[[], [""stop"", ""notifyIcap""]]",[448476161043210430],7208,165120.0,3
https://github.com/squid-cache/squid/commit/b7d249f9ddca7cfe73ac27d273901450e81baf31,02 Nov 2006,"Add support for wccpv2 mask assignment

Forwrd port of 2.6 changes.",535,data/crawl/squid/hunk_4713.cpp,,,data/crawl/squid/old_hunk_4713.cpp,data/crawl/squid/new_hunk_4713.cpp,-1,56,,"fatalf(""Unknown service hash method\n"");","[""addLog""]","[[], [""fatalf"", ""Unknown"", ""service"", ""hash"", ""method\\n""]]",[16020496437618912398],7207,0.0,3
https://github.com/squid-cache/squid/commit/5f8252d203092b380f73e997be7097282c793077,06 Apr 2007,"	- ICAP-unrelated improvements from the squid3-icap branch on SF
	  (see further below for ICAP-specific improvements):

	- Replaced BodyReader with BodyPipe. BodyReader was a
	  collection of function pointers augmented with body size
	  calculation logic. BodyReader was used to deliver request
	  body (of a known size) from the client side to the server
	  side. Reference counting was used to communicate abort
	  conditions to the other side (it did not work well because
	  decreasing the reference count does not have any side-effects
	  if the count remains positive). Direct calls between sides
	  sometimes resulted in a call-me-when-I-am-calling-you ""loops""
	  and related bugs.

	  BodyPipe is used to deliver request or response body (possibly
	  of unknown size) from the body producer to the body consumer.
	  A producer can be the client side (for virgin requests), the
	  server side (for virgin replies), or the ICAP side (for
	  adapted messages). A consumer can be the client side (for
	  adapted responses, including responses in a request
	  satisfaction mode), the server side (for adapted requests),
	  and the ICAP side (for virgin requests and responses).

	  BodyPipe uses asynchronous calls for communication between
	  sides to avoid call-me-when-I-am-calling-you ""loops"".

	  BodyPipe has methods to communicate normal termination and
	  abort conditions to the other side. The use of those methods
	  is mandatory. Reference counting is used only as a garbage
	  collection mechanism.

	  BodyPipe is used to read request bodies, including requests
	  for which there is no consumer and the connection is in a
	  'closing' state. BodyPipe can auto-consume body so that a
	  'closing' connection does not have to rely on the body
	  consumer presence when eating up remaining body data.

	  If auto-consumption is turned on and the pipe starts
	  consuming before a real consumer is attached to the pipe, the
	  setConsumerIfNotLate call fails, and the real consumer has to
	  handle the failure.

	  The new BodyPipe approach should make support for HTTP/1.1
	  chunked requests easier. Only a few places in the pipe-related
	  code assume that the request size is known.

	- Removed ClientBody as unused, replaced by BodyReader, then
	  BodyPipe.

	- Moved HttpRequest::body_reader to HttpMsg::body_pipe so that
	  all HTTP message bodies can be communicated via pipes. This
	  is needed for the server side to supply response bodies to
	  ICAP and for the ICAP side to supply adapted message bodies
	  to others.

	- When cleaning HttpRequest or HttpReply, reset body_pipe to
	  NULL instead of asserting that it is already NULL. BodyPipes
	  are owned and maintained by other objects and HttpMsg is used
	  only as a mechanism to pass the pipe pointer from the body
	  producer to the consumer. To maintain guarantees similar to
	  the old code, the BodyPipe destructor asserts that both the
	  producer and the consumer are gone when the pipe is
	  destructed.

	- When appending body data, do not append more than the known
	  body size. This fixes the following assertion when POSTing
	  from IE in my tests: assertion failed: client_side.cc:3205:
	  ""bodySizeLeft() > 0"".

	  I suspect IE or some Javascripts running on IE were appending
	  extra CRLF to a POST, exposing the bug, and triggering the
	  above assertion.

	- WARNING: Ftp-specific BodyPipe changes are untested, but the
	  old code probably did not work well with ICAP either.  More
	  testing is needed.

	- Moved more common server-side code from http.* and ftp.* into
	  Server.*.  Most ICAP-related code is in the Server class now.

	  The code move to the Server class and migration to BodyPipe
	  exposed several FTP/HTTP inconsistencies and bugs. I marked
	  those I could not fix with XXXs.

	- Distinguish the end of communication with the origin server
	  from the end of communication with ICAP. Clean them up
	  separately when possible. Terminate when both are completed
	  (or aborted).

	- Polished persistentConnStatus() to avoid calling
	  statusIfComplete() until really necessary (and appropriate).
	  This makes debugging easier to understand for some.

	- Use auto-consumption feature to consume data from closing
	  connections for which there is no real body consumer.

	- Use BodyPipe for maintaining the ""closing"" state of a
	  connection instead of in.abortedSize. This change ""removes"" a
	  few memory leaks and an assertion, but does need more work,
	  especially when the regular BodyPipe consumer leaves early
	  and does not consume the request body.

	- The client stream code sometimes marks the ""closing""
	  connection as STREAM_UNPLANNED_COMPLETE, leading to a
	  double-close. I do not yet understand why. There is now code
	  to ignore multiple attempts to enter the ""closing"" state.



	- ICAP improvements from the squid3-icap branch on SF, including:

	- Added icap_service_failure_limit squid.conf option. The limit
	  specifies the number of failures that Squid tolerates when
	  establishing a new TCP connection with an ICAP service. If
	  the number of failures exceeds the limit, the ICAP service is
	  not used for new ICAP requests until it is time to refresh
	  its OPTIONS. The per-service failure counter is reset to zero
	  each time Squid fetches new service OPTIONS.

	  A negative value disables the limit.

	  The limit used to be hardcoded to 10.

	  (based on the patch by Axel Westerhold)

	- Added icap_service_revival_delay squid.conf option.  The
	  delay specifies the number of seconds to wait after an ICAP
	  OPTIONS request failure before requesting the options again.
	  The failed ICAP service is considered ""down"" until fresh
	  OPTIONS are fetched.

	  The actual delay cannot be smaller than the [still] hardcoded
	  minimum delay of 60 seconds.

	  (based on the patch by Axel Westerhold)

	- Added icap_client_username_header and
	  icap_client_username_encode squid.conf options to control how
	  the authenticated client username should be sent to the ICAP
	  service. (based on the patch by Axel Westerhold)

	- Handle REQMOD transaction failures where we cannot proceed
	  with the normal request flow.

	- Use ICAPInitiator API to send ""success"" or ""abort"" messages
	  to ICAP transaction initiator. Store virgin and adapted
	  metadata as public fields (if the newly added ICAPInOut type)
	  that the initiator can access when receiving our ""successful
	  adaptation"" message. This keeps messages simple.

	- Using ICAPInitiator API and a ""universal"" BodyPipe API makes
	  it possible to exchange bodies directly with client- or
	  server-side code without ICAPClient* translators, which are
	  now gone along with the ICAPInitXaction function in
	  ICAPClient.

	- Added ICAPInitiator interface that classes initiating ICAP
	  transactions must now support. The API currently has just two
	  methods: one for receiving adapted message headers
	  (indicating a successful ICAP transaction, at least to the
	  point of fetching adapted headers) and one for receiving a
	  notification of an aborted ICAP transaction.

	  Most ICAP initiators (or their close relatives) will also need
	  to implement BodyConsumer and/or BodyProducer APIs to exchange
	  virgin and/or adapted HTTP message bodies with the initiated
	  ICAP transaction. However, that activity is not addressed in
	  this API.  New AsyncCall API is used to declare the callback
	  wrappers.

	- Use BodyPipe instead of MsgPipe for receiving virgin and
	  sending adapted message bodies. BodyPipe is not much
	  different from MsgPipeBody, but it is better to use a
	  ""universal"" class that the rest of Squid code now uses.  One
	  complication is that BodyPipes are currently not created for
	  messages with zero-size bodies. The code had to be changed to
	  not assume that a zero-size body comes with a pipe.

	- Deleted MsgPipe and related classes. Message pipes had two
	  purposes: coordinate HTTP message adaptation (start, get the
	  adapted headers, abort) and exchange HTTP message bodies. The
	  latter is now done via BodyPipe API. The former can be
	  implemented directly in ICAPModXact.

	  Deleted ICAPClient* and related classes as (my) design
	  failure.

	  The original idea behind message pipes and ICAPClient* classes
	  was to isolate ICAP code from the Squid core. The core code
	  was supposed to use ICAPClient* classes for all ICAP-related
	  needs, and ICAPClient* classes were supposed to translate core
	  needs into ""ICAP needs"" and use message pipes to communicate
	  with asynchronously running ICAP transactions. The latter part
	  worked fine, but the former did not.

	  The core code still did a lot of ICAP-specific work on its
	  own. This could be because ICAP processing affects the flow so
	  much or because the core code had not been refactored enough
	  to minimize ICAP interactions.  Whatever the reason, we ended
	  up with a lot of complex code/logic coordinating the core code
	  and ICAPClient* classes. While ICAPClient* classes were
	  ""translating"", they could not hide the key actions or events
	  (such as message body exchange or transaction aborts) from the
	  core. The core code still had to support those actions or
	  handle those events.  Thus, every major action or event was
	  handled twice:  once in the core side code and once in a
	  ICAPClient* class.

	  Removing ICAPClient* ""translation"" step simplified the code
	  and possibly improved performance. As for the ""ICAP
	  separation"" goal, the current exposure to the ICAPModXact
	  class can be hidden by a generic ""Message Adaptation
	  Transaction"" class if we need to support more adaptation
	  protocols. The core code should not be affected much by such a
	  change.

	- ClientHttpRequest: Support the new ICAPInitiator API and talk
	  to ICAPModXact directly instead of using ICAPClient* classes,
	  which are now gone.

	- ConnStateData: Use BodyPipe for delivering virgin request
	  bodies to the server or ICAP side. Implement the BodyProducer
	  interface.  ClientHttpRequest: Use BodyPipe instead of
	  BodyReader when receiving request bodies (from client side or
	  ICAP).  Implement the BodyConsumer interface.  See the first
	  BodyPipe CVS log message for the rationale.

	- Use BodyPipe for delivering virgin reply bodies to ICAP and
	  receiving adapted reply bodies from ICAP. Implement the
	  BodyProducer interface.

	  Use BodyPipe instead of BodyReader when receiving request
	  bodies (from client side or ICAP).  Implement the BodyConsumer
	  interface.

	- Replaced never-failing doIcap() with startIcap() that fails
	  if we cannot select an ICAP service or the selected service
	  is not usable. Rearranged
	  ClientRequestContext::icapAclCheckDone() to bypass ICAP
	  errors when possible.  Now, ClientRequestContext::startIcap()
	  is very similar to Server::startIcap(). Same for
	  icapAclCheckDone().  Made
	  ClientHttpRequest::handleIcapFailure() public because
	  ClientRequestContext::icapAclCheckDone() calls it.

	- Polished TTL handling to make sure we use the default TTL
	  when the ICAP server did not provide an explicit value or if
	  we failed to communicate with the server. The latter case may
	  not have been handled correctly before.

	- The minimum options update gap (currently hard-coded) must be
	  smaller than the default options TTL. Otherwise, we get stale
	  options and down ICAP services around the update time because
	  we cannot update soon enough.

	- Support asynchronous transaction start. This allows for a
	  better handling of startup errors (or at least makes them
	  similar to other transaction errors).

	- Call a swanSong() method upon expected transaction
	  termination (including aborts). This allows for proper and
	  prompt [partial] transaction cleanup, without waiting for the
	  destructor to be called. The destruction may be delayed by
	  refcounting if we have other transaction users waiting for
	  some transaction notifications.

	- Do not reuse a connection if we are still reading or writing
	  (even if no actual I/O is scheduled). The old code would
	  reuse such connections, and read/write leftovers from aborted
	  transactions from/to the ICAP server.

	- Do not send last-chunk in ICAP Preview with a null-body. It is
	  possible that the old code would send the last-chunk under
	  some Preview conditions with null-body, but I am not sure.

	- Fixed HttpStateData memory leak visible when no RESPMOD
	  services are enabled.  ICAPAccessCheck constructor was
	  cbdata-locking HttpStateData, but was not releasing the lock
	  when there was no matching service class, leading to an
	  HttpStateData leak. Furthermore, ICAPAccessCheck would then
	  call HttpStateData back without validating the cbdata
	  pointer, probably calling wrong or invalid HttpStateData.

	- Fixed ""is it too late to bypass?"" conditions in
	  ClientHttpRequest::handleIcapFailure(). We should be able to
	  bypass more often now. However, handleIcapFailure() still has
	  the old bug: it does not check whether the service is
	  optional. The current fix implies that now Squid may bypass
	  essential services more often.

	- Call storeEntry()->complete() when ending request
	  satisfaction. Without this call, we may keep the connection
	  open, which does not work with responses that mark the end of
	  their body by closing a connection. (Christos Tsantilas)

	- Fixed ieof condition detection. Squid was sending last-chunk
	  without ieof bit and was sending two last chunks when doing
	  preview (Tsantilas Christos).

	- When ICAP server wants the entire virgin body and sends 100
	  Continue after Preview, do not stop backing up virgin body
	  data for echoing if we promised to support 204 No Content
	  responses outside of Preview. If we allow 204s, 100 Continue
	  may be followed by a 204 No Content and we will need the
	  entire virgin body to echo back.

	- Rewrote MemBufClaim into a VirginBodyAct class to simplify
	  and clarify code in hope to minimize the number of bugs like
	  the one mentioned above. MemBufClaim was protecting an area
	  of virgin body pipe content and, as a side effect, was
	  providing the transaction with the content pointer for the
	  write or send actions.

	  Now VirginBodyAct just maintains the activity offset and the
	  transaction code uses that to consume virgin body correctly.
	  The size of the area is no longer maintained because it was
	  usually unknown or unused; and when it was known and used
	  (i.e., Preview), it could be taken from the preview state
	  object anyway.  Renamed and documented VirginBodyAct-related
	  methods to clarify the intent.

	- When sending last-chunk in Preview, send ieof extension if we
	  wrote the entire body. The old code would not send ieof if we
	  wrote as many bytes as promised in the Preview header, even
	  if we promised to write everything.  This would mislead
	  compliant ICAP servers that do not look at the Content-Length
	  header and reply with 100 Continue, expecting more body data.

	- Do not reset Preview size to zero when expecting a virgin
	  body of unknown size. A Squid user reported that this change
	  works.

	- Polished debugging: Instead of using pointers, use unique ICAP
	  transaction IDs.  This helps with isolating a transaction in a
	  large log, where pointers may be reused many times. Print
	  connection descriptor like most of the core code does. Other
	  minor improvements.",4655,data/crawl/squid/hunk_4673.cpp,,,data/crawl/squid/old_hunk_4673.cpp,data/crawl/squid/new_hunk_4673.cpp,96,-1,stop(notifyIcap);,,"[""removeLog""]","[[""stop"", ""notifyIcap""], []]",[-448476161043210430],7206,74880.0,3
https://github.com/squid-cache/squid/commit/89f77e43f36bdbd636826c94085f9b5d882e473d,24 Jun 2007,"Bug #1948: digest_edir_auth helper, using novell eDirectory universal password

This is a modified version of digets_ldap_auth, with eDirectory special hooks
for retrieving the Universal Password plain text password.",1874,data/crawl/squid/hunk_4545.cpp,,,data/crawl/squid/old_hunk_4545.cpp,data/crawl/squid/new_hunk_4545.cpp,-1,644,,"fprintf(stderr, ""\tIf you need to bind as a user to perform searches then use the\n\t-D binddn -w bindpasswd or -D binddn -W secretfile options\n\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""\\tIf"", ""you"", ""need"", ""to"", ""bind"", ""as"", ""a"", ""user"", ""to"", ""perform"", ""searches"", ""then"", ""use"", ""the\\n\\t"", ""D"", ""binddn"", ""w"", ""bindpasswd"", ""or"", ""D"", ""binddn"", ""W"", ""secretfile"", ""options\\n\\n""]]",[-21067398988177175679],7205,475200.0,3
https://github.com/squid-cache/squid/commit/89f77e43f36bdbd636826c94085f9b5d882e473d,24 Jun 2007,"Bug #1948: digest_edir_auth helper, using novell eDirectory universal password

This is a modified version of digets_ldap_auth, with eDirectory special hooks
for retrieving the Universal Password plain text password.",1874,data/crawl/squid/hunk_4545.cpp,,,data/crawl/squid/old_hunk_4545.cpp,data/crawl/squid/new_hunk_4545.cpp,-1,641,,"fprintf(stderr, ""\t-S\t\t\t\t\tStrip NT domain from usernames\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""\\t"", ""S\\t\\t\\t\\t\\tStrip"", ""NT"", ""domain"", ""from"", ""usernames\\n""]]",[5090686850103421743],7204,475200.0,3
https://github.com/squid-cache/squid/commit/89f77e43f36bdbd636826c94085f9b5d882e473d,24 Jun 2007,"Bug #1948: digest_edir_auth helper, using novell eDirectory universal password

This is a modified version of digets_ldap_auth, with eDirectory special hooks
for retrieving the Universal Password plain text password.",1874,data/crawl/squid/hunk_4545.cpp,,,data/crawl/squid/old_hunk_4545.cpp,data/crawl/squid/new_hunk_4545.cpp,-1,639,,"fprintf(stderr, ""\t-Z\t\t\t\t\tTLS encrypt the LDAP connection, requires\n\t\t\t\tLDAP version 3\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""\\t"", ""Z\\t\\t\\t\\t\\tTLS"", ""encrypt"", ""the"", ""LDAP"", ""connection"", ""requires\\n\\t\\t\\t\\tLDAP"", ""version"", ""3\\n""]]",[-5060751713717657718],7203,475200.0,3
https://github.com/squid-cache/squid/commit/89f77e43f36bdbd636826c94085f9b5d882e473d,24 Jun 2007,"Bug #1948: digest_edir_auth helper, using novell eDirectory universal password

This is a modified version of digets_ldap_auth, with eDirectory special hooks
for retrieving the Universal Password plain text password.",1874,data/crawl/squid/hunk_4545.cpp,,,data/crawl/squid/old_hunk_4545.cpp,data/crawl/squid/new_hunk_4545.cpp,-1,638,,"fprintf(stderr, ""\t-v 2|3\t\t\t\t\tLDAP version\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""\\t"", ""v"", ""2"", ""3\\t\\t\\t\\t\\tLDAP"", ""version\\n""]]",[-21145454339206748204],7202,475200.0,3
https://github.com/squid-cache/squid/commit/89f77e43f36bdbd636826c94085f9b5d882e473d,24 Jun 2007,"Bug #1948: digest_edir_auth helper, using novell eDirectory universal password

This is a modified version of digets_ldap_auth, with eDirectory special hooks
for retrieving the Universal Password plain text password.",1874,data/crawl/squid/hunk_4545.cpp,,,data/crawl/squid/old_hunk_4545.cpp,data/crawl/squid/new_hunk_4545.cpp,-1,636,,"fprintf(stderr, ""\t-a never|always|search|find\t\twhen to dereference aliases\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""\\t"", ""a"", ""never"", ""always"", ""search"", ""find\\t\\twhen"", ""to"", ""dereference"", ""aliases\\n""]]",[-23105837796456109078],7201,475200.0,3
https://github.com/squid-cache/squid/commit/89f77e43f36bdbd636826c94085f9b5d882e473d,24 Jun 2007,"Bug #1948: digest_edir_auth helper, using novell eDirectory universal password

This is a modified version of digets_ldap_auth, with eDirectory special hooks
for retrieving the Universal Password plain text password.",1874,data/crawl/squid/hunk_4545.cpp,,,data/crawl/squid/old_hunk_4545.cpp,data/crawl/squid/new_hunk_4545.cpp,-1,635,,"fprintf(stderr, ""\t-R\t\t\t\t\tdo not follow referrals\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""\\t"", ""R\\t\\t\\t\\t\\tdo"", ""not"", ""follow"", ""referrals\\n""]]",[-1894048416314063796],7200,475200.0,3
https://github.com/squid-cache/squid/commit/89f77e43f36bdbd636826c94085f9b5d882e473d,24 Jun 2007,"Bug #1948: digest_edir_auth helper, using novell eDirectory universal password

This is a modified version of digets_ldap_auth, with eDirectory special hooks
for retrieving the Universal Password plain text password.",1874,data/crawl/squid/hunk_4545.cpp,,,data/crawl/squid/old_hunk_4545.cpp,data/crawl/squid/new_hunk_4545.cpp,-1,634,,"fprintf(stderr, ""\t-t timelimit\t\t\t\tsearch time limit\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""\\t"", ""t"", ""timelimit\\t\\t\\t\\tsearch"", ""time"", ""limit\\n""]]",[-11723405557014922537],7199,475200.0,3
https://github.com/squid-cache/squid/commit/89f77e43f36bdbd636826c94085f9b5d882e473d,24 Jun 2007,"Bug #1948: digest_edir_auth helper, using novell eDirectory universal password

This is a modified version of digets_ldap_auth, with eDirectory special hooks
for retrieving the Universal Password plain text password.",1874,data/crawl/squid/hunk_4545.cpp,,,data/crawl/squid/old_hunk_4545.cpp,data/crawl/squid/new_hunk_4545.cpp,-1,633,,"fprintf(stderr, ""\t-c timeout\t\t\t\tconnect timeout\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""\\t"", ""c"", ""timeout\\t\\t\\t\\tconnect"", ""timeout\\n""]]",[2744873673402200451],7198,475200.0,3
https://github.com/squid-cache/squid/commit/89f77e43f36bdbd636826c94085f9b5d882e473d,24 Jun 2007,"Bug #1948: digest_edir_auth helper, using novell eDirectory universal password

This is a modified version of digets_ldap_auth, with eDirectory special hooks
for retrieving the Universal Password plain text password.",1874,data/crawl/squid/hunk_4545.cpp,,,data/crawl/squid/old_hunk_4545.cpp,data/crawl/squid/new_hunk_4545.cpp,-1,631,,"fprintf(stderr, ""\t-E sslcertpath\t\t\t\tenable LDAP over SSL\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""\\t"", ""E"", ""sslcertpath\\t\\t\\t\\tenable"", ""LDAP"", ""over"", ""SSL\\n""]]",[-8592631049204160241],7197,475200.0,3
https://github.com/squid-cache/squid/commit/89f77e43f36bdbd636826c94085f9b5d882e473d,24 Jun 2007,"Bug #1948: digest_edir_auth helper, using novell eDirectory universal password

This is a modified version of digets_ldap_auth, with eDirectory special hooks
for retrieving the Universal Password plain text password.",1874,data/crawl/squid/hunk_4545.cpp,,,data/crawl/squid/old_hunk_4545.cpp,data/crawl/squid/new_hunk_4545.cpp,-1,629,,"fprintf(stderr, ""\t-P\t\t\t\t\tpersistent LDAP connection\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""\\t"", ""P\\t\\t\\t\\t\\tpersistent"", ""LDAP"", ""connection\\n""]]",[-21091167032319512765],7196,475200.0,3
https://github.com/squid-cache/squid/commit/89f77e43f36bdbd636826c94085f9b5d882e473d,24 Jun 2007,"Bug #1948: digest_edir_auth helper, using novell eDirectory universal password

This is a modified version of digets_ldap_auth, with eDirectory special hooks
for retrieving the Universal Password plain text password.",1874,data/crawl/squid/hunk_4545.cpp,,,data/crawl/squid/old_hunk_4545.cpp,data/crawl/squid/new_hunk_4545.cpp,-1,628,,"fprintf(stderr, ""\t-p port\t\t\t\t\tLDAP server port (defaults to %d)\n"", LDAP_PORT);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""\\t"", ""p"", ""port\\t\\t\\t\\t\\tLDAP"", ""server"", ""port"", ""defaults"", ""to"", ""%d"", ""\\n"", ""LDAP_PORT""]]",[-19321455758914240077],7195,475200.0,3
https://github.com/squid-cache/squid/commit/89f77e43f36bdbd636826c94085f9b5d882e473d,24 Jun 2007,"Bug #1948: digest_edir_auth helper, using novell eDirectory universal password

This is a modified version of digets_ldap_auth, with eDirectory special hooks
for retrieving the Universal Password plain text password.",1874,data/crawl/squid/hunk_4545.cpp,,,data/crawl/squid/old_hunk_4545.cpp,data/crawl/squid/new_hunk_4545.cpp,-1,627,,"fprintf(stderr, ""\t-h server\t\t\t\tLDAP server (defaults to localhost)\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""\\t"", ""h"", ""server\\t\\t\\t\\tLDAP"", ""server"", ""defaults"", ""to"", ""localhost"", ""\\n""]]",[-9582311649862625147],7194,475200.0,3
https://github.com/squid-cache/squid/commit/89f77e43f36bdbd636826c94085f9b5d882e473d,24 Jun 2007,"Bug #1948: digest_edir_auth helper, using novell eDirectory universal password

This is a modified version of digets_ldap_auth, with eDirectory special hooks
for retrieving the Universal Password plain text password.",1874,data/crawl/squid/hunk_4545.cpp,,,data/crawl/squid/old_hunk_4545.cpp,data/crawl/squid/new_hunk_4545.cpp,-1,625,,"fprintf(stderr, ""\t-H URI\t\t\t\t\tLDAPURI (defaults to ldap://localhost)\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""\\t"", ""H"", ""URI\\t\\t\\t\\t\\tLDAPURI"", ""defaults"", ""to"", ""ldap"", ""//localhost"", ""\\n""]]",[-10330614204544903234],7193,475200.0,3
https://github.com/squid-cache/squid/commit/89f77e43f36bdbd636826c94085f9b5d882e473d,24 Jun 2007,"Bug #1948: digest_edir_auth helper, using novell eDirectory universal password

This is a modified version of digets_ldap_auth, with eDirectory special hooks
for retrieving the Universal Password plain text password.",1874,data/crawl/squid/hunk_4545.cpp,,,data/crawl/squid/old_hunk_4545.cpp,data/crawl/squid/new_hunk_4545.cpp,-1,623,,"fprintf(stderr, ""\t-W secretfile\t\t\t\tread password for binddn from file secretfile\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""\\t"", ""W"", ""secretfile\\t\\t\\t\\tread"", ""password"", ""for"", ""binddn"", ""from"", ""file"", ""secretfile\\n""]]",[-9878792280319460962],7192,475200.0,3
https://github.com/squid-cache/squid/commit/89f77e43f36bdbd636826c94085f9b5d882e473d,24 Jun 2007,"Bug #1948: digest_edir_auth helper, using novell eDirectory universal password

This is a modified version of digets_ldap_auth, with eDirectory special hooks
for retrieving the Universal Password plain text password.",1874,data/crawl/squid/hunk_4545.cpp,,,data/crawl/squid/old_hunk_4545.cpp,data/crawl/squid/new_hunk_4545.cpp,-1,622,,"fprintf(stderr, ""\t-w bindpasswd\t\t\t\tpassword for binddn\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""\\t"", ""w"", ""bindpasswd\\t\\t\\t\\tpassword"", ""for"", ""binddn\\n""]]",[-12530415325592299573],7191,475200.0,3
https://github.com/squid-cache/squid/commit/89f77e43f36bdbd636826c94085f9b5d882e473d,24 Jun 2007,"Bug #1948: digest_edir_auth helper, using novell eDirectory universal password

This is a modified version of digets_ldap_auth, with eDirectory special hooks
for retrieving the Universal Password plain text password.",1874,data/crawl/squid/hunk_4545.cpp,,,data/crawl/squid/old_hunk_4545.cpp,data/crawl/squid/new_hunk_4545.cpp,-1,621,,"fprintf(stderr, ""\t-D binddn\t\t\t\tDN to bind as to perform searches\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""\\t"", ""D"", ""binddn\\t\\t\\t\\tDN"", ""to"", ""bind"", ""as"", ""to"", ""perform"", ""searches\\n""]]",[-26923766882391008309],7190,475200.0,3
https://github.com/squid-cache/squid/commit/89f77e43f36bdbd636826c94085f9b5d882e473d,24 Jun 2007,"Bug #1948: digest_edir_auth helper, using novell eDirectory universal password

This is a modified version of digets_ldap_auth, with eDirectory special hooks
for retrieving the Universal Password plain text password.",1874,data/crawl/squid/hunk_4545.cpp,,,data/crawl/squid/old_hunk_4545.cpp,data/crawl/squid/new_hunk_4545.cpp,-1,620,,"fprintf(stderr, ""\t-s base|one|sub\t\t\t\tsearch scope\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""\\t"", ""s"", ""base"", ""one"", ""sub\\t\\t\\t\\tsearch"", ""scope\\n""]]",[-8879583864574169648],7189,475200.0,3
https://github.com/squid-cache/squid/commit/89f77e43f36bdbd636826c94085f9b5d882e473d,24 Jun 2007,"Bug #1948: digest_edir_auth helper, using novell eDirectory universal password

This is a modified version of digets_ldap_auth, with eDirectory special hooks
for retrieving the Universal Password plain text password.",1874,data/crawl/squid/hunk_4545.cpp,,,data/crawl/squid/old_hunk_4545.cpp,data/crawl/squid/new_hunk_4545.cpp,-1,619,,"fprintf(stderr, ""\t-u attribute\t\t\t\tattribute to use in combination with the basedn to create the user DN\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""\\t"", ""u"", ""attribute\\t\\t\\t\\tattribute"", ""to"", ""use"", ""in"", ""combination"", ""with"", ""the"", ""basedn"", ""to"", ""create"", ""the"", ""user"", ""DN\\n""]]",[-20820827593741061351],7188,475200.0,3
https://github.com/squid-cache/squid/commit/89f77e43f36bdbd636826c94085f9b5d882e473d,24 Jun 2007,"Bug #1948: digest_edir_auth helper, using novell eDirectory universal password

This is a modified version of digets_ldap_auth, with eDirectory special hooks
for retrieving the Universal Password plain text password.",1874,data/crawl/squid/hunk_4545.cpp,,,data/crawl/squid/old_hunk_4545.cpp,data/crawl/squid/new_hunk_4545.cpp,-1,618,,"fprintf(stderr, ""\t-F filter\t\t\t\tuser search filter pattern. %%s = login\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""\\t"", ""F"", ""filter\\t\\t\\t\\tuser"", ""search"", ""filter"", ""pattern"", ""%%s"", ""login\\n""]]",[-23098753190322380741],7187,475200.0,3
https://github.com/squid-cache/squid/commit/89f77e43f36bdbd636826c94085f9b5d882e473d,24 Jun 2007,"Bug #1948: digest_edir_auth helper, using novell eDirectory universal password

This is a modified version of digets_ldap_auth, with eDirectory special hooks
for retrieving the Universal Password plain text password.",1874,data/crawl/squid/hunk_4545.cpp,,,data/crawl/squid/old_hunk_4545.cpp,data/crawl/squid/new_hunk_4545.cpp,-1,617,,"fprintf(stderr, ""\t-e Encrypted passwords(REQUIRED)\tPassword are stored encrypted using HHA1\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""\\t"", ""e"", ""Encrypted"", ""passwords"", ""REQUIRED"", ""\\tPassword"", ""are"", ""stored"", ""encrypted"", ""using"", ""HHA1\\n""]]",[-10977248088103819280],7186,475200.0,3
https://github.com/squid-cache/squid/commit/89f77e43f36bdbd636826c94085f9b5d882e473d,24 Jun 2007,"Bug #1948: digest_edir_auth helper, using novell eDirectory universal password

This is a modified version of digets_ldap_auth, with eDirectory special hooks
for retrieving the Universal Password plain text password.",1874,data/crawl/squid/hunk_4545.cpp,,,data/crawl/squid/old_hunk_4545.cpp,data/crawl/squid/new_hunk_4545.cpp,-1,616,,"fprintf(stderr, ""\t-b basedn (REQUIRED)\t\t\tbase dn under where to search for users\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""\\t"", ""b"", ""basedn"", ""REQUIRED"", ""\\t\\t\\tbase"", ""dn"", ""under"", ""where"", ""to"", ""search"", ""for"", ""users\\n""]]",[-6268878712008716629],7185,475200.0,3
https://github.com/squid-cache/squid/commit/89f77e43f36bdbd636826c94085f9b5d882e473d,24 Jun 2007,"Bug #1948: digest_edir_auth helper, using novell eDirectory universal password

This is a modified version of digets_ldap_auth, with eDirectory special hooks
for retrieving the Universal Password plain text password.",1874,data/crawl/squid/hunk_4545.cpp,,,data/crawl/squid/old_hunk_4545.cpp,data/crawl/squid/new_hunk_4545.cpp,-1,615,,"fprintf(stderr, ""\t-l password realm delimiter(REQUIRED)\tCharater(s) that devides the password attribute\n\t\t\t\t\t\tin realm and password tokens, default ':' realm:password\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""\\t"", ""l"", ""password"", ""realm"", ""delimiter"", ""REQUIRED"", ""\\tCharater"", ""s"", ""that"", ""devides"", ""the"", ""password"", ""attribute\\n\\t\\t\\t\\t\\t\\tin"", ""realm"", ""and"", ""password"", ""tokens"", ""default"", ""realm"", ""password\\n""]]",[-51223121887047633760],7184,475200.0,3
https://github.com/squid-cache/squid/commit/89f77e43f36bdbd636826c94085f9b5d882e473d,24 Jun 2007,"Bug #1948: digest_edir_auth helper, using novell eDirectory universal password

This is a modified version of digets_ldap_auth, with eDirectory special hooks
for retrieving the Universal Password plain text password.",1874,data/crawl/squid/hunk_4545.cpp,,,data/crawl/squid/old_hunk_4545.cpp,data/crawl/squid/new_hunk_4545.cpp,-1,614,,"fprintf(stderr, ""\t-A password attribute(REQUIRED)\t\tUser attribute that contains the password\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""\\t"", ""A"", ""password"", ""attribute"", ""REQUIRED"", ""\\t\\tUser"", ""attribute"", ""that"", ""contains"", ""the"", ""password\\n""]]",[-44745532800568688908],7183,475200.0,3
https://github.com/squid-cache/squid/commit/89f77e43f36bdbd636826c94085f9b5d882e473d,24 Jun 2007,"Bug #1948: digest_edir_auth helper, using novell eDirectory universal password

This is a modified version of digets_ldap_auth, with eDirectory special hooks
for retrieving the Universal Password plain text password.",1874,data/crawl/squid/hunk_4545.cpp,,,data/crawl/squid/old_hunk_4545.cpp,data/crawl/squid/new_hunk_4545.cpp,-1,613,,"fprintf(stderr, ""Usage: "" PROGRAM_NAME "" -b basedn -f filter [options] ldap_server_name\n\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""Usage"", ""PROGRAM_NAME"", ""b"", ""basedn"", ""f"", ""filter"", ""[options]"", ""ldap_server_name\\n\\n""]]",[67020336773252265],7182,475200.0,3
https://github.com/squid-cache/squid/commit/89f77e43f36bdbd636826c94085f9b5d882e473d,24 Jun 2007,"Bug #1948: digest_edir_auth helper, using novell eDirectory universal password

This is a modified version of digets_ldap_auth, with eDirectory special hooks
for retrieving the Universal Password plain text password.",1874,data/crawl/squid/hunk_4545.cpp,,,data/crawl/squid/old_hunk_4545.cpp,data/crawl/squid/new_hunk_4545.cpp,-1,589,,"fprintf(stderr, PROGRAM_NAME "" ERROR: Unknown command line option '%c'\n"", option);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""PROGRAM_NAME"", ""ERROR"", ""Unknown"", ""command"", ""line"", ""option"", ""%c"", ""\\n"", ""option""]]",[4645213619568394786],7181,475200.0,3
https://github.com/squid-cache/squid/commit/89f77e43f36bdbd636826c94085f9b5d882e473d,24 Jun 2007,"Bug #1948: digest_edir_auth helper, using novell eDirectory universal password

This is a modified version of digets_ldap_auth, with eDirectory special hooks
for retrieving the Universal Password plain text password.",1874,data/crawl/squid/hunk_4545.cpp,,,data/crawl/squid/old_hunk_4545.cpp,data/crawl/squid/new_hunk_4545.cpp,-1,533,,"fprintf(stderr, PROGRAM_NAME "" ERROR: Unknown alias dereference method '%s'\n"", value);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""PROGRAM_NAME"", ""ERROR"", ""Unknown"", ""alias"", ""dereference"", ""method"", ""%s"", ""\\n"", ""value""]]",[-20888195001474585535],7180,475200.0,3
https://github.com/squid-cache/squid/commit/89f77e43f36bdbd636826c94085f9b5d882e473d,24 Jun 2007,"Bug #1948: digest_edir_auth helper, using novell eDirectory universal password

This is a modified version of digets_ldap_auth, with eDirectory special hooks
for retrieving the Universal Password plain text password.",1874,data/crawl/squid/hunk_4545.cpp,,,data/crawl/squid/old_hunk_4545.cpp,data/crawl/squid/new_hunk_4545.cpp,-1,503,,"fprintf(stderr, PROGRAM_NAME "" ERROR: Unknown search scope '%s'\n"", value);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""PROGRAM_NAME"", ""ERROR"", ""Unknown"", ""search"", ""scope"", ""%s"", ""\\n"", ""value""]]",[-28603462415344214557],7179,475200.0,3
https://github.com/squid-cache/squid/commit/89f77e43f36bdbd636826c94085f9b5d882e473d,24 Jun 2007,"Bug #1948: digest_edir_auth helper, using novell eDirectory universal password

This is a modified version of digets_ldap_auth, with eDirectory special hooks
for retrieving the Universal Password plain text password.",1874,data/crawl/squid/hunk_4545.cpp,,,data/crawl/squid/old_hunk_4545.cpp,data/crawl/squid/new_hunk_4545.cpp,-1,424,,"fprintf(stderr, ""Connected OK\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""Connected"", ""OK\\n""]]",[-22669490430663158658],7178,475200.0,3
https://github.com/squid-cache/squid/commit/89f77e43f36bdbd636826c94085f9b5d882e473d,24 Jun 2007,"Bug #1948: digest_edir_auth helper, using novell eDirectory universal password

This is a modified version of digets_ldap_auth, with eDirectory special hooks
for retrieving the Universal Password plain text password.",1874,data/crawl/squid/hunk_4545.cpp,,,data/crawl/squid/old_hunk_4545.cpp,data/crawl/squid/new_hunk_4545.cpp,-1,418,,"fprintf(stderr, PROGRAM_NAME "" WARNING, could not bind to binddn '%s'\n"", ldap_err2string(rc));","[""addLog""]","[[], [""fprintf"", ""stderr"", ""PROGRAM_NAME"", ""WARNING"", ""could"", ""not"", ""bind"", ""to"", ""binddn"", ""%s"", ""\\n"", ""ldap_err2string"", ""rc""]]",[-2103980923165096312],7177,475200.0,3
https://github.com/squid-cache/squid/commit/89f77e43f36bdbd636826c94085f9b5d882e473d,24 Jun 2007,"Bug #1948: digest_edir_auth helper, using novell eDirectory universal password

This is a modified version of digets_ldap_auth, with eDirectory special hooks
for retrieving the Universal Password plain text password.",1874,data/crawl/squid/hunk_4545.cpp,,,data/crawl/squid/old_hunk_4545.cpp,data/crawl/squid/new_hunk_4545.cpp,-1,318,,"fprintf(stderr, PROGRAM_NAME "" WARNING, LDAP error '%s'\n"", ldap_err2string(rc));","[""addLog""]","[[], [""fprintf"", ""stderr"", ""PROGRAM_NAME"", ""WARNING"", ""LDAP"", ""error"", ""%s"", ""\\n"", ""ldap_err2string"", ""rc""]]",[-6417957942758496167],7176,475200.0,3
https://github.com/squid-cache/squid/commit/89f77e43f36bdbd636826c94085f9b5d882e473d,24 Jun 2007,"Bug #1948: digest_edir_auth helper, using novell eDirectory universal password

This is a modified version of digets_ldap_auth, with eDirectory special hooks
for retrieving the Universal Password plain text password.",1874,data/crawl/squid/hunk_4545.cpp,,,data/crawl/squid/old_hunk_4545.cpp,data/crawl/squid/new_hunk_4545.cpp,-1,306,,"printf(""password: %s\n"", password);","[""addLog""]","[[], [""printf"", ""password"", ""%s\\n"", ""password""]]",[-1032207333545575809],7175,475200.0,3
https://github.com/squid-cache/squid/commit/89f77e43f36bdbd636826c94085f9b5d882e473d,24 Jun 2007,"Bug #1948: digest_edir_auth helper, using novell eDirectory universal password

This is a modified version of digets_ldap_auth, with eDirectory special hooks
for retrieving the Universal Password plain text password.",1874,data/crawl/squid/hunk_4545.cpp,,,data/crawl/squid/old_hunk_4545.cpp,data/crawl/squid/new_hunk_4545.cpp,-1,286,,"printf(""No attribute value found\n"");","[""addLog""]","[[], [""printf"", ""No"", ""attribute"", ""value"", ""found\\n""]]",[-419288586331188282],7174,475200.0,3
https://github.com/squid-cache/squid/commit/89f77e43f36bdbd636826c94085f9b5d882e473d,24 Jun 2007,"Bug #1948: digest_edir_auth helper, using novell eDirectory universal password

This is a modified version of digets_ldap_auth, with eDirectory special hooks
for retrieving the Universal Password plain text password.",1874,data/crawl/squid/hunk_4545.cpp,,,data/crawl/squid/old_hunk_4545.cpp,data/crawl/squid/new_hunk_4545.cpp,-1,252,,"fprintf(stderr, ""searchbase '%s'\n"", searchbase);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""searchbase"", ""%s"", ""\\n"", ""searchbase""]]",[-1316827970557873006],7173,475200.0,3
https://github.com/squid-cache/squid/commit/89f77e43f36bdbd636826c94085f9b5d882e473d,24 Jun 2007,"Bug #1948: digest_edir_auth helper, using novell eDirectory universal password

This is a modified version of digets_ldap_auth, with eDirectory special hooks
for retrieving the Universal Password plain text password.",1874,data/crawl/squid/hunk_4545.cpp,,,data/crawl/squid/old_hunk_4545.cpp,data/crawl/squid/new_hunk_4545.cpp,-1,233,,"fprintf(stderr, PROGRAM_NAME "" WARNING, LDAP search error, trying to recover'%s'\n"", ldap_err2string(rc));","[""addLog""]","[[], [""fprintf"", ""stderr"", ""PROGRAM_NAME"", ""WARNING"", ""LDAP"", ""search"", ""error"", ""trying"", ""to"", ""recover"", ""%s"", ""\\n"", ""ldap_err2string"", ""rc""]]",[-1013475353818831774],7172,475200.0,3
https://github.com/squid-cache/squid/commit/89f77e43f36bdbd636826c94085f9b5d882e473d,24 Jun 2007,"Bug #1948: digest_edir_auth helper, using novell eDirectory universal password

This is a modified version of digets_ldap_auth, with eDirectory special hooks
for retrieving the Universal Password plain text password.",1874,data/crawl/squid/hunk_4545.cpp,,,data/crawl/squid/old_hunk_4545.cpp,data/crawl/squid/new_hunk_4545.cpp,-1,216,,"fprintf(stderr, ""user filter '%s', searchbase '%s'\n"", filter, searchbase);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""user"", ""filter"", ""%s"", ""searchbase"", ""%s"", ""\\n"", ""filter"", ""searchbase""]]",[14902606342050671269],7171,475200.0,3
https://github.com/squid-cache/squid/commit/89f77e43f36bdbd636826c94085f9b5d882e473d,24 Jun 2007,"Bug #1948: digest_edir_auth helper, using novell eDirectory universal password

This is a modified version of digets_ldap_auth, with eDirectory special hooks
for retrieving the Universal Password plain text password.",1874,data/crawl/squid/hunk_4544.cpp,,,data/crawl/squid/old_hunk_4544.cpp,data/crawl/squid/new_hunk_4544.cpp,-1,68,,"printf(""%s\n"", requestData->HHA1);","[""addLog""]","[[], [""printf"", ""%s\\n"", ""requestData"", ""HHA1""]]",[12316829383075309951],7170,1223040.0,3
https://github.com/squid-cache/squid/commit/3e5d7cdf22bea10b5f35fd5881ed2d1724ba88b2,25 Jun 2007,"Author: Markus Moeller <huaraz@moeller.plus.com>
Kerberos SPNEGO helper

Kerberos-only SPNEGO helper using MIT or Heimdal kerberos
and the refrence SPNEGO parser published by Microsoft",6172,data/crawl/squid/hunk_4543.cpp,,,data/crawl/squid/old_hunk_4543.cpp,data/crawl/squid/new_hunk_4543.cpp,-1,271,,"fprintf(stdout, ""NA Invalid request\n"");","[""addLog""]","[[], [""fprintf"", ""stdout"", ""NA"", ""Invalid"", ""request\\n""]]",[-14934979249588640222],7169,0.0,3
https://github.com/squid-cache/squid/commit/ee1394034ae6d0c148944ba013ce2d485b2ea57b,17 Aug 2007,"64-bit disk I/O, using off_t / size_t where appropriate",98,data/crawl/squid/hunk_4486.cpp,,,data/crawl/squid/old_hunk_4486.cpp,data/crawl/squid/new_hunk_4486.cpp,7,7,"fprintf(stderr, ""%d FD %d, offset %d: "", (int) mypid, fs->fd, r->offset);","fprintf(stderr, ""%d FD %d, offset %""PRId64"": "", (int) mypid, fs->fd, (int64_t)r->offset);","[""updateContent"", ""addContent"", ""addVariable""]","[[""%d""], [""%"", ""PRId64"", ""int64_t""]]",[13217465345508381607],7168,0.0,3
https://github.com/squid-cache/squid/commit/cc192b5087ebbd5c214fcacdf26f117e4f15241b,15 Dec 2007,"Import IPv6 support from squid3-ipv6 branch to 3-HEAD.

This patch fully enables squid to handle IPv6 on internally supported
protocols which have IPv6 capability.
see 3.1 Release Notes for full details on the IPv6 changes.
also see squid.conf generated from this point for configuration changes.

TODO: Release-Notes fro 3.1 have yet to be created. The mentioned details
      documentation will come in a later patch.",9997,data/crawl/squid/hunk_4410.cpp,,,data/crawl/squid/old_hunk_4410.cpp,data/crawl/squid/new_hunk_4410.cpp,5,4,"buf.Printf(""X-Client-IP: %s\r\n"", inet_ntoa(request->client_addr));","buf.Printf(""X-Client-IP: %s\r\n"", request->client_addr.NtoA(ntoabuf,MAX_IPSTRLEN));","[""moveVariable"", ""removeVariable"", ""addVariable""]","[[""inet_ntoa""], [""NtoA"", ""ntoabuf"", ""MAX_IPSTRLEN""]]",[-13132999907163937786],7167,0.0,3
https://github.com/squid-cache/squid/commit/cc192b5087ebbd5c214fcacdf26f117e4f15241b,15 Dec 2007,"Import IPv6 support from squid3-ipv6 branch to 3-HEAD.

This patch fully enables squid to handle IPv6 on internally supported
protocols which have IPv6 capability.
see 3.1 Release Notes for full details on the IPv6 changes.
also see squid.conf generated from this point for configuration changes.

TODO: Release-Notes fro 3.1 have yet to be created. The mentioned details
      documentation will come in a later patch.",9997,data/crawl/squid/hunk_4409.cpp,,,data/crawl/squid/old_hunk_4409.cpp,data/crawl/squid/new_hunk_4409.cpp,6,7,"mb.Printf(""%s"", inet_ntoa(ip->addr1));","mb.Printf(""%s"", ip->addr1.NtoA(tmpbuf,MAX_IPSTRLEN));","[""moveVariable"", ""removeVariable"", ""addVariable""]","[[""inet_ntoa""], [""NtoA"", ""tmpbuf"", ""MAX_IPSTRLEN""]]",[-11073456879402284372],7166,0.0,3
https://github.com/squid-cache/squid/commit/154dc8842fca8ee7a35553a44c2fe82fecb3786c,12 Feb 2008,"Importing SslBump feature from Squid3 ssl-bump branch:

        Parse/dump the newly added sslBump http_port option. The option
        does not imply an accelerated port because it only accelerates
        after intercepting a CONNECT request.

        Configure SSL Context if SSL certificate or key are specified
        for an HTTP port.",236,data/crawl/squid/hunk_4380.cpp,,,data/crawl/squid/old_hunk_4380.cpp,data/crawl/squid/new_hunk_4380.cpp,39,-1,"storeAppendPrintf(e, ""\n"");",,"[""removeLog""]","[[""storeAppendPrintf"", ""e"", ""\\n""], []]",[-5193143777301589627],7165,1752480.0,3
https://github.com/squid-cache/squid/commit/dc56a9b1420c7f77b90b5abf111d6cb98cd0d7a1,13 Feb 2008,"Merging async-call branch changes to HEAD:

Async-call work replaces event-based asynchronous calls with
stand-alone implementation. The common async call API allows Squid
core do call, debug, and troubleshoot all callback handlers in a
uniform way.

An async ""job"" API is introduced to manage independent logical threads
or work such as protocol transaction handlers on client, server, and
ICAP sides. These jobs should communicate with each other using async
calls to minimize dependencies and avoid reentrant callback loops.

These changes will eventually improve overall code quality, debugging
quality, and Squid robustness.

Below you will find log messages from the async-call branch that are
relevant to the file(s) being committed.

        Convert the comm_* calls to use CommCalls.

        Use the AsyncJob::deleteThis method as ""delete this""
        replacement instead of the previously commited block ""if
        (inCall) musStop(...) else delete this""

        ICAPInitiate::sendAnswer dialers take care of message locking
        now.",611,data/crawl/squid/hunk_4371.cpp,,,data/crawl/squid/old_hunk_4371.cpp,data/crawl/squid/new_hunk_4371.cpp,33,38,"ftpState->abortTransaction(""entry aborted during control reply read"");","abortTransaction(""entry aborted during control reply read"");","[""addLog"", ""removeLog""]","[[""ftpState""], []]",[-5830271478841260977],7164,0.0,3
https://github.com/squid-cache/squid/commit/3e7b6055489b13ca3faa9eef01b42a74971f84e4,20 Mar 2008,"Importing CVS squid3-ecap branch:

lib/Makefile.am
        Added libLtdl to SUBDIRS if USE_LOADABLE_MODULES.


src/ICAP/ICAPModXact.h
src/ICAP/ICAPServiceRep.h

        When USE_ECAP_AS_ICAP_HACK macro is defined, enable a temporary
        hack that uses ICAP class names to implement some of the eCAP
        classes. This is necessary to hide eCAP/ICAP distinction from
        Squid core. Hiding the distinction is necessary to avoid
        numerous conflicts when this branch is merged with async call
        branch changes.
        
        Once the branches are merged, the hack will be removed. Since
        we currently #define eCAP class names to match those of ICAP
        classes, the changes at that time should not be significant:
        remove renaming #defines and adjust autotools meta files to
        allow both ICAP and eCAP co-exist.



configure.in
src/Makefile.am

        Enable eCAP support if loadable module support is enabled.
        Eventually, we may want to control eCAP support directly.
        
        Added eCAP directory to the Makefile. The eCAP directory
        contents will be committed later.



SPONSORS
        Added eCAP sponsor.


src/Makefile.am
        When eCAP is enabled, to support USE_ECAP_AS_ICAP_HACK, ignore
        ICAP files that eCAP overwrites.


configure.in

        Added --enable-ecap option to control eCAP support explicitly.
        Added consistency checks for the combination of --enable-ecap,
        --enable-icap-client, and --disable-loadable-modules options.
        
        Define USE_ECAP_AS_ICAP_HACK macro to enable a temporary hack
        that uses ICAP class names to implement some of the eCAP
        classes. This is necessary to hide eCAP/ICAP distinction from
        Squid core. Hiding the distinction is necessary to avoid
        numerous conflicts when this branch is merged with async call
        branch changes.
        
        Once the branches are merged, the hack will be removed. Since
        we currently #define eCAP class names to match those of ICAP
        classes, the changes at that time should not be significant:
        remove renaming #defines and adjust autotools meta files to
        allow both ICAP and eCAP co-exist.



Makefile.am
acinclude.m4
bootstrap.sh
configure.in
src/Makefile.am

        Added basic support for Libtool ltdl. Libltdl directory is not
        committed yet because I want to investigate whether it can be
        moved from root to lib/. Bootstrap.sh currently strips a large
        copying file from that directory but does not attempt to move
        the directory itself.
        
        The configure options will need to be changed according to
        squid-dev discussion: we should assume that ltdl is always used
        if modules are used, and we should have a --disable-modules
        option.
        
        The code works with a dummy module: Squid was able to load and
        unload using LoadableModule, an ltdl wrapper class from Spicer.
        I have not committed that wrapper yet.

Makefile.am
bootstrap.sh
configure.in
src/Makefile.am

        Moved Libtool libltdl directory to lib/libLtdl to keep all
        3rd-party libs in one place. Will commit the lib/libLtdl
        directory itself soon.
        
        Bootstrap.sh currently moves all files from the generated
        libltdl into lib/libLtdl. A better approach may be to use the
        --ltdl option of libtoolize. Will investigate.
        
        Changed configure options to assume that ltdl is always used if
        modules are used.",48970,data/crawl/squid/hunk_4347.cpp,,,data/crawl/squid/old_hunk_4347.cpp,data/crawl/squid/new_hunk_4347.cpp,-1,1365,,"printf (""vax-dec-bsd4.3reno\n"");","[""addLog""]","[[], [""printf"", ""vax"", ""dec"", ""bsd4"", ""3reno\\n""]]",[6715825018866626433],7163,1137600.0,3
https://github.com/squid-cache/squid/commit/3e7b6055489b13ca3faa9eef01b42a74971f84e4,20 Mar 2008,"Importing CVS squid3-ecap branch:

lib/Makefile.am
        Added libLtdl to SUBDIRS if USE_LOADABLE_MODULES.


src/ICAP/ICAPModXact.h
src/ICAP/ICAPServiceRep.h

        When USE_ECAP_AS_ICAP_HACK macro is defined, enable a temporary
        hack that uses ICAP class names to implement some of the eCAP
        classes. This is necessary to hide eCAP/ICAP distinction from
        Squid core. Hiding the distinction is necessary to avoid
        numerous conflicts when this branch is merged with async call
        branch changes.
        
        Once the branches are merged, the hack will be removed. Since
        we currently #define eCAP class names to match those of ICAP
        classes, the changes at that time should not be significant:
        remove renaming #defines and adjust autotools meta files to
        allow both ICAP and eCAP co-exist.



configure.in
src/Makefile.am

        Enable eCAP support if loadable module support is enabled.
        Eventually, we may want to control eCAP support directly.
        
        Added eCAP directory to the Makefile. The eCAP directory
        contents will be committed later.



SPONSORS
        Added eCAP sponsor.


src/Makefile.am
        When eCAP is enabled, to support USE_ECAP_AS_ICAP_HACK, ignore
        ICAP files that eCAP overwrites.


configure.in

        Added --enable-ecap option to control eCAP support explicitly.
        Added consistency checks for the combination of --enable-ecap,
        --enable-icap-client, and --disable-loadable-modules options.
        
        Define USE_ECAP_AS_ICAP_HACK macro to enable a temporary hack
        that uses ICAP class names to implement some of the eCAP
        classes. This is necessary to hide eCAP/ICAP distinction from
        Squid core. Hiding the distinction is necessary to avoid
        numerous conflicts when this branch is merged with async call
        branch changes.
        
        Once the branches are merged, the hack will be removed. Since
        we currently #define eCAP class names to match those of ICAP
        classes, the changes at that time should not be significant:
        remove renaming #defines and adjust autotools meta files to
        allow both ICAP and eCAP co-exist.



Makefile.am
acinclude.m4
bootstrap.sh
configure.in
src/Makefile.am

        Added basic support for Libtool ltdl. Libltdl directory is not
        committed yet because I want to investigate whether it can be
        moved from root to lib/. Bootstrap.sh currently strips a large
        copying file from that directory but does not attempt to move
        the directory itself.
        
        The configure options will need to be changed according to
        squid-dev discussion: we should assume that ltdl is always used
        if modules are used, and we should have a --disable-modules
        option.
        
        The code works with a dummy module: Squid was able to load and
        unload using LoadableModule, an ltdl wrapper class from Spicer.
        I have not committed that wrapper yet.

Makefile.am
bootstrap.sh
configure.in
src/Makefile.am

        Moved Libtool libltdl directory to lib/libLtdl to keep all
        3rd-party libs in one place. Will commit the lib/libLtdl
        directory itself soon.
        
        Bootstrap.sh currently moves all files from the generated
        libltdl into lib/libLtdl. A better approach may be to use the
        --ltdl option of libtoolize. Will investigate.
        
        Changed configure options to assume that ltdl is always used if
        modules are used.",48970,data/crawl/squid/hunk_4347.cpp,,,data/crawl/squid/old_hunk_4347.cpp,data/crawl/squid/new_hunk_4347.cpp,-1,1362,,"printf (""vax-dec-bsd4.3\n"");","[""addLog""]","[[], [""printf"", ""vax"", ""dec"", ""bsd4"", ""3\\n""]]",[795344038673301191],7162,1137600.0,3
https://github.com/squid-cache/squid/commit/3e7b6055489b13ca3faa9eef01b42a74971f84e4,20 Mar 2008,"Importing CVS squid3-ecap branch:

lib/Makefile.am
        Added libLtdl to SUBDIRS if USE_LOADABLE_MODULES.


src/ICAP/ICAPModXact.h
src/ICAP/ICAPServiceRep.h

        When USE_ECAP_AS_ICAP_HACK macro is defined, enable a temporary
        hack that uses ICAP class names to implement some of the eCAP
        classes. This is necessary to hide eCAP/ICAP distinction from
        Squid core. Hiding the distinction is necessary to avoid
        numerous conflicts when this branch is merged with async call
        branch changes.
        
        Once the branches are merged, the hack will be removed. Since
        we currently #define eCAP class names to match those of ICAP
        classes, the changes at that time should not be significant:
        remove renaming #defines and adjust autotools meta files to
        allow both ICAP and eCAP co-exist.



configure.in
src/Makefile.am

        Enable eCAP support if loadable module support is enabled.
        Eventually, we may want to control eCAP support directly.
        
        Added eCAP directory to the Makefile. The eCAP directory
        contents will be committed later.



SPONSORS
        Added eCAP sponsor.


src/Makefile.am
        When eCAP is enabled, to support USE_ECAP_AS_ICAP_HACK, ignore
        ICAP files that eCAP overwrites.


configure.in

        Added --enable-ecap option to control eCAP support explicitly.
        Added consistency checks for the combination of --enable-ecap,
        --enable-icap-client, and --disable-loadable-modules options.
        
        Define USE_ECAP_AS_ICAP_HACK macro to enable a temporary hack
        that uses ICAP class names to implement some of the eCAP
        classes. This is necessary to hide eCAP/ICAP distinction from
        Squid core. Hiding the distinction is necessary to avoid
        numerous conflicts when this branch is merged with async call
        branch changes.
        
        Once the branches are merged, the hack will be removed. Since
        we currently #define eCAP class names to match those of ICAP
        classes, the changes at that time should not be significant:
        remove renaming #defines and adjust autotools meta files to
        allow both ICAP and eCAP co-exist.



Makefile.am
acinclude.m4
bootstrap.sh
configure.in
src/Makefile.am

        Added basic support for Libtool ltdl. Libltdl directory is not
        committed yet because I want to investigate whether it can be
        moved from root to lib/. Bootstrap.sh currently strips a large
        copying file from that directory but does not attempt to move
        the directory itself.
        
        The configure options will need to be changed according to
        squid-dev discussion: we should assume that ltdl is always used
        if modules are used, and we should have a --disable-modules
        option.
        
        The code works with a dummy module: Squid was able to load and
        unload using LoadableModule, an ltdl wrapper class from Spicer.
        I have not committed that wrapper yet.

Makefile.am
bootstrap.sh
configure.in
src/Makefile.am

        Moved Libtool libltdl directory to lib/libLtdl to keep all
        3rd-party libs in one place. Will commit the lib/libLtdl
        directory itself soon.
        
        Bootstrap.sh currently moves all files from the generated
        libltdl into lib/libLtdl. A better approach may be to use the
        --ltdl option of libtoolize. Will investigate.
        
        Changed configure options to assume that ltdl is always used if
        modules are used.",48970,data/crawl/squid/hunk_4347.cpp,,,data/crawl/squid/old_hunk_4347.cpp,data/crawl/squid/new_hunk_4347.cpp,-1,1313,,"printf (""%s-next-openstep%d\n"", __ARCHITECTURE__, version);","[""addLog""]","[[], [""printf"", ""%s"", ""next"", ""openstep%d\\n"", ""__ARCHITECTURE__"", ""version""]]",[1854032569697081307],7161,1137600.0,3
https://github.com/squid-cache/squid/commit/3e7b6055489b13ca3faa9eef01b42a74971f84e4,20 Mar 2008,"Importing CVS squid3-ecap branch:

lib/Makefile.am
        Added libLtdl to SUBDIRS if USE_LOADABLE_MODULES.


src/ICAP/ICAPModXact.h
src/ICAP/ICAPServiceRep.h

        When USE_ECAP_AS_ICAP_HACK macro is defined, enable a temporary
        hack that uses ICAP class names to implement some of the eCAP
        classes. This is necessary to hide eCAP/ICAP distinction from
        Squid core. Hiding the distinction is necessary to avoid
        numerous conflicts when this branch is merged with async call
        branch changes.
        
        Once the branches are merged, the hack will be removed. Since
        we currently #define eCAP class names to match those of ICAP
        classes, the changes at that time should not be significant:
        remove renaming #defines and adjust autotools meta files to
        allow both ICAP and eCAP co-exist.



configure.in
src/Makefile.am

        Enable eCAP support if loadable module support is enabled.
        Eventually, we may want to control eCAP support directly.
        
        Added eCAP directory to the Makefile. The eCAP directory
        contents will be committed later.



SPONSORS
        Added eCAP sponsor.


src/Makefile.am
        When eCAP is enabled, to support USE_ECAP_AS_ICAP_HACK, ignore
        ICAP files that eCAP overwrites.


configure.in

        Added --enable-ecap option to control eCAP support explicitly.
        Added consistency checks for the combination of --enable-ecap,
        --enable-icap-client, and --disable-loadable-modules options.
        
        Define USE_ECAP_AS_ICAP_HACK macro to enable a temporary hack
        that uses ICAP class names to implement some of the eCAP
        classes. This is necessary to hide eCAP/ICAP distinction from
        Squid core. Hiding the distinction is necessary to avoid
        numerous conflicts when this branch is merged with async call
        branch changes.
        
        Once the branches are merged, the hack will be removed. Since
        we currently #define eCAP class names to match those of ICAP
        classes, the changes at that time should not be significant:
        remove renaming #defines and adjust autotools meta files to
        allow both ICAP and eCAP co-exist.



Makefile.am
acinclude.m4
bootstrap.sh
configure.in
src/Makefile.am

        Added basic support for Libtool ltdl. Libltdl directory is not
        committed yet because I want to investigate whether it can be
        moved from root to lib/. Bootstrap.sh currently strips a large
        copying file from that directory but does not attempt to move
        the directory itself.
        
        The configure options will need to be changed according to
        squid-dev discussion: we should assume that ltdl is always used
        if modules are used, and we should have a --disable-modules
        option.
        
        The code works with a dummy module: Squid was able to load and
        unload using LoadableModule, an ltdl wrapper class from Spicer.
        I have not committed that wrapper yet.

Makefile.am
bootstrap.sh
configure.in
src/Makefile.am

        Moved Libtool libltdl directory to lib/libLtdl to keep all
        3rd-party libs in one place. Will commit the lib/libLtdl
        directory itself soon.
        
        Bootstrap.sh currently moves all files from the generated
        libltdl into lib/libLtdl. A better approach may be to use the
        --ltdl option of libtoolize. Will investigate.
        
        Changed configure options to assume that ltdl is always used if
        modules are used.",48970,data/crawl/squid/hunk_4347.cpp,,,data/crawl/squid/old_hunk_4347.cpp,data/crawl/squid/new_hunk_4347.cpp,-1,608,,"puts (""hppa2.0n"");","[""addLog""]","[[], [""puts"", ""hppa2"", ""0n""]]",[2435868555031571550],7160,1137600.0,3
https://github.com/squid-cache/squid/commit/3e7b6055489b13ca3faa9eef01b42a74971f84e4,20 Mar 2008,"Importing CVS squid3-ecap branch:

lib/Makefile.am
        Added libLtdl to SUBDIRS if USE_LOADABLE_MODULES.


src/ICAP/ICAPModXact.h
src/ICAP/ICAPServiceRep.h

        When USE_ECAP_AS_ICAP_HACK macro is defined, enable a temporary
        hack that uses ICAP class names to implement some of the eCAP
        classes. This is necessary to hide eCAP/ICAP distinction from
        Squid core. Hiding the distinction is necessary to avoid
        numerous conflicts when this branch is merged with async call
        branch changes.
        
        Once the branches are merged, the hack will be removed. Since
        we currently #define eCAP class names to match those of ICAP
        classes, the changes at that time should not be significant:
        remove renaming #defines and adjust autotools meta files to
        allow both ICAP and eCAP co-exist.



configure.in
src/Makefile.am

        Enable eCAP support if loadable module support is enabled.
        Eventually, we may want to control eCAP support directly.
        
        Added eCAP directory to the Makefile. The eCAP directory
        contents will be committed later.



SPONSORS
        Added eCAP sponsor.


src/Makefile.am
        When eCAP is enabled, to support USE_ECAP_AS_ICAP_HACK, ignore
        ICAP files that eCAP overwrites.


configure.in

        Added --enable-ecap option to control eCAP support explicitly.
        Added consistency checks for the combination of --enable-ecap,
        --enable-icap-client, and --disable-loadable-modules options.
        
        Define USE_ECAP_AS_ICAP_HACK macro to enable a temporary hack
        that uses ICAP class names to implement some of the eCAP
        classes. This is necessary to hide eCAP/ICAP distinction from
        Squid core. Hiding the distinction is necessary to avoid
        numerous conflicts when this branch is merged with async call
        branch changes.
        
        Once the branches are merged, the hack will be removed. Since
        we currently #define eCAP class names to match those of ICAP
        classes, the changes at that time should not be significant:
        remove renaming #defines and adjust autotools meta files to
        allow both ICAP and eCAP co-exist.



Makefile.am
acinclude.m4
bootstrap.sh
configure.in
src/Makefile.am

        Added basic support for Libtool ltdl. Libltdl directory is not
        committed yet because I want to investigate whether it can be
        moved from root to lib/. Bootstrap.sh currently strips a large
        copying file from that directory but does not attempt to move
        the directory itself.
        
        The configure options will need to be changed according to
        squid-dev discussion: we should assume that ltdl is always used
        if modules are used, and we should have a --disable-modules
        option.
        
        The code works with a dummy module: Squid was able to load and
        unload using LoadableModule, an ltdl wrapper class from Spicer.
        I have not committed that wrapper yet.

Makefile.am
bootstrap.sh
configure.in
src/Makefile.am

        Moved Libtool libltdl directory to lib/libLtdl to keep all
        3rd-party libs in one place. Will commit the lib/libLtdl
        directory itself soon.
        
        Bootstrap.sh currently moves all files from the generated
        libltdl into lib/libLtdl. A better approach may be to use the
        --ltdl option of libtoolize. Will investigate.
        
        Changed configure options to assume that ltdl is always used if
        modules are used.",48970,data/crawl/squid/hunk_4347.cpp,,,data/crawl/squid/old_hunk_4347.cpp,data/crawl/squid/new_hunk_4347.cpp,-1,607,,"puts (""hppa2.0w"");","[""addLog""]","[[], [""puts"", ""hppa2"", ""0w""]]",[2435868555031571527],7159,1137600.0,3
https://github.com/squid-cache/squid/commit/3e7b6055489b13ca3faa9eef01b42a74971f84e4,20 Mar 2008,"Importing CVS squid3-ecap branch:

lib/Makefile.am
        Added libLtdl to SUBDIRS if USE_LOADABLE_MODULES.


src/ICAP/ICAPModXact.h
src/ICAP/ICAPServiceRep.h

        When USE_ECAP_AS_ICAP_HACK macro is defined, enable a temporary
        hack that uses ICAP class names to implement some of the eCAP
        classes. This is necessary to hide eCAP/ICAP distinction from
        Squid core. Hiding the distinction is necessary to avoid
        numerous conflicts when this branch is merged with async call
        branch changes.
        
        Once the branches are merged, the hack will be removed. Since
        we currently #define eCAP class names to match those of ICAP
        classes, the changes at that time should not be significant:
        remove renaming #defines and adjust autotools meta files to
        allow both ICAP and eCAP co-exist.



configure.in
src/Makefile.am

        Enable eCAP support if loadable module support is enabled.
        Eventually, we may want to control eCAP support directly.
        
        Added eCAP directory to the Makefile. The eCAP directory
        contents will be committed later.



SPONSORS
        Added eCAP sponsor.


src/Makefile.am
        When eCAP is enabled, to support USE_ECAP_AS_ICAP_HACK, ignore
        ICAP files that eCAP overwrites.


configure.in

        Added --enable-ecap option to control eCAP support explicitly.
        Added consistency checks for the combination of --enable-ecap,
        --enable-icap-client, and --disable-loadable-modules options.
        
        Define USE_ECAP_AS_ICAP_HACK macro to enable a temporary hack
        that uses ICAP class names to implement some of the eCAP
        classes. This is necessary to hide eCAP/ICAP distinction from
        Squid core. Hiding the distinction is necessary to avoid
        numerous conflicts when this branch is merged with async call
        branch changes.
        
        Once the branches are merged, the hack will be removed. Since
        we currently #define eCAP class names to match those of ICAP
        classes, the changes at that time should not be significant:
        remove renaming #defines and adjust autotools meta files to
        allow both ICAP and eCAP co-exist.



Makefile.am
acinclude.m4
bootstrap.sh
configure.in
src/Makefile.am

        Added basic support for Libtool ltdl. Libltdl directory is not
        committed yet because I want to investigate whether it can be
        moved from root to lib/. Bootstrap.sh currently strips a large
        copying file from that directory but does not attempt to move
        the directory itself.
        
        The configure options will need to be changed according to
        squid-dev discussion: we should assume that ltdl is always used
        if modules are used, and we should have a --disable-modules
        option.
        
        The code works with a dummy module: Squid was able to load and
        unload using LoadableModule, an ltdl wrapper class from Spicer.
        I have not committed that wrapper yet.

Makefile.am
bootstrap.sh
configure.in
src/Makefile.am

        Moved Libtool libltdl directory to lib/libLtdl to keep all
        3rd-party libs in one place. Will commit the lib/libLtdl
        directory itself soon.
        
        Bootstrap.sh currently moves all files from the generated
        libltdl into lib/libLtdl. A better approach may be to use the
        --ltdl option of libtoolize. Will investigate.
        
        Changed configure options to assume that ltdl is always used if
        modules are used.",48970,data/crawl/squid/hunk_4347.cpp,,,data/crawl/squid/old_hunk_4347.cpp,data/crawl/squid/new_hunk_4347.cpp,-1,602,,"puts (""hppa1.1"");","[""addLog""]","[[], [""puts"", ""hppa1"", ""1""]]",[2429724524391534869],7158,1137600.0,3
https://github.com/squid-cache/squid/commit/ed08b88c5e248d7683016e4fba2d59b9d561e70f,03 Apr 2008,"Ignore and do not version lib/libLtdl because it is libtool-generated.
Ignore cfgaux because it is libtool-generated (merged from trunk).",23843,data/crawl/squid/hunk_4331.cpp,,,data/crawl/squid/old_hunk_4331.cpp,data/crawl/squid/new_hunk_4331.cpp,1323,-1,"printf (""i860-alliant-bsd\n"");",,"[""removeLog""]","[[""printf"", ""i860"", ""alliant"", ""bsd\\n""], []]",[-15258442327341906774],7157,336960.0,3
https://github.com/squid-cache/squid/commit/ed08b88c5e248d7683016e4fba2d59b9d561e70f,03 Apr 2008,"Ignore and do not version lib/libLtdl because it is libtool-generated.
Ignore cfgaux because it is libtool-generated (merged from trunk).",23843,data/crawl/squid/hunk_4331.cpp,,,data/crawl/squid/old_hunk_4331.cpp,data/crawl/squid/new_hunk_4331.cpp,1318,-1,"printf (""vax-dec-ultrix\n"");",,"[""removeLog""]","[[""printf"", ""vax"", ""dec"", ""ultrix\\n""], []]",[-3771227756932470676],7156,336960.0,3
https://github.com/squid-cache/squid/commit/ed08b88c5e248d7683016e4fba2d59b9d561e70f,03 Apr 2008,"Ignore and do not version lib/libLtdl because it is libtool-generated.
Ignore cfgaux because it is libtool-generated (merged from trunk).",23843,data/crawl/squid/hunk_4331.cpp,,,data/crawl/squid/old_hunk_4331.cpp,data/crawl/squid/new_hunk_4331.cpp,1309,-1,"printf (""vax-dec-bsd4.3reno\n"");",,"[""removeLog""]","[[""printf"", ""vax"", ""dec"", ""bsd4"", ""3reno\\n""], []]",[-6715825018866626433],7155,336960.0,3
https://github.com/squid-cache/squid/commit/ed08b88c5e248d7683016e4fba2d59b9d561e70f,03 Apr 2008,"Ignore and do not version lib/libLtdl because it is libtool-generated.
Ignore cfgaux because it is libtool-generated (merged from trunk).",23843,data/crawl/squid/hunk_4331.cpp,,,data/crawl/squid/old_hunk_4331.cpp,data/crawl/squid/new_hunk_4331.cpp,1306,-1,"printf (""vax-dec-bsd4.3\n"");",,"[""removeLog""]","[[""printf"", ""vax"", ""dec"", ""bsd4"", ""3\\n""], []]",[-795344038673301191],7154,336960.0,3
https://github.com/squid-cache/squid/commit/ed08b88c5e248d7683016e4fba2d59b9d561e70f,03 Apr 2008,"Ignore and do not version lib/libLtdl because it is libtool-generated.
Ignore cfgaux because it is libtool-generated (merged from trunk).",23843,data/crawl/squid/hunk_4331.cpp,,,data/crawl/squid/old_hunk_4331.cpp,data/crawl/squid/new_hunk_4331.cpp,1297,-1,"printf (""i386-sequent-ptx\n"");",,"[""removeLog""]","[[""printf"", ""i386"", ""sequent"", ""ptx\\n""], []]",[2966281485289467054],7153,336960.0,3
https://github.com/squid-cache/squid/commit/ed08b88c5e248d7683016e4fba2d59b9d561e70f,03 Apr 2008,"Ignore and do not version lib/libLtdl because it is libtool-generated.
Ignore cfgaux because it is libtool-generated (merged from trunk).",23843,data/crawl/squid/hunk_4331.cpp,,,data/crawl/squid/old_hunk_4331.cpp,data/crawl/squid/new_hunk_4331.cpp,1295,-1,"printf (""i386-sequent-ptx1\n"");",,"[""removeLog""]","[[""printf"", ""i386"", ""sequent"", ""ptx1\\n""], []]",[6392863029535456224],7152,336960.0,3
https://github.com/squid-cache/squid/commit/ed08b88c5e248d7683016e4fba2d59b9d561e70f,03 Apr 2008,"Ignore and do not version lib/libLtdl because it is libtool-generated.
Ignore cfgaux because it is libtool-generated (merged from trunk).",23843,data/crawl/squid/hunk_4331.cpp,,,data/crawl/squid/old_hunk_4331.cpp,data/crawl/squid/new_hunk_4331.cpp,1292,-1,"printf (""i386-sequent-ptx2\n"");",,"[""removeLog""]","[[""printf"", ""i386"", ""sequent"", ""ptx2\\n""], []]",[6392862029409455855],7151,336960.0,3
https://github.com/squid-cache/squid/commit/ed08b88c5e248d7683016e4fba2d59b9d561e70f,03 Apr 2008,"Ignore and do not version lib/libLtdl because it is libtool-generated.
Ignore cfgaux because it is libtool-generated (merged from trunk).",23843,data/crawl/squid/hunk_4331.cpp,,,data/crawl/squid/old_hunk_4331.cpp,data/crawl/squid/new_hunk_4331.cpp,1282,-1,"printf (""ns32k-sequent-dynix\n"");",,"[""removeLog""]","[[""printf"", ""ns32k"", ""sequent"", ""dynix\\n""], []]",[-17209887179899307144],7150,336960.0,3
https://github.com/squid-cache/squid/commit/ed08b88c5e248d7683016e4fba2d59b9d561e70f,03 Apr 2008,"Ignore and do not version lib/libLtdl because it is libtool-generated.
Ignore cfgaux because it is libtool-generated (merged from trunk).",23843,data/crawl/squid/hunk_4331.cpp,,,data/crawl/squid/old_hunk_4331.cpp,data/crawl/squid/new_hunk_4331.cpp,1279,-1,"printf (""i386-sequent-dynix\n"");",,"[""removeLog""]","[[""printf"", ""i386"", ""sequent"", ""dynix\\n""], []]",[-3173292423511830362],7149,336960.0,3
https://github.com/squid-cache/squid/commit/ed08b88c5e248d7683016e4fba2d59b9d561e70f,03 Apr 2008,"Ignore and do not version lib/libLtdl because it is libtool-generated.
Ignore cfgaux because it is libtool-generated (merged from trunk).",23843,data/crawl/squid/hunk_4331.cpp,,,data/crawl/squid/old_hunk_4331.cpp,data/crawl/squid/new_hunk_4331.cpp,1274,-1,"printf (""i386-pc-bsd\n"");",,"[""removeLog""]","[[""printf"", ""i386"", ""pc"", ""bsd\\n""], []]",[-6236355447578103142],7148,336960.0,3
https://github.com/squid-cache/squid/commit/ed08b88c5e248d7683016e4fba2d59b9d561e70f,03 Apr 2008,"Ignore and do not version lib/libLtdl because it is libtool-generated.
Ignore cfgaux because it is libtool-generated (merged from trunk).",23843,data/crawl/squid/hunk_4331.cpp,,,data/crawl/squid/old_hunk_4331.cpp,data/crawl/squid/new_hunk_4331.cpp,1268,-1,"printf (""ns32k-encore-bsd\n"");",,"[""removeLog""]","[[""printf"", ""ns32k"", ""encore"", ""bsd\\n""], []]",[-24666701257148115169],7147,336960.0,3
https://github.com/squid-cache/squid/commit/ed08b88c5e248d7683016e4fba2d59b9d561e70f,03 Apr 2008,"Ignore and do not version lib/libLtdl because it is libtool-generated.
Ignore cfgaux because it is libtool-generated (merged from trunk).",23843,data/crawl/squid/hunk_4331.cpp,,,data/crawl/squid/old_hunk_4331.cpp,data/crawl/squid/new_hunk_4331.cpp,1266,-1,"printf (""ns32k-encore-mach\n"");",,"[""removeLog""]","[[""printf"", ""ns32k"", ""encore"", ""mach\\n""], []]",[-20799389516449904868],7146,336960.0,3
https://github.com/squid-cache/squid/commit/ed08b88c5e248d7683016e4fba2d59b9d561e70f,03 Apr 2008,"Ignore and do not version lib/libLtdl because it is libtool-generated.
Ignore cfgaux because it is libtool-generated (merged from trunk).",23843,data/crawl/squid/hunk_4331.cpp,,,data/crawl/squid/old_hunk_4331.cpp,data/crawl/squid/new_hunk_4331.cpp,1263,-1,"printf (""ns32k-encore-sysv\n"");",,"[""removeLog""]","[[""printf"", ""ns32k"", ""encore"", ""sysv\\n""], []]",[-27225681863095121744],7145,336960.0,3
https://github.com/squid-cache/squid/commit/ed08b88c5e248d7683016e4fba2d59b9d561e70f,03 Apr 2008,"Ignore and do not version lib/libLtdl because it is libtool-generated.
Ignore cfgaux because it is libtool-generated (merged from trunk).",23843,data/crawl/squid/hunk_4331.cpp,,,data/crawl/squid/old_hunk_4331.cpp,data/crawl/squid/new_hunk_4331.cpp,1257,-1,"printf (""%s-next-openstep%d\n"", __ARCHITECTURE__, version);",,"[""removeLog""]","[[""printf"", ""%s"", ""next"", ""openstep%d\\n"", ""__ARCHITECTURE__"", ""version""], []]",[-1854032569697081307],7144,336960.0,3
https://github.com/squid-cache/squid/commit/ed08b88c5e248d7683016e4fba2d59b9d561e70f,03 Apr 2008,"Ignore and do not version lib/libLtdl because it is libtool-generated.
Ignore cfgaux because it is libtool-generated (merged from trunk).",23843,data/crawl/squid/hunk_4331.cpp,,,data/crawl/squid/old_hunk_4331.cpp,data/crawl/squid/new_hunk_4331.cpp,1255,-1,"printf (""%s-next-nextstep%d\n"", __ARCHITECTURE__, version);",,"[""removeLog""]","[[""printf"", ""%s"", ""next"", ""nextstep%d\\n"", ""__ARCHITECTURE__"", ""version""], []]",[-8971082284214367716],7143,336960.0,3
https://github.com/squid-cache/squid/commit/ed08b88c5e248d7683016e4fba2d59b9d561e70f,03 Apr 2008,"Ignore and do not version lib/libLtdl because it is libtool-generated.
Ignore cfgaux because it is libtool-generated (merged from trunk).",23843,data/crawl/squid/hunk_4331.cpp,,,data/crawl/squid/old_hunk_4331.cpp,data/crawl/squid/new_hunk_4331.cpp,1245,-1,"printf (""m68k-hp-bsd\n"");",,"[""removeLog""]","[[""printf"", ""m68k"", ""hp"", ""bsd\\n""], []]",[-4406936890319637595],7142,336960.0,3
https://github.com/squid-cache/squid/commit/ed08b88c5e248d7683016e4fba2d59b9d561e70f,03 Apr 2008,"Ignore and do not version lib/libLtdl because it is libtool-generated.
Ignore cfgaux because it is libtool-generated (merged from trunk).",23843,data/crawl/squid/hunk_4331.cpp,,,data/crawl/squid/old_hunk_4331.cpp,data/crawl/squid/new_hunk_4331.cpp,1241,-1,"printf (""arm-acorn-riscix"");",,"[""removeLog""]","[[""printf"", ""arm"", ""acorn"", ""riscix""], []]",[-9551449641104062770],7141,336960.0,3
https://github.com/squid-cache/squid/commit/ed08b88c5e248d7683016e4fba2d59b9d561e70f,03 Apr 2008,"Ignore and do not version lib/libLtdl because it is libtool-generated.
Ignore cfgaux because it is libtool-generated (merged from trunk).",23843,data/crawl/squid/hunk_4331.cpp,,,data/crawl/squid/old_hunk_4331.cpp,data/crawl/squid/new_hunk_4331.cpp,1230,-1,"printf (""m68k-sony-newsos%s\n"",
#ifdef NEWSOS4
          ""4""
#else
	  """"
#endif
         );",,"[""removeLog""]","[[""printf"", ""m68k"", ""sony"", ""newsos%s\\n"", ""ifdef"", ""NEWSOS4"", ""4"", ""else"", ""endif""], []]",[11037806279510753175],7140,336960.0,3
https://github.com/squid-cache/squid/commit/ed08b88c5e248d7683016e4fba2d59b9d561e70f,03 Apr 2008,"Ignore and do not version lib/libLtdl because it is libtool-generated.
Ignore cfgaux because it is libtool-generated (merged from trunk).",23843,data/crawl/squid/hunk_4331.cpp,,,data/crawl/squid/old_hunk_4331.cpp,data/crawl/squid/new_hunk_4331.cpp,1227,-1,exit (0);,,"[""removeLog""]","[[""exit"", ""0""], []]",[4664224508366039323],7139,336960.0,3
https://github.com/squid-cache/squid/commit/ed08b88c5e248d7683016e4fba2d59b9d561e70f,03 Apr 2008,"Ignore and do not version lib/libLtdl because it is libtool-generated.
Ignore cfgaux because it is libtool-generated (merged from trunk).",23843,data/crawl/squid/hunk_4331.cpp,,,data/crawl/squid/old_hunk_4331.cpp,data/crawl/squid/new_hunk_4331.cpp,667,-1,"puts (""unknown-hitachi-hiuxwe2"");",,"[""removeLog""]","[[""puts"", ""unknown"", ""hitachi"", ""hiuxwe2""], []]",[-16275653397761100143],7138,336960.0,3
https://github.com/squid-cache/squid/commit/ed08b88c5e248d7683016e4fba2d59b9d561e70f,03 Apr 2008,"Ignore and do not version lib/libLtdl because it is libtool-generated.
Ignore cfgaux because it is libtool-generated (merged from trunk).",23843,data/crawl/squid/hunk_4331.cpp,,,data/crawl/squid/old_hunk_4331.cpp,data/crawl/squid/new_hunk_4331.cpp,666,-1,"puts (""m68k-hitachi-hiuxwe2"");",,"[""removeLog""]","[[""puts"", ""m68k"", ""hitachi"", ""hiuxwe2""], []]",[-12535257479151834420],7137,336960.0,3
https://github.com/squid-cache/squid/commit/ed08b88c5e248d7683016e4fba2d59b9d561e70f,03 Apr 2008,"Ignore and do not version lib/libLtdl because it is libtool-generated.
Ignore cfgaux because it is libtool-generated (merged from trunk).",23843,data/crawl/squid/hunk_4331.cpp,,,data/crawl/squid/old_hunk_4331.cpp,data/crawl/squid/new_hunk_4331.cpp,662,-1,"puts (""hppa-hitachi-hiuxwe2"");",,"[""removeLog""]","[[""puts"", ""hppa"", ""hitachi"", ""hiuxwe2""], []]",[-28655898973806569187],7136,336960.0,3
https://github.com/squid-cache/squid/commit/ed08b88c5e248d7683016e4fba2d59b9d561e70f,03 Apr 2008,"Ignore and do not version lib/libLtdl because it is libtool-generated.
Ignore cfgaux because it is libtool-generated (merged from trunk).",23843,data/crawl/squid/hunk_4331.cpp,,,data/crawl/squid/old_hunk_4331.cpp,data/crawl/squid/new_hunk_4331.cpp,661,-1,"puts (""hppa2.0-hitachi-hiuxwe2"");",,"[""removeLog""]","[[""puts"", ""hppa2"", ""0"", ""hitachi"", ""hiuxwe2""], []]",[-19143513846723492019],7135,336960.0,3
https://github.com/squid-cache/squid/commit/ed08b88c5e248d7683016e4fba2d59b9d561e70f,03 Apr 2008,"Ignore and do not version lib/libLtdl because it is libtool-generated.
Ignore cfgaux because it is libtool-generated (merged from trunk).",23843,data/crawl/squid/hunk_4331.cpp,,,data/crawl/squid/old_hunk_4331.cpp,data/crawl/squid/new_hunk_4331.cpp,660,-1,"puts (""hppa1.1-hitachi-hiuxwe2"");",,"[""removeLog""]","[[""puts"", ""hppa1"", ""1"", ""hitachi"", ""hiuxwe2""], []]",[-19143513846851492405],7134,336960.0,3
https://github.com/squid-cache/squid/commit/ed08b88c5e248d7683016e4fba2d59b9d561e70f,03 Apr 2008,"Ignore and do not version lib/libLtdl because it is libtool-generated.
Ignore cfgaux because it is libtool-generated (merged from trunk).",23843,data/crawl/squid/hunk_4331.cpp,,,data/crawl/squid/old_hunk_4331.cpp,data/crawl/squid/new_hunk_4331.cpp,659,-1,"puts (""hppa1.0-hitachi-hiuxwe2"");",,"[""removeLog""]","[[""puts"", ""hppa1"", ""0"", ""hitachi"", ""hiuxwe2""], []]",[-19143513846723492022],7133,336960.0,3
https://github.com/squid-cache/squid/commit/ed08b88c5e248d7683016e4fba2d59b9d561e70f,03 Apr 2008,"Ignore and do not version lib/libLtdl because it is libtool-generated.
Ignore cfgaux because it is libtool-generated (merged from trunk).",23843,data/crawl/squid/hunk_4331.cpp,,,data/crawl/squid/old_hunk_4331.cpp,data/crawl/squid/new_hunk_4331.cpp,612,-1,"puts (""hppa2.0n"");",,"[""removeLog""]","[[""puts"", ""hppa2"", ""0n""], []]",[-2435868555031571550],7132,336960.0,3
https://github.com/squid-cache/squid/commit/ed08b88c5e248d7683016e4fba2d59b9d561e70f,03 Apr 2008,"Ignore and do not version lib/libLtdl because it is libtool-generated.
Ignore cfgaux because it is libtool-generated (merged from trunk).",23843,data/crawl/squid/hunk_4331.cpp,,,data/crawl/squid/old_hunk_4331.cpp,data/crawl/squid/new_hunk_4331.cpp,611,-1,"puts (""hppa2.0w"");",,"[""removeLog""]","[[""puts"", ""hppa2"", ""0w""], []]",[-2435868555031571527],7131,336960.0,3
https://github.com/squid-cache/squid/commit/ed08b88c5e248d7683016e4fba2d59b9d561e70f,03 Apr 2008,"Ignore and do not version lib/libLtdl because it is libtool-generated.
Ignore cfgaux because it is libtool-generated (merged from trunk).",23843,data/crawl/squid/hunk_4331.cpp,,,data/crawl/squid/old_hunk_4331.cpp,data/crawl/squid/new_hunk_4331.cpp,606,-1,"puts (""hppa1.1"");",,"[""removeLog""]","[[""puts"", ""hppa1"", ""1""], []]",[-2429724524391534869],7130,336960.0,3
https://github.com/squid-cache/squid/commit/ed08b88c5e248d7683016e4fba2d59b9d561e70f,03 Apr 2008,"Ignore and do not version lib/libLtdl because it is libtool-generated.
Ignore cfgaux because it is libtool-generated (merged from trunk).",23843,data/crawl/squid/hunk_4331.cpp,,,data/crawl/squid/old_hunk_4331.cpp,data/crawl/squid/new_hunk_4331.cpp,521,-1,"puts(""powerpc-ibm-aix3.2.5"");",,"[""removeLog""]","[[""puts"", ""powerpc"", ""ibm"", ""aix3"", ""2"", ""5""], []]",[2767682009957926458],7129,336960.0,3
https://github.com/squid-cache/squid/commit/ed08b88c5e248d7683016e4fba2d59b9d561e70f,03 Apr 2008,"Ignore and do not version lib/libLtdl because it is libtool-generated.
Ignore cfgaux because it is libtool-generated (merged from trunk).",23843,data/crawl/squid/hunk_4331.cpp,,,data/crawl/squid/old_hunk_4331.cpp,data/crawl/squid/new_hunk_4331.cpp,433,-1,"printf (""mips-mips-riscos%sbsd\n"", argv[1]);",,"[""removeLog""]","[[""printf"", ""mips"", ""mips"", ""riscos%sbsd\\n"", ""argv[1]""], []]",[12615113043110249714],7128,336960.0,3
https://github.com/squid-cache/squid/commit/ed08b88c5e248d7683016e4fba2d59b9d561e70f,03 Apr 2008,"Ignore and do not version lib/libLtdl because it is libtool-generated.
Ignore cfgaux because it is libtool-generated (merged from trunk).",23843,data/crawl/squid/hunk_4331.cpp,,,data/crawl/squid/old_hunk_4331.cpp,data/crawl/squid/new_hunk_4331.cpp,430,-1,"printf (""mips-mips-riscos%ssvr4\n"", argv[1]);",,"[""removeLog""]","[[""printf"", ""mips"", ""mips"", ""riscos%ssvr4\\n"", ""argv[1]""], []]",[6627189546977484297],7127,336960.0,3
https://github.com/squid-cache/squid/commit/ed08b88c5e248d7683016e4fba2d59b9d561e70f,03 Apr 2008,"Ignore and do not version lib/libLtdl because it is libtool-generated.
Ignore cfgaux because it is libtool-generated (merged from trunk).",23843,data/crawl/squid/hunk_4331.cpp,,,data/crawl/squid/old_hunk_4331.cpp,data/crawl/squid/new_hunk_4331.cpp,427,-1,"printf (""mips-mips-riscos%ssysv\n"", argv[1]);",,"[""removeLog""]","[[""printf"", ""mips"", ""mips"", ""riscos%ssysv\\n"", ""argv[1]""], []]",[8018455546522590639],7126,336960.0,3
https://github.com/squid-cache/squid/commit/7dbca7a4b0bf79fe0d6575e03fd02b774d953de4,02 Jul 2008,"Cleanup: Drop appname and full_appname_string constant globals

appname array only ever held a duplicate of ""squid""
      - calling it APP_SHORTNAME now instead of a global

full_appname_string only ever held the catenation VERSION""/""PACKAGE macros
      - calling it APP_FULLNAME now instead of a global",78,data/crawl/squid/hunk_4280.cpp,,,data/crawl/squid/old_hunk_4280.cpp,data/crawl/squid/new_hunk_4280.cpp,3,3,"fprintf(debug_log, ""Memory usage for %s via mallinfo():\n"", appname);","fprintf(debug_log, ""Memory usage for ""APP_SHORTNAME"" via mallinfo():\n"");","[""removeVariable"", ""addContent"", ""updateContent"", ""addVariable""]","[[""%s"", ""appname""], [""APP_SHORTNAME""]]",[4779406518195074565],7125,0.0,3
https://github.com/squid-cache/squid/commit/c70281f8bdba2a5f525ddea764667975bbd79eb3,22 Jul 2008,"Cleanups: shuffle ErrorState functions into methods.

No other changes than namespace moves.",228,data/crawl/squid/hunk_4245.cpp,,,data/crawl/squid/old_hunk_4245.cpp,data/crawl/squid/new_hunk_4245.cpp,42,40,"str.Printf(""ServerIP: %s\r\n"", r->hier.host);","str.Printf(""ServerIP: %s\r\n"", request->hier.host);","[""updateVariable""]","[[""r""], [""request""]]",[-1906760029003681671],7124,0.0,3
https://github.com/squid-cache/squid/commit/63aacec1e26e07afb814a4b54352ab5075fac13e,12 Sep 2008,"Aggregate commit after two --local commits:
 - Cleaned up Comm: comm_close, comm_read_cancel, half-closed monitors, leaks.
 - Cleaned up reconfiguration sequence.
Please see individual commit messages for details (bzr permitting).",372,data/crawl/squid/hunk_4217.cpp,,,data/crawl/squid/old_hunk_4217.cpp,data/crawl/squid/new_hunk_4217.cpp,11,9,"fatalf (""comm_write: fd %d: pending callback!\n"", fd);",assert(!ccb->active());,"[""updateLog"", ""removeVariable"", ""removeContent"", ""addVariable""]","[[""fatalf"", ""comm_write"", ""fd"", ""%d"", ""pending"", ""callback"", ""\\n"", ""fd""], [""assert"", ""ccb"", ""active""]]",[-2313291948716450097],7123,960.0,3
https://github.com/squid-cache/squid/commit/223901927d51abc6759356742b74a1c623818d14,30 Sep 2008,"eCAP support, phase 2: Implemented libecap interfaces, added eCAP
squid.conf options. Link with libecap when eCAP support is enabled.

eCAP code needs polishing and enhancement but appears to work for a few
targeted cases. I am committing this now so that users working on eCAP
modules can test and provide more specific feedback.

These adaptation-specific changes should not have significant effect on
core code.

The libecap library is available at http://www.e-cap.org/",1758,data/crawl/squid/hunk_4187.cpp,,,data/crawl/squid/old_hunk_4187.cpp,data/crawl/squid/new_hunk_4187.cpp,-1,414,,"buf.Printf("" ecapx%d]"", id);","[""addLog""]","[[], [""buf"", ""Printf"", ""ecapx%d]"", ""id""]]",[2386550613750857899],7122,1440.0,3
https://github.com/squid-cache/squid/commit/ee1863f493b30a4848fc0b562078a7d8859bf1a7,21 Oct 2008,"Restore active part of error page stylesheets

This now uses an adjusted form of errorTryLoadText() which accepts
an absoute path page name and NULL dir instead of errorLoadText()
which is intended only for locating a specific page amongst the error
directory content.",107,data/crawl/squid/hunk_4060.cpp,,,data/crawl/squid/old_hunk_4060.cpp,data/crawl/squid/new_hunk_4060.cpp,-1,10,,"error_stylesheet.Printf(""%s"",temp);","[""addLog""]","[[], [""error_stylesheet"", ""Printf"", ""%s"", ""temp""]]",[3209358912624498704],7121,24000.0,3
https://github.com/squid-cache/squid/commit/2e1e4f10bd3ccc01183d99a9cb466f3bc483c5da,10 Aug 2009,merged from trunk,5048,data/crawl/squid/hunk_3674.cpp,,,data/crawl/squid/old_hunk_3674.cpp,data/crawl/squid/new_hunk_3674.cpp,34,-1,"fatal(""StatefulHandleRead: Callback routine attempted to reserve a stateful helper with deferred requests. This can lead to deadlock.\n"");",,"[""removeLog""]","[[""fatal"", ""StatefulHandleRead"", ""Callback"", ""routine"", ""attempted"", ""to"", ""reserve"", ""a"", ""stateful"", ""helper"", ""with"", ""deferred"", ""requests"", ""This"", ""can"", ""lead"", ""to"", ""deadlock"", ""\\n""], []]",[-1031818230852830416],7120,4320.0,3
https://github.com/squid-cache/squid/commit/c6111665d4d240d094f6b29a622389bc3676e401,14 Aug 2009,"Populate cache_mem again on disk cache hits, moving on-disk objects back
into the hot object pool.

This adds a new squid.conf option for tuning when to keep objects in memory.

Sponsored by: The Measurement Factory",181,data/crawl/squid/hunk_3654.cpp,,,data/crawl/squid/old_hunk_3654.cpp,data/crawl/squid/new_hunk_3654.cpp,-1,43,,"storeAppendPrintf(entry, ""none"");","[""addLog""]","[[], [""storeAppendPrintf"", ""entry"", ""none""]]",[-253675936071323782],7119,2136000.0,3
https://github.com/squid-cache/squid/commit/59bce1e80b711c4bc7c7ad5642e3ca227dced424,07 Sep 2009,"Author: Henrik Nordstrom <hno@squid-cache.org>
Bug 2510: digest_ldap_auth uses incorrect logic with TLS",8,data/crawl/squid/hunk_3589.cpp,,,data/crawl/squid/old_hunk_3589.cpp,data/crawl/squid/new_hunk_3589.cpp,-1,4,,"fprintf(stderr, ""TLS requires LDAP version 3\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""TLS"", ""requires"", ""LDAP"", ""version"", ""3\\n""]]",[-15385751882136328078],7118,783840.0,3
https://github.com/squid-cache/squid/commit/0263742023e4872c0db3b6cfd13df08c2e4673c1,23 Sep 2009,Merg from trunk,1314,data/crawl/squid/hunk_3578.cpp,,,data/crawl/squid/old_hunk_3578.cpp,data/crawl/squid/new_hunk_3578.cpp,-1,27,,"reply->header.putStr(HDR_CONTENT_ENCODING, mime_enc);","[""addLog""]","[[], [""reply"", ""header"", ""putStr"", ""HDR_CONTENT_ENCODING"", ""mime_enc""]]",[-13730523031883377103],7117,1183680.0,3
https://github.com/squid-cache/squid/commit/77721eb240367f9d4bd82638f118c811f2e93349,05 Nov 2009,"Author: Markus Moeller huaraz@moeller.plus.com>
Update squid_kerb_auth helper

 * remove sub configure again (too many issues)

Also, by Amso Jeffries
 * naming update to negotiate_kerberos_auth
 * polished helper detection rules in configure",10781,data/crawl/squid/hunk_3547.cpp,,,data/crawl/squid/old_hunk_3547.cpp,data/crawl/squid/new_hunk_3547.cpp,491,-1,"fprintf(stdout, ""BH Not enough memory\n"");",,"[""removeLog""]","[[""fprintf"", ""stdout"", ""BH"", ""Not"", ""enough"", ""memory\\n""], []]",[5566043686881520900],7116,0.0,3
https://github.com/squid-cache/squid/commit/77721eb240367f9d4bd82638f118c811f2e93349,05 Nov 2009,"Author: Markus Moeller huaraz@moeller.plus.com>
Update squid_kerb_auth helper

 * remove sub configure again (too many issues)

Also, by Amso Jeffries
 * naming update to negotiate_kerberos_auth
 * polished helper detection rules in configure",10781,data/crawl/squid/hunk_3547.cpp,,,data/crawl/squid/old_hunk_3547.cpp,data/crawl/squid/new_hunk_3547.cpp,490,-1,"fprintf(stderr, ""%s| %s: Not enough memory\n"", LogTime(), PROGRAM);",,"[""removeLog""]","[[""fprintf"", ""stderr"", ""%s"", ""%s"", ""Not"", ""enough"", ""memory\\n"", ""LogTime"", ""PROGRAM""], []]",[2312750529207102588],7115,0.0,3
https://github.com/squid-cache/squid/commit/77721eb240367f9d4bd82638f118c811f2e93349,05 Nov 2009,"Author: Markus Moeller huaraz@moeller.plus.com>
Update squid_kerb_auth helper

 * remove sub configure again (too many issues)

Also, by Amso Jeffries
 * naming update to negotiate_kerberos_auth
 * polished helper detection rules in configure",10781,data/crawl/squid/hunk_3546.cpp,,,data/crawl/squid/old_hunk_3546.cpp,data/crawl/squid/new_hunk_3546.cpp,-1,251,,"fprintf(stdout, ""Token: %s\n"", Token ? Token : ""NULL"");","[""addLog""]","[[], [""fprintf"", ""stdout"", ""Token"", ""%s\\n"", ""Token"", ""Token"", ""NULL""]]",[10114567155438669502],7114,192480.0,3
https://github.com/squid-cache/squid/commit/77721eb240367f9d4bd82638f118c811f2e93349,05 Nov 2009,"Author: Markus Moeller huaraz@moeller.plus.com>
Update squid_kerb_auth helper

 * remove sub configure again (too many issues)

Also, by Amso Jeffries
 * naming update to negotiate_kerberos_auth
 * polished helper detection rules in configure",10781,data/crawl/squid/hunk_3546.cpp,,,data/crawl/squid/old_hunk_3546.cpp,data/crawl/squid/new_hunk_3546.cpp,-1,237,,"fprintf(stderr, ""%s| %s: Error: No proxy server name given\n"",
	    LogTime(), PROGRAM);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""%s"", ""%s"", ""Error"", ""No"", ""proxy"", ""server"", ""name"", ""given\\n"", ""LogTime"", ""PROGRAM""]]",[-3993605086623310008],7113,192480.0,3
https://github.com/squid-cache/squid/commit/77721eb240367f9d4bd82638f118c811f2e93349,05 Nov 2009,"Author: Markus Moeller huaraz@moeller.plus.com>
Update squid_kerb_auth helper

 * remove sub configure again (too many issues)

Also, by Amso Jeffries
 * naming update to negotiate_kerberos_auth
 * polished helper detection rules in configure",10781,data/crawl/squid/hunk_3546.cpp,,,data/crawl/squid/old_hunk_3546.cpp,data/crawl/squid/new_hunk_3546.cpp,-1,182,,"fprintf(stderr, ""%s| %s: Error: No proxy server name\n"", LogTime(),
	    PROGRAM);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""%s"", ""%s"", ""Error"", ""No"", ""proxy"", ""server"", ""name\\n"", ""LogTime"", ""PROGRAM""]]",[-628383695844682266],7112,192480.0,3
https://github.com/squid-cache/squid/commit/77721eb240367f9d4bd82638f118c811f2e93349,05 Nov 2009,"Author: Markus Moeller huaraz@moeller.plus.com>
Update squid_kerb_auth helper

 * remove sub configure again (too many issues)

Also, by Amso Jeffries
 * naming update to negotiate_kerberos_auth
 * polished helper detection rules in configure",10781,data/crawl/squid/hunk_3545.cpp,,,data/crawl/squid/old_hunk_3545.cpp,data/crawl/squid/new_hunk_3545.cpp,-1,457,,"fprintf(stderr, ""%s| %s: Token is possibly a GSSAPI token\n"",
		    LogTime(), PROGRAM);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""%s"", ""%s"", ""Token"", ""is"", ""possibly"", ""a"", ""GSSAPI"", ""token\\n"", ""LogTime"", ""PROGRAM""]]",[-10652912587544659733],7111,192480.0,3
https://github.com/squid-cache/squid/commit/77721eb240367f9d4bd82638f118c811f2e93349,05 Nov 2009,"Author: Markus Moeller huaraz@moeller.plus.com>
Update squid_kerb_auth helper

 * remove sub configure again (too many issues)

Also, by Amso Jeffries
 * naming update to negotiate_kerberos_auth
 * polished helper detection rules in configure",10781,data/crawl/squid/hunk_3545.cpp,,,data/crawl/squid/old_hunk_3545.cpp,data/crawl/squid/new_hunk_3545.cpp,-1,420,,"fprintf(stderr, ""%s| %s: Decode '%s' (decoded length: %d).\n"",
		LogTime(), PROGRAM, buf + 3, (int) input_token.length);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""%s"", ""%s"", ""Decode"", ""%s"", ""decoded"", ""length"", ""%d"", ""\\n"", ""LogTime"", ""PROGRAM"", ""buf"", ""3"", ""int"", ""input_token"", ""length""]]",[-9209981235340167470],7110,192480.0,3
https://github.com/squid-cache/squid/commit/77721eb240367f9d4bd82638f118c811f2e93349,05 Nov 2009,"Author: Markus Moeller huaraz@moeller.plus.com>
Update squid_kerb_auth helper

 * remove sub configure again (too many issues)

Also, by Amso Jeffries
 * naming update to negotiate_kerberos_auth
 * polished helper detection rules in configure",10781,data/crawl/squid/hunk_3545.cpp,,,data/crawl/squid/old_hunk_3545.cpp,data/crawl/squid/new_hunk_3545.cpp,-1,281,,"fprintf(stderr, ""default SPN is HTTP/fqdn@DEFAULT_REALM\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""default"", ""SPN"", ""is"", ""HTTP/fqdn"", ""DEFAULT_REALM\\n""]]",[-16001149151896106589],7109,192480.0,3
https://github.com/squid-cache/squid/commit/b0365bd9f05a30d13c6ee3dadb3011b075ebcba0,18 Nov 2009,Fixed some cases of variable shadowing,118,data/crawl/squid/hunk_3518.cpp,,,data/crawl/squid/old_hunk_3518.cpp,data/crawl/squid/new_hunk_3518.cpp,3,3,"finalizeMsg(""Inconsistent service method for"", sid, true);","finalizeMsg(""Inconsistent service method for"", serviceId, true);","[""updateVariable""]","[[""sid""], [""serviceId""]]",[4276942373760829436],7108,0.0,3
https://github.com/squid-cache/squid/commit/6a7f4dec1defc21c1e4469788ed25c8eb891a5c6,09 Jan 2010,Remove optional kerberos/spnegohelp/ library due to licensing issues,4343,data/crawl/squid/hunk_3442.cpp,,,data/crawl/squid/old_hunk_3442.cpp,data/crawl/squid/new_hunk_3442.cpp,27,-1,"fprintf(stdout, ""BH received type %d NTLM token\n"",
                        (int) *((unsigned char *) input_token.value +
                                sizeof ntlmProtocol));",,"[""removeLog""]","[[""fprintf"", ""stdout"", ""BH"", ""received"", ""type"", ""%d"", ""NTLM"", ""token\\n"", ""int"", ""*"", ""unsigned"", ""char"", ""*"", ""input_token"", ""value"", ""sizeof"", ""ntlmProtocol""], []]",[33580115765483002823],7107,31200.0,3
https://github.com/squid-cache/squid/commit/6a7f4dec1defc21c1e4469788ed25c8eb891a5c6,09 Jan 2010,Remove optional kerberos/spnegohelp/ library due to licensing issues,4343,data/crawl/squid/hunk_3442.cpp,,,data/crawl/squid/old_hunk_3442.cpp,data/crawl/squid/new_hunk_3442.cpp,23,-1,"fprintf(stderr, ""%s| %s: received type %d NTLM token\n"",
                            LogTime(), PROGRAM,
                            (int) *((unsigned char *) input_token.value +
                                    sizeof ntlmProtocol));",,"[""removeLog""]","[[""fprintf"", ""stderr"", ""%s"", ""%s"", ""received"", ""type"", ""%d"", ""NTLM"", ""token\\n"", ""LogTime"", ""PROGRAM"", ""int"", ""*"", ""unsigned"", ""char"", ""*"", ""input_token"", ""value"", ""sizeof"", ""ntlmProtocol""], []]",[30326822607808584511],7106,31200.0,3
https://github.com/squid-cache/squid/commit/b7ac5457b2c07bf13d3123a4035d22f6c79ce37e,17 Apr 2010,"SourceLayout: Add Ip namespace for internal libip

IpAddress is now Ip::Address, IpInterceptor is now Ip::Interceptor, etc.

* Also detaches QosConfig from the global config structures.
  Clearing up several of the dependency chains to libip",1407,data/crawl/squid/hunk_3399.cpp,,,data/crawl/squid/old_hunk_3399.cpp,data/crawl/squid/new_hunk_3399.cpp,6,6,"IpInterceptor.StopTransparency(""capability setting has failed."");","Ip::Interceptor.StopTransparency(""capability setting has failed."");","[""addLog"", ""updateLog""]","[[""IpInterceptor""], [""Ip"", ""Interceptor""]]",[-942555901688474914],7105,0.0,3
https://github.com/squid-cache/squid/commit/54e8823bf16f1310bcf26d4f5789d4ffc1fc62be,30 Apr 2010,Naming upgrade of digest_pw_auth (now digest_file_auth),206,data/crawl/squid/hunk_3386.cpp,,,data/crawl/squid/old_hunk_3386.cpp,data/crawl/squid/new_hunk_3386.cpp,3,3,"fprintf(stderr, ""digest_pw_auth: cannot create hash table\n"");","fprintf(stderr, ""digest_file_auth: cannot create hash table\n"");","[""updateContent""]","[[""digest_pw_auth""], [""digest_file_auth""]]",[17608948659245283803],7104,0.0,3
https://github.com/squid-cache/squid/commit/4542b25ba0c3d195fcd2f43de2e6ba3167957156,02 Jun 2010,"Bug 2305: Multiple leaks and assertion crashes in authentication.

 * implements proper RefCounting using the RefCount.h classes for
   almost all auth objects in Squid.

 * Restructures auth objects with a simpler structure of duties and scopes.

 * Prunes away several circular and indirectly circular pointer loops

 * Adds an API to auth config for handling the mainRotate() event. To only
   shutdown helpers, fixing the loss of cached credentials on rotate.

 * Adds a username_cache page to cachemgr interface to display the current
   credentials and their TTLs to various revalidation or garbage events.


With this we end up with several global pointers for the auth schemes which
have been built into the current Squid. These are RefCount pointers, fixing
the leak of schemes on shutdown. Schemes are now also permanent structures
for the runtime of Squid, fixing leaks on reconfigure and rotate actions.

These AuthSchemes are responsible for creating auth Config objects for each
auth protocol configured in squid.conf. These config objects are now also
able to be altered with a reconfigure instead of requiring a restart.

Each HTTP request authentication attempt generates AuthUserRequest objects,
which may or may not pointer to an AuthUser set of credentials being checked.
AuthUserRequest is RefCounted instead of locked, fixing several assertion
crashes.

AuthUser is now RefCounted instead of locked. It's children inherit
these properties. This simplifies the object handling a lot and fixes
several assertions.
 * This also means AuthUser no longer needs a back-pointer to all
AuthUserRequest in order to see if its still needed alive, fixing one
circular lock loop and a few possible assertions.
 * The username cache pointers to only AuthUser objects, fixing a second
cirular lock loop and potentially leakage. Also simplifying the hash cache
handling a lot.

Non-Auth code needing a reference to authentication credentials should
hold a pointer to either an AuthUserRequest or AuthUser object. Not any
other auth object.


FUTURE WORK;
 There is still some conditions leading to auth re-challenge when they
 are not expected.
 A fair chunk of classes and enums have been shuffled into separate files
 to keep the scopes clearer. This could be increased in future when
 building the Auth namespace.
 Potential is now present for simpler TTL handling for all auth types.



This work was a collaboration between multiple interested parties over
the last year, with additional developer time and testing funded by
Netspace Online Systems.",5398,data/crawl/squid/hunk_3340.cpp,,,data/crawl/squid/old_hunk_3340.cpp,data/crawl/squid/new_hunk_3340.cpp,147,-1,auth_user_request->denyMessage(blob);,,"[""removeLog""]","[[""auth_user_request"", ""denyMessage"", ""blob""], []]",[-4613437229150417116],7103,0.0,3
https://github.com/squid-cache/squid/commit/43fed740b24c9b64720ba589782c48694ce55c7d,28 Jun 2010,Pull out the basic helper API definitions for sharing,250,data/crawl/squid/hunk_3274.cpp,,,data/crawl/squid/old_hunk_3274.cpp,data/crawl/squid/new_hunk_3274.cpp,19,19,"fprintf(stderr, ""authenticator: Unexpected input '%s'\n"", buf);","debug(""ERROR: %s: Unexpected input '%s'\n"", argv[0], buf);","[""moveContent"", ""updateLog"", ""removeVariable"", ""addContent"", ""updateContent"", ""addVariable""]","[[""fprintf"", ""stderr"", ""authenticator""], [""debug"", ""ERROR"", ""%s"", ""argv[0]""]]",[21528577501340763098],7102,0.0,3
https://github.com/squid-cache/squid/commit/1dcf61eb8b17dc47e6ba3ed0921caa25fc1c232b,30 Jun 2010,"NTLM helpers cleanup pt 3: migrate libsmbval into libntlmauth

Library changes:
* ntlmauth.* files moved to libntlmauth/

* helpers/ntlm_auth/smb_lm/smbval moved to libntlmauth/

* No behaviour changes. Since I can't test the deeper logics.
  Just enough to make the code built with portable types available in Squid

* API shuffled slightly to use less .h and to remove all external uses of
  private *-priv.h definitions.

Library now provides three NTLM backend API:
  libntlmauth/ntlmauth.h  - NTLM packet handling
  libntlmauth/smb.h       - SMB LM credential validation
  libntlmauth/rfcnb.h     - RFCNB (NetBIOS) domain server communications

Helper Changes:

* NTLM helpers tweaked slightly to build with the adjusted libntlmauth API
  and ntlm_smb_lm_auth helper to build as C++

* automake logics updated to obey --disable-auth and --disable-auth-ntlm


NOTE: There will be extra code safety and testing benefits gained by
      converting libntlmauth to C++ as well. But that requries someone who
      can test the code behaviour during the upgrade. For now this wil do.",2475,data/crawl/squid/hunk_3259.cpp,,,data/crawl/squid/old_hunk_3259.cpp,data/crawl/squid/new_hunk_3259.cpp,-1,199,,"fprintf(stderr, ""No auth at all. Returning no-auth\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""No"", ""auth"", ""at"", ""all"", ""Returning"", ""no"", ""auth\\n""]]",[-15157065372892297358],7101,1816320.0,3
https://github.com/squid-cache/squid/commit/abf4be2be005b247ae6cf7ffd4a173ee60ff6867,07 Jul 2010,"SMP support, part 1: Essential non-caching functionality.

Added workers squid.conf option to specify how many main Squid
processes to fork and maintain. Zero means old no-daemon mode.
One means the old non-SMP mode.

Added support for process_name and process_number macros and
if-statement conditionals in squid.conf. Search for .pre changes for
documented details. These features allow the admin to configure each
worker process differently if needed.

Support multiple workers listening on the same HTTP[S] port (port
sharing). This allows multiple workers to split the load without any
special rules.

Support or prohibit port sharing for WCCP, DNS, ICP, HTCP, SNMP, and
Ident protocols, depending on protocol-specific restrictions. Sharing is
implemented by registering listening socket descriptors with the
Coordinator process and obtaining them from the Coordinator as needed.
Here are protocol-specific notes:

   WCCP: Restricted to the Coordinator process due to how WCCP works.
   Workers do not need access to the WCCP code.

   DNS: Done by each worker with no sharing. Fixed source ports not
   supported unless each worker is given its own outgoing address
   because we do not want to match outgoing queries and incoming
   responses across processes.

   SNMP: Workers share incoming and outgoing sockets.

   ICP and HTCP _clients_: Cannot be supported in SMP environment
   unless each process has its own address (i.e., unique IP address
   and/or unique [ICP] port) because we do not want to match outgoing
   queries and incoming responses across processes.

   ICP and HTCP _servers_: share listening sockets.

   Ident clients do not need to share sockets because they use
   unique ports.

Support management signals (squid -k ...) in SMP mode, acting as a
single Squid instance.

Refork dying workers, similar to how we reforked dying process in
non-SMP daemon mode.

Merged from lp smp branch r10306.",3002,data/crawl/squid/hunk_3239.cpp,,,data/crawl/squid/old_hunk_3239.cpp,data/crawl/squid/new_hunk_3239.cpp,-1,9,,"fatal(""Cannot open ICP Port"");","[""addLog""]","[[], [""fatal"", ""Cannot"", ""open"", ""ICP"", ""Port""]]",[-9481987995531124990],7100,4413600.0,3
https://github.com/squid-cache/squid/commit/abf4be2be005b247ae6cf7ffd4a173ee60ff6867,07 Jul 2010,"SMP support, part 1: Essential non-caching functionality.

Added workers squid.conf option to specify how many main Squid
processes to fork and maintain. Zero means old no-daemon mode.
One means the old non-SMP mode.

Added support for process_name and process_number macros and
if-statement conditionals in squid.conf. Search for .pre changes for
documented details. These features allow the admin to configure each
worker process differently if needed.

Support multiple workers listening on the same HTTP[S] port (port
sharing). This allows multiple workers to split the load without any
special rules.

Support or prohibit port sharing for WCCP, DNS, ICP, HTCP, SNMP, and
Ident protocols, depending on protocol-specific restrictions. Sharing is
implemented by registering listening socket descriptors with the
Coordinator process and obtaining them from the Coordinator as needed.
Here are protocol-specific notes:

   WCCP: Restricted to the Coordinator process due to how WCCP works.
   Workers do not need access to the WCCP code.

   DNS: Done by each worker with no sharing. Fixed source ports not
   supported unless each worker is given its own outgoing address
   because we do not want to match outgoing queries and incoming
   responses across processes.

   SNMP: Workers share incoming and outgoing sockets.

   ICP and HTCP _clients_: Cannot be supported in SMP environment
   unless each process has its own address (i.e., unique IP address
   and/or unique [ICP] port) because we do not want to match outgoing
   queries and incoming responses across processes.

   ICP and HTCP _servers_: share listening sockets.

   Ident clients do not need to share sockets because they use
   unique ports.

Support management signals (squid -k ...) in SMP mode, acting as a
single Squid instance.

Refork dying workers, similar to how we reforked dying process in
non-SMP daemon mode.

Merged from lp smp branch r10306.",3002,data/crawl/squid/hunk_3238.cpp,,,data/crawl/squid/old_hunk_3238.cpp,data/crawl/squid/new_hunk_3238.cpp,20,-1,"fatal(""Cannot open ICP Port"");",,"[""removeLog""]","[[""fatal"", ""Cannot"", ""open"", ""ICP"", ""Port""], []]",[9481987995531124990],7099,4413600.0,3
https://github.com/squid-cache/squid/commit/abf4be2be005b247ae6cf7ffd4a173ee60ff6867,07 Jul 2010,"SMP support, part 1: Essential non-caching functionality.

Added workers squid.conf option to specify how many main Squid
processes to fork and maintain. Zero means old no-daemon mode.
One means the old non-SMP mode.

Added support for process_name and process_number macros and
if-statement conditionals in squid.conf. Search for .pre changes for
documented details. These features allow the admin to configure each
worker process differently if needed.

Support multiple workers listening on the same HTTP[S] port (port
sharing). This allows multiple workers to split the load without any
special rules.

Support or prohibit port sharing for WCCP, DNS, ICP, HTCP, SNMP, and
Ident protocols, depending on protocol-specific restrictions. Sharing is
implemented by registering listening socket descriptors with the
Coordinator process and obtaining them from the Coordinator as needed.
Here are protocol-specific notes:

   WCCP: Restricted to the Coordinator process due to how WCCP works.
   Workers do not need access to the WCCP code.

   DNS: Done by each worker with no sharing. Fixed source ports not
   supported unless each worker is given its own outgoing address
   because we do not want to match outgoing queries and incoming
   responses across processes.

   SNMP: Workers share incoming and outgoing sockets.

   ICP and HTCP _clients_: Cannot be supported in SMP environment
   unless each process has its own address (i.e., unique IP address
   and/or unique [ICP] port) because we do not want to match outgoing
   queries and incoming responses across processes.

   ICP and HTCP _servers_: share listening sockets.

   Ident clients do not need to share sockets because they use
   unique ports.

Support management signals (squid -k ...) in SMP mode, acting as a
single Squid instance.

Refork dying workers, similar to how we reforked dying process in
non-SMP daemon mode.

Merged from lp smp branch r10306.",3002,data/crawl/squid/hunk_3237.cpp,,,data/crawl/squid/old_hunk_3237.cpp,data/crawl/squid/new_hunk_3237.cpp,-1,16,,"fatal(""Cannot open HTCP Socket"");","[""addLog""]","[[], [""fatal"", ""Cannot"", ""open"", ""HTCP"", ""Socket""]]",[3828576806609246128],7098,4308000.0,3
https://github.com/squid-cache/squid/commit/56ff468707b9146dc19a5c519fd421dd2b9cfcb9,08 Jul 2010,Helpers: upgrade digest helpers to C++,273,data/crawl/squid/hunk_3221.cpp,,,data/crawl/squid/old_hunk_3221.cpp,data/crawl/squid/new_hunk_3221.cpp,4,-1,"printf(""password: %s\n"", password);",,"[""removeLog""]","[[""printf"", ""password"", ""%s\\n"", ""password""], []]",[1032207333545575809],7097,1488000.0,3
https://github.com/squid-cache/squid/commit/c152a4473c4a3d187f67923eb83c5fe6ccd91013,12 Jul 2010,"Helpers: Naming and C++ update for external ACL helpers

 * Also adds the Fake auth helper for testing Basic authentication.
 * Also adds manual pages for most external ACL helpers

TODO: test for and fix any build issues on Windows.",2485,data/crawl/squid/hunk_3140.cpp,,,data/crawl/squid/old_hunk_3140.cpp,data/crawl/squid/new_hunk_3140.cpp,3,3,"fprintf(stderr, ""Connect timeouts not supported in your LDAP library\n"");","fprintf(stderr, ""WARNING: Connect timeouts not supported in your LDAP library\n"");","[""updateContent""]","[[], [""WARNING""]]",[-4387977558364981357],7096,73440.0,3
https://github.com/squid-cache/squid/commit/2ccf2eb2159f0ee9847669c101f9ed4143e0b01d,19 Aug 2010,"Bundle the purge and hexd tools with Squid sources.

Fixes the remaining known errors with purge tool building within
Squid source tree.


This adds the auto-tools changes necessary to bundle the tool.",564,data/crawl/squid/hunk_3065.cpp,,,data/crawl/squid/old_hunk_3065.cpp,data/crawl/squid/new_hunk_3065.cpp,-1,23,,"fputs( ""(unknown)\n"", stderr );","[""addLog""]","[[], [""fputs"", ""unknown"", ""\\n"", ""stderr""]]",[-16791036293205242296],7095,40320.0,3
https://github.com/squid-cache/squid/commit/2ccf2eb2159f0ee9847669c101f9ed4143e0b01d,19 Aug 2010,"Bundle the purge and hexd tools with Squid sources.

Fixes the remaining known errors with purge tool building within
Squid source tree.


This adds the auto-tools changes necessary to bundle the tool.",564,data/crawl/squid/hunk_3065.cpp,,,data/crawl/squid/old_hunk_3065.cpp,data/crawl/squid/new_hunk_3065.cpp,-1,21,,"fprintf( stderr, ""%s\n"", _sys_siglist[sig] );","[""addLog""]","[[], [""fprintf"", ""stderr"", ""%s\\n"", ""_sys_siglist[sig]""]]",[-1572256004854501974],7094,40320.0,3
https://github.com/squid-cache/squid/commit/2ccf2eb2159f0ee9847669c101f9ed4143e0b01d,19 Aug 2010,"Bundle the purge and hexd tools with Squid sources.

Fixes the remaining known errors with purge tool building within
Squid source tree.


This adds the auto-tools changes necessary to bundle the tool.",564,data/crawl/squid/hunk_3065.cpp,,,data/crawl/squid/old_hunk_3065.cpp,data/crawl/squid/new_hunk_3065.cpp,-1,19,,"fprintf( stderr, ""%s: "", msg );","[""addLog""]","[[], [""fprintf"", ""stderr"", ""%s"", ""msg""]]",[-7533761602946052704],7093,40320.0,3
https://github.com/squid-cache/squid/commit/425de4c8495f778cb43fc61df608575cedf8b60c,06 Oct 2010,"Author: Andrew Beverley <andy@andybev.com>
Netfilter MARK support for QoS",1502,data/crawl/squid/hunk_2979.cpp,,,data/crawl/squid/old_hunk_2979.cpp,data/crawl/squid/new_hunk_2979.cpp,-1,14,,"storeAppendPrintf(entry, ""%s none"", name);","[""addLog""]","[[], [""storeAppendPrintf"", ""entry"", ""%s"", ""none"", ""name""]]",[-4415518394763979715],7092,1856160.0,3
https://github.com/squid-cache/squid/commit/7c16470cc2d053ea2c540459843227dea08e8b40,16 Oct 2010,"basic_msnt_auth helper and NTLM/SMBLIB/RFCNB library polish.

Samba smblib/rfcnb code:
 * Import the latest copy which I could find a download link to.
   This source is from 1997 so I suspect there is something even newer
   we should be using. Time was tight is the only excuse for using
   these sources. Our originals were from 1995 and 1996 depending on the
   helper using it, with a mix of patches.

 * These two directories are in ours sources as lib/smblib and lib/rfcnb.
   Each has its own convenience library. Kept separate with original
   filenames to simplify future upgrades or removal.

 * Samba sources have been diffed and compared function by function
   against the copies previously in our sources. Functionality extensions
   we use have been grafted back on top of the new(er) Samba sources.
  - this was mostly around passing extra Unicode, DC hints and pre-crypted
    passwords to the login checks.
  - some files from libntlmauth have yet to be compared in fine detail,
    that will be completed today before merge.
  - some basic API function and struct definitions had to be moved to the
    API headers to prevent needing to include the *-priv.h private
    definitions externally to the library.

 * the Samba API headers have been wrapped with #ifndef safety wrappers

 * compile errors and include changes required to compile have been
   made (code stays C)

 * duplicate code in helpers/basic_auth/MSNT/* and libntlmauth/* is
   removed.

 * abuse of the smblib-priv.h and rfcnb-priv.h headers and all local
   re-definitions has been erased from our code. Replaced by includes 
   of the library API headers: rfcnb/rfcnb.h  smblib/smblib.h


libntlmauth:
 * smblib/rfcnb bits erased
 * moved to lib/ntlmauth in its much reduced form
 * built as a convenience library instead of full library",14917,data/crawl/squid/hunk_2964.cpp,,,data/crawl/squid/old_hunk_2964.cpp,data/crawl/squid/new_hunk_2964.cpp,-1,550,,"fprintf(stderr, ""SMB_SessSetupAndX failed with errorclass = %i, Error Code = %i\n"",
                CVAL(SMB_Hdr(pkt), SMB_hdr_rcls_offset),
                SVAL(SMB_Hdr(pkt), SMB_hdr_err_offset));","[""addLog""]","[[], [""fprintf"", ""stderr"", ""SMB_SessSetupAndX"", ""failed"", ""with"", ""errorclass"", ""%i"", ""Error"", ""Code"", ""%i\\n"", ""CVAL"", ""SMB_Hdr"", ""pkt"", ""SMB_hdr_rcls_offset"", ""SVAL"", ""SMB_Hdr"", ""pkt"", ""SMB_hdr_err_offset""]]",[5891327049776777669],7091,1712640.0,3
https://github.com/squid-cache/squid/commit/7c16470cc2d053ea2c540459843227dea08e8b40,16 Oct 2010,"basic_msnt_auth helper and NTLM/SMBLIB/RFCNB library polish.

Samba smblib/rfcnb code:
 * Import the latest copy which I could find a download link to.
   This source is from 1997 so I suspect there is something even newer
   we should be using. Time was tight is the only excuse for using
   these sources. Our originals were from 1995 and 1996 depending on the
   helper using it, with a mix of patches.

 * These two directories are in ours sources as lib/smblib and lib/rfcnb.
   Each has its own convenience library. Kept separate with original
   filenames to simplify future upgrades or removal.

 * Samba sources have been diffed and compared function by function
   against the copies previously in our sources. Functionality extensions
   we use have been grafted back on top of the new(er) Samba sources.
  - this was mostly around passing extra Unicode, DC hints and pre-crypted
    passwords to the login checks.
  - some files from libntlmauth have yet to be compared in fine detail,
    that will be completed today before merge.
  - some basic API function and struct definitions had to be moved to the
    API headers to prevent needing to include the *-priv.h private
    definitions externally to the library.

 * the Samba API headers have been wrapped with #ifndef safety wrappers

 * compile errors and include changes required to compile have been
   made (code stays C)

 * duplicate code in helpers/basic_auth/MSNT/* and libntlmauth/* is
   removed.

 * abuse of the smblib-priv.h and rfcnb-priv.h headers and all local
   re-definitions has been erased from our code. Replaced by includes 
   of the library API headers: rfcnb/rfcnb.h  smblib/smblib.h


libntlmauth:
 * smblib/rfcnb bits erased
 * moved to lib/ntlmauth in its much reduced form
 * built as a convenience library instead of full library",14917,data/crawl/squid/hunk_2964.cpp,,,data/crawl/squid/old_hunk_2964.cpp,data/crawl/squid/new_hunk_2964.cpp,-1,536,,"fprintf(stderr, ""Error receiving response to SessSetupAndX\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""Error"", ""receiving"", ""response"", ""to"", ""SessSetupAndX\\n""]]",[-17664103020917590369],7090,1712640.0,3
https://github.com/squid-cache/squid/commit/7c16470cc2d053ea2c540459843227dea08e8b40,16 Oct 2010,"basic_msnt_auth helper and NTLM/SMBLIB/RFCNB library polish.

Samba smblib/rfcnb code:
 * Import the latest copy which I could find a download link to.
   This source is from 1997 so I suspect there is something even newer
   we should be using. Time was tight is the only excuse for using
   these sources. Our originals were from 1995 and 1996 depending on the
   helper using it, with a mix of patches.

 * These two directories are in ours sources as lib/smblib and lib/rfcnb.
   Each has its own convenience library. Kept separate with original
   filenames to simplify future upgrades or removal.

 * Samba sources have been diffed and compared function by function
   against the copies previously in our sources. Functionality extensions
   we use have been grafted back on top of the new(er) Samba sources.
  - this was mostly around passing extra Unicode, DC hints and pre-crypted
    passwords to the login checks.
  - some files from libntlmauth have yet to be compared in fine detail,
    that will be completed today before merge.
  - some basic API function and struct definitions had to be moved to the
    API headers to prevent needing to include the *-priv.h private
    definitions externally to the library.

 * the Samba API headers have been wrapped with #ifndef safety wrappers

 * compile errors and include changes required to compile have been
   made (code stays C)

 * duplicate code in helpers/basic_auth/MSNT/* and libntlmauth/* is
   removed.

 * abuse of the smblib-priv.h and rfcnb-priv.h headers and all local
   re-definitions has been erased from our code. Replaced by includes 
   of the library API headers: rfcnb/rfcnb.h  smblib/smblib.h


libntlmauth:
 * smblib/rfcnb bits erased
 * moved to lib/ntlmauth in its much reduced form
 * built as a convenience library instead of full library",14917,data/crawl/squid/hunk_2964.cpp,,,data/crawl/squid/old_hunk_2964.cpp,data/crawl/squid/new_hunk_2964.cpp,-1,522,,"fprintf(stderr, ""Error sending SessSetupX request\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""Error"", ""sending"", ""SessSetupX"", ""request\\n""]]",[-5811297851841865137],7089,1712640.0,3
https://github.com/squid-cache/squid/commit/7c16470cc2d053ea2c540459843227dea08e8b40,16 Oct 2010,"basic_msnt_auth helper and NTLM/SMBLIB/RFCNB library polish.

Samba smblib/rfcnb code:
 * Import the latest copy which I could find a download link to.
   This source is from 1997 so I suspect there is something even newer
   we should be using. Time was tight is the only excuse for using
   these sources. Our originals were from 1995 and 1996 depending on the
   helper using it, with a mix of patches.

 * These two directories are in ours sources as lib/smblib and lib/rfcnb.
   Each has its own convenience library. Kept separate with original
   filenames to simplify future upgrades or removal.

 * Samba sources have been diffed and compared function by function
   against the copies previously in our sources. Functionality extensions
   we use have been grafted back on top of the new(er) Samba sources.
  - this was mostly around passing extra Unicode, DC hints and pre-crypted
    passwords to the login checks.
  - some files from libntlmauth have yet to be compared in fine detail,
    that will be completed today before merge.
  - some basic API function and struct definitions had to be moved to the
    API headers to prevent needing to include the *-priv.h private
    definitions externally to the library.

 * the Samba API headers have been wrapped with #ifndef safety wrappers

 * compile errors and include changes required to compile have been
   made (code stays C)

 * duplicate code in helpers/basic_auth/MSNT/* and libntlmauth/* is
   removed.

 * abuse of the smblib-priv.h and rfcnb-priv.h headers and all local
   re-definitions has been erased from our code. Replaced by includes 
   of the library API headers: rfcnb/rfcnb.h  smblib/smblib.h


libntlmauth:
 * smblib/rfcnb bits erased
 * moved to lib/ntlmauth in its much reduced form
 * built as a convenience library instead of full library",14917,data/crawl/squid/hunk_2964.cpp,,,data/crawl/squid/old_hunk_2964.cpp,data/crawl/squid/new_hunk_2964.cpp,-1,117,,"fprintf(stderr, ""Setting no-delay on TCP socket failed ...\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""Setting"", ""no"", ""delay"", ""on"", ""TCP"", ""socket"", ""failed"", ""\\n""]]",[-7235141140431330927],7088,1712640.0,3
https://github.com/squid-cache/squid/commit/7c16470cc2d053ea2c540459843227dea08e8b40,16 Oct 2010,"basic_msnt_auth helper and NTLM/SMBLIB/RFCNB library polish.

Samba smblib/rfcnb code:
 * Import the latest copy which I could find a download link to.
   This source is from 1997 so I suspect there is something even newer
   we should be using. Time was tight is the only excuse for using
   these sources. Our originals were from 1995 and 1996 depending on the
   helper using it, with a mix of patches.

 * These two directories are in ours sources as lib/smblib and lib/rfcnb.
   Each has its own convenience library. Kept separate with original
   filenames to simplify future upgrades or removal.

 * Samba sources have been diffed and compared function by function
   against the copies previously in our sources. Functionality extensions
   we use have been grafted back on top of the new(er) Samba sources.
  - this was mostly around passing extra Unicode, DC hints and pre-crypted
    passwords to the login checks.
  - some files from libntlmauth have yet to be compared in fine detail,
    that will be completed today before merge.
  - some basic API function and struct definitions had to be moved to the
    API headers to prevent needing to include the *-priv.h private
    definitions externally to the library.

 * the Samba API headers have been wrapped with #ifndef safety wrappers

 * compile errors and include changes required to compile have been
   made (code stays C)

 * duplicate code in helpers/basic_auth/MSNT/* and libntlmauth/* is
   removed.

 * abuse of the smblib-priv.h and rfcnb-priv.h headers and all local
   re-definitions has been erased from our code. Replaced by includes 
   of the library API headers: rfcnb/rfcnb.h  smblib/smblib.h


libntlmauth:
 * smblib/rfcnb bits erased
 * moved to lib/ntlmauth in its much reduced form
 * built as a convenience library instead of full library",14917,data/crawl/squid/hunk_2956.cpp,,,data/crawl/squid/old_hunk_2956.cpp,data/crawl/squid/new_hunk_2956.cpp,-1,197,,"printf(""  %s\n"", err_string);","[""addLog""]","[[], [""printf"", ""%s\\n"", ""err_string""]]",[11752476434877001442],7087,0.0,3
https://github.com/squid-cache/squid/commit/7c16470cc2d053ea2c540459843227dea08e8b40,16 Oct 2010,"basic_msnt_auth helper and NTLM/SMBLIB/RFCNB library polish.

Samba smblib/rfcnb code:
 * Import the latest copy which I could find a download link to.
   This source is from 1997 so I suspect there is something even newer
   we should be using. Time was tight is the only excuse for using
   these sources. Our originals were from 1995 and 1996 depending on the
   helper using it, with a mix of patches.

 * These two directories are in ours sources as lib/smblib and lib/rfcnb.
   Each has its own convenience library. Kept separate with original
   filenames to simplify future upgrades or removal.

 * Samba sources have been diffed and compared function by function
   against the copies previously in our sources. Functionality extensions
   we use have been grafted back on top of the new(er) Samba sources.
  - this was mostly around passing extra Unicode, DC hints and pre-crypted
    passwords to the login checks.
  - some files from libntlmauth have yet to be compared in fine detail,
    that will be completed today before merge.
  - some basic API function and struct definitions had to be moved to the
    API headers to prevent needing to include the *-priv.h private
    definitions externally to the library.

 * the Samba API headers have been wrapped with #ifndef safety wrappers

 * compile errors and include changes required to compile have been
   made (code stays C)

 * duplicate code in helpers/basic_auth/MSNT/* and libntlmauth/* is
   removed.

 * abuse of the smblib-priv.h and rfcnb-priv.h headers and all local
   re-definitions has been erased from our code. Replaced by includes 
   of the library API headers: rfcnb/rfcnb.h  smblib/smblib.h


libntlmauth:
 * smblib/rfcnb bits erased
 * moved to lib/ntlmauth in its much reduced form
 * built as a convenience library instead of full library",14917,data/crawl/squid/hunk_2955.cpp,,,data/crawl/squid/old_hunk_2955.cpp,data/crawl/squid/new_hunk_2955.cpp,-1,110,,"fprintf(stderr, ""Error sending Open request\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""Error"", ""sending"", ""Open"", ""request\\n""]]",[-656643587028167890],7086,0.0,3
https://github.com/squid-cache/squid/commit/7c16470cc2d053ea2c540459843227dea08e8b40,16 Oct 2010,"basic_msnt_auth helper and NTLM/SMBLIB/RFCNB library polish.

Samba smblib/rfcnb code:
 * Import the latest copy which I could find a download link to.
   This source is from 1997 so I suspect there is something even newer
   we should be using. Time was tight is the only excuse for using
   these sources. Our originals were from 1995 and 1996 depending on the
   helper using it, with a mix of patches.

 * These two directories are in ours sources as lib/smblib and lib/rfcnb.
   Each has its own convenience library. Kept separate with original
   filenames to simplify future upgrades or removal.

 * Samba sources have been diffed and compared function by function
   against the copies previously in our sources. Functionality extensions
   we use have been grafted back on top of the new(er) Samba sources.
  - this was mostly around passing extra Unicode, DC hints and pre-crypted
    passwords to the login checks.
  - some files from libntlmauth have yet to be compared in fine detail,
    that will be completed today before merge.
  - some basic API function and struct definitions had to be moved to the
    API headers to prevent needing to include the *-priv.h private
    definitions externally to the library.

 * the Samba API headers have been wrapped with #ifndef safety wrappers

 * compile errors and include changes required to compile have been
   made (code stays C)

 * duplicate code in helpers/basic_auth/MSNT/* and libntlmauth/* is
   removed.

 * abuse of the smblib-priv.h and rfcnb-priv.h headers and all local
   re-definitions has been erased from our code. Replaced by includes 
   of the library API headers: rfcnb/rfcnb.h  smblib/smblib.h


libntlmauth:
 * smblib/rfcnb bits erased
 * moved to lib/ntlmauth in its much reduced form
 * built as a convenience library instead of full library",14917,data/crawl/squid/hunk_2954.cpp,,,data/crawl/squid/old_hunk_2954.cpp,data/crawl/squid/new_hunk_2954.cpp,-1,391,,"fprintf(stderr, ""Could not allocate file handle space ..."");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""Could"", ""not"", ""allocate"", ""file"", ""handle"", ""space""]]",[8591932977287670914],7085,0.0,3
https://github.com/squid-cache/squid/commit/7c16470cc2d053ea2c540459843227dea08e8b40,16 Oct 2010,"basic_msnt_auth helper and NTLM/SMBLIB/RFCNB library polish.

Samba smblib/rfcnb code:
 * Import the latest copy which I could find a download link to.
   This source is from 1997 so I suspect there is something even newer
   we should be using. Time was tight is the only excuse for using
   these sources. Our originals were from 1995 and 1996 depending on the
   helper using it, with a mix of patches.

 * These two directories are in ours sources as lib/smblib and lib/rfcnb.
   Each has its own convenience library. Kept separate with original
   filenames to simplify future upgrades or removal.

 * Samba sources have been diffed and compared function by function
   against the copies previously in our sources. Functionality extensions
   we use have been grafted back on top of the new(er) Samba sources.
  - this was mostly around passing extra Unicode, DC hints and pre-crypted
    passwords to the login checks.
  - some files from libntlmauth have yet to be compared in fine detail,
    that will be completed today before merge.
  - some basic API function and struct definitions had to be moved to the
    API headers to prevent needing to include the *-priv.h private
    definitions externally to the library.

 * the Samba API headers have been wrapped with #ifndef safety wrappers

 * compile errors and include changes required to compile have been
   made (code stays C)

 * duplicate code in helpers/basic_auth/MSNT/* and libntlmauth/* is
   removed.

 * abuse of the smblib-priv.h and rfcnb-priv.h headers and all local
   re-definitions has been erased from our code. Replaced by includes 
   of the library API headers: rfcnb/rfcnb.h  smblib/smblib.h


libntlmauth:
 * smblib/rfcnb bits erased
 * moved to lib/ntlmauth in its much reduced form
 * built as a convenience library instead of full library",14917,data/crawl/squid/hunk_2953.cpp,,,data/crawl/squid/old_hunk_2953.cpp,data/crawl/squid/new_hunk_2953.cpp,-1,247,,"fprintf(stderr, ""SMB_SessSetupAndTCon failed with errorclass = %i, Error Code = %i\n"",
                CVAL(SMB_Hdr(pkt), SMB_hdr_rcls_offset),
                SVAL(SMB_Hdr(pkt), SMB_hdr_err_offset));","[""addLog""]","[[], [""fprintf"", ""stderr"", ""SMB_SessSetupAndTCon"", ""failed"", ""with"", ""errorclass"", ""%i"", ""Error"", ""Code"", ""%i\\n"", ""CVAL"", ""SMB_Hdr"", ""pkt"", ""SMB_hdr_rcls_offset"", ""SVAL"", ""SMB_Hdr"", ""pkt"", ""SMB_hdr_err_offset""]]",[23461725029944925512],7084,0.0,3
https://github.com/squid-cache/squid/commit/7c16470cc2d053ea2c540459843227dea08e8b40,16 Oct 2010,"basic_msnt_auth helper and NTLM/SMBLIB/RFCNB library polish.

Samba smblib/rfcnb code:
 * Import the latest copy which I could find a download link to.
   This source is from 1997 so I suspect there is something even newer
   we should be using. Time was tight is the only excuse for using
   these sources. Our originals were from 1995 and 1996 depending on the
   helper using it, with a mix of patches.

 * These two directories are in ours sources as lib/smblib and lib/rfcnb.
   Each has its own convenience library. Kept separate with original
   filenames to simplify future upgrades or removal.

 * Samba sources have been diffed and compared function by function
   against the copies previously in our sources. Functionality extensions
   we use have been grafted back on top of the new(er) Samba sources.
  - this was mostly around passing extra Unicode, DC hints and pre-crypted
    passwords to the login checks.
  - some files from libntlmauth have yet to be compared in fine detail,
    that will be completed today before merge.
  - some basic API function and struct definitions had to be moved to the
    API headers to prevent needing to include the *-priv.h private
    definitions externally to the library.

 * the Samba API headers have been wrapped with #ifndef safety wrappers

 * compile errors and include changes required to compile have been
   made (code stays C)

 * duplicate code in helpers/basic_auth/MSNT/* and libntlmauth/* is
   removed.

 * abuse of the smblib-priv.h and rfcnb-priv.h headers and all local
   re-definitions has been erased from our code. Replaced by includes 
   of the library API headers: rfcnb/rfcnb.h  smblib/smblib.h


libntlmauth:
 * smblib/rfcnb bits erased
 * moved to lib/ntlmauth in its much reduced form
 * built as a convenience library instead of full library",14917,data/crawl/squid/hunk_2953.cpp,,,data/crawl/squid/old_hunk_2953.cpp,data/crawl/squid/new_hunk_2953.cpp,-1,233,,"fprintf(stderr, ""Error receiving response to SessSetupAndTCon\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""Error"", ""receiving"", ""response"", ""to"", ""SessSetupAndTCon\\n""]]",[-9047901430437325038],7083,0.0,3
https://github.com/squid-cache/squid/commit/7c16470cc2d053ea2c540459843227dea08e8b40,16 Oct 2010,"basic_msnt_auth helper and NTLM/SMBLIB/RFCNB library polish.

Samba smblib/rfcnb code:
 * Import the latest copy which I could find a download link to.
   This source is from 1997 so I suspect there is something even newer
   we should be using. Time was tight is the only excuse for using
   these sources. Our originals were from 1995 and 1996 depending on the
   helper using it, with a mix of patches.

 * These two directories are in ours sources as lib/smblib and lib/rfcnb.
   Each has its own convenience library. Kept separate with original
   filenames to simplify future upgrades or removal.

 * Samba sources have been diffed and compared function by function
   against the copies previously in our sources. Functionality extensions
   we use have been grafted back on top of the new(er) Samba sources.
  - this was mostly around passing extra Unicode, DC hints and pre-crypted
    passwords to the login checks.
  - some files from libntlmauth have yet to be compared in fine detail,
    that will be completed today before merge.
  - some basic API function and struct definitions had to be moved to the
    API headers to prevent needing to include the *-priv.h private
    definitions externally to the library.

 * the Samba API headers have been wrapped with #ifndef safety wrappers

 * compile errors and include changes required to compile have been
   made (code stays C)

 * duplicate code in helpers/basic_auth/MSNT/* and libntlmauth/* is
   removed.

 * abuse of the smblib-priv.h and rfcnb-priv.h headers and all local
   re-definitions has been erased from our code. Replaced by includes 
   of the library API headers: rfcnb/rfcnb.h  smblib/smblib.h


libntlmauth:
 * smblib/rfcnb bits erased
 * moved to lib/ntlmauth in its much reduced form
 * built as a convenience library instead of full library",14917,data/crawl/squid/hunk_2953.cpp,,,data/crawl/squid/old_hunk_2953.cpp,data/crawl/squid/new_hunk_2953.cpp,-1,219,,"fprintf(stderr, ""Error sending SessSetupAndTCon request\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""Error"", ""sending"", ""SessSetupAndTCon"", ""request\\n""]]",[7125125016913124162],7082,0.0,3
https://github.com/squid-cache/squid/commit/7c16470cc2d053ea2c540459843227dea08e8b40,16 Oct 2010,"basic_msnt_auth helper and NTLM/SMBLIB/RFCNB library polish.

Samba smblib/rfcnb code:
 * Import the latest copy which I could find a download link to.
   This source is from 1997 so I suspect there is something even newer
   we should be using. Time was tight is the only excuse for using
   these sources. Our originals were from 1995 and 1996 depending on the
   helper using it, with a mix of patches.

 * These two directories are in ours sources as lib/smblib and lib/rfcnb.
   Each has its own convenience library. Kept separate with original
   filenames to simplify future upgrades or removal.

 * Samba sources have been diffed and compared function by function
   against the copies previously in our sources. Functionality extensions
   we use have been grafted back on top of the new(er) Samba sources.
  - this was mostly around passing extra Unicode, DC hints and pre-crypted
    passwords to the login checks.
  - some files from libntlmauth have yet to be compared in fine detail,
    that will be completed today before merge.
  - some basic API function and struct definitions had to be moved to the
    API headers to prevent needing to include the *-priv.h private
    definitions externally to the library.

 * the Samba API headers have been wrapped with #ifndef safety wrappers

 * compile errors and include changes required to compile have been
   made (code stays C)

 * duplicate code in helpers/basic_auth/MSNT/* and libntlmauth/* is
   removed.

 * abuse of the smblib-priv.h and rfcnb-priv.h headers and all local
   re-definitions has been erased from our code. Replaced by includes 
   of the library API headers: rfcnb/rfcnb.h  smblib/smblib.h


libntlmauth:
 * smblib/rfcnb bits erased
 * moved to lib/ntlmauth in its much reduced form
 * built as a convenience library instead of full library",14917,data/crawl/squid/hunk_2952.cpp,,,data/crawl/squid/old_hunk_2952.cpp,data/crawl/squid/new_hunk_2952.cpp,-1,274,,"fprintf(stderr, ""Bad packet return in RFCNB_Recv... \n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""Bad"", ""packet"", ""return"", ""in"", ""RFCNB_Recv"", ""\\n""]]",[-13390460590631321895],7081,1712640.0,3
https://github.com/squid-cache/squid/commit/7c16470cc2d053ea2c540459843227dea08e8b40,16 Oct 2010,"basic_msnt_auth helper and NTLM/SMBLIB/RFCNB library polish.

Samba smblib/rfcnb code:
 * Import the latest copy which I could find a download link to.
   This source is from 1997 so I suspect there is something even newer
   we should be using. Time was tight is the only excuse for using
   these sources. Our originals were from 1995 and 1996 depending on the
   helper using it, with a mix of patches.

 * These two directories are in ours sources as lib/smblib and lib/rfcnb.
   Each has its own convenience library. Kept separate with original
   filenames to simplify future upgrades or removal.

 * Samba sources have been diffed and compared function by function
   against the copies previously in our sources. Functionality extensions
   we use have been grafted back on top of the new(er) Samba sources.
  - this was mostly around passing extra Unicode, DC hints and pre-crypted
    passwords to the login checks.
  - some files from libntlmauth have yet to be compared in fine detail,
    that will be completed today before merge.
  - some basic API function and struct definitions had to be moved to the
    API headers to prevent needing to include the *-priv.h private
    definitions externally to the library.

 * the Samba API headers have been wrapped with #ifndef safety wrappers

 * compile errors and include changes required to compile have been
   made (code stays C)

 * duplicate code in helpers/basic_auth/MSNT/* and libntlmauth/* is
   removed.

 * abuse of the smblib-priv.h and rfcnb-priv.h headers and all local
   re-definitions has been erased from our code. Replaced by includes 
   of the library API headers: rfcnb/rfcnb.h  smblib/smblib.h


libntlmauth:
 * smblib/rfcnb bits erased
 * moved to lib/ntlmauth in its much reduced form
 * built as a convenience library instead of full library",14917,data/crawl/squid/hunk_2946.cpp,,,data/crawl/squid/old_hunk_2946.cpp,data/crawl/squid/new_hunk_2946.cpp,-1,440,,"fprintf(stderr,""Pkt Len = %i, read_len = %i\n"", pkt_len, read_len);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""Pkt"", ""Len"", ""%i"", ""read_len"", ""%i\\n"", ""pkt_len"", ""read_len""]]",[14749515261673248060],7080,1712640.0,3
https://github.com/squid-cache/squid/commit/7c16470cc2d053ea2c540459843227dea08e8b40,16 Oct 2010,"basic_msnt_auth helper and NTLM/SMBLIB/RFCNB library polish.

Samba smblib/rfcnb code:
 * Import the latest copy which I could find a download link to.
   This source is from 1997 so I suspect there is something even newer
   we should be using. Time was tight is the only excuse for using
   these sources. Our originals were from 1995 and 1996 depending on the
   helper using it, with a mix of patches.

 * These two directories are in ours sources as lib/smblib and lib/rfcnb.
   Each has its own convenience library. Kept separate with original
   filenames to simplify future upgrades or removal.

 * Samba sources have been diffed and compared function by function
   against the copies previously in our sources. Functionality extensions
   we use have been grafted back on top of the new(er) Samba sources.
  - this was mostly around passing extra Unicode, DC hints and pre-crypted
    passwords to the login checks.
  - some files from libntlmauth have yet to be compared in fine detail,
    that will be completed today before merge.
  - some basic API function and struct definitions had to be moved to the
    API headers to prevent needing to include the *-priv.h private
    definitions externally to the library.

 * the Samba API headers have been wrapped with #ifndef safety wrappers

 * compile errors and include changes required to compile have been
   made (code stays C)

 * duplicate code in helpers/basic_auth/MSNT/* and libntlmauth/* is
   removed.

 * abuse of the smblib-priv.h and rfcnb-priv.h headers and all local
   re-definitions has been erased from our code. Replaced by includes 
   of the library API headers: rfcnb/rfcnb.h  smblib/smblib.h


libntlmauth:
 * smblib/rfcnb bits erased
 * moved to lib/ntlmauth in its much reduced form
 * built as a convenience library instead of full library",14917,data/crawl/squid/hunk_2946.cpp,,,data/crawl/squid/old_hunk_2946.cpp,data/crawl/squid/new_hunk_2946.cpp,-1,421,,"fprintf(stderr, ""Frag_Len = %i, this_time = %i, this_len = %i, more = %i\n"", frag_len,
                this_time, this_len, more);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""Frag_Len"", ""%i"", ""this_time"", ""%i"", ""this_len"", ""%i"", ""more"", ""%i\\n"", ""frag_len"", ""this_time"", ""this_len"", ""more""]]",[-21986929429100296154],7079,1712640.0,3
https://github.com/squid-cache/squid/commit/7c16470cc2d053ea2c540459843227dea08e8b40,16 Oct 2010,"basic_msnt_auth helper and NTLM/SMBLIB/RFCNB library polish.

Samba smblib/rfcnb code:
 * Import the latest copy which I could find a download link to.
   This source is from 1997 so I suspect there is something even newer
   we should be using. Time was tight is the only excuse for using
   these sources. Our originals were from 1995 and 1996 depending on the
   helper using it, with a mix of patches.

 * These two directories are in ours sources as lib/smblib and lib/rfcnb.
   Each has its own convenience library. Kept separate with original
   filenames to simplify future upgrades or removal.

 * Samba sources have been diffed and compared function by function
   against the copies previously in our sources. Functionality extensions
   we use have been grafted back on top of the new(er) Samba sources.
  - this was mostly around passing extra Unicode, DC hints and pre-crypted
    passwords to the login checks.
  - some files from libntlmauth have yet to be compared in fine detail,
    that will be completed today before merge.
  - some basic API function and struct definitions had to be moved to the
    API headers to prevent needing to include the *-priv.h private
    definitions externally to the library.

 * the Samba API headers have been wrapped with #ifndef safety wrappers

 * compile errors and include changes required to compile have been
   made (code stays C)

 * duplicate code in helpers/basic_auth/MSNT/* and libntlmauth/* is
   removed.

 * abuse of the smblib-priv.h and rfcnb-priv.h headers and all local
   re-definitions has been erased from our code. Replaced by includes 
   of the library API headers: rfcnb/rfcnb.h  smblib/smblib.h


libntlmauth:
 * smblib/rfcnb bits erased
 * moved to lib/ntlmauth in its much reduced form
 * built as a convenience library instead of full library",14917,data/crawl/squid/hunk_2946.cpp,,,data/crawl/squid/old_hunk_2946.cpp,data/crawl/squid/new_hunk_2946.cpp,-1,365,,"fprintf(stderr, ""Reading Pkt: Length = %i\n"", pkt_len);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""Reading"", ""Pkt"", ""Length"", ""%i\\n"", ""pkt_len""]]",[-2546329978924844425],7078,1712640.0,3
https://github.com/squid-cache/squid/commit/7c16470cc2d053ea2c540459843227dea08e8b40,16 Oct 2010,"basic_msnt_auth helper and NTLM/SMBLIB/RFCNB library polish.

Samba smblib/rfcnb code:
 * Import the latest copy which I could find a download link to.
   This source is from 1997 so I suspect there is something even newer
   we should be using. Time was tight is the only excuse for using
   these sources. Our originals were from 1995 and 1996 depending on the
   helper using it, with a mix of patches.

 * These two directories are in ours sources as lib/smblib and lib/rfcnb.
   Each has its own convenience library. Kept separate with original
   filenames to simplify future upgrades or removal.

 * Samba sources have been diffed and compared function by function
   against the copies previously in our sources. Functionality extensions
   we use have been grafted back on top of the new(er) Samba sources.
  - this was mostly around passing extra Unicode, DC hints and pre-crypted
    passwords to the login checks.
  - some files from libntlmauth have yet to be compared in fine detail,
    that will be completed today before merge.
  - some basic API function and struct definitions had to be moved to the
    API headers to prevent needing to include the *-priv.h private
    definitions externally to the library.

 * the Samba API headers have been wrapped with #ifndef safety wrappers

 * compile errors and include changes required to compile have been
   made (code stays C)

 * duplicate code in helpers/basic_auth/MSNT/* and libntlmauth/* is
   removed.

 * abuse of the smblib-priv.h and rfcnb-priv.h headers and all local
   re-definitions has been erased from our code. Replaced by includes 
   of the library API headers: rfcnb/rfcnb.h  smblib/smblib.h


libntlmauth:
 * smblib/rfcnb bits erased
 * moved to lib/ntlmauth in its much reduced form
 * built as a convenience library instead of full library",14917,data/crawl/squid/hunk_2946.cpp,,,data/crawl/squid/old_hunk_2946.cpp,data/crawl/squid/new_hunk_2946.cpp,-1,335,,"fprintf(stderr, ""RFCNB KEEP ALIVE received\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""RFCNB"", ""KEEP"", ""ALIVE"", ""received\\n""]]",[-4094161876581336934],7077,1712640.0,3
https://github.com/squid-cache/squid/commit/7c16470cc2d053ea2c540459843227dea08e8b40,16 Oct 2010,"basic_msnt_auth helper and NTLM/SMBLIB/RFCNB library polish.

Samba smblib/rfcnb code:
 * Import the latest copy which I could find a download link to.
   This source is from 1997 so I suspect there is something even newer
   we should be using. Time was tight is the only excuse for using
   these sources. Our originals were from 1995 and 1996 depending on the
   helper using it, with a mix of patches.

 * These two directories are in ours sources as lib/smblib and lib/rfcnb.
   Each has its own convenience library. Kept separate with original
   filenames to simplify future upgrades or removal.

 * Samba sources have been diffed and compared function by function
   against the copies previously in our sources. Functionality extensions
   we use have been grafted back on top of the new(er) Samba sources.
  - this was mostly around passing extra Unicode, DC hints and pre-crypted
    passwords to the login checks.
  - some files from libntlmauth have yet to be compared in fine detail,
    that will be completed today before merge.
  - some basic API function and struct definitions had to be moved to the
    API headers to prevent needing to include the *-priv.h private
    definitions externally to the library.

 * the Samba API headers have been wrapped with #ifndef safety wrappers

 * compile errors and include changes required to compile have been
   made (code stays C)

 * duplicate code in helpers/basic_auth/MSNT/* and libntlmauth/* is
   removed.

 * abuse of the smblib-priv.h and rfcnb-priv.h headers and all local
   re-definitions has been erased from our code. Replaced by includes 
   of the library API headers: rfcnb/rfcnb.h  smblib/smblib.h


libntlmauth:
 * smblib/rfcnb bits erased
 * moved to lib/ntlmauth in its much reduced form
 * built as a convenience library instead of full library",14917,data/crawl/squid/hunk_2946.cpp,,,data/crawl/squid/old_hunk_2946.cpp,data/crawl/squid/new_hunk_2946.cpp,-1,320,,"fprintf(stderr, ""Connection closed reading\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""Connection"", ""closed"", ""reading\\n""]]",[-3658438838238786031],7076,1712640.0,3
https://github.com/squid-cache/squid/commit/7c16470cc2d053ea2c540459843227dea08e8b40,16 Oct 2010,"basic_msnt_auth helper and NTLM/SMBLIB/RFCNB library polish.

Samba smblib/rfcnb code:
 * Import the latest copy which I could find a download link to.
   This source is from 1997 so I suspect there is something even newer
   we should be using. Time was tight is the only excuse for using
   these sources. Our originals were from 1995 and 1996 depending on the
   helper using it, with a mix of patches.

 * These two directories are in ours sources as lib/smblib and lib/rfcnb.
   Each has its own convenience library. Kept separate with original
   filenames to simplify future upgrades or removal.

 * Samba sources have been diffed and compared function by function
   against the copies previously in our sources. Functionality extensions
   we use have been grafted back on top of the new(er) Samba sources.
  - this was mostly around passing extra Unicode, DC hints and pre-crypted
    passwords to the login checks.
  - some files from libntlmauth have yet to be compared in fine detail,
    that will be completed today before merge.
  - some basic API function and struct definitions had to be moved to the
    API headers to prevent needing to include the *-priv.h private
    definitions externally to the library.

 * the Samba API headers have been wrapped with #ifndef safety wrappers

 * compile errors and include changes required to compile have been
   made (code stays C)

 * duplicate code in helpers/basic_auth/MSNT/* and libntlmauth/* is
   removed.

 * abuse of the smblib-priv.h and rfcnb-priv.h headers and all local
   re-definitions has been erased from our code. Replaced by includes 
   of the library API headers: rfcnb/rfcnb.h  smblib/smblib.h


libntlmauth:
 * smblib/rfcnb bits erased
 * moved to lib/ntlmauth in its much reduced form
 * built as a convenience library instead of full library",14917,data/crawl/squid/hunk_2946.cpp,,,data/crawl/squid/old_hunk_2946.cpp,data/crawl/squid/new_hunk_2946.cpp,-1,303,,"fprintf(stderr, ""Reading the packet, we got:"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""Reading"", ""the"", ""packet"", ""we"", ""got""]]",[-31893954141555588920],7075,1712640.0,3
https://github.com/squid-cache/squid/commit/7c16470cc2d053ea2c540459843227dea08e8b40,16 Oct 2010,"basic_msnt_auth helper and NTLM/SMBLIB/RFCNB library polish.

Samba smblib/rfcnb code:
 * Import the latest copy which I could find a download link to.
   This source is from 1997 so I suspect there is something even newer
   we should be using. Time was tight is the only excuse for using
   these sources. Our originals were from 1995 and 1996 depending on the
   helper using it, with a mix of patches.

 * These two directories are in ours sources as lib/smblib and lib/rfcnb.
   Each has its own convenience library. Kept separate with original
   filenames to simplify future upgrades or removal.

 * Samba sources have been diffed and compared function by function
   against the copies previously in our sources. Functionality extensions
   we use have been grafted back on top of the new(er) Samba sources.
  - this was mostly around passing extra Unicode, DC hints and pre-crypted
    passwords to the login checks.
  - some files from libntlmauth have yet to be compared in fine detail,
    that will be completed today before merge.
  - some basic API function and struct definitions had to be moved to the
    API headers to prevent needing to include the *-priv.h private
    definitions externally to the library.

 * the Samba API headers have been wrapped with #ifndef safety wrappers

 * compile errors and include changes required to compile have been
   made (code stays C)

 * duplicate code in helpers/basic_auth/MSNT/* and libntlmauth/* is
   removed.

 * abuse of the smblib-priv.h and rfcnb-priv.h headers and all local
   re-definitions has been erased from our code. Replaced by includes 
   of the library API headers: rfcnb/rfcnb.h  smblib/smblib.h


libntlmauth:
 * smblib/rfcnb bits erased
 * moved to lib/ntlmauth in its much reduced form
 * built as a convenience library instead of full library",14917,data/crawl/squid/hunk_2946.cpp,,,data/crawl/squid/old_hunk_2946.cpp,data/crawl/squid/new_hunk_2946.cpp,-1,286,,"fprintf(stderr, ""Trying to read less than a packet:"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""Trying"", ""to"", ""read"", ""less"", ""than"", ""a"", ""packet""]]",[-16752697044726255696],7074,1712640.0,3
https://github.com/squid-cache/squid/commit/7c16470cc2d053ea2c540459843227dea08e8b40,16 Oct 2010,"basic_msnt_auth helper and NTLM/SMBLIB/RFCNB library polish.

Samba smblib/rfcnb code:
 * Import the latest copy which I could find a download link to.
   This source is from 1997 so I suspect there is something even newer
   we should be using. Time was tight is the only excuse for using
   these sources. Our originals were from 1995 and 1996 depending on the
   helper using it, with a mix of patches.

 * These two directories are in ours sources as lib/smblib and lib/rfcnb.
   Each has its own convenience library. Kept separate with original
   filenames to simplify future upgrades or removal.

 * Samba sources have been diffed and compared function by function
   against the copies previously in our sources. Functionality extensions
   we use have been grafted back on top of the new(er) Samba sources.
  - this was mostly around passing extra Unicode, DC hints and pre-crypted
    passwords to the login checks.
  - some files from libntlmauth have yet to be compared in fine detail,
    that will be completed today before merge.
  - some basic API function and struct definitions had to be moved to the
    API headers to prevent needing to include the *-priv.h private
    definitions externally to the library.

 * the Samba API headers have been wrapped with #ifndef safety wrappers

 * compile errors and include changes required to compile have been
   made (code stays C)

 * duplicate code in helpers/basic_auth/MSNT/* and libntlmauth/* is
   removed.

 * abuse of the smblib-priv.h and rfcnb-priv.h headers and all local
   re-definitions has been erased from our code. Replaced by includes 
   of the library API headers: rfcnb/rfcnb.h  smblib/smblib.h


libntlmauth:
 * smblib/rfcnb bits erased
 * moved to lib/ntlmauth in its much reduced form
 * built as a convenience library instead of full library",14917,data/crawl/squid/hunk_2946.cpp,,,data/crawl/squid/old_hunk_2946.cpp,data/crawl/squid/new_hunk_2946.cpp,-1,255,,"fprintf(stderr, ""Len sent = %i ...\n"", len_sent);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""Len"", ""sent"", ""%i"", ""\\n"", ""len_sent""]]",[-1761508097882951492],7073,1712640.0,3
https://github.com/squid-cache/squid/commit/7c16470cc2d053ea2c540459843227dea08e8b40,16 Oct 2010,"basic_msnt_auth helper and NTLM/SMBLIB/RFCNB library polish.

Samba smblib/rfcnb code:
 * Import the latest copy which I could find a download link to.
   This source is from 1997 so I suspect there is something even newer
   we should be using. Time was tight is the only excuse for using
   these sources. Our originals were from 1995 and 1996 depending on the
   helper using it, with a mix of patches.

 * These two directories are in ours sources as lib/smblib and lib/rfcnb.
   Each has its own convenience library. Kept separate with original
   filenames to simplify future upgrades or removal.

 * Samba sources have been diffed and compared function by function
   against the copies previously in our sources. Functionality extensions
   we use have been grafted back on top of the new(er) Samba sources.
  - this was mostly around passing extra Unicode, DC hints and pre-crypted
    passwords to the login checks.
  - some files from libntlmauth have yet to be compared in fine detail,
    that will be completed today before merge.
  - some basic API function and struct definitions had to be moved to the
    API headers to prevent needing to include the *-priv.h private
    definitions externally to the library.

 * the Samba API headers have been wrapped with #ifndef safety wrappers

 * compile errors and include changes required to compile have been
   made (code stays C)

 * duplicate code in helpers/basic_auth/MSNT/* and libntlmauth/* is
   removed.

 * abuse of the smblib-priv.h and rfcnb-priv.h headers and all local
   re-definitions has been erased from our code. Replaced by includes 
   of the library API headers: rfcnb/rfcnb.h  smblib/smblib.h


libntlmauth:
 * smblib/rfcnb bits erased
 * moved to lib/ntlmauth in its much reduced form
 * built as a convenience library instead of full library",14917,data/crawl/squid/hunk_2946.cpp,,,data/crawl/squid/old_hunk_2946.cpp,data/crawl/squid/new_hunk_2946.cpp,-1,221,,"fprintf(stderr, ""Frags = %i, tot_sent = %i\n"", i, tot_sent);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""Frags"", ""%i"", ""tot_sent"", ""%i\\n"", ""i"", ""tot_sent""]]",[386152058147198788],7072,1712640.0,3
https://github.com/squid-cache/squid/commit/7c16470cc2d053ea2c540459843227dea08e8b40,16 Oct 2010,"basic_msnt_auth helper and NTLM/SMBLIB/RFCNB library polish.

Samba smblib/rfcnb code:
 * Import the latest copy which I could find a download link to.
   This source is from 1997 so I suspect there is something even newer
   we should be using. Time was tight is the only excuse for using
   these sources. Our originals were from 1995 and 1996 depending on the
   helper using it, with a mix of patches.

 * These two directories are in ours sources as lib/smblib and lib/rfcnb.
   Each has its own convenience library. Kept separate with original
   filenames to simplify future upgrades or removal.

 * Samba sources have been diffed and compared function by function
   against the copies previously in our sources. Functionality extensions
   we use have been grafted back on top of the new(er) Samba sources.
  - this was mostly around passing extra Unicode, DC hints and pre-crypted
    passwords to the login checks.
  - some files from libntlmauth have yet to be compared in fine detail,
    that will be completed today before merge.
  - some basic API function and struct definitions had to be moved to the
    API headers to prevent needing to include the *-priv.h private
    definitions externally to the library.

 * the Samba API headers have been wrapped with #ifndef safety wrappers

 * compile errors and include changes required to compile have been
   made (code stays C)

 * duplicate code in helpers/basic_auth/MSNT/* and libntlmauth/* is
   removed.

 * abuse of the smblib-priv.h and rfcnb-priv.h headers and all local
   re-definitions has been erased from our code. Replaced by includes 
   of the library API headers: rfcnb/rfcnb.h  smblib/smblib.h


libntlmauth:
 * smblib/rfcnb bits erased
 * moved to lib/ntlmauth in its much reduced form
 * built as a convenience library instead of full library",14917,data/crawl/squid/hunk_2946.cpp,,,data/crawl/squid/old_hunk_2946.cpp,data/crawl/squid/new_hunk_2946.cpp,-1,141,,"fprintf(stderr, ""Discard_Rest called to discard: %i\n"", len);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""Discard_Rest"", ""called"", ""to"", ""discard"", ""%i\\n"", ""len""]]",[-2698513984810611498],7071,1712640.0,3
https://github.com/squid-cache/squid/commit/7c16470cc2d053ea2c540459843227dea08e8b40,16 Oct 2010,"basic_msnt_auth helper and NTLM/SMBLIB/RFCNB library polish.

Samba smblib/rfcnb code:
 * Import the latest copy which I could find a download link to.
   This source is from 1997 so I suspect there is something even newer
   we should be using. Time was tight is the only excuse for using
   these sources. Our originals were from 1995 and 1996 depending on the
   helper using it, with a mix of patches.

 * These two directories are in ours sources as lib/smblib and lib/rfcnb.
   Each has its own convenience library. Kept separate with original
   filenames to simplify future upgrades or removal.

 * Samba sources have been diffed and compared function by function
   against the copies previously in our sources. Functionality extensions
   we use have been grafted back on top of the new(er) Samba sources.
  - this was mostly around passing extra Unicode, DC hints and pre-crypted
    passwords to the login checks.
  - some files from libntlmauth have yet to be compared in fine detail,
    that will be completed today before merge.
  - some basic API function and struct definitions had to be moved to the
    API headers to prevent needing to include the *-priv.h private
    definitions externally to the library.

 * the Samba API headers have been wrapped with #ifndef safety wrappers

 * compile errors and include changes required to compile have been
   made (code stays C)

 * duplicate code in helpers/basic_auth/MSNT/* and libntlmauth/* is
   removed.

 * abuse of the smblib-priv.h and rfcnb-priv.h headers and all local
   re-definitions has been erased from our code. Replaced by includes 
   of the library API headers: rfcnb/rfcnb.h  smblib/smblib.h


libntlmauth:
 * smblib/rfcnb bits erased
 * moved to lib/ntlmauth in its much reduced form
 * built as a convenience library instead of full library",14917,data/crawl/squid/hunk_2946.cpp,,,data/crawl/squid/old_hunk_2946.cpp,data/crawl/squid/new_hunk_2946.cpp,-1,47,,"fprintf(stderr, ""IO Timed out ...\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""IO"", ""Timed"", ""out"", ""\\n""]]",[-18858184016081431633],7070,1712640.0,3
https://github.com/squid-cache/squid/commit/7c16470cc2d053ea2c540459843227dea08e8b40,16 Oct 2010,"basic_msnt_auth helper and NTLM/SMBLIB/RFCNB library polish.

Samba smblib/rfcnb code:
 * Import the latest copy which I could find a download link to.
   This source is from 1997 so I suspect there is something even newer
   we should be using. Time was tight is the only excuse for using
   these sources. Our originals were from 1995 and 1996 depending on the
   helper using it, with a mix of patches.

 * These two directories are in ours sources as lib/smblib and lib/rfcnb.
   Each has its own convenience library. Kept separate with original
   filenames to simplify future upgrades or removal.

 * Samba sources have been diffed and compared function by function
   against the copies previously in our sources. Functionality extensions
   we use have been grafted back on top of the new(er) Samba sources.
  - this was mostly around passing extra Unicode, DC hints and pre-crypted
    passwords to the login checks.
  - some files from libntlmauth have yet to be compared in fine detail,
    that will be completed today before merge.
  - some basic API function and struct definitions had to be moved to the
    API headers to prevent needing to include the *-priv.h private
    definitions externally to the library.

 * the Samba API headers have been wrapped with #ifndef safety wrappers

 * compile errors and include changes required to compile have been
   made (code stays C)

 * duplicate code in helpers/basic_auth/MSNT/* and libntlmauth/* is
   removed.

 * abuse of the smblib-priv.h and rfcnb-priv.h headers and all local
   re-definitions has been erased from our code. Replaced by includes 
   of the library API headers: rfcnb/rfcnb.h  smblib/smblib.h


libntlmauth:
 * smblib/rfcnb bits erased
 * moved to lib/ntlmauth in its much reduced form
 * built as a convenience library instead of full library",14917,data/crawl/squid/hunk_2943.cpp,,,data/crawl/squid/old_hunk_2943.cpp,data/crawl/squid/new_hunk_2943.cpp,205,-1,"fprintf(stderr, ""Sending packet: "");",,"[""removeLog""]","[[""fprintf"", ""stderr"", ""Sending"", ""packet""], []]",[23441903884649910407],7069,0.0,3
https://github.com/squid-cache/squid/commit/25f983407b3c3df95d9f81edf1bd917316f2dfda,01 Nov 2010,"Bug 3038: Detatch libmisc from libcompat

* Migrates many of the remaining libmisc portability wrappers into
  libcompat.

* Splits libmisc into:
   libprofiler - Squid internal profiler (developer-only)
   libmiscencoding - Various binary encoding / crypto algorithms
   libmisccontainers - Various data container algorithms

* Makes all binaries which need to link the libmisc* pieces directly instead
  of via $(COMPAT_LIB) which now only links the libcompat and internal
  profiler due to profiling being used on some libcompat functions.

* Adds a stub_debug for binaries needing the Debug.h API without squid
  timers and globals.

Some effort has been made to identify binaries whose dependencies can be
reduced. More of this dependency removal can be done in future.",2111,data/crawl/squid/hunk_2901.cpp,,,data/crawl/squid/old_hunk_2901.cpp,data/crawl/squid/new_hunk_2901.cpp,-1,117,,"_db_print(""%s\n"", CurrentDebug->str().c_str());","[""addLog""]","[[], [""_db_print"", ""%s\\n"", ""CurrentDebug"", ""str"", ""c_str""]]",[6980861486925073934],7068,1283040.0,3
https://github.com/squid-cache/squid/commit/25f983407b3c3df95d9f81edf1bd917316f2dfda,01 Nov 2010,"Bug 3038: Detatch libmisc from libcompat

* Migrates many of the remaining libmisc portability wrappers into
  libcompat.

* Splits libmisc into:
   libprofiler - Squid internal profiler (developer-only)
   libmiscencoding - Various binary encoding / crypto algorithms
   libmisccontainers - Various data container algorithms

* Makes all binaries which need to link the libmisc* pieces directly instead
  of via $(COMPAT_LIB) which now only links the libcompat and internal
  profiler due to profiling being used on some libcompat functions.

* Adds a stub_debug for binaries needing the Debug.h API without squid
  timers and globals.

Some effort has been made to identify binaries whose dependencies can be
reduced. More of this dependency removal can be done in future.",2111,data/crawl/squid/hunk_2897.cpp,,,data/crawl/squid/old_hunk_2897.cpp,data/crawl/squid/new_hunk_2897.cpp,-1,224,,"fprintf(tracefp, ""f:%p\n"", s);","[""addLog""]","[[], [""fprintf"", ""tracefp"", ""f"", ""%p\\n"", ""s""]]",[-4185219475741869808],7067,13440.0,3
https://github.com/squid-cache/squid/commit/25f983407b3c3df95d9f81edf1bd917316f2dfda,01 Nov 2010,"Bug 3038: Detatch libmisc from libcompat

* Migrates many of the remaining libmisc portability wrappers into
  libcompat.

* Splits libmisc into:
   libprofiler - Squid internal profiler (developer-only)
   libmiscencoding - Various binary encoding / crypto algorithms
   libmisccontainers - Various data container algorithms

* Makes all binaries which need to link the libmisc* pieces directly instead
  of via $(COMPAT_LIB) which now only links the libcompat and internal
  profiler due to profiling being used on some libcompat functions.

* Adds a stub_debug for binaries needing the Debug.h API without squid
  timers and globals.

Some effort has been made to identify binaries whose dependencies can be
reduced. More of this dependency removal can be done in future.",2111,data/crawl/squid/hunk_2897.cpp,,,data/crawl/squid/old_hunk_2897.cpp,data/crawl/squid/new_hunk_2897.cpp,-1,140,,"fprintf(tracefp, ""m:%d:%p\n"", sz, p);","[""addLog""]","[[], [""fprintf"", ""tracefp"", ""m"", ""%d"", ""%p\\n"", ""sz"", ""p""]]",[-4165763358341692610],7066,13440.0,3
https://github.com/squid-cache/squid/commit/25f983407b3c3df95d9f81edf1bd917316f2dfda,01 Nov 2010,"Bug 3038: Detatch libmisc from libcompat

* Migrates many of the remaining libmisc portability wrappers into
  libcompat.

* Splits libmisc into:
   libprofiler - Squid internal profiler (developer-only)
   libmiscencoding - Various binary encoding / crypto algorithms
   libmisccontainers - Various data container algorithms

* Makes all binaries which need to link the libmisc* pieces directly instead
  of via $(COMPAT_LIB) which now only links the libcompat and internal
  profiler due to profiling being used on some libcompat functions.

* Adds a stub_debug for binaries needing the Debug.h API without squid
  timers and globals.

Some effort has been made to identify binaries whose dependencies can be
reduced. More of this dependency removal can be done in future.",2111,data/crawl/squid/hunk_2897.cpp,,,data/crawl/squid/old_hunk_2897.cpp,data/crawl/squid/new_hunk_2897.cpp,-1,99,,"fprintf(tracefp, ""c:%u:%u:%p\n"", (unsigned int) n, (unsigned int) sz, p);","[""addLog""]","[[], [""fprintf"", ""tracefp"", ""c"", ""%u"", ""%u"", ""%p\\n"", ""unsigned"", ""int"", ""n"", ""unsigned"", ""int"", ""sz"", ""p""]]",[-33602757814329880716],7065,13440.0,3
https://github.com/squid-cache/squid/commit/12e11a5c0e2d896840e65b724f7afa47b5d575ad,04 Dec 2010,"Bug 3068: Actually make SwapDir capacity fields 64-bit.

This one uses uint64_t instead of size_t. It's a bit wider reaching than
the earlier commit since much of the existing code used size_t.",82,data/crawl/squid/hunk_2873.cpp,,,data/crawl/squid/old_hunk_2873.cpp,data/crawl/squid/new_hunk_2873.cpp,3,3,"storeAppendPrintf(&sentry, ""Maximum Size: %Zu KB\n"", max_size);","storeAppendPrintf(&sentry, ""Maximum Size: %""PRIu64"" KB\n"", max_size);","[""updateContent"", ""addContent"", ""addVariable""]","[[""%Zu""], [""%"", ""PRIu64""]]",[12007996375015214115],7064,0.0,3
https://github.com/squid-cache/squid/commit/12e11a5c0e2d896840e65b724f7afa47b5d575ad,04 Dec 2010,"Bug 3068: Actually make SwapDir capacity fields 64-bit.

This one uses uint64_t instead of size_t. It's a bit wider reaching than
the earlier commit since much of the existing code used size_t.",82,data/crawl/squid/hunk_2871.cpp,,,data/crawl/squid/old_hunk_2871.cpp,data/crawl/squid/new_hunk_2871.cpp,3,3,"storeAppendPrintf(&sentry, ""Maximum Size: %Zu KB\n"", max_size);","storeAppendPrintf(&sentry, ""Maximum Size: %lu KB\n"", max_size);","[""updateContent""]","[[""%Zu""], [""%lu""]]",[-17999946],7063,0.0,3
https://github.com/squid-cache/squid/commit/f931485ad46b26cb67d4f982ac671372227c85f4,11 Jan 2011,Portability fix: removed unused code from smblib,34,data/crawl/squid/hunk_2810.cpp,,,data/crawl/squid/old_hunk_2810.cpp,data/crawl/squid/new_hunk_2810.cpp,13,-1,"fprintf(stderr, ""Setting no-delay on TCP socket failed ...\n"");",,"[""removeLog""]","[[""fprintf"", ""stderr"", ""Setting"", ""no"", ""delay"", ""on"", ""TCP"", ""socket"", ""failed"", ""\\n""], []]",[7235141140431330927],7062,2957280.0,3
https://github.com/squid-cache/squid/commit/995eb827aaa64d9bcd4110b756e04051ef9d03e9,02 Mar 2011,merge from trunk,12916,data/crawl/squid/hunk_2740.cpp,,,data/crawl/squid/old_hunk_2740.cpp,data/crawl/squid/new_hunk_2740.cpp,93,-1,"buf.Printf("" [FD %d, requestId %u]"", fd, requestId);",,"[""removeLog""]","[[""buf"", ""Printf"", ""[FD"", ""%d"", ""requestId"", ""%u]"", ""fd"", ""requestId""], []]",[-25233463667732629772],7061,27360.0,3
https://github.com/squid-cache/squid/commit/995eb827aaa64d9bcd4110b756e04051ef9d03e9,02 Mar 2011,merge from trunk,12916,data/crawl/squid/hunk_2739.cpp,,,data/crawl/squid/old_hunk_2739.cpp,data/crawl/squid/new_hunk_2739.cpp,4,-1,mustStop(reason);,,"[""removeLog""]","[[""mustStop"", ""reason""], []]",[12168142237827300475],7060,27360.0,3
https://github.com/squid-cache/squid/commit/995eb827aaa64d9bcd4110b756e04051ef9d03e9,02 Mar 2011,merge from trunk,12916,data/crawl/squid/hunk_2738.cpp,,,data/crawl/squid/old_hunk_2738.cpp,data/crawl/squid/new_hunk_2738.cpp,-1,7,,"mustStop(""long URI"");","[""addLog""]","[[], [""mustStop"", ""long"", ""URI""]]",[-5711881963993431090],7059,27360.0,3
https://github.com/squid-cache/squid/commit/995eb827aaa64d9bcd4110b756e04051ef9d03e9,02 Mar 2011,merge from trunk,12916,data/crawl/squid/hunk_2735.cpp,,,data/crawl/squid/old_hunk_2735.cpp,data/crawl/squid/new_hunk_2735.cpp,-1,202,,"buf.Printf("" [request->requestId %u]"", request->requestId);","[""addLog""]","[[], [""buf"", ""Printf"", ""[request"", ""requestId"", ""%u]"", ""request"", ""requestId""]]",[7296075189643111955],7058,27360.0,3
https://github.com/squid-cache/squid/commit/995eb827aaa64d9bcd4110b756e04051ef9d03e9,02 Mar 2011,merge from trunk,12916,data/crawl/squid/hunk_2734.cpp,,,data/crawl/squid/old_hunk_2734.cpp,data/crawl/squid/new_hunk_2734.cpp,-1,121,,"mustStop(""timeout"");","[""addLog""]","[[], [""mustStop"", ""timeout""]]",[-5542715327692713175],7057,27360.0,3
https://github.com/squid-cache/squid/commit/995eb827aaa64d9bcd4110b756e04051ef9d03e9,02 Mar 2011,merge from trunk,12916,data/crawl/squid/hunk_2729.cpp,,,data/crawl/squid/old_hunk_2729.cpp,data/crawl/squid/new_hunk_2729.cpp,-1,6,,"storeAppendPrintf(sentry, ""FQDNcache Entries Cached: %d\n"",
                      fqdncacheCount());","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""FQDNcache"", ""Entries"", ""Cached"", ""%d\\n"", ""fqdncacheCount""]]",[11149010967697573662],7056,19200.0,3
https://github.com/squid-cache/squid/commit/995eb827aaa64d9bcd4110b756e04051ef9d03e9,02 Mar 2011,merge from trunk,12916,data/crawl/squid/hunk_2722.cpp,,,data/crawl/squid/old_hunk_2722.cpp,data/crawl/squid/new_hunk_2722.cpp,-1,19,,"fatalf(""FATAL: error while accepting new client connection: %s\n"", e.what());","[""addLog""]","[[], [""fatalf"", ""FATAL"", ""error"", ""while"", ""accepting"", ""new"", ""client"", ""connection"", ""%s\\n"", ""e"", ""what""]]",[21925932187621116973],7055,20160.0,3
https://github.com/squid-cache/squid/commit/995eb827aaa64d9bcd4110b756e04051ef9d03e9,02 Mar 2011,merge from trunk,12916,data/crawl/squid/hunk_2721.cpp,,,data/crawl/squid/old_hunk_2721.cpp,data/crawl/squid/new_hunk_2721.cpp,-1,94,,"buf.Printf("" FD %d, %s"",fd, ipbuf);","[""addLog""]","[[], [""buf"", ""Printf"", ""FD"", ""%d"", ""%s"", ""fd"", ""ipbuf""]]",[7907134041917515033],7054,20160.0,3
https://github.com/squid-cache/squid/commit/995eb827aaa64d9bcd4110b756e04051ef9d03e9,02 Mar 2011,merge from trunk,12916,data/crawl/squid/hunk_2718.cpp,,,data/crawl/squid/old_hunk_2718.cpp,data/crawl/squid/new_hunk_2718.cpp,11,11,fatal(msgIfFail);,"fatalf(""Unable to open %s"",FdNote(portType));","[""updateVariable"", ""updateLog"", ""addContent"", ""addVariable""]","[[""fatal"", ""msgIfFail""], [""fatalf"", ""Unable"", ""to"", ""open"", ""%s"", ""FdNote"", ""portType""]]",[39279313673191983323],7053,20160.0,3
https://github.com/squid-cache/squid/commit/995eb827aaa64d9bcd4110b756e04051ef9d03e9,02 Mar 2011,merge from trunk,12916,data/crawl/squid/hunk_2711.cpp,,,data/crawl/squid/old_hunk_2711.cpp,data/crawl/squid/new_hunk_2711.cpp,-1,8,,"mb->Printf(""\tvary_headers: %s\n"", vary_headers);","[""addLog""]","[[], [""mb"", ""Printf"", ""\\tvary_headers"", ""%s\\n"", ""vary_headers""]]",[9692894893635809932],7052,19200.0,3
https://github.com/squid-cache/squid/commit/ffce5f58438c9a15c0351c7b038fd300228cbcb2,09 Mar 2011,"Support libecap v0.2.0; fixed eCAP body handling and logging.

Summary of changes:

libecap v0.2.0 support: accept/update/log eCAP transaction meta-info.
libecap v0.2.0 support: supply client IP and username to eCAP adapter.
libecap v0.1.0 support: Support blockVirgin() API with ERR_ACCESS_DENIED.

Use pkg-config's PKG_CHECK_MODULES to check for and link with libecap.

Support adapter-specific parameters as a part of ecap_service configuration.
Allow uri=value parameter when specifying adaptation service URIs.

Fixed virgin body handling in our eCAP transaction wrapper (Ecap::XactionRep).
Fixed BodyPipe.cc:144 ""!theConsumer"" assertion.

Log ""important"" messages from eCAP adapters with DBG_IMPORTANT not DBG_DATA!

Added XXXs to identify old unrelated problems to be fixed separately.",1302,data/crawl/squid/hunk_2696.cpp,,,data/crawl/squid/old_hunk_2696.cpp,data/crawl/squid/new_hunk_2696.cpp,-1,9,,"(abortOnBadEntry(""entry went bad while ICAP aborted"");","[""addLog""]","[[], [""abortOnBadEntry"", ""entry"", ""went"", ""bad"", ""while"", ""ICAP"", ""aborted""]]",[-15089254301519600519],7051,1335360.0,3
https://github.com/squid-cache/squid/commit/eb3dea38c796fbf091b023e98e832b053c750453,15 Apr 2011,"negotiate_wrapper_auth: version 1.0.1

A helper to perform Negotaite authentication in both its Negotiate/NTLM
and Negotiate/Kerberos forms.
Makes use of additional Squid helpers after unwrapping the header token.",516,data/crawl/squid/hunk_2654.cpp,,,data/crawl/squid/old_hunk_2654.cpp,data/crawl/squid/new_hunk_2654.cpp,-1,159,,"fprintf(stderr, ""%s| %s: Starting version %s\n"", LogTime(), PROGRAM,
                VERSION);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""%s"", ""%s"", ""Starting"", ""version"", ""%s\\n"", ""LogTime"", ""PROGRAM"", ""VERSION""]]",[-3293571494806197117],7050,444960.0,3
https://github.com/squid-cache/squid/commit/eb3dea38c796fbf091b023e98e832b053c750453,15 Apr 2011,"negotiate_wrapper_auth: version 1.0.1

A helper to perform Negotaite authentication in both its Negotiate/NTLM
and Negotiate/Kerberos forms.
Makes use of additional Squid helpers after unwrapping the header token.",516,data/crawl/squid/hunk_2654.cpp,,,data/crawl/squid/old_hunk_2654.cpp,data/crawl/squid/new_hunk_2654.cpp,-1,95,,"fprintf(stderr, ""Usage: \n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""Usage"", ""\\n""]]",[-16792158364100634950],7049,387360.0,3
https://github.com/squid-cache/squid/commit/cc34568dd6d1a7fa78a4db8927f9d21437d84bbb,27 Apr 2011,"Change SwapDir::max_size to bytes, make it protected, use maxSize() instead.",153,data/crawl/squid/hunk_2623.cpp,,,data/crawl/squid/old_hunk_2623.cpp,data/crawl/squid/new_hunk_2623.cpp,6,5,"storeAppendPrintf(&sentry, ""Current Size: %.2f KB\n"", currentSizeInKB);","storeAppendPrintf(&sentry, ""Current Size: %.2f KB\n"", currentSize() / 1024.0);","[""removeVariable"", ""addContent"", ""addVariable""]","[[""currentSizeInKB""], [""currentSize"", ""/"", ""1024"", ""0""]]",[-12190290789123435782],7048,0.0,3
https://github.com/squid-cache/squid/commit/7afc3bf21fb00bef3e0cdc93145bcb4d2bf5a29f,08 May 2011,"Cleanup: sync NTLM and Negotiate UserRequest code

Minor tweaks to reduce diff between the files. No logic changes.

Renames the addHeader() to addAuthentiocationInfoHeader(),
Renames the addTrailer() to addAuthentiocationInfoTrailer() and
document that they add additional *-Info header to the HTTP reply.",315,data/crawl/squid/hunk_2613.cpp,,,data/crawl/squid/old_hunk_2613.cpp,data/crawl/squid/new_hunk_2613.cpp,-1,31,,"httpHeaderPutStrf(&rep->header, type, ""Negotiate %s"", server_blob);","[""addLog""]","[[], [""httpHeaderPutStrf"", ""&rep"", ""header"", ""type"", ""Negotiate"", ""%s"", ""server_blob""]]",[-12596721475175719257],7047,1778880.0,3
https://github.com/squid-cache/squid/commit/63f03f790981f8411a7a5ffd6c91ff3c5f988ea8,20 Jul 2011,Bug 3248: login=NEGOTIATE sends wrong auth header to origin peers,10,data/crawl/squid/hunk_2522.cpp,,,data/crawl/squid/old_hunk_2522.cpp,data/crawl/squid/new_hunk_2522.cpp,3,3,"httpHeaderPutStrf(hdr_out, HDR_PROXY_AUTHORIZATION, ""Negotiate %s"",Token);","httpHeaderPutStrf(hdr_out, header, ""Negotiate %s"",Token);","[""updateVariable""]","[[""HDR_PROXY_AUTHORIZATION""], [""header""]]",[-9782990965685720069],7046,332160.0,3
https://github.com/squid-cache/squid/commit/38e16f927fb0ac854e8a6bfec90f49af5ef1f6eb,04 Aug 2011,"SourceLayout: format namespace for custom tag-based formats

Part 1 of enabling non-logging components to support custom formats in strings

Shuffle the log custom format code into its own library separate from the
logging functionality.

One minor logic change removing redundant LogFileEnabled flag.

TODO:
 - use MemBuf instead or as well as StoreEntry as the output buffer
 - separate from AccessLogEntry confusion
 - upgrade deny_info URL generation format
 - upgrade external_acl_type format
 - add custom helper formats",3483,data/crawl/squid/hunk_2502.cpp,,,data/crawl/squid/old_hunk_2502.cpp,data/crawl/squid/new_hunk_2502.cpp,-1,297,,"fatalf(""Can't parse configuration token: '%s'\n"",
               def);","[""addLog""]","[[], [""fatalf"", ""Can"", ""t"", ""parse"", ""configuration"", ""token"", ""%s"", ""\\n"", ""def""]]",[10658322044005221237],7045,2719200.0,3
https://github.com/squid-cache/squid/commit/38e16f927fb0ac854e8a6bfec90f49af5ef1f6eb,04 Aug 2011,"SourceLayout: format namespace for custom tag-based formats

Part 1 of enabling non-logging components to support custom formats in strings

Shuffle the log custom format code into its own library separate from the
logging functionality.

One minor logic change removing redundant LogFileEnabled flag.

TODO:
 - use MemBuf instead or as well as StoreEntry as the output buffer
 - separate from AccessLogEntry confusion
 - upgrade deny_info URL generation format
 - upgrade external_acl_type format
 - add custom helper formats",3483,data/crawl/squid/hunk_2501.cpp,,,data/crawl/squid/old_hunk_2501.cpp,data/crawl/squid/new_hunk_2501.cpp,-1,1051,,"mb.Printf(""%*s"", (int) fmt->width, out);","[""addLog""]","[[], [""mb"", ""Printf"", ""%*s"", ""int"", ""fmt"", ""width"", ""out""]]",[-7314084157223720897],7044,1948320.0,3
https://github.com/squid-cache/squid/commit/38e16f927fb0ac854e8a6bfec90f49af5ef1f6eb,04 Aug 2011,"SourceLayout: format namespace for custom tag-based formats

Part 1 of enabling non-logging components to support custom formats in strings

Shuffle the log custom format code into its own library separate from the
logging functionality.

One minor logic change removing redundant LogFileEnabled flag.

TODO:
 - use MemBuf instead or as well as StoreEntry as the output buffer
 - separate from AccessLogEntry confusion
 - upgrade deny_info URL generation format
 - upgrade external_acl_type format
 - add custom helper formats",3483,data/crawl/squid/hunk_2501.cpp,,,data/crawl/squid/old_hunk_2501.cpp,data/crawl/squid/new_hunk_2501.cpp,-1,1049,,"mb.Printf(""%-*s"", (int) fmt->width, out);","[""addLog""]","[[], [""mb"", ""Printf"", ""%"", ""*s"", ""int"", ""fmt"", ""width"", ""out""]]",[-2538142304887021005],7043,1948320.0,3
https://github.com/squid-cache/squid/commit/38e16f927fb0ac854e8a6bfec90f49af5ef1f6eb,04 Aug 2011,"SourceLayout: format namespace for custom tag-based formats

Part 1 of enabling non-logging components to support custom formats in strings

Shuffle the log custom format code into its own library separate from the
logging functionality.

One minor logic change removing redundant LogFileEnabled flag.

TODO:
 - use MemBuf instead or as well as StoreEntry as the output buffer
 - separate from AccessLogEntry confusion
 - upgrade deny_info URL generation format
 - upgrade external_acl_type format
 - add custom helper formats",3483,data/crawl/squid/hunk_2501.cpp,,,data/crawl/squid/old_hunk_2501.cpp,data/crawl/squid/new_hunk_2501.cpp,-1,230,,"storeAppendPrintf(entry, ""%s"", te->config);","[""addLog""]","[[], [""storeAppendPrintf"", ""entry"", ""%s"", ""te"", ""config""]]",[5261554217450138221],7042,2719200.0,3
https://github.com/squid-cache/squid/commit/38e16f927fb0ac854e8a6bfec90f49af5ef1f6eb,04 Aug 2011,"SourceLayout: format namespace for custom tag-based formats

Part 1 of enabling non-logging components to support custom formats in strings

Shuffle the log custom format code into its own library separate from the
logging functionality.

One minor logic change removing redundant LogFileEnabled flag.

TODO:
 - use MemBuf instead or as well as StoreEntry as the output buffer
 - separate from AccessLogEntry confusion
 - upgrade deny_info URL generation format
 - upgrade external_acl_type format
 - add custom helper formats",3483,data/crawl/squid/hunk_2501.cpp,,,data/crawl/squid/old_hunk_2501.cpp,data/crawl/squid/new_hunk_2501.cpp,-1,226,,"storeAppendPrintf(entry, ""{%s}"", arg);","[""addLog""]","[[], [""storeAppendPrintf"", ""entry"", ""%s"", ""arg""]]",[5370724308728515853],7041,2719200.0,3
https://github.com/squid-cache/squid/commit/38e16f927fb0ac854e8a6bfec90f49af5ef1f6eb,04 Aug 2011,"SourceLayout: format namespace for custom tag-based formats

Part 1 of enabling non-logging components to support custom formats in strings

Shuffle the log custom format code into its own library separate from the
logging functionality.

One minor logic change removing redundant LogFileEnabled flag.

TODO:
 - use MemBuf instead or as well as StoreEntry as the output buffer
 - separate from AccessLogEntry confusion
 - upgrade deny_info URL generation format
 - upgrade external_acl_type format
 - add custom helper formats",3483,data/crawl/squid/hunk_2501.cpp,,,data/crawl/squid/old_hunk_2501.cpp,data/crawl/squid/new_hunk_2501.cpp,-1,223,,"storeAppendPrintf(entry, "".%d"", (int) t->precision);","[""addLog""]","[[], [""storeAppendPrintf"", ""entry"", ""%d"", ""int"", ""t"", ""precision""]]",[-10961276620916630613],7040,2719200.0,3
https://github.com/squid-cache/squid/commit/38e16f927fb0ac854e8a6bfec90f49af5ef1f6eb,04 Aug 2011,"SourceLayout: format namespace for custom tag-based formats

Part 1 of enabling non-logging components to support custom formats in strings

Shuffle the log custom format code into its own library separate from the
logging functionality.

One minor logic change removing redundant LogFileEnabled flag.

TODO:
 - use MemBuf instead or as well as StoreEntry as the output buffer
 - separate from AccessLogEntry confusion
 - upgrade deny_info URL generation format
 - upgrade external_acl_type format
 - add custom helper formats",3483,data/crawl/squid/hunk_2501.cpp,,,data/crawl/squid/old_hunk_2501.cpp,data/crawl/squid/new_hunk_2501.cpp,-1,220,,"storeAppendPrintf(entry, ""%d"", (int) t->width);","[""addLog""]","[[], [""storeAppendPrintf"", ""entry"", ""%d"", ""int"", ""t"", ""width""]]",[-5835084181075759729],7039,2719200.0,3
https://github.com/squid-cache/squid/commit/38e16f927fb0ac854e8a6bfec90f49af5ef1f6eb,04 Aug 2011,"SourceLayout: format namespace for custom tag-based formats

Part 1 of enabling non-logging components to support custom formats in strings

Shuffle the log custom format code into its own library separate from the
logging functionality.

One minor logic change removing redundant LogFileEnabled flag.

TODO:
 - use MemBuf instead or as well as StoreEntry as the output buffer
 - separate from AccessLogEntry confusion
 - upgrade deny_info URL generation format
 - upgrade external_acl_type format
 - add custom helper formats",3483,data/crawl/squid/hunk_2501.cpp,,,data/crawl/squid/old_hunk_2501.cpp,data/crawl/squid/new_hunk_2501.cpp,-1,83,,"storeAppendPrintf(entry, ""%s"", t->data.string);","[""addLog""]","[[], [""storeAppendPrintf"", ""entry"", ""%s"", ""t"", ""data"", ""string""]]",[-14068941932392998644],7038,2719200.0,3
https://github.com/squid-cache/squid/commit/38e16f927fb0ac854e8a6bfec90f49af5ef1f6eb,04 Aug 2011,"SourceLayout: format namespace for custom tag-based formats

Part 1 of enabling non-logging components to support custom formats in strings

Shuffle the log custom format code into its own library separate from the
logging functionality.

One minor logic change removing redundant LogFileEnabled flag.

TODO:
 - use MemBuf instead or as well as StoreEntry as the output buffer
 - separate from AccessLogEntry confusion
 - upgrade deny_info URL generation format
 - upgrade external_acl_type format
 - add custom helper formats",3483,data/crawl/squid/hunk_2499.cpp,,,data/crawl/squid/old_hunk_2499.cpp,data/crawl/squid/new_hunk_2499.cpp,3,3,"storeAppendPrintf(sentry, ""        %-20.20s %7d %3d%%\n"",log_tags[l], c->Icp.result_hist[l], Math::intPercent(c->Icp.result_hist[l], c->Icp.n_requests));","storeAppendPrintf(sentry, ""        %-20.20s %7d %3d%%\n"",Format::log_tags[l], c->Icp.result_hist[l], Math::intPercent(c->Icp.result_hist[l], c->Icp.n_requests));","[""addVariable""]","[[], [""Format""]]",[2880483376040711751],7037,0.0,3
https://github.com/squid-cache/squid/commit/35a1b223314eddb67b631cb0224d6e03a2360c77,13 Sep 2011,"SMP Caching: Core changes, IPC primitives, Shared memory cache, and Rock Store

Core changes
------------

* Added MemObject::expectedReplySize() and used it instead of object_sz.

When deciding whether an object with a known content length can be
swapped out, do not wait until the object is completely received and its
size (mem_obj->object_sz) becomes known (while asking the store to
recheck in vain with every incoming chunk). Instead, use the known
content length, if any, to make the decision.

This optimizes the common case where the complete object is eventually
received and swapped out, preventing accumulating potentially large
objects in RAM while waiting for the end of the response. Should not
affect objects with unknown content length.

Side-effect1: probably fixes several cases of unknowingly using negative
(unknown) mem_obj->object_sz in calculations. I added a few assertions
to double check some of the remaining object_sz/objectLen() uses.

Side-effect2: When expectedReplySize() is stored on disk as StoreEntry
metadata, it may help to detect truncated entries when the writer
process dies before completing the swapout.


* Removed mem->swapout.memnode in favor of mem->swapout.queue_offset.

The code used swapout.memnode pointer to keep track of the last page
that was swapped out. The code was semi-buggy because it could reset the
pointer to NULL if no new data came in before the call to doPages().
Perhaps the code relied on the assumption that the caller will never
doPages if there is no new data, but I am not sure that assumption was
correct in all cases (it could be that I broke the calling code, of course).

Moreover, the page pointer was kept without any protection from page
disappearing during asynchronous swapout. There were ""Evil hack time""
comments discussing how the page might disappear.

Fortunately, we already have mem->swapout.queue_offset that can be fed
to getBlockContainingLocation to find the page that needs to be swapped
out. There is no need to keep the page pointer around. The
queue_offset-based math is the same so we are not adding any overheads
by using that offset (in fact, we are removing some minor computations).


* Added ""close how?"" parameter to storeClose() and friends.

The old code would follow the same path when closing swapout activity
for an aborted entry and when completing a perfectly healthy swapout. In
non-shared case, that could have been OK because the abort code would
then release the entry, removing any half-written entry from the index
and the disk (but I am not sure that release happened fast enough in
100% of cases).

When the index and disk storage is shared among workers, such
""temporary"" inconsistencies result in truncated responses being
delivered by other workers to the user because once the swapout activity
is closed, other workers can start using the entry.

By adding the ""close how?"" parameter to closing methods we allow the
core and SwapDir-specific code to handle aborted swapouts appropriately.

Since swapin code is ""read only"", we do not currently distinguish
between aborted and fully satisfied readers: The readerGone enum value
applies to both cases. If needed, the SwapDir reading code can make that
distinction by analyzing how much was actually swapped in.


* Moved ""can you store this entry?"" code to virtual SwapDir::canStore().

The old code had some of the tests in SwapDir-specific canStore()
methods and some in storeDirSelect*() methods. This resulted in
inconsistencies, code duplication, and extra calculation overheads.
Making this call virtual allows individual cache_dir types to do custom
access controls.

The same method is used for cache_dir load reporting (if it returns
true). Load management needs more work, but the current code is no worse
than the old one in this aspect, and further improvements are outside
this change scope.


* Minimized from-disk StoreEntry loading/unpacking code duplication.

Moved common (and often rather complex!) code from store modules into
storeRebuildLoadEntry, storeRebuildParseEntry, and storeRebuildKeepEntry.


* Do not set object_sz when the entry is aborted because the true object
size (HTTP reply headers + body) is not known in this case. Setting
object_sz may fool client-side code into believing that the object is
complete.

This addresses an old RBC's complaint.


* When swapout initiation fails, mark swapout decision as
MemObject::SwapOut::swImpossible. This prevents the caller code from trying to
swap out again and again because swap_status becomes SWAPOUT_NONE.

TODO: Consider add SWAPOUT_ERROR, STORE_ERROR, and similar states. It
may solve several problems where the code sees _NONE or _OK and thinks
everything is peachy when in fact there was an error.


* Call haveParsedReplyHeaders() before entry->replaceHttpReply().

HaveParsedReplyHeaders() sets the entry public key and various flags (at 
least). ReplaceHttpReply() packs reply headers, starting swapout process.
It feels natural to adjust the entry _before_ we pack/swap it, but I may be
missing some side-effects here.

The change was necessary because we started calling checkCachable() from
swapoutPossible(). If haveParsedReplyHeaders() is not called before we swap
out checks, the entry will still have the private key and will be declared
impossible to cache.


* Extracted the write-to-store step from StoreEntry::replaceHttpReply().

This allows the caller to set the reply for the entry and then update the
entry and the reply before writing them to store. For example, the server-side
haveParsedReplyHeaders() code needs to set the entry timestamps and make the
entry key public before the entry starts swapping out, but the same code also
needs access to entry->getReply() and such for timestampsSet() and similar
code to work correctly.

TODO: Calls to StoreEntry::replaceHttpReply() do not have to be modified
because replaceHttpReply() does write by default. However, it is likely that
callers other than ServerStateData::setFinalReply() should take advantage of
the new split interface because they call timestampsSet() and such after
replaceHttpReply().


* Moved SwapDir::cur_size and n_disk_objects to specific SwapDirs. Removed
updateSize().  Some cache_dirs maintain their own maps and size statistics,
making the one-size-fits-all SwapDir members inappropriate.

* A new SwapDir public method swappedOut() added. It is called from
storeSwapOutFileClosed() to notify SwapDir that an object was swapped
out.

* Change SwapDir::max_size to bytes, make it protected, use maxSize() instead.

Change SwapDir::cur_size to bytes, make it private, use currentSize() instead.

Store Config.Store.avgObjectSize in bytes to avoid repeated and error-prone
KB<->bytes conversions.


* Change Config.cacheSwap.swapDirs and StoreEntry::store() type to SwapDir.

This allows using SwapDir API without dynamic_cast.


* Always call StoreEntry::abort() instead of setting ENTRY_ABORTED manually.

* Rely on entry->abort() side-effects if ENTRY_ABORTED was set.

* Added or updated comments to better document current code.

* Added operator << for dumping StoreEntry summary into the debugging
log. Needs more work to report more info (and not report yet-unknown info).

* Fixed blocking reads that were sometimes reading from random file offsets.

Core ""disk file"" reading code assumed that if the globally stored disk.offset
matches the desired offset, there is no reason to seek. This was probably done
to reduce seek overhead between consecutive reads. Unfortunately, the disk
writing code did not know about that optimization and left F->disk.offset
unchanged after writing.

This may have worked OK for UFS if it never writes to the file it reads from,
but it does not work for store modules that do both kinds of I/O at different
offsets of the same disk file.

Eventually, implement this optimization correctly or remove disk.offset.


IPC primitives
--------------

To make SMP disk and memory caching non-blocking and correct, worker and
disker processes must asynchronously communicate with each other. We are
adding a collection of classes that support such communication.

At the base of the collection is the AtomicWordT template that uses GCC atomic
primitives such as __sync_add_and_fetch() to perform atomic operations on
integral values in memory shared by multiple Squid kids. AtomicWordT is used
to implement non-blocking shared locks, queues, store tables, and page pools.

To avoid blocking or very long searches, many operations are ""optimistic"" in
nature. For example, it is possible that an atomic store map will refuse to
allocate an entry for two processes even though a blocking implementation
would have allowed one of the processes to get the map slot. We speculate that
such conflict resolution is better than blocking locks when it comes to
caching, especially if the conflicts are rare due to large number of cache
entries, fast operations, and relatively small number of kids.


TODO: Eventually, consider breaking locks left by dead kids.



Shared Memory Cache
-------------------

* Added initial shared memory cache implementation (MemStore).

The shared memory cache keeps its own compact index of cached entries using
extended Ipc::StoreMap class (MemStoreMap). The cache also strives to keep its
Root.get() results out of the store_table except during transit.

Eventually, the non-shared/local memory cache should also be implemented
using a MemStore-like class, I think. This will allow to clearly isolate
local from shared memory cache code.

Allow the user to explicitly disable shared memory caching in SMP mode via
memory_cache_shared to squid.conf. Report whether mem_cache is shared.

Disable shared memory caching by default if atomic operations are not
supported. Prohibit shared memory caching if atomic operations are not
supported.

TODO: Better limits/separation for cache and I/O shared memory pages.
Eventually, support shared memory caching of multi-page entries.


Rock Store
----------

Rock Store uses a single [large] database-style file per cache_dir to store
cached responses and metadata. This part of the design is similar to COSS.
Rock Store does not maintain or rely on swap.state ""log"" for recovery.
Instead, the database is scanned in the background to load entries when Squid
starts. Rock Store maintains its own index of cached entries and avoids global
store_table. All entries must be max-size or smaller.

In SMP mode, each Rock cache_dir is given a dedicated Kid processes called
""disker"". All SMP workers communicate with diskers to store misses and load
hits, using shared memory pages and atomic shared memory queues. Disker blocks
when doing disk I/O but workers do not. Any Diskers:Workers ratio is supported
so that the user can find and configure the optimal number of workers and
diskers for a given number of disks and CPU cores.

In non-SMP mode, should use good old blocking disk I/O, without any diskers,
but this has not been tested recently and probably needs more work.

Feature page: http://wiki.squid-cache.org/Features/RockStore

TODO: Disk rate limit to protect Squid from disk overload. More stats.
Multiple readers? Seek optimization? Remove known max-size requirement?",8765,data/crawl/squid/hunk_2454.cpp,,,data/crawl/squid/old_hunk_2454.cpp,data/crawl/squid/new_hunk_2454.cpp,-1,84,,fatal(s.termedBuf());,"[""addLog""]","[[], [""fatal"", ""s"", ""termedBuf""]]",[1991344095375043898],7036,145920.0,3
https://github.com/squid-cache/squid/commit/35a1b223314eddb67b631cb0224d6e03a2360c77,13 Sep 2011,"SMP Caching: Core changes, IPC primitives, Shared memory cache, and Rock Store

Core changes
------------

* Added MemObject::expectedReplySize() and used it instead of object_sz.

When deciding whether an object with a known content length can be
swapped out, do not wait until the object is completely received and its
size (mem_obj->object_sz) becomes known (while asking the store to
recheck in vain with every incoming chunk). Instead, use the known
content length, if any, to make the decision.

This optimizes the common case where the complete object is eventually
received and swapped out, preventing accumulating potentially large
objects in RAM while waiting for the end of the response. Should not
affect objects with unknown content length.

Side-effect1: probably fixes several cases of unknowingly using negative
(unknown) mem_obj->object_sz in calculations. I added a few assertions
to double check some of the remaining object_sz/objectLen() uses.

Side-effect2: When expectedReplySize() is stored on disk as StoreEntry
metadata, it may help to detect truncated entries when the writer
process dies before completing the swapout.


* Removed mem->swapout.memnode in favor of mem->swapout.queue_offset.

The code used swapout.memnode pointer to keep track of the last page
that was swapped out. The code was semi-buggy because it could reset the
pointer to NULL if no new data came in before the call to doPages().
Perhaps the code relied on the assumption that the caller will never
doPages if there is no new data, but I am not sure that assumption was
correct in all cases (it could be that I broke the calling code, of course).

Moreover, the page pointer was kept without any protection from page
disappearing during asynchronous swapout. There were ""Evil hack time""
comments discussing how the page might disappear.

Fortunately, we already have mem->swapout.queue_offset that can be fed
to getBlockContainingLocation to find the page that needs to be swapped
out. There is no need to keep the page pointer around. The
queue_offset-based math is the same so we are not adding any overheads
by using that offset (in fact, we are removing some minor computations).


* Added ""close how?"" parameter to storeClose() and friends.

The old code would follow the same path when closing swapout activity
for an aborted entry and when completing a perfectly healthy swapout. In
non-shared case, that could have been OK because the abort code would
then release the entry, removing any half-written entry from the index
and the disk (but I am not sure that release happened fast enough in
100% of cases).

When the index and disk storage is shared among workers, such
""temporary"" inconsistencies result in truncated responses being
delivered by other workers to the user because once the swapout activity
is closed, other workers can start using the entry.

By adding the ""close how?"" parameter to closing methods we allow the
core and SwapDir-specific code to handle aborted swapouts appropriately.

Since swapin code is ""read only"", we do not currently distinguish
between aborted and fully satisfied readers: The readerGone enum value
applies to both cases. If needed, the SwapDir reading code can make that
distinction by analyzing how much was actually swapped in.


* Moved ""can you store this entry?"" code to virtual SwapDir::canStore().

The old code had some of the tests in SwapDir-specific canStore()
methods and some in storeDirSelect*() methods. This resulted in
inconsistencies, code duplication, and extra calculation overheads.
Making this call virtual allows individual cache_dir types to do custom
access controls.

The same method is used for cache_dir load reporting (if it returns
true). Load management needs more work, but the current code is no worse
than the old one in this aspect, and further improvements are outside
this change scope.


* Minimized from-disk StoreEntry loading/unpacking code duplication.

Moved common (and often rather complex!) code from store modules into
storeRebuildLoadEntry, storeRebuildParseEntry, and storeRebuildKeepEntry.


* Do not set object_sz when the entry is aborted because the true object
size (HTTP reply headers + body) is not known in this case. Setting
object_sz may fool client-side code into believing that the object is
complete.

This addresses an old RBC's complaint.


* When swapout initiation fails, mark swapout decision as
MemObject::SwapOut::swImpossible. This prevents the caller code from trying to
swap out again and again because swap_status becomes SWAPOUT_NONE.

TODO: Consider add SWAPOUT_ERROR, STORE_ERROR, and similar states. It
may solve several problems where the code sees _NONE or _OK and thinks
everything is peachy when in fact there was an error.


* Call haveParsedReplyHeaders() before entry->replaceHttpReply().

HaveParsedReplyHeaders() sets the entry public key and various flags (at 
least). ReplaceHttpReply() packs reply headers, starting swapout process.
It feels natural to adjust the entry _before_ we pack/swap it, but I may be
missing some side-effects here.

The change was necessary because we started calling checkCachable() from
swapoutPossible(). If haveParsedReplyHeaders() is not called before we swap
out checks, the entry will still have the private key and will be declared
impossible to cache.


* Extracted the write-to-store step from StoreEntry::replaceHttpReply().

This allows the caller to set the reply for the entry and then update the
entry and the reply before writing them to store. For example, the server-side
haveParsedReplyHeaders() code needs to set the entry timestamps and make the
entry key public before the entry starts swapping out, but the same code also
needs access to entry->getReply() and such for timestampsSet() and similar
code to work correctly.

TODO: Calls to StoreEntry::replaceHttpReply() do not have to be modified
because replaceHttpReply() does write by default. However, it is likely that
callers other than ServerStateData::setFinalReply() should take advantage of
the new split interface because they call timestampsSet() and such after
replaceHttpReply().


* Moved SwapDir::cur_size and n_disk_objects to specific SwapDirs. Removed
updateSize().  Some cache_dirs maintain their own maps and size statistics,
making the one-size-fits-all SwapDir members inappropriate.

* A new SwapDir public method swappedOut() added. It is called from
storeSwapOutFileClosed() to notify SwapDir that an object was swapped
out.

* Change SwapDir::max_size to bytes, make it protected, use maxSize() instead.

Change SwapDir::cur_size to bytes, make it private, use currentSize() instead.

Store Config.Store.avgObjectSize in bytes to avoid repeated and error-prone
KB<->bytes conversions.


* Change Config.cacheSwap.swapDirs and StoreEntry::store() type to SwapDir.

This allows using SwapDir API without dynamic_cast.


* Always call StoreEntry::abort() instead of setting ENTRY_ABORTED manually.

* Rely on entry->abort() side-effects if ENTRY_ABORTED was set.

* Added or updated comments to better document current code.

* Added operator << for dumping StoreEntry summary into the debugging
log. Needs more work to report more info (and not report yet-unknown info).

* Fixed blocking reads that were sometimes reading from random file offsets.

Core ""disk file"" reading code assumed that if the globally stored disk.offset
matches the desired offset, there is no reason to seek. This was probably done
to reduce seek overhead between consecutive reads. Unfortunately, the disk
writing code did not know about that optimization and left F->disk.offset
unchanged after writing.

This may have worked OK for UFS if it never writes to the file it reads from,
but it does not work for store modules that do both kinds of I/O at different
offsets of the same disk file.

Eventually, implement this optimization correctly or remove disk.offset.


IPC primitives
--------------

To make SMP disk and memory caching non-blocking and correct, worker and
disker processes must asynchronously communicate with each other. We are
adding a collection of classes that support such communication.

At the base of the collection is the AtomicWordT template that uses GCC atomic
primitives such as __sync_add_and_fetch() to perform atomic operations on
integral values in memory shared by multiple Squid kids. AtomicWordT is used
to implement non-blocking shared locks, queues, store tables, and page pools.

To avoid blocking or very long searches, many operations are ""optimistic"" in
nature. For example, it is possible that an atomic store map will refuse to
allocate an entry for two processes even though a blocking implementation
would have allowed one of the processes to get the map slot. We speculate that
such conflict resolution is better than blocking locks when it comes to
caching, especially if the conflicts are rare due to large number of cache
entries, fast operations, and relatively small number of kids.


TODO: Eventually, consider breaking locks left by dead kids.



Shared Memory Cache
-------------------

* Added initial shared memory cache implementation (MemStore).

The shared memory cache keeps its own compact index of cached entries using
extended Ipc::StoreMap class (MemStoreMap). The cache also strives to keep its
Root.get() results out of the store_table except during transit.

Eventually, the non-shared/local memory cache should also be implemented
using a MemStore-like class, I think. This will allow to clearly isolate
local from shared memory cache code.

Allow the user to explicitly disable shared memory caching in SMP mode via
memory_cache_shared to squid.conf. Report whether mem_cache is shared.

Disable shared memory caching by default if atomic operations are not
supported. Prohibit shared memory caching if atomic operations are not
supported.

TODO: Better limits/separation for cache and I/O shared memory pages.
Eventually, support shared memory caching of multi-page entries.


Rock Store
----------

Rock Store uses a single [large] database-style file per cache_dir to store
cached responses and metadata. This part of the design is similar to COSS.
Rock Store does not maintain or rely on swap.state ""log"" for recovery.
Instead, the database is scanned in the background to load entries when Squid
starts. Rock Store maintains its own index of cached entries and avoids global
store_table. All entries must be max-size or smaller.

In SMP mode, each Rock cache_dir is given a dedicated Kid processes called
""disker"". All SMP workers communicate with diskers to store misses and load
hits, using shared memory pages and atomic shared memory queues. Disker blocks
when doing disk I/O but workers do not. Any Diskers:Workers ratio is supported
so that the user can find and configure the optimal number of workers and
diskers for a given number of disks and CPU cores.

In non-SMP mode, should use good old blocking disk I/O, without any diskers,
but this has not been tested recently and probably needs more work.

Feature page: http://wiki.squid-cache.org/Features/RockStore

TODO: Disk rate limit to protect Squid from disk overload. More stats.
Multiple readers? Seek optimization? Remove known max-size requirement?",8765,data/crawl/squid/hunk_2451.cpp,,,data/crawl/squid/old_hunk_2451.cpp,data/crawl/squid/new_hunk_2451.cpp,3,3,"storeAppendPrintf(&sentry, ""Maximum Size: %""PRIu64"" KB\n"", max_size);","storeAppendPrintf(&sentry, ""Maximum Size: %""PRIu64"" KB\n"", maxSize() >> 10);","[""removeVariable"", ""addContent"", ""addVariable""]","[[""max_size""], [""maxSize"", ""10""]]",[-3169932154592107851],7035,66720.0,3
https://github.com/squid-cache/squid/commit/b46ae5259f2c1a194bf35e1ab76f039deafc10b9,21 Oct 2011,Polished more fatal messages.,23,data/crawl/squid/hunk_2407.cpp,,,data/crawl/squid/old_hunk_2407.cpp,data/crawl/squid/new_hunk_2407.cpp,7,-1,fatal(s.termedBuf());,,"[""removeLog""]","[[""fatal"", ""s"", ""termedBuf""], []]",[-1991344095375043898],7034,182400.0,3
https://github.com/squid-cache/squid/commit/c7baff405558ef38ca6f0b2e5568621ad120004a,30 Dec 2011,"SourceLayout: shuffel UserRequest into Auth:: namespace

No logic changes, symbols and debug only.

* shuffle AuthUserRequest to Auth::UserRequest
* shuffle AuthBasicUserRequest to Auth::Basic::UserRequest
* shuffle AuthDigestUserRequest to Auth::Digest::UserRequest
* shuffle AuthNegotiateUserRequest to Auth::Negotiate::UserRequest
* shuffle AuthNTLMUserRequest to Auth::NTLM::UserRequest

* polish and add documentation for several parts of the hierarchy

* replace obsolete debugs() location texts",547,data/crawl/squid/hunk_2366.cpp,,,data/crawl/squid/old_hunk_2366.cpp,data/crawl/squid/new_hunk_2366.cpp,10,10,"fatal (""AuthUserRequest not directly allocatable\n"");","fatal(""Auth::UserRequest not directly allocatable\n"");","[""updateContent""]","[[""AuthUserRequest""], [""Auth"", ""UserRequest""]]",[-15331411644525419072],7033,0.0,3
https://github.com/squid-cache/squid/commit/081edc2de252e852d0a8e02891fb36d7919a92ef,07 Jan 2012,"Cleanup: update most of the existing stub files to use the STUB.h framework

There are still several sections to be done. Including adding library API
stubs. However these are the ones which can be done immediately without 
breaking or re-writing existing unit tests.",2058,data/crawl/squid/hunk_2357.cpp,,,data/crawl/squid/old_hunk_2357.cpp,data/crawl/squid/new_hunk_2357.cpp,46,-1,"fatal(""tools.cc required"");",,"[""removeLog""]","[[""fatal"", ""tools"", ""cc"", ""required""], []]",[3614026982818920886],7032,0.0,3
https://github.com/squid-cache/squid/commit/65d448bc848526838ea2d5cea65d72a341896f08,25 Apr 2012,"SourceLayout: port config and select-loop priority polishing

- renames http_port_list to AnyP::PortCfg
- de-duplicate https_port_list into AnyP::PortCfg
- shuffles related globals and defines into anyp/PortCfg.*
- renames MAXHTTPPORTS to MAXTCPLISTENPORTS to suit its actual coverage of HTTP and HTTPS ports.
- shuffled config port clone function into a method.
- rename ICP/HTCP/SNMP API functions to consistent *OpenPorts() and *ClosePorts()


  NP:following applies to incoming_* and *_poll_cnt directives.
- renames *_icp_* to *_udp_*
- renames *_http_* to *_tcp_*
- shuffles duplicated struct SquidConf options into a shared structure
- shuffles related defines into comm/Loops.h
- documents options better

- various other cosmetic syntax tweaks and polish

One bug fix:
  comm_dns_incoming was not being propigated in StatsHist copy/clone.
  Now is. I seem to remember mention of something similar being zero before,
  but can't find the bug report.",1098,data/crawl/squid/hunk_2320.cpp,,,data/crawl/squid/old_hunk_2320.cpp,data/crawl/squid/new_hunk_2320.cpp,7,7,"storeAppendPrintf(sentry, ""Current incoming_http_interval: %d\n"",
                      incoming_http_interval >> INCOMING_FACTOR);","storeAppendPrintf(sentry, ""Current incoming_tcp_interval: %d\n"",
                      incoming_tcp_interval >> INCOMING_FACTOR);","[""updateVariable"", ""updateContent""]","[[""incoming_http_interval"", ""incoming_http_interval""], [""incoming_tcp_interval"", ""incoming_tcp_interval""]]",[9573987039334629836],7031,0.0,3
https://github.com/squid-cache/squid/commit/65d448bc848526838ea2d5cea65d72a341896f08,25 Apr 2012,"SourceLayout: port config and select-loop priority polishing

- renames http_port_list to AnyP::PortCfg
- de-duplicate https_port_list into AnyP::PortCfg
- shuffles related globals and defines into anyp/PortCfg.*
- renames MAXHTTPPORTS to MAXTCPLISTENPORTS to suit its actual coverage of HTTP and HTTPS ports.
- shuffled config port clone function into a method.
- rename ICP/HTCP/SNMP API functions to consistent *OpenPorts() and *ClosePorts()


  NP:following applies to incoming_* and *_poll_cnt directives.
- renames *_icp_* to *_udp_*
- renames *_http_* to *_tcp_*
- shuffles duplicated struct SquidConf options into a shared structure
- shuffles related defines into comm/Loops.h
- documents options better

- various other cosmetic syntax tweaks and polish

One bug fix:
  comm_dns_incoming was not being propigated in StatsHist copy/clone.
  Now is. I seem to remember mention of something similar being zero before,
  but can't find the bug report.",1098,data/crawl/squid/hunk_2320.cpp,,,data/crawl/squid/old_hunk_2320.cpp,data/crawl/squid/new_hunk_2320.cpp,3,3,"storeAppendPrintf(sentry, ""Current incoming_icp_interval: %d\n"",
                      incoming_icp_interval >> INCOMING_FACTOR);","storeAppendPrintf(sentry, ""Current incoming_udp_interval: %d\n"",
                      incoming_udp_interval >> INCOMING_FACTOR);","[""updateVariable"", ""updateContent""]","[[""incoming_icp_interval"", ""incoming_icp_interval""], [""incoming_udp_interval"", ""incoming_udp_interval""]]",[-35563025994777130],7030,0.0,3
https://github.com/squid-cache/squid/commit/71cae3894fd0c52dd4b4bfedb3ac1323eb619a73,18 Jul 2012,merge from trunk (r12216 v3.2.0.18+),2062,data/crawl/squid/hunk_2125.cpp,,,data/crawl/squid/old_hunk_2125.cpp,data/crawl/squid/new_hunk_2125.cpp,52,25,"storeAppendPrintf(entry, ""%s %s %s\n"", name, httpHeaderNameById(i),
                          header[i].replacement);","manglers->dumpReplacement(entry, name);","[""addLog"", ""removeVariable"", ""removeContent"", ""removeLog""]","[[""storeAppendPrintf"", ""%s"", ""%s"", ""%s\\n"", ""httpHeaderNameById"", ""i"", ""header[i]"", ""replacement""], [""manglers"", ""dumpReplacement""]]",[-11043328176935827389],7029,12480.0,3
https://github.com/squid-cache/squid/commit/71cae3894fd0c52dd4b4bfedb3ac1323eb619a73,18 Jul 2012,merge from trunk (r12216 v3.2.0.18+),2062,data/crawl/squid/hunk_2124.cpp,,,data/crawl/squid/old_hunk_2124.cpp,data/crawl/squid/new_hunk_2124.cpp,9,6,"storeAppendPrintf(entry, ""%s "", name);","manglers->dumpAccess(entry, name);","[""addLog"", ""removeContent"", ""removeLog""]","[[""storeAppendPrintf"", ""%s""], [""manglers"", ""dumpAccess""]]",[1374559074738771596],7028,12480.0,3
https://github.com/squid-cache/squid/commit/71cae3894fd0c52dd4b4bfedb3ac1323eb619a73,18 Jul 2012,merge from trunk (r12216 v3.2.0.18+),2062,data/crawl/squid/hunk_2117.cpp,,,data/crawl/squid/old_hunk_2117.cpp,data/crawl/squid/new_hunk_2117.cpp,-1,25,,"storeAppendPrintf(entry, ""%s %s %s\n"", option, name, m.replacement);","[""addLog""]","[[], [""storeAppendPrintf"", ""entry"", ""%s"", ""%s"", ""%s\\n"", ""option"", ""name"", ""m"", ""replacement""]]",[5754358729700913051],7027,12480.0,3
https://github.com/squid-cache/squid/commit/71cae3894fd0c52dd4b4bfedb3ac1323eb619a73,18 Jul 2012,merge from trunk (r12216 v3.2.0.18+),2062,data/crawl/squid/hunk_2117.cpp,,,data/crawl/squid/old_hunk_2117.cpp,data/crawl/squid/new_hunk_2117.cpp,-1,15,,"storeAppendPrintf(entry, ""%s "", option);","[""addLog""]","[[], [""storeAppendPrintf"", ""entry"", ""%s"", ""option""]]",[6205846990721878971],7026,12480.0,3
https://github.com/squid-cache/squid/commit/8621b1ac6e2d63a83a41bd808bd3783dee06e416,18 Jul 2012,"author: Alex Rousskov <rousskov@measurement-factory.com>, Christos Tsantilas <chtsanti@users.sourceforge.net>
SslBump: Support bump-ssl-server-first and mimic SSL server certificates.

Summary: These changes allow Squid working in SslBump mode to peek at
the origin server certificate and mimic peeked server certificate
properties in the generated fake certificate, all prior to establishing
a secure connection with the client:
http://wiki.squid-cache.org/Features/BumpSslServerFirst
http://wiki.squid-cache.org/Features/MimicSslServerCert

The changes are required to bump intercepted SSL connections without
excessive browser warnings. The changes allow to disable bumping of some
intercepted SSL connections, forcing Squid to go into a TCP tunnel mode
for those connections.

The changes also empower end user to examine and either honor or bypass
most origin SSL server certificate errors. Prior to these changes, the
responsibility for ignoring certificate validation errors belonged
exclusively to Squid, necessarily leaving users in the dark if errors
are ignored/bypassed.

Squid can still be configured to emulate old bump-ssl-client-first
behavior.  However, a manual revision of ssl_bump options is required
during upgrade because ssl_bump no longer supports an implicit ""negate
the last one"" rule (and it is risky to let Squid guess what the admin
true intent was or mix old- and new-style rules).

Finally, fake certificate generation has been significantly improved.
The new code guarantees that all identically configured Squids receiving
identical origin server certificates will generate identical fake
certificates, even if those Squid instances are running on different
hosts, at different times, and do not communicate with each other. Such
stable, reproducible certificates are required for distributed,
scalable, or fail-safe Squid deployment.

Overall, the changes are meant to make SslBump more powerful and safer.
The code has been tested in several independent labs.


Specific major changes are highlighted below:

Make bumping algorithm selectable using ACLs. Even though
bump-server-first is an overall better method, bumping the client first
is useful for backward compatibility and possibly for serving internal
Squid objects (such as icons inside Squid error pages).  The following
example bumps special and most other requests only, using the old
bump-client-first approach for the special requests only:

    ssl_bump client-first specialOnes
    ssl_bump server-first mostOthers
    ssl_bump none all

It allow use the old ssl_bump syntax:
   ssl_bump allow/deny acl ...
but warns the user to update squid configuration.

Added sslproxy_cert_adapt squid.conf option to overwrite default mimicking
behavior when generating SSL certificates. See squid.conf.documented.

Added sslproxy_cert_sign squid.conf option to control how generated SSL
certificates are signed. See squid.conf.documented.

Added ssl::certHasExpired, ssl::certNotYetValid, ssl::certDomainMismatch,
ssl::certUntrusted, and ssl::certSelfSign predefined ACLs to squid.conf.

Do not require http[s]_port's key option to be set if cert option is given.
The fixed behavior for bumped connections now matches squid.conf docs.

Generate stable fake certificates by using signing and true certificate
hashes as the serial number and by using the configured CA private key
for all fake certificates.

Use minimal, trusted certificate for serving SSL errors to the client
instead of trying to mimic the broken true certificate (which results
in double error for the user: browser error dialog plus Squid error page).

To mimic ""untrusted"" true certificates, generate an untrusted CA certificate
from the configured trusted CA certificate. This both reduces configuration
effort (compared to a configuration option) and results in identical
untrusted fake certificates given identical Squid configurations.

Intelligent handling of CONNECT denials: Do not connect to origin
servers unless CONNECT is successfully authenticated. Delay errors.Added sslproxy_cert_sign squid.conf option to control how generated SSL
certificates are signed. See squid.conf.documented.

Provide '%I' error page formatting code with enough information to avoid
displaying '[unknown]' on SQUID_X509_V_ERR_DOMAIN_MISMATCH errors.

Set logged status code (%<Hs) to 200 when establishing a bumped tunnel.

Improved error detailing and logging: Forget most retried errors.
During SslBump errors, the error details are now logged with both the
initial CONNECT transaction and the first tunneled HTTP transaction.
Do not report system errors as custom Squid errors. Do not report
system errors that did not necessarily happen during the transaction
being logged.

Check SSL server certificate when reconnecting to the origin server for
bumped requests. Despite pinning, Squid maintains two separate connections
and the server may disconnect while the client is still sending requests. To
minimize deployment problems, we reconnect to the origin server but check
that its certificate (which we mimicked for the client) has not changed
much.

Forward bumped server connection-close signal to the bumped client to
improve the ""dumb tunnel"" appearance of the bumped SSL tunnel.

Allow bumping of CONNECT requests without allow-direct set on http_port.
Previously, that flag was required to allow bumped requests to go direct
because they were (and, sometimes, still are) considered ""accelerated"".

Send SNI information to the server when server-first bumping a non-IP
CONNECT request.

Better helper-to-Squid buffer size management to support large certificates.

Bypass rare OpenSSL certificate serialization failures when composing an
ssl_crtd request by generating the certificate in the Squid process.

When generating certificate CN names, strip [] surrounding host names,
assuming they are for IPv6 addresses. Bracketed CNs confuse browsers.

Disable persistent connections after client-side-detected errors. They cause
""abandoning such and such connection"" warnings, stuck ConnStateData jobs, and
other problems.

HttpRequest::SetHost() must invalidate HttpRequest::canonical ""cache"".

Implement ssl::bump_mode logformat code to log SslBump decisions: prints ""none"",
""client-first"", ""server-first"" or ""-"" for no ssl-bump enabled ports

Synced with trunk (trunk r12216, v3.2.0.18+)

This is a Measurement Factory project.",3561,data/crawl/squid/hunk_2097.cpp,,,data/crawl/squid/old_hunk_2097.cpp,data/crawl/squid/new_hunk_2097.cpp,3,3,"fatalf(""Failed to set SSL cipher suite '%s': %s\n"",
                   cipher, ERR_error_string(ssl_error, NULL));","debugs(83, DBG_CRITICAL, ""ERROR: Failed to set SSL cipher suite '"" << cipher << ""': "" << ERR_error_string(ssl_error, NULL));","[""updateVariable"", ""updateLog"", ""updateContent"", ""addContent"", ""addVariable""]","[[""fatalf"", ""%s"", ""%s\\n""], [""debugs"", ""83"", ""DBG_CRITICAL"", ""ERROR""]]",[1675755882985238231],7025,114240.0,3
https://github.com/squid-cache/squid/commit/8621b1ac6e2d63a83a41bd808bd3783dee06e416,18 Jul 2012,"author: Alex Rousskov <rousskov@measurement-factory.com>, Christos Tsantilas <chtsanti@users.sourceforge.net>
SslBump: Support bump-ssl-server-first and mimic SSL server certificates.

Summary: These changes allow Squid working in SslBump mode to peek at
the origin server certificate and mimic peeked server certificate
properties in the generated fake certificate, all prior to establishing
a secure connection with the client:
http://wiki.squid-cache.org/Features/BumpSslServerFirst
http://wiki.squid-cache.org/Features/MimicSslServerCert

The changes are required to bump intercepted SSL connections without
excessive browser warnings. The changes allow to disable bumping of some
intercepted SSL connections, forcing Squid to go into a TCP tunnel mode
for those connections.

The changes also empower end user to examine and either honor or bypass
most origin SSL server certificate errors. Prior to these changes, the
responsibility for ignoring certificate validation errors belonged
exclusively to Squid, necessarily leaving users in the dark if errors
are ignored/bypassed.

Squid can still be configured to emulate old bump-ssl-client-first
behavior.  However, a manual revision of ssl_bump options is required
during upgrade because ssl_bump no longer supports an implicit ""negate
the last one"" rule (and it is risky to let Squid guess what the admin
true intent was or mix old- and new-style rules).

Finally, fake certificate generation has been significantly improved.
The new code guarantees that all identically configured Squids receiving
identical origin server certificates will generate identical fake
certificates, even if those Squid instances are running on different
hosts, at different times, and do not communicate with each other. Such
stable, reproducible certificates are required for distributed,
scalable, or fail-safe Squid deployment.

Overall, the changes are meant to make SslBump more powerful and safer.
The code has been tested in several independent labs.


Specific major changes are highlighted below:

Make bumping algorithm selectable using ACLs. Even though
bump-server-first is an overall better method, bumping the client first
is useful for backward compatibility and possibly for serving internal
Squid objects (such as icons inside Squid error pages).  The following
example bumps special and most other requests only, using the old
bump-client-first approach for the special requests only:

    ssl_bump client-first specialOnes
    ssl_bump server-first mostOthers
    ssl_bump none all

It allow use the old ssl_bump syntax:
   ssl_bump allow/deny acl ...
but warns the user to update squid configuration.

Added sslproxy_cert_adapt squid.conf option to overwrite default mimicking
behavior when generating SSL certificates. See squid.conf.documented.

Added sslproxy_cert_sign squid.conf option to control how generated SSL
certificates are signed. See squid.conf.documented.

Added ssl::certHasExpired, ssl::certNotYetValid, ssl::certDomainMismatch,
ssl::certUntrusted, and ssl::certSelfSign predefined ACLs to squid.conf.

Do not require http[s]_port's key option to be set if cert option is given.
The fixed behavior for bumped connections now matches squid.conf docs.

Generate stable fake certificates by using signing and true certificate
hashes as the serial number and by using the configured CA private key
for all fake certificates.

Use minimal, trusted certificate for serving SSL errors to the client
instead of trying to mimic the broken true certificate (which results
in double error for the user: browser error dialog plus Squid error page).

To mimic ""untrusted"" true certificates, generate an untrusted CA certificate
from the configured trusted CA certificate. This both reduces configuration
effort (compared to a configuration option) and results in identical
untrusted fake certificates given identical Squid configurations.

Intelligent handling of CONNECT denials: Do not connect to origin
servers unless CONNECT is successfully authenticated. Delay errors.Added sslproxy_cert_sign squid.conf option to control how generated SSL
certificates are signed. See squid.conf.documented.

Provide '%I' error page formatting code with enough information to avoid
displaying '[unknown]' on SQUID_X509_V_ERR_DOMAIN_MISMATCH errors.

Set logged status code (%<Hs) to 200 when establishing a bumped tunnel.

Improved error detailing and logging: Forget most retried errors.
During SslBump errors, the error details are now logged with both the
initial CONNECT transaction and the first tunneled HTTP transaction.
Do not report system errors as custom Squid errors. Do not report
system errors that did not necessarily happen during the transaction
being logged.

Check SSL server certificate when reconnecting to the origin server for
bumped requests. Despite pinning, Squid maintains two separate connections
and the server may disconnect while the client is still sending requests. To
minimize deployment problems, we reconnect to the origin server but check
that its certificate (which we mimicked for the client) has not changed
much.

Forward bumped server connection-close signal to the bumped client to
improve the ""dumb tunnel"" appearance of the bumped SSL tunnel.

Allow bumping of CONNECT requests without allow-direct set on http_port.
Previously, that flag was required to allow bumped requests to go direct
because they were (and, sometimes, still are) considered ""accelerated"".

Send SNI information to the server when server-first bumping a non-IP
CONNECT request.

Better helper-to-Squid buffer size management to support large certificates.

Bypass rare OpenSSL certificate serialization failures when composing an
ssl_crtd request by generating the certificate in the Squid process.

When generating certificate CN names, strip [] surrounding host names,
assuming they are for IPv6 addresses. Bracketed CNs confuse browsers.

Disable persistent connections after client-side-detected errors. They cause
""abandoning such and such connection"" warnings, stuck ConnStateData jobs, and
other problems.

HttpRequest::SetHost() must invalidate HttpRequest::canonical ""cache"".

Implement ssl::bump_mode logformat code to log SslBump decisions: prints ""none"",
""client-first"", ""server-first"" or ""-"" for no ssl-bump enabled ports

Synced with trunk (trunk r12216, v3.2.0.18+)

This is a Measurement Factory project.",3561,data/crawl/squid/hunk_2096.cpp,,,data/crawl/squid/old_hunk_2096.cpp,data/crawl/squid/new_hunk_2096.cpp,3,3,"fatalf(""Failed to allocate SSL context: %s\n"",
               ERR_error_string(ssl_error, NULL));","debugs(83, DBG_CRITICAL, ""ERROR: Failed to allocate SSL context: "" << ERR_error_string(ssl_error, NULL));","[""updateLog"", ""updateContent"", ""addContent"", ""addVariable""]","[[""fatalf"", ""%s\\n""], [""debugs"", ""83"", ""DBG_CRITICAL"", ""ERROR""]]",[1680491911438281013],7024,114240.0,3
https://github.com/squid-cache/squid/commit/8621b1ac6e2d63a83a41bd808bd3783dee06e416,18 Jul 2012,"author: Alex Rousskov <rousskov@measurement-factory.com>, Christos Tsantilas <chtsanti@users.sourceforge.net>
SslBump: Support bump-ssl-server-first and mimic SSL server certificates.

Summary: These changes allow Squid working in SslBump mode to peek at
the origin server certificate and mimic peeked server certificate
properties in the generated fake certificate, all prior to establishing
a secure connection with the client:
http://wiki.squid-cache.org/Features/BumpSslServerFirst
http://wiki.squid-cache.org/Features/MimicSslServerCert

The changes are required to bump intercepted SSL connections without
excessive browser warnings. The changes allow to disable bumping of some
intercepted SSL connections, forcing Squid to go into a TCP tunnel mode
for those connections.

The changes also empower end user to examine and either honor or bypass
most origin SSL server certificate errors. Prior to these changes, the
responsibility for ignoring certificate validation errors belonged
exclusively to Squid, necessarily leaving users in the dark if errors
are ignored/bypassed.

Squid can still be configured to emulate old bump-ssl-client-first
behavior.  However, a manual revision of ssl_bump options is required
during upgrade because ssl_bump no longer supports an implicit ""negate
the last one"" rule (and it is risky to let Squid guess what the admin
true intent was or mix old- and new-style rules).

Finally, fake certificate generation has been significantly improved.
The new code guarantees that all identically configured Squids receiving
identical origin server certificates will generate identical fake
certificates, even if those Squid instances are running on different
hosts, at different times, and do not communicate with each other. Such
stable, reproducible certificates are required for distributed,
scalable, or fail-safe Squid deployment.

Overall, the changes are meant to make SslBump more powerful and safer.
The code has been tested in several independent labs.


Specific major changes are highlighted below:

Make bumping algorithm selectable using ACLs. Even though
bump-server-first is an overall better method, bumping the client first
is useful for backward compatibility and possibly for serving internal
Squid objects (such as icons inside Squid error pages).  The following
example bumps special and most other requests only, using the old
bump-client-first approach for the special requests only:

    ssl_bump client-first specialOnes
    ssl_bump server-first mostOthers
    ssl_bump none all

It allow use the old ssl_bump syntax:
   ssl_bump allow/deny acl ...
but warns the user to update squid configuration.

Added sslproxy_cert_adapt squid.conf option to overwrite default mimicking
behavior when generating SSL certificates. See squid.conf.documented.

Added sslproxy_cert_sign squid.conf option to control how generated SSL
certificates are signed. See squid.conf.documented.

Added ssl::certHasExpired, ssl::certNotYetValid, ssl::certDomainMismatch,
ssl::certUntrusted, and ssl::certSelfSign predefined ACLs to squid.conf.

Do not require http[s]_port's key option to be set if cert option is given.
The fixed behavior for bumped connections now matches squid.conf docs.

Generate stable fake certificates by using signing and true certificate
hashes as the serial number and by using the configured CA private key
for all fake certificates.

Use minimal, trusted certificate for serving SSL errors to the client
instead of trying to mimic the broken true certificate (which results
in double error for the user: browser error dialog plus Squid error page).

To mimic ""untrusted"" true certificates, generate an untrusted CA certificate
from the configured trusted CA certificate. This both reduces configuration
effort (compared to a configuration option) and results in identical
untrusted fake certificates given identical Squid configurations.

Intelligent handling of CONNECT denials: Do not connect to origin
servers unless CONNECT is successfully authenticated. Delay errors.Added sslproxy_cert_sign squid.conf option to control how generated SSL
certificates are signed. See squid.conf.documented.

Provide '%I' error page formatting code with enough information to avoid
displaying '[unknown]' on SQUID_X509_V_ERR_DOMAIN_MISMATCH errors.

Set logged status code (%<Hs) to 200 when establishing a bumped tunnel.

Improved error detailing and logging: Forget most retried errors.
During SslBump errors, the error details are now logged with both the
initial CONNECT transaction and the first tunneled HTTP transaction.
Do not report system errors as custom Squid errors. Do not report
system errors that did not necessarily happen during the transaction
being logged.

Check SSL server certificate when reconnecting to the origin server for
bumped requests. Despite pinning, Squid maintains two separate connections
and the server may disconnect while the client is still sending requests. To
minimize deployment problems, we reconnect to the origin server but check
that its certificate (which we mimicked for the client) has not changed
much.

Forward bumped server connection-close signal to the bumped client to
improve the ""dumb tunnel"" appearance of the bumped SSL tunnel.

Allow bumping of CONNECT requests without allow-direct set on http_port.
Previously, that flag was required to allow bumped requests to go direct
because they were (and, sometimes, still are) considered ""accelerated"".

Send SNI information to the server when server-first bumping a non-IP
CONNECT request.

Better helper-to-Squid buffer size management to support large certificates.

Bypass rare OpenSSL certificate serialization failures when composing an
ssl_crtd request by generating the certificate in the Squid process.

When generating certificate CN names, strip [] surrounding host names,
assuming they are for IPv6 addresses. Bracketed CNs confuse browsers.

Disable persistent connections after client-side-detected errors. They cause
""abandoning such and such connection"" warnings, stuck ConnStateData jobs, and
other problems.

HttpRequest::SetHost() must invalidate HttpRequest::canonical ""cache"".

Implement ssl::bump_mode logformat code to log SslBump decisions: prints ""none"",
""client-first"", ""server-first"" or ""-"" for no ssl-bump enabled ports

Synced with trunk (trunk r12216, v3.2.0.18+)

This is a Measurement Factory project.",3561,data/crawl/squid/hunk_2094.cpp,,,data/crawl/squid/old_hunk_2094.cpp,data/crawl/squid/new_hunk_2094.cpp,-1,248,,"storeAppendPrintf(entry, ""%s "", Ssl::bumpMode(sb->allow.kind));","[""addLog""]","[[], [""storeAppendPrintf"", ""entry"", ""%s"", ""Ssl"", ""bumpMode"", ""sb"", ""allow"", ""kind""]]",[13922051435011257693],7023,72000.0,3
https://github.com/squid-cache/squid/commit/8621b1ac6e2d63a83a41bd808bd3783dee06e416,18 Jul 2012,"author: Alex Rousskov <rousskov@measurement-factory.com>, Christos Tsantilas <chtsanti@users.sourceforge.net>
SslBump: Support bump-ssl-server-first and mimic SSL server certificates.

Summary: These changes allow Squid working in SslBump mode to peek at
the origin server certificate and mimic peeked server certificate
properties in the generated fake certificate, all prior to establishing
a secure connection with the client:
http://wiki.squid-cache.org/Features/BumpSslServerFirst
http://wiki.squid-cache.org/Features/MimicSslServerCert

The changes are required to bump intercepted SSL connections without
excessive browser warnings. The changes allow to disable bumping of some
intercepted SSL connections, forcing Squid to go into a TCP tunnel mode
for those connections.

The changes also empower end user to examine and either honor or bypass
most origin SSL server certificate errors. Prior to these changes, the
responsibility for ignoring certificate validation errors belonged
exclusively to Squid, necessarily leaving users in the dark if errors
are ignored/bypassed.

Squid can still be configured to emulate old bump-ssl-client-first
behavior.  However, a manual revision of ssl_bump options is required
during upgrade because ssl_bump no longer supports an implicit ""negate
the last one"" rule (and it is risky to let Squid guess what the admin
true intent was or mix old- and new-style rules).

Finally, fake certificate generation has been significantly improved.
The new code guarantees that all identically configured Squids receiving
identical origin server certificates will generate identical fake
certificates, even if those Squid instances are running on different
hosts, at different times, and do not communicate with each other. Such
stable, reproducible certificates are required for distributed,
scalable, or fail-safe Squid deployment.

Overall, the changes are meant to make SslBump more powerful and safer.
The code has been tested in several independent labs.


Specific major changes are highlighted below:

Make bumping algorithm selectable using ACLs. Even though
bump-server-first is an overall better method, bumping the client first
is useful for backward compatibility and possibly for serving internal
Squid objects (such as icons inside Squid error pages).  The following
example bumps special and most other requests only, using the old
bump-client-first approach for the special requests only:

    ssl_bump client-first specialOnes
    ssl_bump server-first mostOthers
    ssl_bump none all

It allow use the old ssl_bump syntax:
   ssl_bump allow/deny acl ...
but warns the user to update squid configuration.

Added sslproxy_cert_adapt squid.conf option to overwrite default mimicking
behavior when generating SSL certificates. See squid.conf.documented.

Added sslproxy_cert_sign squid.conf option to control how generated SSL
certificates are signed. See squid.conf.documented.

Added ssl::certHasExpired, ssl::certNotYetValid, ssl::certDomainMismatch,
ssl::certUntrusted, and ssl::certSelfSign predefined ACLs to squid.conf.

Do not require http[s]_port's key option to be set if cert option is given.
The fixed behavior for bumped connections now matches squid.conf docs.

Generate stable fake certificates by using signing and true certificate
hashes as the serial number and by using the configured CA private key
for all fake certificates.

Use minimal, trusted certificate for serving SSL errors to the client
instead of trying to mimic the broken true certificate (which results
in double error for the user: browser error dialog plus Squid error page).

To mimic ""untrusted"" true certificates, generate an untrusted CA certificate
from the configured trusted CA certificate. This both reduces configuration
effort (compared to a configuration option) and results in identical
untrusted fake certificates given identical Squid configurations.

Intelligent handling of CONNECT denials: Do not connect to origin
servers unless CONNECT is successfully authenticated. Delay errors.Added sslproxy_cert_sign squid.conf option to control how generated SSL
certificates are signed. See squid.conf.documented.

Provide '%I' error page formatting code with enough information to avoid
displaying '[unknown]' on SQUID_X509_V_ERR_DOMAIN_MISMATCH errors.

Set logged status code (%<Hs) to 200 when establishing a bumped tunnel.

Improved error detailing and logging: Forget most retried errors.
During SslBump errors, the error details are now logged with both the
initial CONNECT transaction and the first tunneled HTTP transaction.
Do not report system errors as custom Squid errors. Do not report
system errors that did not necessarily happen during the transaction
being logged.

Check SSL server certificate when reconnecting to the origin server for
bumped requests. Despite pinning, Squid maintains two separate connections
and the server may disconnect while the client is still sending requests. To
minimize deployment problems, we reconnect to the origin server but check
that its certificate (which we mimicked for the client) has not changed
much.

Forward bumped server connection-close signal to the bumped client to
improve the ""dumb tunnel"" appearance of the bumped SSL tunnel.

Allow bumping of CONNECT requests without allow-direct set on http_port.
Previously, that flag was required to allow bumped requests to go direct
because they were (and, sometimes, still are) considered ""accelerated"".

Send SNI information to the server when server-first bumping a non-IP
CONNECT request.

Better helper-to-Squid buffer size management to support large certificates.

Bypass rare OpenSSL certificate serialization failures when composing an
ssl_crtd request by generating the certificate in the Squid process.

When generating certificate CN names, strip [] surrounding host names,
assuming they are for IPv6 addresses. Bracketed CNs confuse browsers.

Disable persistent connections after client-side-detected errors. They cause
""abandoning such and such connection"" warnings, stuck ConnStateData jobs, and
other problems.

HttpRequest::SetHost() must invalidate HttpRequest::canonical ""cache"".

Implement ssl::bump_mode logformat code to log SslBump decisions: prints ""none"",
""client-first"", ""server-first"" or ""-"" for no ssl-bump enabled ports

Synced with trunk (trunk r12216, v3.2.0.18+)

This is a Measurement Factory project.",3561,data/crawl/squid/hunk_2094.cpp,,,data/crawl/squid/old_hunk_2094.cpp,data/crawl/squid/new_hunk_2094.cpp,-1,121,,"storeAppendPrintf(entry, ""%s "", Ssl::certSignAlgorithm(cs->alg));","[""addLog""]","[[], [""storeAppendPrintf"", ""entry"", ""%s"", ""Ssl"", ""certSignAlgorithm"", ""cs"", ""alg""]]",[953825321972862509],7022,166080.0,3
https://github.com/squid-cache/squid/commit/8621b1ac6e2d63a83a41bd808bd3783dee06e416,18 Jul 2012,"author: Alex Rousskov <rousskov@measurement-factory.com>, Christos Tsantilas <chtsanti@users.sourceforge.net>
SslBump: Support bump-ssl-server-first and mimic SSL server certificates.

Summary: These changes allow Squid working in SslBump mode to peek at
the origin server certificate and mimic peeked server certificate
properties in the generated fake certificate, all prior to establishing
a secure connection with the client:
http://wiki.squid-cache.org/Features/BumpSslServerFirst
http://wiki.squid-cache.org/Features/MimicSslServerCert

The changes are required to bump intercepted SSL connections without
excessive browser warnings. The changes allow to disable bumping of some
intercepted SSL connections, forcing Squid to go into a TCP tunnel mode
for those connections.

The changes also empower end user to examine and either honor or bypass
most origin SSL server certificate errors. Prior to these changes, the
responsibility for ignoring certificate validation errors belonged
exclusively to Squid, necessarily leaving users in the dark if errors
are ignored/bypassed.

Squid can still be configured to emulate old bump-ssl-client-first
behavior.  However, a manual revision of ssl_bump options is required
during upgrade because ssl_bump no longer supports an implicit ""negate
the last one"" rule (and it is risky to let Squid guess what the admin
true intent was or mix old- and new-style rules).

Finally, fake certificate generation has been significantly improved.
The new code guarantees that all identically configured Squids receiving
identical origin server certificates will generate identical fake
certificates, even if those Squid instances are running on different
hosts, at different times, and do not communicate with each other. Such
stable, reproducible certificates are required for distributed,
scalable, or fail-safe Squid deployment.

Overall, the changes are meant to make SslBump more powerful and safer.
The code has been tested in several independent labs.


Specific major changes are highlighted below:

Make bumping algorithm selectable using ACLs. Even though
bump-server-first is an overall better method, bumping the client first
is useful for backward compatibility and possibly for serving internal
Squid objects (such as icons inside Squid error pages).  The following
example bumps special and most other requests only, using the old
bump-client-first approach for the special requests only:

    ssl_bump client-first specialOnes
    ssl_bump server-first mostOthers
    ssl_bump none all

It allow use the old ssl_bump syntax:
   ssl_bump allow/deny acl ...
but warns the user to update squid configuration.

Added sslproxy_cert_adapt squid.conf option to overwrite default mimicking
behavior when generating SSL certificates. See squid.conf.documented.

Added sslproxy_cert_sign squid.conf option to control how generated SSL
certificates are signed. See squid.conf.documented.

Added ssl::certHasExpired, ssl::certNotYetValid, ssl::certDomainMismatch,
ssl::certUntrusted, and ssl::certSelfSign predefined ACLs to squid.conf.

Do not require http[s]_port's key option to be set if cert option is given.
The fixed behavior for bumped connections now matches squid.conf docs.

Generate stable fake certificates by using signing and true certificate
hashes as the serial number and by using the configured CA private key
for all fake certificates.

Use minimal, trusted certificate for serving SSL errors to the client
instead of trying to mimic the broken true certificate (which results
in double error for the user: browser error dialog plus Squid error page).

To mimic ""untrusted"" true certificates, generate an untrusted CA certificate
from the configured trusted CA certificate. This both reduces configuration
effort (compared to a configuration option) and results in identical
untrusted fake certificates given identical Squid configurations.

Intelligent handling of CONNECT denials: Do not connect to origin
servers unless CONNECT is successfully authenticated. Delay errors.Added sslproxy_cert_sign squid.conf option to control how generated SSL
certificates are signed. See squid.conf.documented.

Provide '%I' error page formatting code with enough information to avoid
displaying '[unknown]' on SQUID_X509_V_ERR_DOMAIN_MISMATCH errors.

Set logged status code (%<Hs) to 200 when establishing a bumped tunnel.

Improved error detailing and logging: Forget most retried errors.
During SslBump errors, the error details are now logged with both the
initial CONNECT transaction and the first tunneled HTTP transaction.
Do not report system errors as custom Squid errors. Do not report
system errors that did not necessarily happen during the transaction
being logged.

Check SSL server certificate when reconnecting to the origin server for
bumped requests. Despite pinning, Squid maintains two separate connections
and the server may disconnect while the client is still sending requests. To
minimize deployment problems, we reconnect to the origin server but check
that its certificate (which we mimicked for the client) has not changed
much.

Forward bumped server connection-close signal to the bumped client to
improve the ""dumb tunnel"" appearance of the bumped SSL tunnel.

Allow bumping of CONNECT requests without allow-direct set on http_port.
Previously, that flag was required to allow bumped requests to go direct
because they were (and, sometimes, still are) considered ""accelerated"".

Send SNI information to the server when server-first bumping a non-IP
CONNECT request.

Better helper-to-Squid buffer size management to support large certificates.

Bypass rare OpenSSL certificate serialization failures when composing an
ssl_crtd request by generating the certificate in the Squid process.

When generating certificate CN names, strip [] surrounding host names,
assuming they are for IPv6 addresses. Bracketed CNs confuse browsers.

Disable persistent connections after client-side-detected errors. They cause
""abandoning such and such connection"" warnings, stuck ConnStateData jobs, and
other problems.

HttpRequest::SetHost() must invalidate HttpRequest::canonical ""cache"".

Implement ssl::bump_mode logformat code to log SslBump decisions: prints ""none"",
""client-first"", ""server-first"" or ""-"" for no ssl-bump enabled ports

Synced with trunk (trunk r12216, v3.2.0.18+)

This is a Measurement Factory project.",3561,data/crawl/squid/hunk_2094.cpp,,,data/crawl/squid/old_hunk_2094.cpp,data/crawl/squid/new_hunk_2094.cpp,-1,66,,"storeAppendPrintf(entry, ""%s{%s} "", Ssl::sslCertAdaptAlgoritm(ca->alg), ca->param);","[""addLog""]","[[], [""storeAppendPrintf"", ""entry"", ""%s"", ""%s"", ""Ssl"", ""sslCertAdaptAlgoritm"", ""ca"", ""alg"", ""ca"", ""param""]]",[3422795718846657287],7021,171840.0,3
https://github.com/squid-cache/squid/commit/8621b1ac6e2d63a83a41bd808bd3783dee06e416,18 Jul 2012,"author: Alex Rousskov <rousskov@measurement-factory.com>, Christos Tsantilas <chtsanti@users.sourceforge.net>
SslBump: Support bump-ssl-server-first and mimic SSL server certificates.

Summary: These changes allow Squid working in SslBump mode to peek at
the origin server certificate and mimic peeked server certificate
properties in the generated fake certificate, all prior to establishing
a secure connection with the client:
http://wiki.squid-cache.org/Features/BumpSslServerFirst
http://wiki.squid-cache.org/Features/MimicSslServerCert

The changes are required to bump intercepted SSL connections without
excessive browser warnings. The changes allow to disable bumping of some
intercepted SSL connections, forcing Squid to go into a TCP tunnel mode
for those connections.

The changes also empower end user to examine and either honor or bypass
most origin SSL server certificate errors. Prior to these changes, the
responsibility for ignoring certificate validation errors belonged
exclusively to Squid, necessarily leaving users in the dark if errors
are ignored/bypassed.

Squid can still be configured to emulate old bump-ssl-client-first
behavior.  However, a manual revision of ssl_bump options is required
during upgrade because ssl_bump no longer supports an implicit ""negate
the last one"" rule (and it is risky to let Squid guess what the admin
true intent was or mix old- and new-style rules).

Finally, fake certificate generation has been significantly improved.
The new code guarantees that all identically configured Squids receiving
identical origin server certificates will generate identical fake
certificates, even if those Squid instances are running on different
hosts, at different times, and do not communicate with each other. Such
stable, reproducible certificates are required for distributed,
scalable, or fail-safe Squid deployment.

Overall, the changes are meant to make SslBump more powerful and safer.
The code has been tested in several independent labs.


Specific major changes are highlighted below:

Make bumping algorithm selectable using ACLs. Even though
bump-server-first is an overall better method, bumping the client first
is useful for backward compatibility and possibly for serving internal
Squid objects (such as icons inside Squid error pages).  The following
example bumps special and most other requests only, using the old
bump-client-first approach for the special requests only:

    ssl_bump client-first specialOnes
    ssl_bump server-first mostOthers
    ssl_bump none all

It allow use the old ssl_bump syntax:
   ssl_bump allow/deny acl ...
but warns the user to update squid configuration.

Added sslproxy_cert_adapt squid.conf option to overwrite default mimicking
behavior when generating SSL certificates. See squid.conf.documented.

Added sslproxy_cert_sign squid.conf option to control how generated SSL
certificates are signed. See squid.conf.documented.

Added ssl::certHasExpired, ssl::certNotYetValid, ssl::certDomainMismatch,
ssl::certUntrusted, and ssl::certSelfSign predefined ACLs to squid.conf.

Do not require http[s]_port's key option to be set if cert option is given.
The fixed behavior for bumped connections now matches squid.conf docs.

Generate stable fake certificates by using signing and true certificate
hashes as the serial number and by using the configured CA private key
for all fake certificates.

Use minimal, trusted certificate for serving SSL errors to the client
instead of trying to mimic the broken true certificate (which results
in double error for the user: browser error dialog plus Squid error page).

To mimic ""untrusted"" true certificates, generate an untrusted CA certificate
from the configured trusted CA certificate. This both reduces configuration
effort (compared to a configuration option) and results in identical
untrusted fake certificates given identical Squid configurations.

Intelligent handling of CONNECT denials: Do not connect to origin
servers unless CONNECT is successfully authenticated. Delay errors.Added sslproxy_cert_sign squid.conf option to control how generated SSL
certificates are signed. See squid.conf.documented.

Provide '%I' error page formatting code with enough information to avoid
displaying '[unknown]' on SQUID_X509_V_ERR_DOMAIN_MISMATCH errors.

Set logged status code (%<Hs) to 200 when establishing a bumped tunnel.

Improved error detailing and logging: Forget most retried errors.
During SslBump errors, the error details are now logged with both the
initial CONNECT transaction and the first tunneled HTTP transaction.
Do not report system errors as custom Squid errors. Do not report
system errors that did not necessarily happen during the transaction
being logged.

Check SSL server certificate when reconnecting to the origin server for
bumped requests. Despite pinning, Squid maintains two separate connections
and the server may disconnect while the client is still sending requests. To
minimize deployment problems, we reconnect to the origin server but check
that its certificate (which we mimicked for the client) has not changed
much.

Forward bumped server connection-close signal to the bumped client to
improve the ""dumb tunnel"" appearance of the bumped SSL tunnel.

Allow bumping of CONNECT requests without allow-direct set on http_port.
Previously, that flag was required to allow bumped requests to go direct
because they were (and, sometimes, still are) considered ""accelerated"".

Send SNI information to the server when server-first bumping a non-IP
CONNECT request.

Better helper-to-Squid buffer size management to support large certificates.

Bypass rare OpenSSL certificate serialization failures when composing an
ssl_crtd request by generating the certificate in the Squid process.

When generating certificate CN names, strip [] surrounding host names,
assuming they are for IPv6 addresses. Bracketed CNs confuse browsers.

Disable persistent connections after client-side-detected errors. They cause
""abandoning such and such connection"" warnings, stuck ConnStateData jobs, and
other problems.

HttpRequest::SetHost() must invalidate HttpRequest::canonical ""cache"".

Implement ssl::bump_mode logformat code to log SslBump decisions: prints ""none"",
""client-first"", ""server-first"" or ""-"" for no ssl-bump enabled ports

Synced with trunk (trunk r12216, v3.2.0.18+)

This is a Measurement Factory project.",3561,data/crawl/squid/hunk_2093.cpp,,,data/crawl/squid/old_hunk_2093.cpp,data/crawl/squid/new_hunk_2093.cpp,-1,37,,"fatalf(""Unable to generate  signing SSL certificate for untrusted sites for %s_port %s"", protocol, s.ToURL(buf, sizeof(buf)));","[""addLog""]","[[], [""fatalf"", ""Unable"", ""to"", ""generate"", ""signing"", ""SSL"", ""certificate"", ""for"", ""untrusted"", ""sites"", ""for"", ""%s_port"", ""%s"", ""protocol"", ""s"", ""ToURL"", ""buf"", ""sizeof"", ""buf""]]",[2352543332009545962],7020,114240.0,3
https://github.com/squid-cache/squid/commit/8621b1ac6e2d63a83a41bd808bd3783dee06e416,18 Jul 2012,"author: Alex Rousskov <rousskov@measurement-factory.com>, Christos Tsantilas <chtsanti@users.sourceforge.net>
SslBump: Support bump-ssl-server-first and mimic SSL server certificates.

Summary: These changes allow Squid working in SslBump mode to peek at
the origin server certificate and mimic peeked server certificate
properties in the generated fake certificate, all prior to establishing
a secure connection with the client:
http://wiki.squid-cache.org/Features/BumpSslServerFirst
http://wiki.squid-cache.org/Features/MimicSslServerCert

The changes are required to bump intercepted SSL connections without
excessive browser warnings. The changes allow to disable bumping of some
intercepted SSL connections, forcing Squid to go into a TCP tunnel mode
for those connections.

The changes also empower end user to examine and either honor or bypass
most origin SSL server certificate errors. Prior to these changes, the
responsibility for ignoring certificate validation errors belonged
exclusively to Squid, necessarily leaving users in the dark if errors
are ignored/bypassed.

Squid can still be configured to emulate old bump-ssl-client-first
behavior.  However, a manual revision of ssl_bump options is required
during upgrade because ssl_bump no longer supports an implicit ""negate
the last one"" rule (and it is risky to let Squid guess what the admin
true intent was or mix old- and new-style rules).

Finally, fake certificate generation has been significantly improved.
The new code guarantees that all identically configured Squids receiving
identical origin server certificates will generate identical fake
certificates, even if those Squid instances are running on different
hosts, at different times, and do not communicate with each other. Such
stable, reproducible certificates are required for distributed,
scalable, or fail-safe Squid deployment.

Overall, the changes are meant to make SslBump more powerful and safer.
The code has been tested in several independent labs.


Specific major changes are highlighted below:

Make bumping algorithm selectable using ACLs. Even though
bump-server-first is an overall better method, bumping the client first
is useful for backward compatibility and possibly for serving internal
Squid objects (such as icons inside Squid error pages).  The following
example bumps special and most other requests only, using the old
bump-client-first approach for the special requests only:

    ssl_bump client-first specialOnes
    ssl_bump server-first mostOthers
    ssl_bump none all

It allow use the old ssl_bump syntax:
   ssl_bump allow/deny acl ...
but warns the user to update squid configuration.

Added sslproxy_cert_adapt squid.conf option to overwrite default mimicking
behavior when generating SSL certificates. See squid.conf.documented.

Added sslproxy_cert_sign squid.conf option to control how generated SSL
certificates are signed. See squid.conf.documented.

Added ssl::certHasExpired, ssl::certNotYetValid, ssl::certDomainMismatch,
ssl::certUntrusted, and ssl::certSelfSign predefined ACLs to squid.conf.

Do not require http[s]_port's key option to be set if cert option is given.
The fixed behavior for bumped connections now matches squid.conf docs.

Generate stable fake certificates by using signing and true certificate
hashes as the serial number and by using the configured CA private key
for all fake certificates.

Use minimal, trusted certificate for serving SSL errors to the client
instead of trying to mimic the broken true certificate (which results
in double error for the user: browser error dialog plus Squid error page).

To mimic ""untrusted"" true certificates, generate an untrusted CA certificate
from the configured trusted CA certificate. This both reduces configuration
effort (compared to a configuration option) and results in identical
untrusted fake certificates given identical Squid configurations.

Intelligent handling of CONNECT denials: Do not connect to origin
servers unless CONNECT is successfully authenticated. Delay errors.Added sslproxy_cert_sign squid.conf option to control how generated SSL
certificates are signed. See squid.conf.documented.

Provide '%I' error page formatting code with enough information to avoid
displaying '[unknown]' on SQUID_X509_V_ERR_DOMAIN_MISMATCH errors.

Set logged status code (%<Hs) to 200 when establishing a bumped tunnel.

Improved error detailing and logging: Forget most retried errors.
During SslBump errors, the error details are now logged with both the
initial CONNECT transaction and the first tunneled HTTP transaction.
Do not report system errors as custom Squid errors. Do not report
system errors that did not necessarily happen during the transaction
being logged.

Check SSL server certificate when reconnecting to the origin server for
bumped requests. Despite pinning, Squid maintains two separate connections
and the server may disconnect while the client is still sending requests. To
minimize deployment problems, we reconnect to the origin server but check
that its certificate (which we mimicked for the client) has not changed
much.

Forward bumped server connection-close signal to the bumped client to
improve the ""dumb tunnel"" appearance of the bumped SSL tunnel.

Allow bumping of CONNECT requests without allow-direct set on http_port.
Previously, that flag was required to allow bumped requests to go direct
because they were (and, sometimes, still are) considered ""accelerated"".

Send SNI information to the server when server-first bumping a non-IP
CONNECT request.

Better helper-to-Squid buffer size management to support large certificates.

Bypass rare OpenSSL certificate serialization failures when composing an
ssl_crtd request by generating the certificate in the Squid process.

When generating certificate CN names, strip [] surrounding host names,
assuming they are for IPv6 addresses. Bracketed CNs confuse browsers.

Disable persistent connections after client-side-detected errors. They cause
""abandoning such and such connection"" warnings, stuck ConnStateData jobs, and
other problems.

HttpRequest::SetHost() must invalidate HttpRequest::canonical ""cache"".

Implement ssl::bump_mode logformat code to log SslBump decisions: prints ""none"",
""client-first"", ""server-first"" or ""-"" for no ssl-bump enabled ports

Synced with trunk (trunk r12216, v3.2.0.18+)

This is a Measurement Factory project.",3561,data/crawl/squid/hunk_2093.cpp,,,data/crawl/squid/old_hunk_2093.cpp,data/crawl/squid/new_hunk_2093.cpp,-1,26,,"fatalf(""No valid signing SSL certificate configured for %s_port %s"", protocol,  s.ToURL(buf, sizeof(buf)));","[""addLog""]","[[], [""fatalf"", ""No"", ""valid"", ""signing"", ""SSL"", ""certificate"", ""configured"", ""for"", ""%s_port"", ""%s"", ""protocol"", ""s"", ""ToURL"", ""buf"", ""sizeof"", ""buf""]]",[-5703592576602632753],7019,114240.0,3
https://github.com/squid-cache/squid/commit/b632b875fc726b9eb4e57535e93c4ae1f038818c,09 Aug 2012,Convert all yet-unconverted stub files to the STUB API.,226,data/crawl/squid/hunk_2077.cpp,,,data/crawl/squid/old_hunk_2077.cpp,data/crawl/squid/new_hunk_2077.cpp,6,-1,"fprintf(stderr, ""HelperChildConfig::parseConfig not implemented."");",,"[""removeLog""]","[[""fprintf"", ""stderr"", ""HelperChildConfig"", ""parseConfig"", ""not"", ""implemented""], []]",[15049532103204724158],7018,480.0,3
https://github.com/squid-cache/squid/commit/2d612ae7ecf98d658053f9e43a4893424cf59646,03 Oct 2012,"sourceformat: split protos.h into more specific headers, change many functions' likage to c++.",6626,data/crawl/squid/hunk_2001.cpp,,,data/crawl/squid/old_hunk_2001.cpp,data/crawl/squid/new_hunk_2001.cpp,3,3,">putStr(HDR_CONNECTION, request->flags.proxy_keepalive ? ""keep-alive"" : ""close"");",">putStr(HDR_CONNECTION, request->flags.proxyKeepalive ? ""keep-alive"" : ""close"");","[""updateVariable""]","[[""proxy_keepalive""], [""proxyKeepalive""]]",[-11626908043684631500],7017,12480.0,3
https://github.com/squid-cache/squid/commit/e166785ad679d33acc445d2d96facc065bc63a35,29 Oct 2012,"Support OK/ERR/BH response codes from any helper

Updates the helper reponse callback API from using char* buffer to a
HelperReply object storing teh response code, a blob buffer, and 
pointer to the responding helper 'server' (if stateful).

* the helper I/O read handler is updated to parse the result code off
the start of the helper response as is currently done for channel-ID.
The callback handlers are altered to use the HelperReply::status instead
of parsing it off themselves individually.

* the remaining I/O read buffer is stored in a MemBuf and callbacks are
updated to use it via the method other().

* the responding helper-server is stored into the HelperReply object and
stateful helper callbacks are combined into the same API as stateless.
The callback handlers are updated to use HelperReply::lastserver instead
of function parameter.

After this patch the helper response format is:
  [channel-ID] SP [result] [ [SP] blob] <terminator>

'SP' being one octet \0x20 character.

The behavour changes expected from this is that all helpers are now able
to send OK/ERR/BH states. Although the handlers for some helpers will
deal with the new states as unknown response. None of the bundled
helpers have yet been altered to make use of this changed potential.

TODO:
* implement key=value parser for the blob area of the format, and update
handlers to use the HelperReply API to retrieve them.
* upgrade helpers to make use of new response format",558,data/crawl/squid/hunk_1960.cpp,,,data/crawl/squid/old_hunk_1960.cpp,data/crawl/squid/new_hunk_1960.cpp,5,-1,"fatalf(""authenticateNTLMHandleReply: *** Unsupported helper response ***, '%s'\n"", reply);",,"[""removeLog""]","[[""fatalf"", ""authenticateNTLMHandleReply"", ""***"", ""Unsupported"", ""helper"", ""response"", ""***"", ""%s"", ""\\n"", ""reply""], []]",[3623871199738568275],7016,825600.0,3
https://github.com/squid-cache/squid/commit/e166785ad679d33acc445d2d96facc065bc63a35,29 Oct 2012,"Support OK/ERR/BH response codes from any helper

Updates the helper reponse callback API from using char* buffer to a
HelperReply object storing teh response code, a blob buffer, and 
pointer to the responding helper 'server' (if stateful).

* the helper I/O read handler is updated to parse the result code off
the start of the helper response as is currently done for channel-ID.
The callback handlers are altered to use the HelperReply::status instead
of parsing it off themselves individually.

* the remaining I/O read buffer is stored in a MemBuf and callbacks are
updated to use it via the method other().

* the responding helper-server is stored into the HelperReply object and
stateful helper callbacks are combined into the same API as stateless.
The callback handlers are updated to use HelperReply::lastserver instead
of function parameter.

After this patch the helper response format is:
  [channel-ID] SP [result] [ [SP] blob] <terminator>

'SP' being one octet \0x20 character.

The behavour changes expected from this is that all helpers are now able
to send OK/ERR/BH states. Although the handlers for some helpers will
deal with the new states as unknown response. None of the bundled
helpers have yet been altered to make use of this changed potential.

TODO:
* implement key=value parser for the blob area of the format, and update
handlers to use the HelperReply API to retrieve them.
* upgrade helpers to make use of new response format",558,data/crawl/squid/hunk_1957.cpp,,,data/crawl/squid/old_hunk_1957.cpp,data/crawl/squid/new_hunk_1957.cpp,6,-1,"fatalf(""authenticateNegotiateHandleReply: *** Unsupported helper response ***, '%s'\n"", reply);",,"[""removeLog""]","[[""fatalf"", ""authenticateNegotiateHandleReply"", ""***"", ""Unsupported"", ""helper"", ""response"", ""***"", ""%s"", ""\\n"", ""reply""], []]",[-2877559570256363225],7015,825600.0,3
https://github.com/squid-cache/squid/commit/637c35b2073582f30a4601f98b19fc5fc9c6e976,13 Nov 2012,merge from SslServerCertValidator r12332,16798,data/crawl/squid/hunk_1927.cpp,,,data/crawl/squid/old_hunk_1927.cpp,data/crawl/squid/new_hunk_1927.cpp,-1,118,,"storeAppendPrintf(entry, ""%s "" SQUIDSTRINGPH "" %s"",
                              key, SQUIDSTRINGPRINT((*m)->key), ConfigParser::QuoteString((*v)->value));","[""addLog""]","[[], [""storeAppendPrintf"", ""entry"", ""%s"", ""SQUIDSTRINGPH"", ""%s"", ""key"", ""SQUIDSTRINGPRINT"", ""*m"", ""key"", ""ConfigParser"", ""QuoteString"", ""*v"", ""value""]]",[-561083083629220026],7014,17280.0,3
https://github.com/squid-cache/squid/commit/637c35b2073582f30a4601f98b19fc5fc9c6e976,13 Nov 2012,merge from SslServerCertValidator r12332,16798,data/crawl/squid/hunk_1927.cpp,,,data/crawl/squid/old_hunk_1927.cpp,data/crawl/squid/new_hunk_1927.cpp,-1,101,,"fatalf(""%s:%d: meta key \""%s\"" is a reserved %s name"",
                       cfg_filename, config_lineno, note->key.termedBuf(),
                       descr ? descr : """");","[""addLog""]","[[], [""fatalf"", ""%s"", ""%d"", ""meta"", ""key"", ""\\"", ""%s\\"", ""is"", ""a"", ""reserved"", ""%s"", ""name"", ""cfg_filename"", ""config_lineno"", ""note"", ""key"", ""termedBuf"", ""descr"", ""descr""]]",[31843372144641062895],7013,17280.0,3
https://github.com/squid-cache/squid/commit/637c35b2073582f30a4601f98b19fc5fc9c6e976,13 Nov 2012,merge from SslServerCertValidator r12332,16798,data/crawl/squid/hunk_1921.cpp,,,data/crawl/squid/old_hunk_1921.cpp,data/crawl/squid/new_hunk_1921.cpp,-1,20,,"fatalf(""Disk Threads I/O pipes not initialized before first use."");","[""addLog""]","[[], [""fatalf"", ""Disk"", ""Threads"", ""I/O"", ""pipes"", ""not"", ""initialized"", ""before"", ""first"", ""use""]]",[19287123141693404468],7012,14400.0,3
https://github.com/squid-cache/squid/commit/fd7f26eaf8b41da6b4131ee33d2c898a888b2044,27 Nov 2012,"Audit Review updates

* guarantee that note values output by the HelperReply parser are """"
  nil-terminated string and not undefined String.
* rename HelperReply::responseKeys to 'notes'
* rename Notes::findByName() to find()
* add Note::firstValue() to locate first value provided for a given key
  and present it as a char* terminated string
* various documentation updates",141,data/crawl/squid/hunk_1892.cpp,,,data/crawl/squid/old_hunk_1892.cpp,data/crawl/squid/new_hunk_1892.cpp,5,5,digest_request->setDenyMessage(msgNote->values[0]->value.termedBuf());,digest_request->setDenyMessage(msgNote->firstValue());,"[""updateVariable"", ""moveVariable"", ""removeVariable"", ""removeContent""]","[[""values[0]"", ""value"", ""termedBuf""], [""firstValue""]]",[-7920885891220566413],7011,0.0,3
https://github.com/squid-cache/squid/commit/fc6df0c3a619d283bcd0f755409d5f3ec9554007,04 Dec 2012,merge from parent SslServerCertValidator r12337,2116,data/crawl/squid/hunk_1845.cpp,,,data/crawl/squid/old_hunk_1845.cpp,data/crawl/squid/new_hunk_1845.cpp,-1,4,,"fprintf(stderr, ""%s: can't identify length of file (%s)\n"", argv[0], xstrerror());","[""addLog""]","[[], [""fprintf"", ""stderr"", ""%s"", ""can"", ""t"", ""identify"", ""length"", ""of"", ""file"", ""%s"", ""\\n"", ""argv[0]"", ""xstrerror""]]",[1984672696862652088],7010,17280.0,3
https://github.com/squid-cache/squid/commit/fc6df0c3a619d283bcd0f755409d5f3ec9554007,04 Dec 2012,merge from parent SslServerCertValidator r12337,2116,data/crawl/squid/hunk_1841.cpp,,,data/crawl/squid/old_hunk_1841.cpp,data/crawl/squid/new_hunk_1841.cpp,3,3,"fatal(""Failed to open swap log for reading"");","fatalf(""Failed to open swap log for reading %s"", swaplog_path);","[""updateLog"", ""updateContent"", ""addVariable""]","[[""fatal""], [""fatalf"", ""%s"", ""swaplog_path""]]",[4733547812641902954],7009,3840.0,3
https://github.com/squid-cache/squid/commit/fc6df0c3a619d283bcd0f755409d5f3ec9554007,04 Dec 2012,merge from parent SslServerCertValidator r12337,2116,data/crawl/squid/hunk_1840.cpp,,,data/crawl/squid/old_hunk_1840.cpp,data/crawl/squid/new_hunk_1840.cpp,3,3,"fatal(""UFSSwapDir::openTmpSwapLog: Failed to open swap log."");","fatalf(""Failed to open swap log %s"", new_path);","[""updateLog"", ""updateContent"", ""addVariable""]","[[""fatal"", ""UFSSwapDir"", ""openTmpSwapLog""], [""fatalf"", ""%s"", ""new_path""]]",[10528854663160828935],7008,3840.0,3
https://github.com/squid-cache/squid/commit/fc6df0c3a619d283bcd0f755409d5f3ec9554007,04 Dec 2012,merge from parent SslServerCertValidator r12337,2116,data/crawl/squid/hunk_1839.cpp,,,data/crawl/squid/old_hunk_1839.cpp,data/crawl/squid/new_hunk_1839.cpp,10,9,"fatalf(""Failed to rename log file %s to %s.new"", swaplog_path, swaplog_path);","fatalf(""Failed to rename log file %s to %s"", tmp_path, swaplog_path);","[""updateVariable"", ""updateContent""]","[[""new"", ""swaplog_path""], [""tmp_path""]]",[-6635065609728656627],7007,3840.0,3
https://github.com/squid-cache/squid/commit/fc6df0c3a619d283bcd0f755409d5f3ec9554007,04 Dec 2012,merge from parent SslServerCertValidator r12337,2116,data/crawl/squid/hunk_1837.cpp,,,data/crawl/squid/old_hunk_1837.cpp,data/crawl/squid/new_hunk_1837.cpp,-1,3,,"mustStop(""externally aborted"");","[""addLog""]","[[], [""mustStop"", ""externally"", ""aborted""]]",[-21285172630784138485],7006,2880.0,3
https://github.com/squid-cache/squid/commit/fc6df0c3a619d283bcd0f755409d5f3ec9554007,04 Dec 2012,merge from parent SslServerCertValidator r12337,2116,data/crawl/squid/hunk_1834.cpp,,,data/crawl/squid/old_hunk_1834.cpp,data/crawl/squid/new_hunk_1834.cpp,-1,40,,auth_user_request->denyMessage(errNote->firstValue());,"[""addLog""]","[[], [""auth_user_request"", ""denyMessage"", ""errNote"", ""firstValue""]]",[-7285367826216588968],7005,6720.0,3
https://github.com/squid-cache/squid/commit/fc6df0c3a619d283bcd0f755409d5f3ec9554007,04 Dec 2012,merge from parent SslServerCertValidator r12337,2116,data/crawl/squid/hunk_1834.cpp,,,data/crawl/squid/old_hunk_1834.cpp,data/crawl/squid/new_hunk_1834.cpp,15,17,auth_user_request->denyMessage(arg);,auth_user_request->denyMessage(messageNote->firstValue());,"[""removeVariable"", ""addVariable""]","[[""arg""], [""messageNote"", ""firstValue""]]",[-15861014039095818322],7004,6720.0,3
https://github.com/squid-cache/squid/commit/fc6df0c3a619d283bcd0f755409d5f3ec9554007,04 Dec 2012,merge from parent SslServerCertValidator r12337,2116,data/crawl/squid/hunk_1832.cpp,,,data/crawl/squid/old_hunk_1832.cpp,data/crawl/squid/new_hunk_1832.cpp,-1,55,,digest_request->setDenyMessage(msgNote->firstValue());,"[""addLog""]","[[], [""digest_request"", ""setDenyMessage"", ""msgNote"", ""firstValue""]]",[6639356828016837016],7003,6720.0,3
https://github.com/squid-cache/squid/commit/fc6df0c3a619d283bcd0f755409d5f3ec9554007,04 Dec 2012,merge from parent SslServerCertValidator r12337,2116,data/crawl/squid/hunk_1825.cpp,,,data/crawl/squid/old_hunk_1825.cpp,data/crawl/squid/new_hunk_1825.cpp,3,3,"fprintf(stderr, ""WARNING: %s writing %s. Attempting to recover via a log rotation.\n"",strerror(err),argv[1]);","fprintf(stderr, ""WARNING: %s writing %s. Attempting to recover via a log rotation.\n"",xstrerr(err),argv[1]);","[""updateVariable""]","[[""strerror""], [""xstrerr""]]",[-5201201212762092628],7002,15360.0,3
https://github.com/squid-cache/squid/commit/fc6df0c3a619d283bcd0f755409d5f3ec9554007,04 Dec 2012,merge from parent SslServerCertValidator r12337,2116,data/crawl/squid/hunk_1823.cpp,,,data/crawl/squid/old_hunk_1823.cpp,data/crawl/squid/new_hunk_1823.cpp,-1,22,,"fprintf(stderr, ""ERROR: missing 'period' field on line %u of '%s'.\n"", lineCount, filename);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""ERROR"", ""missing"", ""period"", ""field"", ""on"", ""line"", ""%u"", ""of"", ""%s"", ""\\n"", ""lineCount"", ""filename""]]",[-9040306044563822023],7001,19200.0,3
https://github.com/squid-cache/squid/commit/fc6df0c3a619d283bcd0f755409d5f3ec9554007,04 Dec 2012,merge from parent SslServerCertValidator r12337,2116,data/crawl/squid/hunk_1823.cpp,,,data/crawl/squid/old_hunk_1823.cpp,data/crawl/squid/new_hunk_1823.cpp,-1,18,,"fprintf(stderr, ""ERROR: missing 'budget' field on line %u of '%s'.\n"", lineCount, filename);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""ERROR"", ""missing"", ""budget"", ""field"", ""on"", ""line"", ""%u"", ""of"", ""%s"", ""\\n"", ""lineCount"", ""filename""]]",[-5496400249466088807],7000,19200.0,3
https://github.com/squid-cache/squid/commit/fc6df0c3a619d283bcd0f755409d5f3ec9554007,04 Dec 2012,merge from parent SslServerCertValidator r12337,2116,data/crawl/squid/hunk_1822.cpp,,,data/crawl/squid/old_hunk_1822.cpp,data/crawl/squid/new_hunk_1822.cpp,-1,5,,"fprintf(stderr, ""%s: FATAL: Unable to open file '%s': %s"", program_name, filename, xstrerror());","[""addLog""]","[[], [""fprintf"", ""stderr"", ""%s"", ""FATAL"", ""Unable"", ""to"", ""open"", ""file"", ""%s"", ""%s"", ""program_name"", ""filename"", ""xstrerror""]]",[-20451433145615024222],6999,19200.0,3
https://github.com/squid-cache/squid/commit/fc6df0c3a619d283bcd0f755409d5f3ec9554007,04 Dec 2012,merge from parent SslServerCertValidator r12337,2116,data/crawl/squid/hunk_1821.cpp,,,data/crawl/squid/old_hunk_1821.cpp,data/crawl/squid/new_hunk_1821.cpp,-1,5,,"fprintf(stderr, ""digest_file_auth: cannot open password file: %s\n"", xstrerror());","[""addLog""]","[[], [""fprintf"", ""stderr"", ""digest_file_auth"", ""cannot"", ""open"", ""password"", ""file"", ""%s\\n"", ""xstrerror""]]",[-5116394615007373690],6998,19200.0,3
https://github.com/squid-cache/squid/commit/fc6df0c3a619d283bcd0f755409d5f3ec9554007,04 Dec 2012,merge from parent SslServerCertValidator r12337,2116,data/crawl/squid/hunk_1816.cpp,,,data/crawl/squid/old_hunk_1816.cpp,data/crawl/squid/new_hunk_1816.cpp,-1,4,,"fprintf(stderr,""%s| ERROR: fcntl() failure: %s\n"", argv[0], xstrerror());","[""addLog""]","[[], [""fprintf"", ""stderr"", ""%s"", ""ERROR"", ""fcntl"", ""failure"", ""%s\\n"", ""argv[0]"", ""xstrerror""]]",[-7027583557500576595],6997,19200.0,3
https://github.com/squid-cache/squid/commit/fc6df0c3a619d283bcd0f755409d5f3ec9554007,04 Dec 2012,merge from parent SslServerCertValidator r12337,2116,data/crawl/squid/hunk_1814.cpp,,,data/crawl/squid/old_hunk_1814.cpp,data/crawl/squid/new_hunk_1814.cpp,-1,12,,"fprintf(stderr, ""ERROR: Missing user name at %s line %d\n"", passwdfile, lineCount);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""ERROR"", ""Missing"", ""user"", ""name"", ""at"", ""%s"", ""line"", ""%d\\n"", ""passwdfile"", ""lineCount""]]",[-963025474436057684],6996,20160.0,3
https://github.com/squid-cache/squid/commit/cf9f0261d2588344038a89f764325b80179a7e0d,29 Apr 2013,"HttpRequest::helperNotes to NotePairs

This patch try to fix current current Notes interface and usage.
The changes done having in mind that we need:

  1) to add multiple notes with the same key
  2) to support 3 different note types: adaptation meta headers, helper notes
    and custom notes added by the system administrator
  3) to log notes using the %note formating code
  4) to use the %note formating code everywhere the formating API is used. For
    example use the %note with the request_header_add configuration parameter.
  5) to use notes with ACLs.

Details:
 - The NotePairs class is not a kid of HttpHeader class anymore. It is
   implemented from scratch to cover Helper/adaptation and custom notes needs.
     * The new class stores key:value pairs in list. It allow multiple entries
       with the same key.
     * Includes a find method which return a coma separated list of values
       for a given key
 - The HttpRequest::helperNotes is now a Refcount of a HttpPairs object
 - The HelperReply::notes is now a HttpPairs object
 - The AccessLogEntry::notes now is a RefCount of a HttpPairs object, and
   stores only the custom notes add by the ""note"" configuration parameter
 - Add the AccessLogEntry::helperNotes which is a RefCount of a HttpPairs object
   to store notes added by helpers.
   Now the notes added by adaptation or helpers are accessible to format/* code
   imediatelly after added. Before this patch are accessible only for logging.

Future work:
 - Posible merge AccessLogEntry::notes and AccessLogEntry::helperNotes
 - Performance fixes

This is a Measurement Factory project",488,data/crawl/squid/hunk_1760.cpp,,,data/crawl/squid/old_hunk_1760.cpp,data/crawl/squid/new_hunk_1760.cpp,5,5,digest_request->setDenyMessage(msgNote->firstValue());,digest_request->setDenyMessage(msgNote);,"[""removeVariable"", ""addVariable""]","[[""firstValue""], []]",[5958936810815123457],6995,0.0,3
https://github.com/squid-cache/squid/commit/eb6ac8089e8b4157aad32f3e4616569746ffe6f3,26 Jul 2013,"Update the http(s)_port directives protocol= parameter

... to use AnyP::ProtocolVersion for internal storage instead of opaque
string text.

This both limits the possible parameter values to one of HTTP, HTTP/1.1,
HTTPS or HTTPS/1.1 and ensures that URLs generated from that protocol
parameter value are http:// and https:// URL. 
Other values will cause Squid to abort.",107,data/crawl/squid/hunk_1695.cpp,,,data/crawl/squid/old_hunk_1695.cpp,data/crawl/squid/new_hunk_1695.cpp,3,3,"fatalf(""No valid signing SSL certificate configured for %s_port %s"", protocol,  s.toUrl(buf, sizeof(buf)));","fatalf(""No valid signing SSL certificate configured for %s_port %s"", AnyP::ProtocolType_str[transport.protocol],  s.toUrl(buf, sizeof(buf)));","[""removeVariable"", ""addVariable""]","[[""protocol""], [""AnyP"", ""ProtocolType_str[transport"", ""protocol]""]]",[-6088442366351739298],6994,0.0,3
https://github.com/squid-cache/squid/commit/73656056cdcface25c015c755e9a3688acd404fc,30 Sep 2013,"Remove COSS

This storage type has been superceded by Rock storage since 3.2.",3034,data/crawl/squid/hunk_1682.cpp,,,data/crawl/squid/old_hunk_1682.cpp,data/crawl/squid/new_hunk_1682.cpp,106,-1,"storeAppendPrintf(sentry, ""\n                   OPS     SUCCESS        FAIL\n"");",,"[""removeLog""]","[[""storeAppendPrintf"", ""sentry"", ""\\n"", ""OPS"", ""SUCCESS"", ""FAIL\\n""], []]",[-8741072292188538015],6993,3061440.0,3
https://github.com/squid-cache/squid/commit/fa2301d26b90cbd1298eb7740e8827c7746cd9d2,01 Jan 2014,"Initial Large Rock and Collapsed Forwarding support.

Large Rock: Support disk (and shared memory) caching of responses exceeding
one db slot (or one shared memory page) in size. A single db slot/page size is
still limited to 32KB (smaller values can be configured for disk caches using
the newly added cache_dir slot-size option). Removal of old rock cache dir
(followed by squid-z) is required -- the on-disk db structure has changed.

Collapsed Forwarding: Optionally merge concurrent cachable requests for the
same URI earlier: After the request headers have been parsed (as before), but
now _before_ the response headers have been received. Merging of requests
received by different SMP workers is supported. Controlled by the new
collapsed_forwarding directive in squid.conf. Disabled by default because all
but one of the merged requests have to be delayed (until the response headers
are received) for the merging to work, which may be worse than forwarding all
concurrent requests immediately. The overall feature idea and request
eligibility conditions are based on Collapsed Forwarding in Squid2.


Summary of other important changes (merged branch log contains the details):

* Tightened StoreEntry locking. Split StoreEntry::lock() into ""just lock"" and
  ""update entry reference time"" interfaces, addressing an old XXX.  Improved
  entry lock/unlock debugging. Needs more work.

* Adjusted StoreIOState::write() API to allow callers detect write errors.

* Simplified MemObject::write() API to remove an essentially unused callback.

* Mark client streams that sent everything as STREAM_COMPLETE. The old code
  used STREAM_UNPLANNED_COMPLETE if the completed stream was associated with a
  non-persistent connection, which did not make sense to me and, IIRC, led to
  store entry aborts even though the entries were not damaged in any way.

* mem_hdr::hasContigousContentRange() now returns true for empty ranges.

* Support ""appending"" ReadWriteLock state that can be shared by readers and
  the writer. The writer promises not to update key metadata (except growing
  object size and next pointers) and readers promise to be careful when
  reading growing slices.

* Fixed StoreEntry::mayStartSwapOut() logic to handle terminated swapouts.

* Improved STORE_MEM_CLIENT detection and documented known (and mostly old)
  StoreEntry::storeClientType() problems.

* Removed StoreEntry::hidden_mem_obj hack.

* Polished StoreEntry debugging to report more info, less noise. Use e: prefix.

* Added a script to extract store entry(ies) debugging from cache.log.",6196,data/crawl/squid/hunk_1639.cpp,,,data/crawl/squid/old_hunk_1639.cpp,data/crawl/squid/new_hunk_1639.cpp,-1,4,,"storeAppendPrintf(&e, ""Current Size: %.2f KB %.2f%%\n"",
                      currentSize() / 1024.0,
                      Math::doublePercent(currentSize(), maxSize()));","[""addLog""]","[[], [""storeAppendPrintf"", ""&e"", ""Current"", ""Size"", ""%"", ""2f"", ""KB"", ""%"", ""2f%%\\n"", ""currentSize"", ""/"", ""1024"", ""0"", ""Math"", ""doublePercent"", ""currentSize"", ""maxSize""]]",[-13220344648006792379],6992,807360.0,3
https://github.com/squid-cache/squid/commit/572d2e31eb73a7db23f4b00f14ac45bc2667ac29,21 Feb 2014,"Bug 3186, Bug 3628: Digest authentication always sending stale=false for nonce",100,data/crawl/squid/hunk_1593.cpp,,,data/crawl/squid/old_hunk_1593.cpp,data/crawl/squid/new_hunk_1593.cpp,-1,11,,"digest_request->setDenyMessage(""Stale nonce"");","[""addLog""]","[[], [""digest_request"", ""setDenyMessage"", ""Stale"", ""nonce""]]",[23687127897404164687],6991,2443200.0,3
https://github.com/squid-cache/squid/commit/ae61f2a70b4839175e1896fb984276ec9b122686,17 Mar 2014,Remove XMALLOC_TRACE and references to sbrk(2),348,data/crawl/squid/hunk_1576.cpp,,,data/crawl/squid/old_hunk_1576.cpp,data/crawl/squid/new_hunk_1576.cpp,182,-1,"fprintf(stderr, ""No memory leaks detected\n"");",,"[""removeLog""]","[[""fprintf"", ""stderr"", ""No"", ""memory"", ""leaks"", ""detected\\n""], []]",[9734286523197740853],6990,1163040.0,3
https://github.com/squid-cache/squid/commit/ae61f2a70b4839175e1896fb984276ec9b122686,17 Mar 2014,Remove XMALLOC_TRACE and references to sbrk(2),348,data/crawl/squid/hunk_1576.cpp,,,data/crawl/squid/old_hunk_1576.cpp,data/crawl/squid/new_hunk_1576.cpp,180,-1,"fprintf(stderr, ""Total leaked memory: %d\n"", leak_sum);",,"[""removeLog""]","[[""fprintf"", ""stderr"", ""Total"", ""leaked"", ""memory"", ""%d\\n"", ""leak_sum""], []]",[-1090480920425176742],6989,1163040.0,3
https://github.com/squid-cache/squid/commit/ae61f2a70b4839175e1896fb984276ec9b122686,17 Mar 2014,Remove XMALLOC_TRACE and references to sbrk(2),348,data/crawl/squid/hunk_1576.cpp,,,data/crawl/squid/old_hunk_1576.cpp,data/crawl/squid/new_hunk_1576.cpp,173,-1,"fprintf(stderr, "" allocation %d\n"", malloc_count[B][I]);",,"[""removeLog""]","[[""fprintf"", ""stderr"", ""allocation"", ""%d\\n"", ""malloc_count[B][I]""], []]",[10462376222229726382],6988,1163040.0,3
https://github.com/squid-cache/squid/commit/ae61f2a70b4839175e1896fb984276ec9b122686,17 Mar 2014,Remove XMALLOC_TRACE and references to sbrk(2),348,data/crawl/squid/hunk_1576.cpp,,,data/crawl/squid/old_hunk_1576.cpp,data/crawl/squid/new_hunk_1576.cpp,172,-1,"fprintf(stderr, "" size %d"", malloc_size[B][I]);",,"[""removeLog""]","[[""fprintf"", ""stderr"", ""size"", ""%d"", ""malloc_size[B][I]""], []]",[23792901597658945470],6987,1163040.0,3
https://github.com/squid-cache/squid/commit/ae61f2a70b4839175e1896fb984276ec9b122686,17 Mar 2014,Remove XMALLOC_TRACE and references to sbrk(2),348,data/crawl/squid/hunk_1576.cpp,,,data/crawl/squid/old_hunk_1576.cpp,data/crawl/squid/new_hunk_1576.cpp,171,-1,"fprintf(stderr, "":%d"", malloc_line[B][I]);",,"[""removeLog""]","[[""fprintf"", ""stderr"", ""%d"", ""malloc_line[B][I]""], []]",[20829002662514788700],6986,1163040.0,3
https://github.com/squid-cache/squid/commit/ae61f2a70b4839175e1896fb984276ec9b122686,17 Mar 2014,Remove XMALLOC_TRACE and references to sbrk(2),348,data/crawl/squid/hunk_1576.cpp,,,data/crawl/squid/old_hunk_1576.cpp,data/crawl/squid/new_hunk_1576.cpp,170,-1,"fprintf(stderr, "" %s"", malloc_file[B][I]);",,"[""removeLog""]","[[""fprintf"", ""stderr"", ""%s"", ""malloc_file[B][I]""], []]",[14996614139783100611],6985,1163040.0,3
https://github.com/squid-cache/squid/commit/ae61f2a70b4839175e1896fb984276ec9b122686,17 Mar 2014,Remove XMALLOC_TRACE and references to sbrk(2),348,data/crawl/squid/hunk_1576.cpp,,,data/crawl/squid/old_hunk_1576.cpp,data/crawl/squid/new_hunk_1576.cpp,169,-1,"fprintf(stderr, ""Leak found: %p"", malloc_ptrs[B][I]);",,"[""removeLog""]","[[""fprintf"", ""stderr"", ""Leak"", ""found"", ""%p"", ""malloc_ptrs[B][I]""], []]",[2325989577404035541],6984,1163040.0,3
https://github.com/squid-cache/squid/commit/ae61f2a70b4839175e1896fb984276ec9b122686,17 Mar 2014,Remove XMALLOC_TRACE and references to sbrk(2),348,data/crawl/squid/hunk_1576.cpp,,,data/crawl/squid/old_hunk_1576.cpp,data/crawl/squid/new_hunk_1576.cpp,139,-1,"fprintf(stderr, ""%*s%p %s:%d size %d allocation %d ... (%d)\n"",
                                depth * 2, """",
                                malloc_ptrs[B][I], malloc_file[B][I],
                                malloc_line[B][I], malloc_size[B][I],
                                malloc_count[B][I], malloc_refs[B][I]);",,"[""removeLog""]","[[""fprintf"", ""stderr"", ""%*s%p"", ""%s"", ""%d"", ""size"", ""%d"", ""allocation"", ""%d"", ""%d"", ""\\n"", ""depth"", ""*"", ""2"", ""malloc_ptrs[B][I]"", ""malloc_file[B][I]"", ""malloc_line[B][I]"", ""malloc_size[B][I]"", ""malloc_count[B][I]"", ""malloc_refs[B][I]""], []]",[30585478959801514631],6983,1163040.0,3
https://github.com/squid-cache/squid/commit/ae61f2a70b4839175e1896fb984276ec9b122686,17 Mar 2014,Remove XMALLOC_TRACE and references to sbrk(2),348,data/crawl/squid/hunk_1576.cpp,,,data/crawl/squid/old_hunk_1576.cpp,data/crawl/squid/new_hunk_1576.cpp,130,-1,"fprintf(stderr, ""=== %d bytes\n"", sum);",,"[""removeLog""]","[[""fprintf"", ""stderr"", ""%d"", ""bytes\\n"", ""sum""], []]",[14207206390608598951],6982,1163040.0,3
https://github.com/squid-cache/squid/commit/ae61f2a70b4839175e1896fb984276ec9b122686,17 Mar 2014,Remove XMALLOC_TRACE and references to sbrk(2),348,data/crawl/squid/hunk_1576.cpp,,,data/crawl/squid/old_hunk_1576.cpp,data/crawl/squid/new_hunk_1576.cpp,120,-1,"fprintf(stderr, ""%*s%p %s:%d size %d allocation %d\n"",
                                depth, """",
                                malloc_ptrs[B][I], malloc_file[B][I],
                                malloc_line[B][I], malloc_size[B][I],
                                malloc_count[B][I]);",,"[""removeLog""]","[[""fprintf"", ""stderr"", ""%*s%p"", ""%s"", ""%d"", ""size"", ""%d"", ""allocation"", ""%d\\n"", ""depth"", ""malloc_ptrs[B][I]"", ""malloc_file[B][I]"", ""malloc_line[B][I]"", ""malloc_size[B][I]"", ""malloc_count[B][I]""], []]",[28946520347337305743],6981,1163040.0,3
https://github.com/squid-cache/squid/commit/ae61f2a70b4839175e1896fb984276ec9b122686,17 Mar 2014,Remove XMALLOC_TRACE and references to sbrk(2),348,data/crawl/squid/hunk_1576.cpp,,,data/crawl/squid/old_hunk_1576.cpp,data/crawl/squid/new_hunk_1576.cpp,92,-1,"fprintf(stderr, "" %d\n"", xmalloc_count);",,"[""removeLog""]","[[""fprintf"", ""stderr"", ""%d\\n"", ""xmalloc_count""], []]",[9382290775761783620],6980,1163040.0,3
https://github.com/squid-cache/squid/commit/ae61f2a70b4839175e1896fb984276ec9b122686,17 Mar 2014,Remove XMALLOC_TRACE and references to sbrk(2),348,data/crawl/squid/hunk_1576.cpp,,,data/crawl/squid/old_hunk_1576.cpp,data/crawl/squid/new_hunk_1576.cpp,90,-1,"fprintf(stderr, "" (%d %s:%d)\n"", malloc_number(p), malloc_file_name(p), malloc_line_number(p));",,"[""removeLog""]","[[""fprintf"", ""stderr"", ""%d"", ""%s"", ""%d"", ""\\n"", ""malloc_number"", ""p"", ""malloc_file_name"", ""p"", ""malloc_line_number"", ""p""], []]",[14674548379399223140],6979,1163040.0,3
https://github.com/squid-cache/squid/commit/ae61f2a70b4839175e1896fb984276ec9b122686,17 Mar 2014,Remove XMALLOC_TRACE and references to sbrk(2),348,data/crawl/squid/hunk_1576.cpp,,,data/crawl/squid/old_hunk_1576.cpp,data/crawl/squid/new_hunk_1576.cpp,82,-1,"fprintf(stderr, ""%c%8p size=%5d/%d acc=%5d/%d mallinfo=%5d/%d %s:%d %s"",
                sign > 0 ? '+' : '-', p,
                (int) xmalloc_total - last_total, (int) xmalloc_total,
                (int) accounted - last_accounted, (int) accounted,
                (int) mi - last_mallinfo, (int) mi,
                xmalloc_file, xmalloc_line, xmalloc_func);",,"[""removeLog""]","[[""fprintf"", ""stderr"", ""%c%8p"", ""size"", ""%5d/%d"", ""acc"", ""%5d/%d"", ""mallinfo"", ""%5d/%d"", ""%s"", ""%d"", ""%s"", ""sign"", ""0"", ""p"", ""int"", ""xmalloc_total"", ""last_total"", ""int"", ""xmalloc_total"", ""int"", ""accounted"", ""last_accounted"", ""int"", ""accounted"", ""int"", ""mi"", ""last_mallinfo"", ""int"", ""mi"", ""xmalloc_file"", ""xmalloc_line"", ""xmalloc_func""], []]",[125373654210938505036],6978,1163040.0,3
https://github.com/squid-cache/squid/commit/ba1b862c8e2fb4ac6002432c2f16041119c02758,29 May 2014,merge from trunk r13423,5144,data/crawl/squid/hunk_1421.cpp,,,data/crawl/squid/old_hunk_1421.cpp,data/crawl/squid/new_hunk_1421.cpp,-1,526,,"buf.Printf("" %s%u]"", id.Prefix, id.value);","[""addLog""]","[[], [""buf"", ""Printf"", ""%s%u]"", ""id"", ""Prefix"", ""id"", ""value""]]",[-848067901940049833],6977,32640.0,3
https://github.com/squid-cache/squid/commit/ba1b862c8e2fb4ac6002432c2f16041119c02758,29 May 2014,merge from trunk r13423,5144,data/crawl/squid/hunk_1421.cpp,,,data/crawl/squid/old_hunk_1421.cpp,data/crawl/squid/new_hunk_1421.cpp,-1,525,,"buf.Printf("" FD %d"", serverConn->fd);","[""addLog""]","[[], [""buf"", ""Printf"", ""FD"", ""%d"", ""serverConn"", ""fd""]]",[14674879574681093913],6976,32640.0,3
https://github.com/squid-cache/squid/commit/ba1b862c8e2fb4ac6002432c2f16041119c02758,29 May 2014,merge from trunk r13423,5144,data/crawl/squid/hunk_1421.cpp,,,data/crawl/squid/old_hunk_1421.cpp,data/crawl/squid/new_hunk_1421.cpp,-1,522,,"buf.Printf(""%s"",stopReason);","[""addLog""]","[[], [""buf"", ""Printf"", ""%s"", ""stopReason""]]",[-1074088487245675513],6975,32640.0,3
https://github.com/squid-cache/squid/commit/ba1b862c8e2fb4ac6002432c2f16041119c02758,29 May 2014,merge from trunk r13423,5144,data/crawl/squid/hunk_1400.cpp,,,data/crawl/squid/old_hunk_1400.cpp,data/crawl/squid/new_hunk_1400.cpp,5,-1,"storeAppendPrintf(entry, ""%s %s keep_alive %s\n"", name, ""ntlm"", keep_alive ? ""on"" : ""off"");",,"[""removeLog""]","[[""storeAppendPrintf"", ""entry"", ""%s"", ""%s"", ""keep_alive"", ""%s\\n"", ""name"", ""ntlm"", ""keep_alive"", ""on"", ""off""], []]",[-2570647197035317809],6974,960.0,3
https://github.com/squid-cache/squid/commit/ba1b862c8e2fb4ac6002432c2f16041119c02758,29 May 2014,merge from trunk r13423,5144,data/crawl/squid/hunk_1399.cpp,,,data/crawl/squid/old_hunk_1399.cpp,data/crawl/squid/new_hunk_1399.cpp,5,-1,"storeAppendPrintf(entry, ""%s %s keep_alive %s\n"", name, ""negotiate"", keep_alive ? ""on"" : ""off"");",,"[""removeLog""]","[[""storeAppendPrintf"", ""entry"", ""%s"", ""%s"", ""keep_alive"", ""%s\\n"", ""name"", ""negotiate"", ""keep_alive"", ""on"", ""off""], []]",[-3405918770028475795],6973,960.0,3
https://github.com/squid-cache/squid/commit/ba1b862c8e2fb4ac6002432c2f16041119c02758,29 May 2014,merge from trunk r13423,5144,data/crawl/squid/hunk_1394.cpp,,,data/crawl/squid/old_hunk_1394.cpp,data/crawl/squid/new_hunk_1394.cpp,3,3,"mb->Printf(""\t%s %s\n"",
               RequestMethodStr(method), logUri());","mb->Printf(""\t"" SQUIDSBUFPH "" %s\n"", SQUIDSBUFPRINT(method.image()), logUri());","[""updateVariable"", ""removeVariable"", ""addContent"", ""updateContent"", ""addVariable""]","[[""\\t%s"", ""RequestMethodStr""], [""\\t"", ""SQUIDSBUFPH"", ""SQUIDSBUFPRINT"", ""image""]]",[10501284035843663233],6972,35520.0,3
https://github.com/squid-cache/squid/commit/00d0ce87e4fb95bde86ebb57dc394554b06b169e,21 Jun 2014,"Support for PROXY protocol version 1

This protocol enables other proxies to easily relay indirect client IP
and port details without altering the HTTP (or other) protocol within the
connection.",234,data/crawl/squid/hunk_1367.cpp,,,data/crawl/squid/old_hunk_1367.cpp,data/crawl/squid/new_hunk_1367.cpp,-1,56,,proxyProtocolError(tok.atEnd());,"[""addLog""]","[[], [""proxyProtocolError"", ""tok"", ""atEnd""]]",[-5544144393304699248],6971,0.0,3
https://github.com/squid-cache/squid/commit/cfb88efb1e75015ac6c38fd975eb5c565f1c36b1,24 Jun 2014,"Prep for merge from trunk: undo branch r13313, r13312, and r13311 that were
temporary undoing trunk r13266, r13269, and r13270 (std::vector migration).",1311,data/crawl/squid/hunk_1361.cpp,,,data/crawl/squid/old_hunk_1361.cpp,data/crawl/squid/new_hunk_1361.cpp,422,-1,"fatal (""domain error"");",,"[""removeLog""]","[[""fatal"", ""domain"", ""error""], []]",[-11742947046656841780],6970,64320.0,3
https://github.com/squid-cache/squid/commit/92ae4c86c14b2c6346ee32550d472eb57fd1caea,04 Aug 2014,"Major source layout change: Moved FTP code into servers/, clients/, and ftp/.

  src/servers/FtpServer.*   # new FTP server, relaying FTP
  src/servers/HttpServer.*  # old ConnStateData parts conflicting w/ FtpServer
  src/clients/FtpClient.*   # code shared by old and new FTP clients
  src/clients/FtpGateway.*  # old FTP client, translating back to HTTP
  src/clients/FtpNative.*   # new FTP client, relaying FTP
  src/ftp/*                 # FTP stuff shared by clients and servers

This change attempts to preserve code in moved files to the extent possible:
Only copied or added code was polished. Future changes will polish moved code.

Unfortunately, bzr does not track code changes across file splits, so the code
moved from ConnStateData (client_side.cc) into HttpServer and FtpServer
classes appears as removed and added in bzr diff. If you want to see the
branch log for the FtpServer or HttpServer code added in this revision, look
in the previous branch revision of client_side.cc.",4548,data/crawl/squid/hunk_1328.cpp,,,data/crawl/squid/old_hunk_1328.cpp,data/crawl/squid/new_hunk_1328.cpp,120,-1,"mb.Printf(""%i %s\r\n"", code, msg);",,"[""removeLog""]","[[""mb"", ""Printf"", ""%i"", ""%s\\r\\n"", ""code"", ""msg""], []]",[-27668380407176316555],6969,0.0,3
https://github.com/squid-cache/squid/commit/c6649f6c62f90053f0bf0f162918a94f1d763b3d,26 Aug 2014,merge from trunk,14018,data/crawl/squid/hunk_1212.cpp,,,data/crawl/squid/old_hunk_1212.cpp,data/crawl/squid/new_hunk_1212.cpp,-1,1199,,"mb.Printf(""%i %s\r\n"", header.getInt(HDR_FTP_STATUS),
                  (reason ? reason : 0));","[""addLog""]","[[], [""mb"", ""Printf"", ""%i"", ""%s\\r\\n"", ""header"", ""getInt"", ""HDR_FTP_STATUS"", ""reason"", ""reason"", ""0""]]",[13051058726262438831],6968,13920.0,3
https://github.com/squid-cache/squid/commit/c6649f6c62f90053f0bf0f162918a94f1d763b3d,26 Aug 2014,merge from trunk,14018,data/crawl/squid/hunk_1212.cpp,,,data/crawl/squid/old_hunk_1212.cpp,data/crawl/squid/new_hunk_1212.cpp,-1,1193,,"mb.Printf(""%s\r\n"", raw.termedBuf());","[""addLog""]","[[], [""mb"", ""Printf"", ""%s\\r\\n"", ""raw"", ""termedBuf""]]",[23498504526796650154],6967,13920.0,3
https://github.com/squid-cache/squid/commit/c6649f6c62f90053f0bf0f162918a94f1d763b3d,26 Aug 2014,merge from trunk,14018,data/crawl/squid/hunk_1212.cpp,,,data/crawl/squid/old_hunk_1212.cpp,data/crawl/squid/new_hunk_1212.cpp,-1,1103,,"mb.Printf(""%i %s\r\n"", scode, reason);","[""addLog""]","[[], [""mb"", ""Printf"", ""%i"", ""%s\\r\\n"", ""scode"", ""reason""]]",[9588580236911371895],6966,13920.0,3
https://github.com/squid-cache/squid/commit/c6649f6c62f90053f0bf0f162918a94f1d763b3d,26 Aug 2014,merge from trunk,14018,data/crawl/squid/hunk_1212.cpp,,,data/crawl/squid/old_hunk_1212.cpp,data/crawl/squid/new_hunk_1212.cpp,-1,1094,,"mb.Printf(""%i-Description: %s\r\n"", scode, desc.termedBuf());","[""addLog""]","[[], [""mb"", ""Printf"", ""%i"", ""Description"", ""%s\\r\\n"", ""scode"", ""desc"", ""termedBuf""]]",[10157503322206665686],6965,13920.0,3
https://github.com/squid-cache/squid/commit/c6649f6c62f90053f0bf0f162918a94f1d763b3d,26 Aug 2014,merge from trunk,14018,data/crawl/squid/hunk_1212.cpp,,,data/crawl/squid/old_hunk_1212.cpp,data/crawl/squid/new_hunk_1212.cpp,-1,1092,,"mb.Printf(""%i-Information: %s\r\n"", scode, info.termedBuf());","[""addLog""]","[[], [""mb"", ""Printf"", ""%i"", ""Information"", ""%s\\r\\n"", ""scode"", ""info"", ""termedBuf""]]",[16370919095229531315],6964,13920.0,3
https://github.com/squid-cache/squid/commit/c6649f6c62f90053f0bf0f162918a94f1d763b3d,26 Aug 2014,merge from trunk,14018,data/crawl/squid/hunk_1212.cpp,,,data/crawl/squid/old_hunk_1212.cpp,data/crawl/squid/new_hunk_1212.cpp,-1,1080,,"mb.Printf(""%i-Error: (%d) %s\r\n"", scode,
                  request->errDetail,
                  strerror(request->errDetail));","[""addLog""]","[[], [""mb"", ""Printf"", ""%i"", ""Error"", ""%d"", ""%s\\r\\n"", ""scode"", ""request"", ""errDetail"", ""strerror"", ""request"", ""errDetail""]]",[26435219459047061136],6963,13920.0,3
https://github.com/squid-cache/squid/commit/c6649f6c62f90053f0bf0f162918a94f1d763b3d,26 Aug 2014,merge from trunk,14018,data/crawl/squid/hunk_1212.cpp,,,data/crawl/squid/old_hunk_1212.cpp,data/crawl/squid/new_hunk_1212.cpp,-1,1076,,"mb.Printf(""%i-%s\r\n"", scode, errorPageName(request->errType));","[""addLog""]","[[], [""mb"", ""Printf"", ""%i"", ""%s\\r\\n"", ""scode"", ""errorPageName"", ""request"", ""errType""]]",[8675476368997430674],6962,13920.0,3
https://github.com/squid-cache/squid/commit/c6649f6c62f90053f0bf0f162918a94f1d763b3d,26 Aug 2014,merge from trunk,14018,data/crawl/squid/hunk_1212.cpp,,,data/crawl/squid/old_hunk_1212.cpp,data/crawl/squid/new_hunk_1212.cpp,-1,1059,,"mb.Printf(""229 Entering Extended Passive Mode (|||%u|)\r\n"", localPort);","[""addLog""]","[[], [""mb"", ""Printf"", ""229"", ""Entering"", ""Extended"", ""Passive"", ""Mode"", ""%u"", ""\\r\\n"", ""localPort""]]",[-19738588075219403345],6961,13920.0,3
https://github.com/squid-cache/squid/commit/c6649f6c62f90053f0bf0f162918a94f1d763b3d,26 Aug 2014,merge from trunk,14018,data/crawl/squid/hunk_1212.cpp,,,data/crawl/squid/old_hunk_1212.cpp,data/crawl/squid/new_hunk_1212.cpp,-1,1047,,"writeCustomReply(502, ""Cannot connect to server"", reply);","[""addLog""]","[[], [""writeCustomReply"", ""502"", ""Cannot"", ""connect"", ""to"", ""server"", ""reply""]]",[-10234473869156531835],6960,13920.0,3
https://github.com/squid-cache/squid/commit/c6649f6c62f90053f0bf0f162918a94f1d763b3d,26 Aug 2014,merge from trunk,14018,data/crawl/squid/hunk_1212.cpp,,,data/crawl/squid/old_hunk_1212.cpp,data/crawl/squid/new_hunk_1212.cpp,-1,1038,,"writeCustomReply(200, ""EPRT successfully converted to PASV."");","[""addLog""]","[[], [""writeCustomReply"", ""200"", ""EPRT"", ""successfully"", ""converted"", ""to"", ""PASV""]]",[-4103722366908748665],6959,13920.0,3
https://github.com/squid-cache/squid/commit/c6649f6c62f90053f0bf0f162918a94f1d763b3d,26 Aug 2014,merge from trunk,14018,data/crawl/squid/hunk_1212.cpp,,,data/crawl/squid/old_hunk_1212.cpp,data/crawl/squid/new_hunk_1212.cpp,-1,1034,,"writeCustomReply(502, ""Server does not support PASV (converted from EPRT)"", reply);","[""addLog""]","[[], [""writeCustomReply"", ""502"", ""Server"", ""does"", ""not"", ""support"", ""PASV"", ""converted"", ""from"", ""EPRT"", ""reply""]]",[-14841888926432143417],6958,13920.0,3
https://github.com/squid-cache/squid/commit/c6649f6c62f90053f0bf0f162918a94f1d763b3d,26 Aug 2014,merge from trunk,14018,data/crawl/squid/hunk_1212.cpp,,,data/crawl/squid/old_hunk_1212.cpp,data/crawl/squid/new_hunk_1212.cpp,-1,990,,"writeCustomReply(226, ""Transfer complete"");","[""addLog""]","[[], [""writeCustomReply"", ""226"", ""Transfer"", ""complete""]]",[339440345684861903],6957,13920.0,3
https://github.com/squid-cache/squid/commit/c6649f6c62f90053f0bf0f162918a94f1d763b3d,26 Aug 2014,merge from trunk,14018,data/crawl/squid/hunk_1212.cpp,,,data/crawl/squid/old_hunk_1212.cpp,data/crawl/squid/new_hunk_1212.cpp,-1,970,,"writeCustomReply(426, ""Data connection error; transfer aborted"");","[""addLog""]","[[], [""writeCustomReply"", ""426"", ""Data"", ""connection"", ""error"", ""transfer"", ""aborted""]]",[-12338575398840472949],6956,13920.0,3
https://github.com/squid-cache/squid/commit/c6649f6c62f90053f0bf0f162918a94f1d763b3d,26 Aug 2014,merge from trunk,14018,data/crawl/squid/hunk_1212.cpp,,,data/crawl/squid/old_hunk_1212.cpp,data/crawl/squid/new_hunk_1212.cpp,-1,937,,"writeCustomReply(425, ""Data connection is not established."");","[""addLog""]","[[], [""writeCustomReply"", ""425"", ""Data"", ""connection"", ""is"", ""not"", ""established""]]",[-8935027388215679979],6955,13920.0,3
https://github.com/squid-cache/squid/commit/c6649f6c62f90053f0bf0f162918a94f1d763b3d,26 Aug 2014,merge from trunk,14018,data/crawl/squid/hunk_1212.cpp,,,data/crawl/squid/old_hunk_1212.cpp,data/crawl/squid/new_hunk_1212.cpp,-1,904,,"writeCustomReply(200, ""PORT successfully converted to PASV."");","[""addLog""]","[[], [""writeCustomReply"", ""200"", ""PORT"", ""successfully"", ""converted"", ""to"", ""PASV""]]",[4703057921438157095],6954,13920.0,3
https://github.com/squid-cache/squid/commit/c6649f6c62f90053f0bf0f162918a94f1d763b3d,26 Aug 2014,merge from trunk,14018,data/crawl/squid/hunk_1212.cpp,,,data/crawl/squid/old_hunk_1212.cpp,data/crawl/squid/new_hunk_1212.cpp,-1,900,,"writeCustomReply(502, ""Server does not support PASV (converted from PORT)"", reply);","[""addLog""]","[[], [""writeCustomReply"", ""502"", ""Server"", ""does"", ""not"", ""support"", ""PASV"", ""converted"", ""from"", ""PORT"", ""reply""]]",[-6035108638085237657],6953,13920.0,3
https://github.com/squid-cache/squid/commit/c6649f6c62f90053f0bf0f162918a94f1d763b3d,26 Aug 2014,merge from trunk,14018,data/crawl/squid/hunk_1212.cpp,,,data/crawl/squid/old_hunk_1212.cpp,data/crawl/squid/new_hunk_1212.cpp,-1,888,,"mb.Printf(""227 Entering Passive Mode (%s,%i,%i).\r\n"",
              addr,
              static_cast<int>(localPort / 256),
              static_cast<int>(localPort % 256));","[""addLog""]","[[], [""mb"", ""Printf"", ""227"", ""Entering"", ""Passive"", ""Mode"", ""%s"", ""%i"", ""%i"", ""\\r\\n"", ""addr"", ""static_cast"", ""int"", ""localPort"", ""/"", ""256"", ""static_cast"", ""int"", ""localPort"", ""%"", ""256""]]",[-56978986730655189650],6952,13920.0,3
https://github.com/squid-cache/squid/commit/c6649f6c62f90053f0bf0f162918a94f1d763b3d,26 Aug 2014,merge from trunk,14018,data/crawl/squid/hunk_1212.cpp,,,data/crawl/squid/old_hunk_1212.cpp,data/crawl/squid/new_hunk_1212.cpp,-1,863,,"writeCustomReply(502, ""Server does not support PASV"", reply);","[""addLog""]","[[], [""writeCustomReply"", ""502"", ""Server"", ""does"", ""not"", ""support"", ""PASV"", ""reply""]]",[-16041733232403737805],6951,13920.0,3
https://github.com/squid-cache/squid/commit/c6649f6c62f90053f0bf0f162918a94f1d763b3d,26 Aug 2014,merge from trunk,14018,data/crawl/squid/hunk_1212.cpp,,,data/crawl/squid/old_hunk_1212.cpp,data/crawl/squid/new_hunk_1212.cpp,-1,790,,"writeCustomReply(502, ""Server does not support FEAT"", reply);","[""addLog""]","[[], [""writeCustomReply"", ""502"", ""Server"", ""does"", ""not"", ""support"", ""FEAT"", ""reply""]]",[-20693818389631369539],6950,13920.0,3
https://github.com/squid-cache/squid/commit/c6649f6c62f90053f0bf0f162918a94f1d763b3d,26 Aug 2014,merge from trunk,14018,data/crawl/squid/hunk_1212.cpp,,,data/crawl/squid/old_hunk_1212.cpp,data/crawl/squid/new_hunk_1212.cpp,-1,725,,"request->header.putStr(HDR_TRANSFER_ENCODING, ""chunked"");","[""addLog""]","[[], [""request"", ""header"", ""putStr"", ""HDR_TRANSFER_ENCODING"", ""chunked""]]",[-5293700204190662525],6949,13920.0,3
https://github.com/squid-cache/squid/commit/c6649f6c62f90053f0bf0f162918a94f1d763b3d,26 Aug 2014,merge from trunk,14018,data/crawl/squid/hunk_1212.cpp,,,data/crawl/squid/old_hunk_1212.cpp,data/crawl/squid/new_hunk_1212.cpp,-1,724,,"request->header.putStr(HDR_EXPECT, ""100-continue"");","[""addLog""]","[[], [""request"", ""header"", ""putStr"", ""HDR_EXPECT"", ""100"", ""continue""]]",[3071203418587731188],6948,13920.0,3
https://github.com/squid-cache/squid/commit/c6649f6c62f90053f0bf0f162918a94f1d763b3d,26 Aug 2014,merge from trunk,14018,data/crawl/squid/hunk_1212.cpp,,,data/crawl/squid/old_hunk_1212.cpp,data/crawl/squid/new_hunk_1212.cpp,-1,494,,"mb.Printf(""%i \r\n"", code);","[""addLog""]","[[], [""mb"", ""Printf"", ""%i"", ""\\r\\n"", ""code""]]",[7567834424575262437],6947,13920.0,3
https://github.com/squid-cache/squid/commit/c6649f6c62f90053f0bf0f162918a94f1d763b3d,26 Aug 2014,merge from trunk,14018,data/crawl/squid/hunk_1212.cpp,,,data/crawl/squid/old_hunk_1212.cpp,data/crawl/squid/new_hunk_1212.cpp,-1,492,,"mb.Printf("" Server reply:\r\n"");","[""addLog""]","[[], [""mb"", ""Printf"", ""Server"", ""reply"", ""\\r\\n""]]",[-5456764747709439034],6946,13920.0,3
https://github.com/squid-cache/squid/commit/c6649f6c62f90053f0bf0f162918a94f1d763b3d,26 Aug 2014,merge from trunk,14018,data/crawl/squid/hunk_1212.cpp,,,data/crawl/squid/old_hunk_1212.cpp,data/crawl/squid/new_hunk_1212.cpp,-1,356,,"writeCustomReply(451, ""Internal error"");","[""addLog""]","[[], [""writeCustomReply"", ""451"", ""Internal"", ""error""]]",[-2750567740350901701],6945,13920.0,3
https://github.com/squid-cache/squid/commit/c6649f6c62f90053f0bf0f162918a94f1d763b3d,26 Aug 2014,merge from trunk,14018,data/crawl/squid/hunk_1209.cpp,,,data/crawl/squid/old_hunk_1209.cpp,data/crawl/squid/new_hunk_1209.cpp,-1,41,,"header.putStr(HDR_FTP_REASON, ftpReason);","[""addLog""]","[[], [""header"", ""putStr"", ""HDR_FTP_REASON"", ""ftpReason""]]",[4874593275812037100],6944,11040.0,3
https://github.com/squid-cache/squid/commit/c6649f6c62f90053f0bf0f162918a94f1d763b3d,26 Aug 2014,merge from trunk,14018,data/crawl/squid/hunk_1207.cpp,,,data/crawl/squid/old_hunk_1207.cpp,data/crawl/squid/new_hunk_1207.cpp,-1,278,,"abortTransaction(""entry aborted after calling appendSuccessHeader()"");","[""addLog""]","[[], [""abortTransaction"", ""entry"", ""aborted"", ""after"", ""calling"", ""appendSuccessHeader""]]",[-31140353411621825280],6943,2567520.0,3
https://github.com/squid-cache/squid/commit/c6649f6c62f90053f0bf0f162918a94f1d763b3d,26 Aug 2014,merge from trunk,14018,data/crawl/squid/hunk_1199.cpp,,,data/crawl/squid/old_hunk_1199.cpp,data/crawl/squid/new_hunk_1199.cpp,-1,900,,"abortTransaction(""entry aborted during dataRead"");","[""addLog""]","[[], [""abortTransaction"", ""entry"", ""aborted"", ""during"", ""dataRead""]]",[-14041970511130099506],6942,2583840.0,3
https://github.com/squid-cache/squid/commit/c6649f6c62f90053f0bf0f162918a94f1d763b3d,26 Aug 2014,merge from trunk,14018,data/crawl/squid/hunk_1199.cpp,,,data/crawl/squid/old_hunk_1199.cpp,data/crawl/squid/new_hunk_1199.cpp,-1,833,,"(abortOnBadEntry(""entry went bad while waiting for a timeout"");","[""addLog""]","[[], [""abortOnBadEntry"", ""entry"", ""went"", ""bad"", ""while"", ""waiting"", ""for"", ""a"", ""timeout""]]",[-6015737064028494462],6941,1019040.0,3
https://github.com/squid-cache/squid/commit/c6649f6c62f90053f0bf0f162918a94f1d763b3d,26 Aug 2014,merge from trunk,14018,data/crawl/squid/hunk_1199.cpp,,,data/crawl/squid/old_hunk_1199.cpp,data/crawl/squid/new_hunk_1199.cpp,-1,682,,"mb.Printf(""EPSV ALL%s"", Ftp::crlf);","[""addLog""]","[[], [""mb"", ""Printf"", ""EPSV"", ""ALL%s"", ""Ftp"", ""crlf""]]",[6592608173729305072],6940,276000.0,3
https://github.com/squid-cache/squid/commit/c6649f6c62f90053f0bf0f162918a94f1d763b3d,26 Aug 2014,merge from trunk,14018,data/crawl/squid/hunk_1199.cpp,,,data/crawl/squid/old_hunk_1199.cpp,data/crawl/squid/new_hunk_1199.cpp,-1,585,,"mb.Printf(""EPRT |%d|%s|%d|%s"",
              ( data.conn->local.isIPv6() ? 2 : 1 ),
              data.conn->local.toStr(buf,MAX_IPSTRLEN),
              comm_local_port(data.conn->fd), Ftp::crlf );","[""addLog""]","[[], [""mb"", ""Printf"", ""EPRT"", ""%d"", ""%s"", ""%d"", ""%s"", ""data"", ""conn"", ""local"", ""isIPv6"", ""2"", ""1"", ""data"", ""conn"", ""local"", ""toStr"", ""buf"", ""MAX_IPSTRLEN"", ""comm_local_port"", ""data"", ""conn"", ""fd"", ""Ftp"", ""crlf""]]",[7409817402308099475],6939,276000.0,3
https://github.com/squid-cache/squid/commit/c6649f6c62f90053f0bf0f162918a94f1d763b3d,26 Aug 2014,merge from trunk,14018,data/crawl/squid/hunk_1199.cpp,,,data/crawl/squid/old_hunk_1199.cpp,data/crawl/squid/new_hunk_1199.cpp,-1,368,,"abortTransaction(""zero control reply read"");","[""addLog""]","[[], [""abortTransaction"", ""zero"", ""control"", ""reply"", ""read""]]",[-15868666021114446515],6938,2583840.0,3
https://github.com/squid-cache/squid/commit/c6649f6c62f90053f0bf0f162918a94f1d763b3d,26 Aug 2014,merge from trunk,14018,data/crawl/squid/hunk_1195.cpp,,,data/crawl/squid/old_hunk_1195.cpp,data/crawl/squid/new_hunk_1195.cpp,23,-1,"stopReceiving(""virgin request body consumer aborted"");",,"[""removeLog""]","[[""stopReceiving"", ""virgin"", ""request"", ""body"", ""consumer"", ""aborted""], []]",[7986465492880148666],6937,13920.0,3
https://github.com/squid-cache/squid/commit/c6649f6c62f90053f0bf0f162918a94f1d763b3d,26 Aug 2014,merge from trunk,14018,data/crawl/squid/hunk_1188.cpp,,,data/crawl/squid/old_hunk_1188.cpp,data/crawl/squid/new_hunk_1188.cpp,9,-1,"rep->header.putStr(HDR_CONNECTION, ""keep-alive"");",,"[""removeLog""]","[[""rep"", ""header"", ""putStr"", ""HDR_CONNECTION"", ""keep"", ""alive""], []]",[6436086023878567355],6936,13920.0,3
https://github.com/squid-cache/squid/commit/c6649f6c62f90053f0bf0f162918a94f1d763b3d,26 Aug 2014,merge from trunk,14018,data/crawl/squid/hunk_1187.cpp,,,data/crawl/squid/old_hunk_1187.cpp,data/crawl/squid/new_hunk_1187.cpp,-1,20,,"fatalf(""%s directive does not support protocol="" SQUIDSBUFPH ""\n"", cfg_directive, SQUIDSBUFPRINT(value));","[""addLog""]","[[], [""fatalf"", ""%s"", ""directive"", ""does"", ""not"", ""support"", ""protocol"", ""SQUIDSBUFPH"", ""\\n"", ""cfg_directive"", ""SQUIDSBUFPRINT"", ""value""]]",[-556277199634202520],6935,8160.0,3
https://github.com/squid-cache/squid/commit/6e96d41538a60ced489d2d3e226117768d0ceaba,02 Sep 2014,"Support receiving PROXY protocol version 1 and 2.

PROXY protocol has been developed by Willy Tarreau of HAProxy for
communicating original src and dst IP:port details between proxies and
load balancers in a protocol-agnostic way.

stunnel, HAProxy and some other HTTP proxying software are already
enabled and by adding support to Squid we can effectively chain these
proxies without having to rely on X-Forwarded-For headers.

This patch adds http_port mode flag (require-proxy-header) to signal the
protocol is in use, parsing and processing logics for the PROXY protocol
headers on new connections, and the proxy_protocol_access control to
manage inbound connections.
 The indirect client security/trust model remains unchanged. As do all
HTTP related logics on the connection once PROXY protocol header has
been received.


Furture Work:
 * support sending PROXY protocol to cache_peers
 * support receiving PROXY protocol on https_port
 * rework the PROXY parse logics as a Parser-NG child parser.",1337,data/crawl/squid/hunk_1181.cpp,,,data/crawl/squid/old_hunk_1181.cpp,data/crawl/squid/new_hunk_1181.cpp,-1,105,,"proxyProtocolError(in.buf.length() > 107? ""PROXY/1.0 error: missing CRLF"" : NULL);","[""addLog""]","[[], [""proxyProtocolError"", ""in"", ""buf"", ""length"", ""107"", ""PROXY/1"", ""0"", ""error"", ""missing"", ""CRLF"", ""NULL""]]",[27540090278766768736],6934,10560.0,3
https://github.com/squid-cache/squid/commit/f0174f5b12ac8b7f51baefffac9bea21e2a6196a,01 Dec 2014,"FTP FEAT error handling

Some FTP severs respond to a FEAT command with 5xx status code. Squid sends 
an invalid response in these cases which can confuse the client.

This patch fixes Squid to always send a valid 211 reply to client which
lists at least the EPSV and EPRT ftp commands which supported by Squid
regardless of the origin server support.

This patch also fixes a memory leak when FEAT replies processed.

This is a Measurement Factory project",84,data/crawl/squid/hunk_1149.cpp,,,data/crawl/squid/old_hunk_1149.cpp,data/crawl/squid/new_hunk_1149.cpp,53,-1,"filteredHeader.putStr(HDR_FTP_PRE, buf);",,"[""removeLog""]","[[""filteredHeader"", ""putStr"", ""HDR_FTP_PRE"", ""buf""], []]",[-4621350245977610158],6933,57120.0,3
https://github.com/squid-cache/squid/commit/5de5c2d0686b91fabccbdab4a612a7db2e325037,05 Dec 2014,"HTTP/2: handle 'PRI' method found in HTTP/1.x traffic

draft-ietf-httpbis-http2-16 section 11.6 registers the method PRI.
""
  This method is never used by an actual client.
  This method will appear to be used when an HTTP/1.1 server or
  intermediary attempts to parse an HTTP/2 connection preface.
""

If seen with a non-2.0 version number it means some client or proxy has
mishandled an HTTP/2.0 connection preface and corrupted the traffic.",11,data/crawl/squid/hunk_1145.cpp,,,data/crawl/squid/old_hunk_1145.cpp,data/crawl/squid/new_hunk_1145.cpp,-1,11,,"csd->abortRequestParsing(""error:method-not-allowed"");","[""addLog""]","[[], [""csd"", ""abortRequestParsing"", ""error"", ""method"", ""not"", ""allowed""]]",[7202450654319138192],6932,55200.0,3
https://github.com/squid-cache/squid/commit/685277d8fcb4ba6b1f1a66a634937764c31744d4,19 Dec 2014,"negotiate_kerberos_auth: MEMORY keytab and replay cache support

1) Checks for MEMORY: keytab support and reads the keytab from disk into
   MEMORY to improve performance (i.e. read keytab only at startup and
   nerver again)

2) Add option for replay cache type. Allows to set replay cache to none
   to improve performance ( may reduce security a bit )

3) Add option for replay cache directory.  If /var/tmp is not the best
   location you can choose a different location.",492,data/crawl/squid/hunk_1140.cpp,,,data/crawl/squid/old_hunk_1140.cpp,data/crawl/squid/new_hunk_1140.cpp,-1,55,,"fprintf(stderr, ""%s| %s: ERROR: krb5_read_keytab: %s\n"",
                    LogTime(), PROGRAM, strerror(retval));","[""addLog""]","[[], [""fprintf"", ""stderr"", ""%s"", ""%s"", ""ERROR"", ""krb5_read_keytab"", ""%s\\n"", ""LogTime"", ""PROGRAM"", ""strerror"", ""retval""]]",[19178999263170707185],6931,0.0,3
https://github.com/squid-cache/squid/commit/44ad873e32fc005ee66dbc96828dc5e4301f449a,30 Dec 2014,Simplified MSNT basic auth helper,1113,data/crawl/squid/hunk_1100.cpp,,,data/crawl/squid/old_hunk_1100.cpp,data/crawl/squid/new_hunk_1100.cpp,14,-1,"puts(""ERR"");",,"[""removeLog""]","[[""puts"", ""ERR""], []]",[-1091395453046515340],6930,1575360.0,3
https://github.com/squid-cache/squid/commit/6b634dc323fdfd75bac737a38faeb171fce705df,20 Jan 2015,Bug 4066: Digest auth nonce indefinite rollover,19,data/crawl/squid/hunk_1049.cpp,,,data/crawl/squid/old_hunk_1049.cpp,data/crawl/squid/new_hunk_1049.cpp,6,-1,"digest_request->setDenyMessage(""Stale nonce"");",,"[""removeLog""]","[[""digest_request"", ""setDenyMessage"", ""Stale"", ""nonce""], []]",[-23687127897404164687],6929,1625280.0,3
https://github.com/squid-cache/squid/commit/e8fd04de7b757db01f11b2ba8aa7d091e287b7b0,31 Jan 2015,"Stop emitting (Proxy-)Authentication-Info for Negotiate

This header is not defined for use by RFC 4559, and there seem to
be no clients actually using it.

The syntax Squid was using to emit the details was also clashing
with the syntax defined for use in Digest which is becoming the
standardized ABNF syntax for the header in general.",22,data/crawl/squid/hunk_1043.cpp,,,data/crawl/squid/old_hunk_1043.cpp,data/crawl/squid/new_hunk_1043.cpp,18,-1,"httpHeaderPutStrf(&rep->header, type, ""Negotiate %s"", server_blob);",,"[""removeLog""]","[[""httpHeaderPutStrf"", ""&rep"", ""header"", ""type"", ""Negotiate"", ""%s"", ""server_blob""], []]",[12596721475175719257],6928,981120.0,3
https://github.com/squid-cache/squid/commit/1071ffed56172406d771265af76d8273ffcdb89e,26 May 2015,"Replace Packer object API with Packable API

Majority of thost patch is symbol renaming to unify the
class method names to the Packable API names.

There is effectively no logical change in this patch
despite appearances because it replaces the Packer object
which provides methods which are just wrappers pointing
to static functions which are in turn wrappers pointing
to storage buffer object methods. With direct calls to
those storage object methods (renamed).

We can now interchangebly use MemBuf or StoreEntry objects
with the packInto(Packable *) functions. Or any other
object which inherits and implements the Packable API.

We also gain 0.1% in performance (+2 RPS) by avoiding the
layers of wrapper funcions and Packer object allocate / 
deallocate cycles.",1141,data/crawl/squid/hunk_781.cpp,,,data/crawl/squid/old_hunk_781.cpp,data/crawl/squid/new_hunk_781.cpp,11,6,"output->Printf(""\t\tflags:"");","output->append(""\t\tflags:"", 8);","[""updateLog"", ""addContent""]","[[""Printf""], [""append"", ""8""]]",[-16152299998131696704],6927,64800.0,3
https://github.com/squid-cache/squid/commit/1071ffed56172406d771265af76d8273ffcdb89e,26 May 2015,"Replace Packer object API with Packable API

Majority of thost patch is symbol renaming to unify the
class method names to the Packable API names.

There is effectively no logical change in this patch
despite appearances because it replaces the Packer object
which provides methods which are just wrappers pointing
to static functions which are in turn wrappers pointing
to storage buffer object methods. With direct calls to
those storage object methods (renamed).

We can now interchangebly use MemBuf or StoreEntry objects
with the packInto(Packable *) functions. Or any other
object which inherits and implements the Packable API.

We also gain 0.1% in performance (+2 RPS) by avoiding the
layers of wrapper funcions and Packer object allocate / 
deallocate cycles.",1141,data/crawl/squid/hunk_766.cpp,,,data/crawl/squid/old_hunk_766.cpp,data/crawl/squid/new_hunk_766.cpp,13,12,"mb.Printf(""%s"", name);","mb.append(name, strlen(name));","[""addLog"", ""removeContent"", ""addVariable"", ""removeLog""]","[[""Printf"", ""%s""], [""append"", ""strlen"", ""name""]]",[-29491536403146589910],6926,64800.0,3
https://github.com/squid-cache/squid/commit/1071ffed56172406d771265af76d8273ffcdb89e,26 May 2015,"Replace Packer object API with Packable API

Majority of thost patch is symbol renaming to unify the
class method names to the Packable API names.

There is effectively no logical change in this patch
despite appearances because it replaces the Packer object
which provides methods which are just wrappers pointing
to static functions which are in turn wrappers pointing
to storage buffer object methods. With direct calls to
those storage object methods (renamed).

We can now interchangebly use MemBuf or StoreEntry objects
with the packInto(Packable *) functions. Or any other
object which inherits and implements the Packable API.

We also gain 0.1% in performance (+2 RPS) by avoiding the
layers of wrapper funcions and Packer object allocate / 
deallocate cycles.",1141,data/crawl/squid/hunk_766.cpp,,,data/crawl/squid/old_hunk_766.cpp,data/crawl/squid/new_hunk_766.cpp,11,10,"mb.Printf(""%s"", dir);",strlen(dir);,"[""addLog"", ""removeContent"", ""removeLog""]","[[""mb"", ""Printf"", ""%s""], [""strlen""]]",[-16424019549386861376],6925,64800.0,3
https://github.com/squid-cache/squid/commit/1071ffed56172406d771265af76d8273ffcdb89e,26 May 2015,"Replace Packer object API with Packable API

Majority of thost patch is symbol renaming to unify the
class method names to the Packable API names.

There is effectively no logical change in this patch
despite appearances because it replaces the Packer object
which provides methods which are just wrappers pointing
to static functions which are in turn wrappers pointing
to storage buffer object methods. With direct calls to
those storage object methods (renamed).

We can now interchangebly use MemBuf or StoreEntry objects
with the packInto(Packable *) functions. Or any other
object which inherits and implements the Packable API.

We also gain 0.1% in performance (+2 RPS) by avoiding the
layers of wrapper funcions and Packer object allocate / 
deallocate cycles.",1141,data/crawl/squid/hunk_753.cpp,,,data/crawl/squid/old_hunk_753.cpp,data/crawl/squid/new_hunk_753.cpp,3,3,"mb.Printf(""%s"", sign_mb->content());","mb.append(sign_mb->content(), sign_mb->contentSize());","[""updateLog"", ""removeContent"", ""addVariable""]","[[""Printf"", ""%s""], [""append"", ""sign_mb"", ""contentSize""]]",[-18784583862098719768],6924,64800.0,3
https://github.com/squid-cache/squid/commit/1071ffed56172406d771265af76d8273ffcdb89e,26 May 2015,"Replace Packer object API with Packable API

Majority of thost patch is symbol renaming to unify the
class method names to the Packable API names.

There is effectively no logical change in this patch
despite appearances because it replaces the Packer object
which provides methods which are just wrappers pointing
to static functions which are in turn wrappers pointing
to storage buffer object methods. With direct calls to
those storage object methods (renamed).

We can now interchangebly use MemBuf or StoreEntry objects
with the packInto(Packable *) functions. Or any other
object which inherits and implements the Packable API.

We also gain 0.1% in performance (+2 RPS) by avoiding the
layers of wrapper funcions and Packer object allocate / 
deallocate cycles.",1141,data/crawl/squid/hunk_751.cpp,,,data/crawl/squid/old_hunk_751.cpp,data/crawl/squid/new_hunk_751.cpp,3,3,"mb.Printf(""%d"", (int) request->port);","mb.appendf(""%u"", request->port);","[""updateLog"", ""removeVariable"", ""updateContent""]","[[""Printf"", ""%d"", ""int""], [""appendf"", ""%u""]]",[7152046587264163609],6923,64800.0,3
https://github.com/squid-cache/squid/commit/1071ffed56172406d771265af76d8273ffcdb89e,26 May 2015,"Replace Packer object API with Packable API

Majority of thost patch is symbol renaming to unify the
class method names to the Packable API names.

There is effectively no logical change in this patch
despite appearances because it replaces the Packer object
which provides methods which are just wrappers pointing
to static functions which are in turn wrappers pointing
to storage buffer object methods. With direct calls to
those storage object methods (renamed).

We can now interchangebly use MemBuf or StoreEntry objects
with the packInto(Packable *) functions. Or any other
object which inherits and implements the Packable API.

We also gain 0.1% in performance (+2 RPS) by avoiding the
layers of wrapper funcions and Packer object allocate / 
deallocate cycles.",1141,data/crawl/squid/hunk_747.cpp,,,data/crawl/squid/old_hunk_747.cpp,data/crawl/squid/new_hunk_747.cpp,14,14,"mb.Printf(""[No Error]"");","mb.append(""[No Error]"", 10);","[""updateLog"", ""addContent""]","[[""Printf""], [""append"", ""10""]]",[-16146027967618661656],6922,64800.0,3
https://github.com/squid-cache/squid/commit/1071ffed56172406d771265af76d8273ffcdb89e,26 May 2015,"Replace Packer object API with Packable API

Majority of thost patch is symbol renaming to unify the
class method names to the Packable API names.

There is effectively no logical change in this patch
despite appearances because it replaces the Packer object
which provides methods which are just wrappers pointing
to static functions which are in turn wrappers pointing
to storage buffer object methods. With direct calls to
those storage object methods (renamed).

We can now interchangebly use MemBuf or StoreEntry objects
with the packInto(Packable *) functions. Or any other
object which inherits and implements the Packable API.

We also gain 0.1% in performance (+2 RPS) by avoiding the
layers of wrapper funcions and Packer object allocate / 
deallocate cycles.",1141,data/crawl/squid/hunk_747.cpp,,,data/crawl/squid/old_hunk_747.cpp,data/crawl/squid/new_hunk_747.cpp,3,3,"mb.Printf(""[No Error Detail]"");","mb.append(""[No Error Detail]"", 17);","[""updateLog"", ""addContent""]","[[""Printf""], [""append"", ""17""]]",[-16146027967618661651],6921,64800.0,3
https://github.com/squid-cache/squid/commit/1071ffed56172406d771265af76d8273ffcdb89e,26 May 2015,"Replace Packer object API with Packable API

Majority of thost patch is symbol renaming to unify the
class method names to the Packable API names.

There is effectively no logical change in this patch
despite appearances because it replaces the Packer object
which provides methods which are just wrappers pointing
to static functions which are in turn wrappers pointing
to storage buffer object methods. With direct calls to
those storage object methods (renamed).

We can now interchangebly use MemBuf or StoreEntry objects
with the packInto(Packable *) functions. Or any other
object which inherits and implements the Packable API.

We also gain 0.1% in performance (+2 RPS) by avoiding the
layers of wrapper funcions and Packer object allocate / 
deallocate cycles.",1141,data/crawl/squid/hunk_745.cpp,,,data/crawl/squid/old_hunk_745.cpp,data/crawl/squid/new_hunk_745.cpp,62,59,"str.Printf(""FTP Msg: "");","str.append(""FTP Msg: "", 9);","[""updateLog"", ""addContent""]","[[""Printf""], [""append"", ""9""]]",[-16152299998003696321],6920,64800.0,3
https://github.com/squid-cache/squid/commit/1071ffed56172406d771265af76d8273ffcdb89e,26 May 2015,"Replace Packer object API with Packable API

Majority of thost patch is symbol renaming to unify the
class method names to the Packable API names.

There is effectively no logical change in this patch
despite appearances because it replaces the Packer object
which provides methods which are just wrappers pointing
to static functions which are in turn wrappers pointing
to storage buffer object methods. With direct calls to
those storage object methods (renamed).

We can now interchangebly use MemBuf or StoreEntry objects
with the packInto(Packable *) functions. Or any other
object which inherits and implements the Packable API.

We also gain 0.1% in performance (+2 RPS) by avoiding the
layers of wrapper funcions and Packer object allocate / 
deallocate cycles.",1141,data/crawl/squid/hunk_745.cpp,,,data/crawl/squid/old_hunk_745.cpp,data/crawl/squid/new_hunk_745.cpp,35,35,"str.Printf(""HTTP Request:\r\n"");","str.append(""HTTP Request:\r\n"", 15);","[""updateLog"", ""addContent""]","[[""Printf""], [""append"", ""15""]]",[-16146027967618661653],6919,64800.0,3
https://github.com/squid-cache/squid/commit/1071ffed56172406d771265af76d8273ffcdb89e,26 May 2015,"Replace Packer object API with Packable API

Majority of thost patch is symbol renaming to unify the
class method names to the Packable API names.

There is effectively no logical change in this patch
despite appearances because it replaces the Packer object
which provides methods which are just wrappers pointing
to static functions which are in turn wrappers pointing
to storage buffer object methods. With direct calls to
those storage object methods (renamed).

We can now interchangebly use MemBuf or StoreEntry objects
with the packInto(Packable *) functions. Or any other
object which inherits and implements the Packable API.

We also gain 0.1% in performance (+2 RPS) by avoiding the
layers of wrapper funcions and Packer object allocate / 
deallocate cycles.",1141,data/crawl/squid/hunk_745.cpp,,,data/crawl/squid/old_hunk_745.cpp,data/crawl/squid/new_hunk_745.cpp,14,14,"str.Printf(""Err: [none]\r\n"");","str.append(""Err: [none]\r\n"", 13);","[""updateLog"", ""addContent""]","[[""Printf""], [""append"", ""13""]]",[-16146027967618661655],6918,64800.0,3
https://github.com/squid-cache/squid/commit/1071ffed56172406d771265af76d8273ffcdb89e,26 May 2015,"Replace Packer object API with Packable API

Majority of thost patch is symbol renaming to unify the
class method names to the Packable API names.

There is effectively no logical change in this patch
despite appearances because it replaces the Packer object
which provides methods which are just wrappers pointing
to static functions which are in turn wrappers pointing
to storage buffer object methods. With direct calls to
those storage object methods (renamed).

We can now interchangebly use MemBuf or StoreEntry objects
with the packInto(Packable *) functions. Or any other
object which inherits and implements the Packable API.

We also gain 0.1% in performance (+2 RPS) by avoiding the
layers of wrapper funcions and Packer object allocate / 
deallocate cycles.",1141,data/crawl/squid/hunk_731.cpp,,,data/crawl/squid/old_hunk_731.cpp,data/crawl/squid/new_hunk_731.cpp,4,3,"buf.Printf(""%s"",stopReason);","buf.appendf(""Stopped, reason:%s"", stopReason);","[""updateLog"", ""updateContent""]","[[""Printf""], [""appendf"", ""Stopped"", ""reason""]]",[-5120900317027605544],6917,64800.0,3
https://github.com/squid-cache/squid/commit/1071ffed56172406d771265af76d8273ffcdb89e,26 May 2015,"Replace Packer object API with Packable API

Majority of thost patch is symbol renaming to unify the
class method names to the Packable API names.

There is effectively no logical change in this patch
despite appearances because it replaces the Packer object
which provides methods which are just wrappers pointing
to static functions which are in turn wrappers pointing
to storage buffer object methods. With direct calls to
those storage object methods (renamed).

We can now interchangebly use MemBuf or StoreEntry objects
with the packInto(Packable *) functions. Or any other
object which inherits and implements the Packable API.

We also gain 0.1% in performance (+2 RPS) by avoiding the
layers of wrapper funcions and Packer object allocate / 
deallocate cycles.",1141,data/crawl/squid/hunk_731.cpp,,,data/crawl/squid/old_hunk_731.cpp,data/crawl/squid/new_hunk_731.cpp,3,-1,"buf.Printf(""Stopped, reason:"");",,"[""removeLog""]","[[""buf"", ""Printf"", ""Stopped"", ""reason""], []]",[-2846851238253798841],6916,64800.0,3
https://github.com/squid-cache/squid/commit/1071ffed56172406d771265af76d8273ffcdb89e,26 May 2015,"Replace Packer object API with Packable API

Majority of thost patch is symbol renaming to unify the
class method names to the Packable API names.

There is effectively no logical change in this patch
despite appearances because it replaces the Packer object
which provides methods which are just wrappers pointing
to static functions which are in turn wrappers pointing
to storage buffer object methods. With direct calls to
those storage object methods (renamed).

We can now interchangebly use MemBuf or StoreEntry objects
with the packInto(Packable *) functions. Or any other
object which inherits and implements the Packable API.

We also gain 0.1% in performance (+2 RPS) by avoiding the
layers of wrapper funcions and Packer object allocate / 
deallocate cycles.",1141,data/crawl/squid/hunk_730.cpp,,,data/crawl/squid/old_hunk_730.cpp,data/crawl/squid/new_hunk_730.cpp,6,6,"buf.Printf(""Stopped"");","buf.append(""Stopped"", 7);","[""updateLog"", ""addContent""]","[[""Printf""], [""append"", ""7""]]",[-16152299998259697091],6915,64800.0,3
https://github.com/squid-cache/squid/commit/1071ffed56172406d771265af76d8273ffcdb89e,26 May 2015,"Replace Packer object API with Packable API

Majority of thost patch is symbol renaming to unify the
class method names to the Packable API names.

There is effectively no logical change in this patch
despite appearances because it replaces the Packer object
which provides methods which are just wrappers pointing
to static functions which are in turn wrappers pointing
to storage buffer object methods. With direct calls to
those storage object methods (renamed).

We can now interchangebly use MemBuf or StoreEntry objects
with the packInto(Packable *) functions. Or any other
object which inherits and implements the Packable API.

We also gain 0.1% in performance (+2 RPS) by avoiding the
layers of wrapper funcions and Packer object allocate / 
deallocate cycles.",1141,data/crawl/squid/hunk_726.cpp,,,data/crawl/squid/old_hunk_726.cpp,data/crawl/squid/new_hunk_726.cpp,11,11,"buf.Printf(""Allow: 206\r\n"");","buf.append(""Allow: 206\r\n"", 12);","[""updateLog"", ""addContent""]","[[""Printf""], [""append"", ""12""]]",[-16146027967618661654],6914,64800.0,3
https://github.com/squid-cache/squid/commit/bf3e8d5a0de0f6f59996d1a8fb88402ba2273ede,05 Jun 2015,"SourceLayout: convert helper stats display to Packable API

Requires unifying the classes Helper::Request queues which incidentally
also brings stateful helpers closer to concurrency support",192,data/crawl/squid/hunk_692.cpp,,,data/crawl/squid/old_hunk_692.cpp,data/crawl/squid/new_hunk_692.cpp,12,-1,"storeAppendPrintf(sentry, ""   C = CLOSING\n"");",,"[""removeLog""]","[[""storeAppendPrintf"", ""sentry"", ""C"", ""CLOSING\\n""], []]",[-14263333398775378258],6913,5838720.0,3
https://github.com/squid-cache/squid/commit/bf3e8d5a0de0f6f59996d1a8fb88402ba2273ede,05 Jun 2015,"SourceLayout: convert helper stats display to Packable API

Requires unifying the classes Helper::Request queues which incidentally
also brings stateful helpers closer to concurrency support",192,data/crawl/squid/hunk_692.cpp,,,data/crawl/squid/old_hunk_692.cpp,data/crawl/squid/new_hunk_692.cpp,10,-1,"storeAppendPrintf(sentry, ""   B = BUSY\n"");",,"[""removeLog""]","[[""storeAppendPrintf"", ""sentry"", ""B"", ""BUSY\\n""], []]",[-5774997970090305024],6912,5838720.0,3
https://github.com/squid-cache/squid/commit/4ac1880a33a31144592a93d95fff715d67a6bf05,09 Jul 2015,make dump_peer_options clearer (and address CID 740350),26,data/crawl/squid/hunk_667.cpp,,,data/crawl/squid/old_hunk_667.cpp,data/crawl/squid/new_hunk_667.cpp,7,9,"storeAppendPrintf(sentry, ""%sno-clr"",(doneopts++>0?"","":""=""));","storeAppendPrintf(sentry, ""%sno-clr"",(doneopts?"","":""=""));","[""removeVariable"", ""removeContent""]","[[""0""], []]",[-6144018481],6911,0.0,3
https://github.com/squid-cache/squid/commit/eaba9273ca0d18a75d12c1055b7ed12b8eb2e3df,10 Jul 2015,"Crypto-NG: Use Security::PeerOptions for listening port TLS settings

The bulk of this patch is symbol shuffling to de-duplicate the TLS
settings storage and parsing code.

* Shuffle relevant AnyP::PortCfg settings into a Security::PeerOptions
  member object.
 - removes a lot of duplicate config parsing code.

* Remove the now obsolete and unused Ssl::OpenSSLtoSquidSSLVersion()


The actual logic changes are relatively small:

* Shuffle flags= and options= parsing code from Ssl:: to
  Security::PeerOptions and update to use Tokenizer,
 - fixes performance regression using c_str() on the stored SBuf,
 - fixes performance issue with xstrdup() for option tokens,
 - removes several calls to c-string manipulation.

* Add cachemgr 'config' report dumper of Security::PeerOptions for use
  by all directives using it to dump tls-* parameter names. The old
  parameter names are still accepted, and deprecation will follow in a
  separate patch.
 - fixes bug where cache_peer was not dumping out its SSL/TLS config
  settings at all.

* Change the tls_outgoing_options default value from ""disable"" to setting
  TLS/1.0 minimum version.
  - fixes squid.conf parsing error on default value ""disable"".

* Fix tls-min-version=1.N handling not to alter stored options= config
  string. Now updates the binary representation in parsedOptions directly.

* Expose the TLS context creation and configuration to non-OpenSSL builds.
 - fixes bug where context creation by OpenSSL failed silently.",1036,data/crawl/squid/hunk_657.cpp,,,data/crawl/squid/old_hunk_657.cpp,data/crawl/squid/new_hunk_657.cpp,8,-1,"storeAppendPrintf(e, "" key=%s"", s->key);",,"[""removeLog""]","[[""storeAppendPrintf"", ""e"", ""key"", ""%s"", ""s"", ""key""], []]",[-22464641105818714367],6910,2546400.0,3
https://github.com/squid-cache/squid/commit/789217a2d102b1c99734afd7d48e4d4210ec009d,04 Aug 2015,"Renamed http_hdr_type to Http::HdrType, fixed some HdrType-int implicit conversions",1702,data/crawl/squid/hunk_622.cpp,,,data/crawl/squid/old_hunk_622.cpp,data/crawl/squid/new_hunk_622.cpp,3,3,"req->header.putStr(HDR_ACCEPT, StoreDigestMimeStr);","req->header.putStr(Http::HdrType::ACCEPT, StoreDigestMimeStr);","[""removeVariable"", ""addVariable""]","[[""HDR_ACCEPT""], [""Http"", ""HdrType"", ""ACCEPT""]]",[5411025994465438704],6909,0.0,3
https://github.com/squid-cache/squid/commit/789217a2d102b1c99734afd7d48e4d4210ec009d,04 Aug 2015,"Renamed http_hdr_type to Http::HdrType, fixed some HdrType-int implicit conversions",1702,data/crawl/squid/hunk_611.cpp,,,data/crawl/squid/old_hunk_611.cpp,data/crawl/squid/new_hunk_611.cpp,4,4,"rep->header.putStr(HDR_VARY, ""Accept-Language"");","rep->header.putStr(Http::HdrType::VARY, ""Accept-Language"");","[""removeVariable"", ""addVariable""]","[[""HDR_VARY""], [""Http"", ""HdrType"", ""VARY""]]",[8928636869784475108],6908,0.0,3
https://github.com/squid-cache/squid/commit/789217a2d102b1c99734afd7d48e4d4210ec009d,04 Aug 2015,"Renamed http_hdr_type to Http::HdrType, fixed some HdrType-int implicit conversions",1702,data/crawl/squid/hunk_604.cpp,,,data/crawl/squid/old_hunk_604.cpp,data/crawl/squid/new_hunk_604.cpp,3,3,"hdr->putStr(HDR_TRANSFER_ENCODING, ""chunked"");","hdr->putStr(Http::HdrType::TRANSFER_ENCODING, ""chunked"");","[""removeVariable"", ""addVariable""]","[[""HDR_TRANSFER_ENCODING""], [""Http"", ""HdrType"", ""TRANSFER_ENCODING""]]",[8442495673730136598],6907,0.0,3
https://github.com/squid-cache/squid/commit/789217a2d102b1c99734afd7d48e4d4210ec009d,04 Aug 2015,"Renamed http_hdr_type to Http::HdrType, fixed some HdrType-int implicit conversions",1702,data/crawl/squid/hunk_596.cpp,,,data/crawl/squid/old_hunk_596.cpp,data/crawl/squid/new_hunk_596.cpp,6,6,"hdr->putStr(HDR_LOCATION, loc);","hdr->putStr(Http::HdrType::LOCATION, loc);","[""removeVariable"", ""addVariable""]","[[""HDR_LOCATION""], [""Http"", ""HdrType"", ""LOCATION""]]",[-1917803309236843682],6906,0.0,3
https://github.com/squid-cache/squid/commit/af845cee67e3dc2a58f93a9ac7d9ce091ea4fa00,11 Sep 2015,"Bug 4292: negotiate_wrapper: Unreleased Resources

FILE* handles need to be closed on exit. Shuffle the processing loop logics
to a static function to avoid code duplication from all the requires close
points.

Also, use the available global flag debug_enabled instead of local variable
to avoid having to pass it down explicitly.",337,data/crawl/squid/hunk_574.cpp,,,data/crawl/squid/old_hunk_574.cpp,data/crawl/squid/new_hunk_574.cpp,-1,105,,"fprintf(stdout, ""BH Invalid negotiate request token\n"");","[""addLog""]","[[], [""fprintf"", ""stdout"", ""BH"", ""Invalid"", ""negotiate"", ""request"", ""token\\n""]]",[-23985582874567925232],6905,122400.0,3
https://github.com/squid-cache/squid/commit/af845cee67e3dc2a58f93a9ac7d9ce091ea4fa00,11 Sep 2015,"Bug 4292: negotiate_wrapper: Unreleased Resources

FILE* handles need to be closed on exit. Shuffle the processing loop logics
to a static function to avoid code duplication from all the requires close
points.

Also, use the available global flag debug_enabled instead of local variable
to avoid having to pass it down explicitly.",337,data/crawl/squid/hunk_574.cpp,,,data/crawl/squid/old_hunk_574.cpp,data/crawl/squid/new_hunk_574.cpp,-1,85,,"fprintf(stdout, ""BH Invalid negotiate request\n"");","[""addLog""]","[[], [""fprintf"", ""stdout"", ""BH"", ""Invalid"", ""negotiate"", ""request\\n""]]",[-18267803172806194414],6904,1277760.0,3
https://github.com/squid-cache/squid/commit/af845cee67e3dc2a58f93a9ac7d9ce091ea4fa00,11 Sep 2015,"Bug 4292: negotiate_wrapper: Unreleased Resources

FILE* handles need to be closed on exit. Shuffle the processing loop logics
to a static function to avoid code duplication from all the requires close
points.

Also, use the available global flag debug_enabled instead of local variable
to avoid having to pass it down explicitly.",337,data/crawl/squid/hunk_574.cpp,,,data/crawl/squid/old_hunk_574.cpp,data/crawl/squid/new_hunk_574.cpp,-1,52,,"fprintf(stdout, ""BH Oversized message\n"");","[""addLog""]","[[], [""fprintf"", ""stdout"", ""BH"", ""Oversized"", ""message\\n""]]",[-13401837287885866005],6903,1277760.0,3
https://github.com/squid-cache/squid/commit/af845cee67e3dc2a58f93a9ac7d9ce091ea4fa00,11 Sep 2015,"Bug 4292: negotiate_wrapper: Unreleased Resources

FILE* handles need to be closed on exit. Shuffle the processing loop logics
to a static function to avoid code duplication from all the requires close
points.

Also, use the available global flag debug_enabled instead of local variable
to avoid having to pass it down explicitly.",337,data/crawl/squid/hunk_574.cpp,,,data/crawl/squid/old_hunk_574.cpp,data/crawl/squid/new_hunk_574.cpp,-1,46,,"fprintf(stderr, ""%s| %s: Got '%s' from squid (length: %d).\n"",
                        LogTime(), PROGRAM, buf, length);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""%s"", ""%s"", ""Got"", ""%s"", ""from"", ""squid"", ""length"", ""%d"", ""\\n"", ""LogTime"", ""PROGRAM"", ""buf"", ""length""]]",[-3528819456225505226],6902,1277760.0,3
https://github.com/squid-cache/squid/commit/fbdf945d33765c02929795b8354c6cdd55d67ba4,02 Oct 2015,Cleanup various spelling errors,22,data/crawl/squid/hunk_564.cpp,,,data/crawl/squid/old_hunk_564.cpp,data/crawl/squid/new_hunk_564.cpp,3,3,"fatal_dump(""Attempt to overwrite already in-memory data. Preceeding this there should be a mem_hdr::write output that lists the attempted write, and the currently present data. Please get a 'backtrace full' from this error - using the generated core, and file a bug report with the squid developers including the last 10 lines of cache.log and the backtrace.\n"");","fatal_dump(""Attempt to overwrite already in-memory data. Preceding this there should be a mem_hdr::write output that lists the attempted write, and the currently present data. Please get a 'backtrace full' from this error - using the generated core, and file a bug report with the squid developers including the last 10 lines of cache.log and the backtrace.\n"");","[""updateContent""]","[[""Preceeding""], [""Preceding""]]",[-6138486007324851744],6901,448800.0,3
https://github.com/squid-cache/squid/commit/a87b56f3c1acc2ffdd35d60a82abf64ccfc30e7b,11 Oct 2015,"TLS: shuffle EECDH configuration to libsecurity

* add class ServerOptions to libsecurity to manage server specific
  configuration options. Based on class PeerOptions.

* shuffle the DH config parse and dump logics to ServerOptions

* shuffle the DH params pre-loading logic to ServerOptions

* add configuration warning when tls-dh= is used and overrides
  dhparams= logacy configuration. Also, auto-upgrade the config
  settings when dhparams= is dumped in mgr:config report.",357,data/crawl/squid/hunk_558.cpp,,,data/crawl/squid/old_hunk_558.cpp,data/crawl/squid/new_hunk_558.cpp,4,-1,"storeAppendPrintf(e, "" dhparams=%s"", s->dhfile);",,"[""removeLog""]","[[""storeAppendPrintf"", ""e"", ""dhparams"", ""%s"", ""s"", ""dhfile""], []]",[-7434341468065256817],6900,2685600.0,3
https://github.com/squid-cache/squid/commit/d3b1bee6fff7792f482ff280e8400c6a3e83560f,14 Dec 2015,merge from trunk r14444,9318,data/crawl/squid/hunk_476.cpp,,,data/crawl/squid/old_hunk_476.cpp,data/crawl/squid/new_hunk_476.cpp,1223,-1,"storeAppendPrintf(&output, ""\n"");",,"[""removeLog""]","[[""storeAppendPrintf"", ""&output"", ""\\n""], []]",[-8190073519903471645],6899,12960.0,3
https://github.com/squid-cache/squid/commit/d3b1bee6fff7792f482ff280e8400c6a3e83560f,14 Dec 2015,merge from trunk r14444,9318,data/crawl/squid/hunk_476.cpp,,,data/crawl/squid/old_hunk_476.cpp,data/crawl/squid/new_hunk_476.cpp,1093,-1,"fatal(""'store_avg_object_size' should be larger than 0."");",,"[""removeLog""]","[[""fatal"", ""store_avg_object_size"", ""should"", ""be"", ""larger"", ""than"", ""0""], []]",[-4169576952635120669],6898,12960.0,3
https://github.com/squid-cache/squid/commit/d3b1bee6fff7792f482ff280e8400c6a3e83560f,14 Dec 2015,merge from trunk r14444,9318,data/crawl/squid/hunk_476.cpp,,,data/crawl/squid/old_hunk_476.cpp,data/crawl/squid/new_hunk_476.cpp,1090,-1,"fatal(""'store_objects_per_bucket' should be larger than 0."");",,"[""removeLog""]","[[""fatal"", ""store_objects_per_bucket"", ""should"", ""be"", ""larger"", ""than"", ""0""], []]",[12300532009220373221],6897,12960.0,3
https://github.com/squid-cache/squid/commit/d3b1bee6fff7792f482ff280e8400c6a3e83560f,14 Dec 2015,merge from trunk r14444,9318,data/crawl/squid/hunk_476.cpp,,,data/crawl/squid/old_hunk_476.cpp,data/crawl/squid/new_hunk_476.cpp,1046,-1,"fatal (""too much io\n"");",,"[""removeLog""]","[[""fatal"", ""too"", ""much"", ""io\\n""], []]",[21256136546020748691],6896,12960.0,3
https://github.com/squid-cache/squid/commit/d3b1bee6fff7792f482ff280e8400c6a3e83560f,14 Dec 2015,merge from trunk r14444,9318,data/crawl/squid/hunk_476.cpp,,,data/crawl/squid/old_hunk_476.cpp,data/crawl/squid/new_hunk_476.cpp,334,-1,"storeAppendPrintf(&output, ""Current Capacity       : %.2f%% used, %.2f%% free\n"",
                      Math::doublePercent(currentSize(), maxSize()),
                      Math::doublePercent((maxSize() - currentSize()), maxSize()));",,"[""removeLog""]","[[""storeAppendPrintf"", ""&output"", ""Current"", ""Capacity"", ""%"", ""2f%%"", ""used"", ""%"", ""2f%%"", ""free\\n"", ""Math"", ""doublePercent"", ""currentSize"", ""maxSize"", ""Math"", ""doublePercent"", ""maxSize"", ""currentSize"", ""maxSize""], []]",[5089640615166122444],6895,12960.0,3
https://github.com/squid-cache/squid/commit/d3b1bee6fff7792f482ff280e8400c6a3e83560f,14 Dec 2015,merge from trunk r14444,9318,data/crawl/squid/hunk_476.cpp,,,data/crawl/squid/old_hunk_476.cpp,data/crawl/squid/new_hunk_476.cpp,332,-1,"storeAppendPrintf(&output, ""Current Store Swap Size: %.2f KB\n"",
                      currentSize() / 1024.0);",,"[""removeLog""]","[[""storeAppendPrintf"", ""&output"", ""Current"", ""Store"", ""Swap"", ""Size"", ""%"", ""2f"", ""KB\\n"", ""currentSize"", ""/"", ""1024"", ""0""], []]",[1225167862351329007],6894,12960.0,3
https://github.com/squid-cache/squid/commit/d3b1bee6fff7792f482ff280e8400c6a3e83560f,14 Dec 2015,merge from trunk r14444,9318,data/crawl/squid/hunk_476.cpp,,,data/crawl/squid/old_hunk_476.cpp,data/crawl/squid/new_hunk_476.cpp,330,-1,"storeAppendPrintf(&output, ""Maximum Swap Size      : %"" PRIu64 "" KB\n"",
                      maxSize() >> 10);",,"[""removeLog""]","[[""storeAppendPrintf"", ""&output"", ""Maximum"", ""Swap"", ""Size"", ""%"", ""PRIu64"", ""KB\\n"", ""maxSize"", ""10""], []]",[-21396462949852261658],6893,12960.0,3
https://github.com/squid-cache/squid/commit/d3b1bee6fff7792f482ff280e8400c6a3e83560f,14 Dec 2015,merge from trunk r14444,9318,data/crawl/squid/hunk_476.cpp,,,data/crawl/squid/old_hunk_476.cpp,data/crawl/squid/new_hunk_476.cpp,328,-1,"storeAppendPrintf(&output, ""Store Entries          : %lu\n"",
                      (unsigned long int)StoreEntry::inUseCount());",,"[""removeLog""]","[[""storeAppendPrintf"", ""&output"", ""Store"", ""Entries"", ""%lu\\n"", ""unsigned"", ""long"", ""int"", ""StoreEntry"", ""inUseCount""], []]",[-10641832577037846956],6892,12960.0,3
https://github.com/squid-cache/squid/commit/d3b1bee6fff7792f482ff280e8400c6a3e83560f,14 Dec 2015,merge from trunk r14444,9318,data/crawl/squid/hunk_476.cpp,,,data/crawl/squid/old_hunk_476.cpp,data/crawl/squid/new_hunk_476.cpp,327,-1,"storeAppendPrintf(&output, ""Store Directory Statistics:\n"");",,"[""removeLog""]","[[""storeAppendPrintf"", ""&output"", ""Store"", ""Directory"", ""Statistics"", ""\\n""], []]",[-13978733286480319094],6891,12960.0,3
https://github.com/squid-cache/squid/commit/d3b1bee6fff7792f482ff280e8400c6a3e83560f,14 Dec 2015,merge from trunk r14444,9318,data/crawl/squid/hunk_475.cpp,,,data/crawl/squid/old_hunk_475.cpp,data/crawl/squid/new_hunk_475.cpp,-1,366,,"storeAppendPrintf(&output, ""\n"");","[""addLog""]","[[], [""storeAppendPrintf"", ""&output"", ""\\n""]]",[8190073519903471645],6890,12960.0,3
https://github.com/squid-cache/squid/commit/d3b1bee6fff7792f482ff280e8400c6a3e83560f,14 Dec 2015,merge from trunk r14444,9318,data/crawl/squid/hunk_471.cpp,,,data/crawl/squid/old_hunk_471.cpp,data/crawl/squid/new_hunk_471.cpp,-1,148,,"storeAppendPrintf(&output, ""Current Capacity       : %.2f%% used, %.2f%% free\n"",
                      Math::doublePercent(currentSize(), maxSize()),
                      Math::doublePercent((maxSize() - currentSize()), maxSize()));","[""addLog""]","[[], [""storeAppendPrintf"", ""&output"", ""Current"", ""Capacity"", ""%"", ""2f%%"", ""used"", ""%"", ""2f%%"", ""free\\n"", ""Math"", ""doublePercent"", ""currentSize"", ""maxSize"", ""Math"", ""doublePercent"", ""maxSize"", ""currentSize"", ""maxSize""]]",[-5089640615166122444],6889,12960.0,3
https://github.com/squid-cache/squid/commit/d3b1bee6fff7792f482ff280e8400c6a3e83560f,14 Dec 2015,merge from trunk r14444,9318,data/crawl/squid/hunk_471.cpp,,,data/crawl/squid/old_hunk_471.cpp,data/crawl/squid/new_hunk_471.cpp,-1,146,,"storeAppendPrintf(&output, ""Current Store Swap Size: %.2f KB\n"",
                      currentSize() / 1024.0);","[""addLog""]","[[], [""storeAppendPrintf"", ""&output"", ""Current"", ""Store"", ""Swap"", ""Size"", ""%"", ""2f"", ""KB\\n"", ""currentSize"", ""/"", ""1024"", ""0""]]",[-1225167862351329007],6888,12960.0,3
https://github.com/squid-cache/squid/commit/d3b1bee6fff7792f482ff280e8400c6a3e83560f,14 Dec 2015,merge from trunk r14444,9318,data/crawl/squid/hunk_471.cpp,,,data/crawl/squid/old_hunk_471.cpp,data/crawl/squid/new_hunk_471.cpp,-1,144,,"storeAppendPrintf(&output, ""Maximum Swap Size      : %"" PRIu64 "" KB\n"",
                      maxSize() >> 10);","[""addLog""]","[[], [""storeAppendPrintf"", ""&output"", ""Maximum"", ""Swap"", ""Size"", ""%"", ""PRIu64"", ""KB\\n"", ""maxSize"", ""10""]]",[21396462949852261658],6887,12960.0,3
https://github.com/squid-cache/squid/commit/d3b1bee6fff7792f482ff280e8400c6a3e83560f,14 Dec 2015,merge from trunk r14444,9318,data/crawl/squid/hunk_471.cpp,,,data/crawl/squid/old_hunk_471.cpp,data/crawl/squid/new_hunk_471.cpp,-1,142,,"storeAppendPrintf(&output, ""Store Entries          : %lu\n"",
                      (unsigned long int)StoreEntry::inUseCount());","[""addLog""]","[[], [""storeAppendPrintf"", ""&output"", ""Store"", ""Entries"", ""%lu\\n"", ""unsigned"", ""long"", ""int"", ""StoreEntry"", ""inUseCount""]]",[10641832577037846956],6886,12960.0,3
https://github.com/squid-cache/squid/commit/d3b1bee6fff7792f482ff280e8400c6a3e83560f,14 Dec 2015,merge from trunk r14444,9318,data/crawl/squid/hunk_471.cpp,,,data/crawl/squid/old_hunk_471.cpp,data/crawl/squid/new_hunk_471.cpp,-1,141,,"storeAppendPrintf(&output, ""Store Directory Statistics:\n"");","[""addLog""]","[[], [""storeAppendPrintf"", ""&output"", ""Store"", ""Directory"", ""Statistics"", ""\\n""]]",[13978733286480319094],6885,12960.0,3
https://github.com/squid-cache/squid/commit/d3b1bee6fff7792f482ff280e8400c6a3e83560f,14 Dec 2015,merge from trunk r14444,9318,data/crawl/squid/hunk_470.cpp,,,data/crawl/squid/old_hunk_470.cpp,data/crawl/squid/new_hunk_470.cpp,39,-1,"fatal(""Store::unlink on invalid Store\n"");",,"[""removeLog""]","[[""fatal"", ""Store"", ""unlink"", ""on"", ""invalid"", ""Store\\n""], []]",[9647309652365982831],6884,12960.0,3
https://github.com/squid-cache/squid/commit/d3b1bee6fff7792f482ff280e8400c6a3e83560f,14 Dec 2015,merge from trunk r14444,9318,data/crawl/squid/hunk_469.cpp,,,data/crawl/squid/old_hunk_469.cpp,data/crawl/squid/new_hunk_469.cpp,8,8,"storeAppendPrintf(s, ""\tnrequests: %d\n"",
                              conn->nrequests);","storeAppendPrintf(s, ""\tnrequests: %u\n"", conn->pipeline.nrequests);","[""updateContent"", ""addVariable""]","[[""%d\\n""], [""%u\\n"", ""pipeline""]]",[-6452227546100303071],6883,18720.0,3
https://github.com/squid-cache/squid/commit/d3b1bee6fff7792f482ff280e8400c6a3e83560f,14 Dec 2015,merge from trunk r14444,9318,data/crawl/squid/hunk_443.cpp,,,data/crawl/squid/old_hunk_443.cpp,data/crawl/squid/new_hunk_443.cpp,7,-1,"fatal(""Transients::get(key,callback,data) should not be called"");",,"[""removeLog""]","[[""fatal"", ""Transients"", ""get"", ""key"", ""callback"", ""data"", ""should"", ""not"", ""be"", ""called""], []]",[9343544430058125087],6882,12960.0,3
https://github.com/squid-cache/squid/commit/d3b1bee6fff7792f482ff280e8400c6a3e83560f,14 Dec 2015,merge from trunk r14444,9318,data/crawl/squid/hunk_439.cpp,,,data/crawl/squid/old_hunk_439.cpp,data/crawl/squid/new_hunk_439.cpp,7,-1,"fatal(""MemStore::get(key,callback,data) should not be called"");",,"[""removeLog""]","[[""fatal"", ""MemStore"", ""get"", ""key"", ""callback"", ""data"", ""should"", ""not"", ""be"", ""called""], []]",[-3864778167489770400],6881,12960.0,3
https://github.com/squid-cache/squid/commit/d3b1bee6fff7792f482ff280e8400c6a3e83560f,14 Dec 2015,merge from trunk r14444,9318,data/crawl/squid/hunk_435.cpp,,,data/crawl/squid/old_hunk_435.cpp,data/crawl/squid/new_hunk_435.cpp,121,-1,"fprintf(stderr, PROGRAM_NAME "": WARNING: SSL error %d (%s)\n"", sslerr, ldapssl_err2string(sslerr));",,"[""removeLog""]","[[""fprintf"", ""stderr"", ""PROGRAM_NAME"", ""WARNING"", ""SSL"", ""error"", ""%d"", ""%s"", ""\\n"", ""sslerr"", ""ldapssl_err2string"", ""sslerr""], []]",[8521655138693661446],6880,3375360.0,3
https://github.com/squid-cache/squid/commit/898d1a09e1d9e8f39de5d34df6793197c0fc8dc4,31 Jan 2016,"SourceLayout: rename ClientSocketContext to Http::Stream

 ... and provided through http/libsquid-http.la.

The name is chosen to match the RFC7540 HTTP/2 ""stream"" terminology.
Which defines a stream as a bi-directional transaction, including request,
reply and all related 1xx informational and/or control messages.

That same word ""stream"" is also used in RFC7230 briefly to describe the
same ""transaction"" scope and details. But not formalized until RFC7540.

Http::Stream's may be initiated by a client HTTP request, Squid internally,
or in HTTP/2 a server PUSH_PROMISE frame.

There are no logic changes in this. Just symbol renaming and move.",1958,data/crawl/squid/hunk_369.cpp,,,data/crawl/squid/old_hunk_369.cpp,data/crawl/squid/new_hunk_369.cpp,-1,70,,"initiateClose(""failure or true request status"");","[""addLog""]","[[], [""initiateClose"", ""failure"", ""or"", ""true"", ""request"", ""status""]]",[-6969606714274698964],6879,3082560.0,3
https://github.com/squid-cache/squid/commit/0bffe3cec1400f4d69724552e77e77878defd8a3,23 May 2016,"Sync with trunk-r14686

- Replaces with newer versions of BinaryTokenizer and HandshakeParser classes
- Modifications to use latest Handshake parser from trunk.
- Get HandshakeParser::serverCertificates, HandshakeParser::parseServerCertificates and HandshakeParser::ParseCertificate implementation from lp:fast-sni branch",6170,data/crawl/squid/hunk_227.cpp,,,data/crawl/squid/old_hunk_227.cpp,data/crawl/squid/new_hunk_227.cpp,-1,12,,"fputs(out.buf, stdout);","[""addLog""]","[[], [""fputs"", ""out"", ""buf"", ""stdout""]]",[-7760073820532761677],6878,30720.0,3
https://github.com/squid-cache/squid/commit/0bffe3cec1400f4d69724552e77e77878defd8a3,23 May 2016,"Sync with trunk-r14686

- Replaces with newer versions of BinaryTokenizer and HandshakeParser classes
- Modifications to use latest Handshake parser from trunk.
- Get HandshakeParser::serverCertificates, HandshakeParser::parseServerCertificates and HandshakeParser::ParseCertificate implementation from lp:fast-sni branch",6170,data/crawl/squid/hunk_227.cpp,,,data/crawl/squid/old_hunk_227.cpp,data/crawl/squid/new_hunk_227.cpp,8,-1,"fputs(munge_other_line(buf, req), stdout);",,"[""removeLog""]","[[""fputs"", ""munge_other_line"", ""buf"", ""req"", ""stdout""], []]",[11026334546984865509],6877,30720.0,3
https://github.com/squid-cache/squid/commit/0bffe3cec1400f4d69724552e77e77878defd8a3,23 May 2016,"Sync with trunk-r14686

- Replaces with newer versions of BinaryTokenizer and HandshakeParser classes
- Modifications to use latest Handshake parser from trunk.
- Get HandshakeParser::serverCertificates, HandshakeParser::parseServerCertificates and HandshakeParser::ParseCertificate implementation from lp:fast-sni branch",6170,data/crawl/squid/hunk_227.cpp,,,data/crawl/squid/old_hunk_227.cpp,data/crawl/squid/new_hunk_227.cpp,6,-1,"fputs(munge_menu_line(buf, req), stdout);",,"[""removeLog""]","[[""fputs"", ""munge_menu_line"", ""buf"", ""req"", ""stdout""], []]",[6249281519666114897],6876,30720.0,3
https://github.com/squid-cache/squid/commit/0bffe3cec1400f4d69724552e77e77878defd8a3,23 May 2016,"Sync with trunk-r14686

- Replaces with newer versions of BinaryTokenizer and HandshakeParser classes
- Modifications to use latest Handshake parser from trunk.
- Get HandshakeParser::serverCertificates, HandshakeParser::parseServerCertificates and HandshakeParser::ParseCertificate implementation from lp:fast-sni branch",6170,data/crawl/squid/hunk_224.cpp,,,data/crawl/squid/old_hunk_224.cpp,data/crawl/squid/new_hunk_224.cpp,14,13,"fprintf(stderr, APP_SHORTNAME "": ERROR: Could not read pid file\n"");","fprintf(stderr, APP_SHORTNAME "": ERROR: Could not open PID file for read\n"");","[""updateContent""]","[[""read"", ""pid"", ""file\\n""], [""open"", ""PID"", ""file"", ""for"", ""read\\n""]]",[-6683045894385230470],6875,43200.0,3
https://github.com/squid-cache/squid/commit/0bffe3cec1400f4d69724552e77e77878defd8a3,23 May 2016,"Sync with trunk-r14686

- Replaces with newer versions of BinaryTokenizer and HandshakeParser classes
- Modifications to use latest Handshake parser from trunk.
- Get HandshakeParser::serverCertificates, HandshakeParser::parseServerCertificates and HandshakeParser::ParseCertificate implementation from lp:fast-sni branch",6170,data/crawl/squid/hunk_219.cpp,,,data/crawl/squid/old_hunk_219.cpp,data/crawl/squid/new_hunk_219.cpp,-1,10,,"request->header.putStr(Http::HOST, tmp.c_str());","[""addLog""]","[[], [""request"", ""header"", ""putStr"", ""Http"", ""HOST"", ""tmp"", ""c_str""]]",[2756243321553634903],6874,15360.0,3
https://github.com/squid-cache/squid/commit/0bffe3cec1400f4d69724552e77e77878defd8a3,23 May 2016,"Sync with trunk-r14686

- Replaces with newer versions of BinaryTokenizer and HandshakeParser classes
- Modifications to use latest Handshake parser from trunk.
- Get HandshakeParser::serverCertificates, HandshakeParser::parseServerCertificates and HandshakeParser::ParseCertificate implementation from lp:fast-sni branch",6170,data/crawl/squid/hunk_217.cpp,,,data/crawl/squid/old_hunk_217.cpp,data/crawl/squid/new_hunk_217.cpp,-1,28,,(alert.fatal();,"[""addLog""]","[[], [""alert"", ""fatal""]]",[-2237907343613694454],6873,19680.0,3
https://github.com/squid-cache/squid/commit/0bffe3cec1400f4d69724552e77e77878defd8a3,23 May 2016,"Sync with trunk-r14686

- Replaces with newer versions of BinaryTokenizer and HandshakeParser classes
- Modifications to use latest Handshake parser from trunk.
- Get HandshakeParser::serverCertificates, HandshakeParser::parseServerCertificates and HandshakeParser::ParseCertificate implementation from lp:fast-sni branch",6170,data/crawl/squid/hunk_217.cpp,,,data/crawl/squid/old_hunk_217.cpp,data/crawl/squid/new_hunk_217.cpp,-1,25,,"debugs(83, (alert.fatal() ? 2:3),
           ""level "" << static_cast<int>(alert.level) <<
           "" description "" << static_cast<int>(alert.description));","[""addLog""]","[[], [""debugs"", ""83"", ""alert"", ""fatal"", ""2"", ""3"", ""level"", ""static_cast"", ""int"", ""alert"", ""level"", ""description"", ""static_cast"", ""int"", ""alert"", ""description""]]",[-9004269533873689954],6872,19680.0,3
https://github.com/squid-cache/squid/commit/0bffe3cec1400f4d69724552e77e77878defd8a3,23 May 2016,"Sync with trunk-r14686

- Replaces with newer versions of BinaryTokenizer and HandshakeParser classes
- Modifications to use latest Handshake parser from trunk.
- Get HandshakeParser::serverCertificates, HandshakeParser::parseServerCertificates and HandshakeParser::ParseCertificate implementation from lp:fast-sni branch",6170,data/crawl/squid/hunk_205.cpp,,,data/crawl/squid/old_hunk_205.cpp,data/crawl/squid/new_hunk_205.cpp,3,5,"logfilePrintf(logfile, ""%9ld.%03d %s %s %s\n"",
                  (long int) current_time.tv_sec,
                  (int) current_time.tv_usec / 1000,
                  clientip,
                  referer,
                  al->url ? al->url : ""-"");","logfilePrintf(logfile, ""%9ld.%03d %s %s "" SQUIDSBUFPH ""\n"",
                  (long int) current_time.tv_sec,
                  (int) current_time.tv_usec / 1000,
                  clientip,
                  referer,
                  SQUIDSBUFPRINT(url));","[""removeVariable"", ""updateContent"", ""addContent"", ""removeContent"", ""addVariable""]","[[""%s\\n"", ""al"", ""al"", ""url""], [""SQUIDSBUFPH"", ""\\n"", ""SQUIDSBUFPRINT""]]",[1222651555877977458],6871,51840.0,3
https://github.com/squid-cache/squid/commit/0bffe3cec1400f4d69724552e77e77878defd8a3,23 May 2016,"Sync with trunk-r14686

- Replaces with newer versions of BinaryTokenizer and HandshakeParser classes
- Modifications to use latest Handshake parser from trunk.
- Get HandshakeParser::serverCertificates, HandshakeParser::parseServerCertificates and HandshakeParser::ParseCertificate implementation from lp:fast-sni branch",6170,data/crawl/squid/hunk_182.cpp,,,data/crawl/squid/old_hunk_182.cpp,data/crawl/squid/new_hunk_182.cpp,-1,6,,"storeAppendPrintf(entry, ""%s %"" PRId64 ""\n"", name, var);","[""addLog""]","[[], [""storeAppendPrintf"", ""entry"", ""%s"", ""%"", ""PRId64"", ""\\n"", ""name"", ""var""]]",[3252915763092037348],6870,47040.0,3
https://github.com/squid-cache/squid/commit/83f8d8f97118e1cae98c2c434e6643e04d1be113,11 Sep 2016,"Move Ssl::Errors to libsecurity

Convert to an STL set instead of CBDATA list:
* The list is not passed as a callback parameter, so CBDATA overheads are
  unnecessary.
* STL set has built-in unique entry protection, so special
  push_back_unique handling is not required. Just emplace() entries.
* STL unorderd_set is used for fast lookup property. This should operate
  faster on medium or larger sized ACL lists than CbDataList type could.",110,data/crawl/squid/hunk_143.cpp,,,data/crawl/squid/old_hunk_143.cpp,data/crawl/squid/new_hunk_143.cpp,10,9,"fatalf(""Unknown SSL error name '%s'"", name);","fatalf(""Unknown TLS error name '%s'"", name);","[""updateContent""]","[[""SSL""], [""TLS""]]",[-1126055512629858161],6869,210720.0,3
https://github.com/squid-cache/squid/commit/40fc161851f5809741ddb4774e7c366d23323a97,05 Feb 2017,Sync from v5 r15034,2231,data/crawl/squid/hunk_61.cpp,,,data/crawl/squid/old_hunk_61.cpp,data/crawl/squid/new_hunk_61.cpp,38,28,"auth_user_request->denyMessage(""Negotiate Authentication failed with no reason given"");","auth_user_request->denyMessageFromHelper(""Negotiate"", reply);","[""updateLog"", ""updateContent"", ""addVariable""]","[[""denyMessage"", ""Authentication"", ""failed"", ""with"", ""no"", ""reason"", ""given""], [""denyMessageFromHelper"", ""reply""]]",[14869884450892109253],6868,5760.0,3
https://github.com/squid-cache/squid/commit/40fc161851f5809741ddb4774e7c366d23323a97,05 Feb 2017,Sync from v5 r15034,2231,data/crawl/squid/hunk_61.cpp,,,data/crawl/squid/old_hunk_61.cpp,data/crawl/squid/new_hunk_61.cpp,36,-1,auth_user_request->denyMessage(errNote);,,"[""removeLog""]","[[""auth_user_request"", ""denyMessage"", ""errNote""], []]",[1326431015401465511],6867,0.0,3
https://github.com/squid-cache/squid/commit/12b9e9b1f34032b49437866c39c8f9d2e4f4b045,28 Mar 1996,"new debug section,level stuff",1600,data/crawl/squid/hunk_7958.cpp,,,data/crawl/squid/old_hunk_7958.cpp,data/crawl/squid/new_hunk_7958.cpp,15,-1,"printf(""         use the 'inside_firewall' and 'local_domain' lines\n"");",,"[""removeLog""]","[[""printf"", ""use"", ""the"", ""inside_firewall"", ""and"", ""local_domain"", ""lines\\n""], []]",[-3010694902379083115],6866,0.0,2
https://github.com/squid-cache/squid/commit/f5558c95a8b97794c224a6b03b0d66127891210d,29 Mar 1996,Implemented prototype IMS-GET and change-key-until-headers-read,282,data/crawl/squid/hunk_7938.cpp,,,data/crawl/squid/old_hunk_7938.cpp,data/crawl/squid/new_hunk_7938.cpp,-1,4,,"fatal_dump(""storeUnChangeKey: Hash table 'table' is zero!\n"");","[""addLog""]","[[], [""fatal_dump"", ""storeUnChangeKey"", ""Hash"", ""table"", ""table"", ""is"", ""zero"", ""\\n""]]",[-3178018769607953594],6865,0.0,2
https://github.com/squid-cache/squid/commit/6eb42caec6c6db2142568d6dd4426e89e6c16f8f,04 Apr 1996,major code cleanup/unification/rewrite,624,data/crawl/squid/hunk_7884.cpp,,,data/crawl/squid/old_hunk_7884.cpp,data/crawl/squid/new_hunk_7884.cpp,3,3,"fatal(""Cannot open ascii Port\n"");","fatal(""Cannot open ascii Port"");","[""updateContent""]","[[""Port\\n""], [""Port""]]",[1176236813168864752],6864,0.0,2
https://github.com/squid-cache/squid/commit/6eb42caec6c6db2142568d6dd4426e89e6c16f8f,04 Apr 1996,major code cleanup/unification/rewrite,624,data/crawl/squid/hunk_7882.cpp,,,data/crawl/squid/old_hunk_7882.cpp,data/crawl/squid/new_hunk_7882.cpp,-1,29,,"fatal_dump(""cached_error_url: type out of range."");","[""addLog""]","[[], [""fatal_dump"", ""cached_error_url"", ""type"", ""out"", ""of"", ""range""]]",[-13139861453368182966],6863,3600.0,2
https://github.com/squid-cache/squid/commit/c8bd12b18fe14c595b1b45354df85fd5a47e1f93,04 Apr 1996,"From:    ""Daniel O'Callaghan"" <danny@miriworld.its.unimelb.EDU.AU>

This patch replaces  ip_acl_match(), ip_access_check() and addToIPACL()
with versions which accept the following formats:

proxy_allow 1.2.3.0     (old cached format for 1.2.3.0/24)
proxy_allow 1.2.0.0     (old cached format for 1.2.0.0/16)

proxy_allow 1.2.3.4     (equivalent to 1.2.3.4/32)
proxy_allow 1.2.3.0/24
proxy_allow 1.2.3.0/255.255.255.0

proxy_allow all         (equivalent to 0.0.0.0/0.0.0.0)",132,data/crawl/squid/hunk_7881.cpp,,,data/crawl/squid/old_hunk_7881.cpp,data/crawl/squid/new_hunk_7881.cpp,-1,106,,"fprintf(stderr,
		    ""cached.conf error in IP acl line %s (ignored)\n"",
		    ip_str);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""cached"", ""conf"", ""error"", ""in"", ""IP"", ""acl"", ""line"", ""%s"", ""ignored"", ""\\n"", ""ip_str""]]",[6535138188355621304],6862,0.0,2
https://github.com/squid-cache/squid/commit/da00e8509f4c3bf25e093b0f8901860f01794716,04 Apr 1996,use debug() rather than stderr,11,data/crawl/squid/hunk_7878.cpp,,,data/crawl/squid/old_hunk_7878.cpp,data/crawl/squid/new_hunk_7878.cpp,3,3,"fprintf(stderr,
		    ""cached.conf error in IP acl line %s (ignored)\n"",
		    ip_str);","debug(3, 0, ""addToIPACL: Ignoring invalid IP acl line '%s'\n"",
		    ip_str);","[""updateLog"", ""removeVariable"", ""addContent"", ""updateContent""]","[[""fprintf"", ""stderr"", ""cached"", ""conf"", ""error"", ""in"", ""ignored""], [""debug"", ""3"", ""0"", ""addToIPACL"", ""Ignoring"", ""invalid""]]",[11123615058567768574],6861,0.0,2
https://github.com/squid-cache/squid/commit/8213067d159ba46b0557380d483ce181762bc1df,11 Apr 1996,apparently mostly working ACLs,384,data/crawl/squid/hunk_7859.cpp,,,data/crawl/squid/old_hunk_7859.cpp,data/crawl/squid/new_hunk_7859.cpp,3,3,"printf(""Harvest Cache: Version %s\n"", SQUID_VERSION);","printf(""Harvest Cache: Version %s\n"", version_string);","[""updateVariable""]","[[""SQUID_VERSION""], [""version_string""]]",[2145715888889987516],6860,0.0,2
https://github.com/squid-cache/squid/commit/b8de7ebe12756b6d6a09a0b034952c1e11325c95,16 Apr 1996,"change ""cached"" to ""squid"" in lots of places",640,data/crawl/squid/hunk_7846.cpp,,,data/crawl/squid/old_hunk_7846.cpp,data/crawl/squid/new_hunk_7846.cpp,2,2,"fprintf(cache_hierarchy_log, ""%d %s %s%s %s\n"",
		(int) cached_curtime,
		url,
		timeout ? ""TIMEOUT_"" : """",
		hier_strings[code],
		cache_host);","fprintf(cache_hierarchy_log, ""%d %s %s%s %s\n"",
		(int) squid_curtime,
		url,
		timeout ? ""TIMEOUT_"" : """",
		hier_strings[code],
		cache_host);","[""updateVariable""]","[[""cached_curtime""], [""squid_curtime""]]",[-11233380819947686557],6859,0.0,2
https://github.com/squid-cache/squid/commit/b8de7ebe12756b6d6a09a0b034952c1e11325c95,16 Apr 1996,"change ""cached"" to ""squid"" in lots of places",640,data/crawl/squid/hunk_7842.cpp,,,data/crawl/squid/old_hunk_7842.cpp,data/crawl/squid/new_hunk_7842.cpp,3,3,"fatal_dump(""cached_error_url: type out of range."");","fatal_dump(""squid_error_url: type out of range."");","[""updateContent""]","[[""cached_error_url""], [""squid_error_url""]]",[8710127190126751657],6858,0.0,2
https://github.com/squid-cache/squid/commit/b8de7ebe12756b6d6a09a0b034952c1e11325c95,16 Apr 1996,"change ""cached"" to ""squid"" in lots of places",640,data/crawl/squid/hunk_7838.cpp,,,data/crawl/squid/old_hunk_7838.cpp,data/crawl/squid/new_hunk_7838.cpp,11,11,"printf(""         For this run, however, cached will use %d kbytes for cache_swap.\n"", getCacheSwapMax());","printf(""         For this run, however, %s will use %d kbytes for cache_swap.\n"", appname, getCacheSwapMax());","[""updateContent"", ""addVariable""]","[[""cached""], [""%s"", ""appname""]]",[-6051341086951825635],6857,0.0,2
https://github.com/squid-cache/squid/commit/c5c666abb1fa898db13dd58dbd73e8d3a0e04a6d,16 Apr 1996,"fix Makefile clean target
remove references to Harvest",70,data/crawl/squid/hunk_7834.cpp,,,data/crawl/squid/old_hunk_7834.cpp,data/crawl/squid/new_hunk_7834.cpp,3,3,"printf(""Harvest Cache: Version %s\n"", version_string);","printf(""Squid Cache: Version %s\n"", version_string);","[""updateContent""]","[[""Harvest""], [""Squid""]]",[5933233547553506351],6856,0.0,2
https://github.com/squid-cache/squid/commit/c30c5a739f6b27a74c8750c6b4aa01daad7c813e,19 Apr 1996,use storeAppendPrintf() instead of sprintf();storeAppend(),371,data/crawl/squid/hunk_7817.cpp,,,data/crawl/squid/old_hunk_7817.cpp,data/crawl/squid/new_hunk_7817.cpp,-1,3,,"storeAppendPrintf(data->sentry, ""}\n"");","[""addLog""]","[[], [""storeAppendPrintf"", ""data"", ""sentry"", ""\\n""]]",[-2738076688578465314],6855,0.0,2
https://github.com/squid-cache/squid/commit/234967c95c2a7139e95200ad24a8e2581880a029,02 May 1996,merging all changes up to squid-1.0.beta5,1451,data/crawl/squid/hunk_7802.cpp,,,data/crawl/squid/old_hunk_7802.cpp,data/crawl/squid/new_hunk_7802.cpp,-1,3,,"storeAppendPrintf(sentry, ""{Connection information for %s:}\n"",
	appname);","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""Connection"", ""information"", ""for"", ""%s"", ""\\n"", ""appname""]]",[5207409015510323392],6854,9360.0,2
https://github.com/squid-cache/squid/commit/234967c95c2a7139e95200ad24a8e2581880a029,02 May 1996,merging all changes up to squid-1.0.beta5,1451,data/crawl/squid/hunk_7800.cpp,,,data/crawl/squid/old_hunk_7800.cpp,data/crawl/squid/new_hunk_7800.cpp,3,3,"fprintf(cache_hierarchy_log, ""%d %s %s%s %s\n"",
		(int) squid_curtime,
		url,
		timeout ? ""TIMEOUT_"" : """",
		hier_strings[code],
		cache_host);","fprintf(cache_hierarchy_log, ""%d.%03d %s %s%s %s\n"",
		(int) current_time.tv_sec,
		(int) current_time.tv_usec / 1000,
		url,
		timeout ? ""TIMEOUT_"" : """",
		hier_strings[code],
		cache_host);","[""removeVariable"", ""updateContent"", ""addContent"", ""addVariable""]","[[""squid_curtime""], [""%03d"", ""current_time"", ""tv_sec"", ""int"", ""current_time"", ""tv_usec"", ""/"", ""1000""]]",[9204310726049635646],6853,0.0,2
https://github.com/squid-cache/squid/commit/234967c95c2a7139e95200ad24a8e2581880a029,02 May 1996,merging all changes up to squid-1.0.beta5,1451,data/crawl/squid/hunk_7790.cpp,,,data/crawl/squid/old_hunk_7790.cpp,data/crawl/squid/new_hunk_7790.cpp,7,-1,"printf(""<OPTION VALUE=\""log\"">Cache Log\n"");",,"[""removeLog""]","[[""printf"", ""OPTION"", ""VALUE"", ""\\"", ""log\\"", ""Cache"", ""Log\\n""], []]",[3215372113052218659],6852,0.0,2
https://github.com/squid-cache/squid/commit/983061ed9eb08a8f5b02ae74f5adc0140b933d87,04 May 1996,merging changes from SQUID_1_0 branch,1418,data/crawl/squid/hunk_7782.cpp,,,data/crawl/squid/old_hunk_7782.cpp,data/crawl/squid/new_hunk_7782.cpp,-1,241,,"fatal_dump(""sslReadTimeout: FD mismatch!\n"");","[""addLog""]","[[], [""fatal_dump"", ""sslReadTimeout"", ""FD"", ""mismatch"", ""\\n""]]",[-14846918233041060754],6851,0.0,2
https://github.com/squid-cache/squid/commit/983061ed9eb08a8f5b02ae74f5adc0140b933d87,04 May 1996,merging changes from SQUID_1_0 branch,1418,data/crawl/squid/hunk_7782.cpp,,,data/crawl/squid/old_hunk_7782.cpp,data/crawl/squid/new_hunk_7782.cpp,-1,42,,"fatal_dump(""sslStateFree: FD mismatch!\n"");","[""addLog""]","[[], [""fatal_dump"", ""sslStateFree"", ""FD"", ""mismatch"", ""\\n""]]",[-6575889428949358056],6850,0.0,2
https://github.com/squid-cache/squid/commit/30a4f2a885dbb469498c0e805e1e8d42244788be,09 Jul 1996,cleanup after big merge,12717,data/crawl/squid/hunk_7775.cpp,,,data/crawl/squid/old_hunk_7775.cpp,data/crawl/squid/new_hunk_7775.cpp,45,-1,"fprintf(lf, ""CPU Usage: user %d sys %d\nMemory Usage: rss %d KB\n"",
	rusage.ru_utime.tv_sec, rusage.ru_stime.tv_sec,
	rusage.ru_maxrss * getpagesize() / 1000);",,"[""removeLog""]","[[""fprintf"", ""lf"", ""CPU"", ""Usage"", ""user"", ""%d"", ""sys"", ""%d\\nMemory"", ""Usage"", ""rss"", ""%d"", ""KB\\n"", ""rusage"", ""ru_utime"", ""tv_sec"", ""rusage"", ""ru_stime"", ""tv_sec"", ""rusage"", ""ru_maxrss"", ""*"", ""getpagesize"", ""/"", ""1000""], []]",[12237231477693356759],6849,74160.0,2
https://github.com/squid-cache/squid/commit/30a4f2a885dbb469498c0e805e1e8d42244788be,09 Jul 1996,cleanup after big merge,12717,data/crawl/squid/hunk_7775.cpp,,,data/crawl/squid/old_hunk_7775.cpp,data/crawl/squid/new_hunk_7775.cpp,22,33,"fprintf(f, ""   number of small blocks in a holding block  %d\n"",
	mp.nlblks);","fprintf(f, ""\tnumber of small blocks in a holding block:\t%d\n"",
	mp.nlblks);","[""updateContent""]","[[""number"", ""%d\\n""], [""\\tnumber"", ""\\t%d\\n""]]",[-2632706847231742984],6848,0.0,2
https://github.com/squid-cache/squid/commit/30a4f2a885dbb469498c0e805e1e8d42244788be,09 Jul 1996,cleanup after big merge,12717,data/crawl/squid/hunk_7775.cpp,,,data/crawl/squid/old_hunk_7775.cpp,data/crawl/squid/new_hunk_7775.cpp,17,-1,"fprintf(f, ""   space in ordinary blocks in use  %d\n"", mp.uordblks);",,"[""removeLog""]","[[""fprintf"", ""f"", ""space"", ""in"", ""ordinary"", ""blocks"", ""in"", ""use"", ""%d\\n"", ""mp"", ""uordblks""], []]",[6840522631576659716],6847,74160.0,2
https://github.com/squid-cache/squid/commit/30a4f2a885dbb469498c0e805e1e8d42244788be,09 Jul 1996,cleanup after big merge,12717,data/crawl/squid/hunk_7739.cpp,,,data/crawl/squid/old_hunk_7739.cpp,data/crawl/squid/new_hunk_7739.cpp,4,-1,"fatal_dump(""sslReadTimeout: FD mismatch!\n"");",,"[""removeLog""]","[[""fatal_dump"", ""sslReadTimeout"", ""FD"", ""mismatch"", ""\\n""], []]",[14846918233041060754],6846,0.0,2
https://github.com/squid-cache/squid/commit/30a4f2a885dbb469498c0e805e1e8d42244788be,09 Jul 1996,cleanup after big merge,12717,data/crawl/squid/hunk_7735.cpp,,,data/crawl/squid/old_hunk_7735.cpp,data/crawl/squid/new_hunk_7735.cpp,23,28,fatal(tmp_error_buf);,safe_free(e);,"[""updateVariable"", ""updateLog""]","[[""fatal"", ""tmp_error_buf""], [""safe_free"", ""e""]]",[19412267563886803759],6845,0.0,2
https://github.com/squid-cache/squid/commit/81b795fa81a7ac196b532a343f50be275f1cd429,10 Jul 1996,Added filedesciptor and reply_header entries,22,data/crawl/squid/hunk_7706.cpp,,,data/crawl/squid/old_hunk_7706.cpp,data/crawl/squid/new_hunk_7706.cpp,-1,6,,"printf(""<OPTION VALUE=\""stats/vm_objects\"">VM_Objects\n"");","[""addLog""]","[[], [""printf"", ""OPTION"", ""VALUE"", ""\\"", ""stats/vm_objects\\"", ""VM_Objects\\n""]]",[-1561553180655118294],6844,0.0,2
https://github.com/squid-cache/squid/commit/d2af947760f5e7a92ab3bf260744c55ce19ac073,11 Jul 1996,redirector up to snuff,639,data/crawl/squid/hunk_7696.cpp,,,data/crawl/squid/old_hunk_7696.cpp,data/crawl/squid/new_hunk_7696.cpp,-1,41,,"fatal_dump(""redirectStart: NULL handler"");","[""addLog""]","[[], [""fatal_dump"", ""redirectStart"", ""NULL"", ""handler""]]",[-20307552045099219304],6843,1440.0,2
https://github.com/squid-cache/squid/commit/d2af947760f5e7a92ab3bf260744c55ce19ac073,11 Jul 1996,redirector up to snuff,639,data/crawl/squid/hunk_7693.cpp,,,data/crawl/squid/old_hunk_7693.cpp,data/crawl/squid/new_hunk_7693.cpp,-1,12,,"printf(""WARNING: redirect_children was set to a bad value: %d\n"",
	    getRedirectChildren());","[""addLog""]","[[], [""printf"", ""WARNING"", ""redirect_children"", ""was"", ""set"", ""to"", ""a"", ""bad"", ""value"", ""%d\\n"", ""getRedirectChildren""]]",[-2183495583320205808],6842,0.0,2
https://github.com/squid-cache/squid/commit/f88bb09c780151eb3736f0dc774ab5df6858ee4d,22 Jul 1996,"-Split ipcache.c into ipcache.c and dns.c
-Moved newer functions from icp.c to client_side.c
-Added fqdncache.c, like ipcache.c
-Added new ACL type ACL_SRC_DOMAIN 'srcdomain'
-Use aclMatchDomainList() instead of aclMatchWord() for domain names
-Renamed 'stats/general' to 'stats/ipcache'",1929,data/crawl/squid/hunk_7675.cpp,,,data/crawl/squid/old_hunk_7675.cpp,data/crawl/squid/new_hunk_7675.cpp,-1,252,,"storeAppendPrintf(sentry, ""{dnsservers use histogram:}\n"");","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""dnsservers"", ""use"", ""histogram"", ""\\n""]]",[3592243268571107408],6841,9360.0,2
https://github.com/squid-cache/squid/commit/b6f794d6be5abf71f7d53e6222ed4fc4e7532efb,25 Jul 1996,"Removed all the get*() turds, now use Config structure directly.",843,data/crawl/squid/hunk_7666.cpp,,,data/crawl/squid/old_hunk_7666.cpp,data/crawl/squid/new_hunk_7666.cpp,38,38,"printf(""WARNING: redirect_children was set to a bad value: %d\n"",
	    getRedirectChildren());","printf(""WARNING: redirect_children was set to a bad value: %d\n"",
	    Config.redirectChildren);","[""removeVariable"", ""addVariable""]","[[""getRedirectChildren""], [""Config"", ""redirectChildren""]]",[-979107095127866057],6840,0.0,2
https://github.com/squid-cache/squid/commit/b6f794d6be5abf71f7d53e6222ed4fc4e7532efb,25 Jul 1996,"Removed all the get*() turds, now use Config structure directly.",843,data/crawl/squid/hunk_7666.cpp,,,data/crawl/squid/old_hunk_7666.cpp,data/crawl/squid/new_hunk_7666.cpp,27,27,"printf(""WARNING: dns_children was set to a bad value: %d\n"",
	    getDnsChildren());","printf(""WARNING: dns_children was set to a bad value: %d\n"",
	    Config.dnsChildren);","[""removeVariable"", ""addVariable""]","[[""getDnsChildren""], [""Config"", ""dnsChildren""]]",[-13101996368854436315],6839,0.0,2
https://github.com/squid-cache/squid/commit/b6f794d6be5abf71f7d53e6222ed4fc4e7532efb,25 Jul 1996,"Removed all the get*() turds, now use Config structure directly.",843,data/crawl/squid/hunk_7666.cpp,,,data/crawl/squid/old_hunk_7666.cpp,data/crawl/squid/new_hunk_7666.cpp,23,23,"printf(""         For this run, however, %s will use %d minutes for clean_rate.\n"", appname, (int) (getCleanRate() / 60));","printf(""         For this run, however, %s will use %d minutes for clean_rate.\n"", appname, (int) (Config.cleanRate / 60));","[""removeVariable"", ""addVariable""]","[[""getCleanRate""], [""Config"", ""cleanRate""]]",[2050313424590516075],6838,0.0,2
https://github.com/squid-cache/squid/commit/b6f794d6be5abf71f7d53e6222ed4fc4e7532efb,25 Jul 1996,"Removed all the get*() turds, now use Config structure directly.",843,data/crawl/squid/hunk_7666.cpp,,,data/crawl/squid/old_hunk_7666.cpp,data/crawl/squid/new_hunk_7666.cpp,15,15,"printf(""         For this run, however, %s will use %d kbytes for cache_swap.\n"", appname, getCacheSwapMax());","printf(""         For this run, however, %s will use %d kbytes for cache_swap.\n"", appname, Config.Swap.maxSize);","[""removeVariable"", ""addVariable""]","[[""getCacheSwapMax""], [""Config"", ""Swap"", ""maxSize""]]",[7058633051817301291],6837,0.0,2
https://github.com/squid-cache/squid/commit/edae7bc01b8c21f6c9db039886bb2271dee5758f,20 Aug 1996,compiler,14,data/crawl/squid/hunk_7646.cpp,,,data/crawl/squid/old_hunk_7646.cpp,data/crawl/squid/new_hunk_7646.cpp,3,3,"fprintf(fp, ""To: %s\n"", getAdminEmail());","fprintf(fp, ""To: %s\n"", Config.adminEmail);","[""removeVariable"", ""addVariable""]","[[""getAdminEmail""], [""Config"", ""adminEmail""]]",[-5707690273233795741],6836,18720.0,2
https://github.com/squid-cache/squid/commit/10321c65385827acf581a46836882a8c3fcec259,20 Aug 1996,add redirector stats,12,data/crawl/squid/hunk_7644.cpp,,,data/crawl/squid/old_hunk_7644.cpp,data/crawl/squid/new_hunk_7644.cpp,-1,4,,"printf(""</SELECT>"");","[""addLog""]","[[], [""printf"", ""/SELECT""]]",[4701123320431530247],6835,20880.0,2
https://github.com/squid-cache/squid/commit/10321c65385827acf581a46836882a8c3fcec259,20 Aug 1996,add redirector stats,12,data/crawl/squid/hunk_7643.cpp,,,data/crawl/squid/old_hunk_7643.cpp,data/crawl/squid/new_hunk_7643.cpp,-1,5,,"printf(""<OPTION VALUE=\""refresh\"">Refresh Object (URL required)\n"");","[""addLog""]","[[], [""printf"", ""OPTION"", ""VALUE"", ""\\"", ""refresh\\"", ""Refresh"", ""Object"", ""URL"", ""required"", ""\\n""]]",[-12902735912966907942],6834,20880.0,2
https://github.com/squid-cache/squid/commit/af00901c8240077af4a9e5758dd6c30f14564802,27 Aug 1996,merge from SQUID_1_0_10,477,data/crawl/squid/hunk_7633.cpp,,,data/crawl/squid/old_hunk_7633.cpp,data/crawl/squid/new_hunk_7633.cpp,-1,50,,"storeAppendPrintf(sentry, "" %s"", i->entry.h_name);","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""%s"", ""i"", ""entry"", ""h_name""]]",[8228192580865638877],6833,35280.0,2
https://github.com/squid-cache/squid/commit/af00901c8240077af4a9e5758dd6c30f14564802,27 Aug 1996,merge from SQUID_1_0_10,477,data/crawl/squid/hunk_7633.cpp,,,data/crawl/squid/old_hunk_7633.cpp,data/crawl/squid/new_hunk_7633.cpp,-1,47,,"storeAppendPrintf(sentry, "" %s"", i->entry.h_aliases[k]);","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""%s"", ""i"", ""entry"", ""h_aliases[k]""]]",[-631824269237080595],6832,35280.0,2
https://github.com/squid-cache/squid/commit/e84703adde7a8d6cc0eadf15e4a55022146403d9,04 Sep 1996,"make fqdncache more like ipcache
	- new parsebuffer()
	- use ->expires instead of ->ttl",308,data/crawl/squid/hunk_7604.cpp,,,data/crawl/squid/old_hunk_7604.cpp,data/crawl/squid/new_hunk_7604.cpp,-1,64,,"fatal_dump(""Invalid dnsserver output"");","[""addLog""]","[[], [""fatal_dump"", ""Invalid"", ""dnsserver"", ""output""]]",[-29917273278847675787],6831,5040.0,2
https://github.com/squid-cache/squid/commit/e84703adde7a8d6cc0eadf15e4a55022146403d9,04 Sep 1996,"make fqdncache more like ipcache
	- new parsebuffer()
	- use ->expires instead of ->ttl",308,data/crawl/squid/hunk_7604.cpp,,,data/crawl/squid/old_hunk_7604.cpp,data/crawl/squid/new_hunk_7604.cpp,-1,61,,"fatal_dump(""Invalid $ttl"");","[""addLog""]","[[], [""fatal_dump"", ""Invalid"", ""ttl""]]",[-18337828980884710258],6830,5040.0,2
https://github.com/squid-cache/squid/commit/e84703adde7a8d6cc0eadf15e4a55022146403d9,04 Sep 1996,"make fqdncache more like ipcache
	- new parsebuffer()
	- use ->expires instead of ->ttl",308,data/crawl/squid/hunk_7604.cpp,,,data/crawl/squid/old_hunk_7604.cpp,data/crawl/squid/new_hunk_7604.cpp,-1,57,,"fatal_dump(""Invalid alias"");","[""addLog""]","[[], [""fatal_dump"", ""Invalid"", ""alias""]]",[-14133335461660142488],6829,5040.0,2
https://github.com/squid-cache/squid/commit/e84703adde7a8d6cc0eadf15e4a55022146403d9,04 Sep 1996,"make fqdncache more like ipcache
	- new parsebuffer()
	- use ->expires instead of ->ttl",308,data/crawl/squid/hunk_7604.cpp,,,data/crawl/squid/old_hunk_7604.cpp,data/crawl/squid/new_hunk_7604.cpp,-1,53,,"fatal_dump(""Invalid $aliascount"");","[""addLog""]","[[], [""fatal_dump"", ""Invalid"", ""aliascount""]]",[-11230306074212304254],6828,5040.0,2
https://github.com/squid-cache/squid/commit/e84703adde7a8d6cc0eadf15e4a55022146403d9,04 Sep 1996,"make fqdncache more like ipcache
	- new parsebuffer()
	- use ->expires instead of ->ttl",308,data/crawl/squid/hunk_7604.cpp,,,data/crawl/squid/old_hunk_7604.cpp,data/crawl/squid/new_hunk_7604.cpp,-1,45,,"fatal_dump(""Invalid $ipcount"");","[""addLog""]","[[], [""fatal_dump"", ""Invalid"", ""ipcount""]]",[-10563348015832141258],6827,5040.0,2
https://github.com/squid-cache/squid/commit/e84703adde7a8d6cc0eadf15e4a55022146403d9,04 Sep 1996,"make fqdncache more like ipcache
	- new parsebuffer()
	- use ->expires instead of ->ttl",308,data/crawl/squid/hunk_7604.cpp,,,data/crawl/squid/old_hunk_7604.cpp,data/crawl/squid/new_hunk_7604.cpp,-1,42,,"fatal_dump(""Invalid $h_len"");","[""addLog""]","[[], [""fatal_dump"", ""Invalid"", ""h_len""]]",[-24448664448630495720],6826,5040.0,2
https://github.com/squid-cache/squid/commit/e84703adde7a8d6cc0eadf15e4a55022146403d9,04 Sep 1996,"make fqdncache more like ipcache
	- new parsebuffer()
	- use ->expires instead of ->ttl",308,data/crawl/squid/hunk_7604.cpp,,,data/crawl/squid/old_hunk_7604.cpp,data/crawl/squid/new_hunk_7604.cpp,-1,37,,"fatal_dump(""Invalid $h_name"");","[""addLog""]","[[], [""fatal_dump"", ""Invalid"", ""h_name""]]",[-13419497249733194613],6825,5040.0,2
https://github.com/squid-cache/squid/commit/e84703adde7a8d6cc0eadf15e4a55022146403d9,04 Sep 1996,"make fqdncache more like ipcache
	- new parsebuffer()
	- use ->expires instead of ->ttl",308,data/crawl/squid/hunk_7604.cpp,,,data/crawl/squid/old_hunk_7604.cpp,data/crawl/squid/new_hunk_7604.cpp,-1,33,,"fatal_dump(""Invalid $name"");","[""addLog""]","[[], [""fatal_dump"", ""Invalid"", ""name""]]",[-21009176533381759780],6824,5040.0,2
https://github.com/squid-cache/squid/commit/fddcd1e0281e2b92d67ce596a5ce45b0100e7a79,14 Sep 1996,"From:    Neil Murray <neil@aone.com.au>
        I liked the idea of changeable defaults for cachemgr.cgi but thought
something that I could bookmark so that getting to a number of different
proxies was a bookmark away.

        Below is my attempt at achieving this. I use the QUERY_STRING
environment variable to pass in the proxy host & port number as

                .../cgi-bin/cachemgr.cgi?<proxy host>:<port number>",40,data/crawl/squid/hunk_7570.cpp,,,data/crawl/squid/old_hunk_7570.cpp,data/crawl/squid/new_hunk_7570.cpp,3,3,"printf(""<BODY><FORM METHOD=\""POST\"" ACTION=\""%s\"">\n"", script_name);","printf(""<BODY><FORM METHOD=\""POST\"" ACTION=\""%s?%s:%d\"">\n"",
	script_name, query_host, query_port);","[""addVariable""]","[[""%s\\""], [""%s"", ""%s"", ""%d\\"", ""query_host"", ""query_port""]]",[1048538202904477678],6823,0.0,2
https://github.com/squid-cache/squid/commit/f7d9a2ad2e0f5a75c6ec42b13c5c3ac96214beef,07 Oct 1996,"From:    Markus Gyger <mgyger@itr.ch>
OK, I couldn't resist to make some changes in cachemgr.c:

    - URLs like .../cgi-bin/cachemgr?proxy.w3.org:3128 should now work
    - .../cgi-bin/cachemgr?host=proxy&port=3128&url=http://www.x.org/&operation=
refresh
      works like a POST request (parameters may be omitted)
    - removed ""Current"" item in operation selection;
      previous selection is remembered
    - added ""Empty Form"" entry in selection",352,data/crawl/squid/hunk_7500.cpp,,,data/crawl/squid/old_hunk_7500.cpp,data/crawl/squid/new_hunk_7500.cpp,41,53,"printf(""<OPTION VALUE=\""stats/redirector\"">Redirector Statistics\n"");","print_option(op, STATS_R);","[""updateLog"", ""removeContent"", ""addVariable""]","[[""printf"", ""OPTION"", ""VALUE"", ""\\"", ""stats/redirector\\"", ""Redirector"", ""Statistics\\n""], [""print_option"", ""op"", ""STATS_R""]]",[-90683033449648112],6822,0.0,2
https://github.com/squid-cache/squid/commit/f7d9a2ad2e0f5a75c6ec42b13c5c3ac96214beef,07 Oct 1996,"From:    Markus Gyger <mgyger@itr.ch>
OK, I couldn't resist to make some changes in cachemgr.c:

    - URLs like .../cgi-bin/cachemgr?proxy.w3.org:3128 should now work
    - .../cgi-bin/cachemgr?host=proxy&port=3128&url=http://www.x.org/&operation=
refresh
      works like a POST request (parameters may be omitted)
    - removed ""Current"" item in operation selection;
      previous selection is remembered
    - added ""Empty Form"" entry in selection",352,data/crawl/squid/hunk_7500.cpp,,,data/crawl/squid/old_hunk_7500.cpp,data/crawl/squid/new_hunk_7500.cpp,40,52,"printf(""<OPTION VALUE=\""stats/dns\"">DNS Server Statistics\n"");","print_option(op, STATS_D);","[""updateLog"", ""removeContent"", ""addVariable""]","[[""printf"", ""OPTION"", ""VALUE"", ""\\"", ""stats/dns\\"", ""DNS"", ""Server"", ""Statistics\\n""], [""print_option"", ""op"", ""STATS_D""]]",[-8960997079493189923],6821,0.0,2
https://github.com/squid-cache/squid/commit/f7d9a2ad2e0f5a75c6ec42b13c5c3ac96214beef,07 Oct 1996,"From:    Markus Gyger <mgyger@itr.ch>
OK, I couldn't resist to make some changes in cachemgr.c:

    - URLs like .../cgi-bin/cachemgr?proxy.w3.org:3128 should now work
    - .../cgi-bin/cachemgr?host=proxy&port=3128&url=http://www.x.org/&operation=
refresh
      works like a POST request (parameters may be omitted)
    - removed ""Current"" item in operation selection;
      previous selection is remembered
    - added ""Empty Form"" entry in selection",352,data/crawl/squid/hunk_7500.cpp,,,data/crawl/squid/old_hunk_7500.cpp,data/crawl/squid/new_hunk_7500.cpp,39,51,"printf(""<OPTION VALUE=\""stats/fqdncache\"">FQDN Cache Contents\n"");","print_option(op, STATS_F);","[""updateLog"", ""removeContent"", ""addVariable""]","[[""printf"", ""OPTION"", ""VALUE"", ""\\"", ""stats/fqdncache\\"", ""FQDN"", ""Cache"", ""Contents\\n""], [""print_option"", ""op"", ""STATS_F""]]",[2853397224556786535],6820,0.0,2
https://github.com/squid-cache/squid/commit/f7d9a2ad2e0f5a75c6ec42b13c5c3ac96214beef,07 Oct 1996,"From:    Markus Gyger <mgyger@itr.ch>
OK, I couldn't resist to make some changes in cachemgr.c:

    - URLs like .../cgi-bin/cachemgr?proxy.w3.org:3128 should now work
    - .../cgi-bin/cachemgr?host=proxy&port=3128&url=http://www.x.org/&operation=
refresh
      works like a POST request (parameters may be omitted)
    - removed ""Current"" item in operation selection;
      previous selection is remembered
    - added ""Empty Form"" entry in selection",352,data/crawl/squid/hunk_7500.cpp,,,data/crawl/squid/old_hunk_7500.cpp,data/crawl/squid/new_hunk_7500.cpp,38,50,"printf(""<OPTION VALUE=\""stats/ipcache\"">IP Cache Contents\n"");","print_option(op, STATS_I);","[""updateLog"", ""removeContent"", ""addVariable""]","[[""printf"", ""OPTION"", ""VALUE"", ""\\"", ""stats/ipcache\\"", ""IP"", ""Cache"", ""Contents\\n""], [""print_option"", ""op"", ""STATS_I""]]",[632831879309844688],6819,0.0,2
https://github.com/squid-cache/squid/commit/f7d9a2ad2e0f5a75c6ec42b13c5c3ac96214beef,07 Oct 1996,"From:    Markus Gyger <mgyger@itr.ch>
OK, I couldn't resist to make some changes in cachemgr.c:

    - URLs like .../cgi-bin/cachemgr?proxy.w3.org:3128 should now work
    - .../cgi-bin/cachemgr?host=proxy&port=3128&url=http://www.x.org/&operation=
refresh
      works like a POST request (parameters may be omitted)
    - removed ""Current"" item in operation selection;
      previous selection is remembered
    - added ""Empty Form"" entry in selection",352,data/crawl/squid/hunk_7500.cpp,,,data/crawl/squid/old_hunk_7500.cpp,data/crawl/squid/new_hunk_7500.cpp,37,49,"printf(""<OPTION VALUE=\""server_list\"">Cache Server List\n"");","print_option(op, SERVER);","[""updateLog"", ""removeContent"", ""addVariable""]","[[""printf"", ""OPTION"", ""VALUE"", ""\\"", ""server_list\\"", ""Cache"", ""Server"", ""List\\n""], [""print_option"", ""op"", ""SERVER""]]",[10511872350889121404],6818,0.0,2
https://github.com/squid-cache/squid/commit/f7d9a2ad2e0f5a75c6ec42b13c5c3ac96214beef,07 Oct 1996,"From:    Markus Gyger <mgyger@itr.ch>
OK, I couldn't resist to make some changes in cachemgr.c:

    - URLs like .../cgi-bin/cachemgr?proxy.w3.org:3128 should now work
    - .../cgi-bin/cachemgr?host=proxy&port=3128&url=http://www.x.org/&operation=
refresh
      works like a POST request (parameters may be omitted)
    - removed ""Current"" item in operation selection;
      previous selection is remembered
    - added ""Empty Form"" entry in selection",352,data/crawl/squid/hunk_7500.cpp,,,data/crawl/squid/old_hunk_7500.cpp,data/crawl/squid/new_hunk_7500.cpp,36,48,"printf(""<OPTION VALUE=\""stats/vm_objects\"">VM_Objects\n"");","print_option(op, STATS_VM);","[""updateLog"", ""removeContent"", ""addVariable""]","[[""printf"", ""OPTION"", ""VALUE"", ""\\"", ""stats/vm_objects\\"", ""VM_Objects\\n""], [""print_option"", ""op"", ""STATS_VM""]]",[9665445805269658591],6817,0.0,2
https://github.com/squid-cache/squid/commit/f7d9a2ad2e0f5a75c6ec42b13c5c3ac96214beef,07 Oct 1996,"From:    Markus Gyger <mgyger@itr.ch>
OK, I couldn't resist to make some changes in cachemgr.c:

    - URLs like .../cgi-bin/cachemgr?proxy.w3.org:3128 should now work
    - .../cgi-bin/cachemgr?host=proxy&port=3128&url=http://www.x.org/&operation=
refresh
      works like a POST request (parameters may be omitted)
    - removed ""Current"" item in operation selection;
      previous selection is remembered
    - added ""Empty Form"" entry in selection",352,data/crawl/squid/hunk_7500.cpp,,,data/crawl/squid/old_hunk_7500.cpp,data/crawl/squid/new_hunk_7500.cpp,35,47,"printf(""<OPTION VALUE=\""stats/objects\"">Objects\n"");","print_option(op, STATS_O);","[""updateLog"", ""removeContent"", ""addVariable""]","[[""printf"", ""OPTION"", ""VALUE"", ""\\"", ""stats/objects\\"", ""Objects\\n""], [""print_option"", ""op"", ""STATS_O""]]",[-16239782748446456142],6816,0.0,2
https://github.com/squid-cache/squid/commit/f7d9a2ad2e0f5a75c6ec42b13c5c3ac96214beef,07 Oct 1996,"From:    Markus Gyger <mgyger@itr.ch>
OK, I couldn't resist to make some changes in cachemgr.c:

    - URLs like .../cgi-bin/cachemgr?proxy.w3.org:3128 should now work
    - .../cgi-bin/cachemgr?host=proxy&port=3128&url=http://www.x.org/&operation=
refresh
      works like a POST request (parameters may be omitted)
    - removed ""Current"" item in operation selection;
      previous selection is remembered
    - added ""Empty Form"" entry in selection",352,data/crawl/squid/hunk_7500.cpp,,,data/crawl/squid/old_hunk_7500.cpp,data/crawl/squid/new_hunk_7500.cpp,34,46,"printf(""<OPTION VALUE=\""stats/filedescriptors\"">Filedescriptor Usage\n"");","print_option(op, STATS_FDS);","[""updateLog"", ""removeContent"", ""addVariable""]","[[""printf"", ""OPTION"", ""VALUE"", ""\\"", ""stats/filedescriptors\\"", ""Filedescriptor"", ""Usage\\n""], [""print_option"", ""op"", ""STATS_FDS""]]",[3070119916795852726],6815,0.0,2
https://github.com/squid-cache/squid/commit/f7d9a2ad2e0f5a75c6ec42b13c5c3ac96214beef,07 Oct 1996,"From:    Markus Gyger <mgyger@itr.ch>
OK, I couldn't resist to make some changes in cachemgr.c:

    - URLs like .../cgi-bin/cachemgr?proxy.w3.org:3128 should now work
    - .../cgi-bin/cachemgr?host=proxy&port=3128&url=http://www.x.org/&operation=
refresh
      works like a POST request (parameters may be omitted)
    - removed ""Current"" item in operation selection;
      previous selection is remembered
    - added ""Empty Form"" entry in selection",352,data/crawl/squid/hunk_7500.cpp,,,data/crawl/squid/old_hunk_7500.cpp,data/crawl/squid/new_hunk_7500.cpp,33,45,"printf(""<OPTION VALUE=\""stats/reply_headers\"">HTTP Reply Headers\n"");","print_option(op, STATS_HDRS);","[""updateLog"", ""removeContent"", ""addVariable""]","[[""printf"", ""OPTION"", ""VALUE"", ""\\"", ""stats/reply_headers\\"", ""HTTP"", ""Reply"", ""Headers\\n""], [""print_option"", ""op"", ""STATS_HDRS""]]",[-3933167973364664597],6814,0.0,2
https://github.com/squid-cache/squid/commit/f7d9a2ad2e0f5a75c6ec42b13c5c3ac96214beef,07 Oct 1996,"From:    Markus Gyger <mgyger@itr.ch>
OK, I couldn't resist to make some changes in cachemgr.c:

    - URLs like .../cgi-bin/cachemgr?proxy.w3.org:3128 should now work
    - .../cgi-bin/cachemgr?host=proxy&port=3128&url=http://www.x.org/&operation=
refresh
      works like a POST request (parameters may be omitted)
    - removed ""Current"" item in operation selection;
      previous selection is remembered
    - added ""Empty Form"" entry in selection",352,data/crawl/squid/hunk_7500.cpp,,,data/crawl/squid/old_hunk_7500.cpp,data/crawl/squid/new_hunk_7500.cpp,32,44,"printf(""<OPTION VALUE=\""stats/io\"">I/O\n"");","print_option(op, STATS_IO);","[""updateLog"", ""removeContent"", ""addVariable""]","[[""printf"", ""OPTION"", ""VALUE"", ""\\"", ""stats/io\\"", ""I/O\\n""], [""print_option"", ""op"", ""STATS_IO""]]",[6046403672980567070],6813,0.0,2
https://github.com/squid-cache/squid/commit/f7d9a2ad2e0f5a75c6ec42b13c5c3ac96214beef,07 Oct 1996,"From:    Markus Gyger <mgyger@itr.ch>
OK, I couldn't resist to make some changes in cachemgr.c:

    - URLs like .../cgi-bin/cachemgr?proxy.w3.org:3128 should now work
    - .../cgi-bin/cachemgr?host=proxy&port=3128&url=http://www.x.org/&operation=
refresh
      works like a POST request (parameters may be omitted)
    - removed ""Current"" item in operation selection;
      previous selection is remembered
    - added ""Empty Form"" entry in selection",352,data/crawl/squid/hunk_7500.cpp,,,data/crawl/squid/old_hunk_7500.cpp,data/crawl/squid/new_hunk_7500.cpp,31,43,"printf(""<OPTION VALUE=\""stats/utilization\"">Utilization\n"");","print_option(op, STATS_U);","[""updateLog"", ""removeContent"", ""addVariable""]","[[""printf"", ""OPTION"", ""VALUE"", ""\\"", ""stats/utilization\\"", ""Utilization\\n""], [""print_option"", ""op"", ""STATS_U""]]",[-12308058500309744580],6812,0.0,2
https://github.com/squid-cache/squid/commit/f7d9a2ad2e0f5a75c6ec42b13c5c3ac96214beef,07 Oct 1996,"From:    Markus Gyger <mgyger@itr.ch>
OK, I couldn't resist to make some changes in cachemgr.c:

    - URLs like .../cgi-bin/cachemgr?proxy.w3.org:3128 should now work
    - .../cgi-bin/cachemgr?host=proxy&port=3128&url=http://www.x.org/&operation=
refresh
      works like a POST request (parameters may be omitted)
    - removed ""Current"" item in operation selection;
      previous selection is remembered
    - added ""Empty Form"" entry in selection",352,data/crawl/squid/hunk_7500.cpp,,,data/crawl/squid/old_hunk_7500.cpp,data/crawl/squid/new_hunk_7500.cpp,29,41,"printf(""<OPTION VALUE=\""log\"">Cache Log\n"");","print_option(op, LOG);","[""updateLog"", ""removeContent"", ""addVariable""]","[[""printf"", ""OPTION"", ""VALUE"", ""\\"", ""log\\"", ""Cache"", ""Log\\n""], [""print_option"", ""op"", ""LOG""]]",[11854443745543060334],6811,0.0,2
https://github.com/squid-cache/squid/commit/f7d9a2ad2e0f5a75c6ec42b13c5c3ac96214beef,07 Oct 1996,"From:    Markus Gyger <mgyger@itr.ch>
OK, I couldn't resist to make some changes in cachemgr.c:

    - URLs like .../cgi-bin/cachemgr?proxy.w3.org:3128 should now work
    - .../cgi-bin/cachemgr?host=proxy&port=3128&url=http://www.x.org/&operation=
refresh
      works like a POST request (parameters may be omitted)
    - removed ""Current"" item in operation selection;
      previous selection is remembered
    - added ""Empty Form"" entry in selection",352,data/crawl/squid/hunk_7500.cpp,,,data/crawl/squid/old_hunk_7500.cpp,data/crawl/squid/new_hunk_7500.cpp,27,39,"printf(""<OPTION VALUE=\""parameter\"">Cache Parameters\n"");","print_option(op, PARAM);","[""updateLog"", ""removeContent"", ""addVariable""]","[[""printf"", ""OPTION"", ""VALUE"", ""\\"", ""parameter\\"", ""Cache"", ""Parameters\\n""], [""print_option"", ""op"", ""PARAM""]]",[-1326724882331020529],6810,0.0,2
https://github.com/squid-cache/squid/commit/f7d9a2ad2e0f5a75c6ec42b13c5c3ac96214beef,07 Oct 1996,"From:    Markus Gyger <mgyger@itr.ch>
OK, I couldn't resist to make some changes in cachemgr.c:

    - URLs like .../cgi-bin/cachemgr?proxy.w3.org:3128 should now work
    - .../cgi-bin/cachemgr?host=proxy&port=3128&url=http://www.x.org/&operation=
refresh
      works like a POST request (parameters may be omitted)
    - removed ""Current"" item in operation selection;
      previous selection is remembered
    - added ""Empty Form"" entry in selection",352,data/crawl/squid/hunk_7500.cpp,,,data/crawl/squid/old_hunk_7500.cpp,data/crawl/squid/new_hunk_7500.cpp,26,38,"printf(""<OPTION VALUE=\""squid.conf\"">Cache Configuration File\n"");","print_option(op, CACHED);","[""updateLog"", ""removeContent"", ""addVariable""]","[[""printf"", ""OPTION"", ""VALUE"", ""\\"", ""squid"", ""conf\\"", ""Cache"", ""Configuration"", ""File\\n""], [""print_option"", ""op"", ""CACHED""]]",[-2243033154644659567],6809,0.0,2
https://github.com/squid-cache/squid/commit/f7d9a2ad2e0f5a75c6ec42b13c5c3ac96214beef,07 Oct 1996,"From:    Markus Gyger <mgyger@itr.ch>
OK, I couldn't resist to make some changes in cachemgr.c:

    - URLs like .../cgi-bin/cachemgr?proxy.w3.org:3128 should now work
    - .../cgi-bin/cachemgr?host=proxy&port=3128&url=http://www.x.org/&operation=
refresh
      works like a POST request (parameters may be omitted)
    - removed ""Current"" item in operation selection;
      previous selection is remembered
    - added ""Empty Form"" entry in selection",352,data/crawl/squid/hunk_7500.cpp,,,data/crawl/squid/old_hunk_7500.cpp,data/crawl/squid/new_hunk_7500.cpp,18,30,"printf(""SIZE=30 VALUE=\""%d\""><BR>\n"", CACHE_HTTP_PORT);","printf(""SIZE=30 VALUE=\""%d\""><BR>\n"", port);","[""updateVariable""]","[[""CACHE_HTTP_PORT""], [""port""]]",[8839386030983199447],6808,16560.0,2
https://github.com/squid-cache/squid/commit/f7d9a2ad2e0f5a75c6ec42b13c5c3ac96214beef,07 Oct 1996,"From:    Markus Gyger <mgyger@itr.ch>
OK, I couldn't resist to make some changes in cachemgr.c:

    - URLs like .../cgi-bin/cachemgr?proxy.w3.org:3128 should now work
    - .../cgi-bin/cachemgr?host=proxy&port=3128&url=http://www.x.org/&operation=
refresh
      works like a POST request (parameters may be omitted)
    - removed ""Current"" item in operation selection;
      previous selection is remembered
    - added ""Empty Form"" entry in selection",352,data/crawl/squid/hunk_7500.cpp,,,data/crawl/squid/old_hunk_7500.cpp,data/crawl/squid/new_hunk_7500.cpp,16,28,"printf(""SIZE=30 VALUE=\""%s\""><BR>\n"", CACHEMGR_HOSTNAME);","printf(""SIZE=30 VALUE=\""%s\""><BR>\n"", host);","[""updateVariable""]","[[""CACHEMGR_HOSTNAME""], [""host""]]",[9862897625793279785],6807,16560.0,2
https://github.com/squid-cache/squid/commit/e97f40f4c3e673d5cbc1cd382a4b0c3044810c45,15 Oct 1996,rearrange USE_ICMP defines,451,data/crawl/squid/hunk_7476.cpp,,,data/crawl/squid/old_hunk_7476.cpp,data/crawl/squid/new_hunk_7476.cpp,-1,54,,"storeAppendPrintf(sentry, "" %s"", x->name);","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""%s"", ""x"", ""name""]]",[1906972441691148998],6806,18000.0,2
https://github.com/squid-cache/squid/commit/e97f40f4c3e673d5cbc1cd382a4b0c3044810c45,15 Oct 1996,rearrange USE_ICMP defines,451,data/crawl/squid/hunk_7476.cpp,,,data/crawl/squid/old_hunk_7476.cpp,data/crawl/squid/new_hunk_7476.cpp,-1,30,,"storeAppendPrintf(sentry, ""{Network DB Statistics:\n"");","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""Network"", ""DB"", ""Statistics"", ""\\n""]]",[809246232247150102],6805,18000.0,2
https://github.com/squid-cache/squid/commit/e97f40f4c3e673d5cbc1cd382a4b0c3044810c45,15 Oct 1996,rearrange USE_ICMP defines,451,data/crawl/squid/hunk_7473.cpp,,,data/crawl/squid/old_hunk_7473.cpp,data/crawl/squid/new_hunk_7473.cpp,41,-1,fatal_dump(xstrerror());,,"[""removeLog""]","[[""fatal_dump"", ""xstrerror""], []]",[6060328181111983635],6804,0.0,2
https://github.com/squid-cache/squid/commit/0ee4272be86c64bd8eedf6f662f63f61f8203e13,05 Nov 1996,massive const patch from Markus Gyger,1167,data/crawl/squid/hunk_7446.cpp,,,data/crawl/squid/old_hunk_7446.cpp,data/crawl/squid/new_hunk_7446.cpp,-1,4,,"storeAppendPrintf(sentry, ""{%-16.16s %9s %7s %5s %s}\n"",
	""Network"",
	""recv/sent"",
	""RTT"",
	""Hops"",
	""Hostnames"");","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""%"", ""16"", ""16s"", ""%9s"", ""%7s"", ""%5s"", ""%s"", ""\\n"", ""Network"", ""recv/sent"", ""RTT"", ""Hops"", ""Hostnames""]]",[-13068287709989147905],6803,15120.0,2
https://github.com/squid-cache/squid/commit/1fe4a4e1d88f097f1cfee23610fbed97b8fa1931,14 Jan 1997,fix ru.ru_maxrss in various ways,20,data/crawl/squid/hunk_7409.cpp,,,data/crawl/squid/old_hunk_7409.cpp,data/crawl/squid/new_hunk_7409.cpp,4,4,"fprintf(lf, ""Memory Usage: rss %ld KB\n"", rusage.ru_maxrss);","fprintf(lf, ""Maximum Resident Size: %ld KB\n"", rusage.ru_maxrss);","[""updateContent""]","[[""Memory"", ""Usage"", ""rss""], [""Maximum"", ""Resident"", ""Size""]]",[3900651794928102726],6802,0.0,2
https://github.com/squid-cache/squid/commit/1fe4a4e1d88f097f1cfee23610fbed97b8fa1931,14 Jan 1997,fix ru.ru_maxrss in various ways,20,data/crawl/squid/hunk_7408.cpp,,,data/crawl/squid/old_hunk_7408.cpp,data/crawl/squid/new_hunk_7408.cpp,4,4,"storeAppendPrintf(sentry, ""{\tProcess Size: rss %ld KB}\n"",
	rusage.ru_maxrss);","storeAppendPrintf(sentry, ""{\tMaximum Resident Size: %ld KB}\n"",
	rusage.ru_maxrss);","[""updateContent""]","[[""\\tProcess"", ""rss""], [""\\tMaximum"", ""Resident""]]",[140024472440747910],6801,0.0,2
https://github.com/squid-cache/squid/commit/429fdbecbf36ca7f145bc760181a892136c54445,28 Apr 1997,merge 1.1.8->1.1.10; just get it to compile,2206,data/crawl/squid/hunk_7311.cpp,,,data/crawl/squid/old_hunk_7311.cpp,data/crawl/squid/new_hunk_7311.cpp,20,20,"fatal_dump(""fqdncache_release: expected f == result!"");","fatal_dump(""fqdncache_release: f != table_entry!"");","[""updateContent""]","[[""expected"", ""result""], [""table_entry""]]",[-12437404892355442255],6800,199440.0,2
https://github.com/squid-cache/squid/commit/95d15928422453dc90b7c4d51dec52126ca4982a,30 Apr 1997,moving FD things to common fd.h,403,data/crawl/squid/hunk_7290.cpp,,,data/crawl/squid/old_hunk_7290.cpp,data/crawl/squid/new_hunk_7290.cpp,-1,6,,"fatal_dump(""comm_close: bad FD"");","[""addLog""]","[[], [""fatal_dump"", ""comm_close"", ""bad"", ""FD""]]",[-11972907313379474798],6799,0.0,2
https://github.com/squid-cache/squid/commit/3fdadc70bf49427e4830bec1560ec76f09256685,26 May 1997,mostly done inlining all FTP requsts,1679,data/crawl/squid/hunk_7234.cpp,,,data/crawl/squid/old_hunk_7234.cpp,data/crawl/squid/new_hunk_7234.cpp,-1,20,,"storeAppendPrintf(e, ""<PRE>\n"");","[""addLog""]","[[], [""storeAppendPrintf"", ""e"", ""PRE"", ""\\n""]]",[8202134892678371835],6798,0.0,2
https://github.com/squid-cache/squid/commit/3fdadc70bf49427e4830bec1560ec76f09256685,26 May 1997,mostly done inlining all FTP requsts,1679,data/crawl/squid/hunk_7234.cpp,,,data/crawl/squid/old_hunk_7234.cpp,data/crawl/squid/new_hunk_7234.cpp,-1,12,,"storeAppendPrintf(e, ""FTP Directory: %s\n"",
	ftpState->title_url);","[""addLog""]","[[], [""storeAppendPrintf"", ""e"", ""FTP"", ""Directory"", ""%s\\n"", ""ftpState"", ""title_url""]]",[8861013139451281820],6797,0.0,2
https://github.com/squid-cache/squid/commit/03eb2f0154cbf163ffe8bb4cf8c7dbf23bfdebdf,20 Jun 1997,remove some of that HTTPCacheInfo->crap,234,data/crawl/squid/hunk_7178.cpp,,,data/crawl/squid/old_hunk_7178.cpp,data/crawl/squid/new_hunk_7178.cpp,17,-1,"storeAppendPrintf(sentry, "" "");",,"[""removeLog""]","[[""storeAppendPrintf"", ""sentry""], []]",[-6068814885023758730],6796,0.0,2
https://github.com/squid-cache/squid/commit/a4394ebd753cb4b23be7aaf6a11f5a5cf833df0e,21 Jun 1997,"clean up access logging, remove lots of Cacheinfo garbage
Need to relocate enums to an enums.h file, too many other wierd
dependencies.",464,data/crawl/squid/hunk_7163.cpp,,,data/crawl/squid/old_hunk_7163.cpp,data/crawl/squid/new_hunk_7163.cpp,33,-1,"storeAppendPrintf(ctrl->sentry, close_bracket);",,"[""removeLog""]","[[""storeAppendPrintf"", ""ctrl"", ""sentry"", ""close_bracket""], []]",[-20277669353860243089],6795,0.0,2
https://github.com/squid-cache/squid/commit/270b86af848681f97dab32924f8eb092ebb64d9a,27 Jun 1997,"Max Okumoto configuration file patch.  Config goop will be generated
from a single file.  Still needs work.",1886,data/crawl/squid/hunk_7159.cpp,,,data/crawl/squid/old_hunk_7159.cpp,data/crawl/squid/new_hunk_7159.cpp,-1,486,,"printf(""%s"", var);","[""addLog""]","[[], [""printf"", ""%s"", ""var""]]",[3494803623616240301],6794,0.0,2
https://github.com/squid-cache/squid/commit/270b86af848681f97dab32924f8eb092ebb64d9a,27 Jun 1997,"Max Okumoto configuration file patch.  Config goop will be generated
from a single file.  Still needs work.",1886,data/crawl/squid/hunk_7159.cpp,,,data/crawl/squid/old_hunk_7159.cpp,data/crawl/squid/new_hunk_7159.cpp,524,-1,"printf(""WARNING: redirect_children was set to a bad value: %d\n"",
		Config.redirectChildren);",,"[""removeLog""]","[[""printf"", ""WARNING"", ""redirect_children"", ""was"", ""set"", ""to"", ""a"", ""bad"", ""value"", ""%d\\n"", ""Config"", ""redirectChildren""], []]",[3162602678448071865],6793,183600.0,2
https://github.com/squid-cache/squid/commit/270b86af848681f97dab32924f8eb092ebb64d9a,27 Jun 1997,"Max Okumoto configuration file patch.  Config goop will be generated
from a single file.  Still needs work.",1886,data/crawl/squid/hunk_7157.cpp,,,data/crawl/squid/old_hunk_7157.cpp,data/crawl/squid/new_hunk_7157.cpp,-1,85,,"printf(""Setting it to the maximum (%d).\n"", DefaultRedirectChildrenMax);","[""addLog""]","[[], [""printf"", ""Setting"", ""it"", ""to"", ""the"", ""maximum"", ""%d"", ""\\n"", ""DefaultRedirectChildrenMax""]]",[20849850010002208210],6792,252720.0,2
https://github.com/squid-cache/squid/commit/9e975e4e285472da81c0d6cffc4a55e9fb0b4483,15 Jul 1997,"- warning if no units present for times or byte sizes
- added defaults to all time_t's in cf.data.pre
- Fixed up connect callbacks to recognize COMM_DNS_ERR and !COMM_OK
- Set FTP_HTTP_HEADER_SENT for ftp
- Initialize neighbors_do_private_keys in globals.c
- Remove opt_no_ipcache
- removed redundant externs from squid.h
- changed more debug_trap's to assert's
- changed over-high-water-mark warning to only report once at
  each threshold",283,data/crawl/squid/hunk_7119.cpp,,,data/crawl/squid/old_hunk_7119.cpp,data/crawl/squid/new_hunk_7119.cpp,-1,3,,"fatal_dump(""storeGetMemSpace: Bad Entry in LRU list"");","[""addLog""]","[[], [""fatal_dump"", ""storeGetMemSpace"", ""Bad"", ""Entry"", ""in"", ""LRU"", ""list""]]",[9562399362135629917],6791,224640.0,2
https://github.com/squid-cache/squid/commit/8873879072298d87402309ab70eb85938d040624,17 Jul 1997,successful compile after merging 1.1.10 thru 1.1.14,1065,data/crawl/squid/hunk_7103.cpp,,,data/crawl/squid/old_hunk_7103.cpp,data/crawl/squid/new_hunk_7103.cpp,-1,79,,fatal_dump();,"[""addLog""]","[[], [""fatal_dump""]]",[-8713004596475217207],6790,221040.0,2
https://github.com/squid-cache/squid/commit/f53b06f967ce5bdf5b076bba55d41f8d45a3077d,25 Aug 1997,"Configuration cleanup.
	- set up 'DEFAULT_IF_NONE' option for things like http_port
	  and cache_dir where we want to set a default only if there
	  is not one or more given in the config file.
	- Implemented the configuration dump via cachemanager.  All the
	  easy config types have dump functions; the remainder are
	  unimplemented.",220,data/crawl/squid/hunk_7088.cpp,,,data/crawl/squid/old_hunk_7088.cpp,data/crawl/squid/new_hunk_7088.cpp,5,-1,"printf(""{"");",,"[""removeLog""]","[[""printf""], []]",[-7237409554864562455],6789,0.0,2
https://github.com/squid-cache/squid/commit/a95856a0e5aaaa8b7c588c6052f7dad7127974e2,25 Aug 1997,misc fixes,84,data/crawl/squid/hunk_7052.cpp,,,data/crawl/squid/old_hunk_7052.cpp,data/crawl/squid/new_hunk_7052.cpp,-1,4,,"fatal(""No cache_dir's specified in config file"");","[""addLog""]","[[], [""fatal"", ""No"", ""cache_dir"", ""s"", ""specified"", ""in"", ""config"", ""file""]]",[-5002055989006717529],6788,107280.0,2
https://github.com/squid-cache/squid/commit/79d39a72a5cc1eb6da806eddab662fed74ab6efe,05 Nov 1997,LINT,332,data/crawl/squid/hunk_6992.cpp,,,data/crawl/squid/old_hunk_6992.cpp,data/crawl/squid/new_hunk_6992.cpp,6,7,fatal_dump(NULL);,assert(e1 != NULL && e2 != NULL);,"[""updateLog"", ""addVariable""]","[[""fatal_dump""], [""assert"", ""e1"", ""&&"", ""e2"", ""NULL""]]",[10865151936969747635],6787,0.0,2
https://github.com/squid-cache/squid/commit/f0b1933488ce1ce1e84f6497331a6beaf8543cb5,13 Nov 1997,"Ron Gomes fixes.
	- Remove USE_PROXY_AUTH and LOG_FULL_HEADERS from Makefile.in
	- Fixed log_full_hdrs bug
We can't use pathname_stat() for both default_all() and parsing the
config file.  We must check the pathnames only after both the
defaults and the config file have been parsed.  DW also made misc
other fixes to cache_cf.c and friends.",133,data/crawl/squid/hunk_6986.cpp,,,data/crawl/squid/old_hunk_6986.cpp,data/crawl/squid/new_hunk_6986.cpp,20,-1,"printf(""WARNING: dnsservers are disabled!\n"");",,"[""removeLog""]","[[""printf"", ""WARNING"", ""dnsservers"", ""are"", ""disabled"", ""\\n""], []]",[-8898563971015925156],6786,100080.0,2
https://github.com/squid-cache/squid/commit/f0b1933488ce1ce1e84f6497331a6beaf8543cb5,13 Nov 1997,"Ron Gomes fixes.
	- Remove USE_PROXY_AUTH and LOG_FULL_HEADERS from Makefile.in
	- Fixed log_full_hdrs bug
We can't use pathname_stat() for both default_all() and parsing the
config file.  We must check the pathnames only after both the
defaults and the config file have been parsed.  DW also made misc
other fixes to cache_cf.c and friends.",133,data/crawl/squid/hunk_6986.cpp,,,data/crawl/squid/old_hunk_6986.cpp,data/crawl/squid/new_hunk_6986.cpp,8,-1,"printf(""WARNING: cache_swap (%d kbytes) is less than cache_mem (%d bytes).\n"", Config.Swap.maxSize, Config.Mem.maxSize);",,"[""removeLog""]","[[""printf"", ""WARNING"", ""cache_swap"", ""%d"", ""kbytes"", ""is"", ""less"", ""than"", ""cache_mem"", ""%d"", ""bytes"", ""\\n"", ""Config"", ""Swap"", ""maxSize"", ""Config"", ""Mem"", ""maxSize""], []]",[-2620933435431787524],6785,100080.0,2
https://github.com/squid-cache/squid/commit/ce66013b40dad272f568df241b6f1fb238cec97f,13 Nov 1997,remove fatal_dump calls,59,data/crawl/squid/hunk_6977.cpp,,,data/crawl/squid/old_hunk_6977.cpp,data/crawl/squid/new_hunk_6977.cpp,4,-1,"fatal_dump(""sslStateFree: FD mismatch!\n"");",,"[""removeLog""]","[[""fatal_dump"", ""sslStateFree"", ""FD"", ""mismatch"", ""\\n""], []]",[6575889428949358056],6784,0.0,2
https://github.com/squid-cache/squid/commit/627f6d02e9baad40c38bd35ef893fc6bc9a22ca1,21 Nov 1997,"SNMP, cmu derived, heavily modified",5272,data/crawl/squid/hunk_6958.cpp,,,data/crawl/squid/old_hunk_6958.cpp,data/crawl/squid/new_hunk_6958.cpp,-1,850,,"fprintf(stderr, ""Out of memory!\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""Out"", ""of"", ""memory"", ""\\n""]]",[-2829632968305792191],6783,0.0,2
https://github.com/squid-cache/squid/commit/627f6d02e9baad40c38bd35ef893fc6bc9a22ca1,21 Nov 1997,"SNMP, cmu derived, heavily modified",5272,data/crawl/squid/hunk_6958.cpp,,,data/crawl/squid/old_hunk_6958.cpp,data/crawl/squid/new_hunk_6958.cpp,-1,828,,"fprintf(stderr, ""Error building packet\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""Error"", ""building"", ""packet\\n""]]",[-5499772573560979573],6782,0.0,2
https://github.com/squid-cache/squid/commit/627f6d02e9baad40c38bd35ef893fc6bc9a22ca1,21 Nov 1997,"SNMP, cmu derived, heavily modified",5272,data/crawl/squid/hunk_6957.cpp,,,data/crawl/squid/old_hunk_6957.cpp,data/crawl/squid/new_hunk_6957.cpp,-1,1542,,"print_error(""Bad parse of module identity"", (char *)NULL,
				type);","[""addLog""]","[[], [""print_error"", ""Bad"", ""parse"", ""of"", ""module"", ""identity"", ""char"", ""*"", ""NULL"", ""type""]]",[7997078272424875002],6781,0.0,2
https://github.com/squid-cache/squid/commit/627f6d02e9baad40c38bd35ef893fc6bc9a22ca1,21 Nov 1997,"SNMP, cmu derived, heavily modified",5272,data/crawl/squid/hunk_6957.cpp,,,data/crawl/squid/old_hunk_6957.cpp,data/crawl/squid/new_hunk_6957.cpp,-1,1522,,"print_error(""Bad parse of module compliance"", (char *)NULL,
				type);","[""addLog""]","[[], [""print_error"", ""Bad"", ""parse"", ""of"", ""module"", ""compliance"", ""char"", ""*"", ""NULL"", ""type""]]",[-4890720600463276281],6780,0.0,2
https://github.com/squid-cache/squid/commit/627f6d02e9baad40c38bd35ef893fc6bc9a22ca1,21 Nov 1997,"SNMP, cmu derived, heavily modified",5272,data/crawl/squid/hunk_6957.cpp,,,data/crawl/squid/old_hunk_6957.cpp,data/crawl/squid/new_hunk_6957.cpp,-1,1502,,"print_error(""Bad parse of notification definition"",
				(char *)NULL, type);","[""addLog""]","[[], [""print_error"", ""Bad"", ""parse"", ""of"", ""notification"", ""definition"", ""char"", ""*"", ""NULL"", ""type""]]",[4323801684523373336],6779,0.0,2
https://github.com/squid-cache/squid/commit/627f6d02e9baad40c38bd35ef893fc6bc9a22ca1,21 Nov 1997,"SNMP, cmu derived, heavily modified",5272,data/crawl/squid/hunk_6957.cpp,,,data/crawl/squid/old_hunk_6957.cpp,data/crawl/squid/new_hunk_6957.cpp,-1,1462,,"print_error(""Bad parse of object type"", (char *)NULL,
				type);","[""addLog""]","[[], [""print_error"", ""Bad"", ""parse"", ""of"", ""object"", ""type"", ""char"", ""*"", ""NULL"", ""type""]]",[1341106843915763349],6778,0.0,2
https://github.com/squid-cache/squid/commit/627f6d02e9baad40c38bd35ef893fc6bc9a22ca1,21 Nov 1997,"SNMP, cmu derived, heavily modified",5272,data/crawl/squid/hunk_6957.cpp,,,data/crawl/squid/old_hunk_6957.cpp,data/crawl/squid/new_hunk_6957.cpp,-1,1021,,"print_error(""Bad syntax"", token, type);","[""addLog""]","[[], [""print_error"", ""Bad"", ""syntax"", ""token"", ""type""]]",[17848780491021707584],6777,0.0,2
https://github.com/squid-cache/squid/commit/627f6d02e9baad40c38bd35ef893fc6bc9a22ca1,21 Nov 1997,"SNMP, cmu derived, heavily modified",5272,data/crawl/squid/hunk_6957.cpp,,,data/crawl/squid/old_hunk_6957.cpp,data/crawl/squid/new_hunk_6957.cpp,-1,633,,"print_error(""Bad format"", token, type);","[""addLog""]","[[], [""print_error"", ""Bad"", ""format"", ""token"", ""type""]]",[17693141389288487800],6776,0.0,2
https://github.com/squid-cache/squid/commit/627f6d02e9baad40c38bd35ef893fc6bc9a22ca1,21 Nov 1997,"SNMP, cmu derived, heavily modified",5272,data/crawl/squid/hunk_6956.cpp,,,data/crawl/squid/old_hunk_6956.cpp,data/crawl/squid/new_hunk_6956.cpp,-1,784,,"fprintf(stderr, ""Mib not initialized.  Exiting.\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""Mib"", ""not"", ""initialized"", ""Exiting"", ""\\n""]]",[2000251782537818125],6775,0.0,2
https://github.com/squid-cache/squid/commit/627f6d02e9baad40c38bd35ef893fc6bc9a22ca1,21 Nov 1997,"SNMP, cmu derived, heavily modified",5272,data/crawl/squid/hunk_6956.cpp,,,data/crawl/squid/old_hunk_6956.cpp,data/crawl/squid/new_hunk_6956.cpp,-1,146,,"fprintf(stderr, ""sub-identifier too large: %s\n"", buf);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""sub"", ""identifier"", ""too"", ""large"", ""%s\\n"", ""buf""]]",[-8920168857096952611],6774,0.0,2
https://github.com/squid-cache/squid/commit/15df8349237e9eef90b030838021ad89712bf8ea,23 Nov 1997,"Move *ConnectionOpen() functionality to client_side.c and icp_v2.c.
trying to make it so HUP doesn't require closing all the connections",205,data/crawl/squid/hunk_6917.cpp,,,data/crawl/squid/old_hunk_6917.cpp,data/crawl/squid/new_hunk_6917.cpp,-1,46,,"fatal(""Cannot open Outgoing ICP Port"");","[""addLog""]","[[], [""fatal"", ""Cannot"", ""open"", ""Outgoing"", ""ICP"", ""Port""]]",[-5533911984522645564],6773,361440.0,2
https://github.com/squid-cache/squid/commit/eb5f55b356bb195e1469c6638502a997eca33a91,25 Nov 1997,adding,397,data/crawl/squid/hunk_6910.cpp,,,data/crawl/squid/old_hunk_6910.cpp,data/crawl/squid/new_hunk_6910.cpp,-1,359,,"fprintf(stderr, ""usage: %s: -p port -h host -n max\n"", progname);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""usage"", ""%s"", ""p"", ""port"", ""h"", ""host"", ""n"", ""max\\n"", ""progname""]]",[-4251147104453689710],6772,30240.0,2
https://github.com/squid-cache/squid/commit/eb5f55b356bb195e1469c6638502a997eca33a91,25 Nov 1997,adding,397,data/crawl/squid/hunk_6910.cpp,,,data/crawl/squid/old_hunk_6910.cpp,data/crawl/squid/new_hunk_6910.cpp,-1,327,,"printf(""Done Reading URLS\n"");","[""addLog""]","[[], [""printf"", ""Done"", ""Reading"", ""URLS\\n""]]",[-13343316361656720164],6771,30240.0,2
https://github.com/squid-cache/squid/commit/eb5f55b356bb195e1469c6638502a997eca33a91,25 Nov 1997,adding,397,data/crawl/squid/hunk_6910.cpp,,,data/crawl/squid/old_hunk_6910.cpp,data/crawl/squid/new_hunk_6910.cpp,-1,152,,"printf(""\rWaiting for open connections to finish...\n"");","[""addLog""]","[[], [""printf"", ""\\rWaiting"", ""for"", ""open"", ""connections"", ""to"", ""finish"", ""\\n""]]",[19301964869545538919],6770,30240.0,2
https://github.com/squid-cache/squid/commit/76f729d7a57dcc3f80997ba33acbb78d8bbd9eb0,21 Dec 1997,"Radix-tree algorithm, from NetBSD-4.4",898,data/crawl/squid/hunk_6881.cpp,,,data/crawl/squid/old_hunk_6881.cpp,data/crawl/squid/new_hunk_6881.cpp,-1,681,,"fprintf(stderr, ""rn_delete: inconsistent annotation\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""rn_delete"", ""inconsistent"", ""annotation\\n""]]",[-19893265211029631873],6769,0.0,2
https://github.com/squid-cache/squid/commit/85407535d3bcccc9fd1c0688fbb847201294a70b,06 Jan 1998,copied over v1.1 -z semantics,173,data/crawl/squid/hunk_6868.cpp,,,data/crawl/squid/old_hunk_6868.cpp,data/crawl/squid/new_hunk_6868.cpp,-1,12,,"fatal(""Don't run Squid as root, set 'cache_effective_user'!"");","[""addLog""]","[[], [""fatal"", ""Don"", ""t"", ""run"", ""Squid"", ""as"", ""root"", ""set"", ""cache_effective_user""]]",[-18336888759707698090],6768,239760.0,2
https://github.com/squid-cache/squid/commit/3f6c0fb2ca6b48600072d274f5bacd0ecb422a15,12 Jan 1998,new memory allocation for fixed-size blocks,729,data/crawl/squid/hunk_6863.cpp,,,data/crawl/squid/old_hunk_6863.cpp,data/crawl/squid/new_hunk_6863.cpp,2,2,"storeAppendPrintf(sentry, ""{\t%6d StoreEntries}\n"",
	meta_data.store_entries);","storeAppendPrintf(sentry, ""{\t%6d StoreEntries}\n"",
	memInUse(MEM_STOREENTRY));","[""removeVariable"", ""addVariable""]","[[""meta_data"", ""store_entries""], [""memInUse"", ""MEM_STOREENTRY""]]",[-3822276254173549766],6767,0.0,2
https://github.com/squid-cache/squid/commit/a7c05555fdb0ef180d8df2e68d53acc400bf2984,31 Jan 1998,"	- Combined various interprocess communication setup functions
	  into ipcCreate().
	- Removed some leftover ICP_HIT_OBJ things.
	- Removed cacheinfo and proto_count() and friends; these are to
	  be replaced in functionality by StatCounters and 5/60 minute
	  average views via cachemgr.
Changes to squid-1.2.beta11 (Jan 6, 1998):",997,data/crawl/squid/hunk_6860.cpp,,,data/crawl/squid/old_hunk_6860.cpp,data/crawl/squid/new_hunk_6860.cpp,-1,81,,"storeAppendPrintf(sentry, ""wall_time = %f seconds\n"", dt);","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""wall_time"", ""%f"", ""seconds\\n"", ""dt""]]",[1067573474463398996],6766,18720.0,2
https://github.com/squid-cache/squid/commit/a7c05555fdb0ef180d8df2e68d53acc400bf2984,31 Jan 1998,"	- Combined various interprocess communication setup functions
	  into ipcCreate().
	- Removed some leftover ICP_HIT_OBJ things.
	- Removed cacheinfo and proto_count() and friends; these are to
	  be replaced in functionality by StatCounters and 5/60 minute
	  average views via cachemgr.
Changes to squid-1.2.beta11 (Jan 6, 1998):",997,data/crawl/squid/hunk_6860.cpp,,,data/crawl/squid/old_hunk_6860.cpp,data/crawl/squid/new_hunk_6860.cpp,-1,80,,"storeAppendPrintf(sentry, ""cpu_time = %f seconds\n"", ct);","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""cpu_time"", ""%f"", ""seconds\\n"", ""ct""]]",[1940876692940817866],6765,18720.0,2
https://github.com/squid-cache/squid/commit/a7c05555fdb0ef180d8df2e68d53acc400bf2984,31 Jan 1998,"	- Combined various interprocess communication setup functions
	  into ipcCreate().
	- Removed some leftover ICP_HIT_OBJ things.
	- Removed cacheinfo and proto_count() and friends; these are to
	  be replaced in functionality by StatCounters and 5/60 minute
	  average views via cachemgr.
Changes to squid-1.2.beta11 (Jan 6, 1998):",997,data/crawl/squid/hunk_6857.cpp,,,data/crawl/squid/old_hunk_6857.cpp,data/crawl/squid/new_hunk_6857.cpp,29,-1,fatal(xstrerror());,,"[""removeLog""]","[[""fatal"", ""xstrerror""], []]",[2294497512835379361],6764,0.0,2
https://github.com/squid-cache/squid/commit/15576b6a58a24ed2705d6228d0fde8cfcef26cae,07 Feb 1998,remove brackets from cachemgr output,390,data/crawl/squid/hunk_6829.cpp,,,data/crawl/squid/old_hunk_6829.cpp,data/crawl/squid/new_hunk_6829.cpp,42,41,"storeAppendPrintf(sentry, ""{\tUP Time:\t%.3f seconds}\n"", runtime);","storeAppendPrintf(sentry, ""\tUP Time:\t%.3f seconds\n"", runtime);","[""updateContent""]","[[""seconds"", ""\\n""], [""seconds\\n""]]",[-3934719272372798284],6763,0.0,2
https://github.com/squid-cache/squid/commit/15576b6a58a24ed2705d6228d0fde8cfcef26cae,07 Feb 1998,remove brackets from cachemgr output,390,data/crawl/squid/hunk_6829.cpp,,,data/crawl/squid/old_hunk_6829.cpp,data/crawl/squid/new_hunk_6829.cpp,6,5,"storeAppendPrintf(sentry, ""{Start Time:\t%s}\n"",
	mkrfc1123(squid_start.tv_sec));","storeAppendPrintf(sentry, ""Start Time:\t%s\n"",
	mkrfc1123(squid_start.tv_sec));","[""updateContent""]","[[""\\t%s"", ""\\n""], [""\\t%s\\n""]]",[-1330682662106328288],6762,0.0,2
https://github.com/squid-cache/squid/commit/15576b6a58a24ed2705d6228d0fde8cfcef26cae,07 Feb 1998,remove brackets from cachemgr output,390,data/crawl/squid/hunk_6815.cpp,,,data/crawl/squid/old_hunk_6815.cpp,data/crawl/squid/new_hunk_6815.cpp,32,32,"storeAppendPrintf(sentry, ""{    Read Buffer Size: %d bytes}\n"",
	    dns->size);","storeAppendPrintf(sentry, ""    Read Buffer Size: %d bytes\n"",
	    dns->size);","[""updateContent""]","[[""bytes"", ""\\n""], [""bytes\\n""]]",[3040561417812119672],6761,0.0,2
https://github.com/squid-cache/squid/commit/ed7f56150f25fdd768b7c99d0ea052304fe2e98b,20 Feb 1998,"make all the OBJH functions static, etc",302,data/crawl/squid/hunk_6782.cpp,,,data/crawl/squid/old_hunk_6782.cpp,data/crawl/squid/new_hunk_6782.cpp,16,-1,"storeAppendPrintf(sentry, ""There are no neighbors installed.\n"");",,"[""removeLog""]","[[""storeAppendPrintf"", ""sentry"", ""There"", ""are"", ""no"", ""neighbors"", ""installed"", ""\\n""], []]",[-21427585880408419704],6760,9360.0,2
https://github.com/squid-cache/squid/commit/ed7f56150f25fdd768b7c99d0ea052304fe2e98b,20 Feb 1998,"make all the OBJH functions static, etc",302,data/crawl/squid/hunk_6780.cpp,,,data/crawl/squid/old_hunk_6780.cpp,data/crawl/squid/new_hunk_6780.cpp,-1,62,,"storeAppendPrintf(sentry, ""DOMAIN LIST: "");","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""DOMAIN"", ""LIST""]]",[20444842400479138936],6759,483840.0,2
https://github.com/squid-cache/squid/commit/ed7f56150f25fdd768b7c99d0ea052304fe2e98b,20 Feb 1998,"make all the OBJH functions static, etc",302,data/crawl/squid/hunk_6780.cpp,,,data/crawl/squid/old_hunk_6780.cpp,data/crawl/squid/new_hunk_6780.cpp,-1,48,,"storeAppendPrintf(sentry, ""Histogram of PINGS ACKED:\n"");","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""Histogram"", ""of"", ""PINGS"", ""ACKED"", ""\\n""]]",[10610578670362077077],6758,425520.0,2
https://github.com/squid-cache/squid/commit/ed7f56150f25fdd768b7c99d0ea052304fe2e98b,20 Feb 1998,"make all the OBJH functions static, etc",302,data/crawl/squid/hunk_6780.cpp,,,data/crawl/squid/old_hunk_6780.cpp,data/crawl/squid/new_hunk_6780.cpp,-1,23,,"storeAppendPrintf(sentry, ""There are no neighbors installed.\n"");","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""There"", ""are"", ""no"", ""neighbors"", ""installed"", ""\\n""]]",[21427585880408419704],6757,483840.0,2
https://github.com/squid-cache/squid/commit/5ba18ba6fb69dbc520c465c8754d0af534492919,20 Feb 1998,move function to the non-PUBLIC area,59,data/crawl/squid/hunk_6779.cpp,,,data/crawl/squid/old_hunk_6779.cpp,data/crawl/squid/new_hunk_6779.cpp,29,-1,"storeAppendPrintf(e, ""\t%4d  %9d\n"", i, server_pconn_hist[i]);",,"[""removeLog""]","[[""storeAppendPrintf"", ""e"", ""\\t%4d"", ""%9d\\n"", ""i"", ""server_pconn_hist[i]""], []]",[-4661309132147493222],6756,0.0,2
https://github.com/squid-cache/squid/commit/5ba18ba6fb69dbc520c465c8754d0af534492919,20 Feb 1998,move function to the non-PUBLIC area,59,data/crawl/squid/hunk_6779.cpp,,,data/crawl/squid/old_hunk_6779.cpp,data/crawl/squid/new_hunk_6779.cpp,8,-1,"storeAppendPrintf(e,
        ""Client-side persistent connection counts:\n""
        ""\n""
        ""\treq/\n""
        ""\tconn      count\n""
        ""\t----  ---------\n"");",,"[""removeLog""]","[[""storeAppendPrintf"", ""e"", ""Client"", ""side"", ""persistent"", ""connection"", ""counts"", ""\\n"", ""\\n"", ""\\treq/\\n"", ""\\tconn"", ""count\\n"", ""\\t"", ""\\n""], []]",[-18179187017519893231],6755,0.0,2
https://github.com/squid-cache/squid/commit/5ba18ba6fb69dbc520c465c8754d0af534492919,20 Feb 1998,move function to the non-PUBLIC area,59,data/crawl/squid/hunk_6778.cpp,,,data/crawl/squid/old_hunk_6778.cpp,data/crawl/squid/new_hunk_6778.cpp,-1,16,,"storeAppendPrintf(e, ""\t%4d  %9d\n"", i, client_pconn_hist[i]);","[""addLog""]","[[], [""storeAppendPrintf"", ""e"", ""\\t%4d"", ""%9d\\n"", ""i"", ""client_pconn_hist[i]""]]",[3068874400049008290],6754,0.0,2
https://github.com/squid-cache/squid/commit/5ba18ba6fb69dbc520c465c8754d0af534492919,20 Feb 1998,move function to the non-PUBLIC area,59,data/crawl/squid/hunk_6778.cpp,,,data/crawl/squid/old_hunk_6778.cpp,data/crawl/squid/new_hunk_6778.cpp,-1,7,,"storeAppendPrintf(e,
        ""Client-side persistent connection counts:\n""
        ""\n""
        ""\treq/\n""
        ""\tconn      count\n""
        ""\t----  ---------\n"");","[""addLog""]","[[], [""storeAppendPrintf"", ""e"", ""Client"", ""side"", ""persistent"", ""connection"", ""counts"", ""\\n"", ""\\n"", ""\\treq/\\n"", ""\\tconn"", ""count\\n"", ""\\t"", ""\\n""]]",[18179187017519893231],6753,0.0,2
https://github.com/squid-cache/squid/commit/85269fdf3c2a36641dfae2cf71f495a38c95cc28,22 Feb 1998,"Snmplib for squid, based on v1.8, heavily changed",8289,data/crawl/squid/hunk_6758.cpp,,,data/crawl/squid/old_hunk_6758.cpp,data/crawl/squid/new_hunk_6758.cpp,-1,369,,"printf(""VARS %d: Encoding NULL at 0x%x\n"", Counter, bufp);","[""addLog""]","[[], [""printf"", ""VARS"", ""%d"", ""Encoding"", ""NULL"", ""at"", ""0x%x\\n"", ""Counter"", ""bufp""]]",[-2577900448518484852],6752,0.0,2
https://github.com/squid-cache/squid/commit/85269fdf3c2a36641dfae2cf71f495a38c95cc28,22 Feb 1998,"Snmplib for squid, based on v1.8, heavily changed",8289,data/crawl/squid/hunk_6758.cpp,,,data/crawl/squid/old_hunk_6758.cpp,data/crawl/squid/new_hunk_6758.cpp,-1,216,,"printf(""VARS: Cloned %x.\n"", (unsigned int)Dest);","[""addLog""]","[[], [""printf"", ""VARS"", ""Cloned"", ""%x"", ""\\n"", ""unsigned"", ""int"", ""Dest""]]",[-23764653827026217162],6751,0.0,2
https://github.com/squid-cache/squid/commit/85269fdf3c2a36641dfae2cf71f495a38c95cc28,22 Feb 1998,"Snmplib for squid, based on v1.8, heavily changed",8289,data/crawl/squid/hunk_6758.cpp,,,data/crawl/squid/old_hunk_6758.cpp,data/crawl/squid/new_hunk_6758.cpp,-1,148,,"printf(""VARS: Created %x.\n"", (unsigned int)New);","[""addLog""]","[[], [""printf"", ""VARS"", ""Created"", ""%x"", ""\\n"", ""unsigned"", ""int"", ""New""]]",[-18167291016024732353],6750,0.0,2
https://github.com/squid-cache/squid/commit/85269fdf3c2a36641dfae2cf71f495a38c95cc28,22 Feb 1998,"Snmplib for squid, based on v1.8, heavily changed",8289,data/crawl/squid/hunk_6757.cpp,,,data/crawl/squid/old_hunk_6757.cpp,data/crawl/squid/new_hunk_6757.cpp,-1,160,,"fprintf(out, ""LIBSNMP: ----------------------------------------\n"");","[""addLog""]","[[], [""fprintf"", ""out"", ""LIBSNMP"", ""\\n""]]",[4064873767396912617],6749,0.0,2
https://github.com/squid-cache/squid/commit/85269fdf3c2a36641dfae2cf71f495a38c95cc28,22 Feb 1998,"Snmplib for squid, based on v1.8, heavily changed",8289,data/crawl/squid/hunk_6752.cpp,,,data/crawl/squid/old_hunk_6752.cpp,data/crawl/squid/new_hunk_6752.cpp,-1,338,,"print_error(""Bad parse of object id"", (char *)NULL, type);","[""addLog""]","[[], [""print_error"", ""Bad"", ""parse"", ""of"", ""object"", ""id"", ""char"", ""*"", ""NULL"", ""type""]]",[-959491297452506378],6748,66960.0,2
https://github.com/squid-cache/squid/commit/85269fdf3c2a36641dfae2cf71f495a38c95cc28,22 Feb 1998,"Snmplib for squid, based on v1.8, heavily changed",8289,data/crawl/squid/hunk_6752.cpp,,,data/crawl/squid/old_hunk_6752.cpp,data/crawl/squid/new_hunk_6752.cpp,841,-1,"print_error(""Bad parse of module identity"", (char *) NULL,
			type);",,"[""removeLog""]","[[""print_error"", ""Bad"", ""parse"", ""of"", ""module"", ""identity"", ""char"", ""*"", ""NULL"", ""type""], []]",[-7997078272424875002],6747,0.0,2
https://github.com/squid-cache/squid/commit/85269fdf3c2a36641dfae2cf71f495a38c95cc28,22 Feb 1998,"Snmplib for squid, based on v1.8, heavily changed",8289,data/crawl/squid/hunk_6752.cpp,,,data/crawl/squid/old_hunk_6752.cpp,data/crawl/squid/new_hunk_6752.cpp,821,-1,"print_error(""Bad parse of module compliance"", (char *) NULL,
			type);",,"[""removeLog""]","[[""print_error"", ""Bad"", ""parse"", ""of"", ""module"", ""compliance"", ""char"", ""*"", ""NULL"", ""type""], []]",[4890720600463276281],6746,0.0,2
https://github.com/squid-cache/squid/commit/85269fdf3c2a36641dfae2cf71f495a38c95cc28,22 Feb 1998,"Snmplib for squid, based on v1.8, heavily changed",8289,data/crawl/squid/hunk_6752.cpp,,,data/crawl/squid/old_hunk_6752.cpp,data/crawl/squid/new_hunk_6752.cpp,801,-1,"print_error(""Bad parse of notification definition"",
			(char *) NULL, type);",,"[""removeLog""]","[[""print_error"", ""Bad"", ""parse"", ""of"", ""notification"", ""definition"", ""char"", ""*"", ""NULL"", ""type""], []]",[-4323801684523373336],6745,0.0,2
https://github.com/squid-cache/squid/commit/85269fdf3c2a36641dfae2cf71f495a38c95cc28,22 Feb 1998,"Snmplib for squid, based on v1.8, heavily changed",8289,data/crawl/squid/hunk_6752.cpp,,,data/crawl/squid/old_hunk_6752.cpp,data/crawl/squid/new_hunk_6752.cpp,281,-1,"print_error(""Expected \""(\"""", token, type);",,"[""removeLog""]","[[""print_error"", ""Expected"", ""\\"", ""\\"", ""token"", ""type""], []]",[-23625327351001242289],6744,0.0,2
https://github.com/squid-cache/squid/commit/85269fdf3c2a36641dfae2cf71f495a38c95cc28,22 Feb 1998,"Snmplib for squid, based on v1.8, heavily changed",8289,data/crawl/squid/hunk_6747.cpp,,,data/crawl/squid/old_hunk_6747.cpp,data/crawl/squid/new_hunk_6747.cpp,-1,238,,"printf(""%s"", buf);","[""addLog""]","[[], [""printf"", ""%s"", ""buf""]]",[7569169800143846097],6743,66960.0,2
https://github.com/squid-cache/squid/commit/85269fdf3c2a36641dfae2cf71f495a38c95cc28,22 Feb 1998,"Snmplib for squid, based on v1.8, heavily changed",8289,data/crawl/squid/hunk_6747.cpp,,,data/crawl/squid/old_hunk_6747.cpp,data/crawl/squid/new_hunk_6747.cpp,-1,171,,"printf(""%s\n"", tempbuf);","[""addLog""]","[[], [""printf"", ""%s\\n"", ""tempbuf""]]",[15369913385445251411],6742,66960.0,2
https://github.com/squid-cache/squid/commit/85269fdf3c2a36641dfae2cf71f495a38c95cc28,22 Feb 1998,"Snmplib for squid, based on v1.8, heavily changed",8289,data/crawl/squid/hunk_6747.cpp,,,data/crawl/squid/old_hunk_6747.cpp,data/crawl/squid/new_hunk_6747.cpp,-1,110,,"printf(""%s\n"", buf);","[""addLog""]","[[], [""printf"", ""%s\\n"", ""buf""]]",[13709399011105512741],6741,66960.0,2
https://github.com/squid-cache/squid/commit/85269fdf3c2a36641dfae2cf71f495a38c95cc28,22 Feb 1998,"Snmplib for squid, based on v1.8, heavily changed",8289,data/crawl/squid/hunk_6744.cpp,,,data/crawl/squid/old_hunk_6744.cpp,data/crawl/squid/new_hunk_6744.cpp,73,-1,"fprintf(stderr, ""object identifier too long\n"");",,"[""removeLog""]","[[""fprintf"", ""stderr"", ""object"", ""identifier"", ""too"", ""long\\n""], []]",[16428620954377002349],6740,0.0,2
https://github.com/squid-cache/squid/commit/d23f4e1b36396b975b3de1a630942be944069f3b,23 Feb 1998,new squid-independent cachemgr.cgi,1029,data/crawl/squid/hunk_6741.cpp,,,data/crawl/squid/old_hunk_6741.cpp,data/crawl/squid/new_hunk_6741.cpp,447,-1,"printf(""</FORM>\n"");",,"[""removeLog""]","[[""printf"", ""/FORM"", ""\\n""], []]",[-15263044218574330895],6739,389520.0,2
https://github.com/squid-cache/squid/commit/d23f4e1b36396b975b3de1a630942be944069f3b,23 Feb 1998,new squid-independent cachemgr.cgi,1029,data/crawl/squid/hunk_6741.cpp,,,data/crawl/squid/old_hunk_6741.cpp,data/crawl/squid/new_hunk_6741.cpp,409,-1,"printf(""Unknown operation: %s\n"", operation);",,"[""removeLog""]","[[""printf"", ""Unknown"", ""operation"", ""%s\\n"", ""operation""], []]",[-14080718154647789094],6738,362880.0,2
https://github.com/squid-cache/squid/commit/d23f4e1b36396b975b3de1a630942be944069f3b,23 Feb 1998,new squid-independent cachemgr.cgi,1029,data/crawl/squid/hunk_6741.cpp,,,data/crawl/squid/old_hunk_6741.cpp,data/crawl/squid/new_hunk_6741.cpp,35,-1,"printf(""<HR>\n"");",,"[""removeLog""]","[[""printf"", ""HR"", ""\\n""], []]",[-7262497705588788951],6737,0.0,2
https://github.com/squid-cache/squid/commit/d0e0c8d2e44a6abe849832bb9d03295295be42e6,24 Feb 1998,Update,1347,data/crawl/squid/hunk_6734.cpp,,,data/crawl/squid/old_hunk_6734.cpp,data/crawl/squid/new_hunk_6734.cpp,70,73,"printf(""Received a %d PDU\n"", PDU->command);","debug(49, 9) (""Received a %d PDU\n"", PDU->command);","[""updateLog"", ""moveLog"", ""addContent""]","[[""printf""], [""debug"", ""49"", ""9""]]",[481017038546728640],6736,0.0,2
https://github.com/squid-cache/squid/commit/12cf1be254530ce1179dc222dafe8964932e718f,25 Feb 1998,"- Added rudimental statistics for HTTP headers.

- Adjusted StatLogHist to a more ""generic""/flexible StatHist.
  Moved StatHist implementation into a separate file.",860,data/crawl/squid/hunk_6723.cpp,,,data/crawl/squid/old_hunk_6723.cpp,data/crawl/squid/new_hunk_6723.cpp,-1,131,,"storeAppendPrintf(sentry, ""wall_time = %f\n"",
	tvSubDsec(f->timestamp, current_time));","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""wall_time"", ""%f\\n"", ""tvSubDsec"", ""f"", ""timestamp"", ""current_time""]]",[7225499045681938401],6735,18000.0,2
https://github.com/squid-cache/squid/commit/12cf1be254530ce1179dc222dafe8964932e718f,25 Feb 1998,"- Added rudimental statistics for HTTP headers.

- Adjusted StatLogHist to a more ""generic""/flexible StatHist.
  Moved StatHist implementation into a separate file.",860,data/crawl/squid/hunk_6723.cpp,,,data/crawl/squid/old_hunk_6723.cpp,data/crawl/squid/new_hunk_6723.cpp,-1,129,,"storeAppendPrintf(sentry, ""cpu_time = %f\n"",
	f->cputime);","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""cpu_time"", ""%f\\n"", ""f"", ""cputime""]]",[10681447212033283360],6734,18000.0,2
https://github.com/squid-cache/squid/commit/12cf1be254530ce1179dc222dafe8964932e718f,25 Feb 1998,"- Added rudimental statistics for HTTP headers.

- Adjusted StatLogHist to a more ""generic""/flexible StatHist.
  Moved StatHist implementation into a separate file.",860,data/crawl/squid/hunk_6723.cpp,,,data/crawl/squid/old_hunk_6723.cpp,data/crawl/squid/new_hunk_6723.cpp,-1,127,,"storeAppendPrintf(sentry, ""select_loops = %d\n"",
	f->select_loops);","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""select_loops"", ""%d\\n"", ""f"", ""select_loops""]]",[19552141474140858902],6733,18000.0,2
https://github.com/squid-cache/squid/commit/12cf1be254530ce1179dc222dafe8964932e718f,25 Feb 1998,"- Added rudimental statistics for HTTP headers.

- Adjusted StatLogHist to a more ""generic""/flexible StatHist.
  Moved StatHist implementation into a separate file.",860,data/crawl/squid/hunk_6723.cpp,,,data/crawl/squid/old_hunk_6723.cpp,data/crawl/squid/new_hunk_6723.cpp,-1,125,,"storeAppendPrintf(sentry, ""page_faults = %d\n"",
	f->page_faults);","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""page_faults"", ""%d\\n"", ""f"", ""page_faults""]]",[8775029013852970286],6732,18000.0,2
https://github.com/squid-cache/squid/commit/12cf1be254530ce1179dc222dafe8964932e718f,25 Feb 1998,"- Added rudimental statistics for HTTP headers.

- Adjusted StatLogHist to a more ""generic""/flexible StatHist.
  Moved StatHist implementation into a separate file.",860,data/crawl/squid/hunk_6723.cpp,,,data/crawl/squid/old_hunk_6723.cpp,data/crawl/squid/new_hunk_6723.cpp,-1,123,,"storeAppendPrintf(sentry, ""unlink.requests = %d\n"",
	f->unlink.requests);","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""unlink"", ""requests"", ""%d\\n"", ""f"", ""unlink"", ""requests""]]",[14424672953305956856],6731,18000.0,2
https://github.com/squid-cache/squid/commit/12cf1be254530ce1179dc222dafe8964932e718f,25 Feb 1998,"- Added rudimental statistics for HTTP headers.

- Adjusted StatLogHist to a more ""generic""/flexible StatHist.
  Moved StatHist implementation into a separate file.",860,data/crawl/squid/hunk_6723.cpp,,,data/crawl/squid/old_hunk_6723.cpp,data/crawl/squid/new_hunk_6723.cpp,-1,105,,"storeAppendPrintf(sentry, ""server.kbytes_out = %d\n"",
	(int) f->server.kbytes_out.kb);","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""server"", ""kbytes_out"", ""%d\\n"", ""int"", ""f"", ""server"", ""kbytes_out"", ""kb""]]",[-4372552772645165581],6730,0.0,2
https://github.com/squid-cache/squid/commit/12cf1be254530ce1179dc222dafe8964932e718f,25 Feb 1998,"- Added rudimental statistics for HTTP headers.

- Adjusted StatLogHist to a more ""generic""/flexible StatHist.
  Moved StatHist implementation into a separate file.",860,data/crawl/squid/hunk_6723.cpp,,,data/crawl/squid/old_hunk_6723.cpp,data/crawl/squid/new_hunk_6723.cpp,-1,103,,"storeAppendPrintf(sentry, ""server.kbytes_in = %d\n"",
	(int) f->server.kbytes_in.kb);","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""server"", ""kbytes_in"", ""%d\\n"", ""int"", ""f"", ""server"", ""kbytes_in"", ""kb""]]",[5852715778484342843],6729,0.0,2
https://github.com/squid-cache/squid/commit/12cf1be254530ce1179dc222dafe8964932e718f,25 Feb 1998,"- Added rudimental statistics for HTTP headers.

- Adjusted StatLogHist to a more ""generic""/flexible StatHist.
  Moved StatHist implementation into a separate file.",860,data/crawl/squid/hunk_6723.cpp,,,data/crawl/squid/old_hunk_6723.cpp,data/crawl/squid/new_hunk_6723.cpp,-1,101,,"storeAppendPrintf(sentry, ""server.errors = %d\n"",
	(int) f->server.errors);","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""server"", ""errors"", ""%d\\n"", ""int"", ""f"", ""server"", ""errors""]]",[-10659075048449863174],6728,0.0,2
https://github.com/squid-cache/squid/commit/12cf1be254530ce1179dc222dafe8964932e718f,25 Feb 1998,"- Added rudimental statistics for HTTP headers.

- Adjusted StatLogHist to a more ""generic""/flexible StatHist.
  Moved StatHist implementation into a separate file.",860,data/crawl/squid/hunk_6723.cpp,,,data/crawl/squid/old_hunk_6723.cpp,data/crawl/squid/new_hunk_6723.cpp,-1,99,,"storeAppendPrintf(sentry, ""server.requests = %d\n"",
	(int) f->server.requests);","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""server"", ""requests"", ""%d\\n"", ""int"", ""f"", ""server"", ""requests""]]",[4153088057896327848],6727,0.0,2
https://github.com/squid-cache/squid/commit/12cf1be254530ce1179dc222dafe8964932e718f,25 Feb 1998,"- Added rudimental statistics for HTTP headers.

- Adjusted StatLogHist to a more ""generic""/flexible StatHist.
  Moved StatHist implementation into a separate file.",860,data/crawl/squid/hunk_6723.cpp,,,data/crawl/squid/old_hunk_6723.cpp,data/crawl/squid/new_hunk_6723.cpp,-1,88,,"storeAppendPrintf(sentry, ""client_http.kbytes_out = %d\n"",
	(int) f->client_http.kbytes_out.kb);","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""client_http"", ""kbytes_out"", ""%d\\n"", ""int"", ""f"", ""client_http"", ""kbytes_out"", ""kb""]]",[13540181629153195307],6726,18000.0,2
https://github.com/squid-cache/squid/commit/12cf1be254530ce1179dc222dafe8964932e718f,25 Feb 1998,"- Added rudimental statistics for HTTP headers.

- Adjusted StatLogHist to a more ""generic""/flexible StatHist.
  Moved StatHist implementation into a separate file.",860,data/crawl/squid/hunk_6723.cpp,,,data/crawl/squid/old_hunk_6723.cpp,data/crawl/squid/new_hunk_6723.cpp,-1,86,,"storeAppendPrintf(sentry, ""client_http.kbytes_in = %d\n"",
	(int) f->client_http.kbytes_in.kb);","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""client_http"", ""kbytes_in"", ""%d\\n"", ""int"", ""f"", ""client_http"", ""kbytes_in"", ""kb""]]",[23765450180282703731],6725,18000.0,2
https://github.com/squid-cache/squid/commit/12cf1be254530ce1179dc222dafe8964932e718f,25 Feb 1998,"- Added rudimental statistics for HTTP headers.

- Adjusted StatLogHist to a more ""generic""/flexible StatHist.
  Moved StatHist implementation into a separate file.",860,data/crawl/squid/hunk_6723.cpp,,,data/crawl/squid/old_hunk_6723.cpp,data/crawl/squid/new_hunk_6723.cpp,-1,84,,"storeAppendPrintf(sentry, ""client_http.errors = %d\n"",
	f->client_http.errors);","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""client_http"", ""errors"", ""%d\\n"", ""f"", ""client_http"", ""errors""]]",[14809023724203262378],6724,18000.0,2
https://github.com/squid-cache/squid/commit/12cf1be254530ce1179dc222dafe8964932e718f,25 Feb 1998,"- Added rudimental statistics for HTTP headers.

- Adjusted StatLogHist to a more ""generic""/flexible StatHist.
  Moved StatHist implementation into a separate file.",860,data/crawl/squid/hunk_6723.cpp,,,data/crawl/squid/old_hunk_6723.cpp,data/crawl/squid/new_hunk_6723.cpp,-1,82,,"storeAppendPrintf(sentry, ""client_http.hits = %d\n"",
	f->client_http.hits);","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""client_http"", ""hits"", ""%d\\n"", ""f"", ""client_http"", ""hits""]]",[44393885824770128424],6723,18000.0,2
https://github.com/squid-cache/squid/commit/12cf1be254530ce1179dc222dafe8964932e718f,25 Feb 1998,"- Added rudimental statistics for HTTP headers.

- Adjusted StatLogHist to a more ""generic""/flexible StatHist.
  Moved StatHist implementation into a separate file.",860,data/crawl/squid/hunk_6723.cpp,,,data/crawl/squid/old_hunk_6723.cpp,data/crawl/squid/new_hunk_6723.cpp,-1,80,,"storeAppendPrintf(sentry, ""client_http.requests = %d\n"",
	f->client_http.requests);","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""client_http"", ""requests"", ""%d\\n"", ""f"", ""client_http"", ""requests""]]",[29621186830549453400],6722,18000.0,2
https://github.com/squid-cache/squid/commit/12cf1be254530ce1179dc222dafe8964932e718f,25 Feb 1998,"- Added rudimental statistics for HTTP headers.

- Adjusted StatLogHist to a more ""generic""/flexible StatHist.
  Moved StatHist implementation into a separate file.",860,data/crawl/squid/hunk_6715.cpp,,,data/crawl/squid/old_hunk_6715.cpp,data/crawl/squid/new_hunk_6715.cpp,-1,83,,"storeAppendPrintf(e, ""%s\n"", ""<hr size=1 noshade>"");","[""addLog""]","[[], [""storeAppendPrintf"", ""e"", ""%s\\n"", ""hr"", ""size"", ""1"", ""noshade""]]",[10036459428081683775],6721,0.0,2
https://github.com/squid-cache/squid/commit/36a97e19531e381006a0b7201d79c65572cce2c3,27 Feb 1998,patch for logging malloc/calloc/free traces to file,85,data/crawl/squid/hunk_6677.cpp,,,data/crawl/squid/old_hunk_6677.cpp,data/crawl/squid/new_hunk_6677.cpp,-1,10,,"fprintf(tracefp,""f:%x\n"",s);","[""addLog""]","[[], [""fprintf"", ""tracefp"", ""f"", ""%x\\n"", ""s""]]",[-4185227475741869624],6720,0.0,2
https://github.com/squid-cache/squid/commit/7021844c42212902ee9a10ba7097201a6d66a1c5,03 Mar 1998,"- Added ""mem_pools_limit"" configuration option. Semantics of
  ""mem_pools"" option has also changed a bit to reflect new memory
  management policy.
- Reorganized memory pools. Squid now allocates memory in big chunks
  and distributes that memory among ""frequently allocated"" objects.
- memAllocate() has now only one parameter. Objects are always reset
  with 0s.

- HttpHeader.c: fixed warnings generated by some compilers on member to union
  conversions. Tested using DEC cc only.
- cachmgr.c now tries to interpret strings containing '\t' as table rows and
  format them using html table attributes.",742,data/crawl/squid/hunk_6653.cpp,,,data/crawl/squid/old_hunk_6653.cpp,data/crawl/squid/new_hunk_6653.cpp,-1,6,,"storeAppendPrintf(e, ""<br><h3>Long String Stats</h3>\n"");","[""addLog""]","[[], [""storeAppendPrintf"", ""e"", ""br"", ""h3"", ""Long"", ""String"", ""Stats"", ""/h3"", ""\\n""]]",[6771819759970315408],6719,4320.0,2
https://github.com/squid-cache/squid/commit/7faf2bdbd107159360e994049bb7fdc2a153f37f,05 Mar 1998,"- gb_t additions to .h monsters
- Renamed HttpScc object into HttpHdrCc
- Moved HttpHdrCc from HttpHeader.c to HttpHdrCc.c
- Moved ""commonly used"" routines from HttpHeader.c to HttpHeaderTools.c.
All this was done to prepare for addition of HttpHdrRange.",666,data/crawl/squid/hunk_6632.cpp,,,data/crawl/squid/old_hunk_6632.cpp,data/crawl/squid/new_hunk_6632.cpp,-1,190,,"storeAppendPrintf(sentry, ""%2d\t %-20s\t %5d\t %6.2f\n"",
	    id, name, count, xdiv(count, CcPasredCount));","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""%2d\\t"", ""%"", ""20s\\t"", ""%5d\\t"", ""%6"", ""2f\\n"", ""id"", ""name"", ""count"", ""xdiv"", ""count"", ""CcPasredCount""]]",[20114730292022789432],6718,5760.0,2
https://github.com/squid-cache/squid/commit/5e14bf6d450a13f8ec961da2f76eb53337548bee,17 Mar 1998,"SNMP changes/fixes
	- changed some snmplib debugging messages
	- simplifed and fixed snmplib_debug_hook interface.  It
	  wasn't properly passing all the 'varargs' args.  Now
	  it just vsnprintf's to a buf and passes that.
	- struct _snmpconf was never used.
	- made 'snmp_agent_conf' a stringlist type
	- moved 'snmp_agent_conf' processing to snmpInit().
	- moved snmpInit() call to before 'ready to serve requests'
	  message.",148,data/crawl/squid/hunk_6586.cpp,,,data/crawl/squid/old_hunk_6586.cpp,data/crawl/squid/new_hunk_6586.cpp,35,-1,"storeAppendPrintf(entry, ""%s -- UNIMPLEMENTED\n"", name);",,"[""removeLog""]","[[""storeAppendPrintf"", ""entry"", ""%s"", ""UNIMPLEMENTED\\n"", ""name""], []]",[8524465994432361915],6717,75600.0,2
https://github.com/squid-cache/squid/commit/c411be125a6f44f5895b034f773607cc18a40815,31 Mar 1998,Added test_cache_digest.c: a test-suite for playing with cache digests,332,data/crawl/squid/hunk_6565.cpp,,,data/crawl/squid/old_hunk_6565.cpp,data/crawl/squid/new_hunk_6565.cpp,-1,267,,"fprintf(stderr, ""%s:%d: unknown swap log action\n"", fname, count);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""%s"", ""%d"", ""unknown"", ""swap"", ""log"", ""action\\n"", ""fname"", ""count""]]",[-4349479986286482466],6716,720.0,2
https://github.com/squid-cache/squid/commit/c411be125a6f44f5895b034f773607cc18a40815,31 Mar 1998,Added test_cache_digest.c: a test-suite for playing with cache digests,332,data/crawl/squid/hunk_6565.cpp,,,data/crawl/squid/old_hunk_6565.cpp,data/crawl/squid/new_hunk_6565.cpp,-1,170,,"fprintf(stderr, ""%s: scanned lines: %d\n"", 
	idx->name, idx->scanned_count);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""%s"", ""scanned"", ""lines"", ""%d\\n"", ""idx"", ""name"", ""idx"", ""scanned_count""]]",[-32770925052841502622],6715,720.0,2
https://github.com/squid-cache/squid/commit/c411be125a6f44f5895b034f773607cc18a40815,31 Mar 1998,Added test_cache_digest.c: a test-suite for playing with cache digests,332,data/crawl/squid/hunk_6565.cpp,,,data/crawl/squid/old_hunk_6565.cpp,data/crawl/squid/new_hunk_6565.cpp,-1,168,,"fprintf(stderr, ""%s: bad swap_del:  %d\n"", 
	idx->name, idx->bad_del_count);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""%s"", ""bad"", ""swap_del"", ""%d\\n"", ""idx"", ""name"", ""idx"", ""bad_del_count""]]",[-37650082127031582687],6714,720.0,2
https://github.com/squid-cache/squid/commit/c411be125a6f44f5895b034f773607cc18a40815,31 Mar 1998,Added test_cache_digest.c: a test-suite for playing with cache digests,332,data/crawl/squid/hunk_6565.cpp,,,data/crawl/squid/old_hunk_6565.cpp,data/crawl/squid/new_hunk_6565.cpp,-1,166,,"fprintf(stderr, ""%s: bad swap_add:  %d\n"",
	idx->name, idx->bad_add_count);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""%s"", ""bad"", ""swap_add"", ""%d\\n"", ""idx"", ""name"", ""idx"", ""bad_add_count""]]",[-26870335904675328883],6713,720.0,2
https://github.com/squid-cache/squid/commit/6d80b36f5fa3546be4e989741a1165df97e33c14,01 Apr 1998,"- Added cacheDigestClone() method.
- major test_cache_digest updates",608,data/crawl/squid/hunk_6539.cpp,,,data/crawl/squid/old_hunk_6539.cpp,data/crawl/squid/new_hunk_6539.cpp,8,-1,"fprintf(stderr, ""%s scanning\n"", fname);",,"[""removeLog""]","[[""fprintf"", ""stderr"", ""%s"", ""scanning\\n"", ""fname""], []]",[3659830878210560945],6712,0.0,2
https://github.com/squid-cache/squid/commit/6d80b36f5fa3546be4e989741a1165df97e33c14,01 Apr 1998,"- Added cacheDigestClone() method.
- major test_cache_digest updates",608,data/crawl/squid/hunk_6537.cpp,,,data/crawl/squid/old_hunk_6537.cpp,data/crawl/squid/new_hunk_6537.cpp,102,125,"fprintf(stderr, ""%s: init-ing digest with %d entries\n"", idx->name, idx->count);","fprintf(stderr, ""%s: init-ing digest with %d entries\n"", cache->name, cache->count);","[""updateVariable""]","[[""idx"", ""idx""], [""cache"", ""cache""]]",[-1894896888047170934],6711,0.0,2
https://github.com/squid-cache/squid/commit/bd34f258a4b0bc46f2f65ea4b1331881693b9869,03 Apr 1998,"Changed squid/dnsserver communication to single-line replies.  Removed
all the unused cruft.",455,data/crawl/squid/hunk_6524.cpp,,,data/crawl/squid/old_hunk_6524.cpp,data/crawl/squid/new_hunk_6524.cpp,54,-1,"fatal_dump(""Invalid IP address"");",,"[""removeLog""]","[[""fatal_dump"", ""Invalid"", ""IP"", ""address""], []]",[25587333007482150697],6710,0.0,2
https://github.com/squid-cache/squid/commit/bd34f258a4b0bc46f2f65ea4b1331881693b9869,03 Apr 1998,"Changed squid/dnsserver communication to single-line replies.  Removed
all the unused cruft.",455,data/crawl/squid/hunk_6522.cpp,,,data/crawl/squid/old_hunk_6522.cpp,data/crawl/squid/new_hunk_6522.cpp,60,-1,"fatal_dump(""Invalid $ttl"");",,"[""removeLog""]","[[""fatal_dump"", ""Invalid"", ""ttl""], []]",[18337828980884710258],6709,0.0,2
https://github.com/squid-cache/squid/commit/bd34f258a4b0bc46f2f65ea4b1331881693b9869,03 Apr 1998,"Changed squid/dnsserver communication to single-line replies.  Removed
all the unused cruft.",455,data/crawl/squid/hunk_6522.cpp,,,data/crawl/squid/old_hunk_6522.cpp,data/crawl/squid/new_hunk_6522.cpp,56,-1,"fatal_dump(""Invalid alias"");",,"[""removeLog""]","[[""fatal_dump"", ""Invalid"", ""alias""], []]",[14133335461660142488],6708,0.0,2
https://github.com/squid-cache/squid/commit/bd34f258a4b0bc46f2f65ea4b1331881693b9869,03 Apr 1998,"Changed squid/dnsserver communication to single-line replies.  Removed
all the unused cruft.",455,data/crawl/squid/hunk_6522.cpp,,,data/crawl/squid/old_hunk_6522.cpp,data/crawl/squid/new_hunk_6522.cpp,52,-1,"fatal_dump(""Invalid $aliascount"");",,"[""removeLog""]","[[""fatal_dump"", ""Invalid"", ""aliascount""], []]",[11230306074212304254],6707,0.0,2
https://github.com/squid-cache/squid/commit/bd34f258a4b0bc46f2f65ea4b1331881693b9869,03 Apr 1998,"Changed squid/dnsserver communication to single-line replies.  Removed
all the unused cruft.",455,data/crawl/squid/hunk_6522.cpp,,,data/crawl/squid/old_hunk_6522.cpp,data/crawl/squid/new_hunk_6522.cpp,44,-1,"fatal_dump(""Invalid $ipcount"");",,"[""removeLog""]","[[""fatal_dump"", ""Invalid"", ""ipcount""], []]",[10563348015832141258],6706,0.0,2
https://github.com/squid-cache/squid/commit/bd34f258a4b0bc46f2f65ea4b1331881693b9869,03 Apr 1998,"Changed squid/dnsserver communication to single-line replies.  Removed
all the unused cruft.",455,data/crawl/squid/hunk_6522.cpp,,,data/crawl/squid/old_hunk_6522.cpp,data/crawl/squid/new_hunk_6522.cpp,41,-1,"fatal_dump(""Invalid $h_len"");",,"[""removeLog""]","[[""fatal_dump"", ""Invalid"", ""h_len""], []]",[24448664448630495720],6705,0.0,2
https://github.com/squid-cache/squid/commit/bd34f258a4b0bc46f2f65ea4b1331881693b9869,03 Apr 1998,"Changed squid/dnsserver communication to single-line replies.  Removed
all the unused cruft.",455,data/crawl/squid/hunk_6522.cpp,,,data/crawl/squid/old_hunk_6522.cpp,data/crawl/squid/new_hunk_6522.cpp,36,-1,"fatal_dump(""Invalid $h_name"");",,"[""removeLog""]","[[""fatal_dump"", ""Invalid"", ""h_name""], []]",[13419497249733194613],6704,0.0,2
https://github.com/squid-cache/squid/commit/bd34f258a4b0bc46f2f65ea4b1331881693b9869,03 Apr 1998,"Changed squid/dnsserver communication to single-line replies.  Removed
all the unused cruft.",455,data/crawl/squid/hunk_6522.cpp,,,data/crawl/squid/old_hunk_6522.cpp,data/crawl/squid/new_hunk_6522.cpp,32,-1,"fatal_dump(""Invalid $name"");",,"[""removeLog""]","[[""fatal_dump"", ""Invalid"", ""name""], []]",[21009176533381759780],6703,0.0,2
https://github.com/squid-cache/squid/commit/bd34f258a4b0bc46f2f65ea4b1331881693b9869,03 Apr 1998,"Changed squid/dnsserver communication to single-line replies.  Removed
all the unused cruft.",455,data/crawl/squid/hunk_6522.cpp,,,data/crawl/squid/old_hunk_6522.cpp,data/crawl/squid/new_hunk_6522.cpp,23,25,"fatal_dump(""Invalid $fail"");",xstrdup(token);,"[""updateLog"", ""removeContent"", ""addVariable""]","[[""fatal_dump"", ""Invalid"", ""fail""], [""xstrdup"", ""token""]]",[23960145393658786582],6702,0.0,2
https://github.com/squid-cache/squid/commit/bd34f258a4b0bc46f2f65ea4b1331881693b9869,03 Apr 1998,"Changed squid/dnsserver communication to single-line replies.  Removed
all the unused cruft.",455,data/crawl/squid/hunk_6521.cpp,,,data/crawl/squid/old_hunk_6521.cpp,data/crawl/squid/new_hunk_6521.cpp,39,-1,"printf(""$name %s\n"", request);",,"[""removeLog""]","[[""printf"", ""name"", ""%s\\n"", ""request""], []]",[-7309036292721935386],6701,0.0,2
https://github.com/squid-cache/squid/commit/bd34f258a4b0bc46f2f65ea4b1331881693b9869,03 Apr 1998,"Changed squid/dnsserver communication to single-line replies.  Removed
all the unused cruft.",455,data/crawl/squid/hunk_6520.cpp,,,data/crawl/squid/old_hunk_6520.cpp,data/crawl/squid/new_hunk_6520.cpp,8,-1,"fprintf(stderr, ""Could not open dnsserver's log file\n"");",,"[""removeLog""]","[[""fprintf"", ""stderr"", ""Could"", ""not"", ""open"", ""dnsserver"", ""s"", ""log"", ""file\\n""], []]",[-6736872700914998490],6700,31680.0,2
https://github.com/squid-cache/squid/commit/bd34f258a4b0bc46f2f65ea4b1331881693b9869,03 Apr 1998,"Changed squid/dnsserver communication to single-line replies.  Removed
all the unused cruft.",455,data/crawl/squid/hunk_6519.cpp,,,data/crawl/squid/old_hunk_6519.cpp,data/crawl/squid/new_hunk_6519.cpp,-1,59,,"printf("" %s"", inet_ntoa(addr));","[""addLog""]","[[], [""printf"", ""%s"", ""inet_ntoa"", ""addr""]]",[11114772215085777012],6699,201600.0,2
https://github.com/squid-cache/squid/commit/b1b56fbd783058afdee690b8bd67449f50d9fba2,03 Apr 1998,new dns cachemgr output,34,data/crawl/squid/hunk_6518.cpp,,,data/crawl/squid/old_hunk_6518.cpp,data/crawl/squid/new_hunk_6518.cpp,3,-1,"storeAppendPrintf(sentry, ""dnsservers use histogram:\n"");",,"[""removeLog""]","[[""storeAppendPrintf"", ""sentry"", ""dnsservers"", ""use"", ""histogram"", ""\\n""], []]",[-3592243268571107408],6698,446400.0,2
https://github.com/squid-cache/squid/commit/035f5831cd0ada83e9bb0ebcd2a9442d2a945226,04 Apr 1998,missing newline in cachemgr output,3,data/crawl/squid/hunk_6517.cpp,,,data/crawl/squid/old_hunk_6517.cpp,data/crawl/squid/new_hunk_6517.cpp,-1,4,,"storeAppendPrintf(sentry, ""Keep-Alive Ratio: %d%%\n"",
	    percent(e->stats.n_keepalives_recv, e->stats.n_keepalives_sent));","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""Keep"", ""Alive"", ""Ratio"", ""%d%%\\n"", ""percent"", ""e"", ""stats"", ""n_keepalives_recv"", ""e"", ""stats"", ""n_keepalives_sent""]]",[-3862966612436958554],6697,30960.0,2
https://github.com/squid-cache/squid/commit/43d4303ea3311615cde3e8ce986b5b447f7e89ec,04 Apr 1998,"snmp beautification, code striping etc",7598,data/crawl/squid/hunk_6513.cpp,,,data/crawl/squid/old_hunk_6513.cpp,data/crawl/squid/new_hunk_6513.cpp,110,-1,"printf(""VARS %d: Encoding NULL at 0x%x\n"", Counter, bufp);",,"[""removeLog""]","[[""printf"", ""VARS"", ""%d"", ""Encoding"", ""NULL"", ""at"", ""0x%x\\n"", ""Counter"", ""bufp""], []]",[2577900448518484852],6696,0.0,2
https://github.com/squid-cache/squid/commit/43d4303ea3311615cde3e8ce986b5b447f7e89ec,04 Apr 1998,"snmp beautification, code striping etc",7598,data/crawl/squid/hunk_6512.cpp,,,data/crawl/squid/old_hunk_6512.cpp,data/crawl/squid/new_hunk_6512.cpp,53,-1,"printf(""VARS: Created %x.\n"", (unsigned int)New);",,"[""removeLog""]","[[""printf"", ""VARS"", ""Created"", ""%x"", ""\\n"", ""unsigned"", ""int"", ""New""], []]",[18167291016024732353],6695,0.0,2
https://github.com/squid-cache/squid/commit/26b164ac83cf389215621005dbe69a664c08ac20,09 Apr 1998,"- added peer_digest.o
- a lot of digest related coding and fixes
- new stats (mgr:digest_stats)",233,data/crawl/squid/hunk_6483.cpp,,,data/crawl/squid/old_hunk_6483.cpp,data/crawl/squid/new_hunk_6483.cpp,-1,37,,"storeAppendPrintf(sentry, ""icp.replies_queued = %d\n"",
	f->icp.replies_queued);","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""icp"", ""replies_queued"", ""%d\\n"", ""f"", ""icp"", ""replies_queued""]]",[-2262826027038683720],6694,10800.0,2
https://github.com/squid-cache/squid/commit/26b164ac83cf389215621005dbe69a664c08ac20,09 Apr 1998,"- added peer_digest.o
- a lot of digest related coding and fixes
- new stats (mgr:digest_stats)",233,data/crawl/squid/hunk_6483.cpp,,,data/crawl/squid/old_hunk_6483.cpp,data/crawl/squid/new_hunk_6483.cpp,-1,27,,"storeAppendPrintf(sentry, ""icp.client_median_svc_time = %f seconds\n"",
	x / 1000.0);","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""icp"", ""client_median_svc_time"", ""%f"", ""seconds\\n"", ""x"", ""/"", ""1000"", ""0""]]",[3985394527082167644],6693,720.0,2
https://github.com/squid-cache/squid/commit/26b164ac83cf389215621005dbe69a664c08ac20,09 Apr 1998,"- added peer_digest.o
- a lot of digest related coding and fixes
- new stats (mgr:digest_stats)",233,data/crawl/squid/hunk_6483.cpp,,,data/crawl/squid/old_hunk_6483.cpp,data/crawl/squid/new_hunk_6483.cpp,-1,23,,"storeAppendPrintf(sentry, ""cd.client_median_svc_time = %f seconds\n"",
	x / 1000.0);","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""cd"", ""client_median_svc_time"", ""%f"", ""seconds\\n"", ""x"", ""/"", ""1000"", ""0""]]",[11553430974065046448],6692,720.0,2
https://github.com/squid-cache/squid/commit/c6389cd7052a3ec8bebb56a2a0e00a49ef3987f1,09 Apr 1998,- added more stats into statDigestBlob,22,data/crawl/squid/hunk_6480.cpp,,,data/crawl/squid/old_hunk_6480.cpp,data/crawl/squid/new_hunk_6480.cpp,-1,13,,"storeAppendPrintf(sentry, ""client_http.hit_median_svc_time = %f seconds\n"",
	x / 1000.0);","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""client_http"", ""hit_median_svc_time"", ""%f"", ""seconds\\n"", ""x"", ""/"", ""1000"", ""0""]]",[15990970733818383033],6691,30960.0,2
https://github.com/squid-cache/squid/commit/c6389cd7052a3ec8bebb56a2a0e00a49ef3987f1,09 Apr 1998,- added more stats into statDigestBlob,22,data/crawl/squid/hunk_6480.cpp,,,data/crawl/squid/old_hunk_6480.cpp,data/crawl/squid/new_hunk_6480.cpp,-1,9,,"storeAppendPrintf(sentry, ""client_http.miss_median_svc_time = %f seconds\n"",
	x / 1000.0);","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""client_http"", ""miss_median_svc_time"", ""%f"", ""seconds\\n"", ""x"", ""/"", ""1000"", ""0""]]",[11573547714088272369],6690,30960.0,2
https://github.com/squid-cache/squid/commit/00485c298aba90241e0697bfc2445a926cba630c,10 Apr 1998,"- tuned delaying requests for digests a bit after digests expire (to avoid
  race conditions)
- added more stats for digests: #msgs and kb_sent are now accounted for
- only cachable requests affect t/f-hit/miss stats now",85,data/crawl/squid/hunk_6475.cpp,,,data/crawl/squid/old_hunk_6475.cpp,data/crawl/squid/new_hunk_6475.cpp,-1,14,,"storeAppendPrintf(sentry, ""cd.kbytes_recv = %d\n"",
	(int) f->cd.kbytes_recv.kb);","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""cd"", ""kbytes_recv"", ""%d\\n"", ""int"", ""f"", ""cd"", ""kbytes_recv"", ""kb""]]",[22038706217347481053],6689,720.0,2
https://github.com/squid-cache/squid/commit/00485c298aba90241e0697bfc2445a926cba630c,10 Apr 1998,"- tuned delaying requests for digests a bit after digests expire (to avoid
  race conditions)
- added more stats for digests: #msgs and kb_sent are now accounted for
- only cachable requests affect t/f-hit/miss stats now",85,data/crawl/squid/hunk_6475.cpp,,,data/crawl/squid/old_hunk_6475.cpp,data/crawl/squid/new_hunk_6475.cpp,-1,12,,"storeAppendPrintf(sentry, ""cd.kbytes_sent = %d\n"",
	(int) f->cd.kbytes_sent.kb);","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""cd"", ""kbytes_sent"", ""%d\\n"", ""int"", ""f"", ""cd"", ""kbytes_sent"", ""kb""]]",[20038452216267480529],6688,720.0,2
https://github.com/squid-cache/squid/commit/00485c298aba90241e0697bfc2445a926cba630c,10 Apr 1998,"- tuned delaying requests for digests a bit after digests expire (to avoid
  race conditions)
- added more stats for digests: #msgs and kb_sent are now accounted for
- only cachable requests affect t/f-hit/miss stats now",85,data/crawl/squid/hunk_6475.cpp,,,data/crawl/squid/old_hunk_6475.cpp,data/crawl/squid/new_hunk_6475.cpp,-1,6,,"storeAppendPrintf(sentry, ""cd.msgs_recv = %d\n"",
	f->cd.msgs_recv);","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""cd"", ""msgs_recv"", ""%d\\n"", ""f"", ""cd"", ""msgs_recv""]]",[4837284672466329140],6687,0.0,2
https://github.com/squid-cache/squid/commit/00485c298aba90241e0697bfc2445a926cba630c,10 Apr 1998,"- tuned delaying requests for digests a bit after digests expire (to avoid
  race conditions)
- added more stats for digests: #msgs and kb_sent are now accounted for
- only cachable requests affect t/f-hit/miss stats now",85,data/crawl/squid/hunk_6475.cpp,,,data/crawl/squid/old_hunk_6475.cpp,data/crawl/squid/new_hunk_6475.cpp,-1,4,,"storeAppendPrintf(sentry, ""cd.msgs_sent = %d\n"",
	f->cd.msgs_sent);","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""cd"", ""msgs_sent"", ""%d\\n"", ""f"", ""cd"", ""msgs_sent""]]",[2837526673978331448],6686,0.0,2
https://github.com/squid-cache/squid/commit/071a3ae79623f644f3544044423946dd3a35710b,10 Apr 1998,Cleaned up ICP logging/counting and ICP/CD stats output,269,data/crawl/squid/hunk_6470.cpp,,,data/crawl/squid/old_hunk_6470.cpp,data/crawl/squid/new_hunk_6470.cpp,58,-1,"storeAppendPrintf(sentry, ""icp.kbytes_recv = %d\n"",
	(int) f->icp.kbytes_recv.kb);",,"[""removeLog""]","[[""storeAppendPrintf"", ""sentry"", ""icp"", ""kbytes_recv"", ""%d\\n"", ""int"", ""f"", ""icp"", ""kbytes_recv"", ""kb""], []]",[-6902633323381723445],6685,31680.0,2
https://github.com/squid-cache/squid/commit/071a3ae79623f644f3544044423946dd3a35710b,10 Apr 1998,Cleaned up ICP logging/counting and ICP/CD stats output,269,data/crawl/squid/hunk_6470.cpp,,,data/crawl/squid/old_hunk_6470.cpp,data/crawl/squid/new_hunk_6470.cpp,56,-1,"storeAppendPrintf(sentry, ""icp.kbytes_sent = %d\n"",
	(int) f->icp.kbytes_sent.kb);",,"[""removeLog""]","[[""storeAppendPrintf"", ""sentry"", ""icp"", ""kbytes_sent"", ""%d\\n"", ""int"", ""f"", ""icp"", ""kbytes_sent"", ""kb""], []]",[-4902379322301722921],6684,31680.0,2
https://github.com/squid-cache/squid/commit/071a3ae79623f644f3544044423946dd3a35710b,10 Apr 1998,Cleaned up ICP logging/counting and ICP/CD stats output,269,data/crawl/squid/hunk_6470.cpp,,,data/crawl/squid/old_hunk_6470.cpp,data/crawl/squid/new_hunk_6470.cpp,52,-1,"storeAppendPrintf(sentry, ""icp.pkts_recv = %d\n"",
	f->icp.pkts_recv);",,"[""removeLog""]","[[""storeAppendPrintf"", ""sentry"", ""icp"", ""pkts_recv"", ""%d\\n"", ""f"", ""icp"", ""pkts_recv""], []]",[-4165807127523989432],6683,31680.0,2
https://github.com/squid-cache/squid/commit/071a3ae79623f644f3544044423946dd3a35710b,10 Apr 1998,Cleaned up ICP logging/counting and ICP/CD stats output,269,data/crawl/squid/hunk_6470.cpp,,,data/crawl/squid/old_hunk_6470.cpp,data/crawl/squid/new_hunk_6470.cpp,50,-1,"storeAppendPrintf(sentry, ""icp.pkts_sent = %d\n"",
	f->icp.pkts_sent);",,"[""removeLog""]","[[""storeAppendPrintf"", ""sentry"", ""icp"", ""pkts_sent"", ""%d\\n"", ""f"", ""icp"", ""pkts_sent""], []]",[-2165521125979986932],6682,31680.0,2
https://github.com/squid-cache/squid/commit/071a3ae79623f644f3544044423946dd3a35710b,10 Apr 1998,Cleaned up ICP logging/counting and ICP/CD stats output,269,data/crawl/squid/hunk_6469.cpp,,,data/crawl/squid/old_hunk_6469.cpp,data/crawl/squid/new_hunk_6469.cpp,-1,39,,"storeAppendPrintf(sentry, ""cd.store_memory = %d\n"",
        (int) (store_digest ? store_digest->mask_size/1024 : 0));","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""cd"", ""store_memory"", ""%d\\n"", ""int"", ""store_digest"", ""store_digest"", ""mask_size/1024"", ""0""]]",[-23460585845524430750],6681,720.0,2
https://github.com/squid-cache/squid/commit/071a3ae79623f644f3544044423946dd3a35710b,10 Apr 1998,Cleaned up ICP logging/counting and ICP/CD stats output,269,data/crawl/squid/hunk_6469.cpp,,,data/crawl/squid/old_hunk_6469.cpp,data/crawl/squid/new_hunk_6469.cpp,-1,31,,"storeAppendPrintf(sentry, ""cd.times_used = %d\n"",
        f->cd.times_used);","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""cd"", ""times_used"", ""%d\\n"", ""f"", ""cd"", ""times_used""]]",[23617377622427395332],6680,720.0,2
https://github.com/squid-cache/squid/commit/071a3ae79623f644f3544044423946dd3a35710b,10 Apr 1998,Cleaned up ICP logging/counting and ICP/CD stats output,269,data/crawl/squid/hunk_6469.cpp,,,data/crawl/squid/old_hunk_6469.cpp,data/crawl/squid/new_hunk_6469.cpp,-1,29,,"storeAppendPrintf(sentry, ""icp.times_used = %d\n"",
        f->icp.times_used);","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""icp"", ""times_used"", ""%d\\n"", ""f"", ""icp"", ""times_used""]]",[8481304728461637724],6679,720.0,2
https://github.com/squid-cache/squid/commit/071a3ae79623f644f3544044423946dd3a35710b,10 Apr 1998,Cleaned up ICP logging/counting and ICP/CD stats output,269,data/crawl/squid/hunk_6468.cpp,,,data/crawl/squid/old_hunk_6468.cpp,data/crawl/squid/new_hunk_6468.cpp,10,-1,"storeAppendPrintf(sentry, ""client_http.hit_svc_time histogram:\n"");",,"[""removeLog""]","[[""storeAppendPrintf"", ""sentry"", ""client_http"", ""hit_svc_time"", ""histogram"", ""\\n""], []]",[-8195476901053635300],6678,31680.0,2
https://github.com/squid-cache/squid/commit/071a3ae79623f644f3544044423946dd3a35710b,10 Apr 1998,Cleaned up ICP logging/counting and ICP/CD stats output,269,data/crawl/squid/hunk_6468.cpp,,,data/crawl/squid/old_hunk_6468.cpp,data/crawl/squid/new_hunk_6468.cpp,8,-1,"storeAppendPrintf(sentry, ""client_http.nm_svc_time histogram:\n"");",,"[""removeLog""]","[[""storeAppendPrintf"", ""sentry"", ""client_http"", ""nm_svc_time"", ""histogram"", ""\\n""], []]",[-3132268931358861387],6677,31680.0,2
https://github.com/squid-cache/squid/commit/071a3ae79623f644f3544044423946dd3a35710b,10 Apr 1998,Cleaned up ICP logging/counting and ICP/CD stats output,269,data/crawl/squid/hunk_6468.cpp,,,data/crawl/squid/old_hunk_6468.cpp,data/crawl/squid/new_hunk_6468.cpp,6,-1,"storeAppendPrintf(sentry, ""client_http.miss_svc_time histogram:\n"");",,"[""removeLog""]","[[""storeAppendPrintf"", ""sentry"", ""client_http"", ""miss_svc_time"", ""histogram"", ""\\n""], []]",[-12266767035431664052],6676,31680.0,2
https://github.com/squid-cache/squid/commit/071a3ae79623f644f3544044423946dd3a35710b,10 Apr 1998,Cleaned up ICP logging/counting and ICP/CD stats output,269,data/crawl/squid/hunk_6468.cpp,,,data/crawl/squid/old_hunk_6468.cpp,data/crawl/squid/new_hunk_6468.cpp,4,-1,"storeAppendPrintf(sentry, ""client_http.all_svc_time histogram:\n"");",,"[""removeLog""]","[[""storeAppendPrintf"", ""sentry"", ""client_http"", ""all_svc_time"", ""histogram"", ""\\n""], []]",[-1431764734794782766],6675,31680.0,2
https://github.com/squid-cache/squid/commit/071a3ae79623f644f3544044423946dd3a35710b,10 Apr 1998,Cleaned up ICP logging/counting and ICP/CD stats output,269,data/crawl/squid/hunk_6467.cpp,,,data/crawl/squid/old_hunk_6467.cpp,data/crawl/squid/new_hunk_6467.cpp,-1,28,,"storeAppendPrintf(sentry, ""icp.query_svc_time histogram:\n"");","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""icp"", ""query_svc_time"", ""histogram"", ""\\n""]]",[-3662707251514409093],6674,31680.0,2
https://github.com/squid-cache/squid/commit/071a3ae79623f644f3544044423946dd3a35710b,10 Apr 1998,Cleaned up ICP logging/counting and ICP/CD stats output,269,data/crawl/squid/hunk_6467.cpp,,,data/crawl/squid/old_hunk_6467.cpp,data/crawl/squid/new_hunk_6467.cpp,-1,24,,"storeAppendPrintf(sentry, ""\ncd.client_svc_time histogram:\n"");","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""\\ncd"", ""client_svc_time"", ""histogram"", ""\\n""]]",[-9875232530174705395],6673,720.0,2
https://github.com/squid-cache/squid/commit/071a3ae79623f644f3544044423946dd3a35710b,10 Apr 1998,Cleaned up ICP logging/counting and ICP/CD stats output,269,data/crawl/squid/hunk_6467.cpp,,,data/crawl/squid/old_hunk_6467.cpp,data/crawl/squid/new_hunk_6467.cpp,-1,22,,"storeAppendPrintf(sentry, ""\nicp.client_svc_time histogram:\n"");","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""\\nicp"", ""client_svc_time"", ""histogram"", ""\\n""]]",[-4939705136421208611],6672,720.0,2
https://github.com/squid-cache/squid/commit/071a3ae79623f644f3544044423946dd3a35710b,10 Apr 1998,Cleaned up ICP logging/counting and ICP/CD stats output,269,data/crawl/squid/hunk_6467.cpp,,,data/crawl/squid/old_hunk_6467.cpp,data/crawl/squid/new_hunk_6467.cpp,-1,20,,"storeAppendPrintf(sentry, ""\nicp.reply_svc_time histogram:\n"");","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""\\nicp"", ""reply_svc_time"", ""histogram"", ""\\n""]]",[-1397121129752594633],6671,720.0,2
https://github.com/squid-cache/squid/commit/071a3ae79623f644f3544044423946dd3a35710b,10 Apr 1998,Cleaned up ICP logging/counting and ICP/CD stats output,269,data/crawl/squid/hunk_6467.cpp,,,data/crawl/squid/old_hunk_6467.cpp,data/crawl/squid/new_hunk_6467.cpp,-1,18,,"storeAppendPrintf(sentry, ""\nicp.query_svc_time histogram:\n"");","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""\\nicp"", ""query_svc_time"", ""histogram"", ""\\n""]]",[3666560972374436631],6670,720.0,2
https://github.com/squid-cache/squid/commit/69c95dd31c99255c7d281223688d5f3a8cb29a20,14 May 1998,"Transitioning Cache Digests from ""experimental"" to fundamental.
Removed a lot of stats collection, espeically large histograms.
Made peerDigestInit() called from an event, instead of being
called directly -- this avoids some recursion.
The selection algorithm is still kind of hard coded as follows:
	cache digests
	netdb (if CD's miss)
	ICP (if netdb has no RTT data)",373,data/crawl/squid/hunk_6423.cpp,,,data/crawl/squid/old_hunk_6423.cpp,data/crawl/squid/new_hunk_6423.cpp,16,-1,"storeAppendPrintf(sentry, ""\ncd.client_svc_time histogram:\n"");",,"[""removeLog""]","[[""storeAppendPrintf"", ""sentry"", ""\\ncd"", ""client_svc_time"", ""histogram"", ""\\n""], []]",[9875232530174705395],6669,24480.0,2
https://github.com/squid-cache/squid/commit/69c95dd31c99255c7d281223688d5f3a8cb29a20,14 May 1998,"Transitioning Cache Digests from ""experimental"" to fundamental.
Removed a lot of stats collection, espeically large histograms.
Made peerDigestInit() called from an event, instead of being
called directly -- this avoids some recursion.
The selection algorithm is still kind of hard coded as follows:
	cache digests
	netdb (if CD's miss)
	ICP (if netdb has no RTT data)",373,data/crawl/squid/hunk_6423.cpp,,,data/crawl/squid/old_hunk_6423.cpp,data/crawl/squid/new_hunk_6423.cpp,12,-1,"storeAppendPrintf(sentry, ""\nicp.client_svc_time histogram:\n"");",,"[""removeLog""]","[[""storeAppendPrintf"", ""sentry"", ""\\nicp"", ""client_svc_time"", ""histogram"", ""\\n""], []]",[4939705136421208611],6668,24480.0,2
https://github.com/squid-cache/squid/commit/69c95dd31c99255c7d281223688d5f3a8cb29a20,14 May 1998,"Transitioning Cache Digests from ""experimental"" to fundamental.
Removed a lot of stats collection, espeically large histograms.
Made peerDigestInit() called from an event, instead of being
called directly -- this avoids some recursion.
The selection algorithm is still kind of hard coded as follows:
	cache digests
	netdb (if CD's miss)
	ICP (if netdb has no RTT data)",373,data/crawl/squid/hunk_6422.cpp,,,data/crawl/squid/old_hunk_6422.cpp,data/crawl/squid/new_hunk_6422.cpp,22,-1,"storeAppendPrintf(sentry, ""icp.client_median_svc_time = %f seconds\n"",
	x / 1000.0);",,"[""removeLog""]","[[""storeAppendPrintf"", ""sentry"", ""icp"", ""client_median_svc_time"", ""%f"", ""seconds\\n"", ""x"", ""/"", ""1000"", ""0""], []]",[-3985394527082167644],6667,24480.0,2
https://github.com/squid-cache/squid/commit/69c95dd31c99255c7d281223688d5f3a8cb29a20,14 May 1998,"Transitioning Cache Digests from ""experimental"" to fundamental.
Removed a lot of stats collection, espeically large histograms.
Made peerDigestInit() called from an event, instead of being
called directly -- this avoids some recursion.
The selection algorithm is still kind of hard coded as follows:
	cache digests
	netdb (if CD's miss)
	ICP (if netdb has no RTT data)",373,data/crawl/squid/hunk_6422.cpp,,,data/crawl/squid/old_hunk_6422.cpp,data/crawl/squid/new_hunk_6422.cpp,14,-1,"storeAppendPrintf(sentry, ""cd.client_median_svc_time = %f seconds\n"",
	x / 1000.0);",,"[""removeLog""]","[[""storeAppendPrintf"", ""sentry"", ""cd"", ""client_median_svc_time"", ""%f"", ""seconds\\n"", ""x"", ""/"", ""1000"", ""0""], []]",[-11553430974065046448],6666,24480.0,2
https://github.com/squid-cache/squid/commit/e17d81d3617f3a7ee4ad392767c07bd3ddfc36d6,03 Jun 1998,"- code cleanup (Ranges)
- added HDR_IF_RANGE field (no actual processing yet)",131,data/crawl/squid/hunk_6375.cpp,,,data/crawl/squid/old_hunk_6375.cpp,data/crawl/squid/new_hunk_6375.cpp,-1,56,,"httpHeaderPutStrf(hdr, HDR_CONTENT_TYPE,
		""multipart/byteranges; boundary=\""%s\"""",
		strBuf(http->range_iter.boundary));","[""addLog""]","[[], [""httpHeaderPutStrf"", ""hdr"", ""HDR_CONTENT_TYPE"", ""multipart/byteranges"", ""boundary"", ""\\"", ""%s\\"", ""strBuf"", ""http"", ""range_iter"", ""boundary""]]",[-6063074112591328951],6665,0.0,2
https://github.com/squid-cache/squid/commit/1d21d91da41c51042b444b98958cb4a357a92869,06 Jun 1998,"- changed internal structure of HttpBody to use MemBuf;
  no more inconsistencies with body.size
- removed HTML tags from mgr:http_headers dump",149,data/crawl/squid/hunk_6354.cpp,,,data/crawl/squid/old_hunk_6354.cpp,data/crawl/squid/new_hunk_6354.cpp,8,8,"storeAppendPrintf(e, ""<h3>Cache-control directives distribution</h3>\n"");","storeAppendPrintf(e, ""Cache-control directives distribution\n"");","[""updateContent""]","[[""h3"", ""distribution"", ""/h3"", ""\\n""], [""distribution\\n""]]",[-3062110297471260224],6664,0.0,2
https://github.com/squid-cache/squid/commit/d6fd3381ce2715be4fde056819d20cf0756a1510,15 Jul 1998,"Added time_t StoreEntry->refresh for cache digests.
Don't need to compile a lot of the store_digest code when USE_CACHE_DIGESTS
is not set",151,data/crawl/squid/hunk_6344.cpp,,,data/crawl/squid/old_hunk_6344.cpp,data/crawl/squid/new_hunk_6344.cpp,-1,85,,"storeAppendPrintf(e, ""store digest: disabled.\n"");","[""addLog""]","[[], [""storeAppendPrintf"", ""e"", ""store"", ""digest"", ""disabled"", ""\\n""]]",[4525747576557647335],6663,74160.0,2
https://github.com/squid-cache/squid/commit/d6fd3381ce2715be4fde056819d20cf0756a1510,15 Jul 1998,"Added time_t StoreEntry->refresh for cache digests.
Don't need to compile a lot of the store_digest code when USE_CACHE_DIGESTS
is not set",151,data/crawl/squid/hunk_6344.cpp,,,data/crawl/squid/old_hunk_6344.cpp,data/crawl/squid/new_hunk_6344.cpp,-1,81,,"storeAppendPrintf(e, ""\t collisions: on add: %.2f %% on rej: %.2f %%\n"",
	    xpercent(sd_stats.add_coll_count, sd_stats.add_count),
	    xpercent(sd_stats.rej_coll_count, sd_stats.rej_count));","[""addLog""]","[[], [""storeAppendPrintf"", ""e"", ""\\t"", ""collisions"", ""on"", ""add"", ""%"", ""2f"", ""%%"", ""on"", ""rej"", ""%"", ""2f"", ""%%\\n"", ""xpercent"", ""sd_stats"", ""add_coll_count"", ""sd_stats"", ""add_count"", ""xpercent"", ""sd_stats"", ""rej_coll_count"", ""sd_stats"", ""rej_count""]]",[-19536262234481106060],6662,60480.0,2
https://github.com/squid-cache/squid/commit/d6fd3381ce2715be4fde056819d20cf0756a1510,15 Jul 1998,"Added time_t StoreEntry->refresh for cache digests.
Don't need to compile a lot of the store_digest code when USE_CACHE_DIGESTS
is not set",151,data/crawl/squid/hunk_6344.cpp,,,data/crawl/squid/old_hunk_6344.cpp,data/crawl/squid/new_hunk_6344.cpp,-1,76,,"storeAppendPrintf(e, ""\t added: %d rejected: %d ( %.2f %%) del-ed: %d\n"",
	    sd_stats.add_count,
	    sd_stats.rej_count,
	    xpercent(sd_stats.rej_count, sd_stats.rej_count + sd_stats.add_count),
	    sd_stats.del_count);","[""addLog""]","[[], [""storeAppendPrintf"", ""e"", ""\\t"", ""added"", ""%d"", ""rejected"", ""%d"", ""%"", ""2f"", ""%%"", ""del"", ""ed"", ""%d\\n"", ""sd_stats"", ""add_count"", ""sd_stats"", ""rej_count"", ""xpercent"", ""sd_stats"", ""rej_count"", ""sd_stats"", ""rej_count"", ""sd_stats"", ""add_count"", ""sd_stats"", ""del_count""]]",[-45720816781997758075],6661,60480.0,2
https://github.com/squid-cache/squid/commit/6a78c18e34cfeeb6ec4e045145dd3d1c32c1e773,29 Jul 1998,"Fixed some restart bugs with dnsservers.   Because of switch to
events, we were calling the dnsShutdownServers func AFTER the
new dnsservers had been allocated.  Using a non-NULL callback
data when registering the event fixes this.

Also added fatal() checks for too few running dnsservers and too many
queued IP/FQDN lookups.",87,data/crawl/squid/hunk_6324.cpp,,,data/crawl/squid/old_hunk_6324.cpp,data/crawl/squid/new_hunk_6324.cpp,-1,17,,"fatal(""Too many queued DNS lookups"");","[""addLog""]","[[], [""fatal"", ""Too"", ""many"", ""queued"", ""DNS"", ""lookups""]]",[-16689355757844038674],6660,0.0,2
https://github.com/squid-cache/squid/commit/6a78c18e34cfeeb6ec4e045145dd3d1c32c1e773,29 Jul 1998,"Fixed some restart bugs with dnsservers.   Because of switch to
events, we were calling the dnsShutdownServers func AFTER the
new dnsservers had been allocated.  Using a non-NULL callback
data when registering the event fixes this.

Also added fatal() checks for too few running dnsservers and too many
queued IP/FQDN lookups.",87,data/crawl/squid/hunk_6322.cpp,,,data/crawl/squid/old_hunk_6322.cpp,data/crawl/squid/new_hunk_6322.cpp,-1,17,,"fatal(""Too few DNSSERVER processes are running"");","[""addLog""]","[[], [""fatal"", ""Too"", ""few"", ""DNSSERVER"", ""processes"", ""are"", ""running""]]",[-27371787301548636945],6659,0.0,2
https://github.com/squid-cache/squid/commit/f52a7d75fa0fa951a3b0a1481d531c8b34367976,18 Aug 1998,moved from ../src,448,data/crawl/squid/hunk_6306.cpp,,,data/crawl/squid/old_hunk_6306.cpp,data/crawl/squid/new_hunk_6306.cpp,-1,389,,"printf(""driver finished.\n"");","[""addLog""]","[[], [""printf"", ""driver"", ""finished"", ""\\n""]]",[10937235630725012141],6658,123840.0,2
https://github.com/squid-cache/squid/commit/f52a7d75fa0fa951a3b0a1481d531c8b34367976,18 Aug 1998,moved from ../src,448,data/crawl/squid/hunk_6306.cpp,,,data/crawl/squid/old_hunk_6306.cpp,data/crawl/squid/new_hunk_6306.cpp,-1,379,,"printf(""hash_delete error\n"");","[""addLog""]","[[], [""printf"", ""hash_delete"", ""error\\n""]]",[6171682263091252971],6657,123840.0,2
https://github.com/squid-cache/squid/commit/f52a7d75fa0fa951a3b0a1481d531c8b34367976,18 Aug 1998,moved from ../src,448,data/crawl/squid/hunk_6306.cpp,,,data/crawl/squid/old_hunk_6306.cpp,data/crawl/squid/new_hunk_6306.cpp,-1,377,,"printf(""deleting %s from %d\n"", todelete, hid);","[""addLog""]","[[], [""printf"", ""deleting"", ""%s"", ""from"", ""%d\\n"", ""todelete"", ""hid""]]",[4009515419176151352],6656,123840.0,2
https://github.com/squid-cache/squid/commit/f52a7d75fa0fa951a3b0a1481d531c8b34367976,18 Aug 1998,moved from ../src,448,data/crawl/squid/hunk_6306.cpp,,,data/crawl/squid/old_hunk_6306.cpp,data/crawl/squid/new_hunk_6306.cpp,-1,362,,"printf(""Inserting '%s' for item %p to hash table: %d\n"",
	    buf, buf, hid);","[""addLog""]","[[], [""printf"", ""Inserting"", ""%s"", ""for"", ""item"", ""%p"", ""to"", ""hash"", ""table"", ""%d\\n"", ""buf"", ""buf"", ""hid""]]",[2120647982279806496],6655,123840.0,2
https://github.com/squid-cache/squid/commit/f52a7d75fa0fa951a3b0a1481d531c8b34367976,18 Aug 1998,moved from ../src,448,data/crawl/squid/hunk_6306.cpp,,,data/crawl/squid/old_hunk_6306.cpp,data/crawl/squid/new_hunk_6306.cpp,-1,358,,"printf(""done creating hash table: %d\n"", hid);","[""addLog""]","[[], [""printf"", ""done"", ""creating"", ""hash"", ""table"", ""%d\\n"", ""hid""]]",[3391781315007474814],6654,123840.0,2
https://github.com/squid-cache/squid/commit/f52a7d75fa0fa951a3b0a1481d531c8b34367976,18 Aug 1998,moved from ../src,448,data/crawl/squid/hunk_6306.cpp,,,data/crawl/squid/old_hunk_6306.cpp,data/crawl/squid/new_hunk_6306.cpp,-1,355,,"printf(""hash_create error.\n"");","[""addLog""]","[[], [""printf"", ""hash_create"", ""error"", ""\\n""]]",[14569196363983418386],6653,123840.0,2
https://github.com/squid-cache/squid/commit/f52a7d75fa0fa951a3b0a1481d531c8b34367976,18 Aug 1998,moved from ../src,448,data/crawl/squid/hunk_6306.cpp,,,data/crawl/squid/old_hunk_6306.cpp,data/crawl/squid/new_hunk_6306.cpp,-1,353,,"printf(""creating hash table\n"");","[""addLog""]","[[], [""printf"", ""creating"", ""hash"", ""table\\n""]]",[19631342285717887761],6652,123840.0,2
https://github.com/squid-cache/squid/commit/f52a7d75fa0fa951a3b0a1481d531c8b34367976,18 Aug 1998,moved from ../src,448,data/crawl/squid/hunk_6306.cpp,,,data/crawl/squid/old_hunk_6306.cpp,data/crawl/squid/new_hunk_6306.cpp,-1,351,,"printf(""init\n"");","[""addLog""]","[[], [""printf"", ""init\\n""]]",[4283994461307984809],6651,123840.0,2
https://github.com/squid-cache/squid/commit/1d62076534634576e2979da61bbdbc7ae4d498fd,18 Aug 1998,adding,456,data/crawl/squid/hunk_6304.cpp,,,data/crawl/squid/old_hunk_6304.cpp,data/crawl/squid/new_hunk_6304.cpp,-1,448,,"storeAppendPrintf(sentry, ""use histogram:\n"");","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""use"", ""histogram"", ""\\n""]]",[-1512619810490720141],6650,552960.0,2
https://github.com/squid-cache/squid/commit/e1e641f9d4e49c04986d40c28dac687552749af8,15 Sep 1998,"relocate all-redirectors-have-exited check.
removed NRedirectorsOpen == 0 assertion",8,data/crawl/squid/hunk_6282.cpp,,,data/crawl/squid/old_hunk_6282.cpp,data/crawl/squid/new_hunk_6282.cpp,-1,5,,"fatal_dump(""All redirectors have exited!"");","[""addLog""]","[[], [""fatal_dump"", ""All"", ""redirectors"", ""have"", ""exited""]]",[15506471005322002107],6649,569520.0,2
https://github.com/squid-cache/squid/commit/2c4f7ab251a01835052ec9e0e9cfb80fb45dcc1f,24 Sep 1998,add hash_last(),101,data/crawl/squid/hunk_6255.cpp,,,data/crawl/squid/old_hunk_6255.cpp,data/crawl/squid/new_hunk_6255.cpp,3,3,"storeAppendPrintf(sentry, ""store_files_cleaned = %f/sec\n"",
	XAVG(store_files_cleaned));","storeAppendPrintf(sentry, ""swap_files_cleaned = %f/sec\n"",
	XAVG(swap_files_cleaned));","[""updateVariable"", ""updateContent""]","[[""store_files_cleaned"", ""store_files_cleaned""], [""swap_files_cleaned"", ""swap_files_cleaned""]]",[-24213249133141418830],6648,0.0,2
https://github.com/squid-cache/squid/commit/74addf6ce98ca89de0d44d51bccc45c69d728f1f,10 Oct 1998,Moved many common dns/redirect/authenticate functions into helper.c,2045,data/crawl/squid/hunk_6253.cpp,,,data/crawl/squid/old_hunk_6253.cpp,data/crawl/squid/new_hunk_6253.cpp,134,-1,"storeAppendPrintf(sentry, ""Redirector Statistics:\n"");",,"[""removeLog""]","[[""storeAppendPrintf"", ""sentry"", ""Redirector"", ""Statistics"", ""\\n""], []]",[-2388355921916353954],6647,176400.0,2
https://github.com/squid-cache/squid/commit/74addf6ce98ca89de0d44d51bccc45c69d728f1f,10 Oct 1998,Moved many common dns/redirect/authenticate functions into helper.c,2045,data/crawl/squid/hunk_6253.cpp,,,data/crawl/squid/old_hunk_6253.cpp,data/crawl/squid/new_hunk_6253.cpp,22,-1,"fatal_dump(""All redirectors have exited!"");",,"[""removeLog""]","[[""fatal_dump"", ""All"", ""redirectors"", ""have"", ""exited""], []]",[-15506471005322002107],6646,18000.0,2
https://github.com/squid-cache/squid/commit/74addf6ce98ca89de0d44d51bccc45c69d728f1f,10 Oct 1998,Moved many common dns/redirect/authenticate functions into helper.c,2045,data/crawl/squid/hunk_6252.cpp,,,data/crawl/squid/old_hunk_6252.cpp,data/crawl/squid/new_hunk_6252.cpp,-1,37,,"storeAppendPrintf(sentry, ""Redirector Statistics:\n"");","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""Redirector"", ""Statistics"", ""\\n""]]",[2388355921916353954],6645,591120.0,2
https://github.com/squid-cache/squid/commit/74addf6ce98ca89de0d44d51bccc45c69d728f1f,10 Oct 1998,Moved many common dns/redirect/authenticate functions into helper.c,2045,data/crawl/squid/hunk_6247.cpp,,,data/crawl/squid/old_hunk_6247.cpp,data/crawl/squid/new_hunk_6247.cpp,-1,121,,"storeAppendPrintf(sentry, ""%7s\t%7s\t%11s\t%s\t%7s\t%7s\n"",
	""#"",
	""FD"",
	""# Requests"",
	""Flags"",
	""Time"",
	""Offset"");","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""%7s\\t%7s\\t%11s\\t%s\\t%7s\\t%7s\\n"", ""FD"", ""Requests"", ""Flags"", ""Time"", ""Offset""]]",[17200637322797013196],6644,136800.0,2
https://github.com/squid-cache/squid/commit/74addf6ce98ca89de0d44d51bccc45c69d728f1f,10 Oct 1998,Moved many common dns/redirect/authenticate functions into helper.c,2045,data/crawl/squid/hunk_6246.cpp,,,data/crawl/squid/old_hunk_6246.cpp,data/crawl/squid/new_hunk_6246.cpp,3,-1,"storeAppendPrintf(sentry, ""pending queue length: %d\n"", queue_length);",,"[""removeLog""]","[[""storeAppendPrintf"", ""sentry"", ""pending"", ""queue"", ""length"", ""%d\\n"", ""queue_length""], []]",[-24554605888135001151],6643,0.0,2
https://github.com/squid-cache/squid/commit/74addf6ce98ca89de0d44d51bccc45c69d728f1f,10 Oct 1998,Moved many common dns/redirect/authenticate functions into helper.c,2045,data/crawl/squid/hunk_6245.cpp,,,data/crawl/squid/old_hunk_6245.cpp,data/crawl/squid/new_hunk_6245.cpp,20,-1,"fatal(""Too many queued DNS lookups"");",,"[""removeLog""]","[[""fatal"", ""Too"", ""many"", ""queued"", ""DNS"", ""lookups""], []]",[16689355757844038674],6642,0.0,2
https://github.com/squid-cache/squid/commit/74addf6ce98ca89de0d44d51bccc45c69d728f1f,10 Oct 1998,Moved many common dns/redirect/authenticate functions into helper.c,2045,data/crawl/squid/hunk_6243.cpp,,,data/crawl/squid/old_hunk_6243.cpp,data/crawl/squid/new_hunk_6243.cpp,412,-1,"storeAppendPrintf(sentry, ""use histogram:\n"");",,"[""removeLog""]","[[""storeAppendPrintf"", ""sentry"", ""use"", ""histogram"", ""\\n""], []]",[1512619810490720141],6641,0.0,2
https://github.com/squid-cache/squid/commit/74addf6ce98ca89de0d44d51bccc45c69d728f1f,10 Oct 1998,Moved many common dns/redirect/authenticate functions into helper.c,2045,data/crawl/squid/hunk_6243.cpp,,,data/crawl/squid/old_hunk_6243.cpp,data/crawl/squid/new_hunk_6243.cpp,212,46,"fatal_dump(""authenticateStart: NULL auth_user"");",assert(auth_user);,"[""updateLog"", ""removeContent"", ""addVariable""]","[[""fatal_dump"", ""authenticateStart"", ""NULL""], [""assert""]]",[21379231521988458832],6640,0.0,2
https://github.com/squid-cache/squid/commit/dba79ac56de7e563b80a5cac8678ee41ffa0d4a6,12 Nov 1998,Squid SNMP code rewrite,1686,data/crawl/squid/hunk_6233.cpp,,,data/crawl/squid/old_hunk_6233.cpp,data/crawl/squid/new_hunk_6233.cpp,16,-1,"storeAppendPrintf(entry, ""%s %s %s %s%s\n"",
		    name, cp->name,
		    head->allow ? ""Allow"" : ""Deny"",
		    l->op ? null_string : ""!"",
		    l->acl->name);",,"[""removeLog""]","[[""storeAppendPrintf"", ""entry"", ""%s"", ""%s"", ""%s"", ""%s%s\\n"", ""name"", ""cp"", ""name"", ""head"", ""allow"", ""Allow"", ""Deny"", ""l"", ""op"", ""null_string"", ""l"", ""acl"", ""name""], []]",[-10054000873263661766],6639,0.0,2
https://github.com/squid-cache/squid/commit/c68e9c6b55d5f316a13904483017913a78a4f7b2,12 Nov 1998,2.1 branch merge,3372,data/crawl/squid/hunk_6227.cpp,,,data/crawl/squid/old_hunk_6227.cpp,data/crawl/squid/new_hunk_6227.cpp,-1,10,,"fprintf(stderr, ""-s is not supported on this resolver\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""s"", ""is"", ""not"", ""supported"", ""on"", ""this"", ""resolver\\n""]]",[-9055878808435272472],6638,156960.0,2
https://github.com/squid-cache/squid/commit/6e5ae4a4f3314309a6e851cf295e157e40aab01c,12 Jan 1999,"Small change of Squid output for FTP
Henrik Nordstrom
Andrew Filonov <aef@shu.smolensk.su>",43,data/crawl/squid/hunk_6198.cpp,,,data/crawl/squid/old_hunk_6198.cpp,data/crawl/squid/new_hunk_6198.cpp,-1,17,,"storeAppendPrintf(e, ""%c"", ftpState->title_url[k++]);","[""addLog""]","[[], [""storeAppendPrintf"", ""e"", ""%c"", ""ftpState"", ""title_url[k"", ""]""]]",[20025760452776012787],6637,0.0,2
https://github.com/squid-cache/squid/commit/6e5ae4a4f3314309a6e851cf295e157e40aab01c,12 Jan 1999,"Small change of Squid output for FTP
Henrik Nordstrom
Andrew Filonov <aef@shu.smolensk.su>",43,data/crawl/squid/hunk_6198.cpp,,,data/crawl/squid/old_hunk_6198.cpp,data/crawl/squid/new_hunk_6198.cpp,-1,12,,"storeAppendPrintf(e, ""%c"", ftpState->title_url[k]);","[""addLog""]","[[], [""storeAppendPrintf"", ""e"", ""%c"", ""ftpState"", ""title_url[k]""]]",[15019211266183550861],6636,0.0,2
https://github.com/squid-cache/squid/commit/1cfdbcf024e40720d2b358414e6327fa8de958b1,12 Jan 1999,"This patch fully transforms proxy_auth into a ACL type, allowing both
allow and deny in any order suitable.

Authentication is requested from the user if:
* proxy_auth is used and no valid authentication header is present.
* wrong password is used
* denied by a proxy_auth ACL

A positive sideeffect is that is is also possible to use deny_info on
proxy_auth ACLs to change the message returned. It also fixes the
problem where proxy_auth user wasn't logged if the proxy_auth user info
wasn't cached.

This patch fully replaces my previous attemt.

There is a small collision with one of my other changes in proto.h, but
I assume that you know how to resolve this.",244,data/crawl/squid/hunk_6182.cpp,,,data/crawl/squid/old_hunk_6182.cpp,data/crawl/squid/new_hunk_6182.cpp,-1,12,,"httpHeaderPutStrf(&rep->header, HDR_WWW_AUTHENTICATE,
	    proxy_auth_challenge_fmt, Config.proxyAuthRealm);","[""addLog""]","[[], [""httpHeaderPutStrf"", ""&rep"", ""header"", ""HDR_WWW_AUTHENTICATE"", ""proxy_auth_challenge_fmt"", ""Config"", ""proxyAuthRealm""]]",[1219914597358558908],6635,43920.0,2
https://github.com/squid-cache/squid/commit/1cfdbcf024e40720d2b358414e6327fa8de958b1,12 Jan 1999,"This patch fully transforms proxy_auth into a ACL type, allowing both
allow and deny in any order suitable.

Authentication is requested from the user if:
* proxy_auth is used and no valid authentication header is present.
* wrong password is used
* denied by a proxy_auth ACL

A positive sideeffect is that is is also possible to use deny_info on
proxy_auth ACLs to change the message returned. It also fixes the
problem where proxy_auth user wasn't logged if the proxy_auth user info
wasn't cached.

This patch fully replaces my previous attemt.

There is a small collision with one of my other changes in proto.h, but
I assume that you know how to resolve this.",244,data/crawl/squid/hunk_6182.cpp,,,data/crawl/squid/old_hunk_6182.cpp,data/crawl/squid/new_hunk_6182.cpp,-1,7,,"httpHeaderPutStrf(&rep->header, HDR_PROXY_AUTHENTICATE,
	    proxy_auth_challenge_fmt, Config.proxyAuthRealm);","[""addLog""]","[[], [""httpHeaderPutStrf"", ""&rep"", ""header"", ""HDR_PROXY_AUTHENTICATE"", ""proxy_auth_challenge_fmt"", ""Config"", ""proxyAuthRealm""]]",[-5625760115274389363],6634,115920.0,2
https://github.com/squid-cache/squid/commit/59715b38e9e43d20a1092ee0d67c316365726e95,30 Jan 1999,luyer's mega delay pools rewrite -- without ugly delayPoolsReconfigure(),1419,data/crawl/squid/hunk_6165.cpp,,,data/crawl/squid/old_hunk_6165.cpp,data/crawl/squid/new_hunk_6165.cpp,-1,57,,"storeAppendPrintf(sentry, ""Not used yet."");","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""Not"", ""used"", ""yet""]]",[10673142881662984130],6633,0.0,2
https://github.com/squid-cache/squid/commit/59715b38e9e43d20a1092ee0d67c316365726e95,30 Jan 1999,luyer's mega delay pools rewrite -- without ugly delayPoolsReconfigure(),1419,data/crawl/squid/hunk_6165.cpp,,,data/crawl/squid/old_hunk_6165.cpp,data/crawl/squid/new_hunk_6165.cpp,-1,43,,"storeAppendPrintf(sentry, ""\t\tRate: %d\n"", rate->individual.restore_bps);","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""\\t\\tRate"", ""%d\\n"", ""rate"", ""individual"", ""restore_bps""]]",[5241027730013828207],6632,0.0,2
https://github.com/squid-cache/squid/commit/59715b38e9e43d20a1092ee0d67c316365726e95,30 Jan 1999,luyer's mega delay pools rewrite -- without ugly delayPoolsReconfigure(),1419,data/crawl/squid/hunk_6165.cpp,,,data/crawl/squid/old_hunk_6165.cpp,data/crawl/squid/new_hunk_6165.cpp,-1,42,,"storeAppendPrintf(sentry, ""\t\tMax: %d\n"", rate->individual.max_bytes);","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""\\t\\tMax"", ""%d\\n"", ""rate"", ""individual"", ""max_bytes""]]",[17330750759199346676],6631,0.0,2
https://github.com/squid-cache/squid/commit/59715b38e9e43d20a1092ee0d67c316365726e95,30 Jan 1999,luyer's mega delay pools rewrite -- without ugly delayPoolsReconfigure(),1419,data/crawl/squid/hunk_6165.cpp,,,data/crawl/squid/old_hunk_6165.cpp,data/crawl/squid/new_hunk_6165.cpp,-1,41,,"storeAppendPrintf(sentry, ""\tIndividual:\n"");","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""\\tIndividual"", ""\\n""]]",[1571582944602162551],6630,0.0,2
https://github.com/squid-cache/squid/commit/59715b38e9e43d20a1092ee0d67c316365726e95,30 Jan 1999,luyer's mega delay pools rewrite -- without ugly delayPoolsReconfigure(),1419,data/crawl/squid/hunk_6165.cpp,,,data/crawl/squid/old_hunk_6165.cpp,data/crawl/squid/new_hunk_6165.cpp,-1,38,,"storeAppendPrintf(sentry, ""\tIndividual:\n\t\tDisabled.\n\n"");","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""\\tIndividual"", ""\\n\\t\\tDisabled"", ""\\n\\n""]]",[963377115780707463],6629,0.0,2
https://github.com/squid-cache/squid/commit/59715b38e9e43d20a1092ee0d67c316365726e95,30 Jan 1999,luyer's mega delay pools rewrite -- without ugly delayPoolsReconfigure(),1419,data/crawl/squid/hunk_6164.cpp,,,data/crawl/squid/old_hunk_6164.cpp,data/crawl/squid/new_hunk_6164.cpp,-1,24,,"fatalf(""delayBytesWanted: Invalid class %d\n"", class);","[""addLog""]","[[], [""fatalf"", ""delayBytesWanted"", ""Invalid"", ""class"", ""%d\\n"", ""class""]]",[21516186932988850730],6628,121680.0,2
https://github.com/squid-cache/squid/commit/c8366e06dda8d12145c0532b907aad3e35062502,30 Jun 1999,diskd compile fixes,29,data/crawl/squid/hunk_6100.cpp,,,data/crawl/squid/old_hunk_6100.cpp,data/crawl/squid/new_hunk_6100.cpp,3,3,"fprintf(debug_log, ""FATAL: %s\n"", message);","fprintf(debug_log, ""FATAL: pid %d %s\n"", (int) getpid(), message);","[""updateContent"", ""addVariable""]","[[], [""pid"", ""%d"", ""int"", ""getpid""]]",[-591694301434598510],6627,0.0,2
https://github.com/squid-cache/squid/commit/9bc73deb181f454f4e5597c67c5b6b40fd4d0f58,04 Oct 1999,2.3 branch merge,3942,data/crawl/squid/hunk_6093.cpp,,,data/crawl/squid/old_hunk_6093.cpp,data/crawl/squid/new_hunk_6093.cpp,3,3,"fprintf(debug_log, ""FATAL: pid %d %s\n"", (int) getpid(), message);","fprintf(debug_log, ""FATAL: %s\n"", message);","[""removeVariable"", ""updateContent""]","[[""pid"", ""%d"", ""int"", ""getpid""], []]",[591694301434598510],6626,0.0,2
https://github.com/squid-cache/squid/commit/cd748f27e5282c445ef4e13a0e2eabd19b6b906f,03 May 2000,"MODIO_1 commit. This change (including documentation) implements a more
modular storage directory system, which leaves object replacement and IO
up to the storage modules.

There is a lot of repeated code in the FS modules and some tidying up
is in the pipeline.

The documentation for this new API is in doc/Programming-Guide/prog-guide.sgml .",14498,data/crawl/squid/hunk_6046.cpp,,,data/crawl/squid/old_hunk_6046.cpp,data/crawl/squid/new_hunk_6046.cpp,-1,113,,"fprintf(stderr, ""%d FD %d: "", (int) mypid, fs->fd);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""%d"", ""FD"", ""%d"", ""int"", ""mypid"", ""fs"", ""fd""]]",[-26355200059149090861],6625,0.0,2
https://github.com/squid-cache/squid/commit/cd748f27e5282c445ef4e13a0e2eabd19b6b906f,03 May 2000,"MODIO_1 commit. This change (including documentation) implements a more
modular storage directory system, which leaves object replacement and IO
up to the storage modules.

There is a lot of repeated code in the FS modules and some tidying up
is in the pipeline.

The documentation for this new API is in doc/Programming-Guide/prog-guide.sgml .",14498,data/crawl/squid/hunk_6046.cpp,,,data/crawl/squid/old_hunk_6046.cpp,data/crawl/squid/new_hunk_6046.cpp,-1,103,,"fprintf(stderr, ""%d FD %d, offset %d: "", (int) mypid, fs->fd, r->offset);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""%d"", ""FD"", ""%d"", ""offset"", ""%d"", ""int"", ""mypid"", ""fs"", ""fd"", ""r"", ""offset""]]",[-13868897255681432771],6624,0.0,2
https://github.com/squid-cache/squid/commit/cd748f27e5282c445ef4e13a0e2eabd19b6b906f,03 May 2000,"MODIO_1 commit. This change (including documentation) implements a more
modular storage directory system, which leaves object replacement and IO
up to the storage modules.

There is a lot of repeated code in the FS modules and some tidying up
is in the pipeline.

The documentation for this new API is in doc/Programming-Guide/prog-guide.sgml .",14498,data/crawl/squid/hunk_6045.cpp,,,data/crawl/squid/old_hunk_6045.cpp,data/crawl/squid/new_hunk_6045.cpp,-1,679,,"fatal(""storeCossDirParse: invalid size value"");","[""addLog""]","[[], [""fatal"", ""storeCossDirParse"", ""invalid"", ""size"", ""value""]]",[-27578349261546309526],6623,0.0,2
https://github.com/squid-cache/squid/commit/cd748f27e5282c445ef4e13a0e2eabd19b6b906f,03 May 2000,"MODIO_1 commit. This change (including documentation) implements a more
modular storage directory system, which leaves object replacement and IO
up to the storage modules.

There is a lot of repeated code in the FS modules and some tidying up
is in the pipeline.

The documentation for this new API is in doc/Programming-Guide/prog-guide.sgml .",14498,data/crawl/squid/hunk_6044.cpp,,,data/crawl/squid/old_hunk_6044.cpp,data/crawl/squid/new_hunk_6044.cpp,-1,1633,,"storeAppendPrintf(sentry, ""Filesystem Space in use: %d/%d KB (%d%%)\n"",
            fsbtoblk((sfs.f_blocks - sfs.f_bfree), sfs.f_frsize, 1024),
            fsbtoblk(sfs.f_blocks, sfs.f_frsize, 1024),
            percent(sfs.f_blocks - sfs.f_bfree, sfs.f_blocks));","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""Filesystem"", ""Space"", ""in"", ""use"", ""%d/%d"", ""KB"", ""%d%%"", ""\\n"", ""fsbtoblk"", ""sfs"", ""f_blocks"", ""sfs"", ""f_bfree"", ""sfs"", ""f_frsize"", ""1024"", ""fsbtoblk"", ""sfs"", ""f_blocks"", ""sfs"", ""f_frsize"", ""1024"", ""percent"", ""sfs"", ""f_blocks"", ""sfs"", ""f_bfree"", ""sfs"", ""f_blocks""]]",[-22115632525380332169],6622,0.0,2
https://github.com/squid-cache/squid/commit/cd748f27e5282c445ef4e13a0e2eabd19b6b906f,03 May 2000,"MODIO_1 commit. This change (including documentation) implements a more
modular storage directory system, which leaves object replacement and IO
up to the storage modules.

There is a lot of repeated code in the FS modules and some tidying up
is in the pipeline.

The documentation for this new API is in doc/Programming-Guide/prog-guide.sgml .",14498,data/crawl/squid/hunk_6041.cpp,,,data/crawl/squid/old_hunk_6041.cpp,data/crawl/squid/new_hunk_6041.cpp,-1,69,,"fatalf(""Unknown cache_dir type '%s'\n"", type_str);","[""addLog""]","[[], [""fatalf"", ""Unknown"", ""cache_dir"", ""type"", ""%s"", ""\\n"", ""type_str""]]",[-1483333499295964032],6621,249840.0,2
https://github.com/squid-cache/squid/commit/6a566b9c9fa4d40f154a60497e332bc9067b4fc8,09 Jun 2000,"Modular policy implementation. See programmers guide for API details.

This also includes Adrians improved store I/O callback handler model.",3040,data/crawl/squid/hunk_6005.cpp,,,data/crawl/squid/old_hunk_6005.cpp,data/crawl/squid/new_hunk_6005.cpp,-1,65,,"fatal(""Heap Replacement: Unknown StoreEntry node type"");","[""addLog""]","[[], [""fatal"", ""Heap"", ""Replacement"", ""Unknown"", ""StoreEntry"", ""node"", ""type""]]",[-7271558282186230812],6620,0.0,2
https://github.com/squid-cache/squid/commit/23dc8acafc3dd7a63df446c9712ca11394757cb4,26 Jun 2000,"DW:
 - Added store swapin and swapout counters.
 - Changed the location of 'swap_files_cleaned' in StatCounters structure.",44,data/crawl/squid/hunk_5991.cpp,,,data/crawl/squid/old_hunk_5991.cpp,data/crawl/squid/new_hunk_5991.cpp,3,7,"storeAppendPrintf(sentry, ""swap_files_cleaned = %f/sec\n"",
	XAVG(swap_files_cleaned));","storeAppendPrintf(sentry, ""swap.files_cleaned = %f/sec\n"",
	XAVG(swap.files_cleaned));","[""removeVariable"", ""updateContent"", ""addVariable""]","[[""swap_files_cleaned"", ""swap_files_cleaned""], [""swap"", ""files_cleaned"", ""swap"", ""files_cleaned""]]",[6965924377237808200],6619,0.0,2
https://github.com/squid-cache/squid/commit/111b16cf035d5a7ae8f9e51edb47b0359db33e97,05 Oct 2000,"DW:
 - Removed stdio from net_db.c as suggested by Jens-S. Voeckler.",110,data/crawl/squid/hunk_5972.cpp,,,data/crawl/squid/old_hunk_5972.cpp,data/crawl/squid/new_hunk_5972.cpp,3,3,"fprintf(fp, "" %s"", x->name);","snprintf(rbuf + ro, RBUF_SZ - ro, "" %s"", x->name);","[""updateVariable"", ""updateLog"", ""addVariable""]","[[""fprintf"", ""fp""], [""snprintf"", ""rbuf"", ""ro"", ""RBUF_SZ"", ""ro""]]",[-5788974271948228355],6618,0.0,2
https://github.com/squid-cache/squid/commit/186477c1163c0718cf127587c1ad63a1e61906d9,01 Nov 2000,"DW:
 - Changed occurances of

        struct _foo {
            /* first two items must be same as hash_link */
            char *key;
            foo *next;
            ...
        };

   to

        struct _foo {
            hash_link hash;     /* must be first */
            ...
        };",385,data/crawl/squid/hunk_5957.cpp,,,data/crawl/squid/old_hunk_5957.cpp,data/crawl/squid/new_hunk_5957.cpp,3,3,"logfilePrintf(lf, "" %s"", x->name);","logfilePrintf(lf, "" %s"", hashKeyStr(&x->hash));","[""updateVariable"", ""addVariable""]","[[""x"", ""name""], [""hashKeyStr"", ""&x"", ""hash""]]",[17869657441361125622],6617,0.0,2
https://github.com/squid-cache/squid/commit/10270faab2bc84e50cde13431a6e6d1932966e5f,05 Nov 2000,"Cross-site scripting fixes by Robert Collins and Henrik Nordstrom

Everywhere where Squid inserts text received from the network into
a HTML page (error pages, FTP listings, Gopher listings, ...) care
must be taken to ensure that the text is properly encoded as HTML,
or a malicious user might be able to insert script code or other
HTML tags, and exploit the web browser of any user visiting their
page or clicking on that funny link received in a email..",78,data/crawl/squid/hunk_5950.cpp,,,data/crawl/squid/old_hunk_5950.cpp,data/crawl/squid/new_hunk_5950.cpp,14,15,"storeAppendPrintf(e, ""%c"", ftpState->title_url[k++]);","storeAppendPrintf(e, ""%c"", title[k++]);","[""updateVariable"", ""removeVariable""]","[[""ftpState"", ""title_url[k""], [""title[k""]]",[-19434422821196147371],6616,0.0,2
https://github.com/squid-cache/squid/commit/10270faab2bc84e50cde13431a6e6d1932966e5f,05 Nov 2000,"Cross-site scripting fixes by Robert Collins and Henrik Nordstrom

Everywhere where Squid inserts text received from the network into
a HTML page (error pages, FTP listings, Gopher listings, ...) care
must be taken to ensure that the text is properly encoded as HTML,
or a malicious user might be able to insert script code or other
HTML tags, and exploit the web browser of any user visiting their
page or clicking on that funny link received in a email..",78,data/crawl/squid/hunk_5950.cpp,,,data/crawl/squid/old_hunk_5950.cpp,data/crawl/squid/new_hunk_5950.cpp,9,10,"storeAppendPrintf(e, ""%c"", ftpState->title_url[k]);","storeAppendPrintf(e, ""%c"", title[k]);","[""updateVariable"", ""removeVariable""]","[[""ftpState"", ""title_url[k]""], [""title[k]""]]",[-931880703634394427],6615,0.0,2
https://github.com/squid-cache/squid/commit/b3de4c9b210bf6f6b93577e9179b440f59be586d,05 Jan 2001,"A hack to support array types in Squid's Config structure.  Mostly this
is to eliminate compiler warnings.  The compiler wants us to write
   parse_bar(&Config.bar[0]);
rather than
   parse_bar(&Config.bar);",17,data/crawl/squid/hunk_5929.cpp,,,data/crawl/squid/old_hunk_5929.cpp,data/crawl/squid/new_hunk_5929.cpp,2,2,"fprintf(fp,
		""\t\tparse_%s(&%s);\n"",
		entry->type, entry->loc
		);","fprintf(fp,
		""\t\tparse_%s(&%s%s);\n"",
		entry->type, entry->loc,
		entry->array_flag ? ""[0]"" : """"
		);","[""addContent"", ""addVariable""]","[[""&%s""], [""&%s%s"", ""entry"", ""array_flag"", ""[0]""]]",[19580881337582745350],6614,0.0,2
https://github.com/squid-cache/squid/commit/94439e4e1d1a662f14357ee1e16c4a9af95db94b,08 Jan 2001,"Major rewrite of proxy authentication to support other schemes than
Basic (auth_rewrite branch on SourceForge).
Contributors:
   Andy Doran
   Robert Collins
   Chemolli Francesco
   Henrik Nordstrom

For details about the new API's, see Programmers Guide.

As part of this change everything from auth_modules has been moved to
src/auth/basic/helpers",21209,data/crawl/squid/hunk_5912.cpp,,,data/crawl/squid/old_hunk_5912.cpp,data/crawl/squid/new_hunk_5912.cpp,-1,611,,"fatal(""Invalid authenticate state for NTLMStart"");","[""addLog""]","[[], [""fatal"", ""Invalid"", ""authenticate"", ""state"", ""for"", ""NTLMStart""]]",[-21171954645048328152],6613,0.0,2
https://github.com/squid-cache/squid/commit/94439e4e1d1a662f14357ee1e16c4a9af95db94b,08 Jan 2001,"Major rewrite of proxy authentication to support other schemes than
Basic (auth_rewrite branch on SourceForge).
Contributors:
   Andy Doran
   Robert Collins
   Chemolli Francesco
   Henrik Nordstrom

For details about the new API's, see Programmers Guide.

As part of this change everything from auth_modules has been moved to
src/auth/basic/helpers",21209,data/crawl/squid/hunk_5912.cpp,,,data/crawl/squid/old_hunk_5912.cpp,data/crawl/squid/new_hunk_5912.cpp,-1,278,,"httpHeaderPutStrf(&rep->header, type, ""NTLM"");","[""addLog""]","[[], [""httpHeaderPutStrf"", ""&rep"", ""header"", ""type"", ""NTLM""]]",[-8090161193889355831],6612,0.0,2
https://github.com/squid-cache/squid/commit/94439e4e1d1a662f14357ee1e16c4a9af95db94b,08 Jan 2001,"Major rewrite of proxy authentication to support other schemes than
Basic (auth_rewrite branch on SourceForge).
Contributors:
   Andy Doran
   Robert Collins
   Chemolli Francesco
   Henrik Nordstrom

For details about the new API's, see Programmers Guide.

As part of this change everything from auth_modules has been moved to
src/auth/basic/helpers",21209,data/crawl/squid/hunk_5906.cpp,,,data/crawl/squid/old_hunk_5906.cpp,data/crawl/squid/new_hunk_5906.cpp,-1,299,,"printf(""ERR %s\n"", user);","[""addLog""]","[[], [""printf"", ""ERR"", ""%s\\n"", ""user""]]",[16799966826793604356],6611,0.0,2
https://github.com/squid-cache/squid/commit/94439e4e1d1a662f14357ee1e16c4a9af95db94b,08 Jan 2001,"Major rewrite of proxy authentication to support other schemes than
Basic (auth_rewrite branch on SourceForge).
Contributors:
   Andy Doran
   Robert Collins
   Chemolli Francesco
   Henrik Nordstrom

For details about the new API's, see Programmers Guide.

As part of this change everything from auth_modules has been moved to
src/auth/basic/helpers",21209,data/crawl/squid/hunk_5905.cpp,,,data/crawl/squid/old_hunk_5905.cpp,data/crawl/squid/new_hunk_5905.cpp,-1,373,,"fprintf(stderr, ""SMB_Logon_server: Couldn't allocate packet\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""SMB_Logon_server"", ""Couldn"", ""t"", ""allocate"", ""packet\\n""]]",[-20029027935438814705],6610,0.0,2
https://github.com/squid-cache/squid/commit/94439e4e1d1a662f14357ee1e16c4a9af95db94b,08 Jan 2001,"Major rewrite of proxy authentication to support other schemes than
Basic (auth_rewrite branch on SourceForge).
Contributors:
   Andy Doran
   Robert Collins
   Chemolli Francesco
   Henrik Nordstrom

For details about the new API's, see Programmers Guide.

As part of this change everything from auth_modules has been moved to
src/auth/basic/helpers",21209,data/crawl/squid/hunk_5894.cpp,,,data/crawl/squid/old_hunk_5894.cpp,data/crawl/squid/new_hunk_5894.cpp,-1,56,,"fputs(buf, p);","[""addLog""]","[[], [""fputs"", ""buf"", ""p""]]",[-3173597624094778370],6609,0.0,2
https://github.com/squid-cache/squid/commit/94439e4e1d1a662f14357ee1e16c4a9af95db94b,08 Jan 2001,"Major rewrite of proxy authentication to support other schemes than
Basic (auth_rewrite branch on SourceForge).
Contributors:
   Andy Doran
   Robert Collins
   Chemolli Francesco
   Henrik Nordstrom

For details about the new API's, see Programmers Guide.

As part of this change everything from auth_modules has been moved to
src/auth/basic/helpers",21209,data/crawl/squid/hunk_5893.cpp,,,data/crawl/squid/old_hunk_5893.cpp,data/crawl/squid/new_hunk_5893.cpp,-1,153,,"fprintf(stderr, ""ERROR: failed to release PAM authenticator\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""ERROR"", ""failed"", ""to"", ""release"", ""PAM"", ""authenticator\\n""]]",[-20015993346212209768],6608,0.0,2
https://github.com/squid-cache/squid/commit/94439e4e1d1a662f14357ee1e16c4a9af95db94b,08 Jan 2001,"Major rewrite of proxy authentication to support other schemes than
Basic (auth_rewrite branch on SourceForge).
Contributors:
   Andy Doran
   Robert Collins
   Chemolli Francesco
   Henrik Nordstrom

For details about the new API's, see Programmers Guide.

As part of this change everything from auth_modules has been moved to
src/auth/basic/helpers",21209,data/crawl/squid/hunk_5893.cpp,,,data/crawl/squid/old_hunk_5893.cpp,data/crawl/squid/new_hunk_5893.cpp,-1,132,,"fprintf(stderr, ""authenticator: Unexpected input '%s'\n"", buf);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""authenticator"", ""Unexpected"", ""input"", ""%s"", ""\\n"", ""buf""]]",[-20281078129703161784],6607,0.0,2
https://github.com/squid-cache/squid/commit/94439e4e1d1a662f14357ee1e16c4a9af95db94b,08 Jan 2001,"Major rewrite of proxy authentication to support other schemes than
Basic (auth_rewrite branch on SourceForge).
Contributors:
   Andy Doran
   Robert Collins
   Chemolli Francesco
   Henrik Nordstrom

For details about the new API's, see Programmers Guide.

As part of this change everything from auth_modules has been moved to
src/auth/basic/helpers",21209,data/crawl/squid/hunk_5890.cpp,,,data/crawl/squid/old_hunk_5890.cpp,data/crawl/squid/new_hunk_5890.cpp,-1,700,,"fprintf(stderr, ""Tree disconnect successful ...\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""Tree"", ""disconnect"", ""successful"", ""\\n""]]",[-10455339582062958758],6606,0.0,2
https://github.com/squid-cache/squid/commit/94439e4e1d1a662f14357ee1e16c4a9af95db94b,08 Jan 2001,"Major rewrite of proxy authentication to support other schemes than
Basic (auth_rewrite branch on SourceForge).
Contributors:
   Andy Doran
   Robert Collins
   Chemolli Francesco
   Henrik Nordstrom

For details about the new API's, see Programmers Guide.

As part of this change everything from auth_modules has been moved to
src/auth/basic/helpers",21209,data/crawl/squid/hunk_5890.cpp,,,data/crawl/squid/old_hunk_5890.cpp,data/crawl/squid/new_hunk_5890.cpp,-1,684,,"fprintf(stderr, ""SMB_TDis failed with errorclass = %i, Error Code = %i\n"",
	    CVAL(SMB_Hdr(pkt), SMB_hdr_rcls_offset),
	    SVAL(SMB_Hdr(pkt), SMB_hdr_err_offset));","[""addLog""]","[[], [""fprintf"", ""stderr"", ""SMB_TDis"", ""failed"", ""with"", ""errorclass"", ""%i"", ""Error"", ""Code"", ""%i\\n"", ""CVAL"", ""SMB_Hdr"", ""pkt"", ""SMB_hdr_rcls_offset"", ""SVAL"", ""SMB_Hdr"", ""pkt"", ""SMB_hdr_err_offset""]]",[17608266999179787676],6605,0.0,2
https://github.com/squid-cache/squid/commit/94439e4e1d1a662f14357ee1e16c4a9af95db94b,08 Jan 2001,"Major rewrite of proxy authentication to support other schemes than
Basic (auth_rewrite branch on SourceForge).
Contributors:
   Andy Doran
   Robert Collins
   Chemolli Francesco
   Henrik Nordstrom

For details about the new API's, see Programmers Guide.

As part of this change everything from auth_modules has been moved to
src/auth/basic/helpers",21209,data/crawl/squid/hunk_5890.cpp,,,data/crawl/squid/old_hunk_5890.cpp,data/crawl/squid/new_hunk_5890.cpp,-1,658,,"fprintf(stderr, ""Error sending TDis request\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""Error"", ""sending"", ""TDis"", ""request\\n""]]",[1669284990908647174],6604,0.0,2
https://github.com/squid-cache/squid/commit/94439e4e1d1a662f14357ee1e16c4a9af95db94b,08 Jan 2001,"Major rewrite of proxy authentication to support other schemes than
Basic (auth_rewrite branch on SourceForge).
Contributors:
   Andy Doran
   Robert Collins
   Chemolli Francesco
   Henrik Nordstrom

For details about the new API's, see Programmers Guide.

As part of this change everything from auth_modules has been moved to
src/auth/basic/helpers",21209,data/crawl/squid/hunk_5890.cpp,,,data/crawl/squid/old_hunk_5890.cpp,data/crawl/squid/new_hunk_5890.cpp,-1,600,,"fprintf(stderr, ""TConn succeeded, with TID=%i, Max Xmit=%i\n"",
	tree->tid, tree->mbs);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""TConn"", ""succeeded"", ""with"", ""TID"", ""%i"", ""Max"", ""Xmit"", ""%i\\n"", ""tree"", ""tid"", ""tree"", ""mbs""]]",[-190786774051843867],6603,0.0,2
https://github.com/squid-cache/squid/commit/94439e4e1d1a662f14357ee1e16c4a9af95db94b,08 Jan 2001,"Major rewrite of proxy authentication to support other schemes than
Basic (auth_rewrite branch on SourceForge).
Contributors:
   Andy Doran
   Robert Collins
   Chemolli Francesco
   Henrik Nordstrom

For details about the new API's, see Programmers Guide.

As part of this change everything from auth_modules has been moved to
src/auth/basic/helpers",21209,data/crawl/squid/hunk_5890.cpp,,,data/crawl/squid/old_hunk_5890.cpp,data/crawl/squid/new_hunk_5890.cpp,-1,583,,"fprintf(stderr, ""SMB_TCon failed with errorclass = %i, Error Code = %i\n"",
	    CVAL(SMB_Hdr(pkt), SMB_hdr_rcls_offset),
	    SVAL(SMB_Hdr(pkt), SMB_hdr_err_offset));","[""addLog""]","[[], [""fprintf"", ""stderr"", ""SMB_TCon"", ""failed"", ""with"", ""errorclass"", ""%i"", ""Error"", ""Code"", ""%i\\n"", ""CVAL"", ""SMB_Hdr"", ""pkt"", ""SMB_hdr_rcls_offset"", ""SVAL"", ""SMB_Hdr"", ""pkt"", ""SMB_hdr_err_offset""]]",[17608263999045787280],6602,0.0,2
https://github.com/squid-cache/squid/commit/94439e4e1d1a662f14357ee1e16c4a9af95db94b,08 Jan 2001,"Major rewrite of proxy authentication to support other schemes than
Basic (auth_rewrite branch on SourceForge).
Contributors:
   Andy Doran
   Robert Collins
   Chemolli Francesco
   Henrik Nordstrom

For details about the new API's, see Programmers Guide.

As part of this change everything from auth_modules has been moved to
src/auth/basic/helpers",21209,data/crawl/squid/hunk_5890.cpp,,,data/crawl/squid/old_hunk_5890.cpp,data/crawl/squid/new_hunk_5890.cpp,-1,553,,"fprintf(stderr, ""Error sending TCon request\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""Error"", ""sending"", ""TCon"", ""request\\n""]]",[1669291990818646766],6601,0.0,2
https://github.com/squid-cache/squid/commit/94439e4e1d1a662f14357ee1e16c4a9af95db94b,08 Jan 2001,"Major rewrite of proxy authentication to support other schemes than
Basic (auth_rewrite branch on SourceForge).
Contributors:
   Andy Doran
   Robert Collins
   Chemolli Francesco
   Henrik Nordstrom

For details about the new API's, see Programmers Guide.

As part of this change everything from auth_modules has been moved to
src/auth/basic/helpers",21209,data/crawl/squid/hunk_5890.cpp,,,data/crawl/squid/old_hunk_5890.cpp,data/crawl/squid/new_hunk_5890.cpp,-1,475,,"fprintf(stderr, ""Bad parameter passed to SMB_TreeConnect\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""Bad"", ""parameter"", ""passed"", ""to"", ""SMB_TreeConnect\\n""]]",[-28283292331581745939],6600,0.0,2
https://github.com/squid-cache/squid/commit/94439e4e1d1a662f14357ee1e16c4a9af95db94b,08 Jan 2001,"Major rewrite of proxy authentication to support other schemes than
Basic (auth_rewrite branch on SourceForge).
Contributors:
   Andy Doran
   Robert Collins
   Chemolli Francesco
   Henrik Nordstrom

For details about the new API's, see Programmers Guide.

As part of this change everything from auth_modules has been moved to
src/auth/basic/helpers",21209,data/crawl/squid/hunk_5890.cpp,,,data/crawl/squid/old_hunk_5890.cpp,data/crawl/squid/new_hunk_5890.cpp,-1,446,,"fprintf(stderr, ""gethostname in SMB_Get_My_Name returned error:"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""gethostname"", ""in"", ""SMB_Get_My_Name"", ""returned"", ""error""]]",[-6056458175703647334],6599,0.0,2
https://github.com/squid-cache/squid/commit/94439e4e1d1a662f14357ee1e16c4a9af95db94b,08 Jan 2001,"Major rewrite of proxy authentication to support other schemes than
Basic (auth_rewrite branch on SourceForge).
Contributors:
   Andy Doran
   Robert Collins
   Chemolli Francesco
   Henrik Nordstrom

For details about the new API's, see Programmers Guide.

As part of this change everything from auth_modules has been moved to
src/auth/basic/helpers",21209,data/crawl/squid/hunk_5890.cpp,,,data/crawl/squid/old_hunk_5890.cpp,data/crawl/squid/new_hunk_5890.cpp,-1,425,,"fprintf(stderr, ""Protocol selected is: %i:%s\n"", prot, Prots[prot]);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""Protocol"", ""selected"", ""is"", ""%i"", ""%s\\n"", ""prot"", ""Prots[prot]""]]",[568566326311284656],6598,0.0,2
https://github.com/squid-cache/squid/commit/94439e4e1d1a662f14357ee1e16c4a9af95db94b,08 Jan 2001,"Major rewrite of proxy authentication to support other schemes than
Basic (auth_rewrite branch on SourceForge).
Contributors:
   Andy Doran
   Robert Collins
   Chemolli Francesco
   Henrik Nordstrom

For details about the new API's, see Programmers Guide.

As part of this change everything from auth_modules has been moved to
src/auth/basic/helpers",21209,data/crawl/squid/hunk_5890.cpp,,,data/crawl/squid/old_hunk_5890.cpp,data/crawl/squid/new_hunk_5890.cpp,-1,418,,"fprintf(stderr, ""  wct = %i\n"", CVAL(SMB_Hdr(pkt), SMB_hdr_wct_offset));","[""addLog""]","[[], [""fprintf"", ""stderr"", ""wct"", ""%i\\n"", ""CVAL"", ""SMB_Hdr"", ""pkt"", ""SMB_hdr_wct_offset""]]",[11639558928581341257],6597,0.0,2
https://github.com/squid-cache/squid/commit/94439e4e1d1a662f14357ee1e16c4a9af95db94b,08 Jan 2001,"Major rewrite of proxy authentication to support other schemes than
Basic (auth_rewrite branch on SourceForge).
Contributors:
   Andy Doran
   Robert Collins
   Chemolli Francesco
   Henrik Nordstrom

For details about the new API's, see Programmers Guide.

As part of this change everything from auth_modules has been moved to
src/auth/basic/helpers",21209,data/crawl/squid/hunk_5890.cpp,,,data/crawl/squid/old_hunk_5890.cpp,data/crawl/squid/new_hunk_5890.cpp,-1,417,,"fprintf(stderr, ""Unknown NegProt response format ... Ignored\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""Unknown"", ""NegProt"", ""response"", ""format"", ""Ignored\\n""]]",[-21955897165561237654],6596,0.0,2
https://github.com/squid-cache/squid/commit/94439e4e1d1a662f14357ee1e16c4a9af95db94b,08 Jan 2001,"Major rewrite of proxy authentication to support other schemes than
Basic (auth_rewrite branch on SourceForge).
Contributors:
   Andy Doran
   Robert Collins
   Chemolli Francesco
   Henrik Nordstrom

For details about the new API's, see Programmers Guide.

As part of this change everything from auth_modules has been moved to
src/auth/basic/helpers",21209,data/crawl/squid/hunk_5890.cpp,,,data/crawl/squid/old_hunk_5890.cpp,data/crawl/squid/new_hunk_5890.cpp,-1,341,,"fprintf(stderr, ""None of our protocols was accepted ... "");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""None"", ""of"", ""our"", ""protocols"", ""was"", ""accepted""]]",[-22867513539682129949],6595,0.0,2
https://github.com/squid-cache/squid/commit/94439e4e1d1a662f14357ee1e16c4a9af95db94b,08 Jan 2001,"Major rewrite of proxy authentication to support other schemes than
Basic (auth_rewrite branch on SourceForge).
Contributors:
   Andy Doran
   Robert Collins
   Chemolli Francesco
   Henrik Nordstrom

For details about the new API's, see Programmers Guide.

As part of this change everything from auth_modules has been moved to
src/auth/basic/helpers",21209,data/crawl/squid/hunk_5890.cpp,,,data/crawl/squid/old_hunk_5890.cpp,data/crawl/squid/new_hunk_5890.cpp,-1,327,,"fprintf(stderr, ""SMB_Negotiate failed with errorclass = %i, Error Code = %i\n"",
	    CVAL(SMB_Hdr(pkt), SMB_hdr_rcls_offset),
	    SVAL(SMB_Hdr(pkt), SMB_hdr_err_offset));","[""addLog""]","[[], [""fprintf"", ""stderr"", ""SMB_Negotiate"", ""failed"", ""with"", ""errorclass"", ""%i"", ""Error"", ""Code"", ""%i\\n"", ""CVAL"", ""SMB_Hdr"", ""pkt"", ""SMB_hdr_rcls_offset"", ""SVAL"", ""SMB_Hdr"", ""pkt"", ""SMB_hdr_err_offset""]]",[20240467983439335349],6594,0.0,2
https://github.com/squid-cache/squid/commit/94439e4e1d1a662f14357ee1e16c4a9af95db94b,08 Jan 2001,"Major rewrite of proxy authentication to support other schemes than
Basic (auth_rewrite branch on SourceForge).
Contributors:
   Andy Doran
   Robert Collins
   Chemolli Francesco
   Henrik Nordstrom

For details about the new API's, see Programmers Guide.

As part of this change everything from auth_modules has been moved to
src/auth/basic/helpers",21209,data/crawl/squid/hunk_5890.cpp,,,data/crawl/squid/old_hunk_5890.cpp,data/crawl/squid/new_hunk_5890.cpp,-1,316,,"fprintf(stderr, ""Error receiving response to negotiate\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""Error"", ""receiving"", ""response"", ""to"", ""negotiate\\n""]]",[-10989357414161367393],6593,0.0,2
https://github.com/squid-cache/squid/commit/94439e4e1d1a662f14357ee1e16c4a9af95db94b,08 Jan 2001,"Major rewrite of proxy authentication to support other schemes than
Basic (auth_rewrite branch on SourceForge).
Contributors:
   Andy Doran
   Robert Collins
   Chemolli Francesco
   Henrik Nordstrom

For details about the new API's, see Programmers Guide.

As part of this change everything from auth_modules has been moved to
src/auth/basic/helpers",21209,data/crawl/squid/hunk_5890.cpp,,,data/crawl/squid/old_hunk_5890.cpp,data/crawl/squid/new_hunk_5890.cpp,-1,303,,"fprintf(stderr, ""Error sending negotiate protocol\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""Error"", ""sending"", ""negotiate"", ""protocol\\n""]]",[-6277015129624988613],6592,0.0,2
https://github.com/squid-cache/squid/commit/94439e4e1d1a662f14357ee1e16c4a9af95db94b,08 Jan 2001,"Major rewrite of proxy authentication to support other schemes than
Basic (auth_rewrite branch on SourceForge).
Contributors:
   Andy Doran
   Robert Collins
   Chemolli Francesco
   Henrik Nordstrom

For details about the new API's, see Programmers Guide.

As part of this change everything from auth_modules has been moved to
src/auth/basic/helpers",21209,data/crawl/squid/hunk_5888.cpp,,,data/crawl/squid/old_hunk_5888.cpp,data/crawl/squid/new_hunk_5888.cpp,-1,487,,"fprintf(stderr, ""Getting packet.\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""Getting"", ""packet"", ""\\n""]]",[-16512603769435458569],6591,0.0,2
https://github.com/squid-cache/squid/commit/94439e4e1d1a662f14357ee1e16c4a9af95db94b,08 Jan 2001,"Major rewrite of proxy authentication to support other schemes than
Basic (auth_rewrite branch on SourceForge).
Contributors:
   Andy Doran
   Robert Collins
   Chemolli Francesco
   Henrik Nordstrom

For details about the new API's, see Programmers Guide.

As part of this change everything from auth_modules has been moved to
src/auth/basic/helpers",21209,data/crawl/squid/hunk_5888.cpp,,,data/crawl/squid/old_hunk_5888.cpp,data/crawl/squid/new_hunk_5888.cpp,-1,334,,"fprintf(fd, ""RFCNB SESSION KEEP ALIVE: Length = %i\n"",
	    RFCNB_Pkt_Len(pkt->data));","[""addLog""]","[[], [""fprintf"", ""fd"", ""RFCNB"", ""SESSION"", ""KEEP"", ""ALIVE"", ""Length"", ""%i\\n"", ""RFCNB_Pkt_Len"", ""pkt"", ""data""]]",[11811773037032704824],6590,0.0,2
https://github.com/squid-cache/squid/commit/94439e4e1d1a662f14357ee1e16c4a9af95db94b,08 Jan 2001,"Major rewrite of proxy authentication to support other schemes than
Basic (auth_rewrite branch on SourceForge).
Contributors:
   Andy Doran
   Robert Collins
   Chemolli Francesco
   Henrik Nordstrom

For details about the new API's, see Programmers Guide.

As part of this change everything from auth_modules has been moved to
src/auth/basic/helpers",21209,data/crawl/squid/hunk_5888.cpp,,,data/crawl/squid/old_hunk_5888.cpp,data/crawl/squid/new_hunk_5888.cpp,-1,325,,"fprintf(fd, ""RFCNB SESSION RETARGET: Length = %i\n"",
	    RFCNB_Pkt_Len(pkt->data));","[""addLog""]","[[], [""fprintf"", ""fd"", ""RFCNB"", ""SESSION"", ""RETARGET"", ""Length"", ""%i\\n"", ""RFCNB_Pkt_Len"", ""pkt"", ""data""]]",[14889725013713008903],6589,0.0,2
https://github.com/squid-cache/squid/commit/94439e4e1d1a662f14357ee1e16c4a9af95db94b,08 Jan 2001,"Major rewrite of proxy authentication to support other schemes than
Basic (auth_rewrite branch on SourceForge).
Contributors:
   Andy Doran
   Robert Collins
   Chemolli Francesco
   Henrik Nordstrom

For details about the new API's, see Programmers Guide.

As part of this change everything from auth_modules has been moved to
src/auth/basic/helpers",21209,data/crawl/squid/hunk_5888.cpp,,,data/crawl/squid/old_hunk_5888.cpp,data/crawl/squid/new_hunk_5888.cpp,-1,318,,"fprintf(fd, ""   Error = %x\n"", CVAL(pkt->data, RFCNB_Pkt_Error_Offset));","[""addLog""]","[[], [""fprintf"", ""fd"", ""Error"", ""%x\\n"", ""CVAL"", ""pkt"", ""data"", ""RFCNB_Pkt_Error_Offset""]]",[4754144509928670694],6588,0.0,2
https://github.com/squid-cache/squid/commit/94439e4e1d1a662f14357ee1e16c4a9af95db94b,08 Jan 2001,"Major rewrite of proxy authentication to support other schemes than
Basic (auth_rewrite branch on SourceForge).
Contributors:
   Andy Doran
   Robert Collins
   Chemolli Francesco
   Henrik Nordstrom

For details about the new API's, see Programmers Guide.

As part of this change everything from auth_modules has been moved to
src/auth/basic/helpers",21209,data/crawl/squid/hunk_5888.cpp,,,data/crawl/squid/old_hunk_5888.cpp,data/crawl/squid/new_hunk_5888.cpp,-1,316,,"fprintf(fd, ""   Protocol Error, short Reject packet!\n"");","[""addLog""]","[[], [""fprintf"", ""fd"", ""Protocol"", ""Error"", ""short"", ""Reject"", ""packet"", ""\\n""]]",[213439437028480387],6587,0.0,2
https://github.com/squid-cache/squid/commit/94439e4e1d1a662f14357ee1e16c4a9af95db94b,08 Jan 2001,"Major rewrite of proxy authentication to support other schemes than
Basic (auth_rewrite branch on SourceForge).
Contributors:
   Andy Doran
   Robert Collins
   Chemolli Francesco
   Henrik Nordstrom

For details about the new API's, see Programmers Guide.

As part of this change everything from auth_modules has been moved to
src/auth/basic/helpers",21209,data/crawl/squid/hunk_5888.cpp,,,data/crawl/squid/old_hunk_5888.cpp,data/crawl/squid/new_hunk_5888.cpp,-1,312,,"fprintf(fd, ""RFCNB SESSION REJECT: Length = %i\n"",
	    RFCNB_Pkt_Len(pkt->data));","[""addLog""]","[[], [""fprintf"", ""fd"", ""RFCNB"", ""SESSION"", ""REJECT"", ""Length"", ""%i\\n"", ""RFCNB_Pkt_Len"", ""pkt"", ""data""]]",[-820721139258317966],6586,0.0,2
https://github.com/squid-cache/squid/commit/94439e4e1d1a662f14357ee1e16c4a9af95db94b,08 Jan 2001,"Major rewrite of proxy authentication to support other schemes than
Basic (auth_rewrite branch on SourceForge).
Contributors:
   Andy Doran
   Robert Collins
   Chemolli Francesco
   Henrik Nordstrom

For details about the new API's, see Programmers Guide.

As part of this change everything from auth_modules has been moved to
src/auth/basic/helpers",21209,data/crawl/squid/hunk_5888.cpp,,,data/crawl/squid/old_hunk_5888.cpp,data/crawl/squid/new_hunk_5888.cpp,-1,306,,"fprintf(fd, ""RFCNB SESSION ACK: Length = %i\n"",
	    RFCNB_Pkt_Len(pkt->data));","[""addLog""]","[[], [""fprintf"", ""fd"", ""RFCNB"", ""SESSION"", ""ACK"", ""Length"", ""%i\\n"", ""RFCNB_Pkt_Len"", ""pkt"", ""data""]]",[8738986985758851235],6585,0.0,2
https://github.com/squid-cache/squid/commit/94439e4e1d1a662f14357ee1e16c4a9af95db94b,08 Jan 2001,"Major rewrite of proxy authentication to support other schemes than
Basic (auth_rewrite branch on SourceForge).
Contributors:
   Andy Doran
   Robert Collins
   Chemolli Francesco
   Henrik Nordstrom

For details about the new API's, see Programmers Guide.

As part of this change everything from auth_modules has been moved to
src/auth/basic/helpers",21209,data/crawl/squid/hunk_5888.cpp,,,data/crawl/squid/old_hunk_5888.cpp,data/crawl/squid/new_hunk_5888.cpp,-1,300,,"fprintf(fd, ""  Calling Name: %s\n"", lname);","[""addLog""]","[[], [""fprintf"", ""fd"", ""Calling"", ""Name"", ""%s\\n"", ""lname""]]",[-12850645637521568098],6584,0.0,2
https://github.com/squid-cache/squid/commit/94439e4e1d1a662f14357ee1e16c4a9af95db94b,08 Jan 2001,"Major rewrite of proxy authentication to support other schemes than
Basic (auth_rewrite branch on SourceForge).
Contributors:
   Andy Doran
   Robert Collins
   Chemolli Francesco
   Henrik Nordstrom

For details about the new API's, see Programmers Guide.

As part of this change everything from auth_modules has been moved to
src/auth/basic/helpers",21209,data/crawl/squid/hunk_5888.cpp,,,data/crawl/squid/old_hunk_5888.cpp,data/crawl/squid/new_hunk_5888.cpp,-1,298,,"fprintf(fd, ""  Called Name: %s\n"", lname);","[""addLog""]","[[], [""fprintf"", ""fd"", ""Called"", ""Name"", ""%s\\n"", ""lname""]]",[-9566888668036683348],6583,0.0,2
https://github.com/squid-cache/squid/commit/94439e4e1d1a662f14357ee1e16c4a9af95db94b,08 Jan 2001,"Major rewrite of proxy authentication to support other schemes than
Basic (auth_rewrite branch on SourceForge).
Contributors:
   Andy Doran
   Robert Collins
   Chemolli Francesco
   Henrik Nordstrom

For details about the new API's, see Programmers Guide.

As part of this change everything from auth_modules has been moved to
src/auth/basic/helpers",21209,data/crawl/squid/hunk_5888.cpp,,,data/crawl/squid/old_hunk_5888.cpp,data/crawl/squid/new_hunk_5888.cpp,-1,295,,"fprintf(fd, ""SESSION REQUEST: Length = %i\n"",
	    RFCNB_Pkt_Len(pkt->data));","[""addLog""]","[[], [""fprintf"", ""fd"", ""SESSION"", ""REQUEST"", ""Length"", ""%i\\n"", ""RFCNB_Pkt_Len"", ""pkt"", ""data""]]",[-3187120721537859483],6582,0.0,2
https://github.com/squid-cache/squid/commit/94439e4e1d1a662f14357ee1e16c4a9af95db94b,08 Jan 2001,"Major rewrite of proxy authentication to support other schemes than
Basic (auth_rewrite branch on SourceForge).
Contributors:
   Andy Doran
   Robert Collins
   Chemolli Francesco
   Henrik Nordstrom

For details about the new API's, see Programmers Guide.

As part of this change everything from auth_modules has been moved to
src/auth/basic/helpers",21209,data/crawl/squid/hunk_5888.cpp,,,data/crawl/squid/old_hunk_5888.cpp,data/crawl/squid/new_hunk_5888.cpp,-1,277,,"fprintf(fd, ""SESSION MESSAGE: Length = %i\n"", RFCNB_Pkt_Len(pkt->data));","[""addLog""]","[[], [""fprintf"", ""fd"", ""SESSION"", ""MESSAGE"", ""Length"", ""%i\\n"", ""RFCNB_Pkt_Len"", ""pkt"", ""data""]]",[-8126994675341144173],6581,0.0,2
https://github.com/squid-cache/squid/commit/94439e4e1d1a662f14357ee1e16c4a9af95db94b,08 Jan 2001,"Major rewrite of proxy authentication to support other schemes than
Basic (auth_rewrite branch on SourceForge).
Contributors:
   Andy Doran
   Robert Collins
   Chemolli Francesco
   Henrik Nordstrom

For details about the new API's, see Programmers Guide.

As part of this change everything from auth_modules has been moved to
src/auth/basic/helpers",21209,data/crawl/squid/hunk_5888.cpp,,,data/crawl/squid/old_hunk_5888.cpp,data/crawl/squid/new_hunk_5888.cpp,-1,271,,"fprintf(fd, ""RFCNB Pkt %s:"", dirn);","[""addLog""]","[[], [""fprintf"", ""fd"", ""RFCNB"", ""Pkt"", ""%s"", ""dirn""]]",[-2429762932651283989],6580,0.0,2
https://github.com/squid-cache/squid/commit/94439e4e1d1a662f14357ee1e16c4a9af95db94b,08 Jan 2001,"Major rewrite of proxy authentication to support other schemes than
Basic (auth_rewrite branch on SourceForge).
Contributors:
   Andy Doran
   Robert Collins
   Chemolli Francesco
   Henrik Nordstrom

For details about the new API's, see Programmers Guide.

As part of this change everything from auth_modules has been moved to
src/auth/basic/helpers",21209,data/crawl/squid/hunk_5888.cpp,,,data/crawl/squid/old_hunk_5888.cpp,data/crawl/squid/new_hunk_5888.cpp,-1,200,,"fprintf(fd, ""\n"");","[""addLog""]","[[], [""fprintf"", ""fd"", ""\\n""]]",[-5179306325123647008],6579,0.0,2
https://github.com/squid-cache/squid/commit/5ff76111b95f1e192f101f6ae2625ffb8523c067,30 Jan 2001,"Cleanup of coredump_dir. No longer automatically uses the first cache_dir
location, and can be commented out to use the current directory.",32,data/crawl/squid/hunk_5878.cpp,,,data/crawl/squid/old_hunk_5878.cpp,data/crawl/squid/new_hunk_5878.cpp,16,-1,"fatal_dump(""Cannot cd to swap directory?"");",,"[""removeLog""]","[[""fatal_dump"", ""Cannot"", ""cd"", ""to"", ""swap"", ""directory""], []]",[10293767358945213303],6578,472320.0,2
https://github.com/squid-cache/squid/commit/2d70df7262cac3e29d34bed03b758695f5961b74,01 Feb 2001,"Major update from auth_rewrite

Robert Collins:

Digest (RFC2617) proxy authentication implementation

Chemolli Francesco:

Several bugs in NTLM authentication when dealing with untrusted
domains, wrong passwords, helper arguments and more have been fixed",2527,data/crawl/squid/hunk_5873.cpp,,,data/crawl/squid/old_hunk_5873.cpp,data/crawl/squid/new_hunk_5873.cpp,-1,124,,"fprintf(stderr, ""cannot stat %s\n"", argv[1]);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""cannot"", ""stat"", ""%s\\n"", ""argv[1]""]]",[-9992788649957119247],6577,17280.0,2
https://github.com/squid-cache/squid/commit/de3ee917a46bbf69275684c808627e2e4ec69e01,21 Feb 2001,"cachemgr fix for http_header_access and header_replacement
by Robert Collins

Specifically neither produce output that can be put into a squid.conf
file...",15,data/crawl/squid/hunk_5859.cpp,,,data/crawl/squid/old_hunk_5859.cpp,data/crawl/squid/new_hunk_5859.cpp,7,6,"storeAppendPrintf(entry, ""\t%s: %s"", httpHeaderNameById(i),
	    header[i].replacement);","storeAppendPrintf(entry, ""%s %s %s\n"", name, httpHeaderNameById(i),
	    header[i].replacement);","[""updateContent"", ""addVariable""]","[[""\\t%s""], [""%s"", ""%s\\n"", ""name""]]",[7144772321524469053],6576,0.0,2
https://github.com/squid-cache/squid/commit/de3ee917a46bbf69275684c808627e2e4ec69e01,21 Feb 2001,"cachemgr fix for http_header_access and header_replacement
by Robert Collins

Specifically neither produce output that can be put into a squid.conf
file...",15,data/crawl/squid/hunk_5858.cpp,,,data/crawl/squid/old_hunk_5858.cpp,data/crawl/squid/new_hunk_5858.cpp,6,-1,"storeAppendPrintf(entry, ""\t"");",,"[""removeLog""]","[[""storeAppendPrintf"", ""entry"", ""\\t""], []]",[-3924684621819481210],6575,0.0,2
https://github.com/squid-cache/squid/commit/77d6bd889ba22dc9de04e697b0545782378cf858,26 Feb 2001,"From Chemolli Francesco:

Support for the types int16_t, int32_t, int64_t and their unsigned
counterparts u_int16_t, u_int32_t, u_int64_t. Legacy support for num32
is provided, but I recommend we deprecate num* types and (where struct
packing is useful) we move in time fully to the new types.",2083,data/crawl/squid/hunk_5856.cpp,,,data/crawl/squid/old_hunk_5856.cpp,data/crawl/squid/new_hunk_5856.cpp,-1,19,,"fprintf(f, ""%d\n"", sizeof(void *));","[""addLog""]","[[], [""fprintf"", ""f"", ""%d\\n"", ""sizeof"", ""void"", ""*""]]",[-11360315636553856409],6574,491760.0,2
https://github.com/squid-cache/squid/commit/54b7fec9eafb0777f3d6e2450f39a36d60f9b344,02 Mar 2001,"Oops.. the transition to cache_dir options for Q1 and Q2 was not fully
finished. There was many leftovers in the parsing code...",14,data/crawl/squid/hunk_5854.cpp,,,data/crawl/squid/old_hunk_5854.cpp,data/crawl/squid/new_hunk_5854.cpp,10,-1,"fatal(""storeDiskdDirParse: invalid magic2 value"");",,"[""removeLog""]","[[""fatal"", ""storeDiskdDirParse"", ""invalid"", ""magic2"", ""value""], []]",[8762154747394679386],6573,14400.0,2
https://github.com/squid-cache/squid/commit/54b7fec9eafb0777f3d6e2450f39a36d60f9b344,02 Mar 2001,"Oops.. the transition to cache_dir options for Q1 and Q2 was not fully
finished. There was many leftovers in the parsing code...",14,data/crawl/squid/hunk_5854.cpp,,,data/crawl/squid/old_hunk_5854.cpp,data/crawl/squid/new_hunk_5854.cpp,6,-1,"fatal(""storeDiskdDirParse: invalid magic1 value"");",,"[""removeLog""]","[[""fatal"", ""storeDiskdDirParse"", ""invalid"", ""magic1"", ""value""], []]",[8762154747394679389],6572,14400.0,2
https://github.com/squid-cache/squid/commit/a560ee938de92d50e3d788f4c5067734978c1784,28 Jul 2001,"ACL driven reply_body_max_size by Robert Collins.

Bugzilla #75",207,data/crawl/squid/hunk_5817.cpp,,,data/crawl/squid/old_hunk_5817.cpp,data/crawl/squid/new_hunk_5817.cpp,-1,29,,"storeAppendPrintf(entry, "" %s%s"",
		    l->op ? null_string : ""!"",
		    l->acl->name);","[""addLog""]","[[], [""storeAppendPrintf"", ""entry"", ""%s%s"", ""l"", ""op"", ""null_string"", ""l"", ""acl"", ""name""]]",[16107525661293422335],6571,828000.0,2
https://github.com/squid-cache/squid/commit/c94af0b96468ba69e7b8253488a699efd16a49cb,10 Aug 2001,"COSS fixes from diskio.
This code is now stable, but <2gb and sync.
Next, >2gb.",193,data/crawl/squid/hunk_5806.cpp,,,data/crawl/squid/old_hunk_5806.cpp,data/crawl/squid/new_hunk_5806.cpp,-1,11,,"fatal(""COSS requires max-size to be set to something other than -1!\n"");","[""addLog""]","[[], [""fatal"", ""COSS"", ""requires"", ""max"", ""size"", ""to"", ""be"", ""set"", ""to"", ""something"", ""other"", ""than"", ""1"", ""\\n""]]",[6478755802956658214],6570,0.0,2
https://github.com/squid-cache/squid/commit/dd1ee1e651c0456021274dc194c11b6152e0fba7,12 Aug 2001,"* Add support for the async write op
* Make sure we call freefunc() on the buffer in the write op case",38,data/crawl/squid/hunk_5802.cpp,,,data/crawl/squid/old_hunk_5802.cpp,data/crawl/squid/new_hunk_5802.cpp,-1,15,,"fatal(""Aiee! out of aiocb slots!\n"");","[""addLog""]","[[], [""fatal"", ""Aiee"", ""out"", ""of"", ""aiocb"", ""slots"", ""\\n""]]",[-14025089344181988516],6569,0.0,2
https://github.com/squid-cache/squid/commit/32754419a27c336e2469c7af600096aa6fdc39ab,24 Oct 2001,format fixes,200,data/crawl/squid/hunk_5733.cpp,,,data/crawl/squid/old_hunk_5733.cpp,data/crawl/squid/new_hunk_5733.cpp,3,3,"storeAppendPrintf(e, "" %s=%d"", option, sd->max_objsize);","storeAppendPrintf(e, "" %s=%ld"", option, (long int) sd->max_objsize);","[""updateContent"", ""addVariable""]","[[""%d""], [""%ld"", ""long"", ""int""]]",[-6359622888960138661],6568,0.0,2
https://github.com/squid-cache/squid/commit/ed19251ae02f66618d896168559022c702b740b2,24 Oct 2001,format fixes,124,data/crawl/squid/hunk_5731.cpp,,,data/crawl/squid/old_hunk_5731.cpp,data/crawl/squid/new_hunk_5731.cpp,3,3,"storeAppendPrintf(s, ""req_sz %d\n"", http->req_sz);","storeAppendPrintf(s, ""req_sz %ld\n"", (long int) http->req_sz);","[""updateContent"", ""addVariable""]","[[""%d\\n""], [""%ld\\n"", ""long"", ""int""]]",[-9994225909338810349],6567,0.0,2
https://github.com/squid-cache/squid/commit/1b3db6d92da76719fef67d8dec547908f971c5b6,24 Dec 2001,"Break out the comm code into a more ""modular"" format - poll code
in comm_poll.c, select code in comm_select.c . Rename some of the relevant
#defines (HAVE_POLL/USE_POLL) whilst I'm at it to make things consistent.",2017,data/crawl/squid/hunk_5703.cpp,,,data/crawl/squid/old_hunk_5703.cpp,data/crawl/squid/new_hunk_5703.cpp,-1,583,,"storeAppendPrintf(sentry, ""HTTP Messages handled per comm_poll_http_incoming() call:\n"");","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""HTTP"", ""Messages"", ""handled"", ""per"", ""comm_poll_http_incoming"", ""call"", ""\\n""]]",[28037420321787097118],6566,901440.0,2
https://github.com/squid-cache/squid/commit/1b3db6d92da76719fef67d8dec547908f971c5b6,24 Dec 2001,"Break out the comm code into a more ""modular"" format - poll code
in comm_poll.c, select code in comm_select.c . Rename some of the relevant
#defines (HAVE_POLL/USE_POLL) whilst I'm at it to make things consistent.",2017,data/crawl/squid/hunk_5703.cpp,,,data/crawl/squid/old_hunk_5703.cpp,data/crawl/squid/new_hunk_5703.cpp,-1,581,,"storeAppendPrintf(sentry, ""DNS Messages handled per comm_poll_dns_incoming() call:\n"");","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""DNS"", ""Messages"", ""handled"", ""per"", ""comm_poll_dns_incoming"", ""call"", ""\\n""]]",[11814887229675089924],6565,707760.0,2
https://github.com/squid-cache/squid/commit/1b3db6d92da76719fef67d8dec547908f971c5b6,24 Dec 2001,"Break out the comm code into a more ""modular"" format - poll code
in comm_poll.c, select code in comm_select.c . Rename some of the relevant
#defines (HAVE_POLL/USE_POLL) whilst I'm at it to make things consistent.",2017,data/crawl/squid/hunk_5703.cpp,,,data/crawl/squid/old_hunk_5703.cpp,data/crawl/squid/new_hunk_5703.cpp,-1,579,,"storeAppendPrintf(sentry, ""ICP Messages handled per comm_poll_icp_incoming() call:\n"");","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""ICP"", ""Messages"", ""handled"", ""per"", ""comm_poll_icp_incoming"", ""call"", ""\\n""]]",[17952605922830638338],6564,901440.0,2
https://github.com/squid-cache/squid/commit/1b3db6d92da76719fef67d8dec547908f971c5b6,24 Dec 2001,"Break out the comm code into a more ""modular"" format - poll code
in comm_poll.c, select code in comm_select.c . Rename some of the relevant
#defines (HAVE_POLL/USE_POLL) whilst I'm at it to make things consistent.",2017,data/crawl/squid/hunk_5703.cpp,,,data/crawl/squid/old_hunk_5703.cpp,data/crawl/squid/new_hunk_5703.cpp,-1,368,,"fatalf(""bad return value from commDeferRead(FD %d)\n"", i);","[""addLog""]","[[], [""fatalf"", ""bad"", ""return"", ""value"", ""from"", ""commDeferRead"", ""FD"", ""%d"", ""\\n"", ""i""]]",[-3488724790638796820],6563,521280.0,2
https://github.com/squid-cache/squid/commit/fab7a87efecd0ee96094fb21db85441374d9ba62,07 Jan 2002,"Large rewrite to support one-shot mode of operation (one user per PAM
connection, no connection cache).

Have also added a man page describing it's use.",233,data/crawl/squid/hunk_5699.cpp,,,data/crawl/squid/old_hunk_5699.cpp,data/crawl/squid/new_hunk_5699.cpp,-1,96,,"fprintf(stderr, ""ERROR: failed to create PAM authenticator\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""ERROR"", ""failed"", ""to"", ""create"", ""PAM"", ""authenticator\\n""]]",[-18643874290554917814],6562,262080.0,2
https://github.com/squid-cache/squid/commit/4e2c57a0431489369bd9869aff83772eee1c0ef9,30 Mar 2002,SASL auth helper by Ian Castle,173,data/crawl/squid/hunk_5688.cpp,,,data/crawl/squid/old_hunk_5688.cpp,data/crawl/squid/new_hunk_5688.cpp,-1,90,,"fprintf( stdout, ""OK\n"" );","[""addLog""]","[[], [""fprintf"", ""stdout"", ""OK\\n""]]",[-13937555640283875909],6561,321120.0,2
https://github.com/squid-cache/squid/commit/4e2c57a0431489369bd9869aff83772eee1c0ef9,30 Mar 2002,SASL auth helper by Ian Castle,173,data/crawl/squid/hunk_5688.cpp,,,data/crawl/squid/old_hunk_5688.cpp,data/crawl/squid/new_hunk_5688.cpp,-1,65,,"fprintf( stderr, ""authenticator: Unexpected input '%s'\n"", line );","[""addLog""]","[[], [""fprintf"", ""stderr"", ""authenticator"", ""Unexpected"", ""input"", ""%s"", ""\\n"", ""line""]]",[-14637057020941096890],6560,0.0,2
https://github.com/squid-cache/squid/commit/d96ceb8e4214ec5c04de85ee9814a87be33956c3,06 Apr 2002,"* Commit Andres Kroonmaa's chunked memory pool allocator
* bootstrap",2866,data/crawl/squid/hunk_5680.cpp,,,data/crawl/squid/old_hunk_5680.cpp,data/crawl/squid/new_hunk_5680.cpp,2,2,"storeAppendPrintf(sentry, ""\tTotal in use:          %6d KB %d%%\n"",
	t >> 10, percent(t, mp.arena));","storeAppendPrintf(sentry, ""\tTotal in use:          %6d KB %d%%\n"",
	t >> 10, percent(t, mp.arena + mp.hblkhd));","[""addVariable""]","[[], [""mp"", ""hblkhd""]]",[-4611073784348660412],6559,0.0,2
https://github.com/squid-cache/squid/commit/6473554b0c7508dcc1440bc44633f2c131d20232,13 Apr 2002,Bootstrapped,942,data/crawl/squid/hunk_5674.cpp,,,data/crawl/squid/old_hunk_5674.cpp,data/crawl/squid/new_hunk_5674.cpp,-1,430,,"fprintf(f, ""%d\n"", sizeof(u_int64_t));","[""addLog""]","[[], [""fprintf"", ""f"", ""%d\\n"", ""sizeof"", ""u_int64_t""]]",[-7922969409867035317],6558,295920.0,2
https://github.com/squid-cache/squid/commit/6473554b0c7508dcc1440bc44633f2c131d20232,13 Apr 2002,Bootstrapped,942,data/crawl/squid/hunk_5674.cpp,,,data/crawl/squid/old_hunk_5674.cpp,data/crawl/squid/new_hunk_5674.cpp,-1,385,,"fprintf(f, ""%d\n"", sizeof(uint64_t));","[""addLog""]","[[], [""fprintf"", ""f"", ""%d\\n"", ""sizeof"", ""uint64_t""]]",[-10871295476171264403],6557,295920.0,2
https://github.com/squid-cache/squid/commit/6473554b0c7508dcc1440bc44633f2c131d20232,13 Apr 2002,Bootstrapped,942,data/crawl/squid/hunk_5674.cpp,,,data/crawl/squid/old_hunk_5674.cpp,data/crawl/squid/new_hunk_5674.cpp,-1,340,,"fprintf(f, ""%d\n"", sizeof(int64_t));","[""addLog""]","[[], [""fprintf"", ""f"", ""%d\\n"", ""sizeof"", ""int64_t""]]",[2448077763263589001],6556,295920.0,2
https://github.com/squid-cache/squid/commit/6473554b0c7508dcc1440bc44633f2c131d20232,13 Apr 2002,Bootstrapped,942,data/crawl/squid/hunk_5674.cpp,,,data/crawl/squid/old_hunk_5674.cpp,data/crawl/squid/new_hunk_5674.cpp,-1,295,,"fprintf(f, ""%d\n"", sizeof(u_int32_t));","[""addLog""]","[[], [""fprintf"", ""f"", ""%d\\n"", ""sizeof"", ""u_int32_t""]]",[5523635663285515702],6555,295920.0,2
https://github.com/squid-cache/squid/commit/6473554b0c7508dcc1440bc44633f2c131d20232,13 Apr 2002,Bootstrapped,942,data/crawl/squid/hunk_5674.cpp,,,data/crawl/squid/old_hunk_5674.cpp,data/crawl/squid/new_hunk_5674.cpp,-1,250,,"fprintf(f, ""%d\n"", sizeof(uint32_t));","[""addLog""]","[[], [""fprintf"", ""f"", ""%d\\n"", ""sizeof"", ""uint32_t""]]",[4575451597511287016],6554,295920.0,2
https://github.com/squid-cache/squid/commit/6473554b0c7508dcc1440bc44633f2c131d20232,13 Apr 2002,Bootstrapped,942,data/crawl/squid/hunk_5674.cpp,,,data/crawl/squid/old_hunk_5674.cpp,data/crawl/squid/new_hunk_5674.cpp,-1,205,,"fprintf(f, ""%d\n"", sizeof(int32_t));","[""addLog""]","[[], [""fprintf"", ""f"", ""%d\\n"", ""sizeof"", ""int32_t""]]",[-2552061237549412356],6553,295920.0,2
https://github.com/squid-cache/squid/commit/6473554b0c7508dcc1440bc44633f2c131d20232,13 Apr 2002,Bootstrapped,942,data/crawl/squid/hunk_5674.cpp,,,data/crawl/squid/old_hunk_5674.cpp,data/crawl/squid/new_hunk_5674.cpp,-1,160,,"fprintf(f, ""%d\n"", sizeof(u_int16_t));","[""addLog""]","[[], [""fprintf"", ""f"", ""%d\\n"", ""sizeof"", ""u_int16_t""]]",[3523625663267515724],6552,295920.0,2
https://github.com/squid-cache/squid/commit/6473554b0c7508dcc1440bc44633f2c131d20232,13 Apr 2002,Bootstrapped,942,data/crawl/squid/hunk_5674.cpp,,,data/crawl/squid/old_hunk_5674.cpp,data/crawl/squid/new_hunk_5674.cpp,-1,115,,"fprintf(f, ""%d\n"", sizeof(uint16_t));","[""addLog""]","[[], [""fprintf"", ""f"", ""%d\\n"", ""sizeof"", ""uint16_t""]]",[2575433597429286894],6551,295920.0,2
https://github.com/squid-cache/squid/commit/6473554b0c7508dcc1440bc44633f2c131d20232,13 Apr 2002,Bootstrapped,942,data/crawl/squid/hunk_5674.cpp,,,data/crawl/squid/old_hunk_5674.cpp,data/crawl/squid/new_hunk_5674.cpp,-1,70,,"fprintf(f, ""%d\n"", sizeof(int16_t));","[""addLog""]","[[], [""fprintf"", ""f"", ""%d\\n"", ""sizeof"", ""int16_t""]]",[-4552071237567412346],6550,295920.0,2
https://github.com/squid-cache/squid/commit/6473554b0c7508dcc1440bc44633f2c131d20232,13 Apr 2002,Bootstrapped,942,data/crawl/squid/hunk_5674.cpp,,,data/crawl/squid/old_hunk_5674.cpp,data/crawl/squid/new_hunk_5674.cpp,-1,25,,"fprintf(f, ""%d\n"", sizeof(__int64));","[""addLog""]","[[], [""fprintf"", ""f"", ""%d\\n"", ""sizeof"", ""__int64""]]",[-366467775559753470],6549,295920.0,2
https://github.com/squid-cache/squid/commit/a2f30fc74c0f2ba7b662833a6f12d5233c07c3f2,23 May 2002,"new config.guess, dated 2002-03-04, from autoconf-2.53",254,data/crawl/squid/hunk_5653.cpp,,,data/crawl/squid/old_hunk_5653.cpp,data/crawl/squid/new_hunk_5653.cpp,16,-1,"printf (""%s-pc-linux-gnulibc1\n"", argv[1]);",,"[""removeLog""]","[[""printf"", ""%s"", ""pc"", ""linux"", ""gnulibc1\\n"", ""argv[1]""], []]",[-11866109334529106382],6548,0.0,2
https://github.com/squid-cache/squid/commit/8f7b71f7a6c7d51b7621167b0a0f31b5d1f173cc,23 Jun 2002,A simple external_acl helper to match LDAP groups,295,data/crawl/squid/hunk_5636.cpp,,,data/crawl/squid/old_hunk_5636.cpp,data/crawl/squid/new_hunk_5636.cpp,-1,222,,"fprintf(stderr, ""\nUnable to connect to LDAP server:%s port:%d\n"",
		    ldapServer, LDAP_PORT);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""\\nUnable"", ""to"", ""connect"", ""to"", ""LDAP"", ""server"", ""%s"", ""port"", ""%d\\n"", ""ldapServer"", ""LDAP_PORT""]]",[-1845135886420068900],6547,382320.0,2
https://github.com/squid-cache/squid/commit/8f7b71f7a6c7d51b7621167b0a0f31b5d1f173cc,23 Jun 2002,A simple external_acl helper to match LDAP groups,295,data/crawl/squid/hunk_5636.cpp,,,data/crawl/squid/old_hunk_5636.cpp,data/crawl/squid/new_hunk_5636.cpp,-1,202,,"fprintf(stderr, ""\tIf you need to bind as a user to perform searches then use the\n\t-D binddn -w bindpasswd options\n\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""\\tIf"", ""you"", ""need"", ""to"", ""bind"", ""as"", ""a"", ""user"", ""to"", ""perform"", ""searches"", ""then"", ""use"", ""the\\n\\t"", ""D"", ""binddn"", ""w"", ""bindpasswd"", ""options\\n\\n""]]",[-21723973618091670876],6546,311760.0,2
https://github.com/squid-cache/squid/commit/8f7b71f7a6c7d51b7621167b0a0f31b5d1f173cc,23 Jun 2002,A simple external_acl helper to match LDAP groups,295,data/crawl/squid/hunk_5636.cpp,,,data/crawl/squid/old_hunk_5636.cpp,data/crawl/squid/new_hunk_5636.cpp,-1,200,,"fprintf(stderr, ""\t-a never|always|search|find\n\t\t\t\twhen to dereference aliases\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""\\t"", ""a"", ""never"", ""always"", ""search"", ""find\\n\\t\\t\\t\\twhen"", ""to"", ""dereference"", ""aliases\\n""]]",[-11146516176042788410],6545,311040.0,2
https://github.com/squid-cache/squid/commit/8f7b71f7a6c7d51b7621167b0a0f31b5d1f173cc,23 Jun 2002,A simple external_acl helper to match LDAP groups,295,data/crawl/squid/hunk_5636.cpp,,,data/crawl/squid/old_hunk_5636.cpp,data/crawl/squid/new_hunk_5636.cpp,-1,199,,"fprintf(stderr, ""\t-R\t\t\tdo not follow referrals\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""\\t"", ""R\\t\\t\\tdo"", ""not"", ""follow"", ""referrals\\n""]]",[-4631610688282656088],6544,311040.0,2
https://github.com/squid-cache/squid/commit/8f7b71f7a6c7d51b7621167b0a0f31b5d1f173cc,23 Jun 2002,A simple external_acl helper to match LDAP groups,295,data/crawl/squid/hunk_5636.cpp,,,data/crawl/squid/old_hunk_5636.cpp,data/crawl/squid/new_hunk_5636.cpp,-1,197,,"fprintf(stderr, ""\t-w bindpasswd\t\tpassword for binddn\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""\\t"", ""w"", ""bindpasswd\\t\\tpassword"", ""for"", ""binddn\\n""]]",[-20996528363116112049],6543,311760.0,2
https://github.com/squid-cache/squid/commit/8f7b71f7a6c7d51b7621167b0a0f31b5d1f173cc,23 Jun 2002,A simple external_acl helper to match LDAP groups,295,data/crawl/squid/hunk_5636.cpp,,,data/crawl/squid/old_hunk_5636.cpp,data/crawl/squid/new_hunk_5636.cpp,-1,196,,"fprintf(stderr, ""\t-D binddn\t\tDN to bind as to perform searches\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""\\t"", ""D"", ""binddn\\t\\tDN"", ""to"", ""bind"", ""as"", ""to"", ""perform"", ""searches\\n""]]",[-12647030441262777009],6542,311760.0,2
https://github.com/squid-cache/squid/commit/8f7b71f7a6c7d51b7621167b0a0f31b5d1f173cc,23 Jun 2002,A simple external_acl helper to match LDAP groups,295,data/crawl/squid/hunk_5636.cpp,,,data/crawl/squid/old_hunk_5636.cpp,data/crawl/squid/new_hunk_5636.cpp,-1,195,,"fprintf(stderr, ""\t-s base|one|sub\t\tsearch scope\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""\\t"", ""s"", ""base"", ""one"", ""sub\\t\\tsearch"", ""scope\\n""]]",[-3711046901917112876],6541,311760.0,2
https://github.com/squid-cache/squid/commit/eb7d6bd6cbfc077ca677fa41253a29a1f1f9c6fb,15 Jul 2002,"Cleanup of Gopher HTML code to use a common header format, and the
standard Squid signature.",59,data/crawl/squid/hunk_5624.cpp,,,data/crawl/squid/old_hunk_5624.cpp,data/crawl/squid/new_hunk_5624.cpp,-1,22,,"storeAppendPrintf(e, ""</ADDRESS></BODY></HTML>\n"");","[""addLog""]","[[], [""storeAppendPrintf"", ""e"", ""/ADDRESS"", ""/BODY"", ""/HTML"", ""\\n""]]",[4728870564532490563],6540,1350720.0,2
https://github.com/squid-cache/squid/commit/eb7d6bd6cbfc077ca677fa41253a29a1f1f9c6fb,15 Jul 2002,"Cleanup of Gopher HTML code to use a common header format, and the
standard Squid signature.",59,data/crawl/squid/hunk_5624.cpp,,,data/crawl/squid/old_hunk_5624.cpp,data/crawl/squid/new_hunk_5624.cpp,-1,17,,"storeAppendPrintf(e, ""<ADDRESS>\n"");","[""addLog""]","[[], [""storeAppendPrintf"", ""e"", ""ADDRESS"", ""\\n""]]",[-3565031264689621166],6539,1350720.0,2
https://github.com/squid-cache/squid/commit/eb7d6bd6cbfc077ca677fa41253a29a1f1f9c6fb,15 Jul 2002,"Cleanup of Gopher HTML code to use a common header format, and the
standard Squid signature.",59,data/crawl/squid/hunk_5624.cpp,,,data/crawl/squid/old_hunk_5624.cpp,data/crawl/squid/new_hunk_5624.cpp,-1,7,,"storeAppendPrintf(e, title, substring);","[""addLog""]","[[], [""storeAppendPrintf"", ""e"", ""title"", ""substring""]]",[363019237628138938],6538,0.0,2
https://github.com/squid-cache/squid/commit/429d7b01dda4ee715f5dc2327a18b10657e40635,20 Jul 2002,"winbind helpers cleanup by Guido

- wb_ntlmauth (ntlm): Fixed error message on wrong command line
- wb_auth (basic): Added same command line handling and fix to Squid
potential DoS issue as wb_ntlmauth.
- wb_group (External ACL): Added same command line handling and fix to
Squid potential DoS issue as wb_ntlmauth.",96,data/crawl/squid/hunk_5613.cpp,,,data/crawl/squid/old_hunk_5613.cpp,data/crawl/squid/new_hunk_5613.cpp,-1,6,,"fprintf(stderr,""Usage: %s [-d] [-h]\n""
	    	"" -d      enable debugging\n""
		"" -h      this message\n"",
		program);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""Usage"", ""%s"", ""["", ""d]"", ""["", ""h]\\n"", ""d"", ""enable"", ""debugging\\n"", ""h"", ""this"", ""message\\n"", ""program""]]",[23205508201027029269],6537,0.0,2
https://github.com/squid-cache/squid/commit/6328cedceb815cfc5537237fe58fe2023e0ed6b7,12 Aug 2002,Updated UNIX group helper,428,data/crawl/squid/hunk_5599.cpp,,,data/crawl/squid/old_hunk_5599.cpp,data/crawl/squid/new_hunk_5599.cpp,-1,221,,"fprintf(stderr, ""Unknown option '%s'\n"", argv[optind]);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""Unknown"", ""option"", ""%s"", ""\\n"", ""argv[optind]""]]",[-18437110933072029326],6536,156240.0,2
https://github.com/squid-cache/squid/commit/387b9f71d0a3ff9bf0eb26986e4f5b21065b8d73,05 Sep 2002,Upgraded to version 2.2,203,data/crawl/squid/hunk_5593.cpp,,,data/crawl/squid/old_hunk_5593.cpp,data/crawl/squid/new_hunk_5593.cpp,-1,33,,"fprintf(stderr, ""\t-v 1|2\t\t\tLDAP version\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""\\t"", ""v"", ""1"", ""2\\t\\t\\tLDAP"", ""version\\n""]]",[-21218519462745272872],6535,66960.0,2
https://github.com/squid-cache/squid/commit/edce4d98cbc995233439cb4af45513edecb0550c,15 Sep 2002,"clientStreams, rationalising the client side logic to allow plugin output streams, and providing a simple interface to the store. See the programmers guide for details",5389,data/crawl/squid/hunk_5580.cpp,,,data/crawl/squid/old_hunk_5580.cpp,data/crawl/squid/new_hunk_5580.cpp,-1,1129,,"httpHeaderPutStrf(hdr, HDR_X_CACHE, ""%s from %s"",
	is_hit ? ""HIT"" : ""MISS"", getMyHostname());","[""addLog""]","[[], [""httpHeaderPutStrf"", ""hdr"", ""HDR_X_CACHE"", ""%s"", ""from"", ""%s"", ""is_hit"", ""HIT"", ""MISS"", ""getMyHostname""]]",[-1145198758666488786],6534,1131120.0,2
https://github.com/squid-cache/squid/commit/29b8d8d6366760bd4b285d6f6d56042439e55e50,15 Sep 2002,fix headers to allow inclusion into C++ source,1555,data/crawl/squid/hunk_5573.cpp,,,data/crawl/squid/old_hunk_5573.cpp,data/crawl/squid/new_hunk_5573.cpp,1,1,"storeAppendPrintf(entry, "" %s%s"",
	    l->op ? null_string : ""!"",
	    l->acl->name);","storeAppendPrintf(entry, "" %s%s"",
	    l->op ? null_string : ""!"",
	    l->_acl->name);","[""updateVariable""]","[[""acl""], [""_acl""]]",[5848854120940305982],6533,0.0,2
https://github.com/squid-cache/squid/commit/12e137b0e48abcee9185f2ed456afecd41c2c79b,03 Oct 2002,split async io counters into started and finished to give better visibility on outstanding requests,121,data/crawl/squid/hunk_5559.cpp,,,data/crawl/squid/old_hunk_5559.cpp,data/crawl/squid/new_hunk_5559.cpp,6,6,"storeAppendPrintf(sentry, ""cancel\t%d\n"", squidaio_counts.cancel);","storeAppendPrintf(sentry, ""cancel\t%d\t-\n"", squidaio_counts.cancel);","[""updateContent""]","[[""cancel\\t%d\\n""], [""cancel\\t%d\\t"", ""\\n""]]",[11776070748106334],6532,0.0,2
https://github.com/squid-cache/squid/commit/e48ed43391a35b15066e876ca69755a5582dc26b,25 Oct 2002,cbdata history for cbdata debug mode,162,data/crawl/squid/hunk_5501.cpp,,,data/crawl/squid/old_hunk_5501.cpp,data/crawl/squid/new_hunk_5501.cpp,-1,40,,"storeAppendPrintf(sentry, ""%d cbdata entries\n"", cbdataCount);","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""%d"", ""cbdata"", ""entries\\n"", ""cbdataCount""]]",[8772467633393369014],6531,1290240.0,2
https://github.com/squid-cache/squid/commit/e48ed43391a35b15066e876ca69755a5582dc26b,25 Oct 2002,cbdata history for cbdata debug mode,162,data/crawl/squid/hunk_5501.cpp,,,data/crawl/squid/old_hunk_5501.cpp,data/crawl/squid/new_hunk_5501.cpp,-1,28,,"storeAppendPrintf(where, ""\n"");","[""addLog""]","[[], [""storeAppendPrintf"", ""where"", ""\\n""]]",[3995915360435094291],6530,0.0,2
https://github.com/squid-cache/squid/commit/147a3e90ec90e94424b47fd412a9872318c740f0,02 Dec 2002,allow Visual Studio to compile cf_gen,85,data/crawl/squid/hunk_5488.cpp,,,data/crawl/squid/old_hunk_5488.cpp,data/crawl/squid/new_hunk_5488.cpp,-1,4,,"fprintf(fp,""\t};\n"");","[""addLog""]","[[], [""fprintf"", ""fp"", ""\\t"", ""\\n""]]",[-5167530254375540690],6529,678960.0,2
https://github.com/squid-cache/squid/commit/a7ad6e4e64c71376d504e1e1727b2c7b7930898d,07 Dec 2002,"SSL support update

 - Support for outgoing SSL connetions
   - SSL encrypted peers
   - https:// gatewaying for clients not supporting SSL
     or URLs rewritten via a redirector to https://...

 - Client certificate support

 - Hardware crypto SSL acceleration support via OpenSSL engine

 - SSL key/certificate now read while parsing squid.conf to
   support secure key protection and chroot.

 - A few minor bugfixes/optimizations",1106,data/crawl/squid/hunk_5486.cpp,,,data/crawl/squid/old_hunk_5486.cpp,data/crawl/squid/new_hunk_5486.cpp,-1,3,,"fatalf(""Failed to set SSL cipher suite '%s': %s\n"",
		cipher, ERR_error_string(ssl_error, NULL));","[""addLog""]","[[], [""fatalf"", ""Failed"", ""to"", ""set"", ""SSL"", ""cipher"", ""suite"", ""%s"", ""%s\\n"", ""cipher"", ""ERR_error_string"", ""ssl_error"", ""NULL""]]",[-9112559239306279508],6528,0.0,2
https://github.com/squid-cache/squid/commit/a7ad6e4e64c71376d504e1e1727b2c7b7930898d,07 Dec 2002,"SSL support update

 - Support for outgoing SSL connetions
   - SSL encrypted peers
   - https:// gatewaying for clients not supporting SSL
     or URLs rewritten via a redirector to https://...

 - Client certificate support

 - Hardware crypto SSL acceleration support via OpenSSL engine

 - SSL key/certificate now read while parsing squid.conf to
   support secure key protection and chroot.

 - A few minor bugfixes/optimizations",1106,data/crawl/squid/hunk_5483.cpp,,,data/crawl/squid/old_hunk_5483.cpp,data/crawl/squid/new_hunk_5483.cpp,-1,11,,"fatal(""unknown external_acl format error"");","[""addLog""]","[[], [""fatal"", ""unknown"", ""external_acl"", ""format"", ""error""]]",[7503529408969980762],6527,0.0,2
https://github.com/squid-cache/squid/commit/a7ad6e4e64c71376d504e1e1727b2c7b7930898d,07 Dec 2002,"SSL support update

 - Support for outgoing SSL connetions
   - SSL encrypted peers
   - https:// gatewaying for clients not supporting SSL
     or URLs rewritten via a redirector to https://...

 - Client certificate support

 - Hardware crypto SSL acceleration support via OpenSSL engine

 - SSL key/certificate now read while parsing squid.conf to
   support secure key protection and chroot.

 - A few minor bugfixes/optimizations",1106,data/crawl/squid/hunk_5483.cpp,,,data/crawl/squid/old_hunk_5483.cpp,data/crawl/squid/new_hunk_5483.cpp,-1,4,,"storeAppendPrintf(sentry, "" %%USER_CERT_%s"", format->header);","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""%%USER_CERT_%s"", ""format"", ""header""]]",[12013805193580684723],6526,0.0,2
https://github.com/squid-cache/squid/commit/d3b3ab859857da0851f9c7de916b6df261ba43ae,27 Dec 2002,apply unify io patch to simplify IO code for diskd/aufs/ufs,7586,data/crawl/squid/hunk_5473.cpp,,,data/crawl/squid/old_hunk_5473.cpp,data/crawl/squid/new_hunk_5473.cpp,-1,608,,"fatal(""commonUfsDirCloseTmpSwapLog: Failed to open swap log."");","[""addLog""]","[[], [""fatal"", ""commonUfsDirCloseTmpSwapLog"", ""Failed"", ""to"", ""open"", ""swap"", ""log""]]",[-13294787753322104408],6525,54720.0,2
https://github.com/squid-cache/squid/commit/d3b3ab859857da0851f9c7de916b6df261ba43ae,27 Dec 2002,apply unify io patch to simplify IO code for diskd/aufs/ufs,7586,data/crawl/squid/hunk_5473.cpp,,,data/crawl/squid/old_hunk_5473.cpp,data/crawl/squid/new_hunk_5473.cpp,-1,603,,"fatal(""commonUfsDirCloseTmpSwapLog: rename failed"");","[""addLog""]","[[], [""fatal"", ""commonUfsDirCloseTmpSwapLog"", ""rename"", ""failed""]]",[-23077252140658217855],6524,54720.0,2
https://github.com/squid-cache/squid/commit/d3b3ab859857da0851f9c7de916b6df261ba43ae,27 Dec 2002,apply unify io patch to simplify IO code for diskd/aufs/ufs,7586,data/crawl/squid/hunk_5473.cpp,,,data/crawl/squid/old_hunk_5473.cpp,data/crawl/squid/new_hunk_5473.cpp,-1,65,,"fatal(""storeAufsDirParse: invalid level 1 directories value"");","[""addLog""]","[[], [""fatal"", ""storeAufsDirParse"", ""invalid"", ""level"", ""1"", ""directories"", ""value""]]",[-20381767880830507793],6523,696960.0,2
https://github.com/squid-cache/squid/commit/d3b3ab859857da0851f9c7de916b6df261ba43ae,27 Dec 2002,apply unify io patch to simplify IO code for diskd/aufs/ufs,7586,data/crawl/squid/hunk_5473.cpp,,,data/crawl/squid/old_hunk_5473.cpp,data/crawl/squid/new_hunk_5473.cpp,-1,62,,"fatal(""storeAufsDirParse: invalid size value"");","[""addLog""]","[[], [""fatal"", ""storeAufsDirParse"", ""invalid"", ""size"", ""value""]]",[-31223036232158628979],6522,696960.0,2
https://github.com/squid-cache/squid/commit/d3b3ab859857da0851f9c7de916b6df261ba43ae,27 Dec 2002,apply unify io patch to simplify IO code for diskd/aufs/ufs,7586,data/crawl/squid/hunk_5472.cpp,,,data/crawl/squid/old_hunk_5472.cpp,data/crawl/squid/new_hunk_5472.cpp,-1,21,,"fatal (""Attempt to get a StoreIO from the NULL store!\n"");","[""addLog""]","[[], [""fatal"", ""Attempt"", ""to"", ""get"", ""a"", ""StoreIO"", ""from"", ""the"", ""NULL"", ""store"", ""\\n""]]",[-5257834271153246970],6521,0.0,2
https://github.com/squid-cache/squid/commit/d3b3ab859857da0851f9c7de916b6df261ba43ae,27 Dec 2002,apply unify io patch to simplify IO code for diskd/aufs/ufs,7586,data/crawl/squid/hunk_5471.cpp,,,data/crawl/squid/old_hunk_5471.cpp,data/crawl/squid/new_hunk_5471.cpp,-1,111,,"fatal(""shmat failed"");","[""addLog""]","[[], [""fatal"", ""shmat"", ""failed""]]",[-7429966131967231156],6520,696960.0,2
https://github.com/squid-cache/squid/commit/d3b3ab859857da0851f9c7de916b6df261ba43ae,27 Dec 2002,apply unify io patch to simplify IO code for diskd/aufs/ufs,7586,data/crawl/squid/hunk_5471.cpp,,,data/crawl/squid/old_hunk_5471.cpp,data/crawl/squid/new_hunk_5471.cpp,-1,106,,"fatal(""shmget failed"");","[""addLog""]","[[], [""fatal"", ""shmget"", ""failed""]]",[-6810427592387860720],6519,696960.0,2
https://github.com/squid-cache/squid/commit/d3b3ab859857da0851f9c7de916b6df261ba43ae,27 Dec 2002,apply unify io patch to simplify IO code for diskd/aufs/ufs,7586,data/crawl/squid/hunk_5469.cpp,,,data/crawl/squid/old_hunk_5469.cpp,data/crawl/squid/new_hunk_5469.cpp,15,15,"storeAppendPrintf(e, "" Q1=%d"", diskdinfo->magic1);","storeAppendPrintf(e, "" Q1=%d"", IO->magic1);","[""updateVariable""]","[[""diskdinfo""], [""IO""]]",[4776487161100257370],6518,0.0,2
https://github.com/squid-cache/squid/commit/d3b3ab859857da0851f9c7de916b6df261ba43ae,27 Dec 2002,apply unify io patch to simplify IO code for diskd/aufs/ufs,7586,data/crawl/squid/hunk_5464.cpp,,,data/crawl/squid/old_hunk_5464.cpp,data/crawl/squid/new_hunk_5464.cpp,42,36,"storeAppendPrintf(sentry, ""Number of object collisions: %d\n"", (int) cs->numcollisions);","storeAppendPrintf(&sentry, ""Number of object collisions: %d\n"", (int) numcollisions);","[""removeVariable"", ""addVariable""]","[[""sentry"", ""cs""], [""&sentry""]]",[3257005708990499141],6517,0.0,2
https://github.com/squid-cache/squid/commit/d3b3ab859857da0851f9c7de916b6df261ba43ae,27 Dec 2002,apply unify io patch to simplify IO code for diskd/aufs/ufs,7586,data/crawl/squid/hunk_5464.cpp,,,data/crawl/squid/old_hunk_5464.cpp,data/crawl/squid/new_hunk_5464.cpp,38,32,"storeAppendPrintf(sentry, ""Maximum Size: %d KB\n"", SD->max_size);","storeAppendPrintf(&sentry, ""Maximum Size: %d KB\n"", max_size);","[""removeVariable"", ""addVariable""]","[[""sentry"", ""SD""], [""&sentry""]]",[3254957696686480478],6516,0.0,2
https://github.com/squid-cache/squid/commit/b67e2c8c4da9890e0f3d27d501edf6a0c0fdf1c9,05 Feb 2003,"Summary: Merge from delay-class-4
Keywords:

Patches applied:

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-23
     Merge from HEAD, and shutdown delaypools at shutdown.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-22
     Merge from HEAD.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-21
     Implement class 4 delay pools

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-20
     Fix make dist.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-19
     Document finished aspects of delay pools.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-18
     Merge from HEAD.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-17
     Fixs to handle HEAD changes.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-16
     Merge from head.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-15
     Merge from HEAD

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-14
     Merge from HEAD

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-13
     Separate out code for DelayBucket and DelayId.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-12
     More class split outs.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-11
     More class splitting

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-10
     Splitting classes out to one per file.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-9
     Starting consolidation of delay pools hierarchy.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-8
     Snapshot

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-7
     Finally got composite structure sorted - class one and two delay pools in it.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-6
     snapshotting more refactoring.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-5
     More refactoring - no functionality changes.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-4
     Another refactoring snapshot.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-3
     Snapshot of delay pools refactoring.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-2
     Refactor delay pools code to not cause globals recompiles on most changes.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-20
     Fix make dist.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-21
     Implement class 4 delay pools

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-22
     Merge from HEAD.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-23
     Merge from HEAD, and shutdown delaypools at shutdown.",12710,data/crawl/squid/hunk_5432.cpp,,,data/crawl/squid/old_hunk_5432.cpp,data/crawl/squid/new_hunk_5432.cpp,730,-1,"storeAppendPrintf(sentry, ""Not used yet."");",,"[""removeLog""]","[[""storeAppendPrintf"", ""sentry"", ""Not"", ""used"", ""yet""], []]",[-10673142881662984130],6515,0.0,2
https://github.com/squid-cache/squid/commit/b67e2c8c4da9890e0f3d27d501edf6a0c0fdf1c9,05 Feb 2003,"Summary: Merge from delay-class-4
Keywords:

Patches applied:

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-23
     Merge from HEAD, and shutdown delaypools at shutdown.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-22
     Merge from HEAD.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-21
     Implement class 4 delay pools

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-20
     Fix make dist.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-19
     Document finished aspects of delay pools.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-18
     Merge from HEAD.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-17
     Fixs to handle HEAD changes.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-16
     Merge from head.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-15
     Merge from HEAD

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-14
     Merge from HEAD

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-13
     Separate out code for DelayBucket and DelayId.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-12
     More class split outs.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-11
     More class splitting

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-10
     Splitting classes out to one per file.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-9
     Starting consolidation of delay pools hierarchy.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-8
     Snapshot

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-7
     Finally got composite structure sorted - class one and two delay pools in it.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-6
     snapshotting more refactoring.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-5
     More refactoring - no functionality changes.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-4
     Another refactoring snapshot.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-3
     Snapshot of delay pools refactoring.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-2
     Refactor delay pools code to not cause globals recompiles on most changes.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-20
     Fix make dist.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-21
     Implement class 4 delay pools

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-22
     Merge from HEAD.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-23
     Merge from HEAD, and shutdown delaypools at shutdown.",12710,data/crawl/squid/hunk_5432.cpp,,,data/crawl/squid/old_hunk_5432.cpp,data/crawl/squid/new_hunk_5432.cpp,716,-1,"storeAppendPrintf(sentry, ""\t\tRate: %d\n"", rate->individual.restore_bps);",,"[""removeLog""]","[[""storeAppendPrintf"", ""sentry"", ""\\t\\tRate"", ""%d\\n"", ""rate"", ""individual"", ""restore_bps""], []]",[-5241027730013828207],6514,0.0,2
https://github.com/squid-cache/squid/commit/b67e2c8c4da9890e0f3d27d501edf6a0c0fdf1c9,05 Feb 2003,"Summary: Merge from delay-class-4
Keywords:

Patches applied:

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-23
     Merge from HEAD, and shutdown delaypools at shutdown.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-22
     Merge from HEAD.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-21
     Implement class 4 delay pools

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-20
     Fix make dist.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-19
     Document finished aspects of delay pools.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-18
     Merge from HEAD.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-17
     Fixs to handle HEAD changes.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-16
     Merge from head.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-15
     Merge from HEAD

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-14
     Merge from HEAD

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-13
     Separate out code for DelayBucket and DelayId.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-12
     More class split outs.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-11
     More class splitting

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-10
     Splitting classes out to one per file.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-9
     Starting consolidation of delay pools hierarchy.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-8
     Snapshot

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-7
     Finally got composite structure sorted - class one and two delay pools in it.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-6
     snapshotting more refactoring.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-5
     More refactoring - no functionality changes.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-4
     Another refactoring snapshot.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-3
     Snapshot of delay pools refactoring.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-2
     Refactor delay pools code to not cause globals recompiles on most changes.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-20
     Fix make dist.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-21
     Implement class 4 delay pools

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-22
     Merge from HEAD.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-23
     Merge from HEAD, and shutdown delaypools at shutdown.",12710,data/crawl/squid/hunk_5432.cpp,,,data/crawl/squid/old_hunk_5432.cpp,data/crawl/squid/new_hunk_5432.cpp,715,-1,"storeAppendPrintf(sentry, ""\t\tMax: %d\n"", rate->individual.max_bytes);",,"[""removeLog""]","[[""storeAppendPrintf"", ""sentry"", ""\\t\\tMax"", ""%d\\n"", ""rate"", ""individual"", ""max_bytes""], []]",[-17330750759199346676],6513,0.0,2
https://github.com/squid-cache/squid/commit/b67e2c8c4da9890e0f3d27d501edf6a0c0fdf1c9,05 Feb 2003,"Summary: Merge from delay-class-4
Keywords:

Patches applied:

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-23
     Merge from HEAD, and shutdown delaypools at shutdown.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-22
     Merge from HEAD.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-21
     Implement class 4 delay pools

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-20
     Fix make dist.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-19
     Document finished aspects of delay pools.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-18
     Merge from HEAD.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-17
     Fixs to handle HEAD changes.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-16
     Merge from head.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-15
     Merge from HEAD

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-14
     Merge from HEAD

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-13
     Separate out code for DelayBucket and DelayId.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-12
     More class split outs.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-11
     More class splitting

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-10
     Splitting classes out to one per file.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-9
     Starting consolidation of delay pools hierarchy.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-8
     Snapshot

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-7
     Finally got composite structure sorted - class one and two delay pools in it.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-6
     snapshotting more refactoring.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-5
     More refactoring - no functionality changes.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-4
     Another refactoring snapshot.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-3
     Snapshot of delay pools refactoring.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-2
     Refactor delay pools code to not cause globals recompiles on most changes.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-20
     Fix make dist.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-21
     Implement class 4 delay pools

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-22
     Merge from HEAD.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-23
     Merge from HEAD, and shutdown delaypools at shutdown.",12710,data/crawl/squid/hunk_5432.cpp,,,data/crawl/squid/old_hunk_5432.cpp,data/crawl/squid/new_hunk_5432.cpp,579,-1,"fatalf(""delayBytesWanted: Invalid class %d\n"", delay_class);",,"[""removeLog""]","[[""fatalf"", ""delayBytesWanted"", ""Invalid"", ""class"", ""%d\\n"", ""delay_class""], []]",[-11657005473029996960],6512,0.0,2
https://github.com/squid-cache/squid/commit/b67e2c8c4da9890e0f3d27d501edf6a0c0fdf1c9,05 Feb 2003,"Summary: Merge from delay-class-4
Keywords:

Patches applied:

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-23
     Merge from HEAD, and shutdown delaypools at shutdown.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-22
     Merge from HEAD.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-21
     Implement class 4 delay pools

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-20
     Fix make dist.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-19
     Document finished aspects of delay pools.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-18
     Merge from HEAD.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-17
     Fixs to handle HEAD changes.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-16
     Merge from head.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-15
     Merge from HEAD

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-14
     Merge from HEAD

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-13
     Separate out code for DelayBucket and DelayId.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-12
     More class split outs.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-11
     More class splitting

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-10
     Splitting classes out to one per file.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-9
     Starting consolidation of delay pools hierarchy.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-8
     Snapshot

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-7
     Finally got composite structure sorted - class one and two delay pools in it.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-6
     snapshotting more refactoring.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-5
     More refactoring - no functionality changes.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-4
     Another refactoring snapshot.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-3
     Snapshot of delay pools refactoring.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-2
     Refactor delay pools code to not cause globals recompiles on most changes.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-20
     Fix make dist.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-21
     Implement class 4 delay pools

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-22
     Merge from HEAD.

  * robertc@squid-cache.org--squid/squid--delay-class-4--3.0--patch-23
     Merge from HEAD, and shutdown delaypools at shutdown.",12710,data/crawl/squid/hunk_5428.cpp,,,data/crawl/squid/old_hunk_5428.cpp,data/crawl/squid/new_hunk_5428.cpp,-1,123,,"storeAppendPrintf(entry, ""%s 0\n"", name);","[""addLog""]","[[], [""storeAppendPrintf"", ""entry"", ""%s"", ""0\\n"", ""name""]]",[1040633713334197220],6511,1056240.0,2
https://github.com/squid-cache/squid/commit/8000a96583c4cafed5d348fafaaed771f117287a,12 Feb 2003,"Summary: Merge of ACL refactoring.

Patches applied:

  * robertc@squid-cache.org--squid/squid--acl--3.0--patch-10
     Merge from HEAD.

  * robertc@squid-cache.org--squid/squid--acl--3.0--patch-9
     Refactoring (again!)

  * robertc@squid-cache.org--squid/squid--acl--3.0--patch-8
     More refactoring.

  * robertc@squid-cache.org--squid/squid--acl--3.0--patch-7
     Merge from HEAD.

  * robertc@squid-cache.org--squid/squid--acl--3.0--patch-6
     More refactoring.

  * robertc@squid-cache.org--squid/squid--acl--3.0--patch-5
     More refactoring of ACL's.

  * robertc@squid-cache.org--squid/squid--acl--3.0--patch-4
     Merge from HEAD.

  * robertc@squid-cache.org--squid/squid--acl--3.0--patch-3
     Still more refactoring steps.

  * robertc@squid-cache.org--squid/squid--acl--3.0--patch-2
     More refactoring.

  * robertc@squid-cache.org--squid/squid--acl--3.0--patch-1
     Bootstrap, and start refactoring.",12159,data/crawl/squid/hunk_5416.cpp,,,data/crawl/squid/old_hunk_5416.cpp,data/crawl/squid/new_hunk_5416.cpp,-1,38,,"fatal (""unused"");","[""addLog""]","[[], [""fatal"", ""unused""]]",[-10808439327566762997],6510,0.0,2
https://github.com/squid-cache/squid/commit/225b7b107261e7d01d087e1061533751c2a7a0e0,13 Feb 2003,"Summary: Merge further ACL refactoring (including bugfixes)
Keywords:

Patches applied:

  * robertc@squid-cache.org--squid/squid--acl--3.0--patch-13
     More conversion of ACL's

  * robertc@squid-cache.org--squid/squid--acl--3.0--patch-12
     Fix ACLChecklist async tests.

  * robertc@squid-cache.org--squid/squid--acl--3.0--patch-11
     More conversion to the new ACL approach.",1546,data/crawl/squid/hunk_5406.cpp,,,data/crawl/squid/old_hunk_5406.cpp,data/crawl/squid/new_hunk_5406.cpp,-1,43,,"fatal(""AclLookupProxyAuthDone: Old code floating around somewhere.\nMake clean and if that doesn't work, report a bug to the squid developers.\n"");","[""addLog""]","[[], [""fatal"", ""AclLookupProxyAuthDone"", ""Old"", ""code"", ""floating"", ""around"", ""somewhere"", ""\\nMake"", ""clean"", ""and"", ""if"", ""that"", ""doesn"", ""t"", ""work"", ""report"", ""a"", ""bug"", ""to"", ""the"", ""squid"", ""developers"", ""\\n""]]",[31539841372898536781],6509,551520.0,2
https://github.com/squid-cache/squid/commit/fcc61c4df06783be04009c0a18caefffd06800bd,14 Feb 2003,"in 'client_list' cachemgr output, remove the percentage from the FETCHES
line. It is no longer menaingful because fetches is incremented for
non-ICP based forwarding decisions.  Also moved FETCHES to the
top of the output with other ""TCP-ish"" stats and out of the ""UDP-ish""
stats section.",8,data/crawl/squid/hunk_5402.cpp,,,data/crawl/squid/old_hunk_5402.cpp,data/crawl/squid/new_hunk_5402.cpp,3,-1,"storeAppendPrintf(sentry, ""FETCHES    : %8d %3d%%\n"",
	    e->stats.fetches,
	    percent(e->stats.fetches, e->stats.pings_acked));",,"[""removeLog""]","[[""storeAppendPrintf"", ""sentry"", ""FETCHES"", ""%8d"", ""%3d%%\\n"", ""e"", ""stats"", ""fetches"", ""percent"", ""e"", ""stats"", ""fetches"", ""e"", ""stats"", ""pings_acked""], []]",[4306623850088843647],6508,1310400.0,2
https://github.com/squid-cache/squid/commit/4807186940395788653d89a174fa3e8f9cdc1c3c,25 Feb 2003,"Summary: Merge final stage1 ACL refactoring.
Keywords:

Patches applied:

  * robertc@squid-cache.org--squid/squid--acl--3.0--patch-25
     Merge from HEAD.

  * robertc@squid-cache.org--squid/squid--acl--3.0--patch-24
     Merge from HEAD.

  * robertc@squid-cache.org--squid/squid--acl--3.0--patch-23
     ACL tidyups within new framework.",1862,data/crawl/squid/hunk_5344.cpp,,,data/crawl/squid/old_hunk_5344.cpp,data/crawl/squid/new_hunk_5344.cpp,-1,107,,"fatal(""aclParseUserMaxIP: Malformed ACL\n"");","[""addLog""]","[[], [""fatal"", ""aclParseUserMaxIP"", ""Malformed"", ""ACL\\n""]]",[1444639019846540504],6507,0.0,2
https://github.com/squid-cache/squid/commit/82b045dccfccc9cd8222529d7d603fbcaeaf1c53,26 Feb 2003,"Summary: Merge in digest fixes for #543
Keywords:

Patches applied:

  * robertc@squid-cache.org--squid/squid--digest-auth--3.0--patch-2
     Fixup digest password helper.

  * robertc@squid-cache.org--squid/squid--digest-auth--3.0--patch-1
     Digest auth fixes for #543 - Sean Burfords helper fix, refactor digest auth.

  * robertc@squid-cache.org--squid/squid--digest-auth--3.0--base-0
     tag of robertc@squid-cache.org--squid/squid--HEAD--3.0--patch-99",829,data/crawl/squid/hunk_5334.cpp,,,data/crawl/squid/old_hunk_5334.cpp,data/crawl/squid/new_hunk_5334.cpp,-1,6,,"fatal (""unusable\n"");","[""addLog""]","[[], [""fatal"", ""unusable\\n""]]",[-7868195606522130728],6506,0.0,2
https://github.com/squid-cache/squid/commit/5eecb267fe11b52bfc7d329386c839a653afd0c6,01 Mar 2003,Upgraded squid_ldap_group to 2.12,340,data/crawl/squid/hunk_5320.cpp,,,data/crawl/squid/old_hunk_5320.cpp,data/crawl/squid/new_hunk_5320.cpp,-1,4,,"fprintf(stderr, ""\t-H URI\t\t\tLDAPURI (defaults to ldap://localhost)\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""\\t"", ""H"", ""URI\\t\\t\\tLDAPURI"", ""defaults"", ""to"", ""ldap"", ""//localhost"", ""\\n""]]",[-2200521962967077286],6505,0.0,2
https://github.com/squid-cache/squid/commit/5eecb267fe11b52bfc7d329386c839a653afd0c6,01 Mar 2003,Upgraded squid_ldap_group to 2.12,340,data/crawl/squid/hunk_5320.cpp,,,data/crawl/squid/old_hunk_5320.cpp,data/crawl/squid/new_hunk_5320.cpp,8,12,"fprintf(stderr, ""\t-v 1|2\t\t\tLDAP version\n"");","fprintf(stderr, ""\t-v 2|3\t\t\tLDAP version\n"");","[""updateContent""]","[[""1"", ""2\\t\\t\\tLDAP""], [""2"", ""3\\t\\t\\tLDAP""]]",[13900948296449975672],6504,0.0,2
https://github.com/squid-cache/squid/commit/954a851376707ccc1938b682bf1bae206779a2ee,01 Mar 2003,-W secretfile by Christoph Lechleitner <lech@ibcl.net>,108,data/crawl/squid/hunk_5314.cpp,,,data/crawl/squid/old_hunk_5314.cpp,data/crawl/squid/new_hunk_5314.cpp,3,3,"fprintf(stderr, ""\tIf you need to bind as a user to perform searches then use the\n\t-D binddn -w bindpasswd options\n\n"");","fprintf(stderr, ""\tIf you need to bind as a user to perform searches then use the\n\t-D binddn -w bindpasswd or -D binddn -W secretfile options\n\n"");","[""updateContent""]","[[], [""or"", ""D"", ""binddn"", ""W"", ""secretfile""]]",[656574629914495197],6503,0.0,2
https://github.com/squid-cache/squid/commit/954a851376707ccc1938b682bf1bae206779a2ee,01 Mar 2003,-W secretfile by Christoph Lechleitner <lech@ibcl.net>,108,data/crawl/squid/hunk_5313.cpp,,,data/crawl/squid/old_hunk_5313.cpp,data/crawl/squid/new_hunk_5313.cpp,-1,3,,"fprintf(stderr, ""\t-W secretfile\t\tread password for binddn from file secretfile\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""\\t"", ""W"", ""secretfile\\t\\tread"", ""password"", ""for"", ""binddn"", ""from"", ""file"", ""secretfile\\n""]]",[-16135613133508774014],6502,0.0,2
https://github.com/squid-cache/squid/commit/653b264eeed1a764bf6bcde2b7704f888cbf9cd7,02 Mar 2003,"David J N Begley <d.begley@uws.edu.au>

 - Netscape API support for LDAP over SSL (-E option)

 - Timeout options (-t and -c)",253,data/crawl/squid/hunk_5302.cpp,,,data/crawl/squid/old_hunk_5302.cpp,data/crawl/squid/new_hunk_5302.cpp,-1,7,,"fprintf(stderr, ""\t-t timelimit\t\tsearch time limit\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""\\t"", ""t"", ""timelimit\\t\\tsearch"", ""time"", ""limit\\n""]]",[-18586248740913457925],6501,0.0,2
https://github.com/squid-cache/squid/commit/653b264eeed1a764bf6bcde2b7704f888cbf9cd7,02 Mar 2003,"David J N Begley <d.begley@uws.edu.au>

 - Netscape API support for LDAP over SSL (-E option)

 - Timeout options (-t and -c)",253,data/crawl/squid/hunk_5302.cpp,,,data/crawl/squid/old_hunk_5302.cpp,data/crawl/squid/new_hunk_5302.cpp,-1,6,,"fprintf(stderr, ""\t-c timeout\t\tconnect timeout\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""\\t"", ""c"", ""timeout\\t\\tconnect"", ""timeout\\n""]]",[-6024974905476982393],6500,0.0,2
https://github.com/squid-cache/squid/commit/653b264eeed1a764bf6bcde2b7704f888cbf9cd7,02 Mar 2003,"David J N Begley <d.begley@uws.edu.au>

 - Netscape API support for LDAP over SSL (-E option)

 - Timeout options (-t and -c)",253,data/crawl/squid/hunk_5302.cpp,,,data/crawl/squid/old_hunk_5302.cpp,data/crawl/squid/new_hunk_5302.cpp,-1,4,,"fprintf(stderr, ""\t-E sslcertpath\t\tenable LDAP over SSL\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""\\t"", ""E"", ""sslcertpath\\t\\tenable"", ""LDAP"", ""over"", ""SSL\\n""]]",[-10594442034749042805],6499,0.0,2
https://github.com/squid-cache/squid/commit/a46d2c0eef0e24f55306bb00639625102fad4fbf,04 Mar 2003,"Summary: Merge epoll and delay pools/deferred reads removal.
Keywords:

Patches applied:

  * robertc@squid-cache.org--squid/squid--epoll--3.0--patch-12
     Bufix from merge.

  * robertc@squid-cache.org--squid/squid--epoll--3.0--patch-11
     Remove some duplicate code.

  * robertc@squid-cache.org--squid/squid--epoll--3.0--patch-10
     Handle aborts properly in deferred reads.

  * robertc@squid-cache.org--squid/squid--epoll--3.0--patch-9
     Fixup after merge.

  * robertc@squid-cache.org--squid/squid--epoll--3.0--patch-8
     Merged from HEAD.

  * robertc@squid-cache.org--squid/squid--epoll--3.0--patch-7
     Add missing files.

  * robertc@squid-cache.org--squid/squid--epoll--3.0--patch-6
     Start tackling the StoreEntry defer logic.

  * robertc@squid-cache.org--squid/squid--epoll--3.0--patch-5
     Bugfix: limit the size read in tunnel.cc to the buffer size.

  * robertc@squid-cache.org--squid/squid--epoll--3.0--patch-4
     Squash deferred reads.

  * robertc@squid-cache.org--squid/squid--epoll--3.0--patch-3
     Start addressing the use of deferred reads.

  * robertc@squid-cache.org--squid/squid--epoll--3.0--patch-2
     Start refactoring deferred reads.

  * robertc@squid-cache.org--squid/squid--epoll--3.0--patch-1
     Apply epoll patch from David Nicklay

  * robertc@squid-cache.org--squid/squid--epoll--3.0--patch-10
     Handle aborts properly in deferred reads.

  * robertc@squid-cache.org--squid/squid--epoll--3.0--patch-11
     Remove some duplicate code.

  * robertc@squid-cache.org--squid/squid--epoll--3.0--patch-12
     Bufix from merge.

  * robertc@squid-cache.org--squid/squid--epoll--3.0--base-0
     tag of robertc@squid-cache.org--squid/squid--HEAD--3.0--patch-95",5845,data/crawl/squid/hunk_5291.cpp,,,data/crawl/squid/old_hunk_5291.cpp,data/crawl/squid/new_hunk_5291.cpp,21,-1,"fatalf(""bad return value from commDeferRead(FD %d)\n"", i);",,"[""removeLog""]","[[""fatalf"", ""bad"", ""return"", ""value"", ""from"", ""commDeferRead"", ""FD"", ""%d"", ""\\n"", ""i""], []]",[3488724790638796820],6498,313200.0,2
https://github.com/squid-cache/squid/commit/43ae1d95a7add005149cc7a82fae6609d40f3b44,10 Mar 2003,"Summary: Merge ESI to HEAD.
Keywords:

Patches applied:

  * robertc@squid-cache.org--squid/squid--esi--3.0--patch-30
     Fixup merged for gcc2

  * robertc@squid-cache.org--squid/squid--esi--3.0--patch-29
     Merge recent HEAD changes.

  * robertc@squid-cache.org--squid/squid--esi--3.0--patch-28
     ESI Tweaks

  * robertc@squid-cache.org--squid/squid--esi--3.0--patch-27
     Fixup from merge.

  * robertc@squid-cache.org--squid/squid--esi--3.0--patch-26
     Bootstrapped.

  * robertc@squid-cache.org--squid/squid--esi--3.0--patch-25
     Merge from HEAD.

  * robertc@squid-cache.org--squid/squid--esi--3.0--patch-24
     Merge from HEAD.

  * robertc@squid-cache.org--squid/squid--esi--3.0--patch-23
     Merged from head to avert conflicts.

  * robertc@squid-cache.org--squid/squid--esi--3.0--patch-22
     Fix broken merge.

  * robertc@squid-cache.org--squid/squid--esi--3.0--patch-21
     Merge from HEAD.

  * robertc@squid-cache.org--squid/squid--esi--3.0--patch-20
     Refactor ESI code to clarify reentrancy bugs.

  * robertc@squid-cache.org--squid/squid--esi--3.0--patch-19
     Fixup ESI (again!)

  * robertc@squid-cache.org--squid/squid--esi--3.0--patch-18
     Merge parser fix from HEAD.

  * robertc@squid-cache.org--squid/squid--esi--3.0--patch-17
     bootstrapped.

  * robertc@squid-cache.org--squid/squid--esi--3.0--patch-16
     Merge from HEAD.

  * robertc@squid-cache.org--squid/squid--esi--3.0--patch-15
     Fix breakage after head merge.

  * robertc@squid-cache.org--squid/squid--esi--3.0--patch-14
     Merge from HEAD.

  * robertc@squid-cache.org--squid/squid--esi--3.0--patch-13
     Prevent bogus compile warnings on TrieNode.cci

  * robertc@squid-cache.org--squid/squid--esi--3.0--patch-12
     Updated after head merge + bugfixes.

  * robertc@squid-cache.org--squid/squid--esi--3.0--patch-11
     Merge from HEAD.

  * robertc@squid-cache.org--squid/squid--esi--3.0--patch-10
     Merge from HEAD.

  * robertc@squid-cache.org--squid/squid--esi--3.0--patch-9
     merge from HEAD

  * robertc@squid-cache.org--squid/squid--esi--3.0--patch-8
     Merge with HEAD

  * robertc@squid-cache.org--squid/squid--esi--3.0--patch-7
     Merge from HEAD

  * robertc@squid-cache.org--squid/squid--esi--3.0--patch-6
     ESI custom parser implementation

  * robertc@squid-cache.org--squid/squid--esi--3.0--patch-5
     Fix problems from last merge and tweak parser.

  * robertc@squid-cache.org--squid/squid--esi--3.0--patch-4
     Bootstrap, plus update to deal with HEAD changes

  * robertc@squid-cache.org--squid/squid--esi--3.0--patch-3
     Merge from HEAD

  * robertc@squid-cache.org--squid/squid--esi--3.0--patch-30
     Fixup merged for gcc2

  * robertc@squid-cache.org--squid/squid--esi--3.0--patch-2
     Merge from HEAD (typename fix)

  * robertc@squid-cache.org--squid/squid--esi--3.0--patch-20
     Refactor ESI code to clarify reentrancy bugs.

  * robertc@squid-cache.org--squid/squid--esi--3.0--patch-21
     Merge from HEAD.

  * robertc@squid-cache.org--squid/squid--esi--3.0--patch-22
     Fix broken merge.

  * robertc@squid-cache.org--squid/squid--esi--3.0--patch-23
     Merged from head to avert conflicts.

  * robertc@squid-cache.org--squid/squid--esi--3.0--patch-24
     Merge from HEAD.

  * robertc@squid-cache.org--squid/squid--esi--3.0--patch-25
     Merge from HEAD.

  * robertc@squid-cache.org--squid/squid--esi--3.0--patch-26
     Bootstrapped.

  * robertc@squid-cache.org--squid/squid--esi--3.0--patch-27
     Fixup from merge.

  * robertc@squid-cache.org--squid/squid--esi--3.0--patch-28
     ESI Tweaks

  * robertc@squid-cache.org--squid/squid--esi--3.0--patch-29
     Merge recent HEAD changes.

  * robertc@squid-cache.org--squid/squid--esi--3.0--patch-1
     Import CVS esi tag

  * robertc@squid-cache.org--squid/squid--esi--3.0--patch-10
     Merge from HEAD.

  * robertc@squid-cache.org--squid/squid--esi--3.0--patch-11
     Merge from HEAD.

  * robertc@squid-cache.org--squid/squid--esi--3.0--patch-12
     Updated after head merge + bugfixes.

  * robertc@squid-cache.org--squid/squid--esi--3.0--patch-13
     Prevent bogus compile warnings on TrieNode.cci

  * robertc@squid-cache.org--squid/squid--esi--3.0--patch-14
     Merge from HEAD.

  * robertc@squid-cache.org--squid/squid--esi--3.0--patch-15
     Fix breakage after head merge.

  * robertc@squid-cache.org--squid/squid--esi--3.0--patch-16
     Merge from HEAD.

  * robertc@squid-cache.org--squid/squid--esi--3.0--patch-17
     bootstrapped.

  * robertc@squid-cache.org--squid/squid--esi--3.0--patch-18
     Merge parser fix from HEAD.

  * robertc@squid-cache.org--squid/squid--esi--3.0--patch-19
     Fixup ESI (again!)

  * robertc@squid-cache.org--squid/squid--esi--3.0--base-0
     tag of robertc@squid-cache.org--squid/squid--HEAD--3.0--patch-18",27101,data/crawl/squid/hunk_5275.cpp,,,data/crawl/squid/old_hunk_5275.cpp,data/crawl/squid/new_hunk_5275.cpp,-1,344,,"storeAppendPrintf(sentry, ""%2d\t %-20s\t %5d\t %6.2f\n"",
                          id, name, count, xdiv(count, dump_stat->scParsedCount));","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""%2d\\t"", ""%"", ""20s\\t"", ""%5d\\t"", ""%6"", ""2f\\n"", ""id"", ""name"", ""count"", ""xdiv"", ""count"", ""dump_stat"", ""scParsedCount""]]",[14423007792914159424],6497,0.0,2
https://github.com/squid-cache/squid/commit/0ff1980a4e05750076c5c5d31d6daa5c2b13a1e5,01 Apr 2003,"Summary: Merge in digest helper refactoring.
Keywords:

Patches applied:

  * robertc@squid-cache.org--squid/squid--digest-auth--3.0--patch-6
     Merge from HEAD.

  * robertc@squid-cache.org--squid/squid--digest-auth--3.0--patch-5
     Tweak digest helper.

  * robertc@squid-cache.org--squid/squid--digest-auth--3.0--patch-4
     Factor digest password helper for easy extension.

  * robertc@squid-cache.org--squid/squid--digest-auth--3.0--patch-3
     merge from HEAD.",426,data/crawl/squid/hunk_5268.cpp,,,data/crawl/squid/old_hunk_5268.cpp,data/crawl/squid/new_hunk_5268.cpp,-1,115,,"fprintf(stderr, ""cannot stat %s\n"", passwdfile);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""cannot"", ""stat"", ""%s\\n"", ""passwdfile""]]",[-17969571524081036001],6496,24480.0,2
https://github.com/squid-cache/squid/commit/0ff1980a4e05750076c5c5d31d6daa5c2b13a1e5,01 Apr 2003,"Summary: Merge in digest helper refactoring.
Keywords:

Patches applied:

  * robertc@squid-cache.org--squid/squid--digest-auth--3.0--patch-6
     Merge from HEAD.

  * robertc@squid-cache.org--squid/squid--digest-auth--3.0--patch-5
     Tweak digest helper.

  * robertc@squid-cache.org--squid/squid--digest-auth--3.0--patch-4
     Factor digest password helper for easy extension.

  * robertc@squid-cache.org--squid/squid--digest-auth--3.0--patch-3
     merge from HEAD.",426,data/crawl/squid/hunk_5268.cpp,,,data/crawl/squid/old_hunk_5268.cpp,data/crawl/squid/new_hunk_5268.cpp,-1,111,,"fprintf(stderr, ""  -c   accept HHA1 passwords rather than plaintext in passwordfile\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""c"", ""accept"", ""HHA1"", ""passwords"", ""rather"", ""than"", ""plaintext"", ""in"", ""passwordfile\\n""]]",[-16898237242499810096],6495,24480.0,2
https://github.com/squid-cache/squid/commit/0ff1980a4e05750076c5c5d31d6daa5c2b13a1e5,01 Apr 2003,"Summary: Merge in digest helper refactoring.
Keywords:

Patches applied:

  * robertc@squid-cache.org--squid/squid--digest-auth--3.0--patch-6
     Merge from HEAD.

  * robertc@squid-cache.org--squid/squid--digest-auth--3.0--patch-5
     Tweak digest helper.

  * robertc@squid-cache.org--squid/squid--digest-auth--3.0--patch-4
     Factor digest password helper for easy extension.

  * robertc@squid-cache.org--squid/squid--digest-auth--3.0--patch-3
     merge from HEAD.",426,data/crawl/squid/hunk_5268.cpp,,,data/crawl/squid/old_hunk_5268.cpp,data/crawl/squid/new_hunk_5268.cpp,-1,90,,"fprintf(stderr, ""digest_pw_auth: ignoring %s password for %s\n"",
			""plaintext"", user);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""digest_pw_auth"", ""ignoring"", ""%s"", ""password"", ""for"", ""%s\\n"", ""plaintext"", ""user""]]",[-23962674246672305710],6494,24480.0,2
https://github.com/squid-cache/squid/commit/0ff1980a4e05750076c5c5d31d6daa5c2b13a1e5,01 Apr 2003,"Summary: Merge in digest helper refactoring.
Keywords:

Patches applied:

  * robertc@squid-cache.org--squid/squid--digest-auth--3.0--patch-6
     Merge from HEAD.

  * robertc@squid-cache.org--squid/squid--digest-auth--3.0--patch-5
     Tweak digest helper.

  * robertc@squid-cache.org--squid/squid--digest-auth--3.0--patch-4
     Factor digest password helper for easy extension.

  * robertc@squid-cache.org--squid/squid--digest-auth--3.0--patch-3
     merge from HEAD.",426,data/crawl/squid/hunk_5268.cpp,,,data/crawl/squid/old_hunk_5268.cpp,data/crawl/squid/new_hunk_5268.cpp,-1,69,,"fprintf(stderr, ""digest_pw_auth: cannot create hash table\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""digest_pw_auth"", ""cannot"", ""create"", ""hash"", ""table\\n""]]",[-16689609371367577049],6493,568080.0,2
https://github.com/squid-cache/squid/commit/6c1962dd70c2add16e17fc5a59aa2520aa9d56a6,26 Apr 2003,"Summary: Merge Windows fixes from Guido.
Keywords:

Patches applied:

  * robertc@squid-cache.org--squid/squid--windows--3.0--patch-6
     Native windows enhancements from Guido.",128,data/crawl/squid/hunk_5258.cpp,,,data/crawl/squid/old_hunk_5258.cpp,data/crawl/squid/new_hunk_5258.cpp,-1,11,,"fprintf(stderr, ""%s: ERROR: Could not send "", appname);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""%s"", ""ERROR"", ""Could"", ""not"", ""send"", ""appname""]]",[3562800791171750006],6492,1740240.0,2
https://github.com/squid-cache/squid/commit/1e5562e38ca48d8bf81a6049de49afbc0547de23,20 May 2003,"Summary: Merge in external acl refactoring and tagged delay pools.
Keywords:

Patches applied:

  * robertc@squid-cache.org--squid/squid--tagged-pools--3.0--patch-5
     Enable class 5 pools.

  * robertc@squid-cache.org--squid/squid--tagged-pools--3.0--patch-4
     Implement tag associated delay pools.

  * robertc@squid-cache.org--squid/squid--tagged-pools--3.0--patch-3
     Refactoring external acl.

  * robertc@squid-cache.org--squid/squid--tagged-pools--3.0--patch-2
     Extract ExternalACLState to separate files.

  * robertc@squid-cache.org--squid/squid--tagged-pools--3.0--patch-1
     Create a tagging method for external acl replies.

  * robertc@squid-cache.org--squid/squid--tagged-pools--3.0--base-0
     tag of robertc@squid-cache.org--squid/squid--HEAD--3.0--patch-171",10400,data/crawl/squid/hunk_5247.cpp,,,data/crawl/squid/old_hunk_5247.cpp,data/crawl/squid/new_hunk_5247.cpp,-1,109,,"storeAppendPrintf (sentry, ""Not used yet.\n\n"");","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""Not"", ""used"", ""yet"", ""\\n\\n""]]",[5511519340983568830],6491,74160.0,2
https://github.com/squid-cache/squid/commit/abb929f03f54f744e6b67fdf84b41508a85aae36,28 Jun 2003,"* ext_user acl type to match user name returned by external acl

* cleanup of how external acls present a user name to the
  Squid core to make the code more logical and fix a
  minor security issues if there is downstream proxies.

* concept of password returned by external acl type. Integrated
  with login= cache_peer option to have the password forwarded
  to peers (both proxies and origin type peers)",316,data/crawl/squid/hunk_5238.cpp,,,data/crawl/squid/old_hunk_5238.cpp,data/crawl/squid/new_hunk_5238.cpp,-1,12,,"httpHeaderPutStrf(hdr_out, HDR_AUTHORIZATION, ""Basic %s"",
                                  base64_encode(loginbuf));","[""addLog""]","[[], [""httpHeaderPutStrf"", ""hdr_out"", ""HDR_AUTHORIZATION"", ""Basic"", ""%s"", ""base64_encode"", ""loginbuf""]]",[4153229444962023281],6490,95760.0,2
https://github.com/squid-cache/squid/commit/7684c4b1a8b1fa0a54c1b6269d5dc5ae72bd4ed3,07 Jul 2003,"Custom log formats, and selective access logging. See logformat
and cache_access_log directives",1422,data/crawl/squid/hunk_5234.cpp,,,data/crawl/squid/old_hunk_5234.cpp,data/crawl/squid/new_hunk_5234.cpp,-1,114,,"storeAppendPrintf(entry, ""%s squid"", log->filename);","[""addLog""]","[[], [""storeAppendPrintf"", ""entry"", ""%s"", ""squid"", ""log"", ""filename""]]",[2095200602186377685],6489,0.0,2
https://github.com/squid-cache/squid/commit/59b2d47f54f8988d0dd74430a78b7a8599d819ff,22 Jul 2003,"Summary: Merge disk-factoring.
Keywords:

Patches applied:

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-14
   Merge of robertc@squid-cache.org--squid/squid--HEAD--3.0--patch-283-285

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-13
   Further OOification of the store drivers.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-12
   And more OOification.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-11
   And more OOification of the store drivers.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-10
   And more OOification.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-9
   More store OOification.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-8
   Dist missing files.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-7
   And moe OOification.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-6
   And more OOification.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-5
   More store FS OOification.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-4
   More OOification for the store.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-3
   OO'ing the store layer.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-2
   BUGFIX: array.cc compilation.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-1
   Update to latest HEAD code.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--base-0
   tag of robertc@squid-cache.org--squid/squid--HEAD--3.0--patch-220",3732,data/crawl/squid/hunk_5207.cpp,,,data/crawl/squid/old_hunk_5207.cpp,data/crawl/squid/new_hunk_5207.cpp,26,-1,"fatal(""storeAufsDirParse: invalid level 2 directories value"");",,"[""removeLog""]","[[""fatal"", ""storeAufsDirParse"", ""invalid"", ""level"", ""2"", ""directories"", ""value""], []]",[20381767880702507406],6488,149040.0,2
https://github.com/squid-cache/squid/commit/59b2d47f54f8988d0dd74430a78b7a8599d819ff,22 Jul 2003,"Summary: Merge disk-factoring.
Keywords:

Patches applied:

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-14
   Merge of robertc@squid-cache.org--squid/squid--HEAD--3.0--patch-283-285

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-13
   Further OOification of the store drivers.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-12
   And more OOification.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-11
   And more OOification of the store drivers.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-10
   And more OOification.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-9
   More store OOification.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-8
   Dist missing files.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-7
   And moe OOification.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-6
   And more OOification.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-5
   More store FS OOification.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-4
   More OOification for the store.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-3
   OO'ing the store layer.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-2
   BUGFIX: array.cc compilation.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-1
   Update to latest HEAD code.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--base-0
   tag of robertc@squid-cache.org--squid/squid--HEAD--3.0--patch-220",3732,data/crawl/squid/hunk_5207.cpp,,,data/crawl/squid/old_hunk_5207.cpp,data/crawl/squid/new_hunk_5207.cpp,16,-1,"fatal(""storeAufsDirParse: invalid size value"");",,"[""removeLog""]","[[""fatal"", ""storeAufsDirParse"", ""invalid"", ""size"", ""value""], []]",[31223036232158628979],6487,149040.0,2
https://github.com/squid-cache/squid/commit/59b2d47f54f8988d0dd74430a78b7a8599d819ff,22 Jul 2003,"Summary: Merge disk-factoring.
Keywords:

Patches applied:

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-14
   Merge of robertc@squid-cache.org--squid/squid--HEAD--3.0--patch-283-285

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-13
   Further OOification of the store drivers.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-12
   And more OOification.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-11
   And more OOification of the store drivers.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-10
   And more OOification.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-9
   More store OOification.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-8
   Dist missing files.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-7
   And moe OOification.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-6
   And more OOification.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-5
   More store FS OOification.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-4
   More OOification for the store.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-3
   OO'ing the store layer.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-2
   BUGFIX: array.cc compilation.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-1
   Update to latest HEAD code.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--base-0
   tag of robertc@squid-cache.org--squid/squid--HEAD--3.0--patch-220",3732,data/crawl/squid/hunk_5205.cpp,,,data/crawl/squid/old_hunk_5205.cpp,data/crawl/squid/new_hunk_5205.cpp,13,-1,"fatal(""storeDiskdDirReconfigure: invalid level 2 directories value"");",,"[""removeLog""]","[[""fatal"", ""storeDiskdDirReconfigure"", ""invalid"", ""level"", ""2"", ""directories"", ""value""], []]",[15808245304560283223],6486,149040.0,2
https://github.com/squid-cache/squid/commit/59b2d47f54f8988d0dd74430a78b7a8599d819ff,22 Jul 2003,"Summary: Merge disk-factoring.
Keywords:

Patches applied:

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-14
   Merge of robertc@squid-cache.org--squid/squid--HEAD--3.0--patch-283-285

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-13
   Further OOification of the store drivers.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-12
   And more OOification.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-11
   And more OOification of the store drivers.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-10
   And more OOification.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-9
   More store OOification.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-8
   Dist missing files.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-7
   And moe OOification.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-6
   And more OOification.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-5
   More store FS OOification.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-4
   More OOification for the store.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-3
   OO'ing the store layer.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-2
   BUGFIX: array.cc compilation.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-1
   Update to latest HEAD code.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--base-0
   tag of robertc@squid-cache.org--squid/squid--HEAD--3.0--patch-220",3732,data/crawl/squid/hunk_5205.cpp,,,data/crawl/squid/old_hunk_5205.cpp,data/crawl/squid/new_hunk_5205.cpp,8,-1,"fatal(""storeDiskdDirReconfigure: invalid level 1 directories value"");",,"[""removeLog""]","[[""fatal"", ""storeDiskdDirReconfigure"", ""invalid"", ""level"", ""1"", ""directories"", ""value""], []]",[15808245304688283610],6485,149040.0,2
https://github.com/squid-cache/squid/commit/59b2d47f54f8988d0dd74430a78b7a8599d819ff,22 Jul 2003,"Summary: Merge disk-factoring.
Keywords:

Patches applied:

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-14
   Merge of robertc@squid-cache.org--squid/squid--HEAD--3.0--patch-283-285

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-13
   Further OOification of the store drivers.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-12
   And more OOification.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-11
   And more OOification of the store drivers.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-10
   And more OOification.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-9
   More store OOification.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-8
   Dist missing files.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-7
   And moe OOification.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-6
   And more OOification.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-5
   More store FS OOification.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-4
   More OOification for the store.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-3
   OO'ing the store layer.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-2
   BUGFIX: array.cc compilation.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-1
   Update to latest HEAD code.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--base-0
   tag of robertc@squid-cache.org--squid/squid--HEAD--3.0--patch-220",3732,data/crawl/squid/hunk_5204.cpp,,,data/crawl/squid/old_hunk_5204.cpp,data/crawl/squid/new_hunk_5204.cpp,-1,288,,"storeAppendPrintf(sentry, ""%7s %7d %7d %7d\n"",
                      ""write"", diskd_stats.write.ops, diskd_stats.write.success, diskd_stats.write.fail);","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""%7s"", ""%7d"", ""%7d"", ""%7d\\n"", ""write"", ""diskd_stats"", ""write"", ""ops"", ""diskd_stats"", ""write"", ""success"", ""diskd_stats"", ""write"", ""fail""]]",[22516082997460694746],6484,792720.0,2
https://github.com/squid-cache/squid/commit/59b2d47f54f8988d0dd74430a78b7a8599d819ff,22 Jul 2003,"Summary: Merge disk-factoring.
Keywords:

Patches applied:

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-14
   Merge of robertc@squid-cache.org--squid/squid--HEAD--3.0--patch-283-285

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-13
   Further OOification of the store drivers.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-12
   And more OOification.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-11
   And more OOification of the store drivers.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-10
   And more OOification.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-9
   More store OOification.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-8
   Dist missing files.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-7
   And moe OOification.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-6
   And more OOification.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-5
   More store FS OOification.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-4
   More OOification for the store.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-3
   OO'ing the store layer.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-2
   BUGFIX: array.cc compilation.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-1
   Update to latest HEAD code.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--base-0
   tag of robertc@squid-cache.org--squid/squid--HEAD--3.0--patch-220",3732,data/crawl/squid/hunk_5204.cpp,,,data/crawl/squid/old_hunk_5204.cpp,data/crawl/squid/new_hunk_5204.cpp,-1,286,,"storeAppendPrintf(sentry, ""%7s %7d %7d %7d\n"",
                      ""read"", diskd_stats.read.ops, diskd_stats.read.success, diskd_stats.read.fail);","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""%7s"", ""%7d"", ""%7d"", ""%7d\\n"", ""read"", ""diskd_stats"", ""read"", ""ops"", ""diskd_stats"", ""read"", ""success"", ""diskd_stats"", ""read"", ""fail""]]",[-36675435542570104518],6483,792720.0,2
https://github.com/squid-cache/squid/commit/59b2d47f54f8988d0dd74430a78b7a8599d819ff,22 Jul 2003,"Summary: Merge disk-factoring.
Keywords:

Patches applied:

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-14
   Merge of robertc@squid-cache.org--squid/squid--HEAD--3.0--patch-283-285

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-13
   Further OOification of the store drivers.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-12
   And more OOification.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-11
   And more OOification of the store drivers.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-10
   And more OOification.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-9
   More store OOification.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-8
   Dist missing files.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-7
   And moe OOification.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-6
   And more OOification.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-5
   More store FS OOification.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-4
   More OOification for the store.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-3
   OO'ing the store layer.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-2
   BUGFIX: array.cc compilation.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-1
   Update to latest HEAD code.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--base-0
   tag of robertc@squid-cache.org--squid/squid--HEAD--3.0--patch-220",3732,data/crawl/squid/hunk_5204.cpp,,,data/crawl/squid/old_hunk_5204.cpp,data/crawl/squid/new_hunk_5204.cpp,-1,284,,"storeAppendPrintf(sentry, ""%7s %7d %7d %7d\n"",
                      ""unlink"", diskd_stats.unlink.ops, diskd_stats.unlink.success, diskd_stats.unlink.fail);","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""%7s"", ""%7d"", ""%7d"", ""%7d\\n"", ""unlink"", ""diskd_stats"", ""unlink"", ""ops"", ""diskd_stats"", ""unlink"", ""success"", ""diskd_stats"", ""unlink"", ""fail""]]",[-9926261277360285818],6482,792720.0,2
https://github.com/squid-cache/squid/commit/59b2d47f54f8988d0dd74430a78b7a8599d819ff,22 Jul 2003,"Summary: Merge disk-factoring.
Keywords:

Patches applied:

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-14
   Merge of robertc@squid-cache.org--squid/squid--HEAD--3.0--patch-283-285

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-13
   Further OOification of the store drivers.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-12
   And more OOification.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-11
   And more OOification of the store drivers.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-10
   And more OOification.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-9
   More store OOification.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-8
   Dist missing files.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-7
   And moe OOification.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-6
   And more OOification.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-5
   More store FS OOification.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-4
   More OOification for the store.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-3
   OO'ing the store layer.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-2
   BUGFIX: array.cc compilation.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-1
   Update to latest HEAD code.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--base-0
   tag of robertc@squid-cache.org--squid/squid--HEAD--3.0--patch-220",3732,data/crawl/squid/hunk_5204.cpp,,,data/crawl/squid/old_hunk_5204.cpp,data/crawl/squid/new_hunk_5204.cpp,-1,282,,"storeAppendPrintf(sentry, ""%7s %7d %7d %7d\n"",
                      ""close"", diskd_stats.close.ops, diskd_stats.close.success, diskd_stats.close.fail);","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""%7s"", ""%7d"", ""%7d"", ""%7d\\n"", ""close"", ""diskd_stats"", ""close"", ""ops"", ""diskd_stats"", ""close"", ""success"", ""diskd_stats"", ""close"", ""fail""]]",[15079877643947319934],6481,792720.0,2
https://github.com/squid-cache/squid/commit/59b2d47f54f8988d0dd74430a78b7a8599d819ff,22 Jul 2003,"Summary: Merge disk-factoring.
Keywords:

Patches applied:

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-14
   Merge of robertc@squid-cache.org--squid/squid--HEAD--3.0--patch-283-285

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-13
   Further OOification of the store drivers.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-12
   And more OOification.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-11
   And more OOification of the store drivers.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-10
   And more OOification.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-9
   More store OOification.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-8
   Dist missing files.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-7
   And moe OOification.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-6
   And more OOification.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-5
   More store FS OOification.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-4
   More OOification for the store.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-3
   OO'ing the store layer.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-2
   BUGFIX: array.cc compilation.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-1
   Update to latest HEAD code.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--base-0
   tag of robertc@squid-cache.org--squid/squid--HEAD--3.0--patch-220",3732,data/crawl/squid/hunk_5204.cpp,,,data/crawl/squid/old_hunk_5204.cpp,data/crawl/squid/new_hunk_5204.cpp,-1,280,,"storeAppendPrintf(sentry, ""%7s %7d %7d %7d\n"",
                      ""create"", diskd_stats.create.ops, diskd_stats.create.success, diskd_stats.create.fail);","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""%7s"", ""%7d"", ""%7d"", ""%7d\\n"", ""create"", ""diskd_stats"", ""create"", ""ops"", ""diskd_stats"", ""create"", ""success"", ""diskd_stats"", ""create"", ""fail""]]",[-39649784662971112254],6480,792720.0,2
https://github.com/squid-cache/squid/commit/59b2d47f54f8988d0dd74430a78b7a8599d819ff,22 Jul 2003,"Summary: Merge disk-factoring.
Keywords:

Patches applied:

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-14
   Merge of robertc@squid-cache.org--squid/squid--HEAD--3.0--patch-283-285

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-13
   Further OOification of the store drivers.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-12
   And more OOification.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-11
   And more OOification of the store drivers.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-10
   And more OOification.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-9
   More store OOification.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-8
   Dist missing files.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-7
   And moe OOification.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-6
   And more OOification.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-5
   More store FS OOification.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-4
   More OOification for the store.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-3
   OO'ing the store layer.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-2
   BUGFIX: array.cc compilation.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-1
   Update to latest HEAD code.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--base-0
   tag of robertc@squid-cache.org--squid/squid--HEAD--3.0--patch-220",3732,data/crawl/squid/hunk_5204.cpp,,,data/crawl/squid/old_hunk_5204.cpp,data/crawl/squid/new_hunk_5204.cpp,-1,278,,"storeAppendPrintf(sentry, ""%7s %7d %7d %7d\n"",
                      ""open"", diskd_stats.open.ops, diskd_stats.open.success, diskd_stats.open.fail);","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""%7s"", ""%7d"", ""%7d"", ""%7d\\n"", ""open"", ""diskd_stats"", ""open"", ""ops"", ""diskd_stats"", ""open"", ""success"", ""diskd_stats"", ""open"", ""fail""]]",[-12742640810051175286],6479,792720.0,2
https://github.com/squid-cache/squid/commit/59b2d47f54f8988d0dd74430a78b7a8599d819ff,22 Jul 2003,"Summary: Merge disk-factoring.
Keywords:

Patches applied:

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-14
   Merge of robertc@squid-cache.org--squid/squid--HEAD--3.0--patch-283-285

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-13
   Further OOification of the store drivers.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-12
   And more OOification.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-11
   And more OOification of the store drivers.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-10
   And more OOification.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-9
   More store OOification.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-8
   Dist missing files.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-7
   And moe OOification.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-6
   And more OOification.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-5
   More store FS OOification.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-4
   More OOification for the store.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-3
   OO'ing the store layer.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-2
   BUGFIX: array.cc compilation.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--patch-1
   Update to latest HEAD code.

 * robertc@squid-cache.org--squid/squid--disk-io--3.0--base-0
   tag of robertc@squid-cache.org--squid/squid--HEAD--3.0--patch-220",3732,data/crawl/squid/hunk_5203.cpp,,,data/crawl/squid/old_hunk_5203.cpp,data/crawl/squid/new_hunk_5203.cpp,77,-1,"fatal(""msgget failed"");",,"[""removeLog""]","[[""fatal"", ""msgget"", ""failed""], []]",[9228573894909806285],6478,0.0,2
https://github.com/squid-cache/squid/commit/b883b594bdfdef49b22874738501f742e8ac2d31,23 Jul 2003,"Summary: Port forward the solution for bug #699 (rewrite host header in place).
Keywords:

This fixes some causes for 'Zero sized reply' when squid connects via a firewall.",23,data/crawl/squid/hunk_5198.cpp,,,data/crawl/squid/old_hunk_5198.cpp,data/crawl/squid/new_hunk_5198.cpp,-1,17,,"httpHeaderPutStrf(hdr_out, HDR_HOST, ""%s:%d"",
                                  orig_request->host, (int) orig_request->port);","[""addLog""]","[[], [""httpHeaderPutStrf"", ""hdr_out"", ""HDR_HOST"", ""%s"", ""%d"", ""orig_request"", ""host"", ""int"", ""orig_request"", ""port""]]",[14444787479066876461],6477,1355040.0,2
https://github.com/squid-cache/squid/commit/77dff9d057fa08a6430cfe875abd1429be87e974,03 Aug 2003,"Hi,

On Windows (native and Cygwin) and OS/2, when running
UFSSwapDir::closeTmpSwapLog() in store_dir_ufs.cc, Squid can be fail if the
target file for a rename operation was already deleted.

Because xrename() already try to remove the destination target on Windows,
a previous unlink() is not needed.

This patch extended the native Windows xrename() behaviour to Cygwin and
OS/2 too and remove not needed unlink().

Regards

Guido",17,data/crawl/squid/hunk_5197.cpp,,,data/crawl/squid/old_hunk_5197.cpp,data/crawl/squid/new_hunk_5197.cpp,7,-1,"fatal(""commonUfsDirCloseTmpSwapLog: unlink failed"");",,"[""removeLog""]","[[""fatal"", ""commonUfsDirCloseTmpSwapLog"", ""unlink"", ""failed""], []]",[18278368217137848100],6476,157680.0,2
https://github.com/squid-cache/squid/commit/35516333b6bdd23d476a6f3d344b9a71dc47e0ff,04 Aug 2003,"Cut out unwanted regex interfaces from GNUregex.c
 - emacs related stuff
 - BSD 4.2 regex interface
 - old GNU regex interface
leaving only the POSIX interface which is what we use",446,data/crawl/squid/hunk_5195.cpp,,,data/crawl/squid/old_hunk_5195.cpp,data/crawl/squid/new_hunk_5195.cpp,19,-1,"printf(""/%d"", mcnt);",,"[""removeLog""]","[[""printf"", ""/%d"", ""mcnt""], []]",[-1332014071425927468],6475,0.0,2
https://github.com/squid-cache/squid/commit/55e44db9113a48dea68b11a3636dc3d6154e8835,14 Aug 2003,"Summary: Swallow request bodies even when denying access.
Keywords:

* Assert when destroying requests with body connections.
* Move ClientBody class definition to client_side.h
* Encapsulate comm_close calls from ClientSocketContext.
* When closing a client socket, if there is a body, swallow it.
* When swalling a request body, if the connection needs to close, do so.",103,data/crawl/squid/hunk_5192.cpp,,,data/crawl/squid/old_hunk_5192.cpp,data/crawl/squid/new_hunk_5192.cpp,-1,7,,initiateClose();,"[""addLog""]","[[], [""initiateClose""]]",[2310980032292553174],6474,0.0,2
https://github.com/squid-cache/squid/commit/1a2248431aee8579727981a35527c2663852fc5d,28 Aug 2003,"ported COSS enhancements from squid-2.5 code (dated ~ July 25-29, 2003).",564,data/crawl/squid/hunk_5181.cpp,,,data/crawl/squid/old_hunk_5181.cpp,data/crawl/squid/new_hunk_5181.cpp,12,7,"fatal(""Aiee! out of aiocb slots!\n"");","debug(79, 1) (""WARNING: out of aiocb slots!\n"");","[""updateLog"", ""moveLog"", ""updateContent"", ""addContent""]","[[""fatal"", ""Aiee""], [""debug"", ""79"", ""1"", ""WARNING""]]",[11113744927373523470],6473,0.0,2
https://github.com/squid-cache/squid/commit/e4a67a801853cb8b1837e224dec8cd135442b7e9,06 Sep 2003,"Summary: Allow -DPURIFY to build.
Keywords:

Allow -DPURIFY to build.",70,data/crawl/squid/hunk_5178.cpp,,,data/crawl/squid/old_hunk_5178.cpp,data/crawl/squid/new_hunk_5178.cpp,-1,5,,"fatal (""over 100 errors sending to the daemon - aborting\n"");","[""addLog""]","[[], [""fatal"", ""over"", ""100"", ""errors"", ""sending"", ""to"", ""the"", ""daemon"", ""aborting\\n""]]",[-20476113453257831374],6472,0.0,2
https://github.com/squid-cache/squid/commit/e721bd8c980aeb9812c4e5990c3942bd121863e4,14 Sep 2003,Bootstrapped,10,data/crawl/squid/hunk_5176.cpp,,,data/crawl/squid/old_hunk_5176.cpp,data/crawl/squid/new_hunk_5176.cpp,3,3,"fprintf (fp, ""%d\n"", i);","fprintf (fp, ""%d\n"", i & ~0x3F);","[""addContent"", ""addVariable""]","[[], [""&"", ""0x3F""]]",[-3495018541108921558],6471,720.0,2
https://github.com/squid-cache/squid/commit/1958420ab5c704cef4debfc8300b7a756cedc002,15 Aug 2004,"external_acl helpers updated to use the new protocol format based
on URL-escaped strings rather than quoted words..",333,data/crawl/squid/hunk_5146.cpp,,,data/crawl/squid/old_hunk_5146.cpp,data/crawl/squid/new_hunk_5146.cpp,-1,16,,"fprintf(stderr, ""%s: Invalid request\n"", argv[0]);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""%s"", ""Invalid"", ""request\\n"", ""argv[0]""]]",[-14205886888525048147],6470,0.0,2
https://github.com/squid-cache/squid/commit/1958420ab5c704cef4debfc8300b7a756cedc002,15 Aug 2004,"external_acl helpers updated to use the new protocol format based
on URL-escaped strings rather than quoted words..",333,data/crawl/squid/hunk_5145.cpp,,,data/crawl/squid/old_hunk_5145.cpp,data/crawl/squid/new_hunk_5145.cpp,-1,5,,"fprintf(stderr, ""%s: ERROR: Too large: %s\n"", argv[0], line);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""%s"", ""ERROR"", ""Too"", ""large"", ""%s\\n"", ""argv[0]"", ""line""]]",[-2520549332920755081],6469,0.0,2
https://github.com/squid-cache/squid/commit/f5691f9c44e06c13e6970ff31f0fe540650f787e,30 Aug 2004,/tmp/cvsZKn66v,12787,data/crawl/squid/hunk_5132.cpp,,,data/crawl/squid/old_hunk_5132.cpp,data/crawl/squid/new_hunk_5132.cpp,20,-1,"fatal (""unusable\n"");",,"[""removeLog""]","[[""fatal"", ""unusable\\n""], []]",[7868195606522130728],6468,0.0,2
https://github.com/squid-cache/squid/commit/d8f10d6ad810fec71d79f63336da847228441bfb,22 Dec 2004,Bug #1118: Squid sends requests to redirectors with shutdown flag on,63,data/crawl/squid/hunk_5095.cpp,,,data/crawl/squid/old_hunk_5095.cpp,data/crawl/squid/new_hunk_5095.cpp,7,9,"fatalf(""Too few %s processes are running"", hlp->id_name);","fatalf(""Too few %s processes are running\n"", hlp->id_name);","[""updateContent""]","[[""running""], [""running\\n""]]",[7481285087206984508],6467,0.0,2
https://github.com/squid-cache/squid/commit/5ea33fce1749c26148150d7f0d0959334c6b91ba,22 Dec 2004,Bug #1168: Forward port of 2.5 patch for handle crashing helpers more gracefully,32,data/crawl/squid/hunk_5088.cpp,,,data/crawl/squid/old_hunk_5088.cpp,data/crawl/squid/new_hunk_5088.cpp,-1,7,,"fatalf(""The %s helpers are crashing too rapidly, need help!\n"", hlp->id_name);","[""addLog""]","[[], [""fatalf"", ""The"", ""%s"", ""helpers"", ""are"", ""crashing"", ""too"", ""rapidly"", ""need"", ""help"", ""\\n"", ""hlp"", ""id_name""]]",[-1144953548313843161],6466,0.0,2
https://github.com/squid-cache/squid/commit/5ea33fce1749c26148150d7f0d0959334c6b91ba,22 Dec 2004,Bug #1168: Forward port of 2.5 patch for handle crashing helpers more gracefully,32,data/crawl/squid/hunk_5088.cpp,,,data/crawl/squid/old_hunk_5088.cpp,data/crawl/squid/new_hunk_5088.cpp,4,4,"fatalf(""Too few %s processes are running\n"", hlp->id_name);","debug(80, 0) (""Too few %s processes are running\n"", hlp->id_name);","[""updateLog"", ""moveLog"", ""addContent""]","[[""fatalf""], [""debug"", ""80"", ""0""]]",[1089018975632339177],6465,0.0,2
https://github.com/squid-cache/squid/commit/0a0c70cdc6ca87dff680d55d9e4d9f7be44c17ef,24 Apr 2005,"Bug #1223: Make the use of the %m error page to return auth info
messages

This patch extends the helper protocols for Basic and Digest to provide
some basic information in error responses, and makes use of the error
response already included in the NTLM helper protocol, making these
messages available as %m in error pages. Can be used if desired to
indicate why a login failed. The exact messages returned is helper
dependent.

Forward port of 2.5 patch.",68,data/crawl/squid/hunk_5056.cpp,,,data/crawl/squid/old_hunk_5056.cpp,data/crawl/squid/new_hunk_5056.cpp,-1,6,,auth_user_request->setDenyMessage(reply);,"[""addLog""]","[[], [""auth_user_request"", ""setDenyMessage"", ""reply""]]",[6720371840594190053],6464,0.0,2
https://github.com/squid-cache/squid/commit/0a0c70cdc6ca87dff680d55d9e4d9f7be44c17ef,24 Apr 2005,"Bug #1223: Make the use of the %m error page to return auth info
messages

This patch extends the helper protocols for Basic and Digest to provide
some basic information in error responses, and makes use of the error
response already included in the NTLM helper protocol, making these
messages available as %m in error pages. Can be used if desired to
indicate why a login failed. The exact messages returned is helper
dependent.

Forward port of 2.5 patch.",68,data/crawl/squid/hunk_5048.cpp,,,data/crawl/squid/old_hunk_5048.cpp,data/crawl/squid/new_hunk_5048.cpp,9,9,"printf(""ERR\n"");","printf(""ERR Wrong password\n"");","[""updateContent""]","[[""ERR\\n""], [""ERR"", ""Wrong"", ""password\\n""]]",[-5591343104109682799],6463,0.0,2
https://github.com/squid-cache/squid/commit/4b0f5de8653310c14d9adbccdd27ae8de543d088,06 May 2005,"Bug #1166: Configuration confusing when empty acls are encountered
Bug #1255: http_access line with unknown acls

This patch makes Squid very strict about access configuration errors.
Previously Squid ignored most errors, now it rejects the configuraiton
with an description of the error seen.",258,data/crawl/squid/hunk_5039.cpp,,,data/crawl/squid/old_hunk_5039.cpp,data/crawl/squid/new_hunk_5039.cpp,3,-1,"fatal(""aclParseUserMaxIP: Malformed ACL\n"");",,"[""removeLog""]","[[""fatal"", ""aclParseUserMaxIP"", ""Malformed"", ""ACL\\n""], []]",[-1444639019846540504],6462,0.0,2
https://github.com/squid-cache/squid/commit/d24ef4e96b7e08c55767889ec36eb4ff7d0aa743,14 May 2005,"Implement DNS Virtual Circuit lookups (TCP) as required when seeing a
truncated response.",223,data/crawl/squid/hunk_5038.cpp,,,data/crawl/squid/old_hunk_5038.cpp,data/crawl/squid/new_hunk_5038.cpp,-1,89,,"fatal(""Could not create a DNS socket"");","[""addLog""]","[[], [""fatal"", ""Could"", ""not"", ""create"", ""a"", ""DNS"", ""socket""]]",[1692271683703932066],6461,1599840.0,2
https://github.com/squid-cache/squid/commit/97b131b6130450dd8a7f30cfa87f9d0ac18de508,02 Jul 2005,"Samba-2.X is declared unsupported by the Samba team. Remove the old
winbind helpers to reduce confusion. People wanting winbind integration
really should use Samba-3.X these days.",4319,data/crawl/squid/hunk_5018.cpp,,,data/crawl/squid/old_hunk_5018.cpp,data/crawl/squid/new_hunk_5018.cpp,310,-1,"fprintf(stderr, ""%s: ERROR: Too large: %s\n"", argv[0], buf);",,"[""removeLog""]","[[""fprintf"", ""stderr"", ""%s"", ""ERROR"", ""Too"", ""large"", ""%s\\n"", ""argv[0]"", ""buf""], []]",[8164570441682819975],6460,0.0,2
https://github.com/squid-cache/squid/commit/a572d8be51590c02b60374de995595fcb3e30df5,10 Jul 2005,"Bug #1307: squid -k fails in combination with chroot after patch for bug 1157

Forward port of 2.5 patch.",38,data/crawl/squid/hunk_5011.cpp,,,data/crawl/squid/old_hunk_5011.cpp,data/crawl/squid/new_hunk_5011.cpp,-1,4,,"fatal(""Could not determine fully qualified hostname.  Please set 'visible_hostname'\n"");","[""addLog""]","[[], [""fatal"", ""Could"", ""not"", ""determine"", ""fully"", ""qualified"", ""hostname"", ""Please"", ""set"", ""visible_hostname"", ""\\n""]]",[21476799052309954207],6459,1354320.0,2
https://github.com/squid-cache/squid/commit/6bf4f823fa73dbe9e91d9e3600c313e15347d5d9,23 Oct 2005,"Negotiate authentication scheme support.

Originally written for Squid-2.5 by Henrik, ported to Squid-3 by Kinkie
and bugfixed by Henrik.",2492,data/crawl/squid/hunk_4955.cpp,,,data/crawl/squid/old_hunk_4955.cpp,data/crawl/squid/new_hunk_4955.cpp,76,-1,"fatal(""Invalid authenticate state for NTLMStart"");",,"[""removeLog""]","[[""fatal"", ""Invalid"", ""authenticate"", ""state"", ""for"", ""NTLMStart""], []]",[21171954645048328152],6458,0.0,2
https://github.com/squid-cache/squid/commit/6bf4f823fa73dbe9e91d9e3600c313e15347d5d9,23 Oct 2005,"Negotiate authentication scheme support.

Originally written for Squid-2.5 by Henrik, ported to Squid-3 by Kinkie
and bugfixed by Henrik.",2492,data/crawl/squid/hunk_4951.cpp,,,data/crawl/squid/old_hunk_4951.cpp,data/crawl/squid/new_hunk_4951.cpp,-1,334,,"httpHeaderPutStrf(&rep->header, type, ""Negotiate %s"", negotiate_request->server_blob);","[""addLog""]","[[], [""httpHeaderPutStrf"", ""&rep"", ""header"", ""type"", ""Negotiate"", ""%s"", ""negotiate_request"", ""server_blob""]]",[-16773970435113967854],6457,0.0,2
https://github.com/squid-cache/squid/commit/6e785d853c1867e4b7aea26b0add938b39897a69,31 Oct 2005,"Windows port: addition of native authentication helpers.

- mswin_auth: 		Basic helper
- mswin_ntlm_auth: 	NTLM helper
- mswin_negotiate_auth: Negotiate helper

Supported build environment:

- Cygwin
- MSYS + MinGW
- MS VisualStudio C++ 2005",2901,data/crawl/squid/hunk_4944.cpp,,,data/crawl/squid/old_hunk_4944.cpp,data/crawl/squid/new_hunk_4944.cpp,-1,194,,"printf(""AF %s %s\n"",c,cred);","[""addLog""]","[[], [""printf"", ""AF"", ""%s"", ""%s\\n"", ""c"", ""cred""]]",[18872928208238411468],6456,0.0,2
https://github.com/squid-cache/squid/commit/6e785d853c1867e4b7aea26b0add938b39897a69,31 Oct 2005,"Windows port: addition of native authentication helpers.

- mswin_auth: 		Basic helper
- mswin_ntlm_auth: 	NTLM helper
- mswin_negotiate_auth: Negotiate helper

Supported build environment:

- Cygwin
- MSYS + MinGW
- MS VisualStudio C++ 2005",2901,data/crawl/squid/hunk_4944.cpp,,,data/crawl/squid/old_hunk_4944.cpp,data/crawl/squid/new_hunk_4944.cpp,-1,161,,"fprintf(stderr, ""No newline in '%s'\n"", buf);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""No"", ""newline"", ""in"", ""%s"", ""\\n"", ""buf""]]",[-18626837259027111099],6455,0.0,2
https://github.com/squid-cache/squid/commit/6e785d853c1867e4b7aea26b0add938b39897a69,31 Oct 2005,"Windows port: addition of native authentication helpers.

- mswin_auth: 		Basic helper
- mswin_ntlm_auth: 	NTLM helper
- mswin_negotiate_auth: Negotiate helper

Supported build environment:

- Cygwin
- MSYS + MinGW
- MS VisualStudio C++ 2005",2901,data/crawl/squid/hunk_4940.cpp,,,data/crawl/squid/old_hunk_4940.cpp,data/crawl/squid/new_hunk_4940.cpp,-1,173,,"puts(""OK"");","[""addLog""]","[[], [""puts"", ""OK""]]",[4156745859220976650],6454,1265040.0,2
https://github.com/squid-cache/squid/commit/cf154edc5fe1e856fccf174400c7a288ca08fcb1,01 Nov 2005,Added helper executable name in stateful helper stats,4,data/crawl/squid/hunk_4937.cpp,,,data/crawl/squid/old_hunk_4937.cpp,data/crawl/squid/new_hunk_4937.cpp,-1,3,,"storeAppendPrintf(sentry, ""program: %s\n"",
                      hlp->cmdline->key);","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""program"", ""%s\\n"", ""hlp"", ""cmdline"", ""key""]]",[30445718953000698725],6453,739440.0,2
https://github.com/squid-cache/squid/commit/7da10d2bc6a00bfbac4d7e7335a2acdfe33a650a,07 Nov 2005,Handle crashing auth helper more gracefully in negotiate/ntlm,22,data/crawl/squid/hunk_4935.cpp,,,data/crawl/squid/old_hunk_4935.cpp,data/crawl/squid/new_hunk_4935.cpp,7,3,"fatal(""authenticateNegotiateHandleReply: called with no result string\n"");","debug(29, 1) (""authenticateNegotiateHandleReply: Helper '%p' crashed!.\n"", lastserver);","[""updateLog"", ""moveLog"", ""updateContent"", ""addContent"", ""addVariable""]","[[""fatal"", ""called"", ""with"", ""no"", ""result"", ""string\\n""], [""debug"", ""29"", ""1"", ""Helper"", ""%p"", ""crashed"", ""\\n"", ""lastserver""]]",[14009787677904221979],6452,0.0,2
https://github.com/squid-cache/squid/commit/774c051c0de35e84451b1752874015654c7b48d0,22 Nov 2005,Adding ICAP library files,6049,data/crawl/squid/hunk_4929.cpp,,,data/crawl/squid/old_hunk_4929.cpp,data/crawl/squid/new_hunk_4929.cpp,-1,380,,"buf.Printf(""Comm(%d"", connection);","[""addLog""]","[[], [""buf"", ""Printf"", ""Comm"", ""%d"", ""connection""]]",[15277834671268445314],6451,0.0,2
https://github.com/squid-cache/squid/commit/774c051c0de35e84451b1752874015654c7b48d0,22 Nov 2005,Adding ICAP library files,6049,data/crawl/squid/hunk_4926.cpp,,,data/crawl/squid/old_hunk_4926.cpp,data/crawl/squid/new_hunk_4926.cpp,-1,875,,"buf.Printf(""Host: %s:%d\r\n"", s.host.buf(), s.port);","[""addLog""]","[[], [""buf"", ""Printf"", ""Host"", ""%s"", ""%d\\r\\n"", ""s"", ""host"", ""buf"", ""s"", ""port""]]",[22592627612707107619],6450,0.0,2
https://github.com/squid-cache/squid/commit/774c051c0de35e84451b1752874015654c7b48d0,22 Nov 2005,Adding ICAP library files,6049,data/crawl/squid/hunk_4926.cpp,,,data/crawl/squid/old_hunk_4926.cpp,data/crawl/squid/new_hunk_4926.cpp,-1,788,,stopReceiving();,"[""addLog""]","[[], [""stopReceiving""]]",[-7301041899547781865],6449,0.0,2
https://github.com/squid-cache/squid/commit/625672046a6efd88726bcc9bde2c9fbcf236fb5c,28 Dec 2005,Bootstrapped,12493,data/crawl/squid/hunk_4893.cpp,,,data/crawl/squid/old_hunk_4893.cpp,data/crawl/squid/new_hunk_4893.cpp,-1,4,,puts (dlerror ());,"[""addLog""]","[[], [""puts"", ""dlerror""]]",[6708123453220136283],6448,0.0,2
https://github.com/squid-cache/squid/commit/b6b6f46632f4820a1a473fd51f38040945880fe7,04 Jan 2006,"Converted FwdState to a C++ class to take advantage of features
such as refcounting.",1345,data/crawl/squid/hunk_4888.cpp,,,data/crawl/squid/old_hunk_4888.cpp,data/crawl/squid/new_hunk_4888.cpp,14,-1,"storeAppendPrintf(s, ""\n"");",,"[""removeLog""]","[[""storeAppendPrintf"", ""s"", ""\\n""], []]",[-5193143779093595017],6447,862560.0,2
https://github.com/squid-cache/squid/commit/b6b6f46632f4820a1a473fd51f38040945880fe7,04 Jan 2006,"Converted FwdState to a C++ class to take advantage of features
such as refcounting.",1345,data/crawl/squid/hunk_4887.cpp,,,data/crawl/squid/old_hunk_4887.cpp,data/crawl/squid/new_hunk_4887.cpp,-1,48,,"storeAppendPrintf(s, ""\t%d"", FwdReplyCodes[j][i]);","[""addLog""]","[[], [""storeAppendPrintf"", ""s"", ""\\t%d"", ""FwdReplyCodes[j][i]""]]",[-7071452347212330517],6446,1854720.0,2
https://github.com/squid-cache/squid/commit/b6b6f46632f4820a1a473fd51f38040945880fe7,04 Jan 2006,"Converted FwdState to a C++ class to take advantage of features
such as refcounting.",1345,data/crawl/squid/hunk_4887.cpp,,,data/crawl/squid/old_hunk_4887.cpp,data/crawl/squid/new_hunk_4887.cpp,-1,45,,"storeAppendPrintf(s, ""%3d"", i);","[""addLog""]","[[], [""storeAppendPrintf"", ""s"", ""%3d"", ""i""]]",[410801906505891884],6445,1854720.0,2
https://github.com/squid-cache/squid/commit/b6b6f46632f4820a1a473fd51f38040945880fe7,04 Jan 2006,"Converted FwdState to a C++ class to take advantage of features
such as refcounting.",1345,data/crawl/squid/hunk_4887.cpp,,,data/crawl/squid/old_hunk_4887.cpp,data/crawl/squid/new_hunk_4887.cpp,-1,36,,"storeAppendPrintf(s, ""\ttry#%d"", j + 1);","[""addLog""]","[[], [""storeAppendPrintf"", ""s"", ""\\ttry"", ""%d"", ""j"", ""1""]]",[-2593327316465775669],6444,1854720.0,2
https://github.com/squid-cache/squid/commit/b6b6f46632f4820a1a473fd51f38040945880fe7,04 Jan 2006,"Converted FwdState to a C++ class to take advantage of features
such as refcounting.",1345,data/crawl/squid/hunk_4887.cpp,,,data/crawl/squid/old_hunk_4887.cpp,data/crawl/squid/new_hunk_4887.cpp,-1,33,,"storeAppendPrintf(s, ""Status"");","[""addLog""]","[[], [""storeAppendPrintf"", ""s"", ""Status""]]",[-540009101124091183],6443,1854720.0,2
https://github.com/squid-cache/squid/commit/6f0aab861682a3d9c8f72228b0ac01eac5e52526,24 Jan 2006,Started converting ftp.cc to use more C++ class methods,714,data/crawl/squid/hunk_4886.cpp,,,data/crawl/squid/old_hunk_4886.cpp,data/crawl/squid/new_hunk_4886.cpp,37,41,"storeAppendPrintf(e, ""<PRE>\n"");","storeAppendPrintf(entry, ""</PRE>\n"");","[""updateVariable""]","[[""e"", ""PRE""], [""entry"", ""/PRE""]]",[-11927136948032101437],6442,0.0,2
https://github.com/squid-cache/squid/commit/253caccb08f5a5a23ec0c9b89272145213c09ec0,26 Jan 2006,"The purpose of this change is to add ICAP RESPMOD support for FTP responses.

I created a ""ServerStateData"" class which has common elements of both
HttpStateData and FtpStateData.  It becomes a base class for both
of them.  ICAP now uses the ServerStateData methods.",643,data/crawl/squid/hunk_4884.cpp,,,data/crawl/squid/old_hunk_4884.cpp,data/crawl/squid/new_hunk_4884.cpp,34,38,"storeAppendPrintf(entry, ""</PRE>\n"");","printfReplyBody(""<HR noshade size=\""1px\"">\n"");","[""updateLog"", ""removeVariable""]","[[""storeAppendPrintf"", ""entry"", ""/PRE""], [""printfReplyBody"", ""HR"", ""noshade"", ""size"", ""\\"", ""1px\\""]]",[2373935654350072244],6441,0.0,2
https://github.com/squid-cache/squid/commit/beed27a22dcbf485815b572eeac2b68a5a672f78,02 Apr 2006,"Bug #1504: misleading error message message for bad/unresolveable cache_peer name

Forward port of 2.5 changes.",73,data/crawl/squid/hunk_4874.cpp,,,data/crawl/squid/old_hunk_4874.cpp,data/crawl/squid/new_hunk_4874.cpp,4,4,"str.Printf(""ServerIP: %s\r\n"", err->host);","str.Printf(""ServerIP: %s\r\n"", r->hier.host);","[""updateVariable"", ""addVariable""]","[[""err""], [""r"", ""hier""]]",[10850723213029140737],6440,0.0,2
https://github.com/squid-cache/squid/commit/faadb1b64436077d7f3b02e30cb9684b1c9ad075,10 Apr 2006,removed obsolete ldap files. These was moved to the ldap helper directory,662,data/crawl/squid/hunk_4873.cpp,,,data/crawl/squid/old_hunk_4873.cpp,data/crawl/squid/new_hunk_4873.cpp,363,-1,"fprintf(stderr, ""Could not Activate TLS connection\n"");",,"[""removeLog""]","[[""fprintf"", ""stderr"", ""Could"", ""not"", ""Activate"", ""TLS"", ""connection\\n""], []]",[94042995092749779],6439,455040.0,2
https://github.com/squid-cache/squid/commit/faadb1b64436077d7f3b02e30cb9684b1c9ad075,10 Apr 2006,removed obsolete ldap files. These was moved to the ldap helper directory,662,data/crawl/squid/hunk_4873.cpp,,,data/crawl/squid/old_hunk_4873.cpp,data/crawl/squid/new_hunk_4873.cpp,357,-1,"fprintf(stderr, ""Could not set LDAP_OPT_PROTOCOL_VERSION %d\n"",
		version);",,"[""removeLog""]","[[""fprintf"", ""stderr"", ""Could"", ""not"", ""set"", ""LDAP_OPT_PROTOCOL_VERSION"", ""%d\\n"", ""version""], []]",[-14165094135550653739],6438,455040.0,2
https://github.com/squid-cache/squid/commit/faadb1b64436077d7f3b02e30cb9684b1c9ad075,10 Apr 2006,removed obsolete ldap files. These was moved to the ldap helper directory,662,data/crawl/squid/hunk_4873.cpp,,,data/crawl/squid/old_hunk_4873.cpp,data/crawl/squid/new_hunk_4873.cpp,346,-1,"fprintf(stderr, ""\nUnable to connect to LDAP server:%s port:%d\n"", ldapServer, port);",,"[""removeLog""]","[[""fprintf"", ""stderr"", ""\\nUnable"", ""to"", ""connect"", ""to"", ""LDAP"", ""server"", ""%s"", ""port"", ""%d\\n"", ""ldapServer"", ""port""], []]",[-3824874482844155251],6437,455040.0,2
https://github.com/squid-cache/squid/commit/faadb1b64436077d7f3b02e30cb9684b1c9ad075,10 Apr 2006,removed obsolete ldap files. These was moved to the ldap helper directory,662,data/crawl/squid/hunk_4873.cpp,,,data/crawl/squid/old_hunk_4873.cpp,data/crawl/squid/new_hunk_4873.cpp,339,-1,"fprintf(stderr, ""\nUnable to connect to SSL LDAP server: %s port:%d\n"",
		    ldapServer, port);",,"[""removeLog""]","[[""fprintf"", ""stderr"", ""\\nUnable"", ""to"", ""connect"", ""to"", ""SSL"", ""LDAP"", ""server"", ""%s"", ""port"", ""%d\\n"", ""ldapServer"", ""port""], []]",[-3455699060833364420],6436,455040.0,2
https://github.com/squid-cache/squid/commit/faadb1b64436077d7f3b02e30cb9684b1c9ad075,10 Apr 2006,removed obsolete ldap files. These was moved to the ldap helper directory,662,data/crawl/squid/hunk_4873.cpp,,,data/crawl/squid/old_hunk_4873.cpp,data/crawl/squid/new_hunk_4873.cpp,332,-1,"fprintf(stderr, ""\nUnable to initialise SSL with cert path %s\n"",
		    sslpath);",,"[""removeLog""]","[[""fprintf"", ""stderr"", ""\\nUnable"", ""to"", ""initialise"", ""SSL"", ""with"", ""cert"", ""path"", ""%s\\n"", ""sslpath""], []]",[-8616501409148837831],6435,455040.0,2
https://github.com/squid-cache/squid/commit/faadb1b64436077d7f3b02e30cb9684b1c9ad075,10 Apr 2006,removed obsolete ldap files. These was moved to the ldap helper directory,662,data/crawl/squid/hunk_4873.cpp,,,data/crawl/squid/old_hunk_4873.cpp,data/crawl/squid/new_hunk_4873.cpp,325,-1,"fprintf(stderr, ""\nUnable to connect to LDAPURI:%s\n"", ldapServer);",,"[""removeLog""]","[[""fprintf"", ""stderr"", ""\\nUnable"", ""to"", ""connect"", ""to"", ""LDAPURI"", ""%s\\n"", ""ldapServer""], []]",[968658030135572842],6434,455040.0,2
https://github.com/squid-cache/squid/commit/d295d770bbd2f84321b092fbb097f0867acca675,23 Apr 2006,"BUGFIX: max_user_ip was broken: initialising to -1 meant that the ACL appeared
        already configured to the parser, and thus it never configured to a
	valid value. Fixed with a test case to ensure that a normal ACL line
	will parse the -s and the limit values correctly, and a separat test
	that the defaults are as expected.",2547,data/crawl/squid/hunk_4868.cpp,,,data/crawl/squid/old_hunk_4868.cpp,data/crawl/squid/new_hunk_4868.cpp,-1,95,,"mb->Printf(""%s\n"", w->key);","[""addLog""]","[[], [""mb"", ""Printf"", ""%s\\n"", ""w"", ""key""]]",[22035595571378515708],6433,156960.0,2
https://github.com/squid-cache/squid/commit/d295d770bbd2f84321b092fbb097f0867acca675,23 Apr 2006,"BUGFIX: max_user_ip was broken: initialising to -1 meant that the ACL appeared
        already configured to the parser, and thus it never configured to a
	valid value. Fixed with a test case to ensure that a normal ACL line
	will parse the -s and the limit values correctly, and a separat test
	that the defaults are as expected.",2547,data/crawl/squid/hunk_4865.cpp,,,data/crawl/squid/old_hunk_4865.cpp,data/crawl/squid/new_hunk_4865.cpp,-1,42,,"fatalf(""Bungled %s line %d: %s"",
           cfg_filename, config_lineno, config_input_line);","[""addLog""]","[[], [""fatalf"", ""Bungled"", ""%s"", ""line"", ""%d"", ""%s"", ""cfg_filename"", ""config_lineno"", ""config_input_line""]]",[36399673581523345217],6432,2076480.0,2
https://github.com/squid-cache/squid/commit/a9925b40bf8179ee4468c997960413a6d510abf5,07 May 2006,Converted most other httpHeader*() functions to HttpHeader class methods.,903,data/crawl/squid/hunk_4842.cpp,,,data/crawl/squid/old_hunk_4842.cpp,data/crawl/squid/new_hunk_4842.cpp,-1,7,,pe->getReply();,"[""addLog""]","[[], [""pe"", ""getReply""]]",[-1241114362315085081],6431,0.0,2
https://github.com/squid-cache/squid/commit/a9925b40bf8179ee4468c997960413a6d510abf5,07 May 2006,Converted most other httpHeader*() functions to HttpHeader class methods.,903,data/crawl/squid/hunk_4837.cpp,,,data/crawl/squid/old_hunk_4837.cpp,data/crawl/squid/new_hunk_4837.cpp,-1,41,,"hdr_out->putStr(HDR_HOST, orig_request->host);","[""addLog""]","[[], [""hdr_out"", ""putStr"", ""HDR_HOST"", ""orig_request"", ""host""]]",[2378139491246630316],6430,0.0,2
https://github.com/squid-cache/squid/commit/4daf94197f026ad450d3a84f6bf4762b8975ca88,23 May 2006,"Fix a memory corruption when building the magic Vary marker object headers

somehow this cast made things go very bad. Luckily it isn't needed as
we already hold a reference to the reply a few lines earlier.",6,data/crawl/squid/hunk_4814.cpp,,,data/crawl/squid/old_hunk_4814.cpp,data/crawl/squid/new_hunk_4814.cpp,3,-1,pe->getReply();,,"[""removeLog""]","[[""pe"", ""getReply""], []]",[1241114362315085081],6429,0.0,2
https://github.com/squid-cache/squid/commit/663c0a384e7af8c593647fc04a89cb7051ac6cdf,14 Jun 2006,"Partial Windows native port merge:

- Native Windows comm_select() implementation",945,data/crawl/squid/hunk_4804.cpp,,,data/crawl/squid/old_hunk_4804.cpp,data/crawl/squid/new_hunk_4804.cpp,-1,879,,"storeAppendPrintf(sentry, ""HTTP Messages handled per comm_select_http_incoming() call:\n"");","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""HTTP"", ""Messages"", ""handled"", ""per"", ""comm_select_http_incoming"", ""call"", ""\\n""]]",[30378957463200746489],6428,2077200.0,2
https://github.com/squid-cache/squid/commit/663c0a384e7af8c593647fc04a89cb7051ac6cdf,14 Jun 2006,"Partial Windows native port merge:

- Native Windows comm_select() implementation",945,data/crawl/squid/hunk_4804.cpp,,,data/crawl/squid/old_hunk_4804.cpp,data/crawl/squid/new_hunk_4804.cpp,-1,877,,"storeAppendPrintf(sentry, ""DNS Messages handled per comm_select_dns_incoming() call:\n"");","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""DNS"", ""Messages"", ""handled"", ""per"", ""comm_select_dns_incoming"", ""call"", ""\\n""]]",[13579659345014966049],6427,1883520.0,2
https://github.com/squid-cache/squid/commit/663c0a384e7af8c593647fc04a89cb7051ac6cdf,14 Jun 2006,"Partial Windows native port merge:

- Native Windows comm_select() implementation",945,data/crawl/squid/hunk_4804.cpp,,,data/crawl/squid/old_hunk_4804.cpp,data/crawl/squid/new_hunk_4804.cpp,-1,875,,"storeAppendPrintf(sentry, ""ICP Messages handled per comm_select_icp_incoming() call:\n"");","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""ICP"", ""Messages"", ""handled"", ""per"", ""comm_select_icp_incoming"", ""call"", ""\\n""]]",[7700910912818219009],6426,2077200.0,2
https://github.com/squid-cache/squid/commit/0b0cfcf2551cc75038f51612a0f2f738628dc52c,02 Jul 2006,Forward port of WCCPv2 support and latest WCCPv1 changes from 2.6.,2405,data/crawl/squid/hunk_4802.cpp,,,data/crawl/squid/old_hunk_4802.cpp,data/crawl/squid/new_hunk_4802.cpp,-1,1897,,"storeAppendPrintf(e, ""%ssrc_ip_alt_hash"", comma ? "","" : """");","[""addLog""]","[[], [""storeAppendPrintf"", ""e"", ""%ssrc_ip_alt_hash"", ""comma""]]",[18945722798622765847],6425,0.0,2
https://github.com/squid-cache/squid/commit/0b0cfcf2551cc75038f51612a0f2f738628dc52c,02 Jul 2006,Forward port of WCCPv2 support and latest WCCPv1 changes from 2.6.,2405,data/crawl/squid/hunk_4802.cpp,,,data/crawl/squid/old_hunk_4802.cpp,data/crawl/squid/new_hunk_4802.cpp,-1,862,,"fatal(""Unable to getsockname on WCCP out socket"");","[""addLog""]","[[], [""fatal"", ""Unable"", ""to"", ""getsockname"", ""on"", ""WCCP"", ""out"", ""socket""]]",[5865329681165822785],6424,1826640.0,2
https://github.com/squid-cache/squid/commit/0b0cfcf2551cc75038f51612a0f2f738628dc52c,02 Jul 2006,Forward port of WCCPv2 support and latest WCCPv1 changes from 2.6.,2405,data/crawl/squid/hunk_4802.cpp,,,data/crawl/squid/old_hunk_4802.cpp,data/crawl/squid/new_hunk_4802.cpp,-1,855,,"fatal(""Unable to connect WCCP out socket"");","[""addLog""]","[[], [""fatal"", ""Unable"", ""to"", ""connect"", ""WCCP"", ""out"", ""socket""]]",[7842912790810741343],6423,1826640.0,2
https://github.com/squid-cache/squid/commit/0b0cfcf2551cc75038f51612a0f2f738628dc52c,02 Jul 2006,Forward port of WCCPv2 support and latest WCCPv1 changes from 2.6.,2405,data/crawl/squid/hunk_4802.cpp,,,data/crawl/squid/old_hunk_4802.cpp,data/crawl/squid/new_hunk_4802.cpp,-1,830,,"fatal(""Cannot open WCCP Port"");","[""addLog""]","[[], [""fatal"", ""Cannot"", ""open"", ""WCCP"", ""Port""]]",[-5595549084306699922],6422,1888560.0,2
https://github.com/squid-cache/squid/commit/8ff3fa2e10cb85fb2e2edefdc4f00c935a4ca92f,12 Aug 2006,"Add AsyncEngine and TimeEngine support to the EventLoop, allowing it to
completely replace the old one embedded in main.cc - convert loop using
tests to use an event loop instance.",857,data/crawl/squid/hunk_4775.cpp,,,data/crawl/squid/old_hunk_4775.cpp,data/crawl/squid/new_hunk_4775.cpp,-1,7,,theLoop.stop();,"[""addLog""]","[[], [""theLoop"", ""stop""]]",[-8369492412151735424],6421,3600.0,2
https://github.com/squid-cache/squid/commit/8ff3fa2e10cb85fb2e2edefdc4f00c935a4ca92f,12 Aug 2006,"Add AsyncEngine and TimeEngine support to the EventLoop, allowing it to
completely replace the old one embedded in main.cc - convert loop using
tests to use an event loop instance.",857,data/crawl/squid/hunk_4770.cpp,,,data/crawl/squid/old_hunk_4770.cpp,data/crawl/squid/new_hunk_4770.cpp,61,-1,"fatal_dump(""MAIN: Internal error -- this should never happen."");",,"[""removeLog""]","[[""fatal_dump"", ""MAIN"", ""Internal"", ""error"", ""this"", ""should"", ""never"", ""happen""], []]",[18383739867664462038],6420,3600.0,2
https://github.com/squid-cache/squid/commit/0e6205b4f1d53562b36e8d6f315f54883b944fd7,14 Aug 2006,"Bug #582: fake_auth ntlmGetString: bad ascii: ffffffb9 followed by FATAL: authenticateNTLMHandleReply: called with no result string

This is a major revision of fake_auth:

- Added support for unicode char encoding
- Added runtime debug functionality
- Removed offending fprintf(stdout)
- Removed obslete unused code sections

The support for unicode char encoding allow the usage of high ascii characters
in username with Windows NT/2000/XP/2003 clients. This still cannot work for
obsolete Windows 9x clients.",351,data/crawl/squid/hunk_4769.cpp,,,data/crawl/squid/old_hunk_4769.cpp,data/crawl/squid/new_hunk_4769.cpp,-1,60,,"fprintf(stderr, ""ntlm-auth[%d]: "", getpid());","[""addLog""]","[[], [""fprintf"", ""stderr"", ""ntlm"", ""auth[%d]"", ""getpid""]]",[-9655032389557404923],6419,206640.0,2
https://github.com/squid-cache/squid/commit/0e6205b4f1d53562b36e8d6f315f54883b944fd7,14 Aug 2006,"Bug #582: fake_auth ntlmGetString: bad ascii: ffffffb9 followed by FATAL: authenticateNTLMHandleReply: called with no result string

This is a major revision of fake_auth:

- Added support for unicode char encoding
- Added runtime debug functionality
- Removed offending fprintf(stdout)
- Removed obslete unused code sections

The support for unicode char encoding allow the usage of high ascii characters
in username with Windows NT/2000/XP/2003 clients. This still cannot work for
obsolete Windows 9x clients.",351,data/crawl/squid/hunk_4768.cpp,,,data/crawl/squid/old_hunk_4768.cpp,data/crawl/squid/new_hunk_4768.cpp,-1,51,,"fprintf(stderr,
	""Usage: %s [-d] [-v] [-h]\n""
	"" -d  enable debugging.\n""
	"" -v  enable verbose NTLM packet debugging.\n""
	"" -h  this message\n\n"",
	my_program_name);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""Usage"", ""%s"", ""["", ""d]"", ""["", ""v]"", ""["", ""h]\\n"", ""d"", ""enable"", ""debugging"", ""\\n"", ""v"", ""enable"", ""verbose"", ""NTLM"", ""packet"", ""debugging"", ""\\n"", ""h"", ""this"", ""message\\n\\n"", ""my_program_name""]]",[-19941283037180204258],6418,206640.0,2
https://github.com/squid-cache/squid/commit/ccb8b57c83bd82124bfbad90f64398794ce1a04e,28 Aug 2006,Fix another harmless fake_auth compiler warning on gcc 4.1.1 x86,8,data/crawl/squid/hunk_4758.cpp,,,data/crawl/squid/old_hunk_4758.cpp,data/crawl/squid/new_hunk_4758.cpp,3,3,"fprintf(stderr, ""ntlm-auth[%d]: "", getpid());","fprintf(stderr, ""ntlm-auth[%ld]: "", (long)getpid());","[""updateContent"", ""addVariable""]","[[""auth[%d]""], [""auth[%ld]"", ""long""]]",[10118911498824314933],6417,383760.0,2
https://github.com/squid-cache/squid/commit/595c79732716913858c8b6c0b301fa4672564616,07 Sep 2006,Windows port: Added Windows threads support to DiskThreads Disk module,1272,data/crawl/squid/hunk_4752.cpp,,,data/crawl/squid/old_hunk_4752.cpp,data/crawl/squid/new_hunk_4752.cpp,-1,1217,,"storeAppendPrintf(sentry, ""#\tID\t# Requests\n"");","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""\\tID\\t"", ""Requests\\n""]]",[8194622206143574933],6416,372960.0,2
https://github.com/squid-cache/squid/commit/595c79732716913858c8b6c0b301fa4672564616,07 Sep 2006,Windows port: Added Windows threads support to DiskThreads Disk module,1272,data/crawl/squid/hunk_4752.cpp,,,data/crawl/squid/old_hunk_4752.cpp,data/crawl/squid/new_hunk_4752.cpp,-1,1215,,"storeAppendPrintf(sentry, ""\n\nThreads Status:\n"");","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""\\n\\nThreads"", ""Status"", ""\\n""]]",[5051386184041672194],6415,372960.0,2
https://github.com/squid-cache/squid/commit/595c79732716913858c8b6c0b301fa4672564616,07 Sep 2006,Windows port: Added Windows threads support to DiskThreads Disk module,1272,data/crawl/squid/hunk_4752.cpp,,,data/crawl/squid/old_hunk_4752.cpp,data/crawl/squid/new_hunk_4752.cpp,-1,608,,"fatal(""Couldn't push queue"");","[""addLog""]","[[], [""fatal"", ""Couldn"", ""t"", ""push"", ""queue""]]",[-2482845866887331203],6414,0.0,2
https://github.com/squid-cache/squid/commit/595c79732716913858c8b6c0b301fa4672564616,07 Sep 2006,Windows port: Added Windows threads support to DiskThreads Disk module,1272,data/crawl/squid/hunk_4752.cpp,,,data/crawl/squid/old_hunk_4752.cpp,data/crawl/squid/new_hunk_4752.cpp,-1,334,,"fprintf(stderr, ""Thread creation failed\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""Thread"", ""creation"", ""failed\\n""]]",[-11900499686379701240],6413,1668960.0,2
https://github.com/squid-cache/squid/commit/9c8434f6a8753d321762ff58685cb1ff0364b4a7,14 Sep 2006,"Windows port: split Windows service code into WinSvc.cc, allowing correct execution of make check",1963,data/crawl/squid/hunk_4751.cpp,,,data/crawl/squid/old_hunk_4751.cpp,data/crawl/squid/new_hunk_4751.cpp,109,-1,"fprintf(stderr, ""RegCloseKey %d\n"", (int) rv);",,"[""removeLog""]","[[""fprintf"", ""stderr"", ""RegCloseKey"", ""%d\\n"", ""int"", ""rv""], []]",[13964991524264781003],6412,0.0,2
https://github.com/squid-cache/squid/commit/9c8434f6a8753d321762ff58685cb1ff0364b4a7,14 Sep 2006,"Windows port: split Windows service code into WinSvc.cc, allowing correct execution of make check",1963,data/crawl/squid/hunk_4750.cpp,,,data/crawl/squid/old_hunk_4750.cpp,data/crawl/squid/new_hunk_4750.cpp,-1,895,,"fprintf(stderr, ""StartServiceCtrlDispatcher error = %ld\n"",
                    GetLastError());","[""addLog""]","[[], [""fprintf"", ""stderr"", ""StartServiceCtrlDispatcher"", ""error"", ""%ld\\n"", ""GetLastError""]]",[-15141737662235801812],6411,894240.0,2
https://github.com/squid-cache/squid/commit/9c8434f6a8753d321762ff58685cb1ff0364b4a7,14 Sep 2006,"Windows port: split Windows service code into WinSvc.cc, allowing correct execution of make check",1963,data/crawl/squid/hunk_4750.cpp,,,data/crawl/squid/old_hunk_4750.cpp,data/crawl/squid/new_hunk_4750.cpp,-1,885,,"fprintf(stderr, ""Bad Service Parameter: %s\n"", argv[1]);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""Bad"", ""Service"", ""Parameter"", ""%s\\n"", ""argv[1]""]]",[-10344790016938012624],6410,894240.0,2
https://github.com/squid-cache/squid/commit/9c8434f6a8753d321762ff58685cb1ff0364b4a7,14 Sep 2006,"Windows port: split Windows service code into WinSvc.cc, allowing correct execution of make check",1963,data/crawl/squid/hunk_4750.cpp,,,data/crawl/squid/old_hunk_4750.cpp,data/crawl/squid/new_hunk_4750.cpp,-1,858,,"printf(""  Wait Hint: %ld\n"", ssStatus.dwWaitHint);","[""addLog""]","[[], [""printf"", ""Wait"", ""Hint"", ""%ld\\n"", ""ssStatus"", ""dwWaitHint""]]",[19317442497146412908],6409,894240.0,2
https://github.com/squid-cache/squid/commit/9c8434f6a8753d321762ff58685cb1ff0364b4a7,14 Sep 2006,"Windows port: split Windows service code into WinSvc.cc, allowing correct execution of make check",1963,data/crawl/squid/hunk_4750.cpp,,,data/crawl/squid/old_hunk_4750.cpp,data/crawl/squid/new_hunk_4750.cpp,-1,857,,"printf(""  Check Point: %ld\n"", ssStatus.dwCheckPoint);","[""addLog""]","[[], [""printf"", ""Check"", ""Point"", ""%ld\\n"", ""ssStatus"", ""dwCheckPoint""]]",[-1256790467540788750],6408,894240.0,2
https://github.com/squid-cache/squid/commit/9c8434f6a8753d321762ff58685cb1ff0364b4a7,14 Sep 2006,"Windows port: split Windows service code into WinSvc.cc, allowing correct execution of make check",1963,data/crawl/squid/hunk_4750.cpp,,,data/crawl/squid/old_hunk_4750.cpp,data/crawl/squid/new_hunk_4750.cpp,-1,855,,"printf(""  Service Specific Exit Code: %ld\n"",
                   ssStatus.dwServiceSpecificExitCode);","[""addLog""]","[[], [""printf"", ""Service"", ""Specific"", ""Exit"", ""Code"", ""%ld\\n"", ""ssStatus"", ""dwServiceSpecificExitCode""]]",[18140658492809293212],6407,894240.0,2
https://github.com/squid-cache/squid/commit/9c8434f6a8753d321762ff58685cb1ff0364b4a7,14 Sep 2006,"Windows port: split Windows service code into WinSvc.cc, allowing correct execution of make check",1963,data/crawl/squid/hunk_4750.cpp,,,data/crawl/squid/old_hunk_4750.cpp,data/crawl/squid/new_hunk_4750.cpp,-1,854,,"printf(""  Exit Code: %ld\n"", ssStatus.dwWin32ExitCode);","[""addLog""]","[[], [""printf"", ""Exit"", ""Code"", ""%ld\\n"", ""ssStatus"", ""dwWin32ExitCode""]]",[22858854831581527440],6406,894240.0,2
https://github.com/squid-cache/squid/commit/9c8434f6a8753d321762ff58685cb1ff0364b4a7,14 Sep 2006,"Windows port: split Windows service code into WinSvc.cc, allowing correct execution of make check",1963,data/crawl/squid/hunk_4750.cpp,,,data/crawl/squid/old_hunk_4750.cpp,data/crawl/squid/new_hunk_4750.cpp,-1,853,,"printf(""  Controls Accepted: 0x%lx\n"", ssStatus.dwControlsAccepted);","[""addLog""]","[[], [""printf"", ""Controls"", ""Accepted"", ""0x%lx\\n"", ""ssStatus"", ""dwControlsAccepted""]]",[17710171042922590636],6405,894240.0,2
https://github.com/squid-cache/squid/commit/9c8434f6a8753d321762ff58685cb1ff0364b4a7,14 Sep 2006,"Windows port: split Windows service code into WinSvc.cc, allowing correct execution of make check",1963,data/crawl/squid/hunk_4750.cpp,,,data/crawl/squid/old_hunk_4750.cpp,data/crawl/squid/new_hunk_4750.cpp,-1,852,,"printf(""  Current State: 0x%lx\n"", ssStatus.dwCurrentState);","[""addLog""]","[[], [""printf"", ""Current"", ""State"", ""0x%lx\\n"", ""ssStatus"", ""dwCurrentState""]]",[15574618889590672524],6404,894240.0,2
https://github.com/squid-cache/squid/commit/9c8434f6a8753d321762ff58685cb1ff0364b4a7,14 Sep 2006,"Windows port: split Windows service code into WinSvc.cc, allowing correct execution of make check",1963,data/crawl/squid/hunk_4750.cpp,,,data/crawl/squid/old_hunk_4750.cpp,data/crawl/squid/new_hunk_4750.cpp,-1,851,,"printf(""  Service Type: 0x%lx\n"", ssStatus.dwServiceType);","[""addLog""]","[[], [""printf"", ""Service"", ""Type"", ""0x%lx\\n"", ""ssStatus"", ""dwServiceType""]]",[20150784739377180034],6403,894240.0,2
https://github.com/squid-cache/squid/commit/9c8434f6a8753d321762ff58685cb1ff0364b4a7,14 Sep 2006,"Windows port: split Windows service code into WinSvc.cc, allowing correct execution of make check",1963,data/crawl/squid/hunk_4750.cpp,,,data/crawl/squid/old_hunk_4750.cpp,data/crawl/squid/new_hunk_4750.cpp,-1,850,,"printf(""\nStatus of %s Service:\n"", WIN32_Service_name);","[""addLog""]","[[], [""printf"", ""\\nStatus"", ""of"", ""%s"", ""Service"", ""\\n"", ""WIN32_Service_name""]]",[12232254655465740411],6402,894240.0,2
https://github.com/squid-cache/squid/commit/9c8434f6a8753d321762ff58685cb1ff0364b4a7,14 Sep 2006,"Windows port: split Windows service code into WinSvc.cc, allowing correct execution of make check",1963,data/crawl/squid/hunk_4750.cpp,,,data/crawl/squid/old_hunk_4750.cpp,data/crawl/squid/new_hunk_4750.cpp,-1,845,,"fprintf(stderr, ""%s: ERROR: Could not Control Service %s\n"",
                    appname, WIN32_Service_name);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""%s"", ""ERROR"", ""Could"", ""not"", ""Control"", ""Service"", ""%s\\n"", ""appname"", ""WIN32_Service_name""]]",[14610209532071689463],6401,894240.0,2
https://github.com/squid-cache/squid/commit/9c8434f6a8753d321762ff58685cb1ff0364b4a7,14 Sep 2006,"Windows port: split Windows service code into WinSvc.cc, allowing correct execution of make check",1963,data/crawl/squid/hunk_4750.cpp,,,data/crawl/squid/old_hunk_4750.cpp,data/crawl/squid/new_hunk_4750.cpp,-1,836,,"fprintf(stderr, ""%s: ERROR: Could not open Service %s\n"", appname,
                WIN32_Service_name);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""%s"", ""ERROR"", ""Could"", ""not"", ""open"", ""Service"", ""%s\\n"", ""appname"", ""WIN32_Service_name""]]",[18079543569373335187],6400,894240.0,2
https://github.com/squid-cache/squid/commit/9c8434f6a8753d321762ff58685cb1ff0364b4a7,14 Sep 2006,"Windows port: split Windows service code into WinSvc.cc, allowing correct execution of make check",1963,data/crawl/squid/hunk_4750.cpp,,,data/crawl/squid/old_hunk_4750.cpp,data/crawl/squid/new_hunk_4750.cpp,-1,762,,"fprintf(stderr, ""CreateService failed\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""CreateService"", ""failed\\n""]]",[-20387067007984670057],6399,894240.0,2
https://github.com/squid-cache/squid/commit/9c8434f6a8753d321762ff58685cb1ff0364b4a7,14 Sep 2006,"Windows port: split Windows service code into WinSvc.cc, allowing correct execution of make check",1963,data/crawl/squid/hunk_4750.cpp,,,data/crawl/squid/old_hunk_4750.cpp,data/crawl/squid/new_hunk_4750.cpp,-1,760,,"printf(""Don't forget to edit squid.conf before starting it.\n\n"");","[""addLog""]","[[], [""printf"", ""Don"", ""t"", ""forget"", ""to"", ""edit"", ""squid"", ""conf"", ""before"", ""starting"", ""it"", ""\\n\\n""]]",[6271469254997766867],6398,894240.0,2
https://github.com/squid-cache/squid/commit/9c8434f6a8753d321762ff58685cb1ff0364b4a7,14 Sep 2006,"Windows port: split Windows service code into WinSvc.cc, allowing correct execution of make check",1963,data/crawl/squid/hunk_4750.cpp,,,data/crawl/squid/old_hunk_4750.cpp,data/crawl/squid/new_hunk_4750.cpp,-1,757,,"printf
            (""To run, start it from the Services Applet of Control Panel.\n"");","[""addLog""]","[[], [""printf"", ""To"", ""run"", ""start"", ""it"", ""from"", ""the"", ""Services"", ""Applet"", ""of"", ""Control"", ""Panel"", ""\\n""]]",[-13852713155740126990],6397,894240.0,2
https://github.com/squid-cache/squid/commit/9c8434f6a8753d321762ff58685cb1ff0364b4a7,14 Sep 2006,"Windows port: split Windows service code into WinSvc.cc, allowing correct execution of make check",1963,data/crawl/squid/hunk_4750.cpp,,,data/crawl/squid/old_hunk_4750.cpp,data/crawl/squid/new_hunk_4750.cpp,-1,754,,"printf(""installed successfully as %s Windows System Service.\n"",
                   WIN32_Service_name);","[""addLog""]","[[], [""printf"", ""installed"", ""successfully"", ""as"", ""%s"", ""Windows"", ""System"", ""Service"", ""\\n"", ""WIN32_Service_name""]]",[11372176681377384363],6396,894240.0,2
https://github.com/squid-cache/squid/commit/9c8434f6a8753d321762ff58685cb1ff0364b4a7,14 Sep 2006,"Windows port: split Windows service code into WinSvc.cc, allowing correct execution of make check",1963,data/crawl/squid/hunk_4750.cpp,,,data/crawl/squid/old_hunk_4750.cpp,data/crawl/squid/new_hunk_4750.cpp,-1,751,,"printf(""Squid Cache version %s for %s\n"", version_string,
                   CONFIG_HOST_TYPE);","[""addLog""]","[[], [""printf"", ""Squid"", ""Cache"", ""version"", ""%s"", ""for"", ""%s\\n"", ""version_string"", ""CONFIG_HOST_TYPE""]]",[-4935056387123843478],6395,894240.0,2
https://github.com/squid-cache/squid/commit/9c8434f6a8753d321762ff58685cb1ff0364b4a7,14 Sep 2006,"Windows port: split Windows service code into WinSvc.cc, allowing correct execution of make check",1963,data/crawl/squid/hunk_4750.cpp,,,data/crawl/squid/old_hunk_4750.cpp,data/crawl/squid/new_hunk_4750.cpp,-1,702,,"fprintf(stderr, ""Can't get executable path\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""Can"", ""t"", ""get"", ""executable"", ""path\\n""]]",[-12200881939712585114],6394,894240.0,2
https://github.com/squid-cache/squid/commit/9c8434f6a8753d321762ff58685cb1ff0364b4a7,14 Sep 2006,"Windows port: split Windows service code into WinSvc.cc, allowing correct execution of make check",1963,data/crawl/squid/hunk_4750.cpp,,,data/crawl/squid/old_hunk_4750.cpp,data/crawl/squid/new_hunk_4750.cpp,-1,661,,"printf(""Service %s deleted successfully.\n"",
                       WIN32_Service_name);","[""addLog""]","[[], [""printf"", ""Service"", ""%s"", ""deleted"", ""successfully"", ""\\n"", ""WIN32_Service_name""]]",[15324645909636283837],6393,894240.0,2
https://github.com/squid-cache/squid/commit/9c8434f6a8753d321762ff58685cb1ff0364b4a7,14 Sep 2006,"Windows port: split Windows service code into WinSvc.cc, allowing correct execution of make check",1963,data/crawl/squid/hunk_4750.cpp,,,data/crawl/squid/old_hunk_4750.cpp,data/crawl/squid/new_hunk_4750.cpp,-1,659,,"fprintf(stderr, ""DeleteService failed.\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""DeleteService"", ""failed"", ""\\n""]]",[-17762220787764812022],6392,894240.0,2
https://github.com/squid-cache/squid/commit/9c8434f6a8753d321762ff58685cb1ff0364b4a7,14 Sep 2006,"Windows port: split Windows service code into WinSvc.cc, allowing correct execution of make check",1963,data/crawl/squid/hunk_4750.cpp,,,data/crawl/squid/old_hunk_4750.cpp,data/crawl/squid/new_hunk_4750.cpp,-1,639,,"fprintf(stderr, ""OpenService failed\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""OpenService"", ""failed\\n""]]",[-14145636681122136471],6391,894240.0,2
https://github.com/squid-cache/squid/commit/9c8434f6a8753d321762ff58685cb1ff0364b4a7,14 Sep 2006,"Windows port: split Windows service code into WinSvc.cc, allowing correct execution of make check",1963,data/crawl/squid/hunk_4750.cpp,,,data/crawl/squid/old_hunk_4750.cpp,data/crawl/squid/new_hunk_4750.cpp,-1,242,,"fprintf(stderr, ""RegCloseKey HKLM\\%s, %d\n"", REGKEY, (int) rv);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""RegCloseKey"", ""HKLM\\\\%s"", ""%d\\n"", ""REGKEY"", ""int"", ""rv""]]",[-15587179598092841180],6390,894240.0,2
https://github.com/squid-cache/squid/commit/9c8434f6a8753d321762ff58685cb1ff0364b4a7,14 Sep 2006,"Windows port: split Windows service code into WinSvc.cc, allowing correct execution of make check",1963,data/crawl/squid/hunk_4750.cpp,,,data/crawl/squid/old_hunk_4750.cpp,data/crawl/squid/new_hunk_4750.cpp,-1,230,,"fprintf(stderr, ""Registry stored HKLM\\%s\\%s value %s\n"",
                REGKEY,
                key,
                type == REG_SZ ? value : (unsigned char *) ""(not displayable)"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""Registry"", ""stored"", ""HKLM\\\\%s\\\\%s"", ""value"", ""%s\\n"", ""REGKEY"", ""key"", ""type"", ""REG_SZ"", ""value"", ""unsigned"", ""char"", ""*"", ""not"", ""displayable""]]",[2357888911587133298],6389,894240.0,2
https://github.com/squid-cache/squid/commit/9c8434f6a8753d321762ff58685cb1ff0364b4a7,14 Sep 2006,"Windows port: split Windows service code into WinSvc.cc, allowing correct execution of make check",1963,data/crawl/squid/hunk_4750.cpp,,,data/crawl/squid/old_hunk_4750.cpp,data/crawl/squid/new_hunk_4750.cpp,-1,227,,"fprintf(stderr, ""RegQueryValueEx(key %s),%d\n"", key, (int) rv);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""RegQueryValueEx"", ""key"", ""%s"", ""%d\\n"", ""key"", ""int"", ""rv""]]",[150726254741681836],6388,894240.0,2
https://github.com/squid-cache/squid/commit/9c8434f6a8753d321762ff58685cb1ff0364b4a7,14 Sep 2006,"Windows port: split Windows service code into WinSvc.cc, allowing correct execution of make check",1963,data/crawl/squid/hunk_4750.cpp,,,data/crawl/squid/old_hunk_4750.cpp,data/crawl/squid/new_hunk_4750.cpp,-1,213,,"fprintf(stderr, ""RegOpenKeyEx HKLM\\%s, %d\n"", REGKEY, (int) rv);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""RegOpenKeyEx"", ""HKLM\\\\%s"", ""%d\\n"", ""REGKEY"", ""int"", ""rv""]]",[-8467889701044292624],6387,894240.0,2
https://github.com/squid-cache/squid/commit/9c8434f6a8753d321762ff58685cb1ff0364b4a7,14 Sep 2006,"Windows port: split Windows service code into WinSvc.cc, allowing correct execution of make check",1963,data/crawl/squid/hunk_4750.cpp,,,data/crawl/squid/old_hunk_4750.cpp,data/crawl/squid/new_hunk_4750.cpp,-1,206,,"fprintf(stderr, ""Registry does not contain key %s after creation\n"",
                    REGKEY);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""Registry"", ""does"", ""not"", ""contain"", ""key"", ""%s"", ""after"", ""creation\\n"", ""REGKEY""]]",[-20638689201541593864],6386,894240.0,2
https://github.com/squid-cache/squid/commit/9c8434f6a8753d321762ff58685cb1ff0364b4a7,14 Sep 2006,"Windows port: split Windows service code into WinSvc.cc, allowing correct execution of make check",1963,data/crawl/squid/hunk_4750.cpp,,,data/crawl/squid/old_hunk_4750.cpp,data/crawl/squid/new_hunk_4750.cpp,-1,139,,"fprintf(stderr, ""RegCreateKeyEx(%s),%d\n"", keys[index], (int) rv);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""RegCreateKeyEx"", ""%s"", ""%d\\n"", ""keys[index]"", ""int"", ""rv""]]",[-26557078750273797366],6385,894240.0,2
https://github.com/squid-cache/squid/commit/5f8252d203092b380f73e997be7097282c793077,06 Apr 2007,"	- ICAP-unrelated improvements from the squid3-icap branch on SF
	  (see further below for ICAP-specific improvements):

	- Replaced BodyReader with BodyPipe. BodyReader was a
	  collection of function pointers augmented with body size
	  calculation logic. BodyReader was used to deliver request
	  body (of a known size) from the client side to the server
	  side. Reference counting was used to communicate abort
	  conditions to the other side (it did not work well because
	  decreasing the reference count does not have any side-effects
	  if the count remains positive). Direct calls between sides
	  sometimes resulted in a call-me-when-I-am-calling-you ""loops""
	  and related bugs.

	  BodyPipe is used to deliver request or response body (possibly
	  of unknown size) from the body producer to the body consumer.
	  A producer can be the client side (for virgin requests), the
	  server side (for virgin replies), or the ICAP side (for
	  adapted messages). A consumer can be the client side (for
	  adapted responses, including responses in a request
	  satisfaction mode), the server side (for adapted requests),
	  and the ICAP side (for virgin requests and responses).

	  BodyPipe uses asynchronous calls for communication between
	  sides to avoid call-me-when-I-am-calling-you ""loops"".

	  BodyPipe has methods to communicate normal termination and
	  abort conditions to the other side. The use of those methods
	  is mandatory. Reference counting is used only as a garbage
	  collection mechanism.

	  BodyPipe is used to read request bodies, including requests
	  for which there is no consumer and the connection is in a
	  'closing' state. BodyPipe can auto-consume body so that a
	  'closing' connection does not have to rely on the body
	  consumer presence when eating up remaining body data.

	  If auto-consumption is turned on and the pipe starts
	  consuming before a real consumer is attached to the pipe, the
	  setConsumerIfNotLate call fails, and the real consumer has to
	  handle the failure.

	  The new BodyPipe approach should make support for HTTP/1.1
	  chunked requests easier. Only a few places in the pipe-related
	  code assume that the request size is known.

	- Removed ClientBody as unused, replaced by BodyReader, then
	  BodyPipe.

	- Moved HttpRequest::body_reader to HttpMsg::body_pipe so that
	  all HTTP message bodies can be communicated via pipes. This
	  is needed for the server side to supply response bodies to
	  ICAP and for the ICAP side to supply adapted message bodies
	  to others.

	- When cleaning HttpRequest or HttpReply, reset body_pipe to
	  NULL instead of asserting that it is already NULL. BodyPipes
	  are owned and maintained by other objects and HttpMsg is used
	  only as a mechanism to pass the pipe pointer from the body
	  producer to the consumer. To maintain guarantees similar to
	  the old code, the BodyPipe destructor asserts that both the
	  producer and the consumer are gone when the pipe is
	  destructed.

	- When appending body data, do not append more than the known
	  body size. This fixes the following assertion when POSTing
	  from IE in my tests: assertion failed: client_side.cc:3205:
	  ""bodySizeLeft() > 0"".

	  I suspect IE or some Javascripts running on IE were appending
	  extra CRLF to a POST, exposing the bug, and triggering the
	  above assertion.

	- WARNING: Ftp-specific BodyPipe changes are untested, but the
	  old code probably did not work well with ICAP either.  More
	  testing is needed.

	- Moved more common server-side code from http.* and ftp.* into
	  Server.*.  Most ICAP-related code is in the Server class now.

	  The code move to the Server class and migration to BodyPipe
	  exposed several FTP/HTTP inconsistencies and bugs. I marked
	  those I could not fix with XXXs.

	- Distinguish the end of communication with the origin server
	  from the end of communication with ICAP. Clean them up
	  separately when possible. Terminate when both are completed
	  (or aborted).

	- Polished persistentConnStatus() to avoid calling
	  statusIfComplete() until really necessary (and appropriate).
	  This makes debugging easier to understand for some.

	- Use auto-consumption feature to consume data from closing
	  connections for which there is no real body consumer.

	- Use BodyPipe for maintaining the ""closing"" state of a
	  connection instead of in.abortedSize. This change ""removes"" a
	  few memory leaks and an assertion, but does need more work,
	  especially when the regular BodyPipe consumer leaves early
	  and does not consume the request body.

	- The client stream code sometimes marks the ""closing""
	  connection as STREAM_UNPLANNED_COMPLETE, leading to a
	  double-close. I do not yet understand why. There is now code
	  to ignore multiple attempts to enter the ""closing"" state.



	- ICAP improvements from the squid3-icap branch on SF, including:

	- Added icap_service_failure_limit squid.conf option. The limit
	  specifies the number of failures that Squid tolerates when
	  establishing a new TCP connection with an ICAP service. If
	  the number of failures exceeds the limit, the ICAP service is
	  not used for new ICAP requests until it is time to refresh
	  its OPTIONS. The per-service failure counter is reset to zero
	  each time Squid fetches new service OPTIONS.

	  A negative value disables the limit.

	  The limit used to be hardcoded to 10.

	  (based on the patch by Axel Westerhold)

	- Added icap_service_revival_delay squid.conf option.  The
	  delay specifies the number of seconds to wait after an ICAP
	  OPTIONS request failure before requesting the options again.
	  The failed ICAP service is considered ""down"" until fresh
	  OPTIONS are fetched.

	  The actual delay cannot be smaller than the [still] hardcoded
	  minimum delay of 60 seconds.

	  (based on the patch by Axel Westerhold)

	- Added icap_client_username_header and
	  icap_client_username_encode squid.conf options to control how
	  the authenticated client username should be sent to the ICAP
	  service. (based on the patch by Axel Westerhold)

	- Handle REQMOD transaction failures where we cannot proceed
	  with the normal request flow.

	- Use ICAPInitiator API to send ""success"" or ""abort"" messages
	  to ICAP transaction initiator. Store virgin and adapted
	  metadata as public fields (if the newly added ICAPInOut type)
	  that the initiator can access when receiving our ""successful
	  adaptation"" message. This keeps messages simple.

	- Using ICAPInitiator API and a ""universal"" BodyPipe API makes
	  it possible to exchange bodies directly with client- or
	  server-side code without ICAPClient* translators, which are
	  now gone along with the ICAPInitXaction function in
	  ICAPClient.

	- Added ICAPInitiator interface that classes initiating ICAP
	  transactions must now support. The API currently has just two
	  methods: one for receiving adapted message headers
	  (indicating a successful ICAP transaction, at least to the
	  point of fetching adapted headers) and one for receiving a
	  notification of an aborted ICAP transaction.

	  Most ICAP initiators (or their close relatives) will also need
	  to implement BodyConsumer and/or BodyProducer APIs to exchange
	  virgin and/or adapted HTTP message bodies with the initiated
	  ICAP transaction. However, that activity is not addressed in
	  this API.  New AsyncCall API is used to declare the callback
	  wrappers.

	- Use BodyPipe instead of MsgPipe for receiving virgin and
	  sending adapted message bodies. BodyPipe is not much
	  different from MsgPipeBody, but it is better to use a
	  ""universal"" class that the rest of Squid code now uses.  One
	  complication is that BodyPipes are currently not created for
	  messages with zero-size bodies. The code had to be changed to
	  not assume that a zero-size body comes with a pipe.

	- Deleted MsgPipe and related classes. Message pipes had two
	  purposes: coordinate HTTP message adaptation (start, get the
	  adapted headers, abort) and exchange HTTP message bodies. The
	  latter is now done via BodyPipe API. The former can be
	  implemented directly in ICAPModXact.

	  Deleted ICAPClient* and related classes as (my) design
	  failure.

	  The original idea behind message pipes and ICAPClient* classes
	  was to isolate ICAP code from the Squid core. The core code
	  was supposed to use ICAPClient* classes for all ICAP-related
	  needs, and ICAPClient* classes were supposed to translate core
	  needs into ""ICAP needs"" and use message pipes to communicate
	  with asynchronously running ICAP transactions. The latter part
	  worked fine, but the former did not.

	  The core code still did a lot of ICAP-specific work on its
	  own. This could be because ICAP processing affects the flow so
	  much or because the core code had not been refactored enough
	  to minimize ICAP interactions.  Whatever the reason, we ended
	  up with a lot of complex code/logic coordinating the core code
	  and ICAPClient* classes. While ICAPClient* classes were
	  ""translating"", they could not hide the key actions or events
	  (such as message body exchange or transaction aborts) from the
	  core. The core code still had to support those actions or
	  handle those events.  Thus, every major action or event was
	  handled twice:  once in the core side code and once in a
	  ICAPClient* class.

	  Removing ICAPClient* ""translation"" step simplified the code
	  and possibly improved performance. As for the ""ICAP
	  separation"" goal, the current exposure to the ICAPModXact
	  class can be hidden by a generic ""Message Adaptation
	  Transaction"" class if we need to support more adaptation
	  protocols. The core code should not be affected much by such a
	  change.

	- ClientHttpRequest: Support the new ICAPInitiator API and talk
	  to ICAPModXact directly instead of using ICAPClient* classes,
	  which are now gone.

	- ConnStateData: Use BodyPipe for delivering virgin request
	  bodies to the server or ICAP side. Implement the BodyProducer
	  interface.  ClientHttpRequest: Use BodyPipe instead of
	  BodyReader when receiving request bodies (from client side or
	  ICAP).  Implement the BodyConsumer interface.  See the first
	  BodyPipe CVS log message for the rationale.

	- Use BodyPipe for delivering virgin reply bodies to ICAP and
	  receiving adapted reply bodies from ICAP. Implement the
	  BodyProducer interface.

	  Use BodyPipe instead of BodyReader when receiving request
	  bodies (from client side or ICAP).  Implement the BodyConsumer
	  interface.

	- Replaced never-failing doIcap() with startIcap() that fails
	  if we cannot select an ICAP service or the selected service
	  is not usable. Rearranged
	  ClientRequestContext::icapAclCheckDone() to bypass ICAP
	  errors when possible.  Now, ClientRequestContext::startIcap()
	  is very similar to Server::startIcap(). Same for
	  icapAclCheckDone().  Made
	  ClientHttpRequest::handleIcapFailure() public because
	  ClientRequestContext::icapAclCheckDone() calls it.

	- Polished TTL handling to make sure we use the default TTL
	  when the ICAP server did not provide an explicit value or if
	  we failed to communicate with the server. The latter case may
	  not have been handled correctly before.

	- The minimum options update gap (currently hard-coded) must be
	  smaller than the default options TTL. Otherwise, we get stale
	  options and down ICAP services around the update time because
	  we cannot update soon enough.

	- Support asynchronous transaction start. This allows for a
	  better handling of startup errors (or at least makes them
	  similar to other transaction errors).

	- Call a swanSong() method upon expected transaction
	  termination (including aborts). This allows for proper and
	  prompt [partial] transaction cleanup, without waiting for the
	  destructor to be called. The destruction may be delayed by
	  refcounting if we have other transaction users waiting for
	  some transaction notifications.

	- Do not reuse a connection if we are still reading or writing
	  (even if no actual I/O is scheduled). The old code would
	  reuse such connections, and read/write leftovers from aborted
	  transactions from/to the ICAP server.

	- Do not send last-chunk in ICAP Preview with a null-body. It is
	  possible that the old code would send the last-chunk under
	  some Preview conditions with null-body, but I am not sure.

	- Fixed HttpStateData memory leak visible when no RESPMOD
	  services are enabled.  ICAPAccessCheck constructor was
	  cbdata-locking HttpStateData, but was not releasing the lock
	  when there was no matching service class, leading to an
	  HttpStateData leak. Furthermore, ICAPAccessCheck would then
	  call HttpStateData back without validating the cbdata
	  pointer, probably calling wrong or invalid HttpStateData.

	- Fixed ""is it too late to bypass?"" conditions in
	  ClientHttpRequest::handleIcapFailure(). We should be able to
	  bypass more often now. However, handleIcapFailure() still has
	  the old bug: it does not check whether the service is
	  optional. The current fix implies that now Squid may bypass
	  essential services more often.

	- Call storeEntry()->complete() when ending request
	  satisfaction. Without this call, we may keep the connection
	  open, which does not work with responses that mark the end of
	  their body by closing a connection. (Christos Tsantilas)

	- Fixed ieof condition detection. Squid was sending last-chunk
	  without ieof bit and was sending two last chunks when doing
	  preview (Tsantilas Christos).

	- When ICAP server wants the entire virgin body and sends 100
	  Continue after Preview, do not stop backing up virgin body
	  data for echoing if we promised to support 204 No Content
	  responses outside of Preview. If we allow 204s, 100 Continue
	  may be followed by a 204 No Content and we will need the
	  entire virgin body to echo back.

	- Rewrote MemBufClaim into a VirginBodyAct class to simplify
	  and clarify code in hope to minimize the number of bugs like
	  the one mentioned above. MemBufClaim was protecting an area
	  of virgin body pipe content and, as a side effect, was
	  providing the transaction with the content pointer for the
	  write or send actions.

	  Now VirginBodyAct just maintains the activity offset and the
	  transaction code uses that to consume virgin body correctly.
	  The size of the area is no longer maintained because it was
	  usually unknown or unused; and when it was known and used
	  (i.e., Preview), it could be taken from the preview state
	  object anyway.  Renamed and documented VirginBodyAct-related
	  methods to clarify the intent.

	- When sending last-chunk in Preview, send ieof extension if we
	  wrote the entire body. The old code would not send ieof if we
	  wrote as many bytes as promised in the Preview header, even
	  if we promised to write everything.  This would mislead
	  compliant ICAP servers that do not look at the Content-Length
	  header and reply with 100 Continue, expecting more body data.

	- Do not reset Preview size to zero when expecting a virgin
	  body of unknown size. A Squid user reported that this change
	  works.

	- Polished debugging: Instead of using pointers, use unique ICAP
	  transaction IDs.  This helps with isolating a transaction in a
	  large log, where pointers may be reused many times. Print
	  connection descriptor like most of the core code does. Other
	  minor improvements.",4655,data/crawl/squid/hunk_4677.cpp,,,data/crawl/squid/old_hunk_4677.cpp,data/crawl/squid/new_hunk_4677.cpp,8,-1,stopReceiving();,,"[""removeLog""]","[[""stopReceiving""], []]",[7301041899547781865],6384,0.0,2
https://github.com/squid-cache/squid/commit/ad80164a7909ff0d00b33664f0a3b58343099cc0,18 May 2007,SqString core apparently not automatically added to cvs by patch.,712,data/crawl/squid/hunk_4591.cpp,,,data/crawl/squid/old_hunk_4591.cpp,data/crawl/squid/new_hunk_4591.cpp,-1,290,,"storeAppendPrintf(entry, ""%lu entries, %lu reported from MemPool\n"", (unsigned long) Instance().entries.elements, (unsigned long) memStringCount());","[""addLog""]","[[], [""storeAppendPrintf"", ""entry"", ""%lu"", ""entries"", ""%lu"", ""reported"", ""from"", ""MemPool\\n"", ""unsigned"", ""long"", ""Instance"", ""entries"", ""elements"", ""unsigned"", ""long"", ""memStringCount""]]",[-2217334323894795720],6383,1104480.0,2
https://github.com/squid-cache/squid/commit/89f77e43f36bdbd636826c94085f9b5d882e473d,24 Jun 2007,"Bug #1948: digest_edir_auth helper, using novell eDirectory universal password

This is a modified version of digets_ldap_auth, with eDirectory special hooks
for retrieving the Universal Password plain text password.",1874,data/crawl/squid/hunk_4544.cpp,,,data/crawl/squid/old_hunk_4544.cpp,data/crawl/squid/new_hunk_4544.cpp,-1,65,,"printf(""ERR No such user\n"");","[""addLog""]","[[], [""printf"", ""ERR"", ""No"", ""such"", ""user\\n""]]",[11392756792819906018],6382,390240.0,2
https://github.com/squid-cache/squid/commit/3e5d7cdf22bea10b5f35fd5881ed2d1724ba88b2,25 Jun 2007,"Author: Markus Moeller <huaraz@moeller.plus.com>
Kerberos SPNEGO helper

Kerberos-only SPNEGO helper using MIT or Heimdal kerberos
and the refrence SPNEGO parser published by Microsoft",6172,data/crawl/squid/hunk_4543.cpp,,,data/crawl/squid/old_hunk_4543.cpp,data/crawl/squid/new_hunk_4543.cpp,-1,462,,"fprintf(stderr, ""%s| %s: User %s authenticated\n"", LogTime(), PROGRAM, (char *)output_token.value);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""%s"", ""%s"", ""User"", ""%s"", ""authenticated\\n"", ""LogTime"", ""PROGRAM"", ""char"", ""*"", ""output_token"", ""value""]]",[-6941698923594257972],6381,0.0,2
https://github.com/squid-cache/squid/commit/3e5d7cdf22bea10b5f35fd5881ed2d1724ba88b2,25 Jun 2007,"Author: Markus Moeller <huaraz@moeller.plus.com>
Kerberos SPNEGO helper

Kerberos-only SPNEGO helper using MIT or Heimdal kerberos
and the refrence SPNEGO parser published by Microsoft",6172,data/crawl/squid/hunk_4543.cpp,,,data/crawl/squid/old_hunk_4543.cpp,data/crawl/squid/new_hunk_4543.cpp,-1,358,,"fprintf(stdout, ""NA received type %d NTLM token\n"",(int) *((unsigned char *)input_token.value + sizeof ntlmProtocol));","[""addLog""]","[[], [""fprintf"", ""stdout"", ""NA"", ""received"", ""type"", ""%d"", ""NTLM"", ""token\\n"", ""int"", ""*"", ""unsigned"", ""char"", ""*"", ""input_token"", ""value"", ""sizeof"", ""ntlmProtocol""]]",[-33578579756254989034],6380,0.0,2
https://github.com/squid-cache/squid/commit/63a05fa3d20a15ec5f91d8b127f25136982fa2c7,04 Jul 2007,"Bug #2008: Work around clients trying to use NTLM or Negotiate without persistent connections

This patch forces a fallback on Basic/Digest if the client attempts
to use NTLM or Negotiate without having a persistent connection.",15,data/crawl/squid/hunk_4534.cpp,,,data/crawl/squid/old_hunk_4534.cpp,data/crawl/squid/new_hunk_4534.cpp,3,3,"auth_user_request->denyMessage(""Authenication in progress"");","auth_user_request->denyMessage(""Authentication in progress"");","[""updateContent""]","[[""Authenication""], [""Authentication""]]",[-5763591340059079501],6379,441360.0,2
https://github.com/squid-cache/squid/commit/47f6e231eb0dcf02f69a97a3adebc10ae744fefb,13 Aug 2007,"Author: wessels & Christos Tsantilas
Import squid3-largeobj branch, fixing proxying and caching of >2GB objects

this patch converts all variables referring to object sizes & offsets to
64-bits, and gets rid of a lot of related casts.

The cache format is also updated to use 64-bit offsets, using a format
compatible with Squid-2.6.",1589,data/crawl/squid/hunk_4494.cpp,,,data/crawl/squid/old_hunk_4494.cpp,data/crawl/squid/new_hunk_4494.cpp,3,3,"mb->Printf(""\tinmem_lo: %d\n"", (int) inmem_lo);","mb->Printf(""\tinmem_lo: %""PRId64""\n"", inmem_lo);","[""removeVariable"", ""updateContent"", ""addContent"", ""addVariable""]","[[""%d\\n"", ""int""], [""%"", ""PRId64"", ""\\n""]]",[8659607761916738540],6378,0.0,2
https://github.com/squid-cache/squid/commit/47f6e231eb0dcf02f69a97a3adebc10ae744fefb,13 Aug 2007,"Author: wessels & Christos Tsantilas
Import squid3-largeobj branch, fixing proxying and caching of >2GB objects

this patch converts all variables referring to object sizes & offsets to
64-bits, and gets rid of a lot of related casts.

The cache format is also updated to use 64-bit offsets, using a format
compatible with Squid-2.6.",1589,data/crawl/squid/hunk_4491.cpp,,,data/crawl/squid/old_hunk_4491.cpp,data/crawl/squid/new_hunk_4491.cpp,5,5,"buf.Printf(""<=%d"", (int)theBodySize);","buf.Printf(""<=%""PRId64, theBodySize);","[""removeVariable"", ""addVariable""]","[[""%d"", ""int""], [""%"", ""PRId64""]]",[14788043902068298888],6377,0.0,2
https://github.com/squid-cache/squid/commit/ee1394034ae6d0c148944ba013ce2d485b2ea57b,17 Aug 2007,"64-bit disk I/O, using off_t / size_t where appropriate",98,data/crawl/squid/hunk_4486.cpp,,,data/crawl/squid/old_hunk_4486.cpp,data/crawl/squid/new_hunk_4486.cpp,3,3,"fprintf(stderr, ""seeking to %d\n"", r->offset);","fprintf(stderr, ""seeking to %""PRId64""\n"", (int64_t)r->offset);","[""updateContent"", ""addContent"", ""addVariable""]","[[""%d\\n""], [""%"", ""PRId64"", ""\\n"", ""int64_t""]]",[7089029205356821259],6376,0.0,2
https://github.com/squid-cache/squid/commit/077fe5816c428aa8aae518ac560c10c1a5e1c030,21 Sep 2007,"Misc Formatting & cleanups
Some comment corrections
Some irrelevant typedef cleanups",111,data/crawl/squid/hunk_4457.cpp,,,data/crawl/squid/old_hunk_4457.cpp,data/crawl/squid/new_hunk_4457.cpp,3,3,"storeAppendPrintf(e, ""%2s\t %-20s\t %5s\t %6s\t %6s\n"",
                      ""id"", ""name"", ""#alive"", ""%err"", ""%repeat"");","storeAppendPrintf(e, ""%2s\t %-25s\t %5s\t %6s\t %6s\n"",
                      ""id"", ""name"", ""#alive"", ""%err"", ""%repeat"");","[""updateContent""]","[[""20s\\t""], [""25s\\t""]]",[-2999864999004998501],6375,0.0,2
https://github.com/squid-cache/squid/commit/41d93087a0a99fa4a4c34eba4cf25606229567ff,14 Dec 2007,"Import IPAddress class and unit-tests from squid3-ipv6 branch

This class forms the basis of the IPv6 capable code for squid",2385,data/crawl/squid/hunk_4444.cpp,,,data/crawl/squid/old_hunk_4444.cpp,data/crawl/squid/new_hunk_4444.cpp,-1,584,,"printf(""\nADDRINFO: %x %x %x %x %x %x "",
		  p[0],p[1],p[2],p[3],p[4],p[5] );","[""addLog""]","[[], [""printf"", ""\\nADDRINFO"", ""%x"", ""%x"", ""%x"", ""%x"", ""%x"", ""%x"", ""p[0]"", ""p[1]"", ""p[2]"", ""p[3]"", ""p[4]"", ""p[5]""]]",[34944910071963810791],6374,0.0,2
https://github.com/squid-cache/squid/commit/0710cbcd89ad70d205b1aa53384976830d8dc471,14 Dec 2007,"Import RFC 3596 library extenstions from squid3-ipv6 branch.

This library extends the rfc1035 DNS resolver built into squid to handle
RFC 3596 IPv6 extensions for DNS. Namely the AAAA and PTR records.",466,data/crawl/squid/hunk_4442.cpp,,,data/crawl/squid/old_hunk_4442.cpp,data/crawl/squid/new_hunk_4442.cpp,-1,363,,"fprintf(stderr, ""can't print answer type %d\n"",
                                (int) answers[i].type);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""can"", ""t"", ""print"", ""answer"", ""type"", ""%d\\n"", ""int"", ""answers[i]"", ""type""]]",[-20887627230986489171],6373,2276640.0,2
https://github.com/squid-cache/squid/commit/0710cbcd89ad70d205b1aa53384976830d8dc471,14 Dec 2007,"Import RFC 3596 library extenstions from squid3-ipv6 branch.

This library extends the rfc1035 DNS resolver built into squid to handle
RFC 3596 IPv6 extensions for DNS. Namely the AAAA and PTR records.",466,data/crawl/squid/hunk_4442.cpp,,,data/crawl/squid/old_hunk_4442.cpp,data/crawl/squid/new_hunk_4442.cpp,-1,341,,"printf(""%d answers\n"", n);","[""addLog""]","[[], [""printf"", ""%d"", ""answers\\n"", ""n""]]",[15407037849866405185],6372,2276640.0,2
https://github.com/squid-cache/squid/commit/0710cbcd89ad70d205b1aa53384976830d8dc471,14 Dec 2007,"Import RFC 3596 library extenstions from squid3-ipv6 branch.

This library extends the rfc1035 DNS resolver built into squid to handle
RFC 3596 IPv6 extensions for DNS. Namely the AAAA and PTR records.",466,data/crawl/squid/hunk_4442.cpp,,,data/crawl/squid/old_hunk_4442.cpp,data/crawl/squid/new_hunk_4442.cpp,-1,338,,"printf(""ERROR, ID mismatch (%#hx, %#hx)\n"", sid, rid);","[""addLog""]","[[], [""printf"", ""ERROR"", ""ID"", ""mismatch"", ""%"", ""hx"", ""%"", ""hx"", ""\\n"", ""sid"", ""rid""]]",[14896558406565691660],6371,2279520.0,2
https://github.com/squid-cache/squid/commit/0710cbcd89ad70d205b1aa53384976830d8dc471,14 Dec 2007,"Import RFC 3596 library extenstions from squid3-ipv6 branch.

This library extends the rfc1035 DNS resolver built into squid to handle
RFC 3596 IPv6 extensions for DNS. Namely the AAAA and PTR records.",466,data/crawl/squid/hunk_4442.cpp,,,data/crawl/squid/old_hunk_4442.cpp,data/crawl/squid/new_hunk_4442.cpp,-1,336,,"printf(""ERROR %d\n"", rfc1035_errno);","[""addLog""]","[[], [""printf"", ""ERROR"", ""%d\\n"", ""rfc1035_errno""]]",[13093585953920806563],6370,2279520.0,2
https://github.com/squid-cache/squid/commit/0710cbcd89ad70d205b1aa53384976830d8dc471,14 Dec 2007,"Import RFC 3596 library extenstions from squid3-ipv6 branch.

This library extends the rfc1035 DNS resolver built into squid to handle
RFC 3596 IPv6 extensions for DNS. Namely the AAAA and PTR records.",466,data/crawl/squid/hunk_4442.cpp,,,data/crawl/squid/old_hunk_4442.cpp,data/crawl/squid/new_hunk_4442.cpp,-1,319,,"printf(""TIMEOUT\n"");","[""addLog""]","[[], [""printf"", ""TIMEOUT\\n""]]",[15516084845984908385],6369,2279520.0,2
https://github.com/squid-cache/squid/commit/0710cbcd89ad70d205b1aa53384976830d8dc471,14 Dec 2007,"Import RFC 3596 library extenstions from squid3-ipv6 branch.

This library extends the rfc1035 DNS resolver built into squid to handle
RFC 3596 IPv6 extensions for DNS. Namely the AAAA and PTR records.",466,data/crawl/squid/hunk_4442.cpp,,,data/crawl/squid/old_hunk_4442.cpp,data/crawl/squid/new_hunk_4442.cpp,-1,229,,"fprintf(stderr, ""usage: %s [-6|-4] ip port\n"", argv[0]);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""usage"", ""%s"", ""["", ""6"", ""4]"", ""ip"", ""port\\n"", ""argv[0]""]]",[-13074344889207801967],6368,0.0,2
https://github.com/squid-cache/squid/commit/cc192b5087ebbd5c214fcacdf26f117e4f15241b,15 Dec 2007,"Import IPv6 support from squid3-ipv6 branch to 3-HEAD.

This patch fully enables squid to handle IPv6 on internally supported
protocols which have IPv6 capability.
see 3.1 Release Notes for full details on the IPv6 changes.
also see squid.conf generated from this point for configuration changes.

TODO: Release-Notes fro 3.1 have yet to be created. The mentioned details
      documentation will come in a later patch.",9997,data/crawl/squid/hunk_4435.cpp,,,data/crawl/squid/old_hunk_4435.cpp,data/crawl/squid/new_hunk_4435.cpp,2,2,"storeAppendPrintf(s, ""\tpeer: %s:%d\n"",
                              inet_ntoa(conn->peer.sin_addr),
                              ntohs(conn->peer.sin_port));","storeAppendPrintf(s, ""\tpeer: %s:%d\n"",
                              conn->peer.NtoA(buf,MAX_IPSTRLEN),
                              conn->peer.GetPort());","[""updateVariable"", ""moveVariable"", ""removeVariable"", ""addVariable""]","[[""inet_ntoa"", ""sin_addr"", ""ntohs"", ""sin_port""], [""NtoA"", ""buf"", ""MAX_IPSTRLEN"", ""GetPort""]]",[-14131268765468484045],6367,0.0,2
https://github.com/squid-cache/squid/commit/cc192b5087ebbd5c214fcacdf26f117e4f15241b,15 Dec 2007,"Import IPv6 support from squid3-ipv6 branch to 3-HEAD.

This patch fully enables squid to handle IPv6 on internally supported
protocols which have IPv6 capability.
see 3.1 Release Notes for full details on the IPv6 changes.
also see squid.conf generated from this point for configuration changes.

TODO: Release-Notes fro 3.1 have yet to be created. The mentioned details
      documentation will come in a later patch.",9997,data/crawl/squid/hunk_4418.cpp,,,data/crawl/squid/old_hunk_4418.cpp,data/crawl/squid/new_hunk_4418.cpp,-1,228,,"fprintf(stderr, ""Too many -s options, only %d are allowed\n"", MAXNS);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""Too"", ""many"", ""s"", ""options"", ""only"", ""%d"", ""are"", ""allowed\\n"", ""MAXNS""]]",[-11357842607344951248],6366,2383920.0,2
https://github.com/squid-cache/squid/commit/cc192b5087ebbd5c214fcacdf26f117e4f15241b,15 Dec 2007,"Import IPv6 support from squid3-ipv6 branch to 3-HEAD.

This patch fully enables squid to handle IPv6 on internally supported
protocols which have IPv6 capability.
see 3.1 Release Notes for full details on the IPv6 changes.
also see squid.conf generated from this point for configuration changes.

TODO: Release-Notes fro 3.1 have yet to be created. The mentioned details
      documentation will come in a later patch.",9997,data/crawl/squid/hunk_4412.cpp,,,data/crawl/squid/old_hunk_4412.cpp,data/crawl/squid/new_hunk_4412.cpp,6,6,"storeAppendPrintf(entry, ""%s %s\n"", name, inet_ntoa(addr));","storeAppendPrintf(entry, ""%s %s\n"", name, addr.NtoA(buf,MAX_IPSTRLEN) );","[""updateVariable"", ""removeVariable"", ""addVariable""]","[[""inet_ntoa""], [""NtoA"", ""buf"", ""MAX_IPSTRLEN""]]",[-12710812813841780372],6365,0.0,2
https://github.com/squid-cache/squid/commit/cc192b5087ebbd5c214fcacdf26f117e4f15241b,15 Dec 2007,"Import IPv6 support from squid3-ipv6 branch to 3-HEAD.

This patch fully enables squid to handle IPv6 on internally supported
protocols which have IPv6 capability.
see 3.1 Release Notes for full details on the IPv6 changes.
also see squid.conf generated from this point for configuration changes.

TODO: Release-Notes fro 3.1 have yet to be created. The mentioned details
      documentation will come in a later patch.",9997,data/crawl/squid/hunk_4405.cpp,,,data/crawl/squid/old_hunk_4405.cpp,data/crawl/squid/new_hunk_4405.cpp,5,5,"fprintf(stderr, ""%s| %s: error while resolving hostname with getaddrinfo: %s\n"", LogTime(), PROGRAM, gai_strerror(rc));","fprintf(stderr, ""%s| %s: error while resolving hostname with getaddrinfo: %s\n"", LogTime(), PROGRAM, xgai_strerror(rc));","[""updateVariable""]","[[""gai_strerror""], [""xgai_strerror""]]",[2238227337298578263],6364,0.0,2
https://github.com/squid-cache/squid/commit/bebc043b8df7953e06b2a66ad7b88b362fbc59b5,27 Dec 2007,"Remove the default cache_dir location and the null store type

Many people gets confused by the builtin cache_dir location, thinking
that if there is no cache_dir in squid.conf then there is no on-disk cache.
This removes the builtin default.

By removing the builtin default we can also remove the ""null"" cache_dir
type whos purpose is only to override the builtin default.",410,data/crawl/squid/hunk_4398.cpp,,,data/crawl/squid/old_hunk_4398.cpp,data/crawl/squid/new_hunk_4398.cpp,69,-1,"fatal (""Attempt to get a StoreIO from the NULL store!\n"");",,"[""removeLog""]","[[""fatal"", ""Attempt"", ""to"", ""get"", ""a"", ""StoreIO"", ""from"", ""the"", ""NULL"", ""store"", ""\\n""], []]",[5257834271153246970],6363,0.0,2
https://github.com/squid-cache/squid/commit/bebc043b8df7953e06b2a66ad7b88b362fbc59b5,27 Dec 2007,"Remove the default cache_dir location and the null store type

Many people gets confused by the builtin cache_dir location, thinking
that if there is no cache_dir in squid.conf then there is no on-disk cache.
This removes the builtin default.

By removing the builtin default we can also remove the ""null"" cache_dir
type whos purpose is only to override the builtin default.",410,data/crawl/squid/hunk_4397.cpp,,,data/crawl/squid/old_hunk_4397.cpp,data/crawl/squid/new_hunk_4397.cpp,4,-1,"fatal(""No cache_dir's specified in config file"");",,"[""removeLog""]","[[""fatal"", ""No"", ""cache_dir"", ""s"", ""specified"", ""in"", ""config"", ""file""], []]",[5002055989006717529],6362,2718720.0,2
https://github.com/squid-cache/squid/commit/154dc8842fca8ee7a35553a44c2fe82fecb3786c,12 Feb 2008,"Importing SslBump feature from Squid3 ssl-bump branch:

        Parse/dump the newly added sslBump http_port option. The option
        does not imply an accelerated port because it only accelerates
        after intercepting a CONNECT request.

        Configure SSL Context if SSL certificate or key are specified
        for an HTTP port.",236,data/crawl/squid/hunk_4379.cpp,,,data/crawl/squid/old_hunk_4379.cpp,data/crawl/squid/new_hunk_4379.cpp,-1,36,,"storeAppendPrintf(e, "" sslcontext=%s"", s->sslcontext);","[""addLog""]","[[], [""storeAppendPrintf"", ""e"", ""sslcontext"", ""%s"", ""s"", ""sslcontext""]]",[4512707690062211733],6361,763920.0,2
https://github.com/squid-cache/squid/commit/154dc8842fca8ee7a35553a44c2fe82fecb3786c,12 Feb 2008,"Importing SslBump feature from Squid3 ssl-bump branch:

        Parse/dump the newly added sslBump http_port option. The option
        does not imply an accelerated port because it only accelerates
        after intercepting a CONNECT request.

        Configure SSL Context if SSL certificate or key are specified
        for an HTTP port.",236,data/crawl/squid/hunk_4379.cpp,,,data/crawl/squid/old_hunk_4379.cpp,data/crawl/squid/new_hunk_4379.cpp,-1,33,,"storeAppendPrintf(e, "" sslflags=%s"", s->sslflags);","[""addLog""]","[[], [""storeAppendPrintf"", ""e"", ""sslflags"", ""%s"", ""s"", ""sslflags""]]",[14925440976705579641],6360,1362960.0,2
https://github.com/squid-cache/squid/commit/154dc8842fca8ee7a35553a44c2fe82fecb3786c,12 Feb 2008,"Importing SslBump feature from Squid3 ssl-bump branch:

        Parse/dump the newly added sslBump http_port option. The option
        does not imply an accelerated port because it only accelerates
        after intercepting a CONNECT request.

        Configure SSL Context if SSL certificate or key are specified
        for an HTTP port.",236,data/crawl/squid/hunk_4379.cpp,,,data/crawl/squid/old_hunk_4379.cpp,data/crawl/squid/new_hunk_4379.cpp,-1,30,,"storeAppendPrintf(e, "" dhparams=%s"", s->dhfile);","[""addLog""]","[[], [""storeAppendPrintf"", ""e"", ""dhparams"", ""%s"", ""s"", ""dhfile""]]",[7434341468065256817],6359,1268640.0,2
https://github.com/squid-cache/squid/commit/154dc8842fca8ee7a35553a44c2fe82fecb3786c,12 Feb 2008,"Importing SslBump feature from Squid3 ssl-bump branch:

        Parse/dump the newly added sslBump http_port option. The option
        does not imply an accelerated port because it only accelerates
        after intercepting a CONNECT request.

        Configure SSL Context if SSL certificate or key are specified
        for an HTTP port.",236,data/crawl/squid/hunk_4379.cpp,,,data/crawl/squid/old_hunk_4379.cpp,data/crawl/squid/new_hunk_4379.cpp,-1,27,,"storeAppendPrintf(e, "" crlfile=%s"", s->crlfile);","[""addLog""]","[[], [""storeAppendPrintf"", ""e"", ""crlfile"", ""%s"", ""s"", ""crlfile""]]",[22939110181803402459],6358,763200.0,2
https://github.com/squid-cache/squid/commit/154dc8842fca8ee7a35553a44c2fe82fecb3786c,12 Feb 2008,"Importing SslBump feature from Squid3 ssl-bump branch:

        Parse/dump the newly added sslBump http_port option. The option
        does not imply an accelerated port because it only accelerates
        after intercepting a CONNECT request.

        Configure SSL Context if SSL certificate or key are specified
        for an HTTP port.",236,data/crawl/squid/hunk_4379.cpp,,,data/crawl/squid/old_hunk_4379.cpp,data/crawl/squid/new_hunk_4379.cpp,-1,24,,"storeAppendPrintf(e, "" capath=%s"", s->capath);","[""addLog""]","[[], [""storeAppendPrintf"", ""e"", ""capath"", ""%s"", ""s"", ""capath""]]",[11859293668491330937],6357,1362960.0,2
https://github.com/squid-cache/squid/commit/154dc8842fca8ee7a35553a44c2fe82fecb3786c,12 Feb 2008,"Importing SslBump feature from Squid3 ssl-bump branch:

        Parse/dump the newly added sslBump http_port option. The option
        does not imply an accelerated port because it only accelerates
        after intercepting a CONNECT request.

        Configure SSL Context if SSL certificate or key are specified
        for an HTTP port.",236,data/crawl/squid/hunk_4379.cpp,,,data/crawl/squid/old_hunk_4379.cpp,data/crawl/squid/new_hunk_4379.cpp,-1,21,,"storeAppendPrintf(e, "" cafile=%s"", s->cafile);","[""addLog""]","[[], [""storeAppendPrintf"", ""e"", ""cafile"", ""%s"", ""s"", ""cafile""]]",[18965929520452225931],6356,1362960.0,2
https://github.com/squid-cache/squid/commit/154dc8842fca8ee7a35553a44c2fe82fecb3786c,12 Feb 2008,"Importing SslBump feature from Squid3 ssl-bump branch:

        Parse/dump the newly added sslBump http_port option. The option
        does not imply an accelerated port because it only accelerates
        after intercepting a CONNECT request.

        Configure SSL Context if SSL certificate or key are specified
        for an HTTP port.",236,data/crawl/squid/hunk_4379.cpp,,,data/crawl/squid/old_hunk_4379.cpp,data/crawl/squid/new_hunk_4379.cpp,-1,18,,"storeAppendPrintf(e, "" cipher=%s"", s->cipher);","[""addLog""]","[[], [""storeAppendPrintf"", ""e"", ""cipher"", ""%s"", ""s"", ""cipher""]]",[-627383025728602375],6355,1660320.0,2
https://github.com/squid-cache/squid/commit/154dc8842fca8ee7a35553a44c2fe82fecb3786c,12 Feb 2008,"Importing SslBump feature from Squid3 ssl-bump branch:

        Parse/dump the newly added sslBump http_port option. The option
        does not imply an accelerated port because it only accelerates
        after intercepting a CONNECT request.

        Configure SSL Context if SSL certificate or key are specified
        for an HTTP port.",236,data/crawl/squid/hunk_4379.cpp,,,data/crawl/squid/old_hunk_4379.cpp,data/crawl/squid/new_hunk_4379.cpp,-1,15,,"storeAppendPrintf(e, "" options=%s"", s->options);","[""addLog""]","[[], [""storeAppendPrintf"", ""e"", ""options"", ""%s"", ""s"", ""options""]]",[7893954684300028237],6354,1660320.0,2
https://github.com/squid-cache/squid/commit/154dc8842fca8ee7a35553a44c2fe82fecb3786c,12 Feb 2008,"Importing SslBump feature from Squid3 ssl-bump branch:

        Parse/dump the newly added sslBump http_port option. The option
        does not imply an accelerated port because it only accelerates
        after intercepting a CONNECT request.

        Configure SSL Context if SSL certificate or key are specified
        for an HTTP port.",236,data/crawl/squid/hunk_4379.cpp,,,data/crawl/squid/old_hunk_4379.cpp,data/crawl/squid/new_hunk_4379.cpp,-1,12,,"storeAppendPrintf(e, "" version=%d"", s->version);","[""addLog""]","[[], [""storeAppendPrintf"", ""e"", ""version"", ""%d"", ""s"", ""version""]]",[9558444992649947300],6353,1660320.0,2
https://github.com/squid-cache/squid/commit/154dc8842fca8ee7a35553a44c2fe82fecb3786c,12 Feb 2008,"Importing SslBump feature from Squid3 ssl-bump branch:

        Parse/dump the newly added sslBump http_port option. The option
        does not imply an accelerated port because it only accelerates
        after intercepting a CONNECT request.

        Configure SSL Context if SSL certificate or key are specified
        for an HTTP port.",236,data/crawl/squid/hunk_4379.cpp,,,data/crawl/squid/old_hunk_4379.cpp,data/crawl/squid/new_hunk_4379.cpp,-1,6,,"storeAppendPrintf(e, "" cert=%s"", s->cert);","[""addLog""]","[[], [""storeAppendPrintf"", ""e"", ""cert"", ""%s"", ""s"", ""cert""]]",[16132876345930463543],6352,1362960.0,2
https://github.com/squid-cache/squid/commit/3e7b6055489b13ca3faa9eef01b42a74971f84e4,20 Mar 2008,"Importing CVS squid3-ecap branch:

lib/Makefile.am
        Added libLtdl to SUBDIRS if USE_LOADABLE_MODULES.


src/ICAP/ICAPModXact.h
src/ICAP/ICAPServiceRep.h

        When USE_ECAP_AS_ICAP_HACK macro is defined, enable a temporary
        hack that uses ICAP class names to implement some of the eCAP
        classes. This is necessary to hide eCAP/ICAP distinction from
        Squid core. Hiding the distinction is necessary to avoid
        numerous conflicts when this branch is merged with async call
        branch changes.
        
        Once the branches are merged, the hack will be removed. Since
        we currently #define eCAP class names to match those of ICAP
        classes, the changes at that time should not be significant:
        remove renaming #defines and adjust autotools meta files to
        allow both ICAP and eCAP co-exist.



configure.in
src/Makefile.am

        Enable eCAP support if loadable module support is enabled.
        Eventually, we may want to control eCAP support directly.
        
        Added eCAP directory to the Makefile. The eCAP directory
        contents will be committed later.



SPONSORS
        Added eCAP sponsor.


src/Makefile.am
        When eCAP is enabled, to support USE_ECAP_AS_ICAP_HACK, ignore
        ICAP files that eCAP overwrites.


configure.in

        Added --enable-ecap option to control eCAP support explicitly.
        Added consistency checks for the combination of --enable-ecap,
        --enable-icap-client, and --disable-loadable-modules options.
        
        Define USE_ECAP_AS_ICAP_HACK macro to enable a temporary hack
        that uses ICAP class names to implement some of the eCAP
        classes. This is necessary to hide eCAP/ICAP distinction from
        Squid core. Hiding the distinction is necessary to avoid
        numerous conflicts when this branch is merged with async call
        branch changes.
        
        Once the branches are merged, the hack will be removed. Since
        we currently #define eCAP class names to match those of ICAP
        classes, the changes at that time should not be significant:
        remove renaming #defines and adjust autotools meta files to
        allow both ICAP and eCAP co-exist.



Makefile.am
acinclude.m4
bootstrap.sh
configure.in
src/Makefile.am

        Added basic support for Libtool ltdl. Libltdl directory is not
        committed yet because I want to investigate whether it can be
        moved from root to lib/. Bootstrap.sh currently strips a large
        copying file from that directory but does not attempt to move
        the directory itself.
        
        The configure options will need to be changed according to
        squid-dev discussion: we should assume that ltdl is always used
        if modules are used, and we should have a --disable-modules
        option.
        
        The code works with a dummy module: Squid was able to load and
        unload using LoadableModule, an ltdl wrapper class from Spicer.
        I have not committed that wrapper yet.

Makefile.am
bootstrap.sh
configure.in
src/Makefile.am

        Moved Libtool libltdl directory to lib/libLtdl to keep all
        3rd-party libs in one place. Will commit the lib/libLtdl
        directory itself soon.
        
        Bootstrap.sh currently moves all files from the generated
        libltdl into lib/libLtdl. A better approach may be to use the
        --ltdl option of libtoolize. Will investigate.
        
        Changed configure options to assume that ltdl is always used if
        modules are used.",48970,data/crawl/squid/hunk_4348.cpp,,,data/crawl/squid/old_hunk_4348.cpp,data/crawl/squid/new_hunk_4348.cpp,-1,156,,"suspend(""too many failures"");","[""addLog""]","[[], [""suspend"", ""too"", ""many"", ""failures""]]",[-4129503642083642598],6351,363600.0,2
https://github.com/squid-cache/squid/commit/3e7b6055489b13ca3faa9eef01b42a74971f84e4,20 Mar 2008,"Importing CVS squid3-ecap branch:

lib/Makefile.am
        Added libLtdl to SUBDIRS if USE_LOADABLE_MODULES.


src/ICAP/ICAPModXact.h
src/ICAP/ICAPServiceRep.h

        When USE_ECAP_AS_ICAP_HACK macro is defined, enable a temporary
        hack that uses ICAP class names to implement some of the eCAP
        classes. This is necessary to hide eCAP/ICAP distinction from
        Squid core. Hiding the distinction is necessary to avoid
        numerous conflicts when this branch is merged with async call
        branch changes.
        
        Once the branches are merged, the hack will be removed. Since
        we currently #define eCAP class names to match those of ICAP
        classes, the changes at that time should not be significant:
        remove renaming #defines and adjust autotools meta files to
        allow both ICAP and eCAP co-exist.



configure.in
src/Makefile.am

        Enable eCAP support if loadable module support is enabled.
        Eventually, we may want to control eCAP support directly.
        
        Added eCAP directory to the Makefile. The eCAP directory
        contents will be committed later.



SPONSORS
        Added eCAP sponsor.


src/Makefile.am
        When eCAP is enabled, to support USE_ECAP_AS_ICAP_HACK, ignore
        ICAP files that eCAP overwrites.


configure.in

        Added --enable-ecap option to control eCAP support explicitly.
        Added consistency checks for the combination of --enable-ecap,
        --enable-icap-client, and --disable-loadable-modules options.
        
        Define USE_ECAP_AS_ICAP_HACK macro to enable a temporary hack
        that uses ICAP class names to implement some of the eCAP
        classes. This is necessary to hide eCAP/ICAP distinction from
        Squid core. Hiding the distinction is necessary to avoid
        numerous conflicts when this branch is merged with async call
        branch changes.
        
        Once the branches are merged, the hack will be removed. Since
        we currently #define eCAP class names to match those of ICAP
        classes, the changes at that time should not be significant:
        remove renaming #defines and adjust autotools meta files to
        allow both ICAP and eCAP co-exist.



Makefile.am
acinclude.m4
bootstrap.sh
configure.in
src/Makefile.am

        Added basic support for Libtool ltdl. Libltdl directory is not
        committed yet because I want to investigate whether it can be
        moved from root to lib/. Bootstrap.sh currently strips a large
        copying file from that directory but does not attempt to move
        the directory itself.
        
        The configure options will need to be changed according to
        squid-dev discussion: we should assume that ltdl is always used
        if modules are used, and we should have a --disable-modules
        option.
        
        The code works with a dummy module: Squid was able to load and
        unload using LoadableModule, an ltdl wrapper class from Spicer.
        I have not committed that wrapper yet.

Makefile.am
bootstrap.sh
configure.in
src/Makefile.am

        Moved Libtool libltdl directory to lib/libLtdl to keep all
        3rd-party libs in one place. Will commit the lib/libLtdl
        directory itself soon.
        
        Bootstrap.sh currently moves all files from the generated
        libltdl into lib/libLtdl. A better approach may be to use the
        --ltdl option of libtoolize. Will investigate.
        
        Changed configure options to assume that ltdl is always used if
        modules are used.",48970,data/crawl/squid/hunk_4347.cpp,,,data/crawl/squid/old_hunk_4347.cpp,data/crawl/squid/new_hunk_4347.cpp,-1,1283,,"printf (""mips-sony-bsd\n"");","[""addLog""]","[[], [""printf"", ""mips"", ""sony"", ""bsd\\n""]]",[2553307903029636181],6350,2626560.0,2
https://github.com/squid-cache/squid/commit/64bdef96ce94ed48c38fd37e063fdbd7cf8cce5f,30 Mar 2008,"Moved configuration options that do not depend on the adaptation method
from ICAP/ICAPConfig to adaptation/Config. ICAP and eCAP will not share
the same base configuration but will share the same base configuration code
(i.e., there will be two independent ICAPConfig and ecap::Config objects,
but they will have a common parent).

Implemented delayed creation of adaptation services. We used to create
ICAPServiceRep objects when parsing the configuration file.
Create-as-you-parse is imperfect for several reasons, especially if the
services are dynamically loaded as is the case with eCAP. We now remember the
service configuration and then create the actual service object _after_ the
configuration has been parsed and loadable modules, if any, have been loaded.

No functional changes are expected from this change.",1120,data/crawl/squid/hunk_4337.cpp,,,data/crawl/squid/old_hunk_4337.cpp,data/crawl/squid/new_hunk_4337.cpp,-1,441,,"storeAppendPrintf(entry, ""%s %s\n"", name, (*i)->key.buf());","[""addLog""]","[[], [""storeAppendPrintf"", ""entry"", ""%s"", ""%s\\n"", ""name"", ""*i"", ""key"", ""buf""]]",[14867700258963789652],6349,618480.0,2
https://github.com/squid-cache/squid/commit/48bb425da6b195dbf73b23dffc017e4e5650091c,07 Apr 2008,"Bug #2001: Fails to forward responses where headers >4KB

This changes reply processing to clone the already parsed reply header
instead of trying to parse it yet another time. This allows us to seek
over the header contents and that way get away with just having a 4KB
buffer..

In the long run the store client API will be changed to provide a clean
split between headers and body, providing headers in parsed form (including
intermediary 1xx messages) and then the body starting at offset 0. This
change is a first step along that path but without changing the store client
api as such, with the intention of being merged into 3.0.",250,data/crawl/squid/hunk_4327.cpp,,,data/crawl/squid/old_hunk_4327.cpp,data/crawl/squid/new_hunk_4327.cpp,34,-1,"fatal (""clientReplyContext::sendMoreData: Unreachable code reached \n"");",,"[""removeLog""]","[[""fatal"", ""clientReplyContext"", ""sendMoreData"", ""Unreachable"", ""code"", ""reached"", ""\\n""], []]",[-1677454505947847211],6348,16560.0,2
https://github.com/squid-cache/squid/commit/f836c9ccd633c7973825dd19bcb2a22ffa7512b4,12 Apr 2008,"eCAP support, part 1: Loadable modules and ICAP-independent Squid core.

The first part of eCAP work includes (a) initial support for loadable
modules and (b) removing ICAP from main Squid sources, replaced with the
adaptation API that does not depend on a specific adaptation mechanism.

The patch does not contain significant changes to main Squid sources.
Generic adaptation API should minimize significant core changes going
forward. Details are below. For a low-level change log, see the eCAP bzr
branch at https://code.launchpad.net/~rousskov/squid/ecap

Configuration and features:

  Added adaptation_service_set squid.conf option, deprecating
  icap_class. The new option has more accurate documentation and does
  not depend on the adaptation protocol so one can group eCAP and ICAP
  services.
  
  Added adaptation_service_set squid.conf option, deprecating
  icap_access. The new option has more accurate documentation and does
  not depend on the adaptation protocol so one can mix-and-match eCAP
  and ICAP ACL rules.

  Added loadable_modules squid.conf option to specify what shared
  libraries to load dynamically. The support is based on libtool's ltdl
  convenience library and is enabled by default. It can be disabled
  using --disable-loadable-modules.  Loadable modules are needed for
  eCAP, but loadable_modules code deals with generic module
  manipulation, independent from eCAP support. Squid does not yet
  communicate with the loaded modules. TODO: support cachemgr
  reporting and reconfiguration of modules.


Internals:

  Squid core no longer knows about ICAP: General message adaptation code
  has been moved from src/ICAP to src/adaptation/. The only connection
  between main Squid code and ICAP is squid.conf parser and a few
  enabling lines in main.cc. USE_ADAPTATION is enabled if ICAP_CLIENT or
  USE_ECAP is enabled. TODO: Make adaptation comments, debug, and error
  messages in main Squid code ICAP-neutral. This has not been done yet
  to reduce VCS conflicts.

  The src/ICAP/ directory now has its own Makefile (so does the new
  src/adaptation). TODO: Should ICAP and eCAP directories be moved
  inside adaptation/?

  The eCAP directory and the --enable-ecap option have been added, but
  they should not be used yet.

  Added an adaptation service group API to support groups of services.
  Current code supports service sets and single-service groups. Sets
  provide a way to group interchangeable services together so that one
  (the ""best"" available) service is applied to the message. A
  single-service group is an internal feature to allow user to mix
  service and group names in squid.conf ACLs.  TODO: support service
  chains (as a service group) and perhaps group of groups?

  Implemented delayed creation of adaptation services. We used to create
  ICAPServiceRep objects when parsing the configuration file.
  Create-as-you-parse is imperfect for several reasons, especially if
  the services are dynamically loaded as is the case with eCAP. We now
  remember the service configuration and then create the actual service
  object _after_ the configuration has been parsed and loadable modules,
  if any, have been loaded.

  The bootstrap.sh script has been updated to generate ltdl library
  using libtoolize and move it to lib/libLtdl (except for the standard
  copyright file). With libtool version 2, the move will be supported by
  libtoolize itself.  The lib/libLtdl directory and libtool.m4 file are
  not in VCS.",4043,data/crawl/squid/hunk_4318.cpp,,,data/crawl/squid/old_hunk_4318.cpp,data/crawl/squid/new_hunk_4318.cpp,-1,70,,"storeAppendPrintf(entry, ""%s %s_%s %s %d %s\n"", name, cfg.key.buf(),
            cfg.methodStr(), cfg.vectPointStr(), cfg.bypass, cfg.uri.buf());","[""addLog""]","[[], [""storeAppendPrintf"", ""entry"", ""%s"", ""%s_%s"", ""%s"", ""%d"", ""%s\\n"", ""name"", ""cfg"", ""key"", ""buf"", ""cfg"", ""methodStr"", ""cfg"", ""vectPointStr"", ""cfg"", ""bypass"", ""cfg"", ""uri"", ""buf""]]",[8275548490987375526],6347,9360.0,2
https://github.com/squid-cache/squid/commit/f836c9ccd633c7973825dd19bcb2a22ffa7512b4,12 Apr 2008,"eCAP support, part 1: Loadable modules and ICAP-independent Squid core.

The first part of eCAP work includes (a) initial support for loadable
modules and (b) removing ICAP from main Squid sources, replaced with the
adaptation API that does not depend on a specific adaptation mechanism.

The patch does not contain significant changes to main Squid sources.
Generic adaptation API should minimize significant core changes going
forward. Details are below. For a low-level change log, see the eCAP bzr
branch at https://code.launchpad.net/~rousskov/squid/ecap

Configuration and features:

  Added adaptation_service_set squid.conf option, deprecating
  icap_class. The new option has more accurate documentation and does
  not depend on the adaptation protocol so one can group eCAP and ICAP
  services.
  
  Added adaptation_service_set squid.conf option, deprecating
  icap_access. The new option has more accurate documentation and does
  not depend on the adaptation protocol so one can mix-and-match eCAP
  and ICAP ACL rules.

  Added loadable_modules squid.conf option to specify what shared
  libraries to load dynamically. The support is based on libtool's ltdl
  convenience library and is enabled by default. It can be disabled
  using --disable-loadable-modules.  Loadable modules are needed for
  eCAP, but loadable_modules code deals with generic module
  manipulation, independent from eCAP support. Squid does not yet
  communicate with the loaded modules. TODO: support cachemgr
  reporting and reconfiguration of modules.


Internals:

  Squid core no longer knows about ICAP: General message adaptation code
  has been moved from src/ICAP to src/adaptation/. The only connection
  between main Squid code and ICAP is squid.conf parser and a few
  enabling lines in main.cc. USE_ADAPTATION is enabled if ICAP_CLIENT or
  USE_ECAP is enabled. TODO: Make adaptation comments, debug, and error
  messages in main Squid code ICAP-neutral. This has not been done yet
  to reduce VCS conflicts.

  The src/ICAP/ directory now has its own Makefile (so does the new
  src/adaptation). TODO: Should ICAP and eCAP directories be moved
  inside adaptation/?

  The eCAP directory and the --enable-ecap option have been added, but
  they should not be used yet.

  Added an adaptation service group API to support groups of services.
  Current code supports service sets and single-service groups. Sets
  provide a way to group interchangeable services together so that one
  (the ""best"" available) service is applied to the message. A
  single-service group is an internal feature to allow user to mix
  service and group names in squid.conf ACLs.  TODO: support service
  chains (as a service group) and perhaps group of groups?

  Implemented delayed creation of adaptation services. We used to create
  ICAPServiceRep objects when parsing the configuration file.
  Create-as-you-parse is imperfect for several reasons, especially if
  the services are dynamically loaded as is the case with eCAP. We now
  remember the service configuration and then create the actual service
  object _after_ the configuration has been parsed and loadable modules,
  if any, have been loaded.

  The bootstrap.sh script has been updated to generate ltdl library
  using libtoolize and move it to lib/libLtdl (except for the standard
  copyright file). With libtool version 2, the move will be supported by
  libtoolize itself.  The lib/libLtdl directory and libtool.m4 file are
  not in VCS.",4043,data/crawl/squid/hunk_4312.cpp,,,data/crawl/squid/old_hunk_4312.cpp,data/crawl/squid/new_hunk_4312.cpp,5,5,"buf.Printf(""Host: %s:%d\r\n"", s.host.buf(), s.port);","buf.Printf(""Host: %s:%d\r\n"", s.cfg().host.buf(), s.cfg().port);","[""moveVariable"", ""removeVariable"", ""addVariable""]","[[], [""cfg"", ""cfg""]]",[-1598062591627235054],6346,9360.0,2
https://github.com/squid-cache/squid/commit/f836c9ccd633c7973825dd19bcb2a22ffa7512b4,12 Apr 2008,"eCAP support, part 1: Loadable modules and ICAP-independent Squid core.

The first part of eCAP work includes (a) initial support for loadable
modules and (b) removing ICAP from main Squid sources, replaced with the
adaptation API that does not depend on a specific adaptation mechanism.

The patch does not contain significant changes to main Squid sources.
Generic adaptation API should minimize significant core changes going
forward. Details are below. For a low-level change log, see the eCAP bzr
branch at https://code.launchpad.net/~rousskov/squid/ecap

Configuration and features:

  Added adaptation_service_set squid.conf option, deprecating
  icap_class. The new option has more accurate documentation and does
  not depend on the adaptation protocol so one can group eCAP and ICAP
  services.
  
  Added adaptation_service_set squid.conf option, deprecating
  icap_access. The new option has more accurate documentation and does
  not depend on the adaptation protocol so one can mix-and-match eCAP
  and ICAP ACL rules.

  Added loadable_modules squid.conf option to specify what shared
  libraries to load dynamically. The support is based on libtool's ltdl
  convenience library and is enabled by default. It can be disabled
  using --disable-loadable-modules.  Loadable modules are needed for
  eCAP, but loadable_modules code deals with generic module
  manipulation, independent from eCAP support. Squid does not yet
  communicate with the loaded modules. TODO: support cachemgr
  reporting and reconfiguration of modules.


Internals:

  Squid core no longer knows about ICAP: General message adaptation code
  has been moved from src/ICAP to src/adaptation/. The only connection
  between main Squid code and ICAP is squid.conf parser and a few
  enabling lines in main.cc. USE_ADAPTATION is enabled if ICAP_CLIENT or
  USE_ECAP is enabled. TODO: Make adaptation comments, debug, and error
  messages in main Squid code ICAP-neutral. This has not been done yet
  to reduce VCS conflicts.

  The src/ICAP/ directory now has its own Makefile (so does the new
  src/adaptation). TODO: Should ICAP and eCAP directories be moved
  inside adaptation/?

  The eCAP directory and the --enable-ecap option have been added, but
  they should not be used yet.

  Added an adaptation service group API to support groups of services.
  Current code supports service sets and single-service groups. Sets
  provide a way to group interchangeable services together so that one
  (the ""best"" available) service is applied to the message. A
  single-service group is an internal feature to allow user to mix
  service and group names in squid.conf ACLs.  TODO: support service
  chains (as a service group) and perhaps group of groups?

  Implemented delayed creation of adaptation services. We used to create
  ICAPServiceRep objects when parsing the configuration file.
  Create-as-you-parse is imperfect for several reasons, especially if
  the services are dynamically loaded as is the case with eCAP. We now
  remember the service configuration and then create the actual service
  object _after_ the configuration has been parsed and loadable modules,
  if any, have been loaded.

  The bootstrap.sh script has been updated to generate ltdl library
  using libtoolize and move it to lib/libLtdl (except for the standard
  copyright file). With libtool version 2, the move will be supported by
  libtoolize itself.  The lib/libLtdl directory and libtool.m4 file are
  not in VCS.",4043,data/crawl/squid/hunk_4312.cpp,,,data/crawl/squid/old_hunk_4312.cpp,data/crawl/squid/new_hunk_4312.cpp,4,4,"buf.Printf(""OPTIONS %s ICAP/1.0\r\n"", s.uri.buf());","buf.Printf(""OPTIONS %s ICAP/1.0\r\n"", s.cfg().uri.buf());","[""moveVariable"", ""addVariable""]","[[], [""cfg""]]",[-799031295813617527],6345,9360.0,2
https://github.com/squid-cache/squid/commit/f836c9ccd633c7973825dd19bcb2a22ffa7512b4,12 Apr 2008,"eCAP support, part 1: Loadable modules and ICAP-independent Squid core.

The first part of eCAP work includes (a) initial support for loadable
modules and (b) removing ICAP from main Squid sources, replaced with the
adaptation API that does not depend on a specific adaptation mechanism.

The patch does not contain significant changes to main Squid sources.
Generic adaptation API should minimize significant core changes going
forward. Details are below. For a low-level change log, see the eCAP bzr
branch at https://code.launchpad.net/~rousskov/squid/ecap

Configuration and features:

  Added adaptation_service_set squid.conf option, deprecating
  icap_class. The new option has more accurate documentation and does
  not depend on the adaptation protocol so one can group eCAP and ICAP
  services.
  
  Added adaptation_service_set squid.conf option, deprecating
  icap_access. The new option has more accurate documentation and does
  not depend on the adaptation protocol so one can mix-and-match eCAP
  and ICAP ACL rules.

  Added loadable_modules squid.conf option to specify what shared
  libraries to load dynamically. The support is based on libtool's ltdl
  convenience library and is enabled by default. It can be disabled
  using --disable-loadable-modules.  Loadable modules are needed for
  eCAP, but loadable_modules code deals with generic module
  manipulation, independent from eCAP support. Squid does not yet
  communicate with the loaded modules. TODO: support cachemgr
  reporting and reconfiguration of modules.


Internals:

  Squid core no longer knows about ICAP: General message adaptation code
  has been moved from src/ICAP to src/adaptation/. The only connection
  between main Squid code and ICAP is squid.conf parser and a few
  enabling lines in main.cc. USE_ADAPTATION is enabled if ICAP_CLIENT or
  USE_ECAP is enabled. TODO: Make adaptation comments, debug, and error
  messages in main Squid code ICAP-neutral. This has not been done yet
  to reduce VCS conflicts.

  The src/ICAP/ directory now has its own Makefile (so does the new
  src/adaptation). TODO: Should ICAP and eCAP directories be moved
  inside adaptation/?

  The eCAP directory and the --enable-ecap option have been added, but
  they should not be used yet.

  Added an adaptation service group API to support groups of services.
  Current code supports service sets and single-service groups. Sets
  provide a way to group interchangeable services together so that one
  (the ""best"" available) service is applied to the message. A
  single-service group is an internal feature to allow user to mix
  service and group names in squid.conf ACLs.  TODO: support service
  chains (as a service group) and perhaps group of groups?

  Implemented delayed creation of adaptation services. We used to create
  ICAPServiceRep objects when parsing the configuration file.
  Create-as-you-parse is imperfect for several reasons, especially if
  the services are dynamically loaded as is the case with eCAP. We now
  remember the service configuration and then create the actual service
  object _after_ the configuration has been parsed and loadable modules,
  if any, have been loaded.

  The bootstrap.sh script has been updated to generate ltdl library
  using libtoolize and move it to lib/libLtdl (except for the standard
  copyright file). With libtool version 2, the move will be supported by
  libtoolize itself.  The lib/libLtdl directory and libtool.m4 file are
  not in VCS.",4043,data/crawl/squid/hunk_4310.cpp,,,data/crawl/squid/old_hunk_4310.cpp,data/crawl/squid/new_hunk_4310.cpp,352,-1,"fatalf(""Did not find ICAP class '%s' referenced on line %d\n"",
               aKey.buf(), config_lineno);",,"[""removeLog""]","[[""fatalf"", ""Did"", ""not"", ""find"", ""ICAP"", ""class"", ""%s"", ""referenced"", ""on"", ""line"", ""%d\\n"", ""aKey"", ""buf"", ""config_lineno""], []]",[-23416213931012236585],6344,9360.0,2
https://github.com/squid-cache/squid/commit/f836c9ccd633c7973825dd19bcb2a22ffa7512b4,12 Apr 2008,"eCAP support, part 1: Loadable modules and ICAP-independent Squid core.

The first part of eCAP work includes (a) initial support for loadable
modules and (b) removing ICAP from main Squid sources, replaced with the
adaptation API that does not depend on a specific adaptation mechanism.

The patch does not contain significant changes to main Squid sources.
Generic adaptation API should minimize significant core changes going
forward. Details are below. For a low-level change log, see the eCAP bzr
branch at https://code.launchpad.net/~rousskov/squid/ecap

Configuration and features:

  Added adaptation_service_set squid.conf option, deprecating
  icap_class. The new option has more accurate documentation and does
  not depend on the adaptation protocol so one can group eCAP and ICAP
  services.
  
  Added adaptation_service_set squid.conf option, deprecating
  icap_access. The new option has more accurate documentation and does
  not depend on the adaptation protocol so one can mix-and-match eCAP
  and ICAP ACL rules.

  Added loadable_modules squid.conf option to specify what shared
  libraries to load dynamically. The support is based on libtool's ltdl
  convenience library and is enabled by default. It can be disabled
  using --disable-loadable-modules.  Loadable modules are needed for
  eCAP, but loadable_modules code deals with generic module
  manipulation, independent from eCAP support. Squid does not yet
  communicate with the loaded modules. TODO: support cachemgr
  reporting and reconfiguration of modules.


Internals:

  Squid core no longer knows about ICAP: General message adaptation code
  has been moved from src/ICAP to src/adaptation/. The only connection
  between main Squid code and ICAP is squid.conf parser and a few
  enabling lines in main.cc. USE_ADAPTATION is enabled if ICAP_CLIENT or
  USE_ECAP is enabled. TODO: Make adaptation comments, debug, and error
  messages in main Squid code ICAP-neutral. This has not been done yet
  to reduce VCS conflicts.

  The src/ICAP/ directory now has its own Makefile (so does the new
  src/adaptation). TODO: Should ICAP and eCAP directories be moved
  inside adaptation/?

  The eCAP directory and the --enable-ecap option have been added, but
  they should not be used yet.

  Added an adaptation service group API to support groups of services.
  Current code supports service sets and single-service groups. Sets
  provide a way to group interchangeable services together so that one
  (the ""best"" available) service is applied to the message. A
  single-service group is an internal feature to allow user to mix
  service and group names in squid.conf ACLs.  TODO: support service
  chains (as a service group) and perhaps group of groups?

  Implemented delayed creation of adaptation services. We used to create
  ICAPServiceRep objects when parsing the configuration file.
  Create-as-you-parse is imperfect for several reasons, especially if
  the services are dynamically loaded as is the case with eCAP. We now
  remember the service configuration and then create the actual service
  object _after_ the configuration has been parsed and loadable modules,
  if any, have been loaded.

  The bootstrap.sh script has been updated to generate ltdl library
  using libtoolize and move it to lib/libLtdl (except for the standard
  copyright file). With libtool version 2, the move will be supported by
  libtoolize itself.  The lib/libLtdl directory and libtool.m4 file are
  not in VCS.",4043,data/crawl/squid/hunk_4310.cpp,,,data/crawl/squid/old_hunk_4310.cpp,data/crawl/squid/new_hunk_4310.cpp,339,-1,"storeAppendPrintf(entry, ""%s %s\n"", name, (*i)->key.buf());",,"[""removeLog""]","[[""storeAppendPrintf"", ""entry"", ""%s"", ""%s\\n"", ""name"", ""*i"", ""key"", ""buf""], []]",[-14867700258963789652],6343,9360.0,2
https://github.com/squid-cache/squid/commit/f836c9ccd633c7973825dd19bcb2a22ffa7512b4,12 Apr 2008,"eCAP support, part 1: Loadable modules and ICAP-independent Squid core.

The first part of eCAP work includes (a) initial support for loadable
modules and (b) removing ICAP from main Squid sources, replaced with the
adaptation API that does not depend on a specific adaptation mechanism.

The patch does not contain significant changes to main Squid sources.
Generic adaptation API should minimize significant core changes going
forward. Details are below. For a low-level change log, see the eCAP bzr
branch at https://code.launchpad.net/~rousskov/squid/ecap

Configuration and features:

  Added adaptation_service_set squid.conf option, deprecating
  icap_class. The new option has more accurate documentation and does
  not depend on the adaptation protocol so one can group eCAP and ICAP
  services.
  
  Added adaptation_service_set squid.conf option, deprecating
  icap_access. The new option has more accurate documentation and does
  not depend on the adaptation protocol so one can mix-and-match eCAP
  and ICAP ACL rules.

  Added loadable_modules squid.conf option to specify what shared
  libraries to load dynamically. The support is based on libtool's ltdl
  convenience library and is enabled by default. It can be disabled
  using --disable-loadable-modules.  Loadable modules are needed for
  eCAP, but loadable_modules code deals with generic module
  manipulation, independent from eCAP support. Squid does not yet
  communicate with the loaded modules. TODO: support cachemgr
  reporting and reconfiguration of modules.


Internals:

  Squid core no longer knows about ICAP: General message adaptation code
  has been moved from src/ICAP to src/adaptation/. The only connection
  between main Squid code and ICAP is squid.conf parser and a few
  enabling lines in main.cc. USE_ADAPTATION is enabled if ICAP_CLIENT or
  USE_ECAP is enabled. TODO: Make adaptation comments, debug, and error
  messages in main Squid code ICAP-neutral. This has not been done yet
  to reduce VCS conflicts.

  The src/ICAP/ directory now has its own Makefile (so does the new
  src/adaptation). TODO: Should ICAP and eCAP directories be moved
  inside adaptation/?

  The eCAP directory and the --enable-ecap option have been added, but
  they should not be used yet.

  Added an adaptation service group API to support groups of services.
  Current code supports service sets and single-service groups. Sets
  provide a way to group interchangeable services together so that one
  (the ""best"" available) service is applied to the message. A
  single-service group is an internal feature to allow user to mix
  service and group names in squid.conf ACLs.  TODO: support service
  chains (as a service group) and perhaps group of groups?

  Implemented delayed creation of adaptation services. We used to create
  ICAPServiceRep objects when parsing the configuration file.
  Create-as-you-parse is imperfect for several reasons, especially if
  the services are dynamically loaded as is the case with eCAP. We now
  remember the service configuration and then create the actual service
  object _after_ the configuration has been parsed and loadable modules,
  if any, have been loaded.

  The bootstrap.sh script has been updated to generate ltdl library
  using libtoolize and move it to lib/libLtdl (except for the standard
  copyright file). With libtool version 2, the move will be supported by
  libtoolize itself.  The lib/libLtdl directory and libtool.m4 file are
  not in VCS.",4043,data/crawl/squid/hunk_4310.cpp,,,data/crawl/squid/old_hunk_4310.cpp,data/crawl/squid/new_hunk_4310.cpp,310,-1,"storeAppendPrintf(entry, ""%s %s_%s %s %d %s\n"", name, r->key.buf(),
                          r->methodStr(), r->vectPointStr(), r->bypass, r->uri.buf());",,"[""removeLog""]","[[""storeAppendPrintf"", ""entry"", ""%s"", ""%s_%s"", ""%s"", ""%d"", ""%s\\n"", ""name"", ""r"", ""key"", ""buf"", ""r"", ""methodStr"", ""r"", ""vectPointStr"", ""r"", ""bypass"", ""r"", ""uri"", ""buf""], []]",[-12270705043015682616],6342,9360.0,2
https://github.com/squid-cache/squid/commit/1b328f6dba39a3f81ba8e2e073f5107ea52cb560,24 Apr 2008,"Transparent Interception remodelling.

This patch merges part 2 of the TPROXY-related updates.

 - Makes interception handling flags and options always-present
 - Updates squid.conf http_port options for clarity
 - Builds structure for sequential lookup of multiple interception methods
 - Performs sequential lookups for IPFW and multiple Netfilter targets
   if Squid configured to enable those transparency methods.
 - Pulls most of the TPROXYv2 related code out of Comm into IPInterception

IPFW changes are still experimental, but Netfilter targets have been tested.

TODO: depending on the anoyance levels a better logging method for NAT
      failures may need to be implemented. The existing methods of logging
      one-per-N seconds, for all lookup methods may prove annoying.",692,data/crawl/squid/hunk_4309.cpp,,,data/crawl/squid/old_hunk_4309.cpp,data/crawl/squid/new_hunk_4309.cpp,-1,22,,"IPInterceptor.StopTransparency(""Missing needed capability support."");","[""addLog""]","[[], [""IPInterceptor"", ""StopTransparency"", ""Missing"", ""needed"", ""capability"", ""support""]]",[19422512612443402713],6341,11520.0,2
https://github.com/squid-cache/squid/commit/1b328f6dba39a3f81ba8e2e073f5107ea52cb560,24 Apr 2008,"Transparent Interception remodelling.

This patch merges part 2 of the TPROXY-related updates.

 - Makes interception handling flags and options always-present
 - Updates squid.conf http_port options for clarity
 - Builds structure for sequential lookup of multiple interception methods
 - Performs sequential lookups for IPFW and multiple Netfilter targets
   if Squid configured to enable those transparency methods.
 - Pulls most of the TPROXYv2 related code out of Comm into IPInterception

IPFW changes are still experimental, but Netfilter targets have been tested.

TODO: depending on the anoyance levels a better logging method for NAT
      failures may need to be implemented. The existing methods of logging
      one-per-N seconds, for all lookup methods may prove annoying.",692,data/crawl/squid/hunk_4309.cpp,,,data/crawl/squid/old_hunk_4309.cpp,data/crawl/squid/new_hunk_4309.cpp,-1,14,,"IPInterceptor.StopTransparency(""Error enabling needed capabilities."");","[""addLog""]","[[], [""IPInterceptor"", ""StopTransparency"", ""Error"", ""enabling"", ""needed"", ""capabilities""]]",[16953699030959064077],6340,11520.0,2
https://github.com/squid-cache/squid/commit/1b328f6dba39a3f81ba8e2e073f5107ea52cb560,24 Apr 2008,"Transparent Interception remodelling.

This patch merges part 2 of the TPROXY-related updates.

 - Makes interception handling flags and options always-present
 - Updates squid.conf http_port options for clarity
 - Builds structure for sequential lookup of multiple interception methods
 - Performs sequential lookups for IPFW and multiple Netfilter targets
   if Squid configured to enable those transparency methods.
 - Pulls most of the TPROXYv2 related code out of Comm into IPInterception

IPFW changes are still experimental, but Netfilter targets have been tested.

TODO: depending on the anoyance levels a better logging method for NAT
      failures may need to be implemented. The existing methods of logging
      one-per-N seconds, for all lookup methods may prove annoying.",692,data/crawl/squid/hunk_4307.cpp,,,data/crawl/squid/old_hunk_4307.cpp,data/crawl/squid/new_hunk_4307.cpp,4,4,"storeAppendPrintf(e, "" transparent"");","storeAppendPrintf(e, "" intercept"");","[""updateContent""]","[[""transparent""], [""intercept""]]",[-2470343994809172362],6339,10800.0,2
https://github.com/squid-cache/squid/commit/67c06f0d42ffa2b3b71082e0694460efa22a37a0,10 May 2008,"Bug 2223: Feature: flexible handling of x-forwarded-for

This patch adds three settings for the 'forwarded_for' option in squid.conf:

If set to ""transparent"", Squid will not alter the X-Forwarded-For header in any
way.

If set to ""delete"", Squid will delete the entire X-Forwarded-For header.

If set to ""truncate"", Squid will remove all existing X-Forwarded-For entries,
and place itself as the sole entry.

The old options 'on' and 'off' have been left unaltered.",60,data/crawl/squid/hunk_4293.cpp,,,data/crawl/squid/old_hunk_4293.cpp,data/crawl/squid/new_hunk_4293.cpp,-1,30,,"hdr_out->putStr(HDR_X_FORWARDED_FOR, strFwd.buf());","[""addLog""]","[[], [""hdr_out"", ""putStr"", ""HDR_X_FORWARDED_FOR"", ""strFwd"", ""buf""]]",[-12933192661661450107],6338,528480.0,2
https://github.com/squid-cache/squid/commit/9e6e0372016a2d16124516049b5b9cd0ae9c52f8,17 May 2008,"Windows port: Added new mswin_check_ad_group external ACL helper

This helper allow the lookup of users's group membership in a Windows
Active Directory domain.
It overcomes the Lan Manager limits of mswin_check_lm_group, but it can be
used only with native Windows Active Directory domains, so mswin_check_lm_group 
will not removed from Squid.",669,data/crawl/squid/hunk_4290.cpp,,,data/crawl/squid/old_hunk_4290.cpp,data/crawl/squid/new_hunk_4290.cpp,-1,60,,"fprintf(stderr, ""%s[%d]: "", myname, mypid);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""%s[%d]"", ""myname"", ""mypid""]]",[-19957182019804867126],6337,668880.0,2
https://github.com/squid-cache/squid/commit/9e6e0372016a2d16124516049b5b9cd0ae9c52f8,17 May 2008,"Windows port: Added new mswin_check_ad_group external ACL helper

This helper allow the lookup of users's group membership in a Windows
Active Directory domain.
It overcomes the Lan Manager limits of mswin_check_lm_group, but it can be
used only with native Windows Active Directory domains, so mswin_check_lm_group 
will not removed from Squid.",669,data/crawl/squid/hunk_4289.cpp,,,data/crawl/squid/old_hunk_4289.cpp,data/crawl/squid/new_hunk_4289.cpp,-1,425,,"fprintf(stderr, ""%s Can't read machine domain\n"", myname);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""%s"", ""Can"", ""t"", ""read"", ""machine"", ""domain\\n"", ""myname""]]",[-12245317477140391123],6336,668880.0,2
https://github.com/squid-cache/squid/commit/9e6e0372016a2d16124516049b5b9cd0ae9c52f8,17 May 2008,"Windows port: Added new mswin_check_ad_group external ACL helper

This helper allow the lookup of users's group membership in a Windows
Active Directory domain.
It overcomes the Lan Manager limits of mswin_check_lm_group, but it can be
used only with native Windows Active Directory domains, so mswin_check_lm_group 
will not removed from Squid.",669,data/crawl/squid/hunk_4289.cpp,,,data/crawl/squid/old_hunk_4289.cpp,data/crawl/squid/new_hunk_4289.cpp,-1,387,,"fprintf(stderr, ""%s Unknown option: -%c. Exiting\n"", myname, opt);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""%s"", ""Unknown"", ""option"", ""%c"", ""Exiting\\n"", ""myname"", ""opt""]]",[-5167440251014052868],6335,668880.0,2
https://github.com/squid-cache/squid/commit/9e6e0372016a2d16124516049b5b9cd0ae9c52f8,17 May 2008,"Windows port: Added new mswin_check_ad_group external ACL helper

This helper allow the lookup of users's group membership in a Windows
Active Directory domain.
It overcomes the Lan Manager limits of mswin_check_lm_group, but it can be
used only with native Windows Active Directory domains, so mswin_check_lm_group 
will not removed from Squid.",669,data/crawl/squid/hunk_4289.cpp,,,data/crawl/squid/old_hunk_4289.cpp,data/crawl/squid/new_hunk_4289.cpp,-1,335,,"fprintf(stderr, ""%s NetUserGetGroups() failed.'\n"", myname);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""%s"", ""NetUserGetGroups"", ""failed"", ""\\n"", ""myname""]]",[-17474047509400514334],6334,668880.0,2
https://github.com/squid-cache/squid/commit/63104e28d3eef6502550733c16b04c982c0e1776,11 Jul 2008,copy carp.cc to peer_userhash.cc and peer_sourcehash.cc,454,data/crawl/squid/hunk_4264.cpp,,,data/crawl/squid/old_hunk_4264.cpp,data/crawl/squid/new_hunk_4264.cpp,-1,220,,"storeAppendPrintf(sentry, ""%24s %10x %10f %10f %10f\n"",
                          p->name, p->carp.hash,
                          p->carp.load_multiplier,
                          p->carp.load_factor,
                          sumfetches ? (double) p->stats.fetches / sumfetches : -1.0);","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""%24s"", ""%10x"", ""%10f"", ""%10f"", ""%10f\\n"", ""p"", ""name"", ""p"", ""carp"", ""hash"", ""p"", ""carp"", ""load_multiplier"", ""p"", ""carp"", ""load_factor"", ""sumfetches"", ""double"", ""p"", ""stats"", ""fetches"", ""/"", ""sumfetches"", ""1"", ""0""]]",[28716339615727585681],6333,0.0,2
https://github.com/squid-cache/squid/commit/4a485f7104182aa3290f670f213feb6d7934b669,14 Jul 2008,"userhash and sourcehash peer seletction methods

these is effectively just copies of carp.cc with changed keying method
to key on the authenticated username respectiely client source address.",544,data/crawl/squid/hunk_4256.cpp,,,data/crawl/squid/old_hunk_4256.cpp,data/crawl/squid/new_hunk_4256.cpp,-1,10,,"storeAppendPrintf(sentry, "" sourcehash"");","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""sourcehash""]]",[13456601144098761739],6332,2160.0,2
https://github.com/squid-cache/squid/commit/4a485f7104182aa3290f670f213feb6d7934b669,14 Jul 2008,"userhash and sourcehash peer seletction methods

these is effectively just copies of carp.cc with changed keying method
to key on the authenticated username respectiely client source address.",544,data/crawl/squid/hunk_4256.cpp,,,data/crawl/squid/old_hunk_4256.cpp,data/crawl/squid/new_hunk_4256.cpp,-1,7,,"storeAppendPrintf(sentry, "" userhash"");","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""userhash""]]",[-1248503893836483949],6331,2160.0,2
https://github.com/squid-cache/squid/commit/4a485f7104182aa3290f670f213feb6d7934b669,14 Jul 2008,"userhash and sourcehash peer seletction methods

these is effectively just copies of carp.cc with changed keying method
to key on the authenticated username respectiely client source address.",544,data/crawl/squid/hunk_4256.cpp,,,data/crawl/squid/old_hunk_4256.cpp,data/crawl/squid/new_hunk_4256.cpp,-1,4,,"storeAppendPrintf(sentry, "" carp"");","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""carp""]]",[11542197183133705300],6330,2160.0,2
https://github.com/squid-cache/squid/commit/4a485f7104182aa3290f670f213feb6d7934b669,14 Jul 2008,"userhash and sourcehash peer seletction methods

these is effectively just copies of carp.cc with changed keying method
to key on the authenticated username respectiely client source address.",544,data/crawl/squid/hunk_4255.cpp,,,data/crawl/squid/old_hunk_4255.cpp,data/crawl/squid/new_hunk_4255.cpp,-1,11,,"fatalf(""parse_peer: non-parent sourcehash peer %s/%d\n"", p->host, p->http_port);","[""addLog""]","[[], [""fatalf"", ""parse_peer"", ""non"", ""parent"", ""sourcehash"", ""peer"", ""%s/%d\\n"", ""p"", ""host"", ""p"", ""http_port""]]",[52085279935869630301],6329,2160.0,2
https://github.com/squid-cache/squid/commit/4a485f7104182aa3290f670f213feb6d7934b669,14 Jul 2008,"userhash and sourcehash peer seletction methods

these is effectively just copies of carp.cc with changed keying method
to key on the authenticated username respectiely client source address.",544,data/crawl/squid/hunk_4255.cpp,,,data/crawl/squid/old_hunk_4255.cpp,data/crawl/squid/new_hunk_4255.cpp,-1,5,,"fatalf(""parse_peer: non-parent userhash peer %s/%d\n"", p->host, p->http_port);","[""addLog""]","[[], [""fatalf"", ""parse_peer"", ""non"", ""parent"", ""userhash"", ""peer"", ""%s/%d\\n"", ""p"", ""host"", ""p"", ""http_port""]]",[37380174897934384613],6328,2160.0,2
https://github.com/squid-cache/squid/commit/c70281f8bdba2a5f525ddea764667975bbd79eb3,22 Jul 2008,"Cleanups: shuffle ErrorState functions into methods.

No other changes than namespace moves.",228,data/crawl/squid/hunk_4245.cpp,,,data/crawl/squid/old_hunk_4245.cpp,data/crawl/squid/new_hunk_4245.cpp,51,49,"str.Printf(""%s %s HTTP/%d.%d\n"",
                   RequestMethodStr(r->method),
                   r->urlpath.size() ? r->urlpath.buf() : ""/"",
                   r->http_ver.major, r->http_ver.minor);","str.Printf(""%s %s HTTP/%d.%d\n"",
                   RequestMethodStr(request->method),
                   request->urlpath.size() ? request->urlpath.buf() : ""/"",
                   request->http_ver.major, request->http_ver.minor);","[""updateVariable""]","[[""r"", ""r"", ""r"", ""r"", ""r""], [""request"", ""request"", ""request"", ""request"", ""request""]]",[-9533800145018408355],6327,0.0,2
https://github.com/squid-cache/squid/commit/c70281f8bdba2a5f525ddea764667975bbd79eb3,22 Jul 2008,"Cleanups: shuffle ErrorState functions into methods.

No other changes than namespace moves.",228,data/crawl/squid/hunk_4245.cpp,,,data/crawl/squid/old_hunk_4245.cpp,data/crawl/squid/new_hunk_4245.cpp,23,21,"str.Printf(""Err: (%d) %s\r\n"", err->xerrno, strerror(err->xerrno));","str.Printf(""Err: (%d) %s\r\n"", xerrno, strerror(xerrno));","[""removeVariable"", ""addVariable""]","[[""err"", ""err""], []]",[6102284641630666036],6326,0.0,2
https://github.com/squid-cache/squid/commit/2395c209ffef52204c44a4759bd51fb04b731167,10 Aug 2008,Updates auto-save,488,data/crawl/squid/hunk_4240.cpp,,,data/crawl/squid/old_hunk_4240.cpp,data/crawl/squid/new_hunk_4240.cpp,11,-1,"fatal(""ipcache_init: DNS name lookup tests failed."");",,"[""removeLog""]","[[""fatal"", ""ipcache_init"", ""DNS"", ""name"", ""lookup"", ""tests"", ""failed""], []]",[39169918527781651479],6325,720.0,2
https://github.com/squid-cache/squid/commit/4f4fa8157d4837aada53582861fa9efff6491d8a,01 Sep 2008,Checkpoint HTCP merge.,360,data/crawl/squid/hunk_4228.cpp,,,data/crawl/squid/old_hunk_4228.cpp,data/crawl/squid/new_hunk_4228.cpp,-1,5,,"fatalf(""parse_peer: can't set htcp-no-clr and htcp-only-clr simultaneously"");","[""addLog""]","[[], [""fatalf"", ""parse_peer"", ""can"", ""t"", ""set"", ""htcp"", ""no"", ""clr"", ""and"", ""htcp"", ""only"", ""clr"", ""simultaneously""]]",[21038964246641495832],6324,0.0,2
https://github.com/squid-cache/squid/commit/49e510eab9c639f6e97e24ca17555ab714a5bfd7,12 Sep 2008,"Cleaned up ConnStateData's closing and destruction.

1) Despite its name and the ""if (open) close"" use in ConnStateData
destructor, ConnStateData::close() was not closing anything. It was
called from the Comm close handler and from the destructor and would
attempt to immediately delete the ConnStateData object. Protecting code
in deleteThis() may have prevented the actual [double] delete from
happening, but it is difficult to say exactly what was going on when the
close() method was being called from the destructor.

I converted ConnStateData::close to swanSong, which is the standard
AsyncJob cleanup method. As before, the method does not close anything
(which may still be wrong). The swanSong method is never called directly
by the user code. It is called by lower layers just before the job is
destroyed. The updated close handler initiates job destruction by
calling deleteThis().

We may need to add Comm closing code to swanSong. For now, the updated
ConnStateData destructor will warn if ConnStateData forgot to close the
connection. The destructor will also warn if swanSong was not called,
which would mean that the job object is being deleted incorrectly.


2) Polished ClientSocketContext::writeComplete to distinguish
STREAM_UNPLANNED_COMPLETE from STREAM_FAILED closing state. This helps
when looking at stack traces.


3) Added an XXX comment about duplicated code.


4) Documented ClientSocketContext::initiateClose purpose and context.",29,data/crawl/squid/hunk_4220.cpp,,,data/crawl/squid/old_hunk_4220.cpp,data/crawl/squid/new_hunk_4220.cpp,6,3,"initiateClose(""STREAM_UNPLANNED_COMPLETE|STREAM_FAILED"");","initiateClose(""STREAM_UNPLANNED_COMPLETE"");","[""updateContent""]","[[""STREAM_FAILED""], []]",[3085963687330655591],6323,720.0,2
https://github.com/squid-cache/squid/commit/b2b07b928b4caaadecc4059f99e33880e0089e3c,21 Sep 2008,"Content-Language headers

Adds ""Content-Language"" header properly if the error page language was
negotiated. Hard codes the default templates as 'en', and the squid.conf
value for soft default language of error_default_language was used.

Sets ""Vary: Accept-Language"" if negotiation is configured to take place.",46,data/crawl/squid/hunk_4213.cpp,,,data/crawl/squid/old_hunk_4213.cpp,data/crawl/squid/new_hunk_4213.cpp,-1,27,,"httpHeaderPutStrf(&rep->header, HDR_CONTENT_LANGUAGE, ""en"");","[""addLog""]","[[], [""httpHeaderPutStrf"", ""&rep"", ""header"", ""HDR_CONTENT_LANGUAGE"", ""en""]]",[499558517842474346],6322,5760.0,2
https://github.com/squid-cache/squid/commit/b2b07b928b4caaadecc4059f99e33880e0089e3c,21 Sep 2008,"Content-Language headers

Adds ""Content-Language"" header properly if the error page language was
negotiated. Hard codes the default templates as 'en', and the squid.conf
value for soft default language of error_default_language was used.

Sets ""Vary: Accept-Language"" if negotiation is configured to take place.",46,data/crawl/squid/hunk_4213.cpp,,,data/crawl/squid/old_hunk_4213.cpp,data/crawl/squid/new_hunk_4213.cpp,-1,19,,"httpHeaderPutStrf(&rep->header, HDR_CONTENT_LANGUAGE, ""%s"", err_language);","[""addLog""]","[[], [""httpHeaderPutStrf"", ""&rep"", ""header"", ""HDR_CONTENT_LANGUAGE"", ""%s"", ""err_language""]]",[4034035064471382903],6321,5760.0,2
https://github.com/squid-cache/squid/commit/b2b07b928b4caaadecc4059f99e33880e0089e3c,21 Sep 2008,"Content-Language headers

Adds ""Content-Language"" header properly if the error page language was
negotiated. Hard codes the default templates as 'en', and the squid.conf
value for soft default language of error_default_language was used.

Sets ""Vary: Accept-Language"" if negotiation is configured to take place.",46,data/crawl/squid/hunk_4213.cpp,,,data/crawl/squid/old_hunk_4213.cpp,data/crawl/squid/new_hunk_4213.cpp,-1,14,,"httpHeaderPutStrf(&rep->header, HDR_VARY, ""Accept-Language"");","[""addLog""]","[[], [""httpHeaderPutStrf"", ""&rep"", ""header"", ""HDR_VARY"", ""Accept"", ""Language""]]",[-27758946439854485837],6320,5760.0,2
https://github.com/squid-cache/squid/commit/3ff7facaa3dc851e09c963b354940370fe00b818,23 Sep 2008,"Cleanups: WCCP config

Adds text labels for WCCPv2 methods.
Admin can now use 'gre', 'l1', 'hash', 'mask' in appropriate places
instead of magic numbers.

Magic numbers still supported for backward compatability.",159,data/crawl/squid/hunk_4211.cpp,,,data/crawl/squid/old_hunk_4211.cpp,data/crawl/squid/new_hunk_4211.cpp,-1,87,,"storeAppendPrintf(e, ""%s mask\n"", label);","[""addLog""]","[[], [""storeAppendPrintf"", ""e"", ""%s"", ""mask\\n"", ""label""]]",[998743031190025684],6319,7920.0,2
https://github.com/squid-cache/squid/commit/3ff7facaa3dc851e09c963b354940370fe00b818,23 Sep 2008,"Cleanups: WCCP config

Adds text labels for WCCPv2 methods.
Admin can now use 'gre', 'l1', 'hash', 'mask' in appropriate places
instead of magic numbers.

Magic numbers still supported for backward compatability.",159,data/crawl/squid/hunk_4211.cpp,,,data/crawl/squid/old_hunk_4211.cpp,data/crawl/squid/new_hunk_4211.cpp,-1,84,,"storeAppendPrintf(e, ""%s hash\n"", label);","[""addLog""]","[[], [""storeAppendPrintf"", ""e"", ""%s"", ""hash\\n"", ""label""]]",[4439531265018932300],6318,7920.0,2
https://github.com/squid-cache/squid/commit/3ff7facaa3dc851e09c963b354940370fe00b818,23 Sep 2008,"Cleanups: WCCP config

Adds text labels for WCCPv2 methods.
Admin can now use 'gre', 'l1', 'hash', 'mask' in appropriate places
instead of magic numbers.

Magic numbers still supported for backward compatability.",159,data/crawl/squid/hunk_4211.cpp,,,data/crawl/squid/old_hunk_4211.cpp,data/crawl/squid/new_hunk_4211.cpp,-1,39,,"storeAppendPrintf(e, ""%s l2\n"", label);","[""addLog""]","[[], [""storeAppendPrintf"", ""e"", ""%s"", ""l2\\n"", ""label""]]",[2913227151504063712],6317,9360.0,2
https://github.com/squid-cache/squid/commit/3ff7facaa3dc851e09c963b354940370fe00b818,23 Sep 2008,"Cleanups: WCCP config

Adds text labels for WCCPv2 methods.
Admin can now use 'gre', 'l1', 'hash', 'mask' in appropriate places
instead of magic numbers.

Magic numbers still supported for backward compatability.",159,data/crawl/squid/hunk_4211.cpp,,,data/crawl/squid/old_hunk_4211.cpp,data/crawl/squid/new_hunk_4211.cpp,-1,36,,"storeAppendPrintf(e, ""%s gre\n"", label);","[""addLog""]","[[], [""storeAppendPrintf"", ""e"", ""%s"", ""gre\\n"", ""label""]]",[-2538537717342581857],6316,9360.0,2
https://github.com/squid-cache/squid/commit/ae5b4e1af356f125ee98d5d67da28995a7b38a71,23 Sep 2008,"Added Comm close handler for the data channel of FtpStateData
transaction in preparation for officially dropping connect callbacks for
closing descriptors.

The data channel can be opened and closed a few times and the descriptor
must be kept in sync with the close handler. I factored out the
open/closing code into a simple FtpChannel class. That class is now used
for both FTP control and data channels.

The changes resolve one XXX discussion regarding FTP not having a close
handler for the data channel. On the other hand, adding a second close
handler attached to the same transaction is not a trivial change as the
side-effects of Squid cleanup code are often illusive.

For example, I suspect that FTP cleanup code does not close or even
check the control channel. I added a DBG_IMPORTANT statement to test
whether the control channel remains open. Or should that be an assert()?

I think that only one out of the two callbacks can be dialed because the
close handler executed first will invalidate the transaction object.",167,data/crawl/squid/hunk_4203.cpp,,,data/crawl/squid/old_hunk_4203.cpp,data/crawl/squid/new_hunk_4203.cpp,-1,16,,"failed(ERR_FTP_FAILURE, 0);","[""addLog""]","[[], [""failed"", ""ERR_FTP_FAILURE"", ""0""]]",[-11611541700384122136],6315,720.0,2
https://github.com/squid-cache/squid/commit/2170db3ef67ba8810c35fbfa3affa845deb88b3f,24 Sep 2008,Show request and reply headers new config via cachemgr dump,16,data/crawl/squid/hunk_4201.cpp,,,data/crawl/squid/old_hunk_4201.cpp,data/crawl/squid/new_hunk_4201.cpp,-1,19,,"storeAppendPrintf(sentry, "" %%<{%s:%s}"", format->header, format->member);","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""%%"", ""%s"", ""%s"", ""format"", ""header"", ""format"", ""member""]]",[12951319293946202013],6314,1645200.0,2
https://github.com/squid-cache/squid/commit/2170db3ef67ba8810c35fbfa3affa845deb88b3f,24 Sep 2008,Show request and reply headers new config via cachemgr dump,16,data/crawl/squid/hunk_4201.cpp,,,data/crawl/squid/old_hunk_4201.cpp,data/crawl/squid/new_hunk_4201.cpp,-1,14,,"storeAppendPrintf(sentry, "" %%<{%s}"", format->header);","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""%%"", ""%s"", ""format"", ""header""]]",[3131119357339662664],6313,1645200.0,2
https://github.com/squid-cache/squid/commit/223901927d51abc6759356742b74a1c623818d14,30 Sep 2008,"eCAP support, phase 2: Implemented libecap interfaces, added eCAP
squid.conf options. Link with libecap when eCAP support is enabled.

eCAP code needs polishing and enhancement but appears to work for a few
targeted cases. I am committing this now so that users working on eCAP
modules can test and provide more specific feedback.

These adaptation-specific changes should not have significant effect on
core code.

The libecap library is available at http://www.e-cap.org/",1758,data/crawl/squid/hunk_4187.cpp,,,data/crawl/squid/old_hunk_4187.cpp,data/crawl/squid/new_hunk_4187.cpp,-1,315,,"mustStop(""adaptationAborted"");","[""addLog""]","[[], [""mustStop"", ""adaptationAborted""]]",[-1568400234765993140],6312,720.0,2
https://github.com/squid-cache/squid/commit/5c7a6e90a7d87963e81a67ee8143eeb998ade3a9,06 Oct 2008,"Author: Markus Moeller <markus_moeller@compuserve.com>
Update squid_kerb_auth helper to 1.0.3 release

Also add missing config.test file (empty) so
 --enable-negotiate-auth-helpers=X will build it with Squid.


  squid_kerb_auth 1.0.3 Official ReadMe file:

--------------------------------------------------------------------------------
readme.txt is the squid_kerb_auth read-me file.

Author: Markus Moeller (markus_moeller at compuserve.com)

Copyright (C) 2007 Markus Moeller. All rights reserved.
--------------------------------------------------------------------------------

squid_kerb_auth Read Me

Markus Moeller
May 12, 2007

1 Introduction

squid_kerb_auth is a reference implementation that supports authentication via 
the Negotiate RFC 4559 for proxies. It decodes RFC 2478 SPNEGO GSS-API tokens 
from IE7 either through helper functions or via SPNEGO supporting Kerberos libraries
and RFC 1964 Kerberos tokens from Firefox on Linux. Currently, squid_kerb_auth
 supports Squid 2.6 on Linux. 

squid_auth_kerb requires either MIT or Heimdal Kerberos libraries and header files.

2 Building and Installation

Run ./configure

for help use ./configure --help

Copy the helper squid_kerb_auth to an apropriate directory.

3 Configuration

a) Configure IE or Firefox to point to the squid proxy by using the fqdn. IE and Firefox will use the
fqdn to query for a HTTP/fqdn Kerberos service principal. 

b) Create a keytab which contains the HTTP/fqdn Kerberos service principal and place it into a directory
where the squid run user can read the keytab. 

c) Add the following line to squid.conf

auth_param negotiate program /usr/sbin/squid_kerb_auth 
auth_param negotiate children 10
auth_param negotiate keep_alive on

d) Modify squid startup file

Add the following lines to the squid startup script to point squid to a keytab file which
contains the HTTP/fqdn service principal for the default Kerberos domain. The fqdn must be 
the proxy name set in IE or firefox. You can not use an IP address.

KRB5_KTNAME=/etc/squid/HTTP.keytab
export KRB5_KTNAME

If you use a different Kerberos domain than the machine itself is in you can point squid to 
the seperate Kerberos config file by setting the following environmnet variable in the startup 
script.

KRB5_CONFIG=/etc/krb-squid5.conf
export KRB5_CONFIG

4 Miscellaneous

If squid_kerb_auth doesn't determine for some reason the right service principal you can provide 
it with -s HTTP/fqdn.

If you serve multiple Kerberos realms add a HTTP/fqdn@REALM service principal per realm to the 
HTTP.keytab file and use the -s GSS_C_NO_NAME option with squid_kerb_auth.",1834,data/crawl/squid/hunk_4164.cpp,,,data/crawl/squid/old_hunk_4164.cpp,data/crawl/squid/new_hunk_4164.cpp,17,17,"fprintf(stdout, ""NA No token to return to continue\n"");","fprintf(stdout, ""NA %s\n"",token);","[""updateContent"", ""addVariable""]","[[""No"", ""to"", ""return"", ""to"", ""continue\\n""], [""%s\\n""]]",[6781769196105687938],6311,2160.0,2
https://github.com/squid-cache/squid/commit/5c7a6e90a7d87963e81a67ee8143eeb998ade3a9,06 Oct 2008,"Author: Markus Moeller <markus_moeller@compuserve.com>
Update squid_kerb_auth helper to 1.0.3 release

Also add missing config.test file (empty) so
 --enable-negotiate-auth-helpers=X will build it with Squid.


  squid_kerb_auth 1.0.3 Official ReadMe file:

--------------------------------------------------------------------------------
readme.txt is the squid_kerb_auth read-me file.

Author: Markus Moeller (markus_moeller at compuserve.com)

Copyright (C) 2007 Markus Moeller. All rights reserved.
--------------------------------------------------------------------------------

squid_kerb_auth Read Me

Markus Moeller
May 12, 2007

1 Introduction

squid_kerb_auth is a reference implementation that supports authentication via 
the Negotiate RFC 4559 for proxies. It decodes RFC 2478 SPNEGO GSS-API tokens 
from IE7 either through helper functions or via SPNEGO supporting Kerberos libraries
and RFC 1964 Kerberos tokens from Firefox on Linux. Currently, squid_kerb_auth
 supports Squid 2.6 on Linux. 

squid_auth_kerb requires either MIT or Heimdal Kerberos libraries and header files.

2 Building and Installation

Run ./configure

for help use ./configure --help

Copy the helper squid_kerb_auth to an apropriate directory.

3 Configuration

a) Configure IE or Firefox to point to the squid proxy by using the fqdn. IE and Firefox will use the
fqdn to query for a HTTP/fqdn Kerberos service principal. 

b) Create a keytab which contains the HTTP/fqdn Kerberos service principal and place it into a directory
where the squid run user can read the keytab. 

c) Add the following line to squid.conf

auth_param negotiate program /usr/sbin/squid_kerb_auth 
auth_param negotiate children 10
auth_param negotiate keep_alive on

d) Modify squid startup file

Add the following lines to the squid startup script to point squid to a keytab file which
contains the HTTP/fqdn service principal for the default Kerberos domain. The fqdn must be 
the proxy name set in IE or firefox. You can not use an IP address.

KRB5_KTNAME=/etc/squid/HTTP.keytab
export KRB5_KTNAME

If you use a different Kerberos domain than the machine itself is in you can point squid to 
the seperate Kerberos config file by setting the following environmnet variable in the startup 
script.

KRB5_CONFIG=/etc/krb-squid5.conf
export KRB5_CONFIG

4 Miscellaneous

If squid_kerb_auth doesn't determine for some reason the right service principal you can provide 
it with -s HTTP/fqdn.

If you serve multiple Kerberos realms add a HTTP/fqdn@REALM service principal per realm to the 
HTTP.keytab file and use the -s GSS_C_NO_NAME option with squid_kerb_auth.",1834,data/crawl/squid/hunk_4157.cpp,,,data/crawl/squid/old_hunk_4157.cpp,data/crawl/squid/new_hunk_4157.cpp,9,9,"fprintf(stderr, ""%s| %s: Got '%s' from squid (length: %d).\n"", LogTime(), PROGRAM, buf?buf:""NULL"",length);","fprintf(stderr, ""%s| %s: Got '%s' from squid (length: %d).\n"", LogTime(), PROGRAM, buf,length);","[""moveVariable"", ""removeVariable"", ""removeContent""]","[[""buf"", ""NULL""], []]",[3839534270286458121],6310,2160.0,2
https://github.com/squid-cache/squid/commit/5c7a6e90a7d87963e81a67ee8143eeb998ade3a9,06 Oct 2008,"Author: Markus Moeller <markus_moeller@compuserve.com>
Update squid_kerb_auth helper to 1.0.3 release

Also add missing config.test file (empty) so
 --enable-negotiate-auth-helpers=X will build it with Squid.


  squid_kerb_auth 1.0.3 Official ReadMe file:

--------------------------------------------------------------------------------
readme.txt is the squid_kerb_auth read-me file.

Author: Markus Moeller (markus_moeller at compuserve.com)

Copyright (C) 2007 Markus Moeller. All rights reserved.
--------------------------------------------------------------------------------

squid_kerb_auth Read Me

Markus Moeller
May 12, 2007

1 Introduction

squid_kerb_auth is a reference implementation that supports authentication via 
the Negotiate RFC 4559 for proxies. It decodes RFC 2478 SPNEGO GSS-API tokens 
from IE7 either through helper functions or via SPNEGO supporting Kerberos libraries
and RFC 1964 Kerberos tokens from Firefox on Linux. Currently, squid_kerb_auth
 supports Squid 2.6 on Linux. 

squid_auth_kerb requires either MIT or Heimdal Kerberos libraries and header files.

2 Building and Installation

Run ./configure

for help use ./configure --help

Copy the helper squid_kerb_auth to an apropriate directory.

3 Configuration

a) Configure IE or Firefox to point to the squid proxy by using the fqdn. IE and Firefox will use the
fqdn to query for a HTTP/fqdn Kerberos service principal. 

b) Create a keytab which contains the HTTP/fqdn Kerberos service principal and place it into a directory
where the squid run user can read the keytab. 

c) Add the following line to squid.conf

auth_param negotiate program /usr/sbin/squid_kerb_auth 
auth_param negotiate children 10
auth_param negotiate keep_alive on

d) Modify squid startup file

Add the following lines to the squid startup script to point squid to a keytab file which
contains the HTTP/fqdn service principal for the default Kerberos domain. The fqdn must be 
the proxy name set in IE or firefox. You can not use an IP address.

KRB5_KTNAME=/etc/squid/HTTP.keytab
export KRB5_KTNAME

If you use a different Kerberos domain than the machine itself is in you can point squid to 
the seperate Kerberos config file by setting the following environmnet variable in the startup 
script.

KRB5_CONFIG=/etc/krb-squid5.conf
export KRB5_CONFIG

4 Miscellaneous

If squid_kerb_auth doesn't determine for some reason the right service principal you can provide 
it with -s HTTP/fqdn.

If you serve multiple Kerberos realms add a HTTP/fqdn@REALM service principal per realm to the 
HTTP.keytab file and use the -s GSS_C_NO_NAME option with squid_kerb_auth.",1834,data/crawl/squid/hunk_4155.cpp,,,data/crawl/squid/old_hunk_4155.cpp,data/crawl/squid/new_hunk_4155.cpp,13,32,"fprintf(stdout, ""default SPN is HTTP/fqdn@DEFAULT_REALM\n"");","fprintf(stdout, ""BH hostname error\n"");","[""updateContent""]","[[""default"", ""SPN"", ""is"", ""HTTP/fqdn"", ""DEFAULT_REALM\\n""], [""BH"", ""hostname"", ""error\\n""]]",[2944909987115973973],6309,2160.0,2
https://github.com/squid-cache/squid/commit/5c7a6e90a7d87963e81a67ee8143eeb998ade3a9,06 Oct 2008,"Author: Markus Moeller <markus_moeller@compuserve.com>
Update squid_kerb_auth helper to 1.0.3 release

Also add missing config.test file (empty) so
 --enable-negotiate-auth-helpers=X will build it with Squid.


  squid_kerb_auth 1.0.3 Official ReadMe file:

--------------------------------------------------------------------------------
readme.txt is the squid_kerb_auth read-me file.

Author: Markus Moeller (markus_moeller at compuserve.com)

Copyright (C) 2007 Markus Moeller. All rights reserved.
--------------------------------------------------------------------------------

squid_kerb_auth Read Me

Markus Moeller
May 12, 2007

1 Introduction

squid_kerb_auth is a reference implementation that supports authentication via 
the Negotiate RFC 4559 for proxies. It decodes RFC 2478 SPNEGO GSS-API tokens 
from IE7 either through helper functions or via SPNEGO supporting Kerberos libraries
and RFC 1964 Kerberos tokens from Firefox on Linux. Currently, squid_kerb_auth
 supports Squid 2.6 on Linux. 

squid_auth_kerb requires either MIT or Heimdal Kerberos libraries and header files.

2 Building and Installation

Run ./configure

for help use ./configure --help

Copy the helper squid_kerb_auth to an apropriate directory.

3 Configuration

a) Configure IE or Firefox to point to the squid proxy by using the fqdn. IE and Firefox will use the
fqdn to query for a HTTP/fqdn Kerberos service principal. 

b) Create a keytab which contains the HTTP/fqdn Kerberos service principal and place it into a directory
where the squid run user can read the keytab. 

c) Add the following line to squid.conf

auth_param negotiate program /usr/sbin/squid_kerb_auth 
auth_param negotiate children 10
auth_param negotiate keep_alive on

d) Modify squid startup file

Add the following lines to the squid startup script to point squid to a keytab file which
contains the HTTP/fqdn service principal for the default Kerberos domain. The fqdn must be 
the proxy name set in IE or firefox. You can not use an IP address.

KRB5_KTNAME=/etc/squid/HTTP.keytab
export KRB5_KTNAME

If you use a different Kerberos domain than the machine itself is in you can point squid to 
the seperate Kerberos config file by setting the following environmnet variable in the startup 
script.

KRB5_CONFIG=/etc/krb-squid5.conf
export KRB5_CONFIG

4 Miscellaneous

If squid_kerb_auth doesn't determine for some reason the right service principal you can provide 
it with -s HTTP/fqdn.

If you serve multiple Kerberos realms add a HTTP/fqdn@REALM service principal per realm to the 
HTTP.keytab file and use the -s GSS_C_NO_NAME option with squid_kerb_auth.",1834,data/crawl/squid/hunk_4155.cpp,,,data/crawl/squid/old_hunk_4155.cpp,data/crawl/squid/new_hunk_4155.cpp,12,15,"fprintf(stdout, ""Can be set to GSS_C_NO_NAME to allow any entry from keytab\n"");","fprintf(stderr, ""The SPN can be set to GSS_C_NO_NAME to allow any entry from keytab\n"");","[""updateVariable"", ""updateContent""]","[[""stdout"", ""Can""], [""stderr"", ""The"", ""SPN"", ""can""]]",[-1864400356647439745],6308,2160.0,2
https://github.com/squid-cache/squid/commit/5c7a6e90a7d87963e81a67ee8143eeb998ade3a9,06 Oct 2008,"Author: Markus Moeller <markus_moeller@compuserve.com>
Update squid_kerb_auth helper to 1.0.3 release

Also add missing config.test file (empty) so
 --enable-negotiate-auth-helpers=X will build it with Squid.


  squid_kerb_auth 1.0.3 Official ReadMe file:

--------------------------------------------------------------------------------
readme.txt is the squid_kerb_auth read-me file.

Author: Markus Moeller (markus_moeller at compuserve.com)

Copyright (C) 2007 Markus Moeller. All rights reserved.
--------------------------------------------------------------------------------

squid_kerb_auth Read Me

Markus Moeller
May 12, 2007

1 Introduction

squid_kerb_auth is a reference implementation that supports authentication via 
the Negotiate RFC 4559 for proxies. It decodes RFC 2478 SPNEGO GSS-API tokens 
from IE7 either through helper functions or via SPNEGO supporting Kerberos libraries
and RFC 1964 Kerberos tokens from Firefox on Linux. Currently, squid_kerb_auth
 supports Squid 2.6 on Linux. 

squid_auth_kerb requires either MIT or Heimdal Kerberos libraries and header files.

2 Building and Installation

Run ./configure

for help use ./configure --help

Copy the helper squid_kerb_auth to an apropriate directory.

3 Configuration

a) Configure IE or Firefox to point to the squid proxy by using the fqdn. IE and Firefox will use the
fqdn to query for a HTTP/fqdn Kerberos service principal. 

b) Create a keytab which contains the HTTP/fqdn Kerberos service principal and place it into a directory
where the squid run user can read the keytab. 

c) Add the following line to squid.conf

auth_param negotiate program /usr/sbin/squid_kerb_auth 
auth_param negotiate children 10
auth_param negotiate keep_alive on

d) Modify squid startup file

Add the following lines to the squid startup script to point squid to a keytab file which
contains the HTTP/fqdn service principal for the default Kerberos domain. The fqdn must be 
the proxy name set in IE or firefox. You can not use an IP address.

KRB5_KTNAME=/etc/squid/HTTP.keytab
export KRB5_KTNAME

If you use a different Kerberos domain than the machine itself is in you can point squid to 
the seperate Kerberos config file by setting the following environmnet variable in the startup 
script.

KRB5_CONFIG=/etc/krb-squid5.conf
export KRB5_CONFIG

4 Miscellaneous

If squid_kerb_auth doesn't determine for some reason the right service principal you can provide 
it with -s HTTP/fqdn.

If you serve multiple Kerberos realms add a HTTP/fqdn@REALM service principal per realm to the 
HTTP.keytab file and use the -s GSS_C_NO_NAME option with squid_kerb_auth.",1834,data/crawl/squid/hunk_4155.cpp,,,data/crawl/squid/old_hunk_4155.cpp,data/crawl/squid/new_hunk_4155.cpp,11,13,"fprintf(stdout, ""SPN = service principal name\n"");","fprintf(stderr, ""-s service principal name\n"");","[""updateVariable"", ""updateContent""]","[[""stdout"", ""SPN""], [""stderr"", ""s""]]",[369181436732835403],6307,2160.0,2
https://github.com/squid-cache/squid/commit/5c7a6e90a7d87963e81a67ee8143eeb998ade3a9,06 Oct 2008,"Author: Markus Moeller <markus_moeller@compuserve.com>
Update squid_kerb_auth helper to 1.0.3 release

Also add missing config.test file (empty) so
 --enable-negotiate-auth-helpers=X will build it with Squid.


  squid_kerb_auth 1.0.3 Official ReadMe file:

--------------------------------------------------------------------------------
readme.txt is the squid_kerb_auth read-me file.

Author: Markus Moeller (markus_moeller at compuserve.com)

Copyright (C) 2007 Markus Moeller. All rights reserved.
--------------------------------------------------------------------------------

squid_kerb_auth Read Me

Markus Moeller
May 12, 2007

1 Introduction

squid_kerb_auth is a reference implementation that supports authentication via 
the Negotiate RFC 4559 for proxies. It decodes RFC 2478 SPNEGO GSS-API tokens 
from IE7 either through helper functions or via SPNEGO supporting Kerberos libraries
and RFC 1964 Kerberos tokens from Firefox on Linux. Currently, squid_kerb_auth
 supports Squid 2.6 on Linux. 

squid_auth_kerb requires either MIT or Heimdal Kerberos libraries and header files.

2 Building and Installation

Run ./configure

for help use ./configure --help

Copy the helper squid_kerb_auth to an apropriate directory.

3 Configuration

a) Configure IE or Firefox to point to the squid proxy by using the fqdn. IE and Firefox will use the
fqdn to query for a HTTP/fqdn Kerberos service principal. 

b) Create a keytab which contains the HTTP/fqdn Kerberos service principal and place it into a directory
where the squid run user can read the keytab. 

c) Add the following line to squid.conf

auth_param negotiate program /usr/sbin/squid_kerb_auth 
auth_param negotiate children 10
auth_param negotiate keep_alive on

d) Modify squid startup file

Add the following lines to the squid startup script to point squid to a keytab file which
contains the HTTP/fqdn service principal for the default Kerberos domain. The fqdn must be 
the proxy name set in IE or firefox. You can not use an IP address.

KRB5_KTNAME=/etc/squid/HTTP.keytab
export KRB5_KTNAME

If you use a different Kerberos domain than the machine itself is in you can point squid to 
the seperate Kerberos config file by setting the following environmnet variable in the startup 
script.

KRB5_CONFIG=/etc/krb-squid5.conf
export KRB5_CONFIG

4 Miscellaneous

If squid_kerb_auth doesn't determine for some reason the right service principal you can provide 
it with -s HTTP/fqdn.

If you serve multiple Kerberos realms add a HTTP/fqdn@REALM service principal per realm to the 
HTTP.keytab file and use the -s GSS_C_NO_NAME option with squid_kerb_auth.",1834,data/crawl/squid/hunk_4155.cpp,,,data/crawl/squid/old_hunk_4155.cpp,data/crawl/squid/new_hunk_4155.cpp,10,10,"fprintf(stdout, ""squid_kerb_auth -d [-s SPN]\n"");","fprintf(stderr, ""squid_kerb_auth [-d] [-i] [-s SPN] [-h]\n"");","[""updateVariable"", ""updateContent""]","[[""stdout"", ""d"", ""SPN]\\n""], [""stderr"", ""d]"", ""["", ""i]"", ""["", ""SPN]"", ""["", ""h]\\n""]]",[6469574754496635586],6306,2160.0,2
https://github.com/squid-cache/squid/commit/5c7a6e90a7d87963e81a67ee8143eeb998ade3a9,06 Oct 2008,"Author: Markus Moeller <markus_moeller@compuserve.com>
Update squid_kerb_auth helper to 1.0.3 release

Also add missing config.test file (empty) so
 --enable-negotiate-auth-helpers=X will build it with Squid.


  squid_kerb_auth 1.0.3 Official ReadMe file:

--------------------------------------------------------------------------------
readme.txt is the squid_kerb_auth read-me file.

Author: Markus Moeller (markus_moeller at compuserve.com)

Copyright (C) 2007 Markus Moeller. All rights reserved.
--------------------------------------------------------------------------------

squid_kerb_auth Read Me

Markus Moeller
May 12, 2007

1 Introduction

squid_kerb_auth is a reference implementation that supports authentication via 
the Negotiate RFC 4559 for proxies. It decodes RFC 2478 SPNEGO GSS-API tokens 
from IE7 either through helper functions or via SPNEGO supporting Kerberos libraries
and RFC 1964 Kerberos tokens from Firefox on Linux. Currently, squid_kerb_auth
 supports Squid 2.6 on Linux. 

squid_auth_kerb requires either MIT or Heimdal Kerberos libraries and header files.

2 Building and Installation

Run ./configure

for help use ./configure --help

Copy the helper squid_kerb_auth to an apropriate directory.

3 Configuration

a) Configure IE or Firefox to point to the squid proxy by using the fqdn. IE and Firefox will use the
fqdn to query for a HTTP/fqdn Kerberos service principal. 

b) Create a keytab which contains the HTTP/fqdn Kerberos service principal and place it into a directory
where the squid run user can read the keytab. 

c) Add the following line to squid.conf

auth_param negotiate program /usr/sbin/squid_kerb_auth 
auth_param negotiate children 10
auth_param negotiate keep_alive on

d) Modify squid startup file

Add the following lines to the squid startup script to point squid to a keytab file which
contains the HTTP/fqdn service principal for the default Kerberos domain. The fqdn must be 
the proxy name set in IE or firefox. You can not use an IP address.

KRB5_KTNAME=/etc/squid/HTTP.keytab
export KRB5_KTNAME

If you use a different Kerberos domain than the machine itself is in you can point squid to 
the seperate Kerberos config file by setting the following environmnet variable in the startup 
script.

KRB5_CONFIG=/etc/krb-squid5.conf
export KRB5_CONFIG

4 Miscellaneous

If squid_kerb_auth doesn't determine for some reason the right service principal you can provide 
it with -s HTTP/fqdn.

If you serve multiple Kerberos realms add a HTTP/fqdn@REALM service principal per realm to the 
HTTP.keytab file and use the -s GSS_C_NO_NAME option with squid_kerb_auth.",1834,data/crawl/squid/hunk_4155.cpp,,,data/crawl/squid/old_hunk_4155.cpp,data/crawl/squid/new_hunk_4155.cpp,9,9,"fprintf(stdout, ""Usage: \n"");","fprintf(stderr, ""Usage: \n"");","[""updateVariable""]","[[""stdout""], [""stderr""]]",[6000001000175],6305,2160.0,2
https://github.com/squid-cache/squid/commit/70d1b64c05b0453cbd5541db8095a12bf390b613,13 Oct 2008,Remove several unnecessary uses of putStrf and a compile error,8,data/crawl/squid/hunk_4067.cpp,,,data/crawl/squid/old_hunk_4067.cpp,data/crawl/squid/new_hunk_4067.cpp,4,4,"httpHeaderPutStrf(&rep->header, HDR_VARY, ""Accept-Language"");","rep->header.putStr(HDR_VARY, ""Accept-Language"");","[""addLog"", ""removeVariable"", ""removeLog""]","[[""httpHeaderPutStrf"", ""&rep""], [""rep"", ""putStr""]]",[-3050469503700037925],6304,0.0,2
https://github.com/squid-cache/squid/commit/c76ec3b7646eec9121a8633ff80cd3a7c3f3f105,17 Oct 2008,"Author: Francesco Chemolli <kinkie@squid-cache.org>
Bug 2489: Testsuite doesn't obey authentication scheme ./configure parameters

I've added a couple of AC_DEFINEs and a couple of #ifdefs to make the
offending tests conditional on the actually-built builtin auth-methods.",48,data/crawl/squid/hunk_4063.cpp,,,data/crawl/squid/old_hunk_4063.cpp,data/crawl/squid/new_hunk_4063.cpp,-1,10,,"fprintf(stderr,""Skipping unknown authentication scheme '%s'.\n"", 
                params[scheme].name);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""Skipping"", ""unknown"", ""authentication"", ""scheme"", ""%s"", ""\\n"", ""params[scheme]"", ""name""]]",[-43743832057587395133],6303,720.0,2
https://github.com/squid-cache/squid/commit/c76ec3b7646eec9121a8633ff80cd3a7c3f3f105,17 Oct 2008,"Author: Francesco Chemolli <kinkie@squid-cache.org>
Bug 2489: Testsuite doesn't obey authentication scheme ./configure parameters

I've added a couple of AC_DEFINEs and a couple of #ifdefs to make the
offending tests conditional on the actually-built builtin auth-methods.",48,data/crawl/squid/hunk_4062.cpp,,,data/crawl/squid/old_hunk_4062.cpp,data/crawl/squid/new_hunk_4062.cpp,3,-1,"fatalf(""Unknown authentication scheme '%s'.\n"", type_str);",,"[""removeLog""]","[[""fatalf"", ""Unknown"", ""authentication"", ""scheme"", ""%s"", ""\\n"", ""type_str""], []]",[14800519309887117090],6302,720.0,2
https://github.com/squid-cache/squid/commit/12f45551aa4cd1a157722d040b9d5f9b38f18116,08 Nov 2008,"IPAddress tests and corrections.

Fixes two cases where GetSockAddr did not set sin*_len properly

Fixes configure tests for sin*_len

TODO: still to find and fix where we are getting on FreeBSD:
 SYS SS_LEN=16
 SQD SS_LEN=0    (should be 16)",68,data/crawl/squid/hunk_4054.cpp,,,data/crawl/squid/old_hunk_4054.cpp,data/crawl/squid/new_hunk_4054.cpp,-1,16,,"printf(""\nSYS SS_LEN=%d\nSQD SS_LEN=%d\n"",((struct sockaddr_storage*)expect->ai_addr)->ss_len,
           ((struct sockaddr_storage*)ipval->ai_addr)->ss_len );","[""addLog""]","[[], [""printf"", ""\\nSYS"", ""SS_LEN"", ""%d\\nSQD"", ""SS_LEN"", ""%d\\n"", ""struct"", ""sockaddr_storage*"", ""expect"", ""ai_addr"", ""ss_len"", ""struct"", ""sockaddr_storage*"", ""ipval"", ""ai_addr"", ""ss_len""]]",[-28083088864157364770],6301,0.0,2
https://github.com/squid-cache/squid/commit/12f45551aa4cd1a157722d040b9d5f9b38f18116,08 Nov 2008,"IPAddress tests and corrections.

Fixes two cases where GetSockAddr did not set sin*_len properly

Fixes configure tests for sin*_len

TODO: still to find and fix where we are getting on FreeBSD:
 SYS SS_LEN=16
 SQD SS_LEN=0    (should be 16)",68,data/crawl/squid/hunk_4053.cpp,,,data/crawl/squid/old_hunk_4053.cpp,data/crawl/squid/new_hunk_4053.cpp,3,3,"printf(""\nSYS-ADDRINFO: %x %x %x %x %x %x "",
           p[0],p[1],p[2],p[3],p[4],p[5] );","printf(""\nSYS-ADDRINFO: %2x %2x %2x %2x %2x %2x"",
           p[0],p[1],p[2],p[3],p[4],p[5]);","[""updateContent""]","[[""%x"", ""%x"", ""%x"", ""%x"", ""%x"", ""%x""], [""%2x"", ""%2x"", ""%2x"", ""%2x"", ""%2x"", ""%2x""]]",[-28651811062390079094],6300,0.0,2
https://github.com/squid-cache/squid/commit/488b27c52bc2279046ed0cd6e17da2c8f5d87fb7,25 Nov 2008,"Fix cache_peer forceddomainname when request has a Host header

cache_peer forceddomainname=xxx only worked when the received request
did not have a Host header.",5,data/crawl/squid/hunk_4049.cpp,,,data/crawl/squid/old_hunk_4049.cpp,data/crawl/squid/new_hunk_4049.cpp,-1,4,,"hdr_out->putStr(HDR_HOST, orig_request->peer_domain);","[""addLog""]","[[], [""hdr_out"", ""putStr"", ""HDR_HOST"", ""orig_request"", ""peer_domain""]]",[-4977278106915381522],6299,671760.0,2
https://github.com/squid-cache/squid/commit/ba0beb01c625b8acb4087a7ca66bdcb058f9ee1b,24 Dec 2008,"Polish ZPH configuration interface

This completes the ZPH patch merge for Squid 3.1. It makes significant
changes to the squid.conf options previously used.

ZPH controls are now formally called ""qos_flows"" with a set of options
to set individual output flow TOS based on the flow source. see squid.conf
documentation for details.

Since this is new IP-layer code it also places the new QoS code in a
directory src/ip/ and library libip.la inline with the planned source
layout model.",359,data/crawl/squid/hunk_4027.cpp,,,data/crawl/squid/old_hunk_4027.cpp,data/crawl/squid/new_hunk_4027.cpp,-1,63,,"storeAppendPrintf(entry, "" miss-mask=%2x"", preserve_miss_tos_mask);","[""addLog""]","[[], [""storeAppendPrintf"", ""entry"", ""miss"", ""mask"", ""%2x"", ""preserve_miss_tos_mask""]]",[-17975796826970123251],6298,25200.0,2
https://github.com/squid-cache/squid/commit/ba0beb01c625b8acb4087a7ca66bdcb058f9ee1b,24 Dec 2008,"Polish ZPH configuration interface

This completes the ZPH patch merge for Squid 3.1. It makes significant
changes to the squid.conf options previously used.

ZPH controls are now formally called ""qos_flows"" with a set of options
to set individual output flow TOS based on the flow source. see squid.conf
documentation for details.

Since this is new IP-layer code it also places the new QoS code in a
directory src/ip/ and library libip.la inline with the planned source
layout model.",359,data/crawl/squid/hunk_4027.cpp,,,data/crawl/squid/old_hunk_4027.cpp,data/crawl/squid/new_hunk_4027.cpp,-1,60,,"storeAppendPrintf(entry, "" disable-preserve-miss"");","[""addLog""]","[[], [""storeAppendPrintf"", ""entry"", ""disable"", ""preserve"", ""miss""]]",[-18883107819221956665],6297,25200.0,2
https://github.com/squid-cache/squid/commit/ba0beb01c625b8acb4087a7ca66bdcb058f9ee1b,24 Dec 2008,"Polish ZPH configuration interface

This completes the ZPH patch merge for Squid 3.1. It makes significant
changes to the squid.conf options previously used.

ZPH controls are now formally called ""qos_flows"" with a set of options
to set individual output flow TOS based on the flow source. see squid.conf
documentation for details.

Since this is new IP-layer code it also places the new QoS code in a
directory src/ip/ and library libip.la inline with the planned source
layout model.",359,data/crawl/squid/hunk_4027.cpp,,,data/crawl/squid/old_hunk_4027.cpp,data/crawl/squid/new_hunk_4027.cpp,-1,57,,"storeAppendPrintf(entry, "" parent-hit=%2x"", tos_parent_hit);","[""addLog""]","[[], [""storeAppendPrintf"", ""entry"", ""parent"", ""hit"", ""%2x"", ""tos_parent_hit""]]",[-20364353045639613613],6296,25200.0,2
https://github.com/squid-cache/squid/commit/ba0beb01c625b8acb4087a7ca66bdcb058f9ee1b,24 Dec 2008,"Polish ZPH configuration interface

This completes the ZPH patch merge for Squid 3.1. It makes significant
changes to the squid.conf options previously used.

ZPH controls are now formally called ""qos_flows"" with a set of options
to set individual output flow TOS based on the flow source. see squid.conf
documentation for details.

Since this is new IP-layer code it also places the new QoS code in a
directory src/ip/ and library libip.la inline with the planned source
layout model.",359,data/crawl/squid/hunk_4027.cpp,,,data/crawl/squid/old_hunk_4027.cpp,data/crawl/squid/new_hunk_4027.cpp,-1,54,,"storeAppendPrintf(entry, "" sibling-hit=%2x"", tos_sibling_hit);","[""addLog""]","[[], [""storeAppendPrintf"", ""entry"", ""sibling"", ""hit"", ""%2x"", ""tos_sibling_hit""]]",[154879772627979421],6295,25200.0,2
https://github.com/squid-cache/squid/commit/ba0beb01c625b8acb4087a7ca66bdcb058f9ee1b,24 Dec 2008,"Polish ZPH configuration interface

This completes the ZPH patch merge for Squid 3.1. It makes significant
changes to the squid.conf options previously used.

ZPH controls are now formally called ""qos_flows"" with a set of options
to set individual output flow TOS based on the flow source. see squid.conf
documentation for details.

Since this is new IP-layer code it also places the new QoS code in a
directory src/ip/ and library libip.la inline with the planned source
layout model.",359,data/crawl/squid/hunk_4027.cpp,,,data/crawl/squid/old_hunk_4027.cpp,data/crawl/squid/new_hunk_4027.cpp,-1,50,,"storeAppendPrintf(entry, "" local-hit=%2x"", tos_local_hit);","[""addLog""]","[[], [""storeAppendPrintf"", ""entry"", ""local"", ""hit"", ""%2x"", ""tos_local_hit""]]",[-16247138471038499271],6294,25200.0,2
https://github.com/squid-cache/squid/commit/eca70f3b35a4c7b62467b2d93aa73dca72076271,07 Jan 2009,merge from trunk,9,data/crawl/squid/hunk_4019.cpp,,,data/crawl/squid/old_hunk_4019.cpp,data/crawl/squid/new_hunk_4019.cpp,3,4,"storeAppendPrintf(sentry, ""Name:    %s\n"", fqdnFromAddr(c->addr));","storeAppendPrintf(sentry, ""Name:    %s\n"", name);","[""removeVariable"", ""addVariable""]","[[""fqdnFromAddr"", ""c"", ""addr""], [""name""]]",[-9937693644189345390],6293,720.0,2
https://github.com/squid-cache/squid/commit/37d4da0c0793751c68f1b548ba2842ab59e10128,13 Jan 2009,"SourceLayout: migrate IPAddress into lipip.la

This also makes some small changes to other API inside libip to allow
libbip.la to be built first as a POD library before anything src/ gets built.

Anything added to it from this point on MUST NOT require linkage outside
of libip.la or the planned libcompat.",1431,data/crawl/squid/hunk_4010.cpp,,,data/crawl/squid/old_hunk_4010.cpp,data/crawl/squid/new_hunk_4010.cpp,24,36,"storeAppendPrintf(entry, ""\n"");","snprintf(p, 1, ""\n"");","[""updateVariable"", ""updateLog"", ""addContent""]","[[""storeAppendPrintf"", ""entry""], [""snprintf"", ""p"", ""1""]]",[-9620718947959649137],6292,2160.0,2
https://github.com/squid-cache/squid/commit/37d4da0c0793751c68f1b548ba2842ab59e10128,13 Jan 2009,"SourceLayout: migrate IPAddress into lipip.la

This also makes some small changes to other API inside libip to allow
libbip.la to be built first as a POD library before anything src/ gets built.

Anything added to it from this point on MUST NOT require linkage outside
of libip.la or the planned libcompat.",1431,data/crawl/squid/hunk_4010.cpp,,,data/crawl/squid/old_hunk_4010.cpp,data/crawl/squid/new_hunk_4010.cpp,19,29,"storeAppendPrintf(entry, "" disable-preserve-miss"");","snprintf(p, 22, "" disable-preserve-miss"");","[""updateVariable"", ""updateLog"", ""addContent""]","[[""storeAppendPrintf"", ""entry""], [""snprintf"", ""p"", ""22""]]",[-9614318915781610235],6291,2160.0,2
https://github.com/squid-cache/squid/commit/37d4da0c0793751c68f1b548ba2842ab59e10128,13 Jan 2009,"SourceLayout: migrate IPAddress into lipip.la

This also makes some small changes to other API inside libip to allow
libbip.la to be built first as a POD library before anything src/ gets built.

Anything added to it from this point on MUST NOT require linkage outside
of libip.la or the planned libcompat.",1431,data/crawl/squid/hunk_4010.cpp,,,data/crawl/squid/old_hunk_4010.cpp,data/crawl/squid/new_hunk_4010.cpp,16,25,"storeAppendPrintf(entry, "" parent-hit=%2x"", tos_parent_hit);","snprintf(p, 16, "" parent-hit=%2x"", tos_parent_hit);","[""updateVariable"", ""updateLog"", ""addContent""]","[[""storeAppendPrintf"", ""entry""], [""snprintf"", ""p"", ""16""]]",[-9614446916550611386],6290,2160.0,2
https://github.com/squid-cache/squid/commit/37d4da0c0793751c68f1b548ba2842ab59e10128,13 Jan 2009,"SourceLayout: migrate IPAddress into lipip.la

This also makes some small changes to other API inside libip to allow
libbip.la to be built first as a POD library before anything src/ gets built.

Anything added to it from this point on MUST NOT require linkage outside
of libip.la or the planned libcompat.",1431,data/crawl/squid/hunk_4010.cpp,,,data/crawl/squid/old_hunk_4010.cpp,data/crawl/squid/new_hunk_4010.cpp,13,21,"storeAppendPrintf(entry, "" sibling-hit=%2x"", tos_sibling_hit);","snprintf(p, 17, "" sibling-hit=%2x"", tos_sibling_hit);","[""updateVariable"", ""updateLog"", ""addContent""]","[[""storeAppendPrintf"", ""entry""], [""snprintf"", ""p"", ""17""]]",[-9614446916550611387],6289,2160.0,2
https://github.com/squid-cache/squid/commit/37d4da0c0793751c68f1b548ba2842ab59e10128,13 Jan 2009,"SourceLayout: migrate IPAddress into lipip.la

This also makes some small changes to other API inside libip to allow
libbip.la to be built first as a POD library before anything src/ gets built.

Anything added to it from this point on MUST NOT require linkage outside
of libip.la or the planned libcompat.",1431,data/crawl/squid/hunk_4010.cpp,,,data/crawl/squid/old_hunk_4010.cpp,data/crawl/squid/new_hunk_4010.cpp,6,12,"storeAppendPrintf(entry, ""%s"", name);","snprintf(p, 10, ""%s"", name);","[""updateVariable"", ""updateLog"", ""addContent""]","[[""storeAppendPrintf"", ""entry""], [""snprintf"", ""p"", ""10""]]",[-9614446916550611392],6288,2160.0,2
https://github.com/squid-cache/squid/commit/4ef877d67aaff7156b5611db55b45cb7c57a0120,06 Feb 2009,"Author: Francesco Chemolli <kinkie@squid-cache.org>
String NG : fixes initial merge, take 2

Compared to the retired first attempt it:
 - fixes the issues Tsantilas Christos found out about
 - implements String::find
 - some more users analyzed and fixed.",654,data/crawl/squid/hunk_3932.cpp,,,data/crawl/squid/old_hunk_3932.cpp,data/crawl/squid/new_hunk_3932.cpp,4,6,"buf.Printf(""Host: %s:%d\r\n"", s.cfg().host.buf(), s.cfg().port);","buf.Printf(""Host: %.*s:%d\r\n"", host.size(), host.rawBuf(), s.cfg().port);","[""updateVariable"", ""removeVariable"", ""updateContent""]","[[""%s"", ""buf"", ""s"", ""cfg""], [""%"", ""*s"", ""size"", ""host"", ""rawBuf""]]",[9340148467246749098],6287,5040.0,2
https://github.com/squid-cache/squid/commit/4ef877d67aaff7156b5611db55b45cb7c57a0120,06 Feb 2009,"Author: Francesco Chemolli <kinkie@squid-cache.org>
String NG : fixes initial merge, take 2

Compared to the retired first attempt it:
 - fixes the issues Tsantilas Christos found out about
 - implements String::find
 - some more users analyzed and fixed.",654,data/crawl/squid/hunk_3932.cpp,,,data/crawl/squid/old_hunk_3932.cpp,data/crawl/squid/new_hunk_3932.cpp,3,4,"buf.Printf(""OPTIONS %s ICAP/1.0\r\n"", s.cfg().uri.buf());","buf.Printf(""OPTIONS %.*s ICAP/1.0\r\n"", uri.size(), uri.rawBuf());","[""updateVariable"", ""removeVariable"", ""updateContent""]","[[""%s"", ""s"", ""cfg"", ""buf""], [""%"", ""*s"", ""size"", ""uri"", ""rawBuf""]]",[-1080724857384521019],6286,5040.0,2
https://github.com/squid-cache/squid/commit/4ef877d67aaff7156b5611db55b45cb7c57a0120,06 Feb 2009,"Author: Francesco Chemolli <kinkie@squid-cache.org>
String NG : fixes initial merge, take 2

Compared to the retired first attempt it:
 - fixes the issues Tsantilas Christos found out about
 - implements String::find
 - some more users analyzed and fixed.",654,data/crawl/squid/hunk_3930.cpp,,,data/crawl/squid/old_hunk_3930.cpp,data/crawl/squid/new_hunk_3930.cpp,4,4,"buf.Printf(""Host: %s:%d\r\n"", s.host.buf(), s.port);","buf.Printf(""Host: %.*s:%d\r\n"", s.host.size(), s.host.rawBuf(), s.port);","[""updateVariable"", ""updateContent"", ""addVariable""]","[[""%s"", ""buf""], [""%"", ""*s"", ""size"", ""host"", ""rawBuf"", ""s""]]",[8541117200873220119],6285,4320.0,2
https://github.com/squid-cache/squid/commit/4ef877d67aaff7156b5611db55b45cb7c57a0120,06 Feb 2009,"Author: Francesco Chemolli <kinkie@squid-cache.org>
String NG : fixes initial merge, take 2

Compared to the retired first attempt it:
 - fixes the issues Tsantilas Christos found out about
 - implements String::find
 - some more users analyzed and fixed.",654,data/crawl/squid/hunk_3930.cpp,,,data/crawl/squid/old_hunk_3930.cpp,data/crawl/squid/new_hunk_3930.cpp,3,3,"buf.Printf(""%s %s ICAP/1.0\r\n"", s.methodStr(), s.uri.buf());","buf.Printf(""%s %.*s ICAP/1.0\r\n"", s.methodStr(), s.uri.size(), s.uri.rawBuf());","[""updateVariable"", ""updateContent"", ""addVariable""]","[[""%s"", ""buf""], [""%"", ""*s"", ""size"", ""s"", ""uri"", ""rawBuf""]]",[-1879756123758049998],6284,4320.0,2
https://github.com/squid-cache/squid/commit/9b558d8af0aac1d453f395e5bd719780ad6954c4,09 Feb 2009,"Implemented String.psize() (for printf())
Changed String storage size from 'unsigned short int' to size_t
Implemented String.rfind()
Implemented String.substr() and related tests
Made String.set() private, it's ready to be removed unless there's any dissent
Converted ftp.cc to use rfind in place of rpos",154,data/crawl/squid/hunk_3905.cpp,,,data/crawl/squid/old_hunk_3905.cpp,data/crawl/squid/new_hunk_3905.cpp,3,3,"mb->Printf(""\r\n--%.*s--\r\n"", boundary.size(), boundary.rawBuf());","mb->Printf(""\r\n--%.*s--\r\n"", boundary.psize(), boundary.rawBuf());","[""updateVariable""]","[[""size""], [""psize""]]",[1618675270841124783],6283,0.0,2
https://github.com/squid-cache/squid/commit/8007180b22cef9ff8c0c12127b5de2f1dbbea82e,18 Feb 2009,"Author: Francesco Chemolli <kinkie@squid-cache.org>
String NG : basic SquidString updates pt 2

- finished the analysis of raw buffer exporting, divided among c-sting
and raw-buf access clients
- general sanitization
- reversal of some wrongly-renamed variables and comments
- implementation of SQUIDSTRINGPRINT and SQUIDSTRINGPH (placeholder) macros and
    psize() function for printf-style calls
- implementation of, and migration to, String::size_type and String::npos
- de-inlining of pos(), rpos(), find() and rfind() calls
- implementation and use of a proper substr() call",544,data/crawl/squid/hunk_3861.cpp,,,data/crawl/squid/old_hunk_3861.cpp,data/crawl/squid/new_hunk_3861.cpp,3,3,"storeAppendPrintf(entry, ""%s %.*s_%s %s %d %.*s\n"", name, cfg.key.size(), cfg.key.rawBuf(),
                          cfg.methodStr(), cfg.vectPointStr(), cfg.bypass, cfg.uri.size(), cfg.uri.rawBuf());","storeAppendPrintf(entry, ""%s "" SQUIDSTRINGPH ""_%s %s %d "" SQUIDSTRINGPH ""\n"",
            name,
            SQUIDSTRINGPRINT(cfg.key),
            cfg.methodStr(), cfg.vectPointStr(), cfg.bypass,
            SQUIDSTRINGPRINT(cfg.uri));","[""moveVariable"", ""removeVariable"", ""addContent"", ""removeContent"", ""addVariable""]","[[""%"", ""*s_%s"", ""%"", ""*s\\n"", ""size"", ""key"", ""rawBuf"", ""cfg"", ""size"", ""cfg"", ""uri"", ""rawBuf""], [""SQUIDSTRINGPH"", ""_%s"", ""SQUIDSTRINGPH"", ""\\n"", ""SQUIDSTRINGPRINT"", ""SQUIDSTRINGPRINT""]]",[-28928326602686305833],6282,4320.0,2
https://github.com/squid-cache/squid/commit/8007180b22cef9ff8c0c12127b5de2f1dbbea82e,18 Feb 2009,"Author: Francesco Chemolli <kinkie@squid-cache.org>
String NG : basic SquidString updates pt 2

- finished the analysis of raw buffer exporting, divided among c-sting
and raw-buf access clients
- general sanitization
- reversal of some wrongly-renamed variables and comments
- implementation of SQUIDSTRINGPRINT and SQUIDSTRINGPH (placeholder) macros and
    psize() function for printf-style calls
- implementation of, and migration to, String::size_type and String::npos
- de-inlining of pos(), rpos(), find() and rfind() calls
- implementation and use of a proper substr() call",544,data/crawl/squid/hunk_3860.cpp,,,data/crawl/squid/old_hunk_3860.cpp,data/crawl/squid/new_hunk_3860.cpp,5,5,"buf.Printf(""Host: %.*s:%d\r\n"", host.size(), host.rawBuf(), s.cfg().port);","buf.Printf(""Host: "" SQUIDSTRINGPH "":%d\r\n"", SQUIDSTRINGPRINT(host), s.cfg().port);","[""removeVariable"", ""addContent"", ""updateContent"", ""addVariable""]","[[""%"", ""*s"", ""size"", ""host"", ""rawBuf""], [""SQUIDSTRINGPH"", ""SQUIDSTRINGPRINT""]]",[-18516956952481728125],6281,4320.0,2
https://github.com/squid-cache/squid/commit/8007180b22cef9ff8c0c12127b5de2f1dbbea82e,18 Feb 2009,"Author: Francesco Chemolli <kinkie@squid-cache.org>
String NG : basic SquidString updates pt 2

- finished the analysis of raw buffer exporting, divided among c-sting
and raw-buf access clients
- general sanitization
- reversal of some wrongly-renamed variables and comments
- implementation of SQUIDSTRINGPRINT and SQUIDSTRINGPH (placeholder) macros and
    psize() function for printf-style calls
- implementation of, and migration to, String::size_type and String::npos
- de-inlining of pos(), rpos(), find() and rfind() calls
- implementation and use of a proper substr() call",544,data/crawl/squid/hunk_3860.cpp,,,data/crawl/squid/old_hunk_3860.cpp,data/crawl/squid/new_hunk_3860.cpp,3,3,"buf.Printf(""OPTIONS %.*s ICAP/1.0\r\n"", uri.size(), uri.rawBuf());","buf.Printf(""OPTIONS "" SQUIDSTRINGPH "" ICAP/1.0\r\n"", SQUIDSTRINGPRINT(uri));","[""removeVariable"", ""addContent"", ""updateContent"", ""addVariable""]","[[""%"", ""*s"", ""size"", ""uri"", ""rawBuf""], [""SQUIDSTRINGPH"", ""SQUIDSTRINGPRINT""]]",[-8096083627850458008],6280,4320.0,2
https://github.com/squid-cache/squid/commit/8007180b22cef9ff8c0c12127b5de2f1dbbea82e,18 Feb 2009,"Author: Francesco Chemolli <kinkie@squid-cache.org>
String NG : basic SquidString updates pt 2

- finished the analysis of raw buffer exporting, divided among c-sting
and raw-buf access clients
- general sanitization
- reversal of some wrongly-renamed variables and comments
- implementation of SQUIDSTRINGPRINT and SQUIDSTRINGPH (placeholder) macros and
    psize() function for printf-style calls
- implementation of, and migration to, String::size_type and String::npos
- de-inlining of pos(), rpos(), find() and rfind() calls
- implementation and use of a proper substr() call",544,data/crawl/squid/hunk_3857.cpp,,,data/crawl/squid/old_hunk_3857.cpp,data/crawl/squid/new_hunk_3857.cpp,3,3,"buf.Printf(""%s %.*s ICAP/1.0\r\n"", s.methodStr(), s.uri.size(), s.uri.rawBuf());","buf.Printf(""%s "" SQUIDSTRINGPH "" ICAP/1.0\r\n"", s.methodStr(), SQUIDSTRINGPRINT(s.uri));","[""moveVariable"", ""removeVariable"", ""addContent"", ""updateContent"", ""addVariable""]","[[""%"", ""*s"", ""size"", ""s"", ""uri"", ""rawBuf""], [""SQUIDSTRINGPH"", ""SQUIDSTRINGPRINT""]]",[-8096083642570502282],6279,4320.0,2
https://github.com/squid-cache/squid/commit/8007180b22cef9ff8c0c12127b5de2f1dbbea82e,18 Feb 2009,"Author: Francesco Chemolli <kinkie@squid-cache.org>
String NG : basic SquidString updates pt 2

- finished the analysis of raw buffer exporting, divided among c-sting
and raw-buf access clients
- general sanitization
- reversal of some wrongly-renamed variables and comments
- implementation of SQUIDSTRINGPRINT and SQUIDSTRINGPH (placeholder) macros and
    psize() function for printf-style calls
- implementation of, and migration to, String::size_type and String::npos
- de-inlining of pos(), rpos(), find() and rfind() calls
- implementation and use of a proper substr() call",544,data/crawl/squid/hunk_3852.cpp,,,data/crawl/squid/old_hunk_3852.cpp,data/crawl/squid/new_hunk_3852.cpp,3,3,"storeAppendPrintf(entry, "" %s:"", tag.unsafeBuf());","storeAppendPrintf(entry, "" :"" SQUIDSTRINGPH , SQUIDSTRINGPRINT(tag));","[""removeVariable"", ""updateContent"", ""addVariable""]","[[""%s"", ""unsafeBuf""], [""SQUIDSTRINGPH"", ""SQUIDSTRINGPRINT""]]",[-12388124474740603688],6278,5040.0,2
https://github.com/squid-cache/squid/commit/b2009d52cf41252e222d4bff85cfbf17323014e7,26 Feb 2009,"SourceLayout: adaptation/{icap,ecap}, take 1 with tweaks

Moved src/ICAP into src/adaptation/icap.
Moved src/eCAP into src/adaptation/ecap.

Renamed ICAP source files from ICAPFoo.{cc,h} to Foo.{cc,h}.

Placed ICAP names into Adaptation::Icap namespace, renaming ICAPFoo to
Adaptation::Icap::Foo.",1435,data/crawl/squid/hunk_3825.cpp,,,data/crawl/squid/old_hunk_3825.cpp,data/crawl/squid/new_hunk_3825.cpp,-1,48,,"buf.Printf(""Host: "" SQUIDSTRINGPH "":%d\r\n"", SQUIDSTRINGPRINT(host), s.cfg().port);","[""addLog""]","[[], [""buf"", ""Printf"", ""Host"", ""SQUIDSTRINGPH"", ""%d\\r\\n"", ""SQUIDSTRINGPRINT"", ""host"", ""s"", ""cfg"", ""port""]]",[11817756535844893538],6277,4320.0,2
https://github.com/squid-cache/squid/commit/b2009d52cf41252e222d4bff85cfbf17323014e7,26 Feb 2009,"SourceLayout: adaptation/{icap,ecap}, take 1 with tweaks

Moved src/ICAP into src/adaptation/icap.
Moved src/eCAP into src/adaptation/ecap.

Renamed ICAP source files from ICAPFoo.{cc,h} to Foo.{cc,h}.

Placed ICAP names into Adaptation::Icap namespace, renaming ICAPFoo to
Adaptation::Icap::Foo.",1435,data/crawl/squid/hunk_3825.cpp,,,data/crawl/squid/old_hunk_3825.cpp,data/crawl/squid/new_hunk_3825.cpp,-1,46,,"buf.Printf(""OPTIONS "" SQUIDSTRINGPH "" ICAP/1.0\r\n"", SQUIDSTRINGPRINT(uri));","[""addLog""]","[[], [""buf"", ""Printf"", ""OPTIONS"", ""SQUIDSTRINGPH"", ""ICAP/1"", ""0\\r\\n"", ""SQUIDSTRINGPRINT"", ""uri""]]",[-8740637694297218803],6276,4320.0,2
https://github.com/squid-cache/squid/commit/b2009d52cf41252e222d4bff85cfbf17323014e7,26 Feb 2009,"SourceLayout: adaptation/{icap,ecap}, take 1 with tweaks

Moved src/ICAP into src/adaptation/icap.
Moved src/eCAP into src/adaptation/ecap.

Renamed ICAP source files from ICAPFoo.{cc,h} to Foo.{cc,h}.

Placed ICAP names into Adaptation::Icap namespace, renaming ICAPFoo to
Adaptation::Icap::Foo.",1435,data/crawl/squid/hunk_3824.cpp,,,data/crawl/squid/old_hunk_3824.cpp,data/crawl/squid/new_hunk_3824.cpp,9,9,"buf.Printf(""%s: %s\r\n"", TheICAPConfig.client_username_header,
                       value);","buf.Printf(""%s: %s\r\n"", TheConfig.client_username_header,
                       value);","[""updateVariable""]","[[""TheICAPConfig""], [""TheConfig""]]",[-5214375939227093195],6275,4320.0,2
https://github.com/squid-cache/squid/commit/b2009d52cf41252e222d4bff85cfbf17323014e7,26 Feb 2009,"SourceLayout: adaptation/{icap,ecap}, take 1 with tweaks

Moved src/ICAP into src/adaptation/icap.
Moved src/eCAP into src/adaptation/ecap.

Renamed ICAP source files from ICAPFoo.{cc,h} to Foo.{cc,h}.

Placed ICAP names into Adaptation::Icap namespace, renaming ICAPFoo to
Adaptation::Icap::Foo.",1435,data/crawl/squid/hunk_3814.cpp,,,data/crawl/squid/old_hunk_3814.cpp,data/crawl/squid/new_hunk_3814.cpp,48,-1,"buf.Printf(""Host: "" SQUIDSTRINGPH "":%d\r\n"", SQUIDSTRINGPRINT(host), s.cfg().port);",,"[""removeLog""]","[[""buf"", ""Printf"", ""Host"", ""SQUIDSTRINGPH"", ""%d\\r\\n"", ""SQUIDSTRINGPRINT"", ""host"", ""s"", ""cfg"", ""port""], []]",[-11817756535844893538],6274,4320.0,2
https://github.com/squid-cache/squid/commit/b2009d52cf41252e222d4bff85cfbf17323014e7,26 Feb 2009,"SourceLayout: adaptation/{icap,ecap}, take 1 with tweaks

Moved src/ICAP into src/adaptation/icap.
Moved src/eCAP into src/adaptation/ecap.

Renamed ICAP source files from ICAPFoo.{cc,h} to Foo.{cc,h}.

Placed ICAP names into Adaptation::Icap namespace, renaming ICAPFoo to
Adaptation::Icap::Foo.",1435,data/crawl/squid/hunk_3814.cpp,,,data/crawl/squid/old_hunk_3814.cpp,data/crawl/squid/new_hunk_3814.cpp,46,-1,"buf.Printf(""OPTIONS "" SQUIDSTRINGPH "" ICAP/1.0\r\n"", SQUIDSTRINGPRINT(uri));",,"[""removeLog""]","[[""buf"", ""Printf"", ""OPTIONS"", ""SQUIDSTRINGPH"", ""ICAP/1"", ""0\\r\\n"", ""SQUIDSTRINGPRINT"", ""uri""], []]",[8740637694297218803],6273,4320.0,2
https://github.com/squid-cache/squid/commit/29cb1a9a08f9443a8b8ec75994cb9e506fe21f27,04 Apr 2009,The debug mode option '-d' was not documented in LDAP helpers usage message,2,data/crawl/squid/hunk_3797.cpp,,,data/crawl/squid/old_hunk_3797.cpp,data/crawl/squid/new_hunk_3797.cpp,-1,3,,"fprintf(stderr, ""\t-d\t\t\tenable debug mode\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""\\t"", ""d\\t\\t\\tenable"", ""debug"", ""mode\\n""]]",[-3511835091227355539],6272,0.0,2
https://github.com/squid-cache/squid/commit/445d18a460422224933c2d3b964dce27270bb402,18 May 2009,"Move ASN handling for ACL into ACL area.

This removes one possble compile clash, and one empty file.",1279,data/crawl/squid/hunk_3765.cpp,,,data/crawl/squid/old_hunk_3765.cpp,data/crawl/squid/new_hunk_3765.cpp,-1,560,,"fatal (""cloning of ACLASN not implemented"");","[""addLog""]","[[], [""fatal"", ""cloning"", ""of"", ""ACLASN"", ""not"", ""implemented""]]",[-13663414492368200408],6271,1637280.0,2
https://github.com/squid-cache/squid/commit/445d18a460422224933c2d3b964dce27270bb402,18 May 2009,"Move ASN handling for ACL into ACL area.

This removes one possble compile clash, and one empty file.",1279,data/crawl/squid/hunk_3765.cpp,,,data/crawl/squid/old_hunk_3765.cpp,data/crawl/squid/new_hunk_3765.cpp,-1,187,,"storeAppendPrintf(sentry, ""Address    \tAS Numbers\n"");","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""Address"", ""\\tAS"", ""Numbers\\n""]]",[928166613288019374],6270,2809440.0,2
https://github.com/squid-cache/squid/commit/68924b6db6e4dfe2e74495543c075714803812aa,31 May 2009,"Author: Henrik Nordstrom <henrik@henriknordstrom.net>
Bug #2407: Spelling error in http_port tcpkeepalive option

One of the new parameters according to the docs is ""keepalive"". However, when
using this option you'll get a ""Bungled squid.conf in line ..."". That's because
when parsing the configuration Squid is looking for the keyword ""tcpkeepalive""
instead of ""keepalive"" as stated in the docs.

Selected to fix the docs instead of code as having it named keepalive is too
easily confused with HTTP keep-alive / persistent connections.


2009-05-25: Also mistakes on spelling of config dump.",6,data/crawl/squid/hunk_3763.cpp,,,data/crawl/squid/old_hunk_3763.cpp,data/crawl/squid/new_hunk_3763.cpp,3,3,"storeAppendPrintf(e, "" tcp_keepalive=%d,%d,%d"", s->tcp_keepalive.idle, s->tcp_keepalive.interval, s->tcp_keepalive.timeout);","storeAppendPrintf(e, "" tcpkeepalive=%d,%d,%d"", s->tcp_keepalive.idle, s->tcp_keepalive.interval, s->tcp_keepalive.timeout);","[""updateContent""]","[[""tcp_keepalive""], [""tcpkeepalive""]]",[4559254105560999062],6269,0.0,2
https://github.com/squid-cache/squid/commit/7015d4eb4c0127faad2180b93e996bad6d9935ff,28 Jun 2009,"Author: Francesco Chemolli <kinkie@squid-cache.org>
Bug 2092: Changed select loop call counter to 64-bit

... unsigned long int so that it won't wrap around so easily.",22,data/crawl/squid/hunk_3755.cpp,,,data/crawl/squid/old_hunk_3755.cpp,data/crawl/squid/new_hunk_3755.cpp,3,3,"storeAppendPrintf(sentry, ""\tSelect loop called: %d times, %0.3f ms avg\n"",
                      statCounter.select_loops, 1000.0 * runtime / statCounter.select_loops);","storeAppendPrintf(sentry, ""\tSelect loop called: %ld times, %0.3f ms avg\n"",
                      statCounter.select_loops, 1000.0 * runtime / statCounter.select_loops);","[""updateContent""]","[[""%d""], [""%ld""]]",[-4775301843693679707],6268,67680.0,2
https://github.com/squid-cache/squid/commit/3ff6559699bc1852ae3a6f7be48824d13e2ebf90,12 Jul 2009,"Bug #2459 fix, access logging enhancements, ICAP logging and retries support:

  - Bug #2459 fix

  - Support logging of total DNS wait time to access.log
    (%dt)

  - Support logging response times of adaptation transactions to access.log
    (%adapt::sum_trs and %adapt::all_trs)

  - Enhanced access logging
    (<Hs, <sh, >sh, <pt, <tt, icap::tt, and icap::<last_h in squid.conf)
    
  - ICAP logging 
    (see icap_log and log_icap in squid.conf as well as
    http://wiki.squid-cache.org/Features/AdaptationLog).
    
  - ICAP retries based on the ICAP responses status code
    (see icap_retry_limit in squid.conf).

Merged from 3p1-plus branch at r9511.",2714,data/crawl/squid/hunk_3725.cpp,,,data/crawl/squid/old_hunk_3725.cpp,data/crawl/squid/new_hunk_3725.cpp,-1,45,,.stop();,"[""addLog""]","[[], [""stop""]]",[-1840386907510881204],6267,770400.0,2
https://github.com/squid-cache/squid/commit/d974a0723c00b59328754bbd964e34fdd03a890a,17 Jul 2009,"Bug 2680 regression: Crash after rotate with no helpers running

Regression from bug 2276 fix. n_running was used instead of n_active.
Also documents the relevant counters to prevent this recurring.",30,data/crawl/squid/hunk_3702.cpp,,,data/crawl/squid/old_hunk_3702.cpp,data/crawl/squid/new_hunk_3702.cpp,3,3,"storeAppendPrintf(sentry, ""   S = SHUTDOWN\n"");","storeAppendPrintf(sentry, ""   S = SHUTDOWN PENDING\n"");","[""updateContent""]","[[""SHUTDOWN\\n""], [""SHUTDOWN"", ""PENDING\\n""]]",[5782306439145948962],6266,0.0,2
https://github.com/squid-cache/squid/commit/d974a0723c00b59328754bbd964e34fdd03a890a,17 Jul 2009,"Bug 2680 regression: Crash after rotate with no helpers running

Regression from bug 2276 fix. n_running was used instead of n_active.
Also documents the relevant counters to prevent this recurring.",30,data/crawl/squid/hunk_3701.cpp,,,data/crawl/squid/old_hunk_3701.cpp,data/crawl/squid/new_hunk_3701.cpp,3,3,"storeAppendPrintf(sentry, ""number running: %d of %d\n"",
                      hlp->n_running, hlp->n_to_start);","storeAppendPrintf(sentry, ""number active: %d of %d (%d shutting down)\n"",
                      hlp->n_active, hlp->n_to_start, (hlp->n_running - hlp->n_active) );","[""updateContent"", ""addVariable""]","[[""running"", ""%d\\n""], [""active"", ""%d"", ""%d"", ""shutting"", ""down"", ""\\n"", ""n_active"", ""hlp"", ""hlp"", ""n_active""]]",[-21820597324884949671],6265,0.0,2
https://github.com/squid-cache/squid/commit/2e1e4f10bd3ccc01183d99a9cb466f3bc483c5da,10 Aug 2009,merged from trunk,5048,data/crawl/squid/hunk_3680.cpp,,,data/crawl/squid/old_hunk_3680.cpp,data/crawl/squid/new_hunk_3680.cpp,-1,26,,"fatal(""StoreEntry::setPulicKey. Not implemented."");","[""addLog""]","[[], [""fatal"", ""StoreEntry"", ""setPulicKey"", ""Not"", ""implemented""]]",[-5346853906588702888],6264,10800.0,2
https://github.com/squid-cache/squid/commit/2e1e4f10bd3ccc01183d99a9cb466f3bc483c5da,10 Aug 2009,merged from trunk,5048,data/crawl/squid/hunk_3680.cpp,,,data/crawl/squid/old_hunk_3680.cpp,data/crawl/squid/new_hunk_3680.cpp,-1,20,,"fatal(""StoreEntry::timestampsSet. Not implemented."");","[""addLog""]","[[], [""fatal"", ""StoreEntry"", ""timestampsSet"", ""Not"", ""implemented""]]",[-2860225327935109051],6263,10800.0,2
https://github.com/squid-cache/squid/commit/2e1e4f10bd3ccc01183d99a9cb466f3bc483c5da,10 Aug 2009,merged from trunk,5048,data/crawl/squid/hunk_3679.cpp,,,data/crawl/squid/old_hunk_3679.cpp,data/crawl/squid/new_hunk_3679.cpp,9,9,"fatal(""Not implemented"");","fatal(""storeAppendVPrintf: Not implemented"");","[""updateContent""]","[[], [""storeAppendVPrintf""]]",[3227955763591095296],6262,10800.0,2
https://github.com/squid-cache/squid/commit/2e1e4f10bd3ccc01183d99a9cb466f3bc483c5da,10 Aug 2009,merged from trunk,5048,data/crawl/squid/hunk_3679.cpp,,,data/crawl/squid/old_hunk_3679.cpp,data/crawl/squid/new_hunk_3679.cpp,3,3,"fatal(""Not implemented"");","fatal(""storeAppendPrintf: Not implemented"");","[""updateContent""]","[[], [""storeAppendPrintf""]]",[5181367693625444383],6261,10800.0,2
https://github.com/squid-cache/squid/commit/2e1e4f10bd3ccc01183d99a9cb466f3bc483c5da,10 Aug 2009,merged from trunk,5048,data/crawl/squid/hunk_3678.cpp,,,data/crawl/squid/old_hunk_3678.cpp,data/crawl/squid/new_hunk_3678.cpp,-1,14,,"fatal(""statHistCount: Not implemented"");","[""addLog""]","[[], [""fatal"", ""statHistCount"", ""Not"", ""implemented""]]",[-4662650133473074772],6260,10800.0,2
https://github.com/squid-cache/squid/commit/2e1e4f10bd3ccc01183d99a9cb466f3bc483c5da,10 Aug 2009,merged from trunk,5048,data/crawl/squid/hunk_3678.cpp,,,data/crawl/squid/old_hunk_3678.cpp,data/crawl/squid/new_hunk_3678.cpp,-1,8,,"fatal(""statHistDump: Not implemented"");","[""addLog""]","[[], [""fatal"", ""statHistDump"", ""Not"", ""implemented""]]",[-9684074428778075342],6259,10800.0,2
https://github.com/squid-cache/squid/commit/2e1e4f10bd3ccc01183d99a9cb466f3bc483c5da,10 Aug 2009,merged from trunk,5048,data/crawl/squid/hunk_3674.cpp,,,data/crawl/squid/old_hunk_3674.cpp,data/crawl/squid/new_hunk_3674.cpp,50,-1,"fatal(""helperStatefulHandleRead: unknown stateful helper callback result.\n"");",,"[""removeLog""]","[[""fatal"", ""helperStatefulHandleRead"", ""unknown"", ""stateful"", ""helper"", ""callback"", ""result"", ""\\n""], []]",[16056450529631063150],6258,4320.0,2
https://github.com/squid-cache/squid/commit/2e1e4f10bd3ccc01183d99a9cb466f3bc483c5da,10 Aug 2009,merged from trunk,5048,data/crawl/squid/hunk_3674.cpp,,,data/crawl/squid/old_hunk_3674.cpp,data/crawl/squid/new_hunk_3674.cpp,6,-1,"fatal(""helperStatefulHandleRead: either a non-state aware callback was give to the stateful helper routines, or an uninitialised callback response was received.\n"");",,"[""removeLog""]","[[""fatal"", ""helperStatefulHandleRead"", ""either"", ""a"", ""non"", ""state"", ""aware"", ""callback"", ""was"", ""give"", ""to"", ""the"", ""stateful"", ""helper"", ""routines"", ""or"", ""an"", ""uninitialised"", ""callback"", ""response"", ""was"", ""received"", ""\\n""], []]",[2977755774442763167],6257,4320.0,2
https://github.com/squid-cache/squid/commit/2e1e4f10bd3ccc01183d99a9cb466f3bc483c5da,10 Aug 2009,merged from trunk,5048,data/crawl/squid/hunk_3673.cpp,,,data/crawl/squid/old_hunk_3673.cpp,data/crawl/squid/new_hunk_3673.cpp,3,-1,"storeAppendPrintf(sentry, ""   D = DEFERRED\n"");",,"[""removeLog""]","[[""storeAppendPrintf"", ""sentry"", ""D"", ""DEFERRED\\n""], []]",[-10317540200380591792],6256,5040.0,2
https://github.com/squid-cache/squid/commit/766743af0e72dc241510f65bc660dbd2eaca9420,13 Aug 2009,"Windows port: fix mswin_negotiate_auth.exe crash when executing a LocalCall authentication with verbose debug enabled

- Also ran indent",414,data/crawl/squid/hunk_3658.cpp,,,data/crawl/squid/old_hunk_3658.cpp,data/crawl/squid/new_hunk_3658.cpp,-1,58,,"fprintf(stderr, ""No data available.\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""No"", ""data"", ""available"", ""\\n""]]",[-31602915378819014971],6255,0.0,2
https://github.com/squid-cache/squid/commit/c6111665d4d240d094f6b29a622389bc3676e401,14 Aug 2009,"Populate cache_mem again on disk cache hits, moving on-disk objects back
into the hot object pool.

This adds a new squid.conf option for tuning when to keep objects in memory.

Sponsored by: The Measurement Factory",181,data/crawl/squid/hunk_3654.cpp,,,data/crawl/squid/old_hunk_3654.cpp,data/crawl/squid/new_hunk_3654.cpp,-1,41,,"storeAppendPrintf(entry, ""network"");","[""addLog""]","[[], [""storeAppendPrintf"", ""entry"", ""network""]]",[-3483576670683512643],6254,7200.0,2
https://github.com/squid-cache/squid/commit/c6111665d4d240d094f6b29a622389bc3676e401,14 Aug 2009,"Populate cache_mem again on disk cache hits, moving on-disk objects back
into the hot object pool.

This adds a new squid.conf option for tuning when to keep objects in memory.

Sponsored by: The Measurement Factory",181,data/crawl/squid/hunk_3654.cpp,,,data/crawl/squid/old_hunk_3654.cpp,data/crawl/squid/new_hunk_3654.cpp,-1,39,,"storeAppendPrintf(entry, ""disk"");","[""addLog""]","[[], [""storeAppendPrintf"", ""entry"", ""disk""]]",[-4905767093261955533],6253,7200.0,2
https://github.com/squid-cache/squid/commit/c6111665d4d240d094f6b29a622389bc3676e401,14 Aug 2009,"Populate cache_mem again on disk cache hits, moving on-disk objects back
into the hot object pool.

This adds a new squid.conf option for tuning when to keep objects in memory.

Sponsored by: The Measurement Factory",181,data/crawl/squid/hunk_3654.cpp,,,data/crawl/squid/old_hunk_3654.cpp,data/crawl/squid/new_hunk_3654.cpp,-1,37,,"storeAppendPrintf(entry, ""always"");","[""addLog""]","[[], [""storeAppendPrintf"", ""entry"", ""always""]]",[4876492427515736193],6252,7200.0,2
https://github.com/squid-cache/squid/commit/a0e95c7e26b33cb3df67c566e0daf382738da3ea,27 Aug 2009,"Cleanup of auth header special case forwarding logics

The code dealing with our special case auth header forwarding/synthesising
had grown quite hairy and partially duplicated from all additions. This
cleans up the code moving this logics to a new function and unifying
WWW & Proxy auth cases.",186,data/crawl/squid/hunk_3623.cpp,,,data/crawl/squid/old_hunk_3623.cpp,data/crawl/squid/new_hunk_3623.cpp,78,-1,"httpHeaderPutStrf(hdr_out, HDR_AUTHORIZATION, ""Basic %s"",
                              base64_encode(orig_request->peer_login));",,"[""removeLog""]","[[""httpHeaderPutStrf"", ""hdr_out"", ""HDR_AUTHORIZATION"", ""Basic"", ""%s"", ""base64_encode"", ""orig_request"", ""peer_login""], []]",[-19571167517780228532],6251,720.0,2
https://github.com/squid-cache/squid/commit/a0e95c7e26b33cb3df67c566e0daf382738da3ea,27 Aug 2009,"Cleanup of auth header special case forwarding logics

The code dealing with our special case auth header forwarding/synthesising
had grown quite hairy and partially duplicated from all additions. This
cleans up the code moving this logics to a new function and unifying
WWW & Proxy auth cases.",186,data/crawl/squid/hunk_3623.cpp,,,data/crawl/squid/old_hunk_3623.cpp,data/crawl/squid/new_hunk_3623.cpp,53,-1,"hdr_out->putStr(HDR_AUTHORIZATION, auth);",,"[""removeLog""]","[[""hdr_out"", ""putStr"", ""HDR_AUTHORIZATION"", ""auth""], []]",[-1778347086537125829],6250,720.0,2
https://github.com/squid-cache/squid/commit/a0e95c7e26b33cb3df67c566e0daf382738da3ea,27 Aug 2009,"Cleanup of auth header special case forwarding logics

The code dealing with our special case auth header forwarding/synthesising
had grown quite hairy and partially duplicated from all additions. This
cleans up the code moving this logics to a new function and unifying
WWW & Proxy auth cases.",186,data/crawl/squid/hunk_3623.cpp,,,data/crawl/squid/old_hunk_3623.cpp,data/crawl/squid/new_hunk_3623.cpp,34,-1,"httpHeaderPutStrf(hdr_out, HDR_PROXY_AUTHORIZATION, ""Basic %s"",
                              base64_encode(orig_request->peer_login));",,"[""removeLog""]","[[""httpHeaderPutStrf"", ""hdr_out"", ""HDR_PROXY_AUTHORIZATION"", ""Basic"", ""%s"", ""base64_encode"", ""orig_request"", ""peer_login""], []]",[-18865267603287543529],6249,720.0,2
https://github.com/squid-cache/squid/commit/a0e95c7e26b33cb3df67c566e0daf382738da3ea,27 Aug 2009,"Cleanup of auth header special case forwarding logics

The code dealing with our special case auth header forwarding/synthesising
had grown quite hairy and partially duplicated from all additions. This
cleans up the code moving this logics to a new function and unifying
WWW & Proxy auth cases.",186,data/crawl/squid/hunk_3622.cpp,,,data/crawl/squid/old_hunk_3622.cpp,data/crawl/squid/new_hunk_3622.cpp,-1,50,,"httpHeaderPutStrf(hdr_out, header, ""Basic %s"",
			  base64_encode(loginbuf));","[""addLog""]","[[], [""httpHeaderPutStrf"", ""hdr_out"", ""header"", ""Basic"", ""%s"", ""base64_encode"", ""loginbuf""]]",[-6335661435216381791],6248,0.0,2
https://github.com/squid-cache/squid/commit/a0e95c7e26b33cb3df67c566e0daf382738da3ea,27 Aug 2009,"Cleanup of auth header special case forwarding logics

The code dealing with our special case auth header forwarding/synthesising
had grown quite hairy and partially duplicated from all additions. This
cleans up the code moving this logics to a new function and unifying
WWW & Proxy auth cases.",186,data/crawl/squid/hunk_3622.cpp,,,data/crawl/squid/old_hunk_3622.cpp,data/crawl/squid/new_hunk_3622.cpp,-1,33,,"hdr_out->putStr(header, auth);","[""addLog""]","[[], [""hdr_out"", ""putStr"", ""header"", ""auth""]]",[-8710543793641279243],6247,720.0,2
https://github.com/squid-cache/squid/commit/96e03dd843bf82abfefbb46b3275154853ada1d4,28 Aug 2009,"Cleanup: Remove more traces of old squid debug()() macro

There is now no reason for any of the Squid internal code to contain 'debug()'

TODO: Just the ESI code remaining on the old system.
  It's debug seems to be incrementally building a single line to display
  objects parsed. But using multiple nested calls to dump it.
  VERY nasty. They need to be made writing to a buffer instead.",78,data/crawl/squid/hunk_3618.cpp,,,data/crawl/squid/old_hunk_3618.cpp,data/crawl/squid/new_hunk_3618.cpp,-1,3,,"fprintf(stderr, ""Fatal: %s"",message);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""Fatal"", ""%s"", ""message""]]",[-25714727152405944387],6246,0.0,2
https://github.com/squid-cache/squid/commit/dfeb186b8c66502b97aab952b1b049014c02a733,04 Sep 2009,"Bundle helpers for url_rewrite

Adds the --enable-url-rewrite-helpers configure time option.
see release notes or ./configure help text.

Bundles two 'fake' helpers with exemplar code for shell and C++ coding:

 url_fake_rewrite
	- C++ helper with old non-concurrent protocol.

 url-fake-rewrite.sh
	- shell helper with concurrent and non-concurrent protocols.


Also, some polishing is done to debug code for helpers.",390,data/crawl/squid/hunk_3595.cpp,,,data/crawl/squid/old_hunk_3595.cpp,data/crawl/squid/new_hunk_3595.cpp,-1,95,,"fprintf(stdout,""\n"");","[""addLog""]","[[], [""fprintf"", ""stdout"", ""\\n""]]",[-13913885213698345581],6245,39600.0,2
https://github.com/squid-cache/squid/commit/dfeb186b8c66502b97aab952b1b049014c02a733,04 Sep 2009,"Bundle helpers for url_rewrite

Adds the --enable-url-rewrite-helpers configure time option.
see release notes or ./configure help text.

Bundles two 'fake' helpers with exemplar code for shell and C++ coding:

 url_fake_rewrite
	- C++ helper with old non-concurrent protocol.

 url-fake-rewrite.sh
	- shell helper with concurrent and non-concurrent protocols.


Also, some polishing is done to debug code for helpers.",390,data/crawl/squid/hunk_3595.cpp,,,data/crawl/squid/old_hunk_3595.cpp,data/crawl/squid/new_hunk_3595.cpp,-1,33,,"fprintf(stderr,
            ""Usage: %s [-d] [-v] [-h]\n""
            "" -d  enable debugging.\n""
            "" -h  this message\n\n"",
            my_program_name);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""Usage"", ""%s"", ""["", ""d]"", ""["", ""v]"", ""["", ""h]\\n"", ""d"", ""enable"", ""debugging"", ""\\n"", ""h"", ""this"", ""message\\n\\n"", ""my_program_name""]]",[-8919842937044454803],6244,39600.0,2
https://github.com/squid-cache/squid/commit/0263742023e4872c0db3b6cfd13df08c2e4673c1,23 Sep 2009,Merg from trunk,1314,data/crawl/squid/hunk_3578.cpp,,,data/crawl/squid/old_hunk_3578.cpp,data/crawl/squid/new_hunk_3578.cpp,13,12,".Printf(""\r\n"");",mimeGetContentEncoding(gopherState->request);,"[""updateLog"", ""removeContent"", ""addVariable"", ""removeLog""]","[[""Printf"", ""\\r\\n""], [""mimeGetContentEncoding"", ""gopherState"", ""request""]]",[-435689516880344692],6243,2880.0,2
https://github.com/squid-cache/squid/commit/0263742023e4872c0db3b6cfd13df08c2e4673c1,23 Sep 2009,Merg from trunk,1314,data/crawl/squid/hunk_3577.cpp,,,data/crawl/squid/old_hunk_3577.cpp,data/crawl/squid/new_hunk_3577.cpp,21,-1,"mb.Printf(""Content-Type: video/mpeg\r\n"");",,"[""removeLog""]","[[""mb"", ""Printf"", ""Content"", ""Type"", ""video/mpeg\\r\\n""], []]",[-9193989740658784083],6242,2880.0,2
https://github.com/squid-cache/squid/commit/0263742023e4872c0db3b6cfd13df08c2e4673c1,23 Sep 2009,Merg from trunk,1314,data/crawl/squid/hunk_3577.cpp,,,data/crawl/squid/old_hunk_3577.cpp,data/crawl/squid/new_hunk_3577.cpp,17,-1,"mb.Printf(""Content-Type: audio/basic\r\n"");",,"[""removeLog""]","[[""mb"", ""Printf"", ""Content"", ""Type"", ""audio/basic\\r\\n""], []]",[88978266346472216],6241,2880.0,2
https://github.com/squid-cache/squid/commit/0263742023e4872c0db3b6cfd13df08c2e4673c1,23 Sep 2009,Merg from trunk,1314,data/crawl/squid/hunk_3577.cpp,,,data/crawl/squid/old_hunk_3577.cpp,data/crawl/squid/new_hunk_3577.cpp,11,-1,"mb.Printf(""Content-Type: image/gif\r\n"");",,"[""removeLog""]","[[""mb"", ""Printf"", ""Content"", ""Type"", ""image/gif\\r\\n""], []]",[-566673743170070987],6240,2880.0,2
https://github.com/squid-cache/squid/commit/0263742023e4872c0db3b6cfd13df08c2e4673c1,23 Sep 2009,Merg from trunk,1314,data/crawl/squid/hunk_3577.cpp,,,data/crawl/squid/old_hunk_3577.cpp,data/crawl/squid/new_hunk_3577.cpp,3,-1,"mb.Printf(""Content-Type: text/html\r\n"");",,"[""removeLog""]","[[""mb"", ""Printf"", ""Content"", ""Type"", ""text/html\\r\\n""], []]",[-6341656542888061992],6239,2880.0,2
https://github.com/squid-cache/squid/commit/0263742023e4872c0db3b6cfd13df08c2e4673c1,23 Sep 2009,Merg from trunk,1314,data/crawl/squid/hunk_3576.cpp,,,data/crawl/squid/old_hunk_3576.cpp,data/crawl/squid/new_hunk_3576.cpp,34,-1,"mb.Printf(""HTTP/1.0 200 OK Gatewaying\r\n""
              ""Server: Squid/%s\r\n""
              ""Date: %s\r\n"",
              version_string, mkrfc1123(squid_curtime));",,"[""removeLog""]","[[""mb"", ""Printf"", ""HTTP/1"", ""0"", ""200"", ""OK"", ""Gatewaying\\r\\n"", ""Server"", ""Squid/%s\\r\\n"", ""Date"", ""%s\\r\\n"", ""version_string"", ""mkrfc1123"", ""squid_curtime""], []]",[12261880501776543362],6238,2880.0,2
https://github.com/squid-cache/squid/commit/0263742023e4872c0db3b6cfd13df08c2e4673c1,23 Sep 2009,Merg from trunk,1314,data/crawl/squid/hunk_3576.cpp,,,data/crawl/squid/old_hunk_3576.cpp,data/crawl/squid/new_hunk_3576.cpp,17,-1,"mb->Printf(""Content-Type: %s\r\n"",
               ctype ? ctype : def_ctype);",,"[""removeLog""]","[[""mb"", ""Printf"", ""Content"", ""Type"", ""%s\\r\\n"", ""ctype"", ""ctype"", ""def_ctype""], []]",[-4902108661394051662],6237,2880.0,2
https://github.com/squid-cache/squid/commit/0263742023e4872c0db3b6cfd13df08c2e4673c1,23 Sep 2009,Merg from trunk,1314,data/crawl/squid/hunk_3576.cpp,,,data/crawl/squid/old_hunk_3576.cpp,data/crawl/squid/new_hunk_3576.cpp,15,-1,"mb->Printf(""Content-Encoding: %s\r\n"", cenc);",,"[""removeLog""]","[[""mb"", ""Printf"", ""Content"", ""Encoding"", ""%s\\r\\n"", ""cenc""], []]",[-9598600587970182652],6236,2880.0,2
https://github.com/squid-cache/squid/commit/0477a0720841098ff1fa396e80b6259d827e437c,31 Oct 2009,"Multi-Lingual FTP directory listing

This replaces hard-coded FTP directory page with dynamically loaded
'error page' same as all other FTP result HTML outputs.

This has the added benefit of making the page HTML standards compliant,
CSS branded, and presentable in any of the auto-negotiated languages.",443,data/crawl/squid/hunk_3552.cpp,,,data/crawl/squid/old_hunk_3552.cpp,data/crawl/squid/new_hunk_3552.cpp,-1,8,,"html->Printf(""<tr class=\""entry\""><td colspan=\""5\"">%s</td></tr>\n"", line);","[""addLog""]","[[], [""html"", ""Printf"", ""tr"", ""class"", ""\\"", ""entry\\"", ""td"", ""colspan"", ""\\"", ""5\\"", ""%s"", ""/td"", ""/tr"", ""\\n"", ""line""]]",[50877146634065337813],6235,258480.0,2
https://github.com/squid-cache/squid/commit/77721eb240367f9d4bd82638f118c811f2e93349,05 Nov 2009,"Author: Markus Moeller huaraz@moeller.plus.com>
Update squid_kerb_auth helper

 * remove sub configure again (too many issues)

Also, by Amso Jeffries
 * naming update to negotiate_kerberos_auth
 * polished helper detection rules in configure",10781,data/crawl/squid/hunk_3547.cpp,,,data/crawl/squid/old_hunk_3547.cpp,data/crawl/squid/new_hunk_3547.cpp,524,-1,"fprintf(stderr, ""%s| %s: User %s authenticated\n"", LogTime(), PROGRAM, user);",,"[""removeLog""]","[[""fprintf"", ""stderr"", ""%s"", ""%s"", ""User"", ""%s"", ""authenticated\\n"", ""LogTime"", ""PROGRAM"", ""user""], []]",[6635982612220853237],6234,0.0,2
https://github.com/squid-cache/squid/commit/77721eb240367f9d4bd82638f118c811f2e93349,05 Nov 2009,"Author: Markus Moeller huaraz@moeller.plus.com>
Update squid_kerb_auth helper

 * remove sub configure again (too many issues)

Also, by Amso Jeffries
 * naming update to negotiate_kerberos_auth
 * polished helper detection rules in configure",10781,data/crawl/squid/hunk_3547.cpp,,,data/crawl/squid/old_hunk_3547.cpp,data/crawl/squid/new_hunk_3547.cpp,501,-1,"fprintf(stderr, ""%s| %s: continuation needed\n"", LogTime(), PROGRAM);",,"[""removeLog""]","[[""fprintf"", ""stderr"", ""%s"", ""%s"", ""continuation"", ""needed\\n"", ""LogTime"", ""PROGRAM""], []]",[8607357028711081211],6233,0.0,2
https://github.com/squid-cache/squid/commit/77721eb240367f9d4bd82638f118c811f2e93349,05 Nov 2009,"Author: Markus Moeller huaraz@moeller.plus.com>
Update squid_kerb_auth helper

 * remove sub configure again (too many issues)

Also, by Amso Jeffries
 * naming update to negotiate_kerberos_auth
 * polished helper detection rules in configure",10781,data/crawl/squid/hunk_3547.cpp,,,data/crawl/squid/old_hunk_3547.cpp,data/crawl/squid/new_hunk_3547.cpp,195,-1,"fprintf(stderr, ""%s| %s: %s failed: %s\n"", LogTime(), PROGRAM, function, buf);",,"[""removeLog""]","[[""fprintf"", ""stderr"", ""%s"", ""%s"", ""%s"", ""failed"", ""%s\\n"", ""LogTime"", ""PROGRAM"", ""function"", ""buf""], []]",[13411346457197098932],6232,0.0,2
https://github.com/squid-cache/squid/commit/77721eb240367f9d4bd82638f118c811f2e93349,05 Nov 2009,"Author: Markus Moeller huaraz@moeller.plus.com>
Update squid_kerb_auth helper

 * remove sub configure again (too many issues)

Also, by Amso Jeffries
 * naming update to negotiate_kerberos_auth
 * polished helper detection rules in configure",10781,data/crawl/squid/hunk_3546.cpp,,,data/crawl/squid/old_hunk_3546.cpp,data/crawl/squid/new_hunk_3546.cpp,-1,248,,"fprintf(stdout, ""QQ\n"");","[""addLog""]","[[], [""fprintf"", ""stdout"", ""QQ\\n""]]",[-5628437379305328865],6231,44640.0,2
https://github.com/squid-cache/squid/commit/77721eb240367f9d4bd82638f118c811f2e93349,05 Nov 2009,"Author: Markus Moeller huaraz@moeller.plus.com>
Update squid_kerb_auth helper

 * remove sub configure again (too many issues)

Also, by Amso Jeffries
 * naming update to negotiate_kerberos_auth
 * polished helper detection rules in configure",10781,data/crawl/squid/hunk_3546.cpp,,,data/crawl/squid/old_hunk_3546.cpp,data/crawl/squid/new_hunk_3546.cpp,-1,245,,"fprintf(stdout, ""YR %s\n"", Token ? Token : ""NULL"");","[""addLog""]","[[], [""fprintf"", ""stdout"", ""YR"", ""%s\\n"", ""Token"", ""Token"", ""NULL""]]",[2776114685960105639],6230,44640.0,2
https://github.com/squid-cache/squid/commit/77721eb240367f9d4bd82638f118c811f2e93349,05 Nov 2009,"Author: Markus Moeller huaraz@moeller.plus.com>
Update squid_kerb_auth helper

 * remove sub configure again (too many issues)

Also, by Amso Jeffries
 * naming update to negotiate_kerberos_auth
 * polished helper detection rules in configure",10781,data/crawl/squid/hunk_3545.cpp,,,data/crawl/squid/old_hunk_3545.cpp,data/crawl/squid/new_hunk_3545.cpp,-1,679,,"fprintf(stdout, ""BH Kerberos authentication not supported\n"");","[""addLog""]","[[], [""fprintf"", ""stdout"", ""BH"", ""Kerberos"", ""authentication"", ""not"", ""supported\\n""]]",[-6993364372600971097],6229,39600.0,2
https://github.com/squid-cache/squid/commit/77721eb240367f9d4bd82638f118c811f2e93349,05 Nov 2009,"Author: Markus Moeller huaraz@moeller.plus.com>
Update squid_kerb_auth helper

 * remove sub configure again (too many issues)

Also, by Amso Jeffries
 * naming update to negotiate_kerberos_auth
 * polished helper detection rules in configure",10781,data/crawl/squid/hunk_3545.cpp,,,data/crawl/squid/old_hunk_3545.cpp,data/crawl/squid/new_hunk_3545.cpp,-1,584,,"fprintf(stderr, ""%s| %s: User %s authenticated\n"", LogTime(),
		    PROGRAM, user);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""%s"", ""%s"", ""User"", ""%s"", ""authenticated\\n"", ""LogTime"", ""PROGRAM"", ""user""]]",[-6635982612220853237],6228,0.0,2
https://github.com/squid-cache/squid/commit/77721eb240367f9d4bd82638f118c811f2e93349,05 Nov 2009,"Author: Markus Moeller huaraz@moeller.plus.com>
Update squid_kerb_auth helper

 * remove sub configure again (too many issues)

Also, by Amso Jeffries
 * naming update to negotiate_kerberos_auth
 * polished helper detection rules in configure",10781,data/crawl/squid/hunk_3545.cpp,,,data/crawl/squid/old_hunk_3545.cpp,data/crawl/squid/new_hunk_3545.cpp,-1,555,,"fprintf(stdout, ""TT %s\n"", token);","[""addLog""]","[[], [""fprintf"", ""stdout"", ""TT"", ""%s\\n"", ""token""]]",[-411907393299904919],6227,622080.0,2
https://github.com/squid-cache/squid/commit/77721eb240367f9d4bd82638f118c811f2e93349,05 Nov 2009,"Author: Markus Moeller huaraz@moeller.plus.com>
Update squid_kerb_auth helper

 * remove sub configure again (too many issues)

Also, by Amso Jeffries
 * naming update to negotiate_kerberos_auth
 * polished helper detection rules in configure",10781,data/crawl/squid/hunk_3545.cpp,,,data/crawl/squid/old_hunk_3545.cpp,data/crawl/squid/new_hunk_3545.cpp,-1,521,,"fprintf(stderr,
			    ""%s| %s: makeNegTokenTarg failed with rc=%d\n"",
			    LogTime(), PROGRAM, rc);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""%s"", ""%s"", ""makeNegTokenTarg"", ""failed"", ""with"", ""rc"", ""%d\\n"", ""LogTime"", ""PROGRAM"", ""rc""]]",[-19420802712034584714],6226,622080.0,2
https://github.com/squid-cache/squid/commit/77721eb240367f9d4bd82638f118c811f2e93349,05 Nov 2009,"Author: Markus Moeller huaraz@moeller.plus.com>
Update squid_kerb_auth helper

 * remove sub configure again (too many issues)

Also, by Amso Jeffries
 * naming update to negotiate_kerberos_auth
 * polished helper detection rules in configure",10781,data/crawl/squid/hunk_3545.cpp,,,data/crawl/squid/old_hunk_3545.cpp,data/crawl/squid/new_hunk_3545.cpp,-1,451,,"fprintf(stdout, ""BH received type %d NTLM token\n"",
		    (int) *((unsigned char *) input_token.value +
			sizeof ntlmProtocol));","[""addLog""]","[[], [""fprintf"", ""stdout"", ""BH"", ""received"", ""type"", ""%d"", ""NTLM"", ""token\\n"", ""int"", ""*"", ""unsigned"", ""char"", ""*"", ""input_token"", ""value"", ""sizeof"", ""ntlmProtocol""]]",[-33580115765483002823],6225,0.0,2
https://github.com/squid-cache/squid/commit/77721eb240367f9d4bd82638f118c811f2e93349,05 Nov 2009,"Author: Markus Moeller huaraz@moeller.plus.com>
Update squid_kerb_auth helper

 * remove sub configure again (too many issues)

Also, by Amso Jeffries
 * naming update to negotiate_kerberos_auth
 * polished helper detection rules in configure",10781,data/crawl/squid/hunk_3545.cpp,,,data/crawl/squid/old_hunk_3545.cpp,data/crawl/squid/new_hunk_3545.cpp,-1,438,,"fprintf(stderr, ""%s| %s: Invalid GSS-SPNEGO query [%s]\n"",
			LogTime(), PROGRAM, buf);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""%s"", ""%s"", ""Invalid"", ""GSS"", ""SPNEGO"", ""query"", ""[%s]\\n"", ""LogTime"", ""PROGRAM"", ""buf""]]",[-25308916076387808654],6224,622080.0,2
https://github.com/squid-cache/squid/commit/77721eb240367f9d4bd82638f118c811f2e93349,05 Nov 2009,"Author: Markus Moeller huaraz@moeller.plus.com>
Update squid_kerb_auth helper

 * remove sub configure again (too many issues)

Also, by Amso Jeffries
 * naming update to negotiate_kerberos_auth
 * polished helper detection rules in configure",10781,data/crawl/squid/hunk_3545.cpp,,,data/crawl/squid/old_hunk_3545.cpp,data/crawl/squid/new_hunk_3545.cpp,-1,432,,"fprintf(stderr, ""%s| %s: parseNegTokenInit failed with rc=%d\n"",
		    LogTime(), PROGRAM, rc);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""%s"", ""%s"", ""parseNegTokenInit"", ""failed"", ""with"", ""rc"", ""%d\\n"", ""LogTime"", ""PROGRAM"", ""rc""]]",[-23893375745594741414],6223,622080.0,2
https://github.com/squid-cache/squid/commit/77721eb240367f9d4bd82638f118c811f2e93349,05 Nov 2009,"Author: Markus Moeller huaraz@moeller.plus.com>
Update squid_kerb_auth helper

 * remove sub configure again (too many issues)

Also, by Amso Jeffries
 * naming update to negotiate_kerberos_auth
 * polished helper detection rules in configure",10781,data/crawl/squid/hunk_3545.cpp,,,data/crawl/squid/old_hunk_3545.cpp,data/crawl/squid/new_hunk_3545.cpp,-1,298,,"fprintf(stderr,
		""%s| %s: Local hostname could not be determined. Please specify the service principal\n"",
		LogTime(), PROGRAM);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""%s"", ""%s"", ""Local"", ""hostname"", ""could"", ""not"", ""be"", ""determined"", ""Please"", ""specify"", ""the"", ""service"", ""principal\\n"", ""LogTime"", ""PROGRAM""]]",[21974412835750671669],6222,622080.0,2
https://github.com/squid-cache/squid/commit/77721eb240367f9d4bd82638f118c811f2e93349,05 Nov 2009,"Author: Markus Moeller huaraz@moeller.plus.com>
Update squid_kerb_auth helper

 * remove sub configure again (too many issues)

Also, by Amso Jeffries
 * naming update to negotiate_kerberos_auth
 * polished helper detection rules in configure",10781,data/crawl/squid/hunk_3545.cpp,,,data/crawl/squid/old_hunk_3545.cpp,data/crawl/squid/new_hunk_3545.cpp,-1,284,,"fprintf(stderr, ""%s| %s: unknown option: -%c.\n"", LogTime(),
		PROGRAM, opt);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""%s"", ""%s"", ""unknown"", ""option"", ""%c"", ""\\n"", ""LogTime"", ""PROGRAM"", ""opt""]]",[-8800736611532375069],6221,622080.0,2
https://github.com/squid-cache/squid/commit/77721eb240367f9d4bd82638f118c811f2e93349,05 Nov 2009,"Author: Markus Moeller huaraz@moeller.plus.com>
Update squid_kerb_auth helper

 * remove sub configure again (too many issues)

Also, by Amso Jeffries
 * naming update to negotiate_kerberos_auth
 * polished helper detection rules in configure",10781,data/crawl/squid/hunk_3545.cpp,,,data/crawl/squid/old_hunk_3545.cpp,data/crawl/squid/new_hunk_3545.cpp,-1,276,,"fprintf(stderr, ""-r remove realm from username\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""r"", ""remove"", ""realm"", ""from"", ""username\\n""]]",[-35814785932288394085],6220,44640.0,2
https://github.com/squid-cache/squid/commit/77721eb240367f9d4bd82638f118c811f2e93349,05 Nov 2009,"Author: Markus Moeller huaraz@moeller.plus.com>
Update squid_kerb_auth helper

 * remove sub configure again (too many issues)

Also, by Amso Jeffries
 * naming update to negotiate_kerberos_auth
 * polished helper detection rules in configure",10781,data/crawl/squid/hunk_3545.cpp,,,data/crawl/squid/old_hunk_3545.cpp,data/crawl/squid/new_hunk_3545.cpp,-1,214,,"fprintf(stderr, ""%s| %s: User not authenticated\n"", LogTime(),
		PROGRAM);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""%s"", ""%s"", ""User"", ""not"", ""authenticated\\n"", ""LogTime"", ""PROGRAM""]]",[-7848350853608063440],6219,622080.0,2
https://github.com/squid-cache/squid/commit/77721eb240367f9d4bd82638f118c811f2e93349,05 Nov 2009,"Author: Markus Moeller huaraz@moeller.plus.com>
Update squid_kerb_auth helper

 * remove sub configure again (too many issues)

Also, by Amso Jeffries
 * naming update to negotiate_kerberos_auth
 * polished helper detection rules in configure",10781,data/crawl/squid/hunk_3545.cpp,,,data/crawl/squid/old_hunk_3545.cpp,data/crawl/squid/new_hunk_3545.cpp,-1,131,,"fprintf(stderr, ""%s| %s: error while resolving hostname '%s'\n"",
	    LogTime(), PROGRAM, hostname);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""%s"", ""%s"", ""error"", ""while"", ""resolving"", ""hostname"", ""%s"", ""\\n"", ""LogTime"", ""PROGRAM"", ""hostname""]]",[11597186544908789104],6218,622080.0,2
https://github.com/squid-cache/squid/commit/e4ae841bb56fc39cf350c84d1aa04146f7bd808d,17 Nov 2009,Fixed some cases of linkage type mismatch and parameter shadowing,128,data/crawl/squid/hunk_3537.cpp,,,data/crawl/squid/old_hunk_3537.cpp,data/crawl/squid/new_hunk_3537.cpp,14,14,"fatalf(""Swap directory %s is not a directory."", path);","fatalf(""Swap directory %s is not a directory."", aPath);","[""updateVariable""]","[[""path""], [""aPath""]]",[2566756810777070080],6217,0.0,2
https://github.com/squid-cache/squid/commit/82b7abe3ff9fcee6e92696c8fbf2d66c6777ca2a,22 Nov 2009,"Author: Adrian Chadd + Tim Starling
Port from 2.7: Logging infrastructure updates.

 * Basic port of the Squid-2.7 modular logging code 
 * Adds support for async daemon helpers.
 * One daemon helper for file IO is included.
 * Adds UDP stream logging facility. (Tim Starling)

Ported by Amos Jeffries.",2427,data/crawl/squid/hunk_3511.cpp,,,data/crawl/squid/old_hunk_3511.cpp,data/crawl/squid/new_hunk_3511.cpp,-1,160,,"fatalf(""Cannot open %s: %s"", lf->path, xstrerror());","[""addLog""]","[[], [""fatalf"", ""Cannot"", ""open"", ""%s"", ""%s"", ""lf"", ""path"", ""xstrerror""]]",[12326428478525649570],6216,2548080.0,2
https://github.com/squid-cache/squid/commit/82b7abe3ff9fcee6e92696c8fbf2d66c6777ca2a,22 Nov 2009,"Author: Adrian Chadd + Tim Starling
Port from 2.7: Logging infrastructure updates.

 * Basic port of the Squid-2.7 modular logging code 
 * Adds support for async daemon helpers.
 * One daemon helper for file IO is included.
 * Adds UDP stream logging facility. (Tim Starling)

Ported by Amos Jeffries.",2427,data/crawl/squid/hunk_3510.cpp,,,data/crawl/squid/old_hunk_3510.cpp,data/crawl/squid/new_hunk_3510.cpp,-1,130,,"fatal(""I don't handle this error well!"");","[""addLog""]","[[], [""fatal"", ""I"", ""don"", ""t"", ""handle"", ""this"", ""error"", ""well""]]",[7001999352313155979],6215,0.0,2
https://github.com/squid-cache/squid/commit/a98bcbee0005004c1aa26042060eb1dd7dad482b,02 Dec 2009,"Shuffle simple math functions into SquidMath

This unlinks many depencies pulled in by tools.cc through the more
complicated permissions, and death reporting code.",230,data/crawl/squid/hunk_3486.cpp,,,data/crawl/squid/old_hunk_3486.cpp,data/crawl/squid/new_hunk_3486.cpp,2,2,"storeAppendPrintf(sentry, ""\tCPU Usage:\t%.2f%%\n"",
                      dpercent(cputime, runtime));","storeAppendPrintf(sentry, ""\tCPU Usage:\t%.2f%%\n"",
                      Math::doublePercent(cputime, runtime));","[""removeVariable"", ""addVariable""]","[[""dpercent""], [""Math"", ""doublePercent""]]",[-12199964483368167814],6214,0.0,2
https://github.com/squid-cache/squid/commit/a98bcbee0005004c1aa26042060eb1dd7dad482b,02 Dec 2009,"Shuffle simple math functions into SquidMath

This unlinks many depencies pulled in by tools.cc through the more
complicated permissions, and death reporting code.",230,data/crawl/squid/hunk_3485.cpp,,,data/crawl/squid/old_hunk_3485.cpp,data/crawl/squid/new_hunk_3485.cpp,2,2,"storeAppendPrintf(sentry, ""\tStorage Swap capacity:\t%4.1f%% used, %4.1f%% free\n"",
                      dpercent(store_swap_size, Store::Root().maxSize()),
                      dpercent((Store::Root().maxSize() - store_swap_size), Store::Root().maxSize()));","storeAppendPrintf(sentry, ""\tStorage Swap capacity:\t%4.1f%% used, %4.1f%% free\n"",
                      Math::doublePercent(store_swap_size, Store::Root().maxSize()),
                      Math::doublePercent((Store::Root().maxSize() - store_swap_size), Store::Root().maxSize()));","[""removeVariable"", ""addVariable""]","[[""dpercent"", ""dpercent""], [""Math"", ""doublePercent"", ""Math"", ""doublePercent""]]",[-24399928966736335628],6213,0.0,2
https://github.com/squid-cache/squid/commit/48d54e4daa77f1b390c3d38c0346949703fcb481,16 Dec 2009,"Run helpers on-demand

For some config backwards compatibility the maximum is kept as a single
integer first parameter to the *children directives.

Default setting changes:

 Instead of starting N helpers on startup and each reconfigure this
 makes the default zero and the configured value a maximum cap.
 The default maximum is raised from 5 to 20 for all helpers except
 for dnsservers where the maximum is raised to the old documented
 maximum of 32.

Obsoleted settings:
 url_rewrite_concurrency
  - replaced by the concurrency=N option now available on all *_children
    directives (including auth_param X children).
    To avoid compile problems this directive had to be fully dropped.

 auth_param X concurrency N
  - as above. However the option was able to be retained, as deprecated
    for future removal as well.


Behavior changes:

Whenever a request needs to use a helper and there are none available
immediately Squid tests to see if its okay to start a new one. Then does so.

The ""helpers dying too fast"" warnings and Squid closing has been modified
Squid will now not care about dying helpers if there are more that
startup=N active. If the death causes less than startup=N to be running
and is hit twice in less than 30 seconds will cause the warning message
to be doisplayed and Squid to abort same as before.

NP: that with startup=0 (the new default) helpers dying before or after
their first use will not crash Squid. But may result in a loop of
hung/failed requests and WILL result in a great many helper-failed
warnings in cache.log.

If needed we can bump the startup default back to 1 to avoid all that.
Or add a special check to kill squid if helpers die during startup and
provide a clearer log message ""Foo helper is dying before we can finish
starting it"" etc.

TODO: the current patch has no way to dynamically decrease the number of
      helpers. Only a reconfigure or helper dying can do that.",945,data/crawl/squid/hunk_3463.cpp,,,data/crawl/squid/old_hunk_3463.cpp,data/crawl/squid/new_hunk_3463.cpp,2,2,"storeAppendPrintf(sentry, ""number active: %d of %d (%d shutting down)\n"",
                      hlp->n_active, hlp->n_to_start, (hlp->n_running - hlp->n_active) );","storeAppendPrintf(sentry, ""number active: %d of %d (%d shutting down)\n"",
                      hlp->childs.n_active, hlp->childs.n_max, (hlp->childs.n_running - hlp->childs.n_active) );","[""updateVariable"", ""addVariable""]","[[""n_to_start""], [""childs"", ""childs"", ""n_max"", ""childs"", ""childs""]]",[30422362298305122727],6212,0.0,2
https://github.com/squid-cache/squid/commit/48d54e4daa77f1b390c3d38c0346949703fcb481,16 Dec 2009,"Run helpers on-demand

For some config backwards compatibility the maximum is kept as a single
integer first parameter to the *children directives.

Default setting changes:

 Instead of starting N helpers on startup and each reconfigure this
 makes the default zero and the configured value a maximum cap.
 The default maximum is raised from 5 to 20 for all helpers except
 for dnsservers where the maximum is raised to the old documented
 maximum of 32.

Obsoleted settings:
 url_rewrite_concurrency
  - replaced by the concurrency=N option now available on all *_children
    directives (including auth_param X children).
    To avoid compile problems this directive had to be fully dropped.

 auth_param X concurrency N
  - as above. However the option was able to be retained, as deprecated
    for future removal as well.


Behavior changes:

Whenever a request needs to use a helper and there are none available
immediately Squid tests to see if its okay to start a new one. Then does so.

The ""helpers dying too fast"" warnings and Squid closing has been modified
Squid will now not care about dying helpers if there are more that
startup=N active. If the death causes less than startup=N to be running
and is hit twice in less than 30 seconds will cause the warning message
to be doisplayed and Squid to abort same as before.

NP: that with startup=0 (the new default) helpers dying before or after
their first use will not crash Squid. But may result in a loop of
hung/failed requests and WILL result in a great many helper-failed
warnings in cache.log.

If needed we can bump the startup default back to 1 to avoid all that.
Or add a special check to kill squid if helpers die during startup and
provide a clearer log message ""Foo helper is dying before we can finish
starting it"" etc.

TODO: the current patch has no way to dynamically decrease the number of
      helpers. Only a reconfigure or helper dying can do that.",945,data/crawl/squid/hunk_3455.cpp,,,data/crawl/squid/old_hunk_3455.cpp,data/crawl/squid/new_hunk_3455.cpp,-1,19,,"fprintf(fp, ""%s"", buf + 1);","[""addLog""]","[[], [""fprintf"", ""fp"", ""%s"", ""buf"", ""1""]]",[-4859322144320450882],6211,17280.0,2
https://github.com/squid-cache/squid/commit/5a48ed18b5610e3e2d3d5250797375f4fb93dc1e,02 Jan 2010,"Basic Authentication Helper name upgrades

This nearly completes renaming and C++ compiling of the basic auth helpers.
MSNT is still pending cleanup in it's smb library code.

TODO: other helper types updated.",446,data/crawl/squid/hunk_3445.cpp,,,data/crawl/squid/old_hunk_3445.cpp,data/crawl/squid/new_hunk_3445.cpp,3,3,"fprintf(stderr, ""Usage: yp_auth <domainname> <nis map for password>\n"");","fprintf(stderr, ""Usage: basic_yp_auth <domainname> <nis map for password>\n"");","[""updateContent""]","[[""yp_auth""], [""basic_yp_auth""]]",[-4607854977406401089],6210,0.0,2
https://github.com/squid-cache/squid/commit/6a7f4dec1defc21c1e4469788ed25c8eb891a5c6,09 Jan 2010,Remove optional kerberos/spnegohelp/ library due to licensing issues,4343,data/crawl/squid/hunk_3443.cpp,,,data/crawl/squid/old_hunk_3443.cpp,data/crawl/squid/new_hunk_3443.cpp,12,-1,"fprintf(stdout, ""BH makeNegTokenTarg failed with rc=%d\n"",
                            rc);",,"[""removeLog""]","[[""fprintf"", ""stdout"", ""BH"", ""makeNegTokenTarg"", ""failed"", ""with"", ""rc"", ""%d\\n"", ""rc""], []]",[22674095869709003026],6209,46800.0,2
https://github.com/squid-cache/squid/commit/6a7f4dec1defc21c1e4469788ed25c8eb891a5c6,09 Jan 2010,Remove optional kerberos/spnegohelp/ library due to licensing issues,4343,data/crawl/squid/hunk_3443.cpp,,,data/crawl/squid/old_hunk_3443.cpp,data/crawl/squid/new_hunk_3443.cpp,9,-1,"fprintf(stderr,
                                ""%s| %s: makeNegTokenTarg failed with rc=%d\n"",
                                LogTime(), PROGRAM, rc);",,"[""removeLog""]","[[""fprintf"", ""stderr"", ""%s"", ""%s"", ""makeNegTokenTarg"", ""failed"", ""with"", ""rc"", ""%d\\n"", ""LogTime"", ""PROGRAM"", ""rc""], []]",[19420802712034584714],6208,46800.0,2
https://github.com/squid-cache/squid/commit/6a7f4dec1defc21c1e4469788ed25c8eb891a5c6,09 Jan 2010,Remove optional kerberos/spnegohelp/ library due to licensing issues,4343,data/crawl/squid/hunk_3442.cpp,,,data/crawl/squid/old_hunk_3442.cpp,data/crawl/squid/new_hunk_3442.cpp,33,-1,"fprintf(stderr, ""%s| %s: Token is possibly a GSSAPI token\n"",
                        LogTime(), PROGRAM);",,"[""removeLog""]","[[""fprintf"", ""stderr"", ""%s"", ""%s"", ""Token"", ""is"", ""possibly"", ""a"", ""GSSAPI"", ""token\\n"", ""LogTime"", ""PROGRAM""], []]",[10652912587544659733],6207,46800.0,2
https://github.com/squid-cache/squid/commit/6a7f4dec1defc21c1e4469788ed25c8eb891a5c6,09 Jan 2010,Remove optional kerberos/spnegohelp/ library due to licensing issues,4343,data/crawl/squid/hunk_3442.cpp,,,data/crawl/squid/old_hunk_3442.cpp,data/crawl/squid/new_hunk_3442.cpp,16,-1,"fprintf(stdout, ""BH Invalid GSS-SPNEGO query\n"");",,"[""removeLog""]","[[""fprintf"", ""stdout"", ""BH"", ""Invalid"", ""GSS"", ""SPNEGO"", ""query\\n""], []]",[20368763500999039302],6206,46800.0,2
https://github.com/squid-cache/squid/commit/6a7f4dec1defc21c1e4469788ed25c8eb891a5c6,09 Jan 2010,Remove optional kerberos/spnegohelp/ library due to licensing issues,4343,data/crawl/squid/hunk_3442.cpp,,,data/crawl/squid/old_hunk_3442.cpp,data/crawl/squid/new_hunk_3442.cpp,14,-1,"fprintf(stderr, ""%s| %s: Invalid GSS-SPNEGO query [%s]\n"",
                            LogTime(), PROGRAM, buf);",,"[""removeLog""]","[[""fprintf"", ""stderr"", ""%s"", ""%s"", ""Invalid"", ""GSS"", ""SPNEGO"", ""query"", ""[%s]\\n"", ""LogTime"", ""PROGRAM"", ""buf""], []]",[25308916076387808654],6205,46800.0,2
https://github.com/squid-cache/squid/commit/6a7f4dec1defc21c1e4469788ed25c8eb891a5c6,09 Jan 2010,Remove optional kerberos/spnegohelp/ library due to licensing issues,4343,data/crawl/squid/hunk_3442.cpp,,,data/crawl/squid/old_hunk_3442.cpp,data/crawl/squid/new_hunk_3442.cpp,8,-1,"fprintf(stderr, ""%s| %s: parseNegTokenInit failed with rc=%d\n"",
                        LogTime(), PROGRAM, rc);",,"[""removeLog""]","[[""fprintf"", ""stderr"", ""%s"", ""%s"", ""parseNegTokenInit"", ""failed"", ""with"", ""rc"", ""%d\\n"", ""LogTime"", ""PROGRAM"", ""rc""], []]",[23893375745594741414],6204,46800.0,2
https://github.com/squid-cache/squid/commit/5d8e63c9ae3b576a7b0c9c7e391c11e733ac8160,09 Feb 2010,"Author: Markus Moeller <huaraz@moeller.plus.com>
squid_kerb_auth logging clarification

add ERROR, WARNING, etc to the logging messages.",52,data/crawl/squid/hunk_3421.cpp,,,data/crawl/squid/old_hunk_3421.cpp,data/crawl/squid/new_hunk_3421.cpp,9,9,"fprintf(stderr,
                ""%s| %s: error while resolving hostname with getaddrinfo: %s\n"",
                LogTime(), PROGRAM, xgai_strerror(rc));","fprintf(stderr,
                ""%s| %s: ERROR: resolving hostname with getaddrinfo: %s failed\n"",
                LogTime(), PROGRAM, xgai_strerror(rc));","[""updateContent""]","[[""error"", ""while"", ""%s\\n""], [""ERROR"", ""%s"", ""failed\\n""]]",[-9424697973057449785],6203,0.0,2
https://github.com/squid-cache/squid/commit/c7b1dd5d377a3cd748cf48dde9cfa12e1fb5f3df,22 Apr 2010,"Clarify http_port mode options and enhance config validation.

This makes some changes to the config validation of http_port lines
and documentation of http_port.

It alters documentation to call accel, tproxy, intercept, and sslbump
options ""mode flags"" since they determine the overall code paths which
traffic received is handled by.

The http_port syntax docs are updated to show that mode flags must go
first before any options. This is not strictly true, since the mode flag
only must go before mode-specific options. But its clearer to explain the
syntax docs like this. Both mode and options remain completely optional
(except that some options require certain modes as before).

The parser is updated to validate that only one of the mode flags is used.
Attempts to mix them will result in a fatal error. Attempts to use any of
the mode-specific options without the correct mode being enabled first will
result in a fatal message.

As a side-effect of this the implicit enabling of accel on several of its
options has been dropped. Explicit use as mode flag is preferred (and
required) instead for clear reading of the config.

Implications for older configs are that the http_port may fail a parse
check until some basic re-ordering of options or splitting of http_port
into multiple entries is done. Hopefully the messages emitted on failure
are clear enough for people to follow easily.",273,data/crawl/squid/hunk_3390.cpp,,,data/crawl/squid/old_hunk_3390.cpp,data/crawl/squid/new_hunk_3390.cpp,-1,4,,"storeAppendPrintf(e, "" sslBump"");","[""addLog""]","[[], [""storeAppendPrintf"", ""e"", ""sslBump""]]",[3847535975479246232],6202,576000.0,2
https://github.com/squid-cache/squid/commit/fe090a8613fa719ae354ee7e6027e3006236c8be,02 May 2010,"Replaced blocking comm_open_listener() call for HTTP ports with
Ipc::StartListening calls to use the ""shared listen"" feature when doing SMP.

TODO: convert HTTPS code the same way.",84,data/crawl/squid/hunk_3381.cpp,,,data/crawl/squid/old_hunk_3381.cpp,data/crawl/squid/new_hunk_3381.cpp,-1,32,,"fatal(""Cannot open HTTP Port"");","[""addLog""]","[[], [""fatal"", ""Cannot"", ""open"", ""HTTP"", ""Port""]]",[5872952252793402891],6201,3270960.0,2
https://github.com/squid-cache/squid/commit/42687bb299c004cd94424c85c9a0fa6bf38344bb,09 May 2010,Kill rfc1035_errno & error_message globals. We always have the error code available anyway,58,data/crawl/squid/hunk_3362.cpp,,,data/crawl/squid/old_hunk_3362.cpp,data/crawl/squid/new_hunk_3362.cpp,3,3,"printf(""ERROR %d\n"", rfc1035_errno);","printf(""ERROR %d\n"", -n);","[""updateVariable"", ""addVariable""]","[[""rfc1035_errno""], [""n""]]",[8573910639375888055],6200,0.0,2
https://github.com/squid-cache/squid/commit/4542b25ba0c3d195fcd2f43de2e6ba3167957156,02 Jun 2010,"Bug 2305: Multiple leaks and assertion crashes in authentication.

 * implements proper RefCounting using the RefCount.h classes for
   almost all auth objects in Squid.

 * Restructures auth objects with a simpler structure of duties and scopes.

 * Prunes away several circular and indirectly circular pointer loops

 * Adds an API to auth config for handling the mainRotate() event. To only
   shutdown helpers, fixing the loss of cached credentials on rotate.

 * Adds a username_cache page to cachemgr interface to display the current
   credentials and their TTLs to various revalidation or garbage events.


With this we end up with several global pointers for the auth schemes which
have been built into the current Squid. These are RefCount pointers, fixing
the leak of schemes on shutdown. Schemes are now also permanent structures
for the runtime of Squid, fixing leaks on reconfigure and rotate actions.

These AuthSchemes are responsible for creating auth Config objects for each
auth protocol configured in squid.conf. These config objects are now also
able to be altered with a reconfigure instead of requiring a restart.

Each HTTP request authentication attempt generates AuthUserRequest objects,
which may or may not pointer to an AuthUser set of credentials being checked.
AuthUserRequest is RefCounted instead of locked, fixing several assertion
crashes.

AuthUser is now RefCounted instead of locked. It's children inherit
these properties. This simplifies the object handling a lot and fixes
several assertions.
 * This also means AuthUser no longer needs a back-pointer to all
AuthUserRequest in order to see if its still needed alive, fixing one
circular lock loop and a few possible assertions.
 * The username cache pointers to only AuthUser objects, fixing a second
cirular lock loop and potentially leakage. Also simplifying the hash cache
handling a lot.

Non-Auth code needing a reference to authentication credentials should
hold a pointer to either an AuthUserRequest or AuthUser object. Not any
other auth object.


FUTURE WORK;
 There is still some conditions leading to auth re-challenge when they
 are not expected.
 A fair chunk of classes and enums have been shuffled into separate files
 to keep the scopes clearer. This could be increased in future when
 building the Auth namespace.
 Potential is now present for simpler TTL handling for all auth types.



This work was a collaboration between multiple interested parties over
the last year, with additional developer time and testing funded by
Netspace Online Systems.",5398,data/crawl/squid/hunk_3346.cpp,,,data/crawl/squid/old_hunk_3346.cpp,data/crawl/squid/new_hunk_3346.cpp,-1,347,,"fatalf(""authenticateNTLMHandleReply: *** Unsupported helper response ***, '%s'\n"", reply);","[""addLog""]","[[], [""fatalf"", ""authenticateNTLMHandleReply"", ""***"", ""Unsupported"", ""helper"", ""response"", ""***"", ""%s"", ""\\n"", ""reply""]]",[-3623871199738568275],6199,1211760.0,2
https://github.com/squid-cache/squid/commit/4542b25ba0c3d195fcd2f43de2e6ba3167957156,02 Jun 2010,"Bug 2305: Multiple leaks and assertion crashes in authentication.

 * implements proper RefCounting using the RefCount.h classes for
   almost all auth objects in Squid.

 * Restructures auth objects with a simpler structure of duties and scopes.

 * Prunes away several circular and indirectly circular pointer loops

 * Adds an API to auth config for handling the mainRotate() event. To only
   shutdown helpers, fixing the loss of cached credentials on rotate.

 * Adds a username_cache page to cachemgr interface to display the current
   credentials and their TTLs to various revalidation or garbage events.


With this we end up with several global pointers for the auth schemes which
have been built into the current Squid. These are RefCount pointers, fixing
the leak of schemes on shutdown. Schemes are now also permanent structures
for the runtime of Squid, fixing leaks on reconfigure and rotate actions.

These AuthSchemes are responsible for creating auth Config objects for each
auth protocol configured in squid.conf. These config objects are now also
able to be altered with a reconfigure instead of requiring a restart.

Each HTTP request authentication attempt generates AuthUserRequest objects,
which may or may not pointer to an AuthUser set of credentials being checked.
AuthUserRequest is RefCounted instead of locked, fixing several assertion
crashes.

AuthUser is now RefCounted instead of locked. It's children inherit
these properties. This simplifies the object handling a lot and fixes
several assertions.
 * This also means AuthUser no longer needs a back-pointer to all
AuthUserRequest in order to see if its still needed alive, fixing one
circular lock loop and a few possible assertions.
 * The username cache pointers to only AuthUser objects, fixing a second
cirular lock loop and potentially leakage. Also simplifying the hash cache
handling a lot.

Non-Auth code needing a reference to authentication credentials should
hold a pointer to either an AuthUserRequest or AuthUser object. Not any
other auth object.


FUTURE WORK;
 There is still some conditions leading to auth re-challenge when they
 are not expected.
 A fair chunk of classes and enums have been shuffled into separate files
 to keep the scopes clearer. This could be increased in future when
 building the Auth namespace.
 Potential is now present for simpler TTL handling for all auth types.



This work was a collaboration between multiple interested parties over
the last year, with additional developer time and testing funded by
Netspace Online Systems.",5398,data/crawl/squid/hunk_3342.cpp,,,data/crawl/squid/old_hunk_3342.cpp,data/crawl/squid/new_hunk_3342.cpp,-1,395,,"fatalf(""authenticateNegotiateHandleReply: *** Unsupported helper response ***, '%s'\n"", reply);","[""addLog""]","[[], [""fatalf"", ""authenticateNegotiateHandleReply"", ""***"", ""Unsupported"", ""helper"", ""response"", ""***"", ""%s"", ""\\n"", ""reply""]]",[2877559570256363225],6198,1211760.0,2
https://github.com/squid-cache/squid/commit/4542b25ba0c3d195fcd2f43de2e6ba3167957156,02 Jun 2010,"Bug 2305: Multiple leaks and assertion crashes in authentication.

 * implements proper RefCounting using the RefCount.h classes for
   almost all auth objects in Squid.

 * Restructures auth objects with a simpler structure of duties and scopes.

 * Prunes away several circular and indirectly circular pointer loops

 * Adds an API to auth config for handling the mainRotate() event. To only
   shutdown helpers, fixing the loss of cached credentials on rotate.

 * Adds a username_cache page to cachemgr interface to display the current
   credentials and their TTLs to various revalidation or garbage events.


With this we end up with several global pointers for the auth schemes which
have been built into the current Squid. These are RefCount pointers, fixing
the leak of schemes on shutdown. Schemes are now also permanent structures
for the runtime of Squid, fixing leaks on reconfigure and rotate actions.

These AuthSchemes are responsible for creating auth Config objects for each
auth protocol configured in squid.conf. These config objects are now also
able to be altered with a reconfigure instead of requiring a restart.

Each HTTP request authentication attempt generates AuthUserRequest objects,
which may or may not pointer to an AuthUser set of credentials being checked.
AuthUserRequest is RefCounted instead of locked, fixing several assertion
crashes.

AuthUser is now RefCounted instead of locked. It's children inherit
these properties. This simplifies the object handling a lot and fixes
several assertions.
 * This also means AuthUser no longer needs a back-pointer to all
AuthUserRequest in order to see if its still needed alive, fixing one
circular lock loop and a few possible assertions.
 * The username cache pointers to only AuthUser objects, fixing a second
cirular lock loop and potentially leakage. Also simplifying the hash cache
handling a lot.

Non-Auth code needing a reference to authentication credentials should
hold a pointer to either an AuthUserRequest or AuthUser object. Not any
other auth object.


FUTURE WORK;
 There is still some conditions leading to auth re-challenge when they
 are not expected.
 A fair chunk of classes and enums have been shuffled into separate files
 to keep the scopes clearer. This could be increased in future when
 building the Auth namespace.
 Potential is now present for simpler TTL handling for all auth types.



This work was a collaboration between multiple interested parties over
the last year, with additional developer time and testing funded by
Netspace Online Systems.",5398,data/crawl/squid/hunk_3342.cpp,,,data/crawl/squid/old_hunk_3342.cpp,data/crawl/squid/new_hunk_3342.cpp,-1,376,,auth_user_request->denyMessage(arg);,"[""addLog""]","[[], [""auth_user_request"", ""denyMessage"", ""arg""]]",[4747565790080841534],6197,1211760.0,2
https://github.com/squid-cache/squid/commit/4542b25ba0c3d195fcd2f43de2e6ba3167957156,02 Jun 2010,"Bug 2305: Multiple leaks and assertion crashes in authentication.

 * implements proper RefCounting using the RefCount.h classes for
   almost all auth objects in Squid.

 * Restructures auth objects with a simpler structure of duties and scopes.

 * Prunes away several circular and indirectly circular pointer loops

 * Adds an API to auth config for handling the mainRotate() event. To only
   shutdown helpers, fixing the loss of cached credentials on rotate.

 * Adds a username_cache page to cachemgr interface to display the current
   credentials and their TTLs to various revalidation or garbage events.


With this we end up with several global pointers for the auth schemes which
have been built into the current Squid. These are RefCount pointers, fixing
the leak of schemes on shutdown. Schemes are now also permanent structures
for the runtime of Squid, fixing leaks on reconfigure and rotate actions.

These AuthSchemes are responsible for creating auth Config objects for each
auth protocol configured in squid.conf. These config objects are now also
able to be altered with a reconfigure instead of requiring a restart.

Each HTTP request authentication attempt generates AuthUserRequest objects,
which may or may not pointer to an AuthUser set of credentials being checked.
AuthUserRequest is RefCounted instead of locked, fixing several assertion
crashes.

AuthUser is now RefCounted instead of locked. It's children inherit
these properties. This simplifies the object handling a lot and fixes
several assertions.
 * This also means AuthUser no longer needs a back-pointer to all
AuthUserRequest in order to see if its still needed alive, fixing one
circular lock loop and a few possible assertions.
 * The username cache pointers to only AuthUser objects, fixing a second
cirular lock loop and potentially leakage. Also simplifying the hash cache
handling a lot.

Non-Auth code needing a reference to authentication credentials should
hold a pointer to either an AuthUserRequest or AuthUser object. Not any
other auth object.


FUTURE WORK;
 There is still some conditions leading to auth re-challenge when they
 are not expected.
 A fair chunk of classes and enums have been shuffled into separate files
 to keep the scopes clearer. This could be increased in future when
 building the Auth namespace.
 Potential is now present for simpler TTL handling for all auth types.



This work was a collaboration between multiple interested parties over
the last year, with additional developer time and testing funded by
Netspace Online Systems.",5398,data/crawl/squid/hunk_3342.cpp,,,data/crawl/squid/old_hunk_3342.cpp,data/crawl/squid/new_hunk_3342.cpp,-1,323,,"auth_user_request->denyMessage(""Authentication in progress"");","[""addLog""]","[[], [""auth_user_request"", ""denyMessage"", ""Authentication"", ""in"", ""progress""]]",[-13487520356847963479],6196,0.0,2
https://github.com/squid-cache/squid/commit/4542b25ba0c3d195fcd2f43de2e6ba3167957156,02 Jun 2010,"Bug 2305: Multiple leaks and assertion crashes in authentication.

 * implements proper RefCounting using the RefCount.h classes for
   almost all auth objects in Squid.

 * Restructures auth objects with a simpler structure of duties and scopes.

 * Prunes away several circular and indirectly circular pointer loops

 * Adds an API to auth config for handling the mainRotate() event. To only
   shutdown helpers, fixing the loss of cached credentials on rotate.

 * Adds a username_cache page to cachemgr interface to display the current
   credentials and their TTLs to various revalidation or garbage events.


With this we end up with several global pointers for the auth schemes which
have been built into the current Squid. These are RefCount pointers, fixing
the leak of schemes on shutdown. Schemes are now also permanent structures
for the runtime of Squid, fixing leaks on reconfigure and rotate actions.

These AuthSchemes are responsible for creating auth Config objects for each
auth protocol configured in squid.conf. These config objects are now also
able to be altered with a reconfigure instead of requiring a restart.

Each HTTP request authentication attempt generates AuthUserRequest objects,
which may or may not pointer to an AuthUser set of credentials being checked.
AuthUserRequest is RefCounted instead of locked, fixing several assertion
crashes.

AuthUser is now RefCounted instead of locked. It's children inherit
these properties. This simplifies the object handling a lot and fixes
several assertions.
 * This also means AuthUser no longer needs a back-pointer to all
AuthUserRequest in order to see if its still needed alive, fixing one
circular lock loop and a few possible assertions.
 * The username cache pointers to only AuthUser objects, fixing a second
cirular lock loop and potentially leakage. Also simplifying the hash cache
handling a lot.

Non-Auth code needing a reference to authentication credentials should
hold a pointer to either an AuthUserRequest or AuthUser object. Not any
other auth object.


FUTURE WORK;
 There is still some conditions leading to auth re-challenge when they
 are not expected.
 A fair chunk of classes and enums have been shuffled into separate files
 to keep the scopes clearer. This could be increased in future when
 building the Auth namespace.
 Potential is now present for simpler TTL handling for all auth types.



This work was a collaboration between multiple interested parties over
the last year, with additional developer time and testing funded by
Netspace Online Systems.",5398,data/crawl/squid/hunk_3340.cpp,,,data/crawl/squid/old_hunk_3340.cpp,data/crawl/squid/new_hunk_3340.cpp,85,-1,"auth_user_request->denyMessage(""Login successful"");",,"[""removeLog""]","[[""auth_user_request"", ""denyMessage"", ""Login"", ""successful""], []]",[-9105902704882108649],6195,0.0,2
https://github.com/squid-cache/squid/commit/4542b25ba0c3d195fcd2f43de2e6ba3167957156,02 Jun 2010,"Bug 2305: Multiple leaks and assertion crashes in authentication.

 * implements proper RefCounting using the RefCount.h classes for
   almost all auth objects in Squid.

 * Restructures auth objects with a simpler structure of duties and scopes.

 * Prunes away several circular and indirectly circular pointer loops

 * Adds an API to auth config for handling the mainRotate() event. To only
   shutdown helpers, fixing the loss of cached credentials on rotate.

 * Adds a username_cache page to cachemgr interface to display the current
   credentials and their TTLs to various revalidation or garbage events.


With this we end up with several global pointers for the auth schemes which
have been built into the current Squid. These are RefCount pointers, fixing
the leak of schemes on shutdown. Schemes are now also permanent structures
for the runtime of Squid, fixing leaks on reconfigure and rotate actions.

These AuthSchemes are responsible for creating auth Config objects for each
auth protocol configured in squid.conf. These config objects are now also
able to be altered with a reconfigure instead of requiring a restart.

Each HTTP request authentication attempt generates AuthUserRequest objects,
which may or may not pointer to an AuthUser set of credentials being checked.
AuthUserRequest is RefCounted instead of locked, fixing several assertion
crashes.

AuthUser is now RefCounted instead of locked. It's children inherit
these properties. This simplifies the object handling a lot and fixes
several assertions.
 * This also means AuthUser no longer needs a back-pointer to all
AuthUserRequest in order to see if its still needed alive, fixing one
circular lock loop and a few possible assertions.
 * The username cache pointers to only AuthUser objects, fixing a second
cirular lock loop and potentially leakage. Also simplifying the hash cache
handling a lot.

Non-Auth code needing a reference to authentication credentials should
hold a pointer to either an AuthUserRequest or AuthUser object. Not any
other auth object.


FUTURE WORK;
 There is still some conditions leading to auth re-challenge when they
 are not expected.
 A fair chunk of classes and enums have been shuffled into separate files
 to keep the scopes clearer. This could be increased in future when
 building the Auth namespace.
 Potential is now present for simpler TTL handling for all auth types.



This work was a collaboration between multiple interested parties over
the last year, with additional developer time and testing funded by
Netspace Online Systems.",5398,data/crawl/squid/hunk_3340.cpp,,,data/crawl/squid/old_hunk_3340.cpp,data/crawl/squid/new_hunk_3340.cpp,75,-1,"auth_user_request->denyMessage(""NTLM authentication requires a persistent connection"");",,"[""removeLog""]","[[""auth_user_request"", ""denyMessage"", ""NTLM"", ""authentication"", ""requires"", ""a"", ""persistent"", ""connection""], []]",[18540693860504430209],6194,0.0,2
https://github.com/squid-cache/squid/commit/4542b25ba0c3d195fcd2f43de2e6ba3167957156,02 Jun 2010,"Bug 2305: Multiple leaks and assertion crashes in authentication.

 * implements proper RefCounting using the RefCount.h classes for
   almost all auth objects in Squid.

 * Restructures auth objects with a simpler structure of duties and scopes.

 * Prunes away several circular and indirectly circular pointer loops

 * Adds an API to auth config for handling the mainRotate() event. To only
   shutdown helpers, fixing the loss of cached credentials on rotate.

 * Adds a username_cache page to cachemgr interface to display the current
   credentials and their TTLs to various revalidation or garbage events.


With this we end up with several global pointers for the auth schemes which
have been built into the current Squid. These are RefCount pointers, fixing
the leak of schemes on shutdown. Schemes are now also permanent structures
for the runtime of Squid, fixing leaks on reconfigure and rotate actions.

These AuthSchemes are responsible for creating auth Config objects for each
auth protocol configured in squid.conf. These config objects are now also
able to be altered with a reconfigure instead of requiring a restart.

Each HTTP request authentication attempt generates AuthUserRequest objects,
which may or may not pointer to an AuthUser set of credentials being checked.
AuthUserRequest is RefCounted instead of locked, fixing several assertion
crashes.

AuthUser is now RefCounted instead of locked. It's children inherit
these properties. This simplifies the object handling a lot and fixes
several assertions.
 * This also means AuthUser no longer needs a back-pointer to all
AuthUserRequest in order to see if its still needed alive, fixing one
circular lock loop and a few possible assertions.
 * The username cache pointers to only AuthUser objects, fixing a second
cirular lock loop and potentially leakage. Also simplifying the hash cache
handling a lot.

Non-Auth code needing a reference to authentication credentials should
hold a pointer to either an AuthUserRequest or AuthUser object. Not any
other auth object.


FUTURE WORK;
 There is still some conditions leading to auth re-challenge when they
 are not expected.
 A fair chunk of classes and enums have been shuffled into separate files
 to keep the scopes clearer. This could be increased in future when
 building the Auth namespace.
 Potential is now present for simpler TTL handling for all auth types.



This work was a collaboration between multiple interested parties over
the last year, with additional developer time and testing funded by
Netspace Online Systems.",5398,data/crawl/squid/hunk_3340.cpp,,,data/crawl/squid/old_hunk_3340.cpp,data/crawl/squid/new_hunk_3340.cpp,71,-1,"auth_user_request->denyMessage(""Authentication in progress"");",,"[""removeLog""]","[[""auth_user_request"", ""denyMessage"", ""Authentication"", ""in"", ""progress""], []]",[13487520356847963479],6193,0.0,2
https://github.com/squid-cache/squid/commit/4542b25ba0c3d195fcd2f43de2e6ba3167957156,02 Jun 2010,"Bug 2305: Multiple leaks and assertion crashes in authentication.

 * implements proper RefCounting using the RefCount.h classes for
   almost all auth objects in Squid.

 * Restructures auth objects with a simpler structure of duties and scopes.

 * Prunes away several circular and indirectly circular pointer loops

 * Adds an API to auth config for handling the mainRotate() event. To only
   shutdown helpers, fixing the loss of cached credentials on rotate.

 * Adds a username_cache page to cachemgr interface to display the current
   credentials and their TTLs to various revalidation or garbage events.


With this we end up with several global pointers for the auth schemes which
have been built into the current Squid. These are RefCount pointers, fixing
the leak of schemes on shutdown. Schemes are now also permanent structures
for the runtime of Squid, fixing leaks on reconfigure and rotate actions.

These AuthSchemes are responsible for creating auth Config objects for each
auth protocol configured in squid.conf. These config objects are now also
able to be altered with a reconfigure instead of requiring a restart.

Each HTTP request authentication attempt generates AuthUserRequest objects,
which may or may not pointer to an AuthUser set of credentials being checked.
AuthUserRequest is RefCounted instead of locked, fixing several assertion
crashes.

AuthUser is now RefCounted instead of locked. It's children inherit
these properties. This simplifies the object handling a lot and fixes
several assertions.
 * This also means AuthUser no longer needs a back-pointer to all
AuthUserRequest in order to see if its still needed alive, fixing one
circular lock loop and a few possible assertions.
 * The username cache pointers to only AuthUser objects, fixing a second
cirular lock loop and potentially leakage. Also simplifying the hash cache
handling a lot.

Non-Auth code needing a reference to authentication credentials should
hold a pointer to either an AuthUserRequest or AuthUser object. Not any
other auth object.


FUTURE WORK;
 There is still some conditions leading to auth re-challenge when they
 are not expected.
 A fair chunk of classes and enums have been shuffled into separate files
 to keep the scopes clearer. This could be increased in future when
 building the Auth namespace.
 Potential is now present for simpler TTL handling for all auth types.



This work was a collaboration between multiple interested parties over
the last year, with additional developer time and testing funded by
Netspace Online Systems.",5398,data/crawl/squid/hunk_3336.cpp,,,data/crawl/squid/old_hunk_3336.cpp,data/crawl/squid/new_hunk_3336.cpp,-1,304,,digest_request->setDenyMessage(t);,"[""addLog""]","[[], [""digest_request"", ""setDenyMessage"", ""t""]]",[15362534897672714506],6192,1342800.0,2
https://github.com/squid-cache/squid/commit/4542b25ba0c3d195fcd2f43de2e6ba3167957156,02 Jun 2010,"Bug 2305: Multiple leaks and assertion crashes in authentication.

 * implements proper RefCounting using the RefCount.h classes for
   almost all auth objects in Squid.

 * Restructures auth objects with a simpler structure of duties and scopes.

 * Prunes away several circular and indirectly circular pointer loops

 * Adds an API to auth config for handling the mainRotate() event. To only
   shutdown helpers, fixing the loss of cached credentials on rotate.

 * Adds a username_cache page to cachemgr interface to display the current
   credentials and their TTLs to various revalidation or garbage events.


With this we end up with several global pointers for the auth schemes which
have been built into the current Squid. These are RefCount pointers, fixing
the leak of schemes on shutdown. Schemes are now also permanent structures
for the runtime of Squid, fixing leaks on reconfigure and rotate actions.

These AuthSchemes are responsible for creating auth Config objects for each
auth protocol configured in squid.conf. These config objects are now also
able to be altered with a reconfigure instead of requiring a restart.

Each HTTP request authentication attempt generates AuthUserRequest objects,
which may or may not pointer to an AuthUser set of credentials being checked.
AuthUserRequest is RefCounted instead of locked, fixing several assertion
crashes.

AuthUser is now RefCounted instead of locked. It's children inherit
these properties. This simplifies the object handling a lot and fixes
several assertions.
 * This also means AuthUser no longer needs a back-pointer to all
AuthUserRequest in order to see if its still needed alive, fixing one
circular lock loop and a few possible assertions.
 * The username cache pointers to only AuthUser objects, fixing a second
cirular lock loop and potentially leakage. Also simplifying the hash cache
handling a lot.

Non-Auth code needing a reference to authentication credentials should
hold a pointer to either an AuthUserRequest or AuthUser object. Not any
other auth object.


FUTURE WORK;
 There is still some conditions leading to auth re-challenge when they
 are not expected.
 A fair chunk of classes and enums have been shuffled into separate files
 to keep the scopes clearer. This could be increased in future when
 building the Auth namespace.
 Potential is now present for simpler TTL handling for all auth types.



This work was a collaboration between multiple interested parties over
the last year, with additional developer time and testing funded by
Netspace Online Systems.",5398,data/crawl/squid/hunk_3334.cpp,,,data/crawl/squid/old_hunk_3334.cpp,data/crawl/squid/new_hunk_3334.cpp,85,-1,"digest_request->setDenyMessage(""Incorrect password"");",,"[""removeLog""]","[[""digest_request"", ""setDenyMessage"", ""Incorrect"", ""password""], []]",[-3651971687145068688],6191,0.0,2
https://github.com/squid-cache/squid/commit/4542b25ba0c3d195fcd2f43de2e6ba3167957156,02 Jun 2010,"Bug 2305: Multiple leaks and assertion crashes in authentication.

 * implements proper RefCounting using the RefCount.h classes for
   almost all auth objects in Squid.

 * Restructures auth objects with a simpler structure of duties and scopes.

 * Prunes away several circular and indirectly circular pointer loops

 * Adds an API to auth config for handling the mainRotate() event. To only
   shutdown helpers, fixing the loss of cached credentials on rotate.

 * Adds a username_cache page to cachemgr interface to display the current
   credentials and their TTLs to various revalidation or garbage events.


With this we end up with several global pointers for the auth schemes which
have been built into the current Squid. These are RefCount pointers, fixing
the leak of schemes on shutdown. Schemes are now also permanent structures
for the runtime of Squid, fixing leaks on reconfigure and rotate actions.

These AuthSchemes are responsible for creating auth Config objects for each
auth protocol configured in squid.conf. These config objects are now also
able to be altered with a reconfigure instead of requiring a restart.

Each HTTP request authentication attempt generates AuthUserRequest objects,
which may or may not pointer to an AuthUser set of credentials being checked.
AuthUserRequest is RefCounted instead of locked, fixing several assertion
crashes.

AuthUser is now RefCounted instead of locked. It's children inherit
these properties. This simplifies the object handling a lot and fixes
several assertions.
 * This also means AuthUser no longer needs a back-pointer to all
AuthUserRequest in order to see if its still needed alive, fixing one
circular lock loop and a few possible assertions.
 * The username cache pointers to only AuthUser objects, fixing a second
cirular lock loop and potentially leakage. Also simplifying the hash cache
handling a lot.

Non-Auth code needing a reference to authentication credentials should
hold a pointer to either an AuthUserRequest or AuthUser object. Not any
other auth object.


FUTURE WORK;
 There is still some conditions leading to auth re-challenge when they
 are not expected.
 A fair chunk of classes and enums have been shuffled into separate files
 to keep the scopes clearer. This could be increased in future when
 building the Auth namespace.
 Potential is now present for simpler TTL handling for all auth types.



This work was a collaboration between multiple interested parties over
the last year, with additional developer time and testing funded by
Netspace Online Systems.",5398,data/crawl/squid/hunk_3329.cpp,,,data/crawl/squid/old_hunk_3329.cpp,data/crawl/squid/new_hunk_3329.cpp,-1,32,,"storeAppendPrintf(output, ""--------------- --------- --------- --------- ------------------------------\n"");","[""addLog""]","[[], [""storeAppendPrintf"", ""output"", ""\\n""]]",[-2964719264643062512],6190,2021760.0,2
https://github.com/squid-cache/squid/commit/f3f0f5634cad7a073e461f5a45e797f9c1349324,11 Jun 2010,"Port from 2.7: max_filedescriptor config option

Since Squid no longer really has any hardcoded filedescriptor limitations
it makes sense to have a squid.conf directive allowing the number of
filedescriptors to be tuned runtime. Default if unset is to obey whatever
ulimit settings as before.

 setMaxFD: figures out what to we can use for Squid_MaxFD

 setSystemLimits: Configures the system limitations to match our
expectations which might be lower than what setMaxFD finds if
the comm loop has additional restrictions",100,data/crawl/squid/hunk_3316.cpp,,,data/crawl/squid/old_hunk_3316.cpp,data/crawl/squid/new_hunk_3316.cpp,41,-1,fatal_dump(tmp_error_buf);,,"[""removeLog""]","[[""fatal_dump"", ""tmp_error_buf""], []]",[17726151251914438360],6189,2546640.0,2
https://github.com/squid-cache/squid/commit/75aa769bc374a0ebb66d3c41a763d5ca2ed44d4b,11 Jun 2010,"Upgrade ntlm_fake_auth helper and internal libntlmauth

Fake auth helper changes:

 - renames fakeauth to ntlm_fake_auth
 - links ntlm_fake_auth to libntlmauth
 - removes duplicate code provided by libcompat and libntlmauth
 - moves the remaining bits of fakeauth/ntlm.h to ntlm_fake_auth.cc

Library API changes:

 - moves some of the basic NTLM operations into libntlmauth
    * fetch_string UNICODE support
    * make challenge packet
    * validate packet type
    * make challenge nonce
    * unpack user and domain from authenticate packet

 - tweaks libntlmauth to split the make challenge operation so that it
   only generates the challenge object (does not encode blob for sending,
   or hard-code field values any more).

Other related changes:

 - tweaks the smb_lm helper which already linked libntlmauth so that it
   uses the updated API correctly after the above changes.

 - documents libntlmauth and some of ntlm_fake_auth helper",1471,data/crawl/squid/hunk_3315.cpp,,,data/crawl/squid/old_hunk_3315.cpp,data/crawl/squid/new_hunk_3315.cpp,-1,130,,"fprintf(stderr, ""ntlmDecodeAuth: header check fails\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""ntlmDecodeAuth"", ""header"", ""check"", ""fails\\n""]]",[-15589273938587539073],6188,2477520.0,2
https://github.com/squid-cache/squid/commit/75aa769bc374a0ebb66d3c41a763d5ca2ed44d4b,11 Jun 2010,"Upgrade ntlm_fake_auth helper and internal libntlmauth

Fake auth helper changes:

 - renames fakeauth to ntlm_fake_auth
 - links ntlm_fake_auth to libntlmauth
 - removes duplicate code provided by libcompat and libntlmauth
 - moves the remaining bits of fakeauth/ntlm.h to ntlm_fake_auth.cc

Library API changes:

 - moves some of the basic NTLM operations into libntlmauth
    * fetch_string UNICODE support
    * make challenge packet
    * validate packet type
    * make challenge nonce
    * unpack user and domain from authenticate packet

 - tweaks libntlmauth to split the make challenge operation so that it
   only generates the challenge object (does not encode blob for sending,
   or hard-code field values any more).

Other related changes:

 - tweaks the smb_lm helper which already linked libntlmauth so that it
   uses the updated API correctly after the above changes.

 - documents libntlmauth and some of ntlm_fake_auth helper",1471,data/crawl/squid/hunk_3314.cpp,,,data/crawl/squid/old_hunk_3314.cpp,data/crawl/squid/new_hunk_3314.cpp,-1,19,,"fprintf(stderr, ""ntlmCheckHeader: bad header signature\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""ntlmCheckHeader"", ""bad"", ""header"", ""signature\\n""]]",[-18351222388485653775],6187,2477520.0,2
https://github.com/squid-cache/squid/commit/75aa769bc374a0ebb66d3c41a763d5ca2ed44d4b,11 Jun 2010,"Upgrade ntlm_fake_auth helper and internal libntlmauth

Fake auth helper changes:

 - renames fakeauth to ntlm_fake_auth
 - links ntlm_fake_auth to libntlmauth
 - removes duplicate code provided by libcompat and libntlmauth
 - moves the remaining bits of fakeauth/ntlm.h to ntlm_fake_auth.cc

Library API changes:

 - moves some of the basic NTLM operations into libntlmauth
    * fetch_string UNICODE support
    * make challenge packet
    * validate packet type
    * make challenge nonce
    * unpack user and domain from authenticate packet

 - tweaks libntlmauth to split the make challenge operation so that it
   only generates the challenge object (does not encode blob for sending,
   or hard-code field values any more).

Other related changes:

 - tweaks the smb_lm helper which already linked libntlmauth so that it
   uses the updated API correctly after the above changes.

 - documents libntlmauth and some of ntlm_fake_auth helper",1471,data/crawl/squid/hunk_3308.cpp,,,data/crawl/squid/old_hunk_3308.cpp,data/crawl/squid/new_hunk_3308.cpp,-1,276,,"printf(""TT %s\n"", data);","[""addLog""]","[[], [""printf"", ""TT"", ""%s\\n"", ""data""]]",[4578555239133075407],6186,2477520.0,2
https://github.com/squid-cache/squid/commit/43fed740b24c9b64720ba589782c48694ce55c7d,28 Jun 2010,Pull out the basic helper API definitions for sharing,250,data/crawl/squid/hunk_3276.cpp,,,data/crawl/squid/old_hunk_3276.cpp,data/crawl/squid/new_hunk_3276.cpp,3,3,"fprintf(stdout, ""OK\n"");","SEND_OK("""");","[""updateLog"", ""removeVariable"", ""updateContent""]","[[""fprintf"", ""stdout"", ""OK\\n""], [""SEND_OK""]]",[11827114508404674509],6185,0.0,2
https://github.com/squid-cache/squid/commit/43fed740b24c9b64720ba589782c48694ce55c7d,28 Jun 2010,Pull out the basic helper API definitions for sharing,250,data/crawl/squid/hunk_3271.cpp,,,data/crawl/squid/old_hunk_3271.cpp,data/crawl/squid/new_hunk_3271.cpp,24,24,"printf(""ERR Wrong password\n"");","SEND_ERR(""Wrong password"");","[""updateLog"", ""updateContent""]","[[""printf"", ""ERR"", ""password\\n""], [""SEND_ERR"", ""password""]]",[-702912338452461715],6184,0.0,2
https://github.com/squid-cache/squid/commit/1dcf61eb8b17dc47e6ba3ed0921caa25fc1c232b,30 Jun 2010,"NTLM helpers cleanup pt 3: migrate libsmbval into libntlmauth

Library changes:
* ntlmauth.* files moved to libntlmauth/

* helpers/ntlm_auth/smb_lm/smbval moved to libntlmauth/

* No behaviour changes. Since I can't test the deeper logics.
  Just enough to make the code built with portable types available in Squid

* API shuffled slightly to use less .h and to remove all external uses of
  private *-priv.h definitions.

Library now provides three NTLM backend API:
  libntlmauth/ntlmauth.h  - NTLM packet handling
  libntlmauth/smb.h       - SMB LM credential validation
  libntlmauth/rfcnb.h     - RFCNB (NetBIOS) domain server communications

Helper Changes:

* NTLM helpers tweaked slightly to build with the adjusted libntlmauth API
  and ntlm_smb_lm_auth helper to build as C++

* automake logics updated to obey --disable-auth and --disable-auth-ntlm


NOTE: There will be extra code safety and testing benefits gained by
      converting libntlmauth to C++ as well. But that requries someone who
      can test the code behaviour during the upgrade. For now this wil do.",2475,data/crawl/squid/hunk_3259.cpp,,,data/crawl/squid/old_hunk_3259.cpp,data/crawl/squid/new_hunk_3259.cpp,-1,216,,"fprintf(stderr,""Empty LM password supplied for user %s\\%s. ""
                ""No-auth\n"",domain,user);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""Empty"", ""LM"", ""password"", ""supplied"", ""for"", ""user"", ""%s\\\\%s"", ""No"", ""auth\\n"", ""domain"", ""user""]]",[-839344826604013263],6183,2257920.0,2
https://github.com/squid-cache/squid/commit/1dcf61eb8b17dc47e6ba3ed0921caa25fc1c232b,30 Jun 2010,"NTLM helpers cleanup pt 3: migrate libsmbval into libntlmauth

Library changes:
* ntlmauth.* files moved to libntlmauth/

* helpers/ntlm_auth/smb_lm/smbval moved to libntlmauth/

* No behaviour changes. Since I can't test the deeper logics.
  Just enough to make the code built with portable types available in Squid

* API shuffled slightly to use less .h and to remove all external uses of
  private *-priv.h definitions.

Library now provides three NTLM backend API:
  libntlmauth/ntlmauth.h  - NTLM packet handling
  libntlmauth/smb.h       - SMB LM credential validation
  libntlmauth/rfcnb.h     - RFCNB (NetBIOS) domain server communications

Helper Changes:

* NTLM helpers tweaked slightly to build with the adjusted libntlmauth API
  and ntlm_smb_lm_auth helper to build as C++

* automake logics updated to obey --disable-auth and --disable-auth-ntlm


NOTE: There will be extra code safety and testing benefits gained by
      converting libntlmauth to C++ as well. But that requries someone who
      can test the code behaviour during the upgrade. For now this wil do.",2475,data/crawl/squid/hunk_3257.cpp,,,data/crawl/squid/old_hunk_3257.cpp,data/crawl/squid/new_hunk_3257.cpp,255,-1,"fprintf(stderr, ""No auth at all. Returning no-auth\n"");",,"[""removeLog""]","[[""fprintf"", ""stderr"", ""No"", ""auth"", ""at"", ""all"", ""Returning"", ""no"", ""auth\\n""], []]",[15157065372892297358],6182,2257920.0,2
https://github.com/squid-cache/squid/commit/abf4be2be005b247ae6cf7ffd4a173ee60ff6867,07 Jul 2010,"SMP support, part 1: Essential non-caching functionality.

Added workers squid.conf option to specify how many main Squid
processes to fork and maintain. Zero means old no-daemon mode.
One means the old non-SMP mode.

Added support for process_name and process_number macros and
if-statement conditionals in squid.conf. Search for .pre changes for
documented details. These features allow the admin to configure each
worker process differently if needed.

Support multiple workers listening on the same HTTP[S] port (port
sharing). This allows multiple workers to split the load without any
special rules.

Support or prohibit port sharing for WCCP, DNS, ICP, HTCP, SNMP, and
Ident protocols, depending on protocol-specific restrictions. Sharing is
implemented by registering listening socket descriptors with the
Coordinator process and obtaining them from the Coordinator as needed.
Here are protocol-specific notes:

   WCCP: Restricted to the Coordinator process due to how WCCP works.
   Workers do not need access to the WCCP code.

   DNS: Done by each worker with no sharing. Fixed source ports not
   supported unless each worker is given its own outgoing address
   because we do not want to match outgoing queries and incoming
   responses across processes.

   SNMP: Workers share incoming and outgoing sockets.

   ICP and HTCP _clients_: Cannot be supported in SMP environment
   unless each process has its own address (i.e., unique IP address
   and/or unique [ICP] port) because we do not want to match outgoing
   queries and incoming responses across processes.

   ICP and HTCP _servers_: share listening sockets.

   Ident clients do not need to share sockets because they use
   unique ports.

Support management signals (squid -k ...) in SMP mode, acting as a
single Squid instance.

Refork dying workers, similar to how we reforked dying process in
non-SMP daemon mode.

Merged from lp smp branch r10306.",3002,data/crawl/squid/hunk_3245.cpp,,,data/crawl/squid/old_hunk_3245.cpp,data/crawl/squid/new_hunk_3245.cpp,19,39,"fatal(""Cannot open SNMP Port"");","fatal(""Cannot open Incoming SNMP Port"");","[""updateContent""]","[[], [""Incoming""]]",[-3658564119226930972],6181,23040.0,2
https://github.com/squid-cache/squid/commit/abf4be2be005b247ae6cf7ffd4a173ee60ff6867,07 Jul 2010,"SMP support, part 1: Essential non-caching functionality.

Added workers squid.conf option to specify how many main Squid
processes to fork and maintain. Zero means old no-daemon mode.
One means the old non-SMP mode.

Added support for process_name and process_number macros and
if-statement conditionals in squid.conf. Search for .pre changes for
documented details. These features allow the admin to configure each
worker process differently if needed.

Support multiple workers listening on the same HTTP[S] port (port
sharing). This allows multiple workers to split the load without any
special rules.

Support or prohibit port sharing for WCCP, DNS, ICP, HTCP, SNMP, and
Ident protocols, depending on protocol-specific restrictions. Sharing is
implemented by registering listening socket descriptors with the
Coordinator process and obtaining them from the Coordinator as needed.
Here are protocol-specific notes:

   WCCP: Restricted to the Coordinator process due to how WCCP works.
   Workers do not need access to the WCCP code.

   DNS: Done by each worker with no sharing. Fixed source ports not
   supported unless each worker is given its own outgoing address
   because we do not want to match outgoing queries and incoming
   responses across processes.

   SNMP: Workers share incoming and outgoing sockets.

   ICP and HTCP _clients_: Cannot be supported in SMP environment
   unless each process has its own address (i.e., unique IP address
   and/or unique [ICP] port) because we do not want to match outgoing
   queries and incoming responses across processes.

   ICP and HTCP _servers_: share listening sockets.

   Ident clients do not need to share sockets because they use
   unique ports.

Support management signals (squid -k ...) in SMP mode, acting as a
single Squid instance.

Refork dying workers, similar to how we reforked dying process in
non-SMP daemon mode.

Merged from lp smp branch r10306.",3002,data/crawl/squid/hunk_3236.cpp,,,data/crawl/squid/old_hunk_3236.cpp,data/crawl/squid/new_hunk_3236.cpp,12,-1,"fatal(""Cannot open HTCP Socket"");",,"[""removeLog""]","[[""fatal"", ""Cannot"", ""open"", ""HTCP"", ""Socket""], []]",[-3828576806609246128],6180,16560.0,2
https://github.com/squid-cache/squid/commit/abf4be2be005b247ae6cf7ffd4a173ee60ff6867,07 Jul 2010,"SMP support, part 1: Essential non-caching functionality.

Added workers squid.conf option to specify how many main Squid
processes to fork and maintain. Zero means old no-daemon mode.
One means the old non-SMP mode.

Added support for process_name and process_number macros and
if-statement conditionals in squid.conf. Search for .pre changes for
documented details. These features allow the admin to configure each
worker process differently if needed.

Support multiple workers listening on the same HTTP[S] port (port
sharing). This allows multiple workers to split the load without any
special rules.

Support or prohibit port sharing for WCCP, DNS, ICP, HTCP, SNMP, and
Ident protocols, depending on protocol-specific restrictions. Sharing is
implemented by registering listening socket descriptors with the
Coordinator process and obtaining them from the Coordinator as needed.
Here are protocol-specific notes:

   WCCP: Restricted to the Coordinator process due to how WCCP works.
   Workers do not need access to the WCCP code.

   DNS: Done by each worker with no sharing. Fixed source ports not
   supported unless each worker is given its own outgoing address
   because we do not want to match outgoing queries and incoming
   responses across processes.

   SNMP: Workers share incoming and outgoing sockets.

   ICP and HTCP _clients_: Cannot be supported in SMP environment
   unless each process has its own address (i.e., unique IP address
   and/or unique [ICP] port) because we do not want to match outgoing
   queries and incoming responses across processes.

   ICP and HTCP _servers_: share listening sockets.

   Ident clients do not need to share sockets because they use
   unique ports.

Support management signals (squid -k ...) in SMP mode, acting as a
single Squid instance.

Refork dying workers, similar to how we reforked dying process in
non-SMP daemon mode.

Merged from lp smp branch r10306.",3002,data/crawl/squid/hunk_3234.cpp,,,data/crawl/squid/old_hunk_3234.cpp,data/crawl/squid/new_hunk_3234.cpp,3,3,"fatal(""Cannot open HTTP Port"");","fatal(""No HTTP or HTTPS ports configured"");","[""updateContent""]","[[""Cannot"", ""open"", ""Port""], [""No"", ""or"", ""HTTPS"", ""ports"", ""configured""]]",[-11900905311244628267],6179,47520.0,2
https://github.com/squid-cache/squid/commit/abf4be2be005b247ae6cf7ffd4a173ee60ff6867,07 Jul 2010,"SMP support, part 1: Essential non-caching functionality.

Added workers squid.conf option to specify how many main Squid
processes to fork and maintain. Zero means old no-daemon mode.
One means the old non-SMP mode.

Added support for process_name and process_number macros and
if-statement conditionals in squid.conf. Search for .pre changes for
documented details. These features allow the admin to configure each
worker process differently if needed.

Support multiple workers listening on the same HTTP[S] port (port
sharing). This allows multiple workers to split the load without any
special rules.

Support or prohibit port sharing for WCCP, DNS, ICP, HTCP, SNMP, and
Ident protocols, depending on protocol-specific restrictions. Sharing is
implemented by registering listening socket descriptors with the
Coordinator process and obtaining them from the Coordinator as needed.
Here are protocol-specific notes:

   WCCP: Restricted to the Coordinator process due to how WCCP works.
   Workers do not need access to the WCCP code.

   DNS: Done by each worker with no sharing. Fixed source ports not
   supported unless each worker is given its own outgoing address
   because we do not want to match outgoing queries and incoming
   responses across processes.

   SNMP: Workers share incoming and outgoing sockets.

   ICP and HTCP _clients_: Cannot be supported in SMP environment
   unless each process has its own address (i.e., unique IP address
   and/or unique [ICP] port) because we do not want to match outgoing
   queries and incoming responses across processes.

   ICP and HTCP _servers_: share listening sockets.

   Ident clients do not need to share sockets because they use
   unique ports.

Support management signals (squid -k ...) in SMP mode, acting as a
single Squid instance.

Refork dying workers, similar to how we reforked dying process in
non-SMP daemon mode.

Merged from lp smp branch r10306.",3002,data/crawl/squid/hunk_3233.cpp,,,data/crawl/squid/old_hunk_3233.cpp,data/crawl/squid/new_hunk_3233.cpp,-1,13,,fatal(msgIfFail);,"[""addLog""]","[[], [""fatal"", ""msgIfFail""]]",[-12734579319536127246],6178,31680.0,2
https://github.com/squid-cache/squid/commit/eb1f6bfa7c19555c72c72c7102cac62d8417ee2f,08 Jul 2010,"Author: Jens-S. V�ckler <voeckler@rvs.uni-hannover.de>
Import squid cache 'purge' tool

Just the original code import for crediting the original author.

TODO:
 - patch to fix build problems in modern systems
 - upgrade to cope with current cache_dir formats
 - bundle and distribute updated tool",3295,data/crawl/squid/hunk_3193.cpp,,,data/crawl/squid/old_hunk_3193.cpp,data/crawl/squid/new_hunk_3193.cpp,-1,766,,"puts("""");","[""addLog""]","[[], [""puts""]]",[4142537773861848358],6177,0.0,2
https://github.com/squid-cache/squid/commit/eb1f6bfa7c19555c72c72c7102cac62d8417ee2f,08 Jul 2010,"Author: Jens-S. V�ckler <voeckler@rvs.uni-hannover.de>
Import squid cache 'purge' tool

Just the original code import for crediting the original author.

TODO:
 - patch to fix build problems in modern systems
 - upgrade to cope with current cache_dir formats
 - bundle and distribute updated tool",3295,data/crawl/squid/hunk_3193.cpp,,,data/crawl/squid/old_hunk_3193.cpp,data/crawl/squid/new_hunk_3193.cpp,-1,700,,"fprintf( stderr, ""unable to resolve host %s!\n"", optarg );","[""addLog""]","[[], [""fprintf"", ""stderr"", ""unable"", ""to"", ""resolve"", ""host"", ""%s"", ""\\n"", ""optarg""]]",[7986427115954510008],6176,0.0,2
https://github.com/squid-cache/squid/commit/eb1f6bfa7c19555c72c72c7102cac62d8417ee2f,08 Jul 2010,"Author: Jens-S. V�ckler <voeckler@rvs.uni-hannover.de>
Import squid cache 'purge' tool

Just the original code import for crediting the original author.

TODO:
 - patch to fix build problems in modern systems
 - upgrade to cope with current cache_dir formats
 - bundle and distribute updated tool",3295,data/crawl/squid/hunk_3193.cpp,,,data/crawl/squid/old_hunk_3193.cpp,data/crawl/squid/new_hunk_3193.cpp,-1,381,,"fprintf( stderr, ""WARNING: unable to unlink %s: %s\n"",
	       fn, strerror(errno) );","[""addLog""]","[[], [""fprintf"", ""stderr"", ""WARNING"", ""unable"", ""to"", ""unlink"", ""%s"", ""%s\\n"", ""fn"", ""strerror"", ""errno""]]",[7435396119948429792],6175,0.0,2
https://github.com/squid-cache/squid/commit/eb1f6bfa7c19555c72c72c7102cac62d8417ee2f,08 Jul 2010,"Author: Jens-S. V�ckler <voeckler@rvs.uni-hannover.de>
Import squid cache 'purge' tool

Just the original code import for crediting the original author.

TODO:
 - patch to fix build problems in modern systems
 - upgrade to cope with current cache_dir formats
 - bundle and distribute updated tool",3295,data/crawl/squid/hunk_3191.cpp,,,data/crawl/squid/old_hunk_3191.cpp,data/crawl/squid/new_hunk_3191.cpp,-1,159,,"fprintf( stderr, ""# creating %s\n"", filename );","[""addLog""]","[[], [""fprintf"", ""stderr"", ""creating"", ""%s\\n"", ""filename""]]",[-15899706780798451664],6174,0.0,2
https://github.com/squid-cache/squid/commit/c152a4473c4a3d187f67923eb83c5fe6ccd91013,12 Jul 2010,"Helpers: Naming and C++ update for external ACL helpers

 * Also adds the Fake auth helper for testing Basic authentication.
 * Also adds manual pages for most external ACL helpers

TODO: test for and fix any build issues on Windows.",2485,data/crawl/squid/hunk_3179.cpp,,,data/crawl/squid/old_hunk_3179.cpp,data/crawl/squid/new_hunk_3179.cpp,3,3,"fprintf(stderr, ""helper: User does not exist '%s'\n"", username);","fprintf(stderr, ""ERROR: User does not exist '%s'\n"", username);","[""updateContent""]","[[""helper""], [""ERROR""]]",[9112892746385274865],6173,0.0,2
https://github.com/squid-cache/squid/commit/c152a4473c4a3d187f67923eb83c5fe6ccd91013,12 Jul 2010,"Helpers: Naming and C++ update for external ACL helpers

 * Also adds the Fake auth helper for testing Basic authentication.
 * Also adds manual pages for most external ACL helpers

TODO: test for and fix any build issues on Windows.",2485,data/crawl/squid/hunk_3174.cpp,,,data/crawl/squid/old_hunk_3174.cpp,data/crawl/squid/new_hunk_3174.cpp,66,-1,"fprintf(stderr, ""%s[%d]: "", myname, mypid);",,"[""removeLog""]","[[""fprintf"", ""stderr"", ""%s[%d]"", ""myname"", ""mypid""], []]",[19957182019804867126],6172,0.0,2
https://github.com/squid-cache/squid/commit/c152a4473c4a3d187f67923eb83c5fe6ccd91013,12 Jul 2010,"Helpers: Naming and C++ update for external ACL helpers

 * Also adds the Fake auth helper for testing Basic authentication.
 * Also adds manual pages for most external ACL helpers

TODO: test for and fix any build issues on Windows.",2485,data/crawl/squid/hunk_3172.cpp,,,data/crawl/squid/old_hunk_3172.cpp,data/crawl/squid/new_hunk_3172.cpp,71,-1,"fprintf(stderr, ""%s: ERROR: Too large: %s\n"", argv[0], line);",,"[""removeLog""]","[[""fprintf"", ""stderr"", ""%s"", ""ERROR"", ""Too"", ""large"", ""%s\\n"", ""argv[0]"", ""line""], []]",[2520549332920755081],6171,0.0,2
https://github.com/squid-cache/squid/commit/c152a4473c4a3d187f67923eb83c5fe6ccd91013,12 Jul 2010,"Helpers: Naming and C++ update for external ACL helpers

 * Also adds the Fake auth helper for testing Basic authentication.
 * Also adds manual pages for most external ACL helpers

TODO: test for and fix any build issues on Windows.",2485,data/crawl/squid/hunk_3170.cpp,,,data/crawl/squid/old_hunk_3170.cpp,data/crawl/squid/new_hunk_3170.cpp,-1,252,,"fprintf(stderr, ""%s: ERROR: Input Too Large: %s\n"", program_name, line);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""%s"", ""ERROR"", ""Input"", ""Too"", ""Large"", ""%s\\n"", ""program_name"", ""line""]]",[-14606652758763455837],6170,0.0,2
https://github.com/squid-cache/squid/commit/c152a4473c4a3d187f67923eb83c5fe6ccd91013,12 Jul 2010,"Helpers: Naming and C++ update for external ACL helpers

 * Also adds the Fake auth helper for testing Basic authentication.
 * Also adds manual pages for most external ACL helpers

TODO: test for and fix any build issues on Windows.",2485,data/crawl/squid/hunk_3168.cpp,,,data/crawl/squid/old_hunk_3168.cpp,data/crawl/squid/new_hunk_3168.cpp,3,3,"fprintf(stderr, ""Invalid Request\n"");","SEND_ERR(""Invalid Request."");","[""updateLog"", ""removeVariable"", ""updateContent""]","[[""fprintf"", ""stderr"", ""Request\\n""], [""SEND_ERR"", ""Request""]]",[12545476235354964556],6169,10080.0,2
https://github.com/squid-cache/squid/commit/c152a4473c4a3d187f67923eb83c5fe6ccd91013,12 Jul 2010,"Helpers: Naming and C++ update for external ACL helpers

 * Also adds the Fake auth helper for testing Basic authentication.
 * Also adds manual pages for most external ACL helpers

TODO: test for and fix any build issues on Windows.",2485,data/crawl/squid/hunk_3149.cpp,,,data/crawl/squid/old_hunk_3149.cpp,data/crawl/squid/new_hunk_3149.cpp,11,11,"fprintf(stderr, ""\nUnable to initialise SSL with cert path %s\n"",
                                    sslpath);","fprintf(stderr, ""FATAL: Unable to initialise SSL with cert path %s\n"", sslpath);","[""updateContent""]","[[""\\nUnable""], [""FATAL"", ""Unable""]]",[-604721142753830105],6168,0.0,2
https://github.com/squid-cache/squid/commit/c152a4473c4a3d187f67923eb83c5fe6ccd91013,12 Jul 2010,"Helpers: Naming and C++ update for external ACL helpers

 * Also adds the Fake auth helper for testing Basic authentication.
 * Also adds manual pages for most external ACL helpers

TODO: test for and fix any build issues on Windows.",2485,data/crawl/squid/hunk_3147.cpp,,,data/crawl/squid/old_hunk_3147.cpp,data/crawl/squid/new_hunk_3147.cpp,13,13,"fprintf(stderr, ""%s: ERROR: Too large: %s\n"", argv[0], buf);","fprintf(stderr, ""%s: ERROR: Input Too large: %s\n"", argv[0], buf);","[""updateContent""]","[[], [""Input""]]",[-8139556017175161287],6167,0.0,2
https://github.com/squid-cache/squid/commit/c152a4473c4a3d187f67923eb83c5fe6ccd91013,12 Jul 2010,"Helpers: Naming and C++ update for external ACL helpers

 * Also adds the Fake auth helper for testing Basic authentication.
 * Also adds manual pages for most external ACL helpers

TODO: test for and fix any build issues on Windows.",2485,data/crawl/squid/hunk_3139.cpp,,,data/crawl/squid/old_hunk_3139.cpp,data/crawl/squid/new_hunk_3139.cpp,3,3,"fprintf(stderr, ""Invalid Request\n"");","SEND_ERR(""Invalid Request. No Username."");","[""updateLog"", ""removeVariable"", ""updateContent""]","[[""fprintf"", ""stderr"", ""Request\\n""], [""SEND_ERR"", ""Request"", ""No"", ""Username""]]",[7242255541100848947],6166,0.0,2
https://github.com/squid-cache/squid/commit/e0f8b7097291fc129f5090eb975832a8f16ca401,30 Jul 2010,"Bug 2994: pt 1: Open *_port directives correctly in IPv4-only mode.

Was opening snmp_port, icp_port, htcp_port under the v4-mapping assumption.
This forces the ports both listening and outgoing to IPv4-only unless
v4-mapping is actually available in the system.",30,data/crawl/squid/hunk_3115.cpp,,,data/crawl/squid/old_hunk_3115.cpp,data/crawl/squid/new_hunk_3115.cpp,-1,5,,"fatal(""SNMP port cannot be opened."");","[""addLog""]","[[], [""fatal"", ""SNMP"", ""port"", ""cannot"", ""be"", ""opened""]]",[-4901172764364796483],6165,0.0,2
https://github.com/squid-cache/squid/commit/e0f8b7097291fc129f5090eb975832a8f16ca401,30 Jul 2010,"Bug 2994: pt 1: Open *_port directives correctly in IPv4-only mode.

Was opening snmp_port, icp_port, htcp_port under the v4-mapping assumption.
This forces the ports both listening and outgoing to IPv4-only unless
v4-mapping is actually available in the system.",30,data/crawl/squid/hunk_3113.cpp,,,data/crawl/squid/old_hunk_3113.cpp,data/crawl/squid/new_hunk_3113.cpp,-1,5,,"fatal(""ICP port cannot be opened."");","[""addLog""]","[[], [""fatal"", ""ICP"", ""port"", ""cannot"", ""be"", ""opened""]]",[-10616160227703679668],6164,0.0,2
https://github.com/squid-cache/squid/commit/e0f8b7097291fc129f5090eb975832a8f16ca401,30 Jul 2010,"Bug 2994: pt 1: Open *_port directives correctly in IPv4-only mode.

Was opening snmp_port, icp_port, htcp_port under the v4-mapping assumption.
This forces the ports both listening and outgoing to IPv4-only unless
v4-mapping is actually available in the system.",30,data/crawl/squid/hunk_3111.cpp,,,data/crawl/squid/old_hunk_3111.cpp,data/crawl/squid/new_hunk_3111.cpp,-1,5,,"fatal(""HTCP port cannot be opened."");","[""addLog""]","[[], [""fatal"", ""HTCP"", ""port"", ""cannot"", ""be"", ""opened""]]",[4738780020611848114],6163,0.0,2
https://github.com/squid-cache/squid/commit/b1218840b92df2ac65c8da509fae0ec7e63a632d,13 Aug 2010,"Author: Markus Moeller <huaraz@moeller.plus.com>
Helper: ext_kerberos_ldap_group_acl: Lookup Kerberos/NTLM group via LDAP",5482,data/crawl/squid/hunk_3096.cpp,,,data/crawl/squid/old_hunk_3096.cpp,data/crawl/squid/new_hunk_3096.cpp,-1,414,,"fprintf(stderr, ""%02x"", (unsigned char) av[n]);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""%02x"", ""unsigned"", ""char"", ""av[n]""]]",[-763546040624748714],6162,0.0,2
https://github.com/squid-cache/squid/commit/2ccf2eb2159f0ee9847669c101f9ed4143e0b01d,19 Aug 2010,"Bundle the purge and hexd tools with Squid sources.

Fixes the remaining known errors with purge tool building within
Squid source tree.


This adds the auto-tools changes necessary to bundle the tool.",564,data/crawl/squid/hunk_3070.cpp,,,data/crawl/squid/old_hunk_3070.cpp,data/crawl/squid/new_hunk_3070.cpp,34,-1,"fputs( ""(unknown)\n"", stderr );",,"[""removeLog""]","[[""fputs"", ""unknown"", ""\\n"", ""stderr""], []]",[16791036293205242296],6161,0.0,2
https://github.com/squid-cache/squid/commit/2ccf2eb2159f0ee9847669c101f9ed4143e0b01d,19 Aug 2010,"Bundle the purge and hexd tools with Squid sources.

Fixes the remaining known errors with purge tool building within
Squid source tree.


This adds the auto-tools changes necessary to bundle the tool.",564,data/crawl/squid/hunk_3070.cpp,,,data/crawl/squid/old_hunk_3070.cpp,data/crawl/squid/new_hunk_3070.cpp,32,-1,"fprintf( stderr, ""%s\n"", _sys_siglist[sig] );",,"[""removeLog""]","[[""fprintf"", ""stderr"", ""%s\\n"", ""_sys_siglist[sig]""], []]",[1572256004854501974],6160,0.0,2
https://github.com/squid-cache/squid/commit/2ccf2eb2159f0ee9847669c101f9ed4143e0b01d,19 Aug 2010,"Bundle the purge and hexd tools with Squid sources.

Fixes the remaining known errors with purge tool building within
Squid source tree.


This adds the auto-tools changes necessary to bundle the tool.",564,data/crawl/squid/hunk_3070.cpp,,,data/crawl/squid/old_hunk_3070.cpp,data/crawl/squid/new_hunk_3070.cpp,30,-1,"fprintf( stderr, ""%s: "", msg );",,"[""removeLog""]","[[""fprintf"", ""stderr"", ""%s"", ""msg""], []]",[7533761602946052704],6159,0.0,2
https://github.com/squid-cache/squid/commit/ec3c3187987682b6b4c87f53ad10dc5e44577ddc,20 Aug 2010,Fixed some build errors in purge tool.,14,data/crawl/squid/hunk_3061.cpp,,,data/crawl/squid/old_hunk_3061.cpp,data/crawl/squid/new_hunk_3061.cpp,3,3,"fprintf( stderr, ""lseek(%s,%lu): %s\n"", filename, filesize-metasize,
                 strerror(errno) );","fprintf( stderr, ""lseek(%s,%lu): %s\n"", filename, 
                 (unsigned long)filesize-metasize,
                 strerror(errno) );","[""addVariable""]","[[], [""unsigned"", ""long""]]",[-1194457552177564325],6158,1400400.0,2
https://github.com/squid-cache/squid/commit/4299f876344efc8a8446f2bc0c940fadad2bff09,23 Aug 2010,"Bug #2583 fix: pure virtual method called

When a cbdata-protected class holds its own cbdata and has virtual
toCbdata(), there is a catch22 problem: we need cbdata to know whether
the pointer to the class object is valid, and we need to dereference
that pointer to get cbdata.

Added CbcPointer class to hold both a pointer to a potentially freed
class object and the cbdata pointer protecting that object. Keeping the
cbdata pointer allows us to test whether the object is still there
without dereferencing the object pointer.

Use the CbcPointer class to hold safe pointers to AsyncJobs. This
prevents ""pure virtual method called"" failures because we no longer
dereference freed job pointers.

Removed Initiator parameter from many initiatee constructors. The
Adaptation::Initiator::initiateAdaptation method now sets the initiator
of the job. This makes the constructor profile simpler and removes the
need to propagate Initiator changes through all the [nested]
constructors.

Renamed AsyncJob::AsyncStart() to AsyncJob::Start(). I had to change the
callers code anyway and it was a good opportunity to remove the
redundant ""Async"".


Special thanks to Stefan Fritsch for updating and testing an earlier
version of this patch.",1078,data/crawl/squid/hunk_3056.cpp,,,data/crawl/squid/old_hunk_3056.cpp,data/crawl/squid/new_hunk_3056.cpp,4,4,"outputBuffer.Printf("" prod%p"", theProducer);","outputBuffer.Printf("" prod%p"", theProducer.get());","[""removeVariable"", ""addVariable""]","[[], [""get""]]",[-5303253345844048825],6157,0.0,2
https://github.com/squid-cache/squid/commit/4ad606098377d311d430be87556c6fd52f0ab8e1,24 Aug 2010,"Send chunked responses if body size is unknown.

Apply HTTP chunked transfer encoding to the response body sent to client
if all of the following conditions are met:

* client claims HTTP version 1.1 or later support
* response does not have a Content-Length header already
* response does not use multipart/byteranges encoding
* connection is persistent

If we decide to send chunked reply, chunked_reply flag is set. Chunked
encoding is done in ClientSocketContext::packChunk(). The last-chunk
is sent only when clientReplyContext complete flag is set.

This change helps keep client-side connections persistent.",77,data/crawl/squid/hunk_3054.cpp,,,data/crawl/squid/old_hunk_3054.cpp,data/crawl/squid/new_hunk_3054.cpp,-1,16,,"mb.Printf(""\r\n"");","[""addLog""]","[[], [""mb"", ""Printf"", ""\\r\\n""]]",[2089718098006273182],6156,1297440.0,2
https://github.com/squid-cache/squid/commit/18191440e92905de717a542b41e303cd73c119ce,24 Aug 2010,"Author: Henrik Nordstrom <henrik@nordstrom.net>
Author: Amos Jeffries <squid3@treenet.co.nz>
Collapse HTCP cache_peer options into one setting.

The list of HTCP mode options had grown a bit too large. Collapse them
all into a single htcp= option taking a list of mode flags.",93,data/crawl/squid/hunk_3043.cpp,,,data/crawl/squid/old_hunk_3043.cpp,data/crawl/squid/new_hunk_3043.cpp,8,10,"storeAppendPrintf(sentry, "" htcp-no-clr"");","storeAppendPrintf(sentry, ""%sno-clr"",(doneopts++>0?"","":""=""));","[""updateContent"", ""addContent"", ""addVariable""]","[[""htcp"", ""no""], [""%sno"", ""doneopts"", ""0""]]",[4611187678436319760],6155,0.0,2
https://github.com/squid-cache/squid/commit/f86504f1cb4c3d6f8b576ef2cff1b6323f2a4c1f,19 Sep 2010,"Author: Chad Naugle <chad.naugle@travimp.com>
ext_edirectory_userip_acl - add omitted new file",2082,data/crawl/squid/hunk_3025.cpp,,,data/crawl/squid/old_hunk_3025.cpp,data/crawl/squid/new_hunk_3025.cpp,-1,297,,"fputs(dbuf, stdout);","[""addLog""]","[[], [""fputs"", ""dbuf"", ""stdout""]]",[-21040811309856973769],6154,43920.0,2
https://github.com/squid-cache/squid/commit/f86504f1cb4c3d6f8b576ef2cff1b6323f2a4c1f,19 Sep 2010,"Author: Chad Naugle <chad.naugle@travimp.com>
ext_edirectory_userip_acl - add omitted new file",2082,data/crawl/squid/hunk_3025.cpp,,,data/crawl/squid/old_hunk_3025.cpp,data/crawl/squid/new_hunk_3025.cpp,-1,222,,"fputs(cbuf, stderr);","[""addLog""]","[[], [""fputs"", ""cbuf"", ""stderr""]]",[-6748753367423696763],6153,43920.0,2
https://github.com/squid-cache/squid/commit/ac5de05bed05906909d7ccc894f940438b8a9967,29 Sep 2010,"Bug 3051: integer display overflow

This alters the cachemgr display formatting to use 64-bit integers
instead of 32-bit. Revealing overflows hiding behind display overflows.",302,data/crawl/squid/hunk_3017.cpp,,,data/crawl/squid/old_hunk_3017.cpp,data/crawl/squid/new_hunk_3017.cpp,3,3,"storeAppendPrintf(sentry, ""\t%6d Hot Object Cache Items\n"",
                      hot_obj_count);","storeAppendPrintf(sentry, ""\t%6ld Hot Object Cache Items\n"",
                      (long)hot_obj_count);","[""updateContent"", ""addVariable""]","[[""\\t%6d""], [""\\t%6ld"", ""long""]]",[7270058267196035803],6152,0.0,2
https://github.com/squid-cache/squid/commit/ac5de05bed05906909d7ccc894f940438b8a9967,29 Sep 2010,"Bug 3051: integer display overflow

This alters the cachemgr display formatting to use 64-bit integers
instead of 32-bit. Revealing overflows hiding behind display overflows.",302,data/crawl/squid/hunk_3016.cpp,,,data/crawl/squid/old_hunk_3016.cpp,data/crawl/squid/new_hunk_3016.cpp,17,17,"storeAppendPrintf(sentry, ""\tmemPool accounted:     %6d KB %3d%%\n"",
                          (int) mp_stats.TheMeter->alloc.level >> 10,
                          Math::intPercent(mp_stats.TheMeter->alloc.level, t));","storeAppendPrintf(sentry, ""\tmemPool accounted:     %6ld KB %3d%%\n"",
                          (long)(mp_stats.TheMeter->alloc.level >> 10),
                          Math::intPercent(mp_stats.TheMeter->alloc.level, t));","[""moveContent"", ""moveVariable"", ""removeVariable"", ""updateContent"", ""addVariable""]","[[""%6d"", ""int""], [""%6ld"", ""long""]]",[24441871750778416335],6151,0.0,2
https://github.com/squid-cache/squid/commit/6da430a4640e07dfae7ef7a4451acc2854817014,01 Oct 2010,"Bug 3068: cache_dir capacity and usage overflows

Makes usage calculations use size_t instead of int and updates the
relevant fields storing the cache_dir capacity and usage fields as well.

This fixes Squid filling cache_dir with files >2GB in size.
Also allows Squid to store more than 2TB of data total in one dir.",55,data/crawl/squid/hunk_3003.cpp,,,data/crawl/squid/old_hunk_3003.cpp,data/crawl/squid/new_hunk_3003.cpp,5,5,"storeAppendPrintf(&sentry, ""Percent Used: %0.2f%%\n"",
                      100.0 * cur_size / max_size);","storeAppendPrintf(&sentry, ""Percent Used: %0.2f%%\n"",
                      (100.0 * (double)cur_size / (double)max_size) );","[""addVariable""]","[[], [""double"", ""double""]]",[-8976833915472058670],6150,0.0,2
https://github.com/squid-cache/squid/commit/6ca7324f4760764b0597e7779dcffccd07e058ab,12 Oct 2010,"Author: Chad Naugle <chad.naugle@travimp.com>
eDirectory user-IP ACl string safety updates",400,data/crawl/squid/hunk_2975.cpp,,,data/crawl/squid/old_hunk_2975.cpp,data/crawl/squid/new_hunk_2975.cpp,5,4,"fputs(dbuf, stderr);","fputs(bbuf, stderr);","[""updateVariable""]","[[""dbuf""], [""bbuf""]]",[10137611812727004426],6149,0.0,2
https://github.com/squid-cache/squid/commit/7c16470cc2d053ea2c540459843227dea08e8b40,16 Oct 2010,"basic_msnt_auth helper and NTLM/SMBLIB/RFCNB library polish.

Samba smblib/rfcnb code:
 * Import the latest copy which I could find a download link to.
   This source is from 1997 so I suspect there is something even newer
   we should be using. Time was tight is the only excuse for using
   these sources. Our originals were from 1995 and 1996 depending on the
   helper using it, with a mix of patches.

 * These two directories are in ours sources as lib/smblib and lib/rfcnb.
   Each has its own convenience library. Kept separate with original
   filenames to simplify future upgrades or removal.

 * Samba sources have been diffed and compared function by function
   against the copies previously in our sources. Functionality extensions
   we use have been grafted back on top of the new(er) Samba sources.
  - this was mostly around passing extra Unicode, DC hints and pre-crypted
    passwords to the login checks.
  - some files from libntlmauth have yet to be compared in fine detail,
    that will be completed today before merge.
  - some basic API function and struct definitions had to be moved to the
    API headers to prevent needing to include the *-priv.h private
    definitions externally to the library.

 * the Samba API headers have been wrapped with #ifndef safety wrappers

 * compile errors and include changes required to compile have been
   made (code stays C)

 * duplicate code in helpers/basic_auth/MSNT/* and libntlmauth/* is
   removed.

 * abuse of the smblib-priv.h and rfcnb-priv.h headers and all local
   re-definitions has been erased from our code. Replaced by includes 
   of the library API headers: rfcnb/rfcnb.h  smblib/smblib.h


libntlmauth:
 * smblib/rfcnb bits erased
 * moved to lib/ntlmauth in its much reduced form
 * built as a convenience library instead of full library",14917,data/crawl/squid/hunk_2969.cpp,,,data/crawl/squid/old_hunk_2969.cpp,data/crawl/squid/new_hunk_2969.cpp,327,-1,"fprintf(stderr, ""SMB_Logon_server: Couldn't allocate packet\n"");",,"[""removeLog""]","[[""fprintf"", ""stderr"", ""SMB_Logon_server"", ""Couldn"", ""t"", ""allocate"", ""packet\\n""], []]",[20029027935438814705],6148,0.0,2
https://github.com/squid-cache/squid/commit/7c16470cc2d053ea2c540459843227dea08e8b40,16 Oct 2010,"basic_msnt_auth helper and NTLM/SMBLIB/RFCNB library polish.

Samba smblib/rfcnb code:
 * Import the latest copy which I could find a download link to.
   This source is from 1997 so I suspect there is something even newer
   we should be using. Time was tight is the only excuse for using
   these sources. Our originals were from 1995 and 1996 depending on the
   helper using it, with a mix of patches.

 * These two directories are in ours sources as lib/smblib and lib/rfcnb.
   Each has its own convenience library. Kept separate with original
   filenames to simplify future upgrades or removal.

 * Samba sources have been diffed and compared function by function
   against the copies previously in our sources. Functionality extensions
   we use have been grafted back on top of the new(er) Samba sources.
  - this was mostly around passing extra Unicode, DC hints and pre-crypted
    passwords to the login checks.
  - some files from libntlmauth have yet to be compared in fine detail,
    that will be completed today before merge.
  - some basic API function and struct definitions had to be moved to the
    API headers to prevent needing to include the *-priv.h private
    definitions externally to the library.

 * the Samba API headers have been wrapped with #ifndef safety wrappers

 * compile errors and include changes required to compile have been
   made (code stays C)

 * duplicate code in helpers/basic_auth/MSNT/* and libntlmauth/* is
   removed.

 * abuse of the smblib-priv.h and rfcnb-priv.h headers and all local
   re-definitions has been erased from our code. Replaced by includes 
   of the library API headers: rfcnb/rfcnb.h  smblib/smblib.h


libntlmauth:
 * smblib/rfcnb bits erased
 * moved to lib/ntlmauth in its much reduced form
 * built as a convenience library instead of full library",14917,data/crawl/squid/hunk_2968.cpp,,,data/crawl/squid/old_hunk_2968.cpp,data/crawl/squid/new_hunk_2968.cpp,150,-1,"fprintf(fd, ""    %s\n"", outbuf1);",,"[""removeLog""]","[[""fprintf"", ""fd"", ""%s\\n"", ""outbuf1""], []]",[-1103988382793225785],6147,0.0,2
https://github.com/squid-cache/squid/commit/7c16470cc2d053ea2c540459843227dea08e8b40,16 Oct 2010,"basic_msnt_auth helper and NTLM/SMBLIB/RFCNB library polish.

Samba smblib/rfcnb code:
 * Import the latest copy which I could find a download link to.
   This source is from 1997 so I suspect there is something even newer
   we should be using. Time was tight is the only excuse for using
   these sources. Our originals were from 1995 and 1996 depending on the
   helper using it, with a mix of patches.

 * These two directories are in ours sources as lib/smblib and lib/rfcnb.
   Each has its own convenience library. Kept separate with original
   filenames to simplify future upgrades or removal.

 * Samba sources have been diffed and compared function by function
   against the copies previously in our sources. Functionality extensions
   we use have been grafted back on top of the new(er) Samba sources.
  - this was mostly around passing extra Unicode, DC hints and pre-crypted
    passwords to the login checks.
  - some files from libntlmauth have yet to be compared in fine detail,
    that will be completed today before merge.
  - some basic API function and struct definitions had to be moved to the
    API headers to prevent needing to include the *-priv.h private
    definitions externally to the library.

 * the Samba API headers have been wrapped with #ifndef safety wrappers

 * compile errors and include changes required to compile have been
   made (code stays C)

 * duplicate code in helpers/basic_auth/MSNT/* and libntlmauth/* is
   removed.

 * abuse of the smblib-priv.h and rfcnb-priv.h headers and all local
   re-definitions has been erased from our code. Replaced by includes 
   of the library API headers: rfcnb/rfcnb.h  smblib/smblib.h


libntlmauth:
 * smblib/rfcnb bits erased
 * moved to lib/ntlmauth in its much reduced form
 * built as a convenience library instead of full library",14917,data/crawl/squid/hunk_2965.cpp,,,data/crawl/squid/old_hunk_2965.cpp,data/crawl/squid/new_hunk_2965.cpp,-1,123,,"printf(""Error in calling: %s ...\n"", err_string);","[""addLog""]","[[], [""printf"", ""Error"", ""in"", ""calling"", ""%s"", ""\\n"", ""err_string""]]",[7528727076570886787],6146,0.0,2
https://github.com/squid-cache/squid/commit/7c16470cc2d053ea2c540459843227dea08e8b40,16 Oct 2010,"basic_msnt_auth helper and NTLM/SMBLIB/RFCNB library polish.

Samba smblib/rfcnb code:
 * Import the latest copy which I could find a download link to.
   This source is from 1997 so I suspect there is something even newer
   we should be using. Time was tight is the only excuse for using
   these sources. Our originals were from 1995 and 1996 depending on the
   helper using it, with a mix of patches.

 * These two directories are in ours sources as lib/smblib and lib/rfcnb.
   Each has its own convenience library. Kept separate with original
   filenames to simplify future upgrades or removal.

 * Samba sources have been diffed and compared function by function
   against the copies previously in our sources. Functionality extensions
   we use have been grafted back on top of the new(er) Samba sources.
  - this was mostly around passing extra Unicode, DC hints and pre-crypted
    passwords to the login checks.
  - some files from libntlmauth have yet to be compared in fine detail,
    that will be completed today before merge.
  - some basic API function and struct definitions had to be moved to the
    API headers to prevent needing to include the *-priv.h private
    definitions externally to the library.

 * the Samba API headers have been wrapped with #ifndef safety wrappers

 * compile errors and include changes required to compile have been
   made (code stays C)

 * duplicate code in helpers/basic_auth/MSNT/* and libntlmauth/* is
   removed.

 * abuse of the smblib-priv.h and rfcnb-priv.h headers and all local
   re-definitions has been erased from our code. Replaced by includes 
   of the library API headers: rfcnb/rfcnb.h  smblib/smblib.h


libntlmauth:
 * smblib/rfcnb bits erased
 * moved to lib/ntlmauth in its much reduced form
 * built as a convenience library instead of full library",14917,data/crawl/squid/hunk_2955.cpp,,,data/crawl/squid/old_hunk_2955.cpp,data/crawl/squid/new_hunk_2955.cpp,-1,1117,,"fprintf(stderr, ""Error receiving response to Check Dir request\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""Error"", ""receiving"", ""response"", ""to"", ""Check"", ""Dir"", ""request\\n""]]",[-10029968754704655339],6145,0.0,2
https://github.com/squid-cache/squid/commit/7c16470cc2d053ea2c540459843227dea08e8b40,16 Oct 2010,"basic_msnt_auth helper and NTLM/SMBLIB/RFCNB library polish.

Samba smblib/rfcnb code:
 * Import the latest copy which I could find a download link to.
   This source is from 1997 so I suspect there is something even newer
   we should be using. Time was tight is the only excuse for using
   these sources. Our originals were from 1995 and 1996 depending on the
   helper using it, with a mix of patches.

 * These two directories are in ours sources as lib/smblib and lib/rfcnb.
   Each has its own convenience library. Kept separate with original
   filenames to simplify future upgrades or removal.

 * Samba sources have been diffed and compared function by function
   against the copies previously in our sources. Functionality extensions
   we use have been grafted back on top of the new(er) Samba sources.
  - this was mostly around passing extra Unicode, DC hints and pre-crypted
    passwords to the login checks.
  - some files from libntlmauth have yet to be compared in fine detail,
    that will be completed today before merge.
  - some basic API function and struct definitions had to be moved to the
    API headers to prevent needing to include the *-priv.h private
    definitions externally to the library.

 * the Samba API headers have been wrapped with #ifndef safety wrappers

 * compile errors and include changes required to compile have been
   made (code stays C)

 * duplicate code in helpers/basic_auth/MSNT/* and libntlmauth/* is
   removed.

 * abuse of the smblib-priv.h and rfcnb-priv.h headers and all local
   re-definitions has been erased from our code. Replaced by includes 
   of the library API headers: rfcnb/rfcnb.h  smblib/smblib.h


libntlmauth:
 * smblib/rfcnb bits erased
 * moved to lib/ntlmauth in its much reduced form
 * built as a convenience library instead of full library",14917,data/crawl/squid/hunk_2955.cpp,,,data/crawl/squid/old_hunk_2955.cpp,data/crawl/squid/new_hunk_2955.cpp,-1,384,,"fprintf(stderr, ""Error receiving response to write\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""Error"", ""receiving"", ""response"", ""to"", ""write\\n""]]",[-22887121004651147542],6144,0.0,2
https://github.com/squid-cache/squid/commit/7c16470cc2d053ea2c540459843227dea08e8b40,16 Oct 2010,"basic_msnt_auth helper and NTLM/SMBLIB/RFCNB library polish.

Samba smblib/rfcnb code:
 * Import the latest copy which I could find a download link to.
   This source is from 1997 so I suspect there is something even newer
   we should be using. Time was tight is the only excuse for using
   these sources. Our originals were from 1995 and 1996 depending on the
   helper using it, with a mix of patches.

 * These two directories are in ours sources as lib/smblib and lib/rfcnb.
   Each has its own convenience library. Kept separate with original
   filenames to simplify future upgrades or removal.

 * Samba sources have been diffed and compared function by function
   against the copies previously in our sources. Functionality extensions
   we use have been grafted back on top of the new(er) Samba sources.
  - this was mostly around passing extra Unicode, DC hints and pre-crypted
    passwords to the login checks.
  - some files from libntlmauth have yet to be compared in fine detail,
    that will be completed today before merge.
  - some basic API function and struct definitions had to be moved to the
    API headers to prevent needing to include the *-priv.h private
    definitions externally to the library.

 * the Samba API headers have been wrapped with #ifndef safety wrappers

 * compile errors and include changes required to compile have been
   made (code stays C)

 * duplicate code in helpers/basic_auth/MSNT/* and libntlmauth/* is
   removed.

 * abuse of the smblib-priv.h and rfcnb-priv.h headers and all local
   re-definitions has been erased from our code. Replaced by includes 
   of the library API headers: rfcnb/rfcnb.h  smblib/smblib.h


libntlmauth:
 * smblib/rfcnb bits erased
 * moved to lib/ntlmauth in its much reduced form
 * built as a convenience library instead of full library",14917,data/crawl/squid/hunk_2955.cpp,,,data/crawl/squid/old_hunk_2955.cpp,data/crawl/squid/new_hunk_2955.cpp,-1,130,,"fprintf(stderr, ""Error receiving response to open request\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""Error"", ""receiving"", ""response"", ""to"", ""open"", ""request\\n""]]",[-11060493559980804330],6143,0.0,2
https://github.com/squid-cache/squid/commit/7c16470cc2d053ea2c540459843227dea08e8b40,16 Oct 2010,"basic_msnt_auth helper and NTLM/SMBLIB/RFCNB library polish.

Samba smblib/rfcnb code:
 * Import the latest copy which I could find a download link to.
   This source is from 1997 so I suspect there is something even newer
   we should be using. Time was tight is the only excuse for using
   these sources. Our originals were from 1995 and 1996 depending on the
   helper using it, with a mix of patches.

 * These two directories are in ours sources as lib/smblib and lib/rfcnb.
   Each has its own convenience library. Kept separate with original
   filenames to simplify future upgrades or removal.

 * Samba sources have been diffed and compared function by function
   against the copies previously in our sources. Functionality extensions
   we use have been grafted back on top of the new(er) Samba sources.
  - this was mostly around passing extra Unicode, DC hints and pre-crypted
    passwords to the login checks.
  - some files from libntlmauth have yet to be compared in fine detail,
    that will be completed today before merge.
  - some basic API function and struct definitions had to be moved to the
    API headers to prevent needing to include the *-priv.h private
    definitions externally to the library.

 * the Samba API headers have been wrapped with #ifndef safety wrappers

 * compile errors and include changes required to compile have been
   made (code stays C)

 * duplicate code in helpers/basic_auth/MSNT/* and libntlmauth/* is
   removed.

 * abuse of the smblib-priv.h and rfcnb-priv.h headers and all local
   re-definitions has been erased from our code. Replaced by includes 
   of the library API headers: rfcnb/rfcnb.h  smblib/smblib.h


libntlmauth:
 * smblib/rfcnb bits erased
 * moved to lib/ntlmauth in its much reduced form
 * built as a convenience library instead of full library",14917,data/crawl/squid/hunk_2945.cpp,,,data/crawl/squid/old_hunk_2945.cpp,data/crawl/squid/new_hunk_2945.cpp,493,-1,"fprintf(stderr, ""SessSetupAndX response. Action = %i\n"",
            SVAL(SMB_Hdr(pkt), SMB_ssetpr_act_offset));",,"[""removeLog""]","[[""fprintf"", ""stderr"", ""SessSetupAndX"", ""response"", ""Action"", ""%i\\n"", ""SVAL"", ""SMB_Hdr"", ""pkt"", ""SMB_ssetpr_act_offset""], []]",[4441335963205359382],6142,0.0,2
https://github.com/squid-cache/squid/commit/7c16470cc2d053ea2c540459843227dea08e8b40,16 Oct 2010,"basic_msnt_auth helper and NTLM/SMBLIB/RFCNB library polish.

Samba smblib/rfcnb code:
 * Import the latest copy which I could find a download link to.
   This source is from 1997 so I suspect there is something even newer
   we should be using. Time was tight is the only excuse for using
   these sources. Our originals were from 1995 and 1996 depending on the
   helper using it, with a mix of patches.

 * These two directories are in ours sources as lib/smblib and lib/rfcnb.
   Each has its own convenience library. Kept separate with original
   filenames to simplify future upgrades or removal.

 * Samba sources have been diffed and compared function by function
   against the copies previously in our sources. Functionality extensions
   we use have been grafted back on top of the new(er) Samba sources.
  - this was mostly around passing extra Unicode, DC hints and pre-crypted
    passwords to the login checks.
  - some files from libntlmauth have yet to be compared in fine detail,
    that will be completed today before merge.
  - some basic API function and struct definitions had to be moved to the
    API headers to prevent needing to include the *-priv.h private
    definitions externally to the library.

 * the Samba API headers have been wrapped with #ifndef safety wrappers

 * compile errors and include changes required to compile have been
   made (code stays C)

 * duplicate code in helpers/basic_auth/MSNT/* and libntlmauth/* is
   removed.

 * abuse of the smblib-priv.h and rfcnb-priv.h headers and all local
   re-definitions has been erased from our code. Replaced by includes 
   of the library API headers: rfcnb/rfcnb.h  smblib/smblib.h


libntlmauth:
 * smblib/rfcnb bits erased
 * moved to lib/ntlmauth in its much reduced form
 * built as a convenience library instead of full library",14917,data/crawl/squid/hunk_2945.cpp,,,data/crawl/squid/old_hunk_2945.cpp,data/crawl/squid/new_hunk_2945.cpp,481,-1,"fprintf(stderr, ""SMB_SessSetupAndX failed with errorclass = %i, Error Code = %i\n"",
                CVAL(SMB_Hdr(pkt), SMB_hdr_rcls_offset),
                SVAL(SMB_Hdr(pkt), SMB_hdr_err_offset));",,"[""removeLog""]","[[""fprintf"", ""stderr"", ""SMB_SessSetupAndX"", ""failed"", ""with"", ""errorclass"", ""%i"", ""Error"", ""Code"", ""%i\\n"", ""CVAL"", ""SMB_Hdr"", ""pkt"", ""SMB_hdr_rcls_offset"", ""SVAL"", ""SMB_Hdr"", ""pkt"", ""SMB_hdr_err_offset""], []]",[-5891327049776777669],6141,0.0,2
https://github.com/squid-cache/squid/commit/7c16470cc2d053ea2c540459843227dea08e8b40,16 Oct 2010,"basic_msnt_auth helper and NTLM/SMBLIB/RFCNB library polish.

Samba smblib/rfcnb code:
 * Import the latest copy which I could find a download link to.
   This source is from 1997 so I suspect there is something even newer
   we should be using. Time was tight is the only excuse for using
   these sources. Our originals were from 1995 and 1996 depending on the
   helper using it, with a mix of patches.

 * These two directories are in ours sources as lib/smblib and lib/rfcnb.
   Each has its own convenience library. Kept separate with original
   filenames to simplify future upgrades or removal.

 * Samba sources have been diffed and compared function by function
   against the copies previously in our sources. Functionality extensions
   we use have been grafted back on top of the new(er) Samba sources.
  - this was mostly around passing extra Unicode, DC hints and pre-crypted
    passwords to the login checks.
  - some files from libntlmauth have yet to be compared in fine detail,
    that will be completed today before merge.
  - some basic API function and struct definitions had to be moved to the
    API headers to prevent needing to include the *-priv.h private
    definitions externally to the library.

 * the Samba API headers have been wrapped with #ifndef safety wrappers

 * compile errors and include changes required to compile have been
   made (code stays C)

 * duplicate code in helpers/basic_auth/MSNT/* and libntlmauth/* is
   removed.

 * abuse of the smblib-priv.h and rfcnb-priv.h headers and all local
   re-definitions has been erased from our code. Replaced by includes 
   of the library API headers: rfcnb/rfcnb.h  smblib/smblib.h


libntlmauth:
 * smblib/rfcnb bits erased
 * moved to lib/ntlmauth in its much reduced form
 * built as a convenience library instead of full library",14917,data/crawl/squid/hunk_2945.cpp,,,data/crawl/squid/old_hunk_2945.cpp,data/crawl/squid/new_hunk_2945.cpp,468,-1,"fprintf(stderr, ""Error receiving response to SessSetupAndX\n"");",,"[""removeLog""]","[[""fprintf"", ""stderr"", ""Error"", ""receiving"", ""response"", ""to"", ""SessSetupAndX\\n""], []]",[17664103020917590369],6140,0.0,2
https://github.com/squid-cache/squid/commit/7c16470cc2d053ea2c540459843227dea08e8b40,16 Oct 2010,"basic_msnt_auth helper and NTLM/SMBLIB/RFCNB library polish.

Samba smblib/rfcnb code:
 * Import the latest copy which I could find a download link to.
   This source is from 1997 so I suspect there is something even newer
   we should be using. Time was tight is the only excuse for using
   these sources. Our originals were from 1995 and 1996 depending on the
   helper using it, with a mix of patches.

 * These two directories are in ours sources as lib/smblib and lib/rfcnb.
   Each has its own convenience library. Kept separate with original
   filenames to simplify future upgrades or removal.

 * Samba sources have been diffed and compared function by function
   against the copies previously in our sources. Functionality extensions
   we use have been grafted back on top of the new(er) Samba sources.
  - this was mostly around passing extra Unicode, DC hints and pre-crypted
    passwords to the login checks.
  - some files from libntlmauth have yet to be compared in fine detail,
    that will be completed today before merge.
  - some basic API function and struct definitions had to be moved to the
    API headers to prevent needing to include the *-priv.h private
    definitions externally to the library.

 * the Samba API headers have been wrapped with #ifndef safety wrappers

 * compile errors and include changes required to compile have been
   made (code stays C)

 * duplicate code in helpers/basic_auth/MSNT/* and libntlmauth/* is
   removed.

 * abuse of the smblib-priv.h and rfcnb-priv.h headers and all local
   re-definitions has been erased from our code. Replaced by includes 
   of the library API headers: rfcnb/rfcnb.h  smblib/smblib.h


libntlmauth:
 * smblib/rfcnb bits erased
 * moved to lib/ntlmauth in its much reduced form
 * built as a convenience library instead of full library",14917,data/crawl/squid/hunk_2945.cpp,,,data/crawl/squid/old_hunk_2945.cpp,data/crawl/squid/new_hunk_2945.cpp,455,-1,"fprintf(stderr, ""Error sending SessSetupX request\n"");",,"[""removeLog""]","[[""fprintf"", ""stderr"", ""Error"", ""sending"", ""SessSetupX"", ""request\\n""], []]",[5811297851841865137],6139,0.0,2
https://github.com/squid-cache/squid/commit/7c16470cc2d053ea2c540459843227dea08e8b40,16 Oct 2010,"basic_msnt_auth helper and NTLM/SMBLIB/RFCNB library polish.

Samba smblib/rfcnb code:
 * Import the latest copy which I could find a download link to.
   This source is from 1997 so I suspect there is something even newer
   we should be using. Time was tight is the only excuse for using
   these sources. Our originals were from 1995 and 1996 depending on the
   helper using it, with a mix of patches.

 * These two directories are in ours sources as lib/smblib and lib/rfcnb.
   Each has its own convenience library. Kept separate with original
   filenames to simplify future upgrades or removal.

 * Samba sources have been diffed and compared function by function
   against the copies previously in our sources. Functionality extensions
   we use have been grafted back on top of the new(er) Samba sources.
  - this was mostly around passing extra Unicode, DC hints and pre-crypted
    passwords to the login checks.
  - some files from libntlmauth have yet to be compared in fine detail,
    that will be completed today before merge.
  - some basic API function and struct definitions had to be moved to the
    API headers to prevent needing to include the *-priv.h private
    definitions externally to the library.

 * the Samba API headers have been wrapped with #ifndef safety wrappers

 * compile errors and include changes required to compile have been
   made (code stays C)

 * duplicate code in helpers/basic_auth/MSNT/* and libntlmauth/* is
   removed.

 * abuse of the smblib-priv.h and rfcnb-priv.h headers and all local
   re-definitions has been erased from our code. Replaced by includes 
   of the library API headers: rfcnb/rfcnb.h  smblib/smblib.h


libntlmauth:
 * smblib/rfcnb bits erased
 * moved to lib/ntlmauth in its much reduced form
 * built as a convenience library instead of full library",14917,data/crawl/squid/hunk_2944.cpp,,,data/crawl/squid/old_hunk_2944.cpp,data/crawl/squid/new_hunk_2944.cpp,442,-1,"fprintf(stderr, ""Error receiving response to TCon\n"");",,"[""removeLog""]","[[""fprintf"", ""stderr"", ""Error"", ""receiving"", ""response"", ""to"", ""TCon\\n""], []]",[26711466169847032482],6138,2186640.0,2
https://github.com/squid-cache/squid/commit/7c16470cc2d053ea2c540459843227dea08e8b40,16 Oct 2010,"basic_msnt_auth helper and NTLM/SMBLIB/RFCNB library polish.

Samba smblib/rfcnb code:
 * Import the latest copy which I could find a download link to.
   This source is from 1997 so I suspect there is something even newer
   we should be using. Time was tight is the only excuse for using
   these sources. Our originals were from 1995 and 1996 depending on the
   helper using it, with a mix of patches.

 * These two directories are in ours sources as lib/smblib and lib/rfcnb.
   Each has its own convenience library. Kept separate with original
   filenames to simplify future upgrades or removal.

 * Samba sources have been diffed and compared function by function
   against the copies previously in our sources. Functionality extensions
   we use have been grafted back on top of the new(er) Samba sources.
  - this was mostly around passing extra Unicode, DC hints and pre-crypted
    passwords to the login checks.
  - some files from libntlmauth have yet to be compared in fine detail,
    that will be completed today before merge.
  - some basic API function and struct definitions had to be moved to the
    API headers to prevent needing to include the *-priv.h private
    definitions externally to the library.

 * the Samba API headers have been wrapped with #ifndef safety wrappers

 * compile errors and include changes required to compile have been
   made (code stays C)

 * duplicate code in helpers/basic_auth/MSNT/* and libntlmauth/* is
   removed.

 * abuse of the smblib-priv.h and rfcnb-priv.h headers and all local
   re-definitions has been erased from our code. Replaced by includes 
   of the library API headers: rfcnb/rfcnb.h  smblib/smblib.h


libntlmauth:
 * smblib/rfcnb bits erased
 * moved to lib/ntlmauth in its much reduced form
 * built as a convenience library instead of full library",14917,data/crawl/squid/hunk_2943.cpp,,,data/crawl/squid/old_hunk_2943.cpp,data/crawl/squid/new_hunk_2943.cpp,260,-1,"fprintf(stderr, ""Bad packet return in RFCNB_Recv... \n"");",,"[""removeLog""]","[[""fprintf"", ""stderr"", ""Bad"", ""packet"", ""return"", ""in"", ""RFCNB_Recv"", ""\\n""], []]",[13390460590631321895],6137,0.0,2
https://github.com/squid-cache/squid/commit/7c16470cc2d053ea2c540459843227dea08e8b40,16 Oct 2010,"basic_msnt_auth helper and NTLM/SMBLIB/RFCNB library polish.

Samba smblib/rfcnb code:
 * Import the latest copy which I could find a download link to.
   This source is from 1997 so I suspect there is something even newer
   we should be using. Time was tight is the only excuse for using
   these sources. Our originals were from 1995 and 1996 depending on the
   helper using it, with a mix of patches.

 * These two directories are in ours sources as lib/smblib and lib/rfcnb.
   Each has its own convenience library. Kept separate with original
   filenames to simplify future upgrades or removal.

 * Samba sources have been diffed and compared function by function
   against the copies previously in our sources. Functionality extensions
   we use have been grafted back on top of the new(er) Samba sources.
  - this was mostly around passing extra Unicode, DC hints and pre-crypted
    passwords to the login checks.
  - some files from libntlmauth have yet to be compared in fine detail,
    that will be completed today before merge.
  - some basic API function and struct definitions had to be moved to the
    API headers to prevent needing to include the *-priv.h private
    definitions externally to the library.

 * the Samba API headers have been wrapped with #ifndef safety wrappers

 * compile errors and include changes required to compile have been
   made (code stays C)

 * duplicate code in helpers/basic_auth/MSNT/* and libntlmauth/* is
   removed.

 * abuse of the smblib-priv.h and rfcnb-priv.h headers and all local
   re-definitions has been erased from our code. Replaced by includes 
   of the library API headers: rfcnb/rfcnb.h  smblib/smblib.h


libntlmauth:
 * smblib/rfcnb bits erased
 * moved to lib/ntlmauth in its much reduced form
 * built as a convenience library instead of full library",14917,data/crawl/squid/hunk_2942.cpp,,,data/crawl/squid/old_hunk_2942.cpp,data/crawl/squid/new_hunk_2942.cpp,383,-1,"fprintf(stderr, ""Pkt Len = %i, read_len = %i\n"", pkt_len, read_len);",,"[""removeLog""]","[[""fprintf"", ""stderr"", ""Pkt"", ""Len"", ""%i"", ""read_len"", ""%i\\n"", ""pkt_len"", ""read_len""], []]",[-14749515261673248060],6136,0.0,2
https://github.com/squid-cache/squid/commit/7c16470cc2d053ea2c540459843227dea08e8b40,16 Oct 2010,"basic_msnt_auth helper and NTLM/SMBLIB/RFCNB library polish.

Samba smblib/rfcnb code:
 * Import the latest copy which I could find a download link to.
   This source is from 1997 so I suspect there is something even newer
   we should be using. Time was tight is the only excuse for using
   these sources. Our originals were from 1995 and 1996 depending on the
   helper using it, with a mix of patches.

 * These two directories are in ours sources as lib/smblib and lib/rfcnb.
   Each has its own convenience library. Kept separate with original
   filenames to simplify future upgrades or removal.

 * Samba sources have been diffed and compared function by function
   against the copies previously in our sources. Functionality extensions
   we use have been grafted back on top of the new(er) Samba sources.
  - this was mostly around passing extra Unicode, DC hints and pre-crypted
    passwords to the login checks.
  - some files from libntlmauth have yet to be compared in fine detail,
    that will be completed today before merge.
  - some basic API function and struct definitions had to be moved to the
    API headers to prevent needing to include the *-priv.h private
    definitions externally to the library.

 * the Samba API headers have been wrapped with #ifndef safety wrappers

 * compile errors and include changes required to compile have been
   made (code stays C)

 * duplicate code in helpers/basic_auth/MSNT/* and libntlmauth/* is
   removed.

 * abuse of the smblib-priv.h and rfcnb-priv.h headers and all local
   re-definitions has been erased from our code. Replaced by includes 
   of the library API headers: rfcnb/rfcnb.h  smblib/smblib.h


libntlmauth:
 * smblib/rfcnb bits erased
 * moved to lib/ntlmauth in its much reduced form
 * built as a convenience library instead of full library",14917,data/crawl/squid/hunk_2942.cpp,,,data/crawl/squid/old_hunk_2942.cpp,data/crawl/squid/new_hunk_2942.cpp,363,-1,"fprintf(stderr, ""Frag_Len = %i, this_time = %i, this_len = %i, more = %i\n"", frag_len,
                this_time, this_len, more);",,"[""removeLog""]","[[""fprintf"", ""stderr"", ""Frag_Len"", ""%i"", ""this_time"", ""%i"", ""this_len"", ""%i"", ""more"", ""%i\\n"", ""frag_len"", ""this_time"", ""this_len"", ""more""], []]",[21986929429100296154],6135,0.0,2
https://github.com/squid-cache/squid/commit/7c16470cc2d053ea2c540459843227dea08e8b40,16 Oct 2010,"basic_msnt_auth helper and NTLM/SMBLIB/RFCNB library polish.

Samba smblib/rfcnb code:
 * Import the latest copy which I could find a download link to.
   This source is from 1997 so I suspect there is something even newer
   we should be using. Time was tight is the only excuse for using
   these sources. Our originals were from 1995 and 1996 depending on the
   helper using it, with a mix of patches.

 * These two directories are in ours sources as lib/smblib and lib/rfcnb.
   Each has its own convenience library. Kept separate with original
   filenames to simplify future upgrades or removal.

 * Samba sources have been diffed and compared function by function
   against the copies previously in our sources. Functionality extensions
   we use have been grafted back on top of the new(er) Samba sources.
  - this was mostly around passing extra Unicode, DC hints and pre-crypted
    passwords to the login checks.
  - some files from libntlmauth have yet to be compared in fine detail,
    that will be completed today before merge.
  - some basic API function and struct definitions had to be moved to the
    API headers to prevent needing to include the *-priv.h private
    definitions externally to the library.

 * the Samba API headers have been wrapped with #ifndef safety wrappers

 * compile errors and include changes required to compile have been
   made (code stays C)

 * duplicate code in helpers/basic_auth/MSNT/* and libntlmauth/* is
   removed.

 * abuse of the smblib-priv.h and rfcnb-priv.h headers and all local
   re-definitions has been erased from our code. Replaced by includes 
   of the library API headers: rfcnb/rfcnb.h  smblib/smblib.h


libntlmauth:
 * smblib/rfcnb bits erased
 * moved to lib/ntlmauth in its much reduced form
 * built as a convenience library instead of full library",14917,data/crawl/squid/hunk_2942.cpp,,,data/crawl/squid/old_hunk_2942.cpp,data/crawl/squid/new_hunk_2942.cpp,308,-1,"fprintf(stderr, ""Reading Pkt: Length = %i\n"", pkt_len);",,"[""removeLog""]","[[""fprintf"", ""stderr"", ""Reading"", ""Pkt"", ""Length"", ""%i\\n"", ""pkt_len""], []]",[2546329978924844425],6134,0.0,2
https://github.com/squid-cache/squid/commit/7c16470cc2d053ea2c540459843227dea08e8b40,16 Oct 2010,"basic_msnt_auth helper and NTLM/SMBLIB/RFCNB library polish.

Samba smblib/rfcnb code:
 * Import the latest copy which I could find a download link to.
   This source is from 1997 so I suspect there is something even newer
   we should be using. Time was tight is the only excuse for using
   these sources. Our originals were from 1995 and 1996 depending on the
   helper using it, with a mix of patches.

 * These two directories are in ours sources as lib/smblib and lib/rfcnb.
   Each has its own convenience library. Kept separate with original
   filenames to simplify future upgrades or removal.

 * Samba sources have been diffed and compared function by function
   against the copies previously in our sources. Functionality extensions
   we use have been grafted back on top of the new(er) Samba sources.
  - this was mostly around passing extra Unicode, DC hints and pre-crypted
    passwords to the login checks.
  - some files from libntlmauth have yet to be compared in fine detail,
    that will be completed today before merge.
  - some basic API function and struct definitions had to be moved to the
    API headers to prevent needing to include the *-priv.h private
    definitions externally to the library.

 * the Samba API headers have been wrapped with #ifndef safety wrappers

 * compile errors and include changes required to compile have been
   made (code stays C)

 * duplicate code in helpers/basic_auth/MSNT/* and libntlmauth/* is
   removed.

 * abuse of the smblib-priv.h and rfcnb-priv.h headers and all local
   re-definitions has been erased from our code. Replaced by includes 
   of the library API headers: rfcnb/rfcnb.h  smblib/smblib.h


libntlmauth:
 * smblib/rfcnb bits erased
 * moved to lib/ntlmauth in its much reduced form
 * built as a convenience library instead of full library",14917,data/crawl/squid/hunk_2942.cpp,,,data/crawl/squid/old_hunk_2942.cpp,data/crawl/squid/new_hunk_2942.cpp,279,-1,"fprintf(stderr, ""RFCNB KEEP ALIVE received\n"");",,"[""removeLog""]","[[""fprintf"", ""stderr"", ""RFCNB"", ""KEEP"", ""ALIVE"", ""received\\n""], []]",[4094161876581336934],6133,0.0,2
https://github.com/squid-cache/squid/commit/7c16470cc2d053ea2c540459843227dea08e8b40,16 Oct 2010,"basic_msnt_auth helper and NTLM/SMBLIB/RFCNB library polish.

Samba smblib/rfcnb code:
 * Import the latest copy which I could find a download link to.
   This source is from 1997 so I suspect there is something even newer
   we should be using. Time was tight is the only excuse for using
   these sources. Our originals were from 1995 and 1996 depending on the
   helper using it, with a mix of patches.

 * These two directories are in ours sources as lib/smblib and lib/rfcnb.
   Each has its own convenience library. Kept separate with original
   filenames to simplify future upgrades or removal.

 * Samba sources have been diffed and compared function by function
   against the copies previously in our sources. Functionality extensions
   we use have been grafted back on top of the new(er) Samba sources.
  - this was mostly around passing extra Unicode, DC hints and pre-crypted
    passwords to the login checks.
  - some files from libntlmauth have yet to be compared in fine detail,
    that will be completed today before merge.
  - some basic API function and struct definitions had to be moved to the
    API headers to prevent needing to include the *-priv.h private
    definitions externally to the library.

 * the Samba API headers have been wrapped with #ifndef safety wrappers

 * compile errors and include changes required to compile have been
   made (code stays C)

 * duplicate code in helpers/basic_auth/MSNT/* and libntlmauth/* is
   removed.

 * abuse of the smblib-priv.h and rfcnb-priv.h headers and all local
   re-definitions has been erased from our code. Replaced by includes 
   of the library API headers: rfcnb/rfcnb.h  smblib/smblib.h


libntlmauth:
 * smblib/rfcnb bits erased
 * moved to lib/ntlmauth in its much reduced form
 * built as a convenience library instead of full library",14917,data/crawl/squid/hunk_2942.cpp,,,data/crawl/squid/old_hunk_2942.cpp,data/crawl/squid/new_hunk_2942.cpp,265,-1,"fprintf(stderr, ""Connection closed reading\n"");",,"[""removeLog""]","[[""fprintf"", ""stderr"", ""Connection"", ""closed"", ""reading\\n""], []]",[3658438838238786031],6132,0.0,2
https://github.com/squid-cache/squid/commit/7c16470cc2d053ea2c540459843227dea08e8b40,16 Oct 2010,"basic_msnt_auth helper and NTLM/SMBLIB/RFCNB library polish.

Samba smblib/rfcnb code:
 * Import the latest copy which I could find a download link to.
   This source is from 1997 so I suspect there is something even newer
   we should be using. Time was tight is the only excuse for using
   these sources. Our originals were from 1995 and 1996 depending on the
   helper using it, with a mix of patches.

 * These two directories are in ours sources as lib/smblib and lib/rfcnb.
   Each has its own convenience library. Kept separate with original
   filenames to simplify future upgrades or removal.

 * Samba sources have been diffed and compared function by function
   against the copies previously in our sources. Functionality extensions
   we use have been grafted back on top of the new(er) Samba sources.
  - this was mostly around passing extra Unicode, DC hints and pre-crypted
    passwords to the login checks.
  - some files from libntlmauth have yet to be compared in fine detail,
    that will be completed today before merge.
  - some basic API function and struct definitions had to be moved to the
    API headers to prevent needing to include the *-priv.h private
    definitions externally to the library.

 * the Samba API headers have been wrapped with #ifndef safety wrappers

 * compile errors and include changes required to compile have been
   made (code stays C)

 * duplicate code in helpers/basic_auth/MSNT/* and libntlmauth/* is
   removed.

 * abuse of the smblib-priv.h and rfcnb-priv.h headers and all local
   re-definitions has been erased from our code. Replaced by includes 
   of the library API headers: rfcnb/rfcnb.h  smblib/smblib.h


libntlmauth:
 * smblib/rfcnb bits erased
 * moved to lib/ntlmauth in its much reduced form
 * built as a convenience library instead of full library",14917,data/crawl/squid/hunk_2942.cpp,,,data/crawl/squid/old_hunk_2942.cpp,data/crawl/squid/new_hunk_2942.cpp,249,-1,"fprintf(stderr, ""Reading the packet, we got:"");",,"[""removeLog""]","[[""fprintf"", ""stderr"", ""Reading"", ""the"", ""packet"", ""we"", ""got""], []]",[31893954141555588920],6131,0.0,2
https://github.com/squid-cache/squid/commit/7c16470cc2d053ea2c540459843227dea08e8b40,16 Oct 2010,"basic_msnt_auth helper and NTLM/SMBLIB/RFCNB library polish.

Samba smblib/rfcnb code:
 * Import the latest copy which I could find a download link to.
   This source is from 1997 so I suspect there is something even newer
   we should be using. Time was tight is the only excuse for using
   these sources. Our originals were from 1995 and 1996 depending on the
   helper using it, with a mix of patches.

 * These two directories are in ours sources as lib/smblib and lib/rfcnb.
   Each has its own convenience library. Kept separate with original
   filenames to simplify future upgrades or removal.

 * Samba sources have been diffed and compared function by function
   against the copies previously in our sources. Functionality extensions
   we use have been grafted back on top of the new(er) Samba sources.
  - this was mostly around passing extra Unicode, DC hints and pre-crypted
    passwords to the login checks.
  - some files from libntlmauth have yet to be compared in fine detail,
    that will be completed today before merge.
  - some basic API function and struct definitions had to be moved to the
    API headers to prevent needing to include the *-priv.h private
    definitions externally to the library.

 * the Samba API headers have been wrapped with #ifndef safety wrappers

 * compile errors and include changes required to compile have been
   made (code stays C)

 * duplicate code in helpers/basic_auth/MSNT/* and libntlmauth/* is
   removed.

 * abuse of the smblib-priv.h and rfcnb-priv.h headers and all local
   re-definitions has been erased from our code. Replaced by includes 
   of the library API headers: rfcnb/rfcnb.h  smblib/smblib.h


libntlmauth:
 * smblib/rfcnb bits erased
 * moved to lib/ntlmauth in its much reduced form
 * built as a convenience library instead of full library",14917,data/crawl/squid/hunk_2942.cpp,,,data/crawl/squid/old_hunk_2942.cpp,data/crawl/squid/new_hunk_2942.cpp,233,-1,"fprintf(stderr, ""Trying to read less than a packet:"");",,"[""removeLog""]","[[""fprintf"", ""stderr"", ""Trying"", ""to"", ""read"", ""less"", ""than"", ""a"", ""packet""], []]",[16752697044726255696],6130,0.0,2
https://github.com/squid-cache/squid/commit/7c16470cc2d053ea2c540459843227dea08e8b40,16 Oct 2010,"basic_msnt_auth helper and NTLM/SMBLIB/RFCNB library polish.

Samba smblib/rfcnb code:
 * Import the latest copy which I could find a download link to.
   This source is from 1997 so I suspect there is something even newer
   we should be using. Time was tight is the only excuse for using
   these sources. Our originals were from 1995 and 1996 depending on the
   helper using it, with a mix of patches.

 * These two directories are in ours sources as lib/smblib and lib/rfcnb.
   Each has its own convenience library. Kept separate with original
   filenames to simplify future upgrades or removal.

 * Samba sources have been diffed and compared function by function
   against the copies previously in our sources. Functionality extensions
   we use have been grafted back on top of the new(er) Samba sources.
  - this was mostly around passing extra Unicode, DC hints and pre-crypted
    passwords to the login checks.
  - some files from libntlmauth have yet to be compared in fine detail,
    that will be completed today before merge.
  - some basic API function and struct definitions had to be moved to the
    API headers to prevent needing to include the *-priv.h private
    definitions externally to the library.

 * the Samba API headers have been wrapped with #ifndef safety wrappers

 * compile errors and include changes required to compile have been
   made (code stays C)

 * duplicate code in helpers/basic_auth/MSNT/* and libntlmauth/* is
   removed.

 * abuse of the smblib-priv.h and rfcnb-priv.h headers and all local
   re-definitions has been erased from our code. Replaced by includes 
   of the library API headers: rfcnb/rfcnb.h  smblib/smblib.h


libntlmauth:
 * smblib/rfcnb bits erased
 * moved to lib/ntlmauth in its much reduced form
 * built as a convenience library instead of full library",14917,data/crawl/squid/hunk_2942.cpp,,,data/crawl/squid/old_hunk_2942.cpp,data/crawl/squid/new_hunk_2942.cpp,202,-1,"fprintf(stderr, ""Len sent = %i ...\n"", len_sent);",,"[""removeLog""]","[[""fprintf"", ""stderr"", ""Len"", ""sent"", ""%i"", ""\\n"", ""len_sent""], []]",[1761508097882951492],6129,0.0,2
https://github.com/squid-cache/squid/commit/7c16470cc2d053ea2c540459843227dea08e8b40,16 Oct 2010,"basic_msnt_auth helper and NTLM/SMBLIB/RFCNB library polish.

Samba smblib/rfcnb code:
 * Import the latest copy which I could find a download link to.
   This source is from 1997 so I suspect there is something even newer
   we should be using. Time was tight is the only excuse for using
   these sources. Our originals were from 1995 and 1996 depending on the
   helper using it, with a mix of patches.

 * These two directories are in ours sources as lib/smblib and lib/rfcnb.
   Each has its own convenience library. Kept separate with original
   filenames to simplify future upgrades or removal.

 * Samba sources have been diffed and compared function by function
   against the copies previously in our sources. Functionality extensions
   we use have been grafted back on top of the new(er) Samba sources.
  - this was mostly around passing extra Unicode, DC hints and pre-crypted
    passwords to the login checks.
  - some files from libntlmauth have yet to be compared in fine detail,
    that will be completed today before merge.
  - some basic API function and struct definitions had to be moved to the
    API headers to prevent needing to include the *-priv.h private
    definitions externally to the library.

 * the Samba API headers have been wrapped with #ifndef safety wrappers

 * compile errors and include changes required to compile have been
   made (code stays C)

 * duplicate code in helpers/basic_auth/MSNT/* and libntlmauth/* is
   removed.

 * abuse of the smblib-priv.h and rfcnb-priv.h headers and all local
   re-definitions has been erased from our code. Replaced by includes 
   of the library API headers: rfcnb/rfcnb.h  smblib/smblib.h


libntlmauth:
 * smblib/rfcnb bits erased
 * moved to lib/ntlmauth in its much reduced form
 * built as a convenience library instead of full library",14917,data/crawl/squid/hunk_2942.cpp,,,data/crawl/squid/old_hunk_2942.cpp,data/crawl/squid/new_hunk_2942.cpp,170,-1,"fprintf(stderr, ""Frags = %i, tot_sent = %i\n"", i, tot_sent);",,"[""removeLog""]","[[""fprintf"", ""stderr"", ""Frags"", ""%i"", ""tot_sent"", ""%i\\n"", ""i"", ""tot_sent""], []]",[-386152058147198788],6128,0.0,2
https://github.com/squid-cache/squid/commit/7c16470cc2d053ea2c540459843227dea08e8b40,16 Oct 2010,"basic_msnt_auth helper and NTLM/SMBLIB/RFCNB library polish.

Samba smblib/rfcnb code:
 * Import the latest copy which I could find a download link to.
   This source is from 1997 so I suspect there is something even newer
   we should be using. Time was tight is the only excuse for using
   these sources. Our originals were from 1995 and 1996 depending on the
   helper using it, with a mix of patches.

 * These two directories are in ours sources as lib/smblib and lib/rfcnb.
   Each has its own convenience library. Kept separate with original
   filenames to simplify future upgrades or removal.

 * Samba sources have been diffed and compared function by function
   against the copies previously in our sources. Functionality extensions
   we use have been grafted back on top of the new(er) Samba sources.
  - this was mostly around passing extra Unicode, DC hints and pre-crypted
    passwords to the login checks.
  - some files from libntlmauth have yet to be compared in fine detail,
    that will be completed today before merge.
  - some basic API function and struct definitions had to be moved to the
    API headers to prevent needing to include the *-priv.h private
    definitions externally to the library.

 * the Samba API headers have been wrapped with #ifndef safety wrappers

 * compile errors and include changes required to compile have been
   made (code stays C)

 * duplicate code in helpers/basic_auth/MSNT/* and libntlmauth/* is
   removed.

 * abuse of the smblib-priv.h and rfcnb-priv.h headers and all local
   re-definitions has been erased from our code. Replaced by includes 
   of the library API headers: rfcnb/rfcnb.h  smblib/smblib.h


libntlmauth:
 * smblib/rfcnb bits erased
 * moved to lib/ntlmauth in its much reduced form
 * built as a convenience library instead of full library",14917,data/crawl/squid/hunk_2942.cpp,,,data/crawl/squid/old_hunk_2942.cpp,data/crawl/squid/new_hunk_2942.cpp,93,-1,"fprintf(stderr, ""Discard_Rest called to discard: %i\n"", len);",,"[""removeLog""]","[[""fprintf"", ""stderr"", ""Discard_Rest"", ""called"", ""to"", ""discard"", ""%i\\n"", ""len""], []]",[2698513984810611498],6127,0.0,2
https://github.com/squid-cache/squid/commit/e210930bd797caf3c79c65f995aabd10b15332a1,17 Oct 2010,"Bug 2785: DNS needs to set EDNS options advertising Squid capabilities

... allowing Squid to advertise a larger UDP reply size than 512 bytes.

Internally Squid has a buffer allocated on demand so there is no
practicable limit on individual packets. Network topology and external
software places stricter boundaries on what works and what does not.

Squid does not parse the additional section of replies so for now the
full auto-negotiation EDNS allows is not used. Instead a configuration
option is provided for admin to configure a desirable packet size in
bytes. EDNS defaults to ""none"" (disabled) until tested in a wider
environment.

Testing so far has brought to light problems with EDNS adverts on A and
IPv4-PTR queries. So support is limited to AAAA and IPv6-PTR queries only.
EDNS compliant resolvers have the option of caching the info between
requests for a short while so this will hopefully leak over to improve
IPv4 responses as well.",457,data/crawl/squid/hunk_2940.cpp,,,data/crawl/squid/old_hunk_2940.cpp,data/crawl/squid/new_hunk_2940.cpp,-1,8,,"storeAppendPrintf(sentry, ""\nNameservers:\n"");","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""\\nNameservers"", ""\\n""]]",[5476975443759984694],6126,3026160.0,2
https://github.com/squid-cache/squid/commit/a1ad2f9b4fc8d5540bd531dad4bf1b70bf6e34f9,17 Oct 2010,"Author: Adrian Chadd <adri@squid-cache.org>
Author: Peter Payne
Bug 2356: Solaris /dev/poll event ports support.

Original code by Adrian Chadd.
Ported from Squid-2 by Peter Payne, Pirosa Limited UK.

With sponsorship of development and testing from:
  BBC (UK)
  Siemens IT Solutions and Services (UK)",546,data/crawl/squid/hunk_2936.cpp,,,data/crawl/squid/old_hunk_2936.cpp,data/crawl/squid/new_hunk_2936.cpp,-1,175,,"storeAppendPrintf(sentry, ""Histogram of returned filedescriptors\n"");","[""addLog""]","[[], [""storeAppendPrintf"", ""sentry"", ""Histogram"", ""of"", ""returned"", ""filedescriptors\\n""]]",[8793565030453698602],6125,1152720.0,2
https://github.com/squid-cache/squid/commit/8822ebee4947bcf883d74aa79a26e896449d0c36,28 Oct 2010,"SMP Cache Manager, Phase2 implementation.

Cache Manager actions are forwarded to Coordinator. Coordinator iterates over
Kids, aggregating their stats if possible and/or allowing each kid to dump
non-aggregatable output directly into response if needed. Non-aggregated
output is wrapped in ""by kidN { ... } by kidN"" markup to ease auto-processing.

Regressions and small output formatting changes are probably unavoidable
because stats are aggregated and passed around as doubles instead of integers
(no more overflows though!) and because many stats collection and formatting
lines had to be touched. These are steps in the right direction though, IMO.


Old code both computed and dumped stats to Store at the same time. To avoid
computing code duplication, we now collect stats in primitive Stats objects
and then either dump those to Store or send them to Coordinator for
aggregation and, eventual Store dump. What stats to collect, when to
aggregate, and when to dump is decided by action-specific Mgr::Action classes.

The Cache Manager menu now consists of ActionProfile objects. ActionProfile
maintains hard-coded information about specific actions. It uses ActionCreator
member to create Action objects when a cache manager request is received.

Added Mgr::ActionParams class to maintain action parameters, including HTTP
request details necessary for Store entry creation (in another strand) and
action-specific parameters (currently just credentials). In Phase3, this class
can be extended to supply more parameters such as kid IDs to which the action
should apply.

Added Mgr::Command that combines hard-coded ActionProfile details with
user-specified ActionParams. This simplifies many interfaces because we no
longer need to supply a long list of parameters, covering various parts of
action config.


Moved Cache Manager registration to Mgr::RegisterAction() globals to reduce
dependency on the CacheManager class, which is a singleton anyway, and which
is unused by most of the registration callers.  On the other hand, without
this change, no legacy (function-based actions) code would have been changed!


Enhanced TypedMsgHdr class to simplify storing and loading non-POD classes.
The caller can now easily handle a non-POD class as a series of put/get calls,
one for each POD member. This was necessary to send Mgr::ActionParams to
Coordinator and back. Will probably be useful for sending other complex
structures as well.


Reconfigure, shutdown, and other ""basic"" actions have been moved to
src/mgr/BasicActions.cc. Mgr::RegisterBasics() registers them.


Most of the Cache Manager code is now in src/mgr/.


Many more polishing touches.


More polishing left for future projects: Move CacheManager to Mgr namespace
and src/mgr/ directory. Use SBuf instead of String for ActionParams and
TypedMsgHdr. Rename Ipc::TypedMsgHdr to Ipc::Msg, Ipc::SocketMsg, or similar
because it maintains more than just msghdr struct. More stats aggregation,
and Phase3 changes.",6354,data/crawl/squid/hunk_2922.cpp,,,data/crawl/squid/old_hunk_2922.cpp,data/crawl/squid/new_hunk_2922.cpp,113,-1,"storeAppendPrintf(sentry, ""wall_time = %f\n"",
                      tvSubDsec(f->timestamp, current_time));",,"[""removeLog""]","[[""storeAppendPrintf"", ""sentry"", ""wall_time"", ""%f\\n"", ""tvSubDsec"", ""f"", ""timestamp"", ""current_time""], []]",[-7225499045681938401],6124,3332160.0,2
https://github.com/squid-cache/squid/commit/8822ebee4947bcf883d74aa79a26e896449d0c36,28 Oct 2010,"SMP Cache Manager, Phase2 implementation.

Cache Manager actions are forwarded to Coordinator. Coordinator iterates over
Kids, aggregating their stats if possible and/or allowing each kid to dump
non-aggregatable output directly into response if needed. Non-aggregated
output is wrapped in ""by kidN { ... } by kidN"" markup to ease auto-processing.

Regressions and small output formatting changes are probably unavoidable
because stats are aggregated and passed around as doubles instead of integers
(no more overflows though!) and because many stats collection and formatting
lines had to be touched. These are steps in the right direction though, IMO.


Old code both computed and dumped stats to Store at the same time. To avoid
computing code duplication, we now collect stats in primitive Stats objects
and then either dump those to Store or send them to Coordinator for
aggregation and, eventual Store dump. What stats to collect, when to
aggregate, and when to dump is decided by action-specific Mgr::Action classes.

The Cache Manager menu now consists of ActionProfile objects. ActionProfile
maintains hard-coded information about specific actions. It uses ActionCreator
member to create Action objects when a cache manager request is received.

Added Mgr::ActionParams class to maintain action parameters, including HTTP
request details necessary for Store entry creation (in another strand) and
action-specific parameters (currently just credentials). In Phase3, this class
can be extended to supply more parameters such as kid IDs to which the action
should apply.

Added Mgr::Command that combines hard-coded ActionProfile details with
user-specified ActionParams. This simplifies many interfaces because we no
longer need to supply a long list of parameters, covering various parts of
action config.


Moved Cache Manager registration to Mgr::RegisterAction() globals to reduce
dependency on the CacheManager class, which is a singleton anyway, and which
is unused by most of the registration callers.  On the other hand, without
this change, no legacy (function-based actions) code would have been changed!


Enhanced TypedMsgHdr class to simplify storing and loading non-POD classes.
The caller can now easily handle a non-POD class as a series of put/get calls,
one for each POD member. This was necessary to send Mgr::ActionParams to
Coordinator and back. Will probably be useful for sending other complex
structures as well.


Reconfigure, shutdown, and other ""basic"" actions have been moved to
src/mgr/BasicActions.cc. Mgr::RegisterBasics() registers them.


Most of the Cache Manager code is now in src/mgr/.


Many more polishing touches.


More polishing left for future projects: Move CacheManager to Mgr namespace
and src/mgr/ directory. Use SBuf instead of String for ActionParams and
TypedMsgHdr. Rename Ipc::TypedMsgHdr to Ipc::Msg, Ipc::SocketMsg, or similar
because it maintains more than just msghdr struct. More stats aggregation,
and Phase3 changes.",6354,data/crawl/squid/hunk_2921.cpp,,,data/crawl/squid/old_hunk_2921.cpp,data/crawl/squid/new_hunk_2921.cpp,14,-1,"storeAppendPrintf(sentry, ""client_http.hits = %f/sec\n"",
                      XAVG(client_http.hits));",,"[""removeLog""]","[[""storeAppendPrintf"", ""sentry"", ""client_http"", ""hits"", ""%f/sec\\n"", ""XAVG"", ""client_http"", ""hits""], []]",[-33372811212936453129],6123,3350160.0,2
https://github.com/squid-cache/squid/commit/8822ebee4947bcf883d74aa79a26e896449d0c36,28 Oct 2010,"SMP Cache Manager, Phase2 implementation.

Cache Manager actions are forwarded to Coordinator. Coordinator iterates over
Kids, aggregating their stats if possible and/or allowing each kid to dump
non-aggregatable output directly into response if needed. Non-aggregated
output is wrapped in ""by kidN { ... } by kidN"" markup to ease auto-processing.

Regressions and small output formatting changes are probably unavoidable
because stats are aggregated and passed around as doubles instead of integers
(no more overflows though!) and because many stats collection and formatting
lines had to be touched. These are steps in the right direction though, IMO.


Old code both computed and dumped stats to Store at the same time. To avoid
computing code duplication, we now collect stats in primitive Stats objects
and then either dump those to Store or send them to Coordinator for
aggregation and, eventual Store dump. What stats to collect, when to
aggregate, and when to dump is decided by action-specific Mgr::Action classes.

The Cache Manager menu now consists of ActionProfile objects. ActionProfile
maintains hard-coded information about specific actions. It uses ActionCreator
member to create Action objects when a cache manager request is received.

Added Mgr::ActionParams class to maintain action parameters, including HTTP
request details necessary for Store entry creation (in another strand) and
action-specific parameters (currently just credentials). In Phase3, this class
can be extended to supply more parameters such as kid IDs to which the action
should apply.

Added Mgr::Command that combines hard-coded ActionProfile details with
user-specified ActionParams. This simplifies many interfaces because we no
longer need to supply a long list of parameters, covering various parts of
action config.


Moved Cache Manager registration to Mgr::RegisterAction() globals to reduce
dependency on the CacheManager class, which is a singleton anyway, and which
is unused by most of the registration callers.  On the other hand, without
this change, no legacy (function-based actions) code would have been changed!


Enhanced TypedMsgHdr class to simplify storing and loading non-POD classes.
The caller can now easily handle a non-POD class as a series of put/get calls,
one for each POD member. This was necessary to send Mgr::ActionParams to
Coordinator and back. Will probably be useful for sending other complex
structures as well.


Reconfigure, shutdown, and other ""basic"" actions have been moved to
src/mgr/BasicActions.cc. Mgr::RegisterBasics() registers them.


Most of the Cache Manager code is now in src/mgr/.


Many more polishing touches.


More polishing left for future projects: Move CacheManager to Mgr namespace
and src/mgr/ directory. Use SBuf instead of String for ActionParams and
TypedMsgHdr. Rename Ipc::TypedMsgHdr to Ipc::Msg, Ipc::SocketMsg, or similar
because it maintains more than just msghdr struct. More stats aggregation,
and Phase3 changes.",6354,data/crawl/squid/hunk_2921.cpp,,,data/crawl/squid/old_hunk_2921.cpp,data/crawl/squid/new_hunk_2921.cpp,12,-1,"storeAppendPrintf(sentry, ""client_http.requests = %f/sec\n"",
                      XAVG(client_http.requests));",,"[""removeLog""]","[[""storeAppendPrintf"", ""sentry"", ""client_http"", ""requests"", ""%f/sec\\n"", ""XAVG"", ""client_http"", ""requests""], []]",[-18600112218715778105],6122,3350160.0,2
https://github.com/squid-cache/squid/commit/8822ebee4947bcf883d74aa79a26e896449d0c36,28 Oct 2010,"SMP Cache Manager, Phase2 implementation.

Cache Manager actions are forwarded to Coordinator. Coordinator iterates over
Kids, aggregating their stats if possible and/or allowing each kid to dump
non-aggregatable output directly into response if needed. Non-aggregated
output is wrapped in ""by kidN { ... } by kidN"" markup to ease auto-processing.

Regressions and small output formatting changes are probably unavoidable
because stats are aggregated and passed around as doubles instead of integers
(no more overflows though!) and because many stats collection and formatting
lines had to be touched. These are steps in the right direction though, IMO.


Old code both computed and dumped stats to Store at the same time. To avoid
computing code duplication, we now collect stats in primitive Stats objects
and then either dump those to Store or send them to Coordinator for
aggregation and, eventual Store dump. What stats to collect, when to
aggregate, and when to dump is decided by action-specific Mgr::Action classes.

The Cache Manager menu now consists of ActionProfile objects. ActionProfile
maintains hard-coded information about specific actions. It uses ActionCreator
member to create Action objects when a cache manager request is received.

Added Mgr::ActionParams class to maintain action parameters, including HTTP
request details necessary for Store entry creation (in another strand) and
action-specific parameters (currently just credentials). In Phase3, this class
can be extended to supply more parameters such as kid IDs to which the action
should apply.

Added Mgr::Command that combines hard-coded ActionProfile details with
user-specified ActionParams. This simplifies many interfaces because we no
longer need to supply a long list of parameters, covering various parts of
action config.


Moved Cache Manager registration to Mgr::RegisterAction() globals to reduce
dependency on the CacheManager class, which is a singleton anyway, and which
is unused by most of the registration callers.  On the other hand, without
this change, no legacy (function-based actions) code would have been changed!


Enhanced TypedMsgHdr class to simplify storing and loading non-POD classes.
The caller can now easily handle a non-POD class as a series of put/get calls,
one for each POD member. This was necessary to send Mgr::ActionParams to
Coordinator and back. Will probably be useful for sending other complex
structures as well.


Reconfigure, shutdown, and other ""basic"" actions have been moved to
src/mgr/BasicActions.cc. Mgr::RegisterBasics() registers them.


Most of the Cache Manager code is now in src/mgr/.


Many more polishing touches.


More polishing left for future projects: Move CacheManager to Mgr namespace
and src/mgr/ directory. Use SBuf instead of String for ActionParams and
TypedMsgHdr. Rename Ipc::TypedMsgHdr to Ipc::Msg, Ipc::SocketMsg, or similar
because it maintains more than just msghdr struct. More stats aggregation,
and Phase3 changes.",6354,data/crawl/squid/hunk_2919.cpp,,,data/crawl/squid/old_hunk_2919.cpp,data/crawl/squid/new_hunk_2919.cpp,55,54,"storeAppendPrintf(sentry, ""\t%6ld Hot Object Cache Items\n"",
                      (long)hot_obj_count);","storeAppendPrintf(sentry, ""\t%6.0f Hot Object Cache Items\n"",
                      stats.hot_obj_count);","[""removeVariable"", ""updateContent"", ""addVariable""]","[[""\\t%6ld"", ""long""], [""\\t%6"", ""0f"", ""stats""]]",[-2311981446863047312],6121,0.0,2
https://github.com/squid-cache/squid/commit/8822ebee4947bcf883d74aa79a26e896449d0c36,28 Oct 2010,"SMP Cache Manager, Phase2 implementation.

Cache Manager actions are forwarded to Coordinator. Coordinator iterates over
Kids, aggregating their stats if possible and/or allowing each kid to dump
non-aggregatable output directly into response if needed. Non-aggregated
output is wrapped in ""by kidN { ... } by kidN"" markup to ease auto-processing.

Regressions and small output formatting changes are probably unavoidable
because stats are aggregated and passed around as doubles instead of integers
(no more overflows though!) and because many stats collection and formatting
lines had to be touched. These are steps in the right direction though, IMO.


Old code both computed and dumped stats to Store at the same time. To avoid
computing code duplication, we now collect stats in primitive Stats objects
and then either dump those to Store or send them to Coordinator for
aggregation and, eventual Store dump. What stats to collect, when to
aggregate, and when to dump is decided by action-specific Mgr::Action classes.

The Cache Manager menu now consists of ActionProfile objects. ActionProfile
maintains hard-coded information about specific actions. It uses ActionCreator
member to create Action objects when a cache manager request is received.

Added Mgr::ActionParams class to maintain action parameters, including HTTP
request details necessary for Store entry creation (in another strand) and
action-specific parameters (currently just credentials). In Phase3, this class
can be extended to supply more parameters such as kid IDs to which the action
should apply.

Added Mgr::Command that combines hard-coded ActionProfile details with
user-specified ActionParams. This simplifies many interfaces because we no
longer need to supply a long list of parameters, covering various parts of
action config.


Moved Cache Manager registration to Mgr::RegisterAction() globals to reduce
dependency on the CacheManager class, which is a singleton anyway, and which
is unused by most of the registration callers.  On the other hand, without
this change, no legacy (function-based actions) code would have been changed!


Enhanced TypedMsgHdr class to simplify storing and loading non-POD classes.
The caller can now easily handle a non-POD class as a series of put/get calls,
one for each POD member. This was necessary to send Mgr::ActionParams to
Coordinator and back. Will probably be useful for sending other complex
structures as well.


Reconfigure, shutdown, and other ""basic"" actions have been moved to
src/mgr/BasicActions.cc. Mgr::RegisterBasics() registers them.


Most of the Cache Manager code is now in src/mgr/.


Many more polishing touches.


More polishing left for future projects: Move CacheManager to Mgr namespace
and src/mgr/ directory. Use SBuf instead of String for ActionParams and
TypedMsgHdr. Rename Ipc::TypedMsgHdr to Ipc::Msg, Ipc::SocketMsg, or similar
because it maintains more than just msghdr struct. More stats aggregation,
and Phase3 changes.",6354,data/crawl/squid/hunk_2910.cpp,,,data/crawl/squid/old_hunk_2910.cpp,data/crawl/squid/new_hunk_2910.cpp,-1,48,,"storeAppendPrintf(entry, ""} by kid%d\n\n"", KidIdentifier);","[""addLog""]","[[], [""storeAppendPrintf"", ""entry"", ""by"", ""kid%d\\n\\n"", ""KidIdentifier""]]",[-5031128074946964333],6120,0.0,2
https://github.com/squid-cache/squid/commit/8822ebee4947bcf883d74aa79a26e896449d0c36,28 Oct 2010,"SMP Cache Manager, Phase2 implementation.

Cache Manager actions are forwarded to Coordinator. Coordinator iterates over
Kids, aggregating their stats if possible and/or allowing each kid to dump
non-aggregatable output directly into response if needed. Non-aggregated
output is wrapped in ""by kidN { ... } by kidN"" markup to ease auto-processing.

Regressions and small output formatting changes are probably unavoidable
because stats are aggregated and passed around as doubles instead of integers
(no more overflows though!) and because many stats collection and formatting
lines had to be touched. These are steps in the right direction though, IMO.


Old code both computed and dumped stats to Store at the same time. To avoid
computing code duplication, we now collect stats in primitive Stats objects
and then either dump those to Store or send them to Coordinator for
aggregation and, eventual Store dump. What stats to collect, when to
aggregate, and when to dump is decided by action-specific Mgr::Action classes.

The Cache Manager menu now consists of ActionProfile objects. ActionProfile
maintains hard-coded information about specific actions. It uses ActionCreator
member to create Action objects when a cache manager request is received.

Added Mgr::ActionParams class to maintain action parameters, including HTTP
request details necessary for Store entry creation (in another strand) and
action-specific parameters (currently just credentials). In Phase3, this class
can be extended to supply more parameters such as kid IDs to which the action
should apply.

Added Mgr::Command that combines hard-coded ActionProfile details with
user-specified ActionParams. This simplifies many interfaces because we no
longer need to supply a long list of parameters, covering various parts of
action config.


Moved Cache Manager registration to Mgr::RegisterAction() globals to reduce
dependency on the CacheManager class, which is a singleton anyway, and which
is unused by most of the registration callers.  On the other hand, without
this change, no legacy (function-based actions) code would have been changed!


Enhanced TypedMsgHdr class to simplify storing and loading non-POD classes.
The caller can now easily handle a non-POD class as a series of put/get calls,
one for each POD member. This was necessary to send Mgr::ActionParams to
Coordinator and back. Will probably be useful for sending other complex
structures as well.


Reconfigure, shutdown, and other ""basic"" actions have been moved to
src/mgr/BasicActions.cc. Mgr::RegisterBasics() registers them.


Most of the Cache Manager code is now in src/mgr/.


Many more polishing touches.


More polishing left for future projects: Move CacheManager to Mgr namespace
and src/mgr/ directory. Use SBuf instead of String for ActionParams and
TypedMsgHdr. Rename Ipc::TypedMsgHdr to Ipc::Msg, Ipc::SocketMsg, or similar
because it maintains more than just msghdr struct. More stats aggregation,
and Phase3 changes.",6354,data/crawl/squid/hunk_2910.cpp,,,data/crawl/squid/old_hunk_2910.cpp,data/crawl/squid/new_hunk_2910.cpp,-1,45,,"storeAppendPrintf(entry, ""by kid%d {\n"", KidIdentifier);","[""addLog""]","[[], [""storeAppendPrintf"", ""entry"", ""by"", ""kid%d"", ""\\n"", ""KidIdentifier""]]",[-6840278166809764065],6119,0.0,2
https://github.com/squid-cache/squid/commit/8822ebee4947bcf883d74aa79a26e896449d0c36,28 Oct 2010,"SMP Cache Manager, Phase2 implementation.

Cache Manager actions are forwarded to Coordinator. Coordinator iterates over
Kids, aggregating their stats if possible and/or allowing each kid to dump
non-aggregatable output directly into response if needed. Non-aggregated
output is wrapped in ""by kidN { ... } by kidN"" markup to ease auto-processing.

Regressions and small output formatting changes are probably unavoidable
because stats are aggregated and passed around as doubles instead of integers
(no more overflows though!) and because many stats collection and formatting
lines had to be touched. These are steps in the right direction though, IMO.


Old code both computed and dumped stats to Store at the same time. To avoid
computing code duplication, we now collect stats in primitive Stats objects
and then either dump those to Store or send them to Coordinator for
aggregation and, eventual Store dump. What stats to collect, when to
aggregate, and when to dump is decided by action-specific Mgr::Action classes.

The Cache Manager menu now consists of ActionProfile objects. ActionProfile
maintains hard-coded information about specific actions. It uses ActionCreator
member to create Action objects when a cache manager request is received.

Added Mgr::ActionParams class to maintain action parameters, including HTTP
request details necessary for Store entry creation (in another strand) and
action-specific parameters (currently just credentials). In Phase3, this class
can be extended to supply more parameters such as kid IDs to which the action
should apply.

Added Mgr::Command that combines hard-coded ActionProfile details with
user-specified ActionParams. This simplifies many interfaces because we no
longer need to supply a long list of parameters, covering various parts of
action config.


Moved Cache Manager registration to Mgr::RegisterAction() globals to reduce
dependency on the CacheManager class, which is a singleton anyway, and which
is unused by most of the registration callers.  On the other hand, without
this change, no legacy (function-based actions) code would have been changed!


Enhanced TypedMsgHdr class to simplify storing and loading non-POD classes.
The caller can now easily handle a non-POD class as a series of put/get calls,
one for each POD member. This was necessary to send Mgr::ActionParams to
Coordinator and back. Will probably be useful for sending other complex
structures as well.


Reconfigure, shutdown, and other ""basic"" actions have been moved to
src/mgr/BasicActions.cc. Mgr::RegisterBasics() registers them.


Most of the Cache Manager code is now in src/mgr/.


Many more polishing touches.


More polishing left for future projects: Move CacheManager to Mgr namespace
and src/mgr/ directory. Use SBuf instead of String for ActionParams and
TypedMsgHdr. Rename Ipc::TypedMsgHdr to Ipc::Msg, Ipc::SocketMsg, or similar
because it maintains more than just msghdr struct. More stats aggregation,
and Phase3 changes.",6354,data/crawl/squid/hunk_2904.cpp,,,data/crawl/squid/old_hunk_2904.cpp,data/crawl/squid/new_hunk_2904.cpp,11,-1,"storeAppendPrintf(sentry, ""block_queue_len: %d\n"", diskd_stats.block_queue_len);",,"[""removeLog""]","[[""storeAppendPrintf"", ""sentry"", ""block_queue_len"", ""%d\\n"", ""diskd_stats"", ""block_queue_len""], []]",[5726905984326187091],6118,1911600.0,2
https://github.com/squid-cache/squid/commit/8822ebee4947bcf883d74aa79a26e896449d0c36,28 Oct 2010,"SMP Cache Manager, Phase2 implementation.

Cache Manager actions are forwarded to Coordinator. Coordinator iterates over
Kids, aggregating their stats if possible and/or allowing each kid to dump
non-aggregatable output directly into response if needed. Non-aggregated
output is wrapped in ""by kidN { ... } by kidN"" markup to ease auto-processing.

Regressions and small output formatting changes are probably unavoidable
because stats are aggregated and passed around as doubles instead of integers
(no more overflows though!) and because many stats collection and formatting
lines had to be touched. These are steps in the right direction though, IMO.


Old code both computed and dumped stats to Store at the same time. To avoid
computing code duplication, we now collect stats in primitive Stats objects
and then either dump those to Store or send them to Coordinator for
aggregation and, eventual Store dump. What stats to collect, when to
aggregate, and when to dump is decided by action-specific Mgr::Action classes.

The Cache Manager menu now consists of ActionProfile objects. ActionProfile
maintains hard-coded information about specific actions. It uses ActionCreator
member to create Action objects when a cache manager request is received.

Added Mgr::ActionParams class to maintain action parameters, including HTTP
request details necessary for Store entry creation (in another strand) and
action-specific parameters (currently just credentials). In Phase3, this class
can be extended to supply more parameters such as kid IDs to which the action
should apply.

Added Mgr::Command that combines hard-coded ActionProfile details with
user-specified ActionParams. This simplifies many interfaces because we no
longer need to supply a long list of parameters, covering various parts of
action config.


Moved Cache Manager registration to Mgr::RegisterAction() globals to reduce
dependency on the CacheManager class, which is a singleton anyway, and which
is unused by most of the registration callers.  On the other hand, without
this change, no legacy (function-based actions) code would have been changed!


Enhanced TypedMsgHdr class to simplify storing and loading non-POD classes.
The caller can now easily handle a non-POD class as a series of put/get calls,
one for each POD member. This was necessary to send Mgr::ActionParams to
Coordinator and back. Will probably be useful for sending other complex
structures as well.


Reconfigure, shutdown, and other ""basic"" actions have been moved to
src/mgr/BasicActions.cc. Mgr::RegisterBasics() registers them.


Most of the Cache Manager code is now in src/mgr/.


Many more polishing touches.


More polishing left for future projects: Move CacheManager to Mgr namespace
and src/mgr/ directory. Use SBuf instead of String for ActionParams and
TypedMsgHdr. Rename Ipc::TypedMsgHdr to Ipc::Msg, Ipc::SocketMsg, or similar
because it maintains more than just msghdr struct. More stats aggregation,
and Phase3 changes.",6354,data/crawl/squid/hunk_2904.cpp,,,data/crawl/squid/old_hunk_2904.cpp,data/crawl/squid/new_hunk_2904.cpp,10,-1,"storeAppendPrintf(sentry, ""open_fail_queue_len: %d\n"", diskd_stats.open_fail_queue_len);",,"[""removeLog""]","[[""storeAppendPrintf"", ""sentry"", ""open_fail_queue_len"", ""%d\\n"", ""diskd_stats"", ""open_fail_queue_len""], []]",[7111146043948283811],6117,1911600.0,2
https://github.com/squid-cache/squid/commit/8822ebee4947bcf883d74aa79a26e896449d0c36,28 Oct 2010,"SMP Cache Manager, Phase2 implementation.

Cache Manager actions are forwarded to Coordinator. Coordinator iterates over
Kids, aggregating their stats if possible and/or allowing each kid to dump
non-aggregatable output directly into response if needed. Non-aggregated
output is wrapped in ""by kidN { ... } by kidN"" markup to ease auto-processing.

Regressions and small output formatting changes are probably unavoidable
because stats are aggregated and passed around as doubles instead of integers
(no more overflows though!) and because many stats collection and formatting
lines had to be touched. These are steps in the right direction though, IMO.


Old code both computed and dumped stats to Store at the same time. To avoid
computing code duplication, we now collect stats in primitive Stats objects
and then either dump those to Store or send them to Coordinator for
aggregation and, eventual Store dump. What stats to collect, when to
aggregate, and when to dump is decided by action-specific Mgr::Action classes.

The Cache Manager menu now consists of ActionProfile objects. ActionProfile
maintains hard-coded information about specific actions. It uses ActionCreator
member to create Action objects when a cache manager request is received.

Added Mgr::ActionParams class to maintain action parameters, including HTTP
request details necessary for Store entry creation (in another strand) and
action-specific parameters (currently just credentials). In Phase3, this class
can be extended to supply more parameters such as kid IDs to which the action
should apply.

Added Mgr::Command that combines hard-coded ActionProfile details with
user-specified ActionParams. This simplifies many interfaces because we no
longer need to supply a long list of parameters, covering various parts of
action config.


Moved Cache Manager registration to Mgr::RegisterAction() globals to reduce
dependency on the CacheManager class, which is a singleton anyway, and which
is unused by most of the registration callers.  On the other hand, without
this change, no legacy (function-based actions) code would have been changed!


Enhanced TypedMsgHdr class to simplify storing and loading non-POD classes.
The caller can now easily handle a non-POD class as a series of put/get calls,
one for each POD member. This was necessary to send Mgr::ActionParams to
Coordinator and back. Will probably be useful for sending other complex
structures as well.


Reconfigure, shutdown, and other ""basic"" actions have been moved to
src/mgr/BasicActions.cc. Mgr::RegisterBasics() registers them.


Most of the Cache Manager code is now in src/mgr/.


Many more polishing touches.


More polishing left for future projects: Move CacheManager to Mgr namespace
and src/mgr/ directory. Use SBuf instead of String for ActionParams and
TypedMsgHdr. Rename Ipc::TypedMsgHdr to Ipc::Msg, Ipc::SocketMsg, or similar
because it maintains more than just msghdr struct. More stats aggregation,
and Phase3 changes.",6354,data/crawl/squid/hunk_2904.cpp,,,data/crawl/squid/old_hunk_2904.cpp,data/crawl/squid/new_hunk_2904.cpp,9,-1,"storeAppendPrintf(sentry, ""max_shmuse: %d\n"", diskd_stats.max_shmuse);",,"[""removeLog""]","[[""storeAppendPrintf"", ""sentry"", ""max_shmuse"", ""%d\\n"", ""diskd_stats"", ""max_shmuse""], []]",[-26632339423346660253],6116,1911600.0,2
https://github.com/squid-cache/squid/commit/8822ebee4947bcf883d74aa79a26e896449d0c36,28 Oct 2010,"SMP Cache Manager, Phase2 implementation.

Cache Manager actions are forwarded to Coordinator. Coordinator iterates over
Kids, aggregating their stats if possible and/or allowing each kid to dump
non-aggregatable output directly into response if needed. Non-aggregated
output is wrapped in ""by kidN { ... } by kidN"" markup to ease auto-processing.

Regressions and small output formatting changes are probably unavoidable
because stats are aggregated and passed around as doubles instead of integers
(no more overflows though!) and because many stats collection and formatting
lines had to be touched. These are steps in the right direction though, IMO.


Old code both computed and dumped stats to Store at the same time. To avoid
computing code duplication, we now collect stats in primitive Stats objects
and then either dump those to Store or send them to Coordinator for
aggregation and, eventual Store dump. What stats to collect, when to
aggregate, and when to dump is decided by action-specific Mgr::Action classes.

The Cache Manager menu now consists of ActionProfile objects. ActionProfile
maintains hard-coded information about specific actions. It uses ActionCreator
member to create Action objects when a cache manager request is received.

Added Mgr::ActionParams class to maintain action parameters, including HTTP
request details necessary for Store entry creation (in another strand) and
action-specific parameters (currently just credentials). In Phase3, this class
can be extended to supply more parameters such as kid IDs to which the action
should apply.

Added Mgr::Command that combines hard-coded ActionProfile details with
user-specified ActionParams. This simplifies many interfaces because we no
longer need to supply a long list of parameters, covering various parts of
action config.


Moved Cache Manager registration to Mgr::RegisterAction() globals to reduce
dependency on the CacheManager class, which is a singleton anyway, and which
is unused by most of the registration callers.  On the other hand, without
this change, no legacy (function-based actions) code would have been changed!


Enhanced TypedMsgHdr class to simplify storing and loading non-POD classes.
The caller can now easily handle a non-POD class as a series of put/get calls,
one for each POD member. This was necessary to send Mgr::ActionParams to
Coordinator and back. Will probably be useful for sending other complex
structures as well.


Reconfigure, shutdown, and other ""basic"" actions have been moved to
src/mgr/BasicActions.cc. Mgr::RegisterBasics() registers them.


Most of the Cache Manager code is now in src/mgr/.


Many more polishing touches.


More polishing left for future projects: Move CacheManager to Mgr namespace
and src/mgr/ directory. Use SBuf instead of String for ActionParams and
TypedMsgHdr. Rename Ipc::TypedMsgHdr to Ipc::Msg, Ipc::SocketMsg, or similar
because it maintains more than just msghdr struct. More stats aggregation,
and Phase3 changes.",6354,data/crawl/squid/hunk_2904.cpp,,,data/crawl/squid/old_hunk_2904.cpp,data/crawl/squid/new_hunk_2904.cpp,8,-1,"storeAppendPrintf(sentry, ""max_away: %d\n"", diskd_stats.max_away);",,"[""removeLog""]","[[""storeAppendPrintf"", ""sentry"", ""max_away"", ""%d\\n"", ""diskd_stats"", ""max_away""], []]",[-22948254924291130043],6115,1911600.0,2
https://github.com/squid-cache/squid/commit/8822ebee4947bcf883d74aa79a26e896449d0c36,28 Oct 2010,"SMP Cache Manager, Phase2 implementation.

Cache Manager actions are forwarded to Coordinator. Coordinator iterates over
Kids, aggregating their stats if possible and/or allowing each kid to dump
non-aggregatable output directly into response if needed. Non-aggregated
output is wrapped in ""by kidN { ... } by kidN"" markup to ease auto-processing.

Regressions and small output formatting changes are probably unavoidable
because stats are aggregated and passed around as doubles instead of integers
(no more overflows though!) and because many stats collection and formatting
lines had to be touched. These are steps in the right direction though, IMO.


Old code both computed and dumped stats to Store at the same time. To avoid
computing code duplication, we now collect stats in primitive Stats objects
and then either dump those to Store or send them to Coordinator for
aggregation and, eventual Store dump. What stats to collect, when to
aggregate, and when to dump is decided by action-specific Mgr::Action classes.

The Cache Manager menu now consists of ActionProfile objects. ActionProfile
maintains hard-coded information about specific actions. It uses ActionCreator
member to create Action objects when a cache manager request is received.

Added Mgr::ActionParams class to maintain action parameters, including HTTP
request details necessary for Store entry creation (in another strand) and
action-specific parameters (currently just credentials). In Phase3, this class
can be extended to supply more parameters such as kid IDs to which the action
should apply.

Added Mgr::Command that combines hard-coded ActionProfile details with
user-specified ActionParams. This simplifies many interfaces because we no
longer need to supply a long list of parameters, covering various parts of
action config.


Moved Cache Manager registration to Mgr::RegisterAction() globals to reduce
dependency on the CacheManager class, which is a singleton anyway, and which
is unused by most of the registration callers.  On the other hand, without
this change, no legacy (function-based actions) code would have been changed!


Enhanced TypedMsgHdr class to simplify storing and loading non-POD classes.
The caller can now easily handle a non-POD class as a series of put/get calls,
one for each POD member. This was necessary to send Mgr::ActionParams to
Coordinator and back. Will probably be useful for sending other complex
structures as well.


Reconfigure, shutdown, and other ""basic"" actions have been moved to
src/mgr/BasicActions.cc. Mgr::RegisterBasics() registers them.


Most of the Cache Manager code is now in src/mgr/.


Many more polishing touches.


More polishing left for future projects: Move CacheManager to Mgr namespace
and src/mgr/ directory. Use SBuf instead of String for ActionParams and
TypedMsgHdr. Rename Ipc::TypedMsgHdr to Ipc::Msg, Ipc::SocketMsg, or similar
because it maintains more than just msghdr struct. More stats aggregation,
and Phase3 changes.",6354,data/crawl/squid/hunk_2904.cpp,,,data/crawl/squid/old_hunk_2904.cpp,data/crawl/squid/new_hunk_2904.cpp,7,-1,"storeAppendPrintf(sentry, ""recv_count: %d\n"", diskd_stats.recv_count);",,"[""removeLog""]","[[""storeAppendPrintf"", ""sentry"", ""recv_count"", ""%d\\n"", ""diskd_stats"", ""recv_count""], []]",[-14633075712997139321],6114,1911600.0,2
https://github.com/squid-cache/squid/commit/8822ebee4947bcf883d74aa79a26e896449d0c36,28 Oct 2010,"SMP Cache Manager, Phase2 implementation.

Cache Manager actions are forwarded to Coordinator. Coordinator iterates over
Kids, aggregating their stats if possible and/or allowing each kid to dump
non-aggregatable output directly into response if needed. Non-aggregated
output is wrapped in ""by kidN { ... } by kidN"" markup to ease auto-processing.

Regressions and small output formatting changes are probably unavoidable
because stats are aggregated and passed around as doubles instead of integers
(no more overflows though!) and because many stats collection and formatting
lines had to be touched. These are steps in the right direction though, IMO.


Old code both computed and dumped stats to Store at the same time. To avoid
computing code duplication, we now collect stats in primitive Stats objects
and then either dump those to Store or send them to Coordinator for
aggregation and, eventual Store dump. What stats to collect, when to
aggregate, and when to dump is decided by action-specific Mgr::Action classes.

The Cache Manager menu now consists of ActionProfile objects. ActionProfile
maintains hard-coded information about specific actions. It uses ActionCreator
member to create Action objects when a cache manager request is received.

Added Mgr::ActionParams class to maintain action parameters, including HTTP
request details necessary for Store entry creation (in another strand) and
action-specific parameters (currently just credentials). In Phase3, this class
can be extended to supply more parameters such as kid IDs to which the action
should apply.

Added Mgr::Command that combines hard-coded ActionProfile details with
user-specified ActionParams. This simplifies many interfaces because we no
longer need to supply a long list of parameters, covering various parts of
action config.


Moved Cache Manager registration to Mgr::RegisterAction() globals to reduce
dependency on the CacheManager class, which is a singleton anyway, and which
is unused by most of the registration callers.  On the other hand, without
this change, no legacy (function-based actions) code would have been changed!


Enhanced TypedMsgHdr class to simplify storing and loading non-POD classes.
The caller can now easily handle a non-POD class as a series of put/get calls,
one for each POD member. This was necessary to send Mgr::ActionParams to
Coordinator and back. Will probably be useful for sending other complex
structures as well.


Reconfigure, shutdown, and other ""basic"" actions have been moved to
src/mgr/BasicActions.cc. Mgr::RegisterBasics() registers them.


Most of the Cache Manager code is now in src/mgr/.


Many more polishing touches.


More polishing left for future projects: Move CacheManager to Mgr namespace
and src/mgr/ directory. Use SBuf instead of String for ActionParams and
TypedMsgHdr. Rename Ipc::TypedMsgHdr to Ipc::Msg, Ipc::SocketMsg, or similar
because it maintains more than just msghdr struct. More stats aggregation,
and Phase3 changes.",6354,data/crawl/squid/hunk_2904.cpp,,,data/crawl/squid/old_hunk_2904.cpp,data/crawl/squid/new_hunk_2904.cpp,6,-1,"storeAppendPrintf(sentry, ""sent_count: %d\n"", diskd_stats.sent_count);",,"[""removeLog""]","[[""storeAppendPrintf"", ""sentry"", ""sent_count"", ""%d\\n"", ""diskd_stats"", ""sent_count""], []]",[4828664847466580635],6113,1911600.0,2
https://github.com/squid-cache/squid/commit/25f983407b3c3df95d9f81edf1bd917316f2dfda,01 Nov 2010,"Bug 3038: Detatch libmisc from libcompat

* Migrates many of the remaining libmisc portability wrappers into
  libcompat.

* Splits libmisc into:
   libprofiler - Squid internal profiler (developer-only)
   libmiscencoding - Various binary encoding / crypto algorithms
   libmisccontainers - Various data container algorithms

* Makes all binaries which need to link the libmisc* pieces directly instead
  of via $(COMPAT_LIB) which now only links the libcompat and internal
  profiler due to profiling being used on some libcompat functions.

* Adds a stub_debug for binaries needing the Debug.h API without squid
  timers and globals.

Some effort has been made to identify binaries whose dependencies can be
reduced. More of this dependency removal can be done in future.",2111,data/crawl/squid/hunk_2899.cpp,,,data/crawl/squid/old_hunk_2899.cpp,data/crawl/squid/new_hunk_2899.cpp,258,-1,"fprintf(stderr, ""xstrdup: tried to dup a NULL pointer!\n"");",,"[""removeLog""]","[[""fprintf"", ""stderr"", ""xstrdup"", ""tried"", ""to"", ""dup"", ""a"", ""NULL"", ""pointer"", ""\\n""], []]",[19651270150576097542],6112,20160.0,2
https://github.com/squid-cache/squid/commit/25f983407b3c3df95d9f81edf1bd917316f2dfda,01 Nov 2010,"Bug 3038: Detatch libmisc from libcompat

* Migrates many of the remaining libmisc portability wrappers into
  libcompat.

* Splits libmisc into:
   libprofiler - Squid internal profiler (developer-only)
   libmiscencoding - Various binary encoding / crypto algorithms
   libmisccontainers - Various data container algorithms

* Makes all binaries which need to link the libmisc* pieces directly instead
  of via $(COMPAT_LIB) which now only links the libcompat and internal
  profiler due to profiling being used on some libcompat functions.

* Adds a stub_debug for binaries needing the Debug.h API without squid
  timers and globals.

Some effort has been made to identify binaries whose dependencies can be
reduced. More of this dependency removal can be done in future.",2111,data/crawl/squid/hunk_2897.cpp,,,data/crawl/squid/old_hunk_2897.cpp,data/crawl/squid/new_hunk_2897.cpp,-1,189,,"fprintf(tracefp, ""r:%p:%p:%d\n"", p, s, sz);","[""addLog""]","[[], [""fprintf"", ""tracefp"", ""r"", ""%p"", ""%p"", ""%d\\n"", ""p"", ""s"", ""sz""]]",[-4161047314464603172],6111,3333600.0,2
https://github.com/squid-cache/squid/commit/df1b20e405c3c5bd0e8de9b58a683f599d6a62da,19 Nov 2010,Fix cachemgr http_port config report hiding options,45,data/crawl/squid/hunk_2891.cpp,,,data/crawl/squid/old_hunk_2891.cpp,data/crawl/squid/new_hunk_2891.cpp,-1,31,,"storeAppendPrintf(e, "" ignore-cc"");","[""addLog""]","[[], [""storeAppendPrintf"", ""e"", ""ignore"", ""cc""]]",[13247397465283335035],6110,0.0,2
https://github.com/squid-cache/squid/commit/2ded5176931a7d1f472a39c200747a1f26480f27,21 Nov 2010,"failure_notify is C++-only

The global function failure_notify is tightly type dependent.

This makes sure all code which uses it is C++ and wraps it away from any
situations where the symbol may be re-defined with a C definition.

As a side-effect the malloc tracing code is shuffled into its own file.",813,data/crawl/squid/hunk_2889.cpp,,,data/crawl/squid/old_hunk_2889.cpp,data/crawl/squid/new_hunk_2889.cpp,-1,419,,"fprintf(stderr, ""No memory leaks detected\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""No"", ""memory"", ""leaks"", ""detected\\n""]]",[-9734286523197740853],6109,3357360.0,2
https://github.com/squid-cache/squid/commit/2ded5176931a7d1f472a39c200747a1f26480f27,21 Nov 2010,"failure_notify is C++-only

The global function failure_notify is tightly type dependent.

This makes sure all code which uses it is C++ and wraps it away from any
situations where the symbol may be re-defined with a C definition.

As a side-effect the malloc tracing code is shuffled into its own file.",813,data/crawl/squid/hunk_2889.cpp,,,data/crawl/squid/old_hunk_2889.cpp,data/crawl/squid/new_hunk_2889.cpp,-1,417,,"fprintf(stderr, ""Total leaked memory: %d\n"", leak_sum);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""Total"", ""leaked"", ""memory"", ""%d\\n"", ""leak_sum""]]",[1090480920425176742],6108,3357360.0,2
https://github.com/squid-cache/squid/commit/2ded5176931a7d1f472a39c200747a1f26480f27,21 Nov 2010,"failure_notify is C++-only

The global function failure_notify is tightly type dependent.

This makes sure all code which uses it is C++ and wraps it away from any
situations where the symbol may be re-defined with a C definition.

As a side-effect the malloc tracing code is shuffled into its own file.",813,data/crawl/squid/hunk_2889.cpp,,,data/crawl/squid/old_hunk_2889.cpp,data/crawl/squid/new_hunk_2889.cpp,-1,408,,"fprintf(stderr, "":%d"", malloc_line[B][I]);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""%d"", ""malloc_line[B][I]""]]",[-20829002662514788700],6107,3357360.0,2
https://github.com/squid-cache/squid/commit/2ded5176931a7d1f472a39c200747a1f26480f27,21 Nov 2010,"failure_notify is C++-only

The global function failure_notify is tightly type dependent.

This makes sure all code which uses it is C++ and wraps it away from any
situations where the symbol may be re-defined with a C definition.

As a side-effect the malloc tracing code is shuffled into its own file.",813,data/crawl/squid/hunk_2889.cpp,,,data/crawl/squid/old_hunk_2889.cpp,data/crawl/squid/new_hunk_2889.cpp,-1,407,,"fprintf(stderr, "" %s"", malloc_file[B][I]);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""%s"", ""malloc_file[B][I]""]]",[-14996614139783100611],6106,3357360.0,2
https://github.com/squid-cache/squid/commit/2ded5176931a7d1f472a39c200747a1f26480f27,21 Nov 2010,"failure_notify is C++-only

The global function failure_notify is tightly type dependent.

This makes sure all code which uses it is C++ and wraps it away from any
situations where the symbol may be re-defined with a C definition.

As a side-effect the malloc tracing code is shuffled into its own file.",813,data/crawl/squid/hunk_2889.cpp,,,data/crawl/squid/old_hunk_2889.cpp,data/crawl/squid/new_hunk_2889.cpp,-1,406,,"fprintf(stderr, ""Leak found: %p"", malloc_ptrs[B][I]);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""Leak"", ""found"", ""%p"", ""malloc_ptrs[B][I]""]]",[-2325989577404035541],6105,3357360.0,2
https://github.com/squid-cache/squid/commit/2ded5176931a7d1f472a39c200747a1f26480f27,21 Nov 2010,"failure_notify is C++-only

The global function failure_notify is tightly type dependent.

This makes sure all code which uses it is C++ and wraps it away from any
situations where the symbol may be re-defined with a C definition.

As a side-effect the malloc tracing code is shuffled into its own file.",813,data/crawl/squid/hunk_2889.cpp,,,data/crawl/squid/old_hunk_2889.cpp,data/crawl/squid/new_hunk_2889.cpp,-1,399,,"fprintf(stderr, ""----- Memory map ----\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""Memory"", ""map"", ""\\n""]]",[-591730028667204742],6104,3357360.0,2
https://github.com/squid-cache/squid/commit/2ded5176931a7d1f472a39c200747a1f26480f27,21 Nov 2010,"failure_notify is C++-only

The global function failure_notify is tightly type dependent.

This makes sure all code which uses it is C++ and wraps it away from any
situations where the symbol may be re-defined with a C definition.

As a side-effect the malloc tracing code is shuffled into its own file.",813,data/crawl/squid/hunk_2889.cpp,,,data/crawl/squid/old_hunk_2889.cpp,data/crawl/squid/new_hunk_2889.cpp,-1,376,,"fprintf(stderr, ""%*s%p %s:%d size %d allocation %d ... (%d)\n"",
                                depth * 2, """",
                                malloc_ptrs[B][I], malloc_file[B][I],
                                malloc_line[B][I], malloc_size[B][I],
                                malloc_count[B][I], malloc_refs[B][I]);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""%*s%p"", ""%s"", ""%d"", ""size"", ""%d"", ""allocation"", ""%d"", ""%d"", ""\\n"", ""depth"", ""*"", ""2"", ""malloc_ptrs[B][I]"", ""malloc_file[B][I]"", ""malloc_line[B][I]"", ""malloc_size[B][I]"", ""malloc_count[B][I]"", ""malloc_refs[B][I]""]]",[-30585478959801514631],6103,3354480.0,2
https://github.com/squid-cache/squid/commit/2ded5176931a7d1f472a39c200747a1f26480f27,21 Nov 2010,"failure_notify is C++-only

The global function failure_notify is tightly type dependent.

This makes sure all code which uses it is C++ and wraps it away from any
situations where the symbol may be re-defined with a C definition.

As a side-effect the malloc tracing code is shuffled into its own file.",813,data/crawl/squid/hunk_2889.cpp,,,data/crawl/squid/old_hunk_2889.cpp,data/crawl/squid/new_hunk_2889.cpp,-1,367,,"fprintf(stderr, ""=== %d bytes\n"", sum);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""%d"", ""bytes\\n"", ""sum""]]",[-14207206390608598951],6102,3354480.0,2
https://github.com/squid-cache/squid/commit/2ded5176931a7d1f472a39c200747a1f26480f27,21 Nov 2010,"failure_notify is C++-only

The global function failure_notify is tightly type dependent.

This makes sure all code which uses it is C++ and wraps it away from any
situations where the symbol may be re-defined with a C definition.

As a side-effect the malloc tracing code is shuffled into its own file.",813,data/crawl/squid/hunk_2889.cpp,,,data/crawl/squid/old_hunk_2889.cpp,data/crawl/squid/new_hunk_2889.cpp,-1,357,,"fprintf(stderr, ""%*s%p %s:%d size %d allocation %d\n"",
                                depth, """",
                                malloc_ptrs[B][I], malloc_file[B][I],
                                malloc_line[B][I], malloc_size[B][I],
                                malloc_count[B][I]);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""%*s%p"", ""%s"", ""%d"", ""size"", ""%d"", ""allocation"", ""%d\\n"", ""depth"", ""malloc_ptrs[B][I]"", ""malloc_file[B][I]"", ""malloc_line[B][I]"", ""malloc_size[B][I]"", ""malloc_count[B][I]""]]",[-28946520347337305743],6101,3354480.0,2
https://github.com/squid-cache/squid/commit/2ded5176931a7d1f472a39c200747a1f26480f27,21 Nov 2010,"failure_notify is C++-only

The global function failure_notify is tightly type dependent.

This makes sure all code which uses it is C++ and wraps it away from any
situations where the symbol may be re-defined with a C definition.

As a side-effect the malloc tracing code is shuffled into its own file.",813,data/crawl/squid/hunk_2889.cpp,,,data/crawl/squid/old_hunk_2889.cpp,data/crawl/squid/new_hunk_2889.cpp,-1,329,,"fprintf(stderr, "" %d\n"", xmalloc_count);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""%d\\n"", ""xmalloc_count""]]",[-9382290775761783620],6100,3363120.0,2
https://github.com/squid-cache/squid/commit/2ded5176931a7d1f472a39c200747a1f26480f27,21 Nov 2010,"failure_notify is C++-only

The global function failure_notify is tightly type dependent.

This makes sure all code which uses it is C++ and wraps it away from any
situations where the symbol may be re-defined with a C definition.

As a side-effect the malloc tracing code is shuffled into its own file.",813,data/crawl/squid/hunk_2889.cpp,,,data/crawl/squid/old_hunk_2889.cpp,data/crawl/squid/new_hunk_2889.cpp,-1,327,,"fprintf(stderr, "" (%d %s:%d)\n"", malloc_number(p), malloc_file_name(p), malloc_line_number(p));","[""addLog""]","[[], [""fprintf"", ""stderr"", ""%d"", ""%s"", ""%d"", ""\\n"", ""malloc_number"", ""p"", ""malloc_file_name"", ""p"", ""malloc_line_number"", ""p""]]",[-14674548379399223140],6099,3363120.0,2
https://github.com/squid-cache/squid/commit/20efa1c285cf589c5e289fd4f07bf41ef3564fd6,12 Dec 2010,"SourceLayout: cleanup the various log line formatting code

Adds:

* namespace Log::Format for log display functionality. Each line formater
  is a global function inside here. The log format enum is also in here
  along with the display encoding 'gadget' functions.

* namespace Time in SquidTime.h for the related time string display
  functions. Unified the various log pretty-print httpd-style time 
  functions into Time::FormatHttpd(time_t).
 ** care has been taken to preserve the local-static optimization found
    in accessLogTime() to prevent wasted cycles re-printing the same 
    time value more than once per second.

NP: the similar but timezone-missing format is now Time::FormatStrf()
    with the same optimization applied to speed up its callers.

* namespace Math:: to avoid symbol clash with global function Log() and
  namespace Log.

* support for the Apache ""combined"" log format. Was documented earlier as
  being available but not actually present.


Obsoletes:

* forward_log directive and associated experimental code. If needed
  we can easily add another special format to dump the details.
  FWIW they are all available in the squid format anyway (timestamp,
  squid status, source peer). The documented action of dumping every 
  forwarding attempt was not working.

* referer_log and useragent_log directives and matching ./configure options.
 ** shuffled into access_log formats ""referrer"" and ""useragent"" for more
    flexibility with less directives.

* emulate_httpd_log replaced with Apache ""common"" format.

* the ""auto"" pseudo-format becomes obsolete with emulat_httpd_log.
  default is now ""squid"" format in all situations.


Code Shuffles:

* moved the logformat directive parsing into LogConfig object methods.

* shuffled the logformat parsing and token code into src/log/Tokens.h|cc
 ** this is purely to break it out of access_log.cc. namespace and scoping
    needs some work.",5091,data/crawl/squid/hunk_2860.cpp,,,data/crawl/squid/old_hunk_2860.cpp,data/crawl/squid/new_hunk_2860.cpp,1859,-1,"logfilePrintf(logfile, "" [%s] [%s]\n"", ereq, erep);",,"[""removeLog""]","[[""logfilePrintf"", ""logfile"", ""[%s]"", ""[%s]\\n"", ""ereq"", ""erep""], []]",[-2243749579326389688],6098,1104480.0,2
https://github.com/squid-cache/squid/commit/20efa1c285cf589c5e289fd4f07bf41ef3564fd6,12 Dec 2010,"SourceLayout: cleanup the various log line formatting code

Adds:

* namespace Log::Format for log display functionality. Each line formater
  is a global function inside here. The log format enum is also in here
  along with the display encoding 'gadget' functions.

* namespace Time in SquidTime.h for the related time string display
  functions. Unified the various log pretty-print httpd-style time 
  functions into Time::FormatHttpd(time_t).
 ** care has been taken to preserve the local-static optimization found
    in accessLogTime() to prevent wasted cycles re-printing the same 
    time value more than once per second.

NP: the similar but timezone-missing format is now Time::FormatStrf()
    with the same optimization applied to speed up its callers.

* namespace Math:: to avoid symbol clash with global function Log() and
  namespace Log.

* support for the Apache ""combined"" log format. Was documented earlier as
  being available but not actually present.


Obsoletes:

* forward_log directive and associated experimental code. If needed
  we can easily add another special format to dump the details.
  FWIW they are all available in the squid format anyway (timestamp,
  squid status, source peer). The documented action of dumping every 
  forwarding attempt was not working.

* referer_log and useragent_log directives and matching ./configure options.
 ** shuffled into access_log formats ""referrer"" and ""useragent"" for more
    flexibility with less directives.

* emulate_httpd_log replaced with Apache ""common"" format.

* the ""auto"" pseudo-format becomes obsolete with emulat_httpd_log.
  default is now ""squid"" format in all situations.


Code Shuffles:

* moved the logformat directive parsing into LogConfig object methods.

* shuffled the logformat parsing and token code into src/log/Tokens.h|cc
 ** this is purely to break it out of access_log.cc. namespace and scoping
    needs some work.",5091,data/crawl/squid/hunk_2859.cpp,,,data/crawl/squid/old_hunk_2859.cpp,data/crawl/squid/new_hunk_2859.cpp,-1,497,,"storeAppendPrintf(entry, ""logformat %s "", format->name);","[""addLog""]","[[], [""storeAppendPrintf"", ""entry"", ""logformat"", ""%s"", ""format"", ""name""]]",[535866354762710868],6097,1954800.0,2
https://github.com/squid-cache/squid/commit/20efa1c285cf589c5e289fd4f07bf41ef3564fd6,12 Dec 2010,"SourceLayout: cleanup the various log line formatting code

Adds:

* namespace Log::Format for log display functionality. Each line formater
  is a global function inside here. The log format enum is also in here
  along with the display encoding 'gadget' functions.

* namespace Time in SquidTime.h for the related time string display
  functions. Unified the various log pretty-print httpd-style time 
  functions into Time::FormatHttpd(time_t).
 ** care has been taken to preserve the local-static optimization found
    in accessLogTime() to prevent wasted cycles re-printing the same 
    time value more than once per second.

NP: the similar but timezone-missing format is now Time::FormatStrf()
    with the same optimization applied to speed up its callers.

* namespace Math:: to avoid symbol clash with global function Log() and
  namespace Log.

* support for the Apache ""combined"" log format. Was documented earlier as
  being available but not actually present.


Obsoletes:

* forward_log directive and associated experimental code. If needed
  we can easily add another special format to dump the details.
  FWIW they are all available in the squid format anyway (timestamp,
  squid status, source peer). The documented action of dumping every 
  forwarding attempt was not working.

* referer_log and useragent_log directives and matching ./configure options.
 ** shuffled into access_log formats ""referrer"" and ""useragent"" for more
    flexibility with less directives.

* emulate_httpd_log replaced with Apache ""common"" format.

* the ""auto"" pseudo-format becomes obsolete with emulat_httpd_log.
  default is now ""squid"" format in all situations.


Code Shuffles:

* moved the logformat directive parsing into LogConfig object methods.

* shuffled the logformat parsing and token code into src/log/Tokens.h|cc
 ** this is purely to break it out of access_log.cc. namespace and scoping
    needs some work.",5091,data/crawl/squid/hunk_2854.cpp,,,data/crawl/squid/old_hunk_2854.cpp,data/crawl/squid/new_hunk_2854.cpp,-1,815,,"logfilePrintf(logfile, ""%s\n"", mb.buf);","[""addLog""]","[[], [""logfilePrintf"", ""logfile"", ""%s\\n"", ""mb"", ""buf""]]",[9532949238227755944],6096,1954800.0,2
https://github.com/squid-cache/squid/commit/4d16918eadf2b696b160599b3a013310da420ea7,13 Dec 2010,"Report ERR_SECURE_CONNECT_FAIL details to the user via a new error detail API.

Currently, the ERR_SECURE_CONNECT_FAIL response contains no usable error
information. Moreover, there is no interface to pass SSL error information
to the response generation code.

This patch adds an interface to allow Squid error responses to contain detailed
information about SSL certificate verification failure. For example, the error
message may contain the following text:
 ""Server Certificate Verification Failed: Certificate Common Name
  (www.lufthansa.com) does not match the host name you are connecting to
  (www.lufthansa.de).""

This is a Measurement Factory project.

Change details:
--------------------

- errorpage.cc/.h: The error page now supports the '%D'  formating code to 
  display the detail string passed by modules. The detail strings passed by 
  modules can contain error page formating codes. Currently only SSL detail
  errors messages are supported.

- A new class Ssl::ErrorDetail defined in ssl/ErrorDetail.[cc,h]
  The Ssl::ErrorDetail objects passed to the SSL verification callback functions
  (sl_verify_cb callback function defined in support.cc) and filled with error
  detail data (error_no and a pointer to the X509 Certificate) in the case of
  an error and passed back to the forward.cc code.

- The Ssl::ErrorDetail class internally uses (hard coded) templates and 
  formating codes to allow supporting multiple languages and adding easily
   new features

Other changes:
-------------------

- errorpage.cc/.h: The BuildContent method split to BuildContent and ConvertText
  method. The second method does the real conversion from a given text template
  to output. It is used now to allow formating the detail strings passed with 
  %D.

 - sslparseErrorString moved to ssl/ErrorDetail.cc file and renamed to 
   Ssl::parseErrorString

 - sslFindErrorString moved to ssl/ErrorDetail.cc file and renamed to 
   Ssl::getErrorName

 - The ssl_error_t typedef definition moved from ssl/support.h to 
   ssl/ErrorDetail.h and renamed to Ssl::error_t",652,data/crawl/squid/hunk_2845.cpp,,,data/crawl/squid/old_hunk_2845.cpp,data/crawl/squid/new_hunk_2845.cpp,-1,56,,"fatalf(""Unknown SSL error name '%s'"", name);","[""addLog""]","[[], [""fatalf"", ""Unknown"", ""SSL"", ""error"", ""name"", ""%s"", ""name""]]",[1636788338292482163],6095,745200.0,2
https://github.com/squid-cache/squid/commit/4d16918eadf2b696b160599b3a013310da420ea7,13 Dec 2010,"Report ERR_SECURE_CONNECT_FAIL details to the user via a new error detail API.

Currently, the ERR_SECURE_CONNECT_FAIL response contains no usable error
information. Moreover, there is no interface to pass SSL error information
to the response generation code.

This patch adds an interface to allow Squid error responses to contain detailed
information about SSL certificate verification failure. For example, the error
message may contain the following text:
 ""Server Certificate Verification Failed: Certificate Common Name
  (www.lufthansa.com) does not match the host name you are connecting to
  (www.lufthansa.de).""

This is a Measurement Factory project.

Change details:
--------------------

- errorpage.cc/.h: The error page now supports the '%D'  formating code to 
  display the detail string passed by modules. The detail strings passed by 
  modules can contain error page formating codes. Currently only SSL detail
  errors messages are supported.

- A new class Ssl::ErrorDetail defined in ssl/ErrorDetail.[cc,h]
  The Ssl::ErrorDetail objects passed to the SSL verification callback functions
  (sl_verify_cb callback function defined in support.cc) and filled with error
  detail data (error_no and a pointer to the X509 Certificate) in the case of
  an error and passed back to the forward.cc code.

- The Ssl::ErrorDetail class internally uses (hard coded) templates and 
  formating codes to allow supporting multiple languages and adding easily
   new features

Other changes:
-------------------

- errorpage.cc/.h: The BuildContent method split to BuildContent and ConvertText
  method. The second method does the real conversion from a given text template
  to output. It is used now to allow formating the detail strings passed with 
  %D.

 - sslparseErrorString moved to ssl/ErrorDetail.cc file and renamed to 
   Ssl::parseErrorString

 - sslFindErrorString moved to ssl/ErrorDetail.cc file and renamed to 
   Ssl::getErrorName

 - The ssl_error_t typedef definition moved from ssl/support.h to 
   ssl/ErrorDetail.h and renamed to Ssl::error_t",652,data/crawl/squid/hunk_2845.cpp,,,data/crawl/squid/old_hunk_2845.cpp,data/crawl/squid/new_hunk_2845.cpp,-1,53,,"fatalf(""Too small or too bug SSL error code '%s'"", name);","[""addLog""]","[[], [""fatalf"", ""Too"", ""small"", ""or"", ""too"", ""bug"", ""SSL"", ""error"", ""code"", ""%s"", ""name""]]",[4095456431433332772],6094,745200.0,2
https://github.com/squid-cache/squid/commit/f5eef98cd5550fbd9887b1fd72e8a1be2ddefc5a,30 Jan 2011,Shared Rock::DirMap version 1.,396,data/crawl/squid/hunk_2784.cpp,,,data/crawl/squid/old_hunk_2784.cpp,data/crawl/squid/new_hunk_2784.cpp,-1,62,,"fatal(""SharedMemory::open failed"");","[""addLog""]","[[], [""fatal"", ""SharedMemory"", ""open"", ""failed""]]",[-10009450357715478938],6093,0.0,2
https://github.com/squid-cache/squid/commit/f5eef98cd5550fbd9887b1fd72e8a1be2ddefc5a,30 Jan 2011,Shared Rock::DirMap version 1.,396,data/crawl/squid/hunk_2784.cpp,,,data/crawl/squid/old_hunk_2784.cpp,data/crawl/squid/new_hunk_2784.cpp,-1,41,,"fatal(""SharedMemory::create failed"");","[""addLog""]","[[], [""fatal"", ""SharedMemory"", ""create"", ""failed""]]",[-16736236320945463180],6092,0.0,2
https://github.com/squid-cache/squid/commit/f1eaa2540453dccde688d900e75f900c67f0dd7e,31 Jan 2011,Shared Rock::DirMap version 5.,283,data/crawl/squid/hunk_2782.cpp,,,data/crawl/squid/old_hunk_2782.cpp,data/crawl/squid/new_hunk_2782.cpp,3,5,"fatal(""SharedMemory::open failed"");",fatal(s.termedBuf());,"[""removeContent"", ""addVariable""]","[[""SharedMemory"", ""open"", ""failed""], [""s"", ""termedBuf""]]",[12000794453090522836],6091,0.0,2
https://github.com/squid-cache/squid/commit/95be26ed834fa89ac6da8e0e85559614e846364c,01 Feb 2011,"Removed ""multiple of page size"" restriction on cache_dir rock max-size.

The restriction came from mmap writing days and was meant to prevent forcing
mmap to read and merge the unchanged tail of a page we were updating.",9,data/crawl/squid/hunk_2776.cpp,,,data/crawl/squid/old_hunk_2776.cpp,data/crawl/squid/new_hunk_2776.cpp,10,-1,"fatal(""Rock store max-size should be a multiple of page size"");",,"[""removeLog""]","[[""fatal"", ""Rock"", ""store"", ""max"", ""size"", ""should"", ""be"", ""a"", ""multiple"", ""of"", ""page"", ""size""], []]",[-9403061361864848369],6090,0.0,2
https://github.com/squid-cache/squid/commit/714a769f772fe5732068bd7a4f2f5d29d4ec54f9,03 Feb 2011,Avoid assertions when mgr:storedir is requested before cache_dir has a map.,10,data/crawl/squid/hunk_2755.cpp,,,data/crawl/squid/old_hunk_2755.cpp,data/crawl/squid/new_hunk_2755.cpp,3,5,"storeAppendPrintf(&e, ""Maximum entries: %9d\n"", map->entryLimit());","storeAppendPrintf(&e, ""Maximum entries: %9d\n"", limit);","[""removeVariable"", ""addVariable""]","[[""map"", ""entryLimit""], [""limit""]]",[-15342710095649559044],6089,0.0,2
https://github.com/squid-cache/squid/commit/995eb827aaa64d9bcd4110b756e04051ef9d03e9,02 Mar 2011,merge from trunk,12916,data/crawl/squid/hunk_2737.cpp,,,data/crawl/squid/old_hunk_2737.cpp,data/crawl/squid/new_hunk_2737.cpp,-1,4,,"fatalf(""Cannot open '%s' because it is a directory, not a file.\n"", path);","[""addLog""]","[[], [""fatalf"", ""Cannot"", ""open"", ""%s"", ""because"", ""it"", ""is"", ""a"", ""directory"", ""not"", ""a"", ""file"", ""\\n"", ""path""]]",[17095642847503903928],6088,16560.0,2
https://github.com/squid-cache/squid/commit/995eb827aaa64d9bcd4110b756e04051ef9d03e9,02 Mar 2011,merge from trunk,12916,data/crawl/squid/hunk_2716.cpp,,,data/crawl/squid/old_hunk_2716.cpp,data/crawl/squid/new_hunk_2716.cpp,-1,10,,"fatalf(""parse_peer: userhash requires authentication. peer %s/%d\n"", p->host, p->http_port);","[""addLog""]","[[], [""fatalf"", ""parse_peer"", ""userhash"", ""requires"", ""authentication"", ""peer"", ""%s/%d\\n"", ""p"", ""host"", ""p"", ""http_port""]]",[22167663731656608907],6087,16560.0,2
https://github.com/squid-cache/squid/commit/995eb827aaa64d9bcd4110b756e04051ef9d03e9,02 Mar 2011,merge from trunk,12916,data/crawl/squid/hunk_2714.cpp,,,data/crawl/squid/old_hunk_2714.cpp,data/crawl/squid/new_hunk_2714.cpp,-1,37,,"auth_user_request->setDenyMessage(""Request denied because you provided an empty password. Users MUST have a password."");","[""addLog""]","[[], [""auth_user_request"", ""setDenyMessage"", ""Request"", ""denied"", ""because"", ""you"", ""provided"", ""an"", ""empty"", ""password"", ""Users"", ""MUST"", ""have"", ""a"", ""password""]]",[-16720659610080363062],6086,10800.0,2
https://github.com/squid-cache/squid/commit/995eb827aaa64d9bcd4110b756e04051ef9d03e9,02 Mar 2011,merge from trunk,12916,data/crawl/squid/hunk_2714.cpp,,,data/crawl/squid/old_hunk_2714.cpp,data/crawl/squid/new_hunk_2714.cpp,-1,32,,"auth_user_request->setDenyMessage(""no password was present in the HTTP [proxy-]authorization header. This is most likely a browser bug"");","[""addLog""]","[[], [""auth_user_request"", ""setDenyMessage"", ""no"", ""password"", ""was"", ""present"", ""in"", ""the"", ""HTTP"", ""[proxy"", ""]authorization"", ""header"", ""This"", ""is"", ""most"", ""likely"", ""a"", ""browser"", ""bug""]]",[-10644024353310434392],6085,10800.0,2
https://github.com/squid-cache/squid/commit/995eb827aaa64d9bcd4110b756e04051ef9d03e9,02 Mar 2011,merge from trunk,12916,data/crawl/squid/hunk_2713.cpp,,,data/crawl/squid/old_hunk_2713.cpp,data/crawl/squid/new_hunk_2713.cpp,85,-1,"currentRequest->setDenyMessage(""Request denied because you provided an empty password. Users MUST have a password."");",,"[""removeLog""]","[[""currentRequest"", ""setDenyMessage"", ""Request"", ""denied"", ""because"", ""you"", ""provided"", ""an"", ""empty"", ""password"", ""Users"", ""MUST"", ""have"", ""a"", ""password""], []]",[26811334352053999021],6084,10800.0,2
https://github.com/squid-cache/squid/commit/995eb827aaa64d9bcd4110b756e04051ef9d03e9,02 Mar 2011,merge from trunk,12916,data/crawl/squid/hunk_2713.cpp,,,data/crawl/squid/old_hunk_2713.cpp,data/crawl/squid/new_hunk_2713.cpp,79,-1,"currentRequest->setDenyMessage(""no password was present in the HTTP [proxy-]authorization header. This is most likely a browser bug"");",,"[""removeLog""]","[[""currentRequest"", ""setDenyMessage"", ""no"", ""password"", ""was"", ""present"", ""in"", ""the"", ""HTTP"", ""[proxy"", ""]authorization"", ""header"", ""This"", ""is"", ""most"", ""likely"", ""a"", ""browser"", ""bug""], []]",[20734699095284070351],6083,10800.0,2
https://github.com/squid-cache/squid/commit/ffce5f58438c9a15c0351c7b038fd300228cbcb2,09 Mar 2011,"Support libecap v0.2.0; fixed eCAP body handling and logging.

Summary of changes:

libecap v0.2.0 support: accept/update/log eCAP transaction meta-info.
libecap v0.2.0 support: supply client IP and username to eCAP adapter.
libecap v0.1.0 support: Support blockVirgin() API with ERR_ACCESS_DENIED.

Use pkg-config's PKG_CHECK_MODULES to check for and link with libecap.

Support adapter-specific parameters as a part of ecap_service configuration.
Allow uri=value parameter when specifying adaptation service URIs.

Fixed virgin body handling in our eCAP transaction wrapper (Ecap::XactionRep).
Fixed BodyPipe.cc:144 ""!theConsumer"" assertion.

Log ""important"" messages from eCAP adapters with DBG_IMPORTANT not DBG_DATA!

Added XXXs to identify old unrelated problems to be fixed separately.",1302,data/crawl/squid/hunk_2701.cpp,,,data/crawl/squid/old_hunk_2701.cpp,data/crawl/squid/new_hunk_2701.cpp,-1,19,,"buf.Printf("" A%d"", static_cast<int>(proxyingAb));","[""addLog""]","[[], [""buf"", ""Printf"", ""A%d"", ""static_cast"", ""int"", ""proxyingAb""]]",[3539411117056577306],6082,58320.0,2
https://github.com/squid-cache/squid/commit/ffce5f58438c9a15c0351c7b038fd300228cbcb2,09 Mar 2011,"Support libecap v0.2.0; fixed eCAP body handling and logging.

Summary of changes:

libecap v0.2.0 support: accept/update/log eCAP transaction meta-info.
libecap v0.2.0 support: supply client IP and username to eCAP adapter.
libecap v0.1.0 support: Support blockVirgin() API with ERR_ACCESS_DENIED.

Use pkg-config's PKG_CHECK_MODULES to check for and link with libecap.

Support adapter-specific parameters as a part of ecap_service configuration.
Allow uri=value parameter when specifying adaptation service URIs.

Fixed virgin body handling in our eCAP transaction wrapper (Ecap::XactionRep).
Fixed BodyPipe.cc:144 ""!theConsumer"" assertion.

Log ""important"" messages from eCAP adapters with DBG_IMPORTANT not DBG_DATA!

Added XXXs to identify old unrelated problems to be fixed separately.",1302,data/crawl/squid/hunk_2701.cpp,,,data/crawl/squid/old_hunk_2701.cpp,data/crawl/squid/new_hunk_2701.cpp,-1,4,,"buf.Printf(""M%d"", static_cast<int>(makingVb));","[""addLog""]","[[], [""buf"", ""Printf"", ""M%d"", ""static_cast"", ""int"", ""makingVb""]]",[5807745462519037038],6081,58320.0,2
https://github.com/squid-cache/squid/commit/ffce5f58438c9a15c0351c7b038fd300228cbcb2,09 Mar 2011,"Support libecap v0.2.0; fixed eCAP body handling and logging.

Summary of changes:

libecap v0.2.0 support: accept/update/log eCAP transaction meta-info.
libecap v0.2.0 support: supply client IP and username to eCAP adapter.
libecap v0.1.0 support: Support blockVirgin() API with ERR_ACCESS_DENIED.

Use pkg-config's PKG_CHECK_MODULES to check for and link with libecap.

Support adapter-specific parameters as a part of ecap_service configuration.
Allow uri=value parameter when specifying adaptation service URIs.

Fixed virgin body handling in our eCAP transaction wrapper (Ecap::XactionRep).
Fixed BodyPipe.cc:144 ""!theConsumer"" assertion.

Log ""important"" messages from eCAP adapters with DBG_IMPORTANT not DBG_DATA!

Added XXXs to identify old unrelated problems to be fixed separately.",1302,data/crawl/squid/hunk_2699.cpp,,,data/crawl/squid/old_hunk_2699.cpp,data/crawl/squid/new_hunk_2699.cpp,-1,9,,"mustStop(""blocked"");","[""addLog""]","[[], [""mustStop"", ""blocked""]]",[-7768935051605558574],6080,60480.0,2
https://github.com/squid-cache/squid/commit/ffce5f58438c9a15c0351c7b038fd300228cbcb2,09 Mar 2011,"Support libecap v0.2.0; fixed eCAP body handling and logging.

Summary of changes:

libecap v0.2.0 support: accept/update/log eCAP transaction meta-info.
libecap v0.2.0 support: supply client IP and username to eCAP adapter.
libecap v0.1.0 support: Support blockVirgin() API with ERR_ACCESS_DENIED.

Use pkg-config's PKG_CHECK_MODULES to check for and link with libecap.

Support adapter-specific parameters as a part of ecap_service configuration.
Allow uri=value parameter when specifying adaptation service URIs.

Fixed virgin body handling in our eCAP transaction wrapper (Ecap::XactionRep).
Fixed BodyPipe.cc:144 ""!theConsumer"" assertion.

Log ""important"" messages from eCAP adapters with DBG_IMPORTANT not DBG_DATA!

Added XXXs to identify old unrelated problems to be fixed separately.",1302,data/crawl/squid/hunk_2696.cpp,,,data/crawl/squid/old_hunk_2696.cpp,data/crawl/squid/new_hunk_2696.cpp,-1,31,,"abortTransaction(""timely adaptation block"");","[""addLog""]","[[], [""abortTransaction"", ""timely"", ""adaptation"", ""block""]]",[-8470589001559555923],6079,60480.0,2
https://github.com/squid-cache/squid/commit/ffce5f58438c9a15c0351c7b038fd300228cbcb2,09 Mar 2011,"Support libecap v0.2.0; fixed eCAP body handling and logging.

Summary of changes:

libecap v0.2.0 support: accept/update/log eCAP transaction meta-info.
libecap v0.2.0 support: supply client IP and username to eCAP adapter.
libecap v0.1.0 support: Support blockVirgin() API with ERR_ACCESS_DENIED.

Use pkg-config's PKG_CHECK_MODULES to check for and link with libecap.

Support adapter-specific parameters as a part of ecap_service configuration.
Allow uri=value parameter when specifying adaptation service URIs.

Fixed virgin body handling in our eCAP transaction wrapper (Ecap::XactionRep).
Fixed BodyPipe.cc:144 ""!theConsumer"" assertion.

Log ""important"" messages from eCAP adapters with DBG_IMPORTANT not DBG_DATA!

Added XXXs to identify old unrelated problems to be fixed separately.",1302,data/crawl/squid/hunk_2696.cpp,,,data/crawl/squid/old_hunk_2696.cpp,data/crawl/squid/new_hunk_2696.cpp,-1,15,,"abortTransaction(""late adaptation block"");","[""addLog""]","[[], [""abortTransaction"", ""late"", ""adaptation"", ""block""]]",[-8139058427817919875],6078,60480.0,2
https://github.com/squid-cache/squid/commit/f602c423b782d0c1b4233e70a01b337dcbb824a9,14 Mar 2011,ext_kerberos_ldap_group_acl version 1.3.0sq,337,data/crawl/squid/hunk_2693.cpp,,,data/crawl/squid/old_hunk_2693.cpp,data/crawl/squid/new_hunk_2693.cpp,-1,4,,"fprintf(stderr, ""server - In this case server can be used for all Kerberos domains\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""server"", ""In"", ""this"", ""case"", ""server"", ""can"", ""be"", ""used"", ""for"", ""all"", ""Kerberos"", ""domains\\n""]]",[2359019322648951223],6077,0.0,2
https://github.com/squid-cache/squid/commit/8765bc8cba81d5776992f8b243447e01860d8892,27 Apr 2011,"Change SwapDir::cur_size to bytes, make it private, use currentSize() instead.",40,data/crawl/squid/hunk_2638.cpp,,,data/crawl/squid/old_hunk_2638.cpp,data/crawl/squid/new_hunk_2638.cpp,6,7,"storeAppendPrintf(&sentry, ""Percent Used: %0.2f%%\n"",
                      (100.0 * (double)cur_size / (double)max_size) );","storeAppendPrintf(&sentry, ""Percent Used: %0.2f%%\n"",
                      Math::doublePercent(currentSizeInKB, max_size) );","[""updateVariable"", ""moveVariable"", ""removeVariable"", ""removeContent"", ""addVariable""]","[[""100"", ""0"", ""*"", ""double"", ""cur_size"", ""/"", ""double""], [""Math"", ""doublePercent"", ""currentSizeInKB""]]",[3574925131379787238],6076,0.0,2
https://github.com/squid-cache/squid/commit/cc34568dd6d1a7fa78a4db8927f9d21437d84bbb,27 Apr 2011,"Change SwapDir::max_size to bytes, make it protected, use maxSize() instead.",153,data/crawl/squid/hunk_2623.cpp,,,data/crawl/squid/old_hunk_2623.cpp,data/crawl/squid/new_hunk_2623.cpp,7,6,"storeAppendPrintf(&sentry, ""Percent Used: %0.2f%%\n"",
                      Math::doublePercent(currentSizeInKB, max_size) );","storeAppendPrintf(&sentry, ""Percent Used: %0.2f%%\n"",
                      Math::doublePercent(currentSize(), maxSize()) );","[""removeVariable"", ""addVariable""]","[[""currentSizeInKB"", ""max_size""], [""currentSize"", ""maxSize""]]",[-16025968577689973746],6075,0.0,2
https://github.com/squid-cache/squid/commit/983983ce5ef0d6785a1f6a65b1685e07ea68a9af,04 Jun 2011,Sync with trunk,6637,data/crawl/squid/hunk_2589.cpp,,,data/crawl/squid/old_hunk_2589.cpp,data/crawl/squid/new_hunk_2589.cpp,-1,6,,"mb.Printf(""%s"", detail->errorName());","[""addLog""]","[[], [""mb"", ""Printf"", ""%s"", ""detail"", ""errorName""]]",[3667522566685898263],6074,15840.0,2
https://github.com/squid-cache/squid/commit/983983ce5ef0d6785a1f6a65b1685e07ea68a9af,04 Jun 2011,Sync with trunk,6637,data/crawl/squid/hunk_2585.cpp,,,data/crawl/squid/old_hunk_2585.cpp,data/crawl/squid/new_hunk_2585.cpp,-1,33,,"disableRepeats(""ICAP service is not available"");","[""addLog""]","[[], [""disableRepeats"", ""ICAP"", ""service"", ""is"", ""not"", ""available""]]",[-3623296679770679195],6073,15840.0,2
https://github.com/squid-cache/squid/commit/983983ce5ef0d6785a1f6a65b1685e07ea68a9af,04 Jun 2011,Sync with trunk,6637,data/crawl/squid/hunk_2585.cpp,,,data/crawl/squid/old_hunk_2585.cpp,data/crawl/squid/new_hunk_2585.cpp,-1,28,,"disableBypass(""not available"", true);","[""addLog""]","[[], [""disableBypass"", ""not"", ""available"", ""true""]]",[3123086995756103309],6072,15840.0,2
https://github.com/squid-cache/squid/commit/983983ce5ef0d6785a1f6a65b1685e07ea68a9af,04 Jun 2011,Sync with trunk,6637,data/crawl/squid/hunk_2584.cpp,,,data/crawl/squid/old_hunk_2584.cpp,data/crawl/squid/new_hunk_2584.cpp,3,3,"fprintf(logfile, ""%ld %s| %s: "", now, program_name, level);","fprintf(logfile, ""%ld %s| %s: "", static_cast<long int>(now),
            program_name, level);","[""addVariable""]","[[], [""static_cast"", ""long"", ""int""]]",[-7267402898558735395],6071,6480.0,2
https://github.com/squid-cache/squid/commit/1c8f25bbb056368c4405473ff7304156608e92cc,17 Jun 2011,"Upgrade comm layer Connection handling

The premise underlying this large patch is that instead of copying and
re-copying and re-lookups for the FD related data we can take the
ConnectionDetail class which is generated to store a few bits of IP
information about newly accept()'d connections and make it persist across
the whole of Squid.

It has been renamed from ConnectionDetails to Comm::Connection and has
absorbed a few FD data fields from other classes long the code paths.
Its scope is to hold an FD (or potential FD) plus meta data.

Comm::Connection are valid before, during and after the period when their
particular FD is open. The meta data may be used beforehand to setup the
FD (in the case of peer selection or other TcpAcceptor usage), and it may
remain in use after FD closure until logging or all linked job and call
objects have detected the closure and terminated. A global function
Comm::IsConnOpen() may be used on the pointer objects to detect whether
they point at an active connection.

Most of the patch is simple parameter changes to functions and methods to
pass a ""cont Comm::ConnectionPointer &"" instead of an ""int FD"". Along with
class FD fields being converted to these object pointers.


In order to support this alteration there have been behavioral changes to:

The socket accept() Job
  Comm::TcpAcceptor altered to spawn Comm::Connection objects and to
  operate with one controlling their active/closed state.

FTP data channel handling Calls.
  efficiency improvements making use of Comm::Connection as a feedback
  channel between TcpAcceptor and FtpStateData to cancel the listening
  Job. Most of the underlying logic change is already in trunk to use
  the Subscription API. This just streamlines and fixes some race bugs.

Peer selection
  updated to spawn a set of Comm::Connection objects. To do this it is
  updated to determine *all* peers including DIRECT ones. Doing the DNS
  lookup instead of leaving it to comm_connect() on the other side of
  FwdState. It also absorbs the outgoing address selection from FwdState
  and can now specify details of local+remote ends of an outgoing TCP link.

Forwarding
  updated to handle the new outputs from peer selection and to open sequentially.

pconn handling
  updated to use destination IP/port and hold a Comm::Connection instead
  of domain name indexing an FD. This allows us to maintain idle pools
  and re-use FD more efficiently with virtual-hosted servers. Along
  with maintaining certainty that the pconn selected actually goes to
  the exact destination IP:port needed by forwarding.

comm layer outgoing connections
  now have a control job Comm::ConnOpener to do this. Due to the peer
  selection and forwarding changes this is a much simpler operation.

HTTP / CONNECT tunnel / gopher / whois / FTP
  updated to receive a server and client Comm::Connection object from
  forwarding. To operate on those until they close or are finished with.

SNMP / ICP / HTCP / DNS port listeners
  updated to work with Comm::Connection holding their listening socket
  meta data. This is a side-effect of the ICP and Comm read/write/timeout
  changes.",8518,data/crawl/squid/hunk_2579.cpp,,,data/crawl/squid/old_hunk_2579.cpp,data/crawl/squid/new_hunk_2579.cpp,3,3,"fprintf(stderr, ""Not implemented"");","fatal(""tools.cc required"");","[""updateLog"", ""removeVariable"", ""updateContent""]","[[""fprintf"", ""stderr"", ""Not"", ""implemented""], [""fatal"", ""tools"", ""cc"", ""required""]]",[14254032591148478797],6070,76320.0,2
https://github.com/squid-cache/squid/commit/1c8f25bbb056368c4405473ff7304156608e92cc,17 Jun 2011,"Upgrade comm layer Connection handling

The premise underlying this large patch is that instead of copying and
re-copying and re-lookups for the FD related data we can take the
ConnectionDetail class which is generated to store a few bits of IP
information about newly accept()'d connections and make it persist across
the whole of Squid.

It has been renamed from ConnectionDetails to Comm::Connection and has
absorbed a few FD data fields from other classes long the code paths.
Its scope is to hold an FD (or potential FD) plus meta data.

Comm::Connection are valid before, during and after the period when their
particular FD is open. The meta data may be used beforehand to setup the
FD (in the case of peer selection or other TcpAcceptor usage), and it may
remain in use after FD closure until logging or all linked job and call
objects have detected the closure and terminated. A global function
Comm::IsConnOpen() may be used on the pointer objects to detect whether
they point at an active connection.

Most of the patch is simple parameter changes to functions and methods to
pass a ""cont Comm::ConnectionPointer &"" instead of an ""int FD"". Along with
class FD fields being converted to these object pointers.


In order to support this alteration there have been behavioral changes to:

The socket accept() Job
  Comm::TcpAcceptor altered to spawn Comm::Connection objects and to
  operate with one controlling their active/closed state.

FTP data channel handling Calls.
  efficiency improvements making use of Comm::Connection as a feedback
  channel between TcpAcceptor and FtpStateData to cancel the listening
  Job. Most of the underlying logic change is already in trunk to use
  the Subscription API. This just streamlines and fixes some race bugs.

Peer selection
  updated to spawn a set of Comm::Connection objects. To do this it is
  updated to determine *all* peers including DIRECT ones. Doing the DNS
  lookup instead of leaving it to comm_connect() on the other side of
  FwdState. It also absorbs the outgoing address selection from FwdState
  and can now specify details of local+remote ends of an outgoing TCP link.

Forwarding
  updated to handle the new outputs from peer selection and to open sequentially.

pconn handling
  updated to use destination IP/port and hold a Comm::Connection instead
  of domain name indexing an FD. This allows us to maintain idle pools
  and re-use FD more efficiently with virtual-hosted servers. Along
  with maintaining certainty that the pconn selected actually goes to
  the exact destination IP:port needed by forwarding.

comm layer outgoing connections
  now have a control job Comm::ConnOpener to do this. Due to the peer
  selection and forwarding changes this is a much simpler operation.

HTTP / CONNECT tunnel / gopher / whois / FTP
  updated to receive a server and client Comm::Connection object from
  forwarding. To operate on those until they close or are finished with.

SNMP / ICP / HTCP / DNS port listeners
  updated to work with Comm::Connection holding their listening socket
  meta data. This is a side-effect of the ICP and Comm read/write/timeout
  changes.",8518,data/crawl/squid/hunk_2568.cpp,,,data/crawl/squid/old_hunk_2568.cpp,data/crawl/squid/new_hunk_2568.cpp,-1,58,,"fatalf(""Lost SNMP port (%d) on FD %d"", (int)conn->local.GetPort(), conn->fd);","[""addLog""]","[[], [""fatalf"", ""Lost"", ""SNMP"", ""port"", ""%d"", ""on"", ""FD"", ""%d"", ""int"", ""conn"", ""local"", ""GetPort"", ""conn"", ""fd""]]",[24907459338955178110],6069,185760.0,2
https://github.com/squid-cache/squid/commit/1c8f25bbb056368c4405473ff7304156608e92cc,17 Jun 2011,"Upgrade comm layer Connection handling

The premise underlying this large patch is that instead of copying and
re-copying and re-lookups for the FD related data we can take the
ConnectionDetail class which is generated to store a few bits of IP
information about newly accept()'d connections and make it persist across
the whole of Squid.

It has been renamed from ConnectionDetails to Comm::Connection and has
absorbed a few FD data fields from other classes long the code paths.
Its scope is to hold an FD (or potential FD) plus meta data.

Comm::Connection are valid before, during and after the period when their
particular FD is open. The meta data may be used beforehand to setup the
FD (in the case of peer selection or other TcpAcceptor usage), and it may
remain in use after FD closure until logging or all linked job and call
objects have detected the closure and terminated. A global function
Comm::IsConnOpen() may be used on the pointer objects to detect whether
they point at an active connection.

Most of the patch is simple parameter changes to functions and methods to
pass a ""cont Comm::ConnectionPointer &"" instead of an ""int FD"". Along with
class FD fields being converted to these object pointers.


In order to support this alteration there have been behavioral changes to:

The socket accept() Job
  Comm::TcpAcceptor altered to spawn Comm::Connection objects and to
  operate with one controlling their active/closed state.

FTP data channel handling Calls.
  efficiency improvements making use of Comm::Connection as a feedback
  channel between TcpAcceptor and FtpStateData to cancel the listening
  Job. Most of the underlying logic change is already in trunk to use
  the Subscription API. This just streamlines and fixes some race bugs.

Peer selection
  updated to spawn a set of Comm::Connection objects. To do this it is
  updated to determine *all* peers including DIRECT ones. Doing the DNS
  lookup instead of leaving it to comm_connect() on the other side of
  FwdState. It also absorbs the outgoing address selection from FwdState
  and can now specify details of local+remote ends of an outgoing TCP link.

Forwarding
  updated to handle the new outputs from peer selection and to open sequentially.

pconn handling
  updated to use destination IP/port and hold a Comm::Connection instead
  of domain name indexing an FD. This allows us to maintain idle pools
  and re-use FD more efficiently with virtual-hosted servers. Along
  with maintaining certainty that the pconn selected actually goes to
  the exact destination IP:port needed by forwarding.

comm layer outgoing connections
  now have a control job Comm::ConnOpener to do this. Due to the peer
  selection and forwarding changes this is a much simpler operation.

HTTP / CONNECT tunnel / gopher / whois / FTP
  updated to receive a server and client Comm::Connection object from
  forwarding. To operate on those until they close or are finished with.

SNMP / ICP / HTCP / DNS port listeners
  updated to work with Comm::Connection holding their listening socket
  meta data. This is a side-effect of the ICP and Comm read/write/timeout
  changes.",8518,data/crawl/squid/hunk_2568.cpp,,,data/crawl/squid/old_hunk_2568.cpp,data/crawl/squid/new_hunk_2568.cpp,-1,49,,"fatalf(""Cannot open SNMP %s Port"",(conn->fd == snmpIncomingConn->fd?""receiving"":""sending""));","[""addLog""]","[[], [""fatalf"", ""Cannot"", ""open"", ""SNMP"", ""%s"", ""Port"", ""conn"", ""fd"", ""snmpIncomingConn"", ""fd"", ""receiving"", ""sending""]]",[3126058313037085896],6068,185760.0,2
https://github.com/squid-cache/squid/commit/1c8f25bbb056368c4405473ff7304156608e92cc,17 Jun 2011,"Upgrade comm layer Connection handling

The premise underlying this large patch is that instead of copying and
re-copying and re-lookups for the FD related data we can take the
ConnectionDetail class which is generated to store a few bits of IP
information about newly accept()'d connections and make it persist across
the whole of Squid.

It has been renamed from ConnectionDetails to Comm::Connection and has
absorbed a few FD data fields from other classes long the code paths.
Its scope is to hold an FD (or potential FD) plus meta data.

Comm::Connection are valid before, during and after the period when their
particular FD is open. The meta data may be used beforehand to setup the
FD (in the case of peer selection or other TcpAcceptor usage), and it may
remain in use after FD closure until logging or all linked job and call
objects have detected the closure and terminated. A global function
Comm::IsConnOpen() may be used on the pointer objects to detect whether
they point at an active connection.

Most of the patch is simple parameter changes to functions and methods to
pass a ""cont Comm::ConnectionPointer &"" instead of an ""int FD"". Along with
class FD fields being converted to these object pointers.


In order to support this alteration there have been behavioral changes to:

The socket accept() Job
  Comm::TcpAcceptor altered to spawn Comm::Connection objects and to
  operate with one controlling their active/closed state.

FTP data channel handling Calls.
  efficiency improvements making use of Comm::Connection as a feedback
  channel between TcpAcceptor and FtpStateData to cancel the listening
  Job. Most of the underlying logic change is already in trunk to use
  the Subscription API. This just streamlines and fixes some race bugs.

Peer selection
  updated to spawn a set of Comm::Connection objects. To do this it is
  updated to determine *all* peers including DIRECT ones. Doing the DNS
  lookup instead of leaving it to comm_connect() on the other side of
  FwdState. It also absorbs the outgoing address selection from FwdState
  and can now specify details of local+remote ends of an outgoing TCP link.

Forwarding
  updated to handle the new outputs from peer selection and to open sequentially.

pconn handling
  updated to use destination IP/port and hold a Comm::Connection instead
  of domain name indexing an FD. This allows us to maintain idle pools
  and re-use FD more efficiently with virtual-hosted servers. Along
  with maintaining certainty that the pconn selected actually goes to
  the exact destination IP:port needed by forwarding.

comm layer outgoing connections
  now have a control job Comm::ConnOpener to do this. Due to the peer
  selection and forwarding changes this is a much simpler operation.

HTTP / CONNECT tunnel / gopher / whois / FTP
  updated to receive a server and client Comm::Connection object from
  forwarding. To operate on those until they close or are finished with.

SNMP / ICP / HTCP / DNS port listeners
  updated to work with Comm::Connection holding their listening socket
  meta data. This is a side-effect of the ICP and Comm read/write/timeout
  changes.",8518,data/crawl/squid/hunk_2568.cpp,,,data/crawl/squid/old_hunk_2568.cpp,data/crawl/squid/new_hunk_2568.cpp,70,-1,"fatal(""Cannot open Outgoing SNMP Port"");",,"[""removeLog""]","[[""fatal"", ""Cannot"", ""open"", ""Outgoing"", ""SNMP"", ""Port""], []]",[-181075478816237621],6067,185760.0,2
https://github.com/squid-cache/squid/commit/1c8f25bbb056368c4405473ff7304156608e92cc,17 Jun 2011,"Upgrade comm layer Connection handling

The premise underlying this large patch is that instead of copying and
re-copying and re-lookups for the FD related data we can take the
ConnectionDetail class which is generated to store a few bits of IP
information about newly accept()'d connections and make it persist across
the whole of Squid.

It has been renamed from ConnectionDetails to Comm::Connection and has
absorbed a few FD data fields from other classes long the code paths.
Its scope is to hold an FD (or potential FD) plus meta data.

Comm::Connection are valid before, during and after the period when their
particular FD is open. The meta data may be used beforehand to setup the
FD (in the case of peer selection or other TcpAcceptor usage), and it may
remain in use after FD closure until logging or all linked job and call
objects have detected the closure and terminated. A global function
Comm::IsConnOpen() may be used on the pointer objects to detect whether
they point at an active connection.

Most of the patch is simple parameter changes to functions and methods to
pass a ""cont Comm::ConnectionPointer &"" instead of an ""int FD"". Along with
class FD fields being converted to these object pointers.


In order to support this alteration there have been behavioral changes to:

The socket accept() Job
  Comm::TcpAcceptor altered to spawn Comm::Connection objects and to
  operate with one controlling their active/closed state.

FTP data channel handling Calls.
  efficiency improvements making use of Comm::Connection as a feedback
  channel between TcpAcceptor and FtpStateData to cancel the listening
  Job. Most of the underlying logic change is already in trunk to use
  the Subscription API. This just streamlines and fixes some race bugs.

Peer selection
  updated to spawn a set of Comm::Connection objects. To do this it is
  updated to determine *all* peers including DIRECT ones. Doing the DNS
  lookup instead of leaving it to comm_connect() on the other side of
  FwdState. It also absorbs the outgoing address selection from FwdState
  and can now specify details of local+remote ends of an outgoing TCP link.

Forwarding
  updated to handle the new outputs from peer selection and to open sequentially.

pconn handling
  updated to use destination IP/port and hold a Comm::Connection instead
  of domain name indexing an FD. This allows us to maintain idle pools
  and re-use FD more efficiently with virtual-hosted servers. Along
  with maintaining certainty that the pconn selected actually goes to
  the exact destination IP:port needed by forwarding.

comm layer outgoing connections
  now have a control job Comm::ConnOpener to do this. Due to the peer
  selection and forwarding changes this is a much simpler operation.

HTTP / CONNECT tunnel / gopher / whois / FTP
  updated to receive a server and client Comm::Connection object from
  forwarding. To operate on those until they close or are finished with.

SNMP / ICP / HTCP / DNS port listeners
  updated to work with Comm::Connection holding their listening socket
  meta data. This is a side-effect of the ICP and Comm read/write/timeout
  changes.",8518,data/crawl/squid/hunk_2568.cpp,,,data/crawl/squid/old_hunk_2568.cpp,data/crawl/squid/new_hunk_2568.cpp,54,-1,"fatal(""Cannot open Incoming SNMP Port"");",,"[""removeLog""]","[[""fatal"", ""Cannot"", ""open"", ""Incoming"", ""SNMP"", ""Port""], []]",[7425564651419172777],6066,185760.0,2
https://github.com/squid-cache/squid/commit/1c8f25bbb056368c4405473ff7304156608e92cc,17 Jun 2011,"Upgrade comm layer Connection handling

The premise underlying this large patch is that instead of copying and
re-copying and re-lookups for the FD related data we can take the
ConnectionDetail class which is generated to store a few bits of IP
information about newly accept()'d connections and make it persist across
the whole of Squid.

It has been renamed from ConnectionDetails to Comm::Connection and has
absorbed a few FD data fields from other classes long the code paths.
Its scope is to hold an FD (or potential FD) plus meta data.

Comm::Connection are valid before, during and after the period when their
particular FD is open. The meta data may be used beforehand to setup the
FD (in the case of peer selection or other TcpAcceptor usage), and it may
remain in use after FD closure until logging or all linked job and call
objects have detected the closure and terminated. A global function
Comm::IsConnOpen() may be used on the pointer objects to detect whether
they point at an active connection.

Most of the patch is simple parameter changes to functions and methods to
pass a ""cont Comm::ConnectionPointer &"" instead of an ""int FD"". Along with
class FD fields being converted to these object pointers.


In order to support this alteration there have been behavioral changes to:

The socket accept() Job
  Comm::TcpAcceptor altered to spawn Comm::Connection objects and to
  operate with one controlling their active/closed state.

FTP data channel handling Calls.
  efficiency improvements making use of Comm::Connection as a feedback
  channel between TcpAcceptor and FtpStateData to cancel the listening
  Job. Most of the underlying logic change is already in trunk to use
  the Subscription API. This just streamlines and fixes some race bugs.

Peer selection
  updated to spawn a set of Comm::Connection objects. To do this it is
  updated to determine *all* peers including DIRECT ones. Doing the DNS
  lookup instead of leaving it to comm_connect() on the other side of
  FwdState. It also absorbs the outgoing address selection from FwdState
  and can now specify details of local+remote ends of an outgoing TCP link.

Forwarding
  updated to handle the new outputs from peer selection and to open sequentially.

pconn handling
  updated to use destination IP/port and hold a Comm::Connection instead
  of domain name indexing an FD. This allows us to maintain idle pools
  and re-use FD more efficiently with virtual-hosted servers. Along
  with maintaining certainty that the pconn selected actually goes to
  the exact destination IP:port needed by forwarding.

comm layer outgoing connections
  now have a control job Comm::ConnOpener to do this. Due to the peer
  selection and forwarding changes this is a much simpler operation.

HTTP / CONNECT tunnel / gopher / whois / FTP
  updated to receive a server and client Comm::Connection object from
  forwarding. To operate on those until they close or are finished with.

SNMP / ICP / HTCP / DNS port listeners
  updated to work with Comm::Connection holding their listening socket
  meta data. This is a side-effect of the ICP and Comm read/write/timeout
  changes.",8518,data/crawl/squid/hunk_2560.cpp,,,data/crawl/squid/old_hunk_2560.cpp,data/crawl/squid/new_hunk_2560.cpp,46,49,"mb.Printf(""%d, %d\r\n"",
              state->my_peer.GetPort(),
              state->me.GetPort());","mb.Printf(""%d, %d\r\n"",
              conn->remote.GetPort(),
              conn->local.GetPort());","[""updateVariable""]","[[""state"", ""my_peer"", ""state"", ""me""], [""conn"", ""remote"", ""conn"", ""local""]]",[-7824832284880526778],6065,283680.0,2
https://github.com/squid-cache/squid/commit/1c8f25bbb056368c4405473ff7304156608e92cc,17 Jun 2011,"Upgrade comm layer Connection handling

The premise underlying this large patch is that instead of copying and
re-copying and re-lookups for the FD related data we can take the
ConnectionDetail class which is generated to store a few bits of IP
information about newly accept()'d connections and make it persist across
the whole of Squid.

It has been renamed from ConnectionDetails to Comm::Connection and has
absorbed a few FD data fields from other classes long the code paths.
Its scope is to hold an FD (or potential FD) plus meta data.

Comm::Connection are valid before, during and after the period when their
particular FD is open. The meta data may be used beforehand to setup the
FD (in the case of peer selection or other TcpAcceptor usage), and it may
remain in use after FD closure until logging or all linked job and call
objects have detected the closure and terminated. A global function
Comm::IsConnOpen() may be used on the pointer objects to detect whether
they point at an active connection.

Most of the patch is simple parameter changes to functions and methods to
pass a ""cont Comm::ConnectionPointer &"" instead of an ""int FD"". Along with
class FD fields being converted to these object pointers.


In order to support this alteration there have been behavioral changes to:

The socket accept() Job
  Comm::TcpAcceptor altered to spawn Comm::Connection objects and to
  operate with one controlling their active/closed state.

FTP data channel handling Calls.
  efficiency improvements making use of Comm::Connection as a feedback
  channel between TcpAcceptor and FtpStateData to cancel the listening
  Job. Most of the underlying logic change is already in trunk to use
  the Subscription API. This just streamlines and fixes some race bugs.

Peer selection
  updated to spawn a set of Comm::Connection objects. To do this it is
  updated to determine *all* peers including DIRECT ones. Doing the DNS
  lookup instead of leaving it to comm_connect() on the other side of
  FwdState. It also absorbs the outgoing address selection from FwdState
  and can now specify details of local+remote ends of an outgoing TCP link.

Forwarding
  updated to handle the new outputs from peer selection and to open sequentially.

pconn handling
  updated to use destination IP/port and hold a Comm::Connection instead
  of domain name indexing an FD. This allows us to maintain idle pools
  and re-use FD more efficiently with virtual-hosted servers. Along
  with maintaining certainty that the pconn selected actually goes to
  the exact destination IP:port needed by forwarding.

comm layer outgoing connections
  now have a control job Comm::ConnOpener to do this. Due to the peer
  selection and forwarding changes this is a much simpler operation.

HTTP / CONNECT tunnel / gopher / whois / FTP
  updated to receive a server and client Comm::Connection object from
  forwarding. To operate on those until they close or are finished with.

SNMP / ICP / HTCP / DNS port listeners
  updated to work with Comm::Connection holding their listening socket
  meta data. This is a side-effect of the ICP and Comm read/write/timeout
  changes.",8518,data/crawl/squid/hunk_2549.cpp,,,data/crawl/squid/old_hunk_2549.cpp,data/crawl/squid/new_hunk_2549.cpp,34,-1,"fatal(""Could not create a DNS socket"");",,"[""removeLog""]","[[""fatal"", ""Could"", ""not"", ""create"", ""a"", ""DNS"", ""socket""], []]",[-1692271683703932066],6064,283680.0,2
https://github.com/squid-cache/squid/commit/1c8f25bbb056368c4405473ff7304156608e92cc,17 Jun 2011,"Upgrade comm layer Connection handling

The premise underlying this large patch is that instead of copying and
re-copying and re-lookups for the FD related data we can take the
ConnectionDetail class which is generated to store a few bits of IP
information about newly accept()'d connections and make it persist across
the whole of Squid.

It has been renamed from ConnectionDetails to Comm::Connection and has
absorbed a few FD data fields from other classes long the code paths.
Its scope is to hold an FD (or potential FD) plus meta data.

Comm::Connection are valid before, during and after the period when their
particular FD is open. The meta data may be used beforehand to setup the
FD (in the case of peer selection or other TcpAcceptor usage), and it may
remain in use after FD closure until logging or all linked job and call
objects have detected the closure and terminated. A global function
Comm::IsConnOpen() may be used on the pointer objects to detect whether
they point at an active connection.

Most of the patch is simple parameter changes to functions and methods to
pass a ""cont Comm::ConnectionPointer &"" instead of an ""int FD"". Along with
class FD fields being converted to these object pointers.


In order to support this alteration there have been behavioral changes to:

The socket accept() Job
  Comm::TcpAcceptor altered to spawn Comm::Connection objects and to
  operate with one controlling their active/closed state.

FTP data channel handling Calls.
  efficiency improvements making use of Comm::Connection as a feedback
  channel between TcpAcceptor and FtpStateData to cancel the listening
  Job. Most of the underlying logic change is already in trunk to use
  the Subscription API. This just streamlines and fixes some race bugs.

Peer selection
  updated to spawn a set of Comm::Connection objects. To do this it is
  updated to determine *all* peers including DIRECT ones. Doing the DNS
  lookup instead of leaving it to comm_connect() on the other side of
  FwdState. It also absorbs the outgoing address selection from FwdState
  and can now specify details of local+remote ends of an outgoing TCP link.

Forwarding
  updated to handle the new outputs from peer selection and to open sequentially.

pconn handling
  updated to use destination IP/port and hold a Comm::Connection instead
  of domain name indexing an FD. This allows us to maintain idle pools
  and re-use FD more efficiently with virtual-hosted servers. Along
  with maintaining certainty that the pconn selected actually goes to
  the exact destination IP:port needed by forwarding.

comm layer outgoing connections
  now have a control job Comm::ConnOpener to do this. Due to the peer
  selection and forwarding changes this is a much simpler operation.

HTTP / CONNECT tunnel / gopher / whois / FTP
  updated to receive a server and client Comm::Connection object from
  forwarding. To operate on those until they close or are finished with.

SNMP / ICP / HTCP / DNS port listeners
  updated to work with Comm::Connection holding their listening socket
  meta data. This is a side-effect of the ICP and Comm read/write/timeout
  changes.",8518,data/crawl/squid/hunk_2544.cpp,,,data/crawl/squid/old_hunk_2544.cpp,data/crawl/squid/new_hunk_2544.cpp,4,-1,"fatal(""maximum_single_addr_tries cannot be larger than 10"");",,"[""removeLog""]","[[""fatal"", ""maximum_single_addr_tries"", ""cannot"", ""be"", ""larger"", ""than"", ""10""], []]",[12211649581919459562],6063,268560.0,2
https://github.com/squid-cache/squid/commit/e24f13cdd75215b6b297ef81b44b93daf94b5f20,30 Jun 2011,"Remove the HttpStateData::orig_request member

When FwdServer::_peer is set, HttpStateData constructor creates a new special
HttpRequest, overwriting the request pointer set in the parent (ServerStateData) 
constructor to fwd->request.

This special HttpRequest sets the proper urlpath (which maybe different from
the original HttpRequest), the host (HttpRequest::SetHost/GetHost) to be the
peer hostname and inherits flags, protocol, method. Also sets the
HttpRequest::flags.proxying.

Probably this is originaly done to handle only the differences in urlpath and
the host. But this is has  as result to have two HttpRequests object in
HttpStateData, but their difference is not clear.

This patch removes the HttpStateData::orig_request member and uses only the 
HttpStateData::request member

Bugs fixed with this patch:

- Debugs() and error pages sometimes display the cache_peer hostname as the URL   requested domain name when going to an origin. Regardless of what the virtual
  host name actually is.

- The request_header_access configuration parameter does not work when
  sending requests to parent proxies.

- Squid may cache replies to requests with no-store in headers when uses a
  parent cache.

- parent caches which have been configured as ""sibling"" for specific domains
  using the neighbor_type_domain parameter are not counted.

- Probably many other


This is a Measurement Factory project",271,data/crawl/squid/hunk_2528.cpp,,,data/crawl/squid/old_hunk_2528.cpp,data/crawl/squid/new_hunk_2528.cpp,9,9,"httpHeaderPutStrf(hdr_out, HDR_HOST, ""%s:%d"",
                              orig_request->GetHost(),
                              (int) orig_request->port);","httpHeaderPutStrf(hdr_out, HDR_HOST, ""%s:%d"",
                              request->GetHost(),
                              (int) request->port);","[""updateVariable""]","[[""orig_request"", ""orig_request""], [""request"", ""request""]]",[-10844026487092080938],6062,0.0,2
https://github.com/squid-cache/squid/commit/c9fd01b4b829bc16d2691a84cdc103ac5dd15333,29 Jul 2011,"SourceLayout: generic AnyP::ProtocolVersion tag class

Protocol agnostic class to store the request-line version details.
HTTP/1.0, HTTP/1.1, ICY/1.0, WebSockets/1.0 etc

For patch reduction leaves HttpVersion as a child class for HTTP/*.* tags",169,data/crawl/squid/hunk_2516.cpp,,,data/crawl/squid/old_hunk_2516.cpp,data/crawl/squid/new_hunk_2516.cpp,3,3,"str.Printf(""%s "" SQUIDSTRINGPH "" HTTP/%d.%d\n"",
                   RequestMethodStr(request->method),
                   SQUIDSTRINGPRINT(urlpath_or_slash),
                   request->http_ver.major, request->http_ver.minor);","str.Printf(""%s "" SQUIDSTRINGPH "" %s/%d.%d\n"",
                   RequestMethodStr(request->method),
                   SQUIDSTRINGPRINT(urlpath_or_slash),
                   AnyP::ProtocolType_str[request->http_ver.protocol],
                   request->http_ver.major, request->http_ver.minor);","[""updateContent"", ""addVariable""]","[[""HTTP/%d""], [""%s/%d"", ""AnyP"", ""ProtocolType_str[request"", ""protocol]"", ""http_ver""]]",[-458833104310664244],6061,0.0,2
https://github.com/squid-cache/squid/commit/fe0a0419ef9d7034005134abdcbec3fa567608be,30 Jul 2011,"SourceLayout: Basic auth: shuffle helper request functions

helper lookup functions are AuthBasicUserRequest members. Should be in
that classes .cc file.

Also merge submit and queue functions. no need to be separate.",205,data/crawl/squid/hunk_2514.cpp,,,data/crawl/squid/old_hunk_2514.cpp,data/crawl/squid/new_hunk_2514.cpp,-1,75,,r->auth_user_request->setDenyMessage(t);,"[""addLog""]","[[], [""r"", ""auth_user_request"", ""setDenyMessage"", ""t""]]",[13600967980912857108],6060,1647360.0,2
https://github.com/squid-cache/squid/commit/38e16f927fb0ac854e8a6bfec90f49af5ef1f6eb,04 Aug 2011,"SourceLayout: format namespace for custom tag-based formats

Part 1 of enabling non-logging components to support custom formats in strings

Shuffle the log custom format code into its own library separate from the
logging functionality.

One minor logic change removing redundant LogFileEnabled flag.

TODO:
 - use MemBuf instead or as well as StoreEntry as the output buffer
 - separate from AccessLogEntry confusion
 - upgrade deny_info URL generation format
 - upgrade external_acl_type format
 - add custom helper formats",3483,data/crawl/squid/hunk_2510.cpp,,,data/crawl/squid/old_hunk_2510.cpp,data/crawl/squid/new_hunk_2510.cpp,684,-1,"storeAppendPrintf(entry, ""%s"", te->config);",,"[""removeLog""]","[[""storeAppendPrintf"", ""entry"", ""%s"", ""te"", ""config""], []]",[-5261554217450138221],6059,169200.0,2
https://github.com/squid-cache/squid/commit/38e16f927fb0ac854e8a6bfec90f49af5ef1f6eb,04 Aug 2011,"SourceLayout: format namespace for custom tag-based formats

Part 1 of enabling non-logging components to support custom formats in strings

Shuffle the log custom format code into its own library separate from the
logging functionality.

One minor logic change removing redundant LogFileEnabled flag.

TODO:
 - use MemBuf instead or as well as StoreEntry as the output buffer
 - separate from AccessLogEntry confusion
 - upgrade deny_info URL generation format
 - upgrade external_acl_type format
 - add custom helper formats",3483,data/crawl/squid/hunk_2510.cpp,,,data/crawl/squid/old_hunk_2510.cpp,data/crawl/squid/new_hunk_2510.cpp,680,-1,"storeAppendPrintf(entry, ""{%s}"", arg);",,"[""removeLog""]","[[""storeAppendPrintf"", ""entry"", ""%s"", ""arg""], []]",[-5370724308728515853],6058,169200.0,2
https://github.com/squid-cache/squid/commit/38e16f927fb0ac854e8a6bfec90f49af5ef1f6eb,04 Aug 2011,"SourceLayout: format namespace for custom tag-based formats

Part 1 of enabling non-logging components to support custom formats in strings

Shuffle the log custom format code into its own library separate from the
logging functionality.

One minor logic change removing redundant LogFileEnabled flag.

TODO:
 - use MemBuf instead or as well as StoreEntry as the output buffer
 - separate from AccessLogEntry confusion
 - upgrade deny_info URL generation format
 - upgrade external_acl_type format
 - add custom helper formats",3483,data/crawl/squid/hunk_2510.cpp,,,data/crawl/squid/old_hunk_2510.cpp,data/crawl/squid/new_hunk_2510.cpp,677,-1,"storeAppendPrintf(entry, "".%d"", (int) t->precision);",,"[""removeLog""]","[[""storeAppendPrintf"", ""entry"", ""%d"", ""int"", ""t"", ""precision""], []]",[10961276620916630613],6057,169200.0,2
https://github.com/squid-cache/squid/commit/38e16f927fb0ac854e8a6bfec90f49af5ef1f6eb,04 Aug 2011,"SourceLayout: format namespace for custom tag-based formats

Part 1 of enabling non-logging components to support custom formats in strings

Shuffle the log custom format code into its own library separate from the
logging functionality.

One minor logic change removing redundant LogFileEnabled flag.

TODO:
 - use MemBuf instead or as well as StoreEntry as the output buffer
 - separate from AccessLogEntry confusion
 - upgrade deny_info URL generation format
 - upgrade external_acl_type format
 - add custom helper formats",3483,data/crawl/squid/hunk_2510.cpp,,,data/crawl/squid/old_hunk_2510.cpp,data/crawl/squid/new_hunk_2510.cpp,674,-1,"storeAppendPrintf(entry, ""%d"", (int) t->width);",,"[""removeLog""]","[[""storeAppendPrintf"", ""entry"", ""%d"", ""int"", ""t"", ""width""], []]",[5835084181075759729],6056,169200.0,2
https://github.com/squid-cache/squid/commit/38e16f927fb0ac854e8a6bfec90f49af5ef1f6eb,04 Aug 2011,"SourceLayout: format namespace for custom tag-based formats

Part 1 of enabling non-logging components to support custom formats in strings

Shuffle the log custom format code into its own library separate from the
logging functionality.

One minor logic change removing redundant LogFileEnabled flag.

TODO:
 - use MemBuf instead or as well as StoreEntry as the output buffer
 - separate from AccessLogEntry confusion
 - upgrade deny_info URL generation format
 - upgrade external_acl_type format
 - add custom helper formats",3483,data/crawl/squid/hunk_2510.cpp,,,data/crawl/squid/old_hunk_2510.cpp,data/crawl/squid/new_hunk_2510.cpp,537,-1,"storeAppendPrintf(entry, ""%s"", t->data.string);",,"[""removeLog""]","[[""storeAppendPrintf"", ""entry"", ""%s"", ""t"", ""data"", ""string""], []]",[14068941932392998644],6055,169200.0,2
https://github.com/squid-cache/squid/commit/38e16f927fb0ac854e8a6bfec90f49af5ef1f6eb,04 Aug 2011,"SourceLayout: format namespace for custom tag-based formats

Part 1 of enabling non-logging components to support custom formats in strings

Shuffle the log custom format code into its own library separate from the
logging functionality.

One minor logic change removing redundant LogFileEnabled flag.

TODO:
 - use MemBuf instead or as well as StoreEntry as the output buffer
 - separate from AccessLogEntry confusion
 - upgrade deny_info URL generation format
 - upgrade external_acl_type format
 - add custom helper formats",3483,data/crawl/squid/hunk_2510.cpp,,,data/crawl/squid/old_hunk_2510.cpp,data/crawl/squid/new_hunk_2510.cpp,533,-1,"storeAppendPrintf(entry, ""logformat %s "", format->name);",,"[""removeLog""]","[[""storeAppendPrintf"", ""entry"", ""logformat"", ""%s"", ""format"", ""name""], []]",[-535866354762710868],6054,169200.0,2
https://github.com/squid-cache/squid/commit/38e16f927fb0ac854e8a6bfec90f49af5ef1f6eb,04 Aug 2011,"SourceLayout: format namespace for custom tag-based formats

Part 1 of enabling non-logging components to support custom formats in strings

Shuffle the log custom format code into its own library separate from the
logging functionality.

One minor logic change removing redundant LogFileEnabled flag.

TODO:
 - use MemBuf instead or as well as StoreEntry as the output buffer
 - separate from AccessLogEntry confusion
 - upgrade deny_info URL generation format
 - upgrade external_acl_type format
 - add custom helper formats",3483,data/crawl/squid/hunk_2510.cpp,,,data/crawl/squid/old_hunk_2510.cpp,data/crawl/squid/new_hunk_2510.cpp,339,-1,"fatalf(""Can't parse configuration token: '%s'\n"",
               def);",,"[""removeLog""]","[[""fatalf"", ""Can"", ""t"", ""parse"", ""configuration"", ""token"", ""%s"", ""\\n"", ""def""], []]",[-10658322044005221237],6053,169200.0,2
https://github.com/squid-cache/squid/commit/38e16f927fb0ac854e8a6bfec90f49af5ef1f6eb,04 Aug 2011,"SourceLayout: format namespace for custom tag-based formats

Part 1 of enabling non-logging components to support custom formats in strings

Shuffle the log custom format code into its own library separate from the
logging functionality.

One minor logic change removing redundant LogFileEnabled flag.

TODO:
 - use MemBuf instead or as well as StoreEntry as the output buffer
 - separate from AccessLogEntry confusion
 - upgrade deny_info URL generation format
 - upgrade external_acl_type format
 - add custom helper formats",3483,data/crawl/squid/hunk_2508.cpp,,,data/crawl/squid/old_hunk_2508.cpp,data/crawl/squid/new_hunk_2508.cpp,831,-1,"mb.Printf(""%*s"", (int) fmt->width, out);",,"[""removeLog""]","[[""mb"", ""Printf"", ""%*s"", ""int"", ""fmt"", ""width"", ""out""], []]",[7314084157223720897],6052,169200.0,2
https://github.com/squid-cache/squid/commit/38e16f927fb0ac854e8a6bfec90f49af5ef1f6eb,04 Aug 2011,"SourceLayout: format namespace for custom tag-based formats

Part 1 of enabling non-logging components to support custom formats in strings

Shuffle the log custom format code into its own library separate from the
logging functionality.

One minor logic change removing redundant LogFileEnabled flag.

TODO:
 - use MemBuf instead or as well as StoreEntry as the output buffer
 - separate from AccessLogEntry confusion
 - upgrade deny_info URL generation format
 - upgrade external_acl_type format
 - add custom helper formats",3483,data/crawl/squid/hunk_2508.cpp,,,data/crawl/squid/old_hunk_2508.cpp,data/crawl/squid/new_hunk_2508.cpp,829,-1,"mb.Printf(""%-*s"", (int) fmt->width, out);",,"[""removeLog""]","[[""mb"", ""Printf"", ""%"", ""*s"", ""int"", ""fmt"", ""width"", ""out""], []]",[2538142304887021005],6051,169200.0,2
https://github.com/squid-cache/squid/commit/7ff7a211c25688d2d6742acc7bc271f700c9dbe9,08 Aug 2011,Migrate cf_gen.cc from C-style stdio to C++ iostreams.,300,data/crawl/squid/hunk_2493.cpp,,,data/crawl/squid/old_hunk_2493.cpp,data/crawl/squid/new_hunk_2493.cpp,17,-1,"fprintf(fp, ""\t}\n"");",,"[""removeLog""]","[[""fprintf"", ""fp"", ""\\t"", ""\\n""], []]",[5167530254375540690],6050,0.0,2
https://github.com/squid-cache/squid/commit/a8d8f7510feda5b32a6a2e9cd3496b9426287aff,06 Sep 2011,Removed an accidently added file.,834,data/crawl/squid/hunk_2476.cpp,,,data/crawl/squid/old_hunk_2476.cpp,data/crawl/squid/new_hunk_2476.cpp,832,-1,"logfilePrintf(logfile, ""%s\n"", mb.buf);",,"[""removeLog""]","[[""logfilePrintf"", ""logfile"", ""%s\\n"", ""mb"", ""buf""], []]",[-9532949238227755944],6049,192960.0,2
https://github.com/squid-cache/squid/commit/c32c6db7e28a12379ccb01aa07261d233137ac47,06 Sep 2011,"Support maximum field width for string access.log fields.

Some standard command-line and some log processing tools have trouble
handling URLs or other logged fields exceeding 8KB in length. Moreover,
Squid violates its own log line format and truncates the entire log line
if, for example, the URL is 8KB long. By supporting .precision format
argument, we allow the administrator to specify logged URL size and
avoid these problems.

Limiting logged field width has no effect on traffic on the wire, with
the exception of log records if they are sent over the network, of course.

TODO: The name comes from the printf(3) ""precision"" format part. It may
be a good idea to rename our ""precision"" into max_width or similar,
especially if we do not support floating point precision logging.

TODO: Old code used chars to store user-configured field width and
precision. That does not work for URLs, headers, and other entries
longer than 256 characters. This patch changes the storage type to int.
The code should probably be polished further to remove unsigned->signed
conversions.",25,data/crawl/squid/hunk_2475.cpp,,,data/crawl/squid/old_hunk_2475.cpp,data/crawl/squid/new_hunk_2475.cpp,7,14,"mb.Printf(""%*s"", (int) fmt->width, out);","mb.Printf(""%*.*s"", minWidth, maxWidth, out);","[""removeVariable"", ""updateContent"", ""addVariable""]","[[""%*s"", ""int"", ""fmt"", ""width""], [""%*"", ""*s"", ""minWidth"", ""maxWidth""]]",[14156439937232948778],6048,159840.0,2
https://github.com/squid-cache/squid/commit/c32c6db7e28a12379ccb01aa07261d233137ac47,06 Sep 2011,"Support maximum field width for string access.log fields.

Some standard command-line and some log processing tools have trouble
handling URLs or other logged fields exceeding 8KB in length. Moreover,
Squid violates its own log line format and truncates the entire log line
if, for example, the URL is 8KB long. By supporting .precision format
argument, we allow the administrator to specify logged URL size and
avoid these problems.

Limiting logged field width has no effect on traffic on the wire, with
the exception of log records if they are sent over the network, of course.

TODO: The name comes from the printf(3) ""precision"" format part. It may
be a good idea to rename our ""precision"" into max_width or similar,
especially if we do not support floating point precision logging.

TODO: Old code used chars to store user-configured field width and
precision. That does not work for URLs, headers, and other entries
longer than 256 characters. This patch changes the storage type to int.
The code should probably be polished further to remove unsigned->signed
conversions.",25,data/crawl/squid/hunk_2475.cpp,,,data/crawl/squid/old_hunk_2475.cpp,data/crawl/squid/new_hunk_2475.cpp,5,12,"mb.Printf(""%-*s"", (int) fmt->width, out);","mb.Printf(""%-*.*s"", minWidth, maxWidth, out);","[""removeVariable"", ""updateContent"", ""addVariable""]","[[""int"", ""fmt"", ""width""], [""*"", ""minWidth"", ""maxWidth""]]",[9375762066555236606],6047,159840.0,2
https://github.com/squid-cache/squid/commit/35a1b223314eddb67b631cb0224d6e03a2360c77,13 Sep 2011,"SMP Caching: Core changes, IPC primitives, Shared memory cache, and Rock Store

Core changes
------------

* Added MemObject::expectedReplySize() and used it instead of object_sz.

When deciding whether an object with a known content length can be
swapped out, do not wait until the object is completely received and its
size (mem_obj->object_sz) becomes known (while asking the store to
recheck in vain with every incoming chunk). Instead, use the known
content length, if any, to make the decision.

This optimizes the common case where the complete object is eventually
received and swapped out, preventing accumulating potentially large
objects in RAM while waiting for the end of the response. Should not
affect objects with unknown content length.

Side-effect1: probably fixes several cases of unknowingly using negative
(unknown) mem_obj->object_sz in calculations. I added a few assertions
to double check some of the remaining object_sz/objectLen() uses.

Side-effect2: When expectedReplySize() is stored on disk as StoreEntry
metadata, it may help to detect truncated entries when the writer
process dies before completing the swapout.


* Removed mem->swapout.memnode in favor of mem->swapout.queue_offset.

The code used swapout.memnode pointer to keep track of the last page
that was swapped out. The code was semi-buggy because it could reset the
pointer to NULL if no new data came in before the call to doPages().
Perhaps the code relied on the assumption that the caller will never
doPages if there is no new data, but I am not sure that assumption was
correct in all cases (it could be that I broke the calling code, of course).

Moreover, the page pointer was kept without any protection from page
disappearing during asynchronous swapout. There were ""Evil hack time""
comments discussing how the page might disappear.

Fortunately, we already have mem->swapout.queue_offset that can be fed
to getBlockContainingLocation to find the page that needs to be swapped
out. There is no need to keep the page pointer around. The
queue_offset-based math is the same so we are not adding any overheads
by using that offset (in fact, we are removing some minor computations).


* Added ""close how?"" parameter to storeClose() and friends.

The old code would follow the same path when closing swapout activity
for an aborted entry and when completing a perfectly healthy swapout. In
non-shared case, that could have been OK because the abort code would
then release the entry, removing any half-written entry from the index
and the disk (but I am not sure that release happened fast enough in
100% of cases).

When the index and disk storage is shared among workers, such
""temporary"" inconsistencies result in truncated responses being
delivered by other workers to the user because once the swapout activity
is closed, other workers can start using the entry.

By adding the ""close how?"" parameter to closing methods we allow the
core and SwapDir-specific code to handle aborted swapouts appropriately.

Since swapin code is ""read only"", we do not currently distinguish
between aborted and fully satisfied readers: The readerGone enum value
applies to both cases. If needed, the SwapDir reading code can make that
distinction by analyzing how much was actually swapped in.


* Moved ""can you store this entry?"" code to virtual SwapDir::canStore().

The old code had some of the tests in SwapDir-specific canStore()
methods and some in storeDirSelect*() methods. This resulted in
inconsistencies, code duplication, and extra calculation overheads.
Making this call virtual allows individual cache_dir types to do custom
access controls.

The same method is used for cache_dir load reporting (if it returns
true). Load management needs more work, but the current code is no worse
than the old one in this aspect, and further improvements are outside
this change scope.


* Minimized from-disk StoreEntry loading/unpacking code duplication.

Moved common (and often rather complex!) code from store modules into
storeRebuildLoadEntry, storeRebuildParseEntry, and storeRebuildKeepEntry.


* Do not set object_sz when the entry is aborted because the true object
size (HTTP reply headers + body) is not known in this case. Setting
object_sz may fool client-side code into believing that the object is
complete.

This addresses an old RBC's complaint.


* When swapout initiation fails, mark swapout decision as
MemObject::SwapOut::swImpossible. This prevents the caller code from trying to
swap out again and again because swap_status becomes SWAPOUT_NONE.

TODO: Consider add SWAPOUT_ERROR, STORE_ERROR, and similar states. It
may solve several problems where the code sees _NONE or _OK and thinks
everything is peachy when in fact there was an error.


* Call haveParsedReplyHeaders() before entry->replaceHttpReply().

HaveParsedReplyHeaders() sets the entry public key and various flags (at 
least). ReplaceHttpReply() packs reply headers, starting swapout process.
It feels natural to adjust the entry _before_ we pack/swap it, but I may be
missing some side-effects here.

The change was necessary because we started calling checkCachable() from
swapoutPossible(). If haveParsedReplyHeaders() is not called before we swap
out checks, the entry will still have the private key and will be declared
impossible to cache.


* Extracted the write-to-store step from StoreEntry::replaceHttpReply().

This allows the caller to set the reply for the entry and then update the
entry and the reply before writing them to store. For example, the server-side
haveParsedReplyHeaders() code needs to set the entry timestamps and make the
entry key public before the entry starts swapping out, but the same code also
needs access to entry->getReply() and such for timestampsSet() and similar
code to work correctly.

TODO: Calls to StoreEntry::replaceHttpReply() do not have to be modified
because replaceHttpReply() does write by default. However, it is likely that
callers other than ServerStateData::setFinalReply() should take advantage of
the new split interface because they call timestampsSet() and such after
replaceHttpReply().


* Moved SwapDir::cur_size and n_disk_objects to specific SwapDirs. Removed
updateSize().  Some cache_dirs maintain their own maps and size statistics,
making the one-size-fits-all SwapDir members inappropriate.

* A new SwapDir public method swappedOut() added. It is called from
storeSwapOutFileClosed() to notify SwapDir that an object was swapped
out.

* Change SwapDir::max_size to bytes, make it protected, use maxSize() instead.

Change SwapDir::cur_size to bytes, make it private, use currentSize() instead.

Store Config.Store.avgObjectSize in bytes to avoid repeated and error-prone
KB<->bytes conversions.


* Change Config.cacheSwap.swapDirs and StoreEntry::store() type to SwapDir.

This allows using SwapDir API without dynamic_cast.


* Always call StoreEntry::abort() instead of setting ENTRY_ABORTED manually.

* Rely on entry->abort() side-effects if ENTRY_ABORTED was set.

* Added or updated comments to better document current code.

* Added operator << for dumping StoreEntry summary into the debugging
log. Needs more work to report more info (and not report yet-unknown info).

* Fixed blocking reads that were sometimes reading from random file offsets.

Core ""disk file"" reading code assumed that if the globally stored disk.offset
matches the desired offset, there is no reason to seek. This was probably done
to reduce seek overhead between consecutive reads. Unfortunately, the disk
writing code did not know about that optimization and left F->disk.offset
unchanged after writing.

This may have worked OK for UFS if it never writes to the file it reads from,
but it does not work for store modules that do both kinds of I/O at different
offsets of the same disk file.

Eventually, implement this optimization correctly or remove disk.offset.


IPC primitives
--------------

To make SMP disk and memory caching non-blocking and correct, worker and
disker processes must asynchronously communicate with each other. We are
adding a collection of classes that support such communication.

At the base of the collection is the AtomicWordT template that uses GCC atomic
primitives such as __sync_add_and_fetch() to perform atomic operations on
integral values in memory shared by multiple Squid kids. AtomicWordT is used
to implement non-blocking shared locks, queues, store tables, and page pools.

To avoid blocking or very long searches, many operations are ""optimistic"" in
nature. For example, it is possible that an atomic store map will refuse to
allocate an entry for two processes even though a blocking implementation
would have allowed one of the processes to get the map slot. We speculate that
such conflict resolution is better than blocking locks when it comes to
caching, especially if the conflicts are rare due to large number of cache
entries, fast operations, and relatively small number of kids.


TODO: Eventually, consider breaking locks left by dead kids.



Shared Memory Cache
-------------------

* Added initial shared memory cache implementation (MemStore).

The shared memory cache keeps its own compact index of cached entries using
extended Ipc::StoreMap class (MemStoreMap). The cache also strives to keep its
Root.get() results out of the store_table except during transit.

Eventually, the non-shared/local memory cache should also be implemented
using a MemStore-like class, I think. This will allow to clearly isolate
local from shared memory cache code.

Allow the user to explicitly disable shared memory caching in SMP mode via
memory_cache_shared to squid.conf. Report whether mem_cache is shared.

Disable shared memory caching by default if atomic operations are not
supported. Prohibit shared memory caching if atomic operations are not
supported.

TODO: Better limits/separation for cache and I/O shared memory pages.
Eventually, support shared memory caching of multi-page entries.


Rock Store
----------

Rock Store uses a single [large] database-style file per cache_dir to store
cached responses and metadata. This part of the design is similar to COSS.
Rock Store does not maintain or rely on swap.state ""log"" for recovery.
Instead, the database is scanned in the background to load entries when Squid
starts. Rock Store maintains its own index of cached entries and avoids global
store_table. All entries must be max-size or smaller.

In SMP mode, each Rock cache_dir is given a dedicated Kid processes called
""disker"". All SMP workers communicate with diskers to store misses and load
hits, using shared memory pages and atomic shared memory queues. Disker blocks
when doing disk I/O but workers do not. Any Diskers:Workers ratio is supported
so that the user can find and configure the optimal number of workers and
diskers for a given number of disks and CPU cores.

In non-SMP mode, should use good old blocking disk I/O, without any diskers,
but this has not been tested recently and probably needs more work.

Feature page: http://wiki.squid-cache.org/Features/RockStore

TODO: Disk rate limit to protect Squid from disk overload. More stats.
Multiple readers? Seek optimization? Remove known max-size requirement?",8765,data/crawl/squid/hunk_2459.cpp,,,data/crawl/squid/old_hunk_2459.cpp,data/crawl/squid/new_hunk_2459.cpp,29,9,"storeAppendPrintf(&output, ""Maximum Swap Size      : %""PRIu64"" KB\n"",
                      maxSize());","storeAppendPrintf(&output, ""Maximum Swap Size      : %""PRIu64"" KB\n"",
                      maxSize() >> 10);","[""addContent"", ""addVariable""]","[[], [""10""]]",[6272037681056609],6046,100080.0,2
https://github.com/squid-cache/squid/commit/35a1b223314eddb67b631cb0224d6e03a2360c77,13 Sep 2011,"SMP Caching: Core changes, IPC primitives, Shared memory cache, and Rock Store

Core changes
------------

* Added MemObject::expectedReplySize() and used it instead of object_sz.

When deciding whether an object with a known content length can be
swapped out, do not wait until the object is completely received and its
size (mem_obj->object_sz) becomes known (while asking the store to
recheck in vain with every incoming chunk). Instead, use the known
content length, if any, to make the decision.

This optimizes the common case where the complete object is eventually
received and swapped out, preventing accumulating potentially large
objects in RAM while waiting for the end of the response. Should not
affect objects with unknown content length.

Side-effect1: probably fixes several cases of unknowingly using negative
(unknown) mem_obj->object_sz in calculations. I added a few assertions
to double check some of the remaining object_sz/objectLen() uses.

Side-effect2: When expectedReplySize() is stored on disk as StoreEntry
metadata, it may help to detect truncated entries when the writer
process dies before completing the swapout.


* Removed mem->swapout.memnode in favor of mem->swapout.queue_offset.

The code used swapout.memnode pointer to keep track of the last page
that was swapped out. The code was semi-buggy because it could reset the
pointer to NULL if no new data came in before the call to doPages().
Perhaps the code relied on the assumption that the caller will never
doPages if there is no new data, but I am not sure that assumption was
correct in all cases (it could be that I broke the calling code, of course).

Moreover, the page pointer was kept without any protection from page
disappearing during asynchronous swapout. There were ""Evil hack time""
comments discussing how the page might disappear.

Fortunately, we already have mem->swapout.queue_offset that can be fed
to getBlockContainingLocation to find the page that needs to be swapped
out. There is no need to keep the page pointer around. The
queue_offset-based math is the same so we are not adding any overheads
by using that offset (in fact, we are removing some minor computations).


* Added ""close how?"" parameter to storeClose() and friends.

The old code would follow the same path when closing swapout activity
for an aborted entry and when completing a perfectly healthy swapout. In
non-shared case, that could have been OK because the abort code would
then release the entry, removing any half-written entry from the index
and the disk (but I am not sure that release happened fast enough in
100% of cases).

When the index and disk storage is shared among workers, such
""temporary"" inconsistencies result in truncated responses being
delivered by other workers to the user because once the swapout activity
is closed, other workers can start using the entry.

By adding the ""close how?"" parameter to closing methods we allow the
core and SwapDir-specific code to handle aborted swapouts appropriately.

Since swapin code is ""read only"", we do not currently distinguish
between aborted and fully satisfied readers: The readerGone enum value
applies to both cases. If needed, the SwapDir reading code can make that
distinction by analyzing how much was actually swapped in.


* Moved ""can you store this entry?"" code to virtual SwapDir::canStore().

The old code had some of the tests in SwapDir-specific canStore()
methods and some in storeDirSelect*() methods. This resulted in
inconsistencies, code duplication, and extra calculation overheads.
Making this call virtual allows individual cache_dir types to do custom
access controls.

The same method is used for cache_dir load reporting (if it returns
true). Load management needs more work, but the current code is no worse
than the old one in this aspect, and further improvements are outside
this change scope.


* Minimized from-disk StoreEntry loading/unpacking code duplication.

Moved common (and often rather complex!) code from store modules into
storeRebuildLoadEntry, storeRebuildParseEntry, and storeRebuildKeepEntry.


* Do not set object_sz when the entry is aborted because the true object
size (HTTP reply headers + body) is not known in this case. Setting
object_sz may fool client-side code into believing that the object is
complete.

This addresses an old RBC's complaint.


* When swapout initiation fails, mark swapout decision as
MemObject::SwapOut::swImpossible. This prevents the caller code from trying to
swap out again and again because swap_status becomes SWAPOUT_NONE.

TODO: Consider add SWAPOUT_ERROR, STORE_ERROR, and similar states. It
may solve several problems where the code sees _NONE or _OK and thinks
everything is peachy when in fact there was an error.


* Call haveParsedReplyHeaders() before entry->replaceHttpReply().

HaveParsedReplyHeaders() sets the entry public key and various flags (at 
least). ReplaceHttpReply() packs reply headers, starting swapout process.
It feels natural to adjust the entry _before_ we pack/swap it, but I may be
missing some side-effects here.

The change was necessary because we started calling checkCachable() from
swapoutPossible(). If haveParsedReplyHeaders() is not called before we swap
out checks, the entry will still have the private key and will be declared
impossible to cache.


* Extracted the write-to-store step from StoreEntry::replaceHttpReply().

This allows the caller to set the reply for the entry and then update the
entry and the reply before writing them to store. For example, the server-side
haveParsedReplyHeaders() code needs to set the entry timestamps and make the
entry key public before the entry starts swapping out, but the same code also
needs access to entry->getReply() and such for timestampsSet() and similar
code to work correctly.

TODO: Calls to StoreEntry::replaceHttpReply() do not have to be modified
because replaceHttpReply() does write by default. However, it is likely that
callers other than ServerStateData::setFinalReply() should take advantage of
the new split interface because they call timestampsSet() and such after
replaceHttpReply().


* Moved SwapDir::cur_size and n_disk_objects to specific SwapDirs. Removed
updateSize().  Some cache_dirs maintain their own maps and size statistics,
making the one-size-fits-all SwapDir members inappropriate.

* A new SwapDir public method swappedOut() added. It is called from
storeSwapOutFileClosed() to notify SwapDir that an object was swapped
out.

* Change SwapDir::max_size to bytes, make it protected, use maxSize() instead.

Change SwapDir::cur_size to bytes, make it private, use currentSize() instead.

Store Config.Store.avgObjectSize in bytes to avoid repeated and error-prone
KB<->bytes conversions.


* Change Config.cacheSwap.swapDirs and StoreEntry::store() type to SwapDir.

This allows using SwapDir API without dynamic_cast.


* Always call StoreEntry::abort() instead of setting ENTRY_ABORTED manually.

* Rely on entry->abort() side-effects if ENTRY_ABORTED was set.

* Added or updated comments to better document current code.

* Added operator << for dumping StoreEntry summary into the debugging
log. Needs more work to report more info (and not report yet-unknown info).

* Fixed blocking reads that were sometimes reading from random file offsets.

Core ""disk file"" reading code assumed that if the globally stored disk.offset
matches the desired offset, there is no reason to seek. This was probably done
to reduce seek overhead between consecutive reads. Unfortunately, the disk
writing code did not know about that optimization and left F->disk.offset
unchanged after writing.

This may have worked OK for UFS if it never writes to the file it reads from,
but it does not work for store modules that do both kinds of I/O at different
offsets of the same disk file.

Eventually, implement this optimization correctly or remove disk.offset.


IPC primitives
--------------

To make SMP disk and memory caching non-blocking and correct, worker and
disker processes must asynchronously communicate with each other. We are
adding a collection of classes that support such communication.

At the base of the collection is the AtomicWordT template that uses GCC atomic
primitives such as __sync_add_and_fetch() to perform atomic operations on
integral values in memory shared by multiple Squid kids. AtomicWordT is used
to implement non-blocking shared locks, queues, store tables, and page pools.

To avoid blocking or very long searches, many operations are ""optimistic"" in
nature. For example, it is possible that an atomic store map will refuse to
allocate an entry for two processes even though a blocking implementation
would have allowed one of the processes to get the map slot. We speculate that
such conflict resolution is better than blocking locks when it comes to
caching, especially if the conflicts are rare due to large number of cache
entries, fast operations, and relatively small number of kids.


TODO: Eventually, consider breaking locks left by dead kids.



Shared Memory Cache
-------------------

* Added initial shared memory cache implementation (MemStore).

The shared memory cache keeps its own compact index of cached entries using
extended Ipc::StoreMap class (MemStoreMap). The cache also strives to keep its
Root.get() results out of the store_table except during transit.

Eventually, the non-shared/local memory cache should also be implemented
using a MemStore-like class, I think. This will allow to clearly isolate
local from shared memory cache code.

Allow the user to explicitly disable shared memory caching in SMP mode via
memory_cache_shared to squid.conf. Report whether mem_cache is shared.

Disable shared memory caching by default if atomic operations are not
supported. Prohibit shared memory caching if atomic operations are not
supported.

TODO: Better limits/separation for cache and I/O shared memory pages.
Eventually, support shared memory caching of multi-page entries.


Rock Store
----------

Rock Store uses a single [large] database-style file per cache_dir to store
cached responses and metadata. This part of the design is similar to COSS.
Rock Store does not maintain or rely on swap.state ""log"" for recovery.
Instead, the database is scanned in the background to load entries when Squid
starts. Rock Store maintains its own index of cached entries and avoids global
store_table. All entries must be max-size or smaller.

In SMP mode, each Rock cache_dir is given a dedicated Kid processes called
""disker"". All SMP workers communicate with diskers to store misses and load
hits, using shared memory pages and atomic shared memory queues. Disker blocks
when doing disk I/O but workers do not. Any Diskers:Workers ratio is supported
so that the user can find and configure the optimal number of workers and
diskers for a given number of disks and CPU cores.

In non-SMP mode, should use good old blocking disk I/O, without any diskers,
but this has not been tested recently and probably needs more work.

Feature page: http://wiki.squid-cache.org/Features/RockStore

TODO: Disk rate limit to protect Squid from disk overload. More stats.
Multiple readers? Seek optimization? Remove known max-size requirement?",8765,data/crawl/squid/hunk_2459.cpp,,,data/crawl/squid/old_hunk_2459.cpp,data/crawl/squid/new_hunk_2459.cpp,6,-1,"fatal(""StoreController has no independent size\n"");",,"[""removeLog""]","[[""fatal"", ""StoreController"", ""has"", ""no"", ""independent"", ""size\\n""], []]",[17146783349596625227],6045,100080.0,2
https://github.com/squid-cache/squid/commit/35a1b223314eddb67b631cb0224d6e03a2360c77,13 Sep 2011,"SMP Caching: Core changes, IPC primitives, Shared memory cache, and Rock Store

Core changes
------------

* Added MemObject::expectedReplySize() and used it instead of object_sz.

When deciding whether an object with a known content length can be
swapped out, do not wait until the object is completely received and its
size (mem_obj->object_sz) becomes known (while asking the store to
recheck in vain with every incoming chunk). Instead, use the known
content length, if any, to make the decision.

This optimizes the common case where the complete object is eventually
received and swapped out, preventing accumulating potentially large
objects in RAM while waiting for the end of the response. Should not
affect objects with unknown content length.

Side-effect1: probably fixes several cases of unknowingly using negative
(unknown) mem_obj->object_sz in calculations. I added a few assertions
to double check some of the remaining object_sz/objectLen() uses.

Side-effect2: When expectedReplySize() is stored on disk as StoreEntry
metadata, it may help to detect truncated entries when the writer
process dies before completing the swapout.


* Removed mem->swapout.memnode in favor of mem->swapout.queue_offset.

The code used swapout.memnode pointer to keep track of the last page
that was swapped out. The code was semi-buggy because it could reset the
pointer to NULL if no new data came in before the call to doPages().
Perhaps the code relied on the assumption that the caller will never
doPages if there is no new data, but I am not sure that assumption was
correct in all cases (it could be that I broke the calling code, of course).

Moreover, the page pointer was kept without any protection from page
disappearing during asynchronous swapout. There were ""Evil hack time""
comments discussing how the page might disappear.

Fortunately, we already have mem->swapout.queue_offset that can be fed
to getBlockContainingLocation to find the page that needs to be swapped
out. There is no need to keep the page pointer around. The
queue_offset-based math is the same so we are not adding any overheads
by using that offset (in fact, we are removing some minor computations).


* Added ""close how?"" parameter to storeClose() and friends.

The old code would follow the same path when closing swapout activity
for an aborted entry and when completing a perfectly healthy swapout. In
non-shared case, that could have been OK because the abort code would
then release the entry, removing any half-written entry from the index
and the disk (but I am not sure that release happened fast enough in
100% of cases).

When the index and disk storage is shared among workers, such
""temporary"" inconsistencies result in truncated responses being
delivered by other workers to the user because once the swapout activity
is closed, other workers can start using the entry.

By adding the ""close how?"" parameter to closing methods we allow the
core and SwapDir-specific code to handle aborted swapouts appropriately.

Since swapin code is ""read only"", we do not currently distinguish
between aborted and fully satisfied readers: The readerGone enum value
applies to both cases. If needed, the SwapDir reading code can make that
distinction by analyzing how much was actually swapped in.


* Moved ""can you store this entry?"" code to virtual SwapDir::canStore().

The old code had some of the tests in SwapDir-specific canStore()
methods and some in storeDirSelect*() methods. This resulted in
inconsistencies, code duplication, and extra calculation overheads.
Making this call virtual allows individual cache_dir types to do custom
access controls.

The same method is used for cache_dir load reporting (if it returns
true). Load management needs more work, but the current code is no worse
than the old one in this aspect, and further improvements are outside
this change scope.


* Minimized from-disk StoreEntry loading/unpacking code duplication.

Moved common (and often rather complex!) code from store modules into
storeRebuildLoadEntry, storeRebuildParseEntry, and storeRebuildKeepEntry.


* Do not set object_sz when the entry is aborted because the true object
size (HTTP reply headers + body) is not known in this case. Setting
object_sz may fool client-side code into believing that the object is
complete.

This addresses an old RBC's complaint.


* When swapout initiation fails, mark swapout decision as
MemObject::SwapOut::swImpossible. This prevents the caller code from trying to
swap out again and again because swap_status becomes SWAPOUT_NONE.

TODO: Consider add SWAPOUT_ERROR, STORE_ERROR, and similar states. It
may solve several problems where the code sees _NONE or _OK and thinks
everything is peachy when in fact there was an error.


* Call haveParsedReplyHeaders() before entry->replaceHttpReply().

HaveParsedReplyHeaders() sets the entry public key and various flags (at 
least). ReplaceHttpReply() packs reply headers, starting swapout process.
It feels natural to adjust the entry _before_ we pack/swap it, but I may be
missing some side-effects here.

The change was necessary because we started calling checkCachable() from
swapoutPossible(). If haveParsedReplyHeaders() is not called before we swap
out checks, the entry will still have the private key and will be declared
impossible to cache.


* Extracted the write-to-store step from StoreEntry::replaceHttpReply().

This allows the caller to set the reply for the entry and then update the
entry and the reply before writing them to store. For example, the server-side
haveParsedReplyHeaders() code needs to set the entry timestamps and make the
entry key public before the entry starts swapping out, but the same code also
needs access to entry->getReply() and such for timestampsSet() and similar
code to work correctly.

TODO: Calls to StoreEntry::replaceHttpReply() do not have to be modified
because replaceHttpReply() does write by default. However, it is likely that
callers other than ServerStateData::setFinalReply() should take advantage of
the new split interface because they call timestampsSet() and such after
replaceHttpReply().


* Moved SwapDir::cur_size and n_disk_objects to specific SwapDirs. Removed
updateSize().  Some cache_dirs maintain their own maps and size statistics,
making the one-size-fits-all SwapDir members inappropriate.

* A new SwapDir public method swappedOut() added. It is called from
storeSwapOutFileClosed() to notify SwapDir that an object was swapped
out.

* Change SwapDir::max_size to bytes, make it protected, use maxSize() instead.

Change SwapDir::cur_size to bytes, make it private, use currentSize() instead.

Store Config.Store.avgObjectSize in bytes to avoid repeated and error-prone
KB<->bytes conversions.


* Change Config.cacheSwap.swapDirs and StoreEntry::store() type to SwapDir.

This allows using SwapDir API without dynamic_cast.


* Always call StoreEntry::abort() instead of setting ENTRY_ABORTED manually.

* Rely on entry->abort() side-effects if ENTRY_ABORTED was set.

* Added or updated comments to better document current code.

* Added operator << for dumping StoreEntry summary into the debugging
log. Needs more work to report more info (and not report yet-unknown info).

* Fixed blocking reads that were sometimes reading from random file offsets.

Core ""disk file"" reading code assumed that if the globally stored disk.offset
matches the desired offset, there is no reason to seek. This was probably done
to reduce seek overhead between consecutive reads. Unfortunately, the disk
writing code did not know about that optimization and left F->disk.offset
unchanged after writing.

This may have worked OK for UFS if it never writes to the file it reads from,
but it does not work for store modules that do both kinds of I/O at different
offsets of the same disk file.

Eventually, implement this optimization correctly or remove disk.offset.


IPC primitives
--------------

To make SMP disk and memory caching non-blocking and correct, worker and
disker processes must asynchronously communicate with each other. We are
adding a collection of classes that support such communication.

At the base of the collection is the AtomicWordT template that uses GCC atomic
primitives such as __sync_add_and_fetch() to perform atomic operations on
integral values in memory shared by multiple Squid kids. AtomicWordT is used
to implement non-blocking shared locks, queues, store tables, and page pools.

To avoid blocking or very long searches, many operations are ""optimistic"" in
nature. For example, it is possible that an atomic store map will refuse to
allocate an entry for two processes even though a blocking implementation
would have allowed one of the processes to get the map slot. We speculate that
such conflict resolution is better than blocking locks when it comes to
caching, especially if the conflicts are rare due to large number of cache
entries, fast operations, and relatively small number of kids.


TODO: Eventually, consider breaking locks left by dead kids.



Shared Memory Cache
-------------------

* Added initial shared memory cache implementation (MemStore).

The shared memory cache keeps its own compact index of cached entries using
extended Ipc::StoreMap class (MemStoreMap). The cache also strives to keep its
Root.get() results out of the store_table except during transit.

Eventually, the non-shared/local memory cache should also be implemented
using a MemStore-like class, I think. This will allow to clearly isolate
local from shared memory cache code.

Allow the user to explicitly disable shared memory caching in SMP mode via
memory_cache_shared to squid.conf. Report whether mem_cache is shared.

Disable shared memory caching by default if atomic operations are not
supported. Prohibit shared memory caching if atomic operations are not
supported.

TODO: Better limits/separation for cache and I/O shared memory pages.
Eventually, support shared memory caching of multi-page entries.


Rock Store
----------

Rock Store uses a single [large] database-style file per cache_dir to store
cached responses and metadata. This part of the design is similar to COSS.
Rock Store does not maintain or rely on swap.state ""log"" for recovery.
Instead, the database is scanned in the background to load entries when Squid
starts. Rock Store maintains its own index of cached entries and avoids global
store_table. All entries must be max-size or smaller.

In SMP mode, each Rock cache_dir is given a dedicated Kid processes called
""disker"". All SMP workers communicate with diskers to store misses and load
hits, using shared memory pages and atomic shared memory queues. Disker blocks
when doing disk I/O but workers do not. Any Diskers:Workers ratio is supported
so that the user can find and configure the optimal number of workers and
diskers for a given number of disks and CPU cores.

In non-SMP mode, should use good old blocking disk I/O, without any diskers,
but this has not been tested recently and probably needs more work.

Feature page: http://wiki.squid-cache.org/Features/RockStore

TODO: Disk rate limit to protect Squid from disk overload. More stats.
Multiple readers? Seek optimization? Remove known max-size requirement?",8765,data/crawl/squid/hunk_2453.cpp,,,data/crawl/squid/old_hunk_2453.cpp,data/crawl/squid/new_hunk_2453.cpp,-1,93,,"storeAppendPrintf(&e, ""Writers:         %9d %6.2f%%\n"",
                          writers, (100.0 * writers / locked));","[""addLog""]","[[], [""storeAppendPrintf"", ""&e"", ""Writers"", ""%9d"", ""%6"", ""2f%%\\n"", ""writers"", ""100"", ""0"", ""*"", ""writers"", ""/"", ""locked""]]",[-6087512155400589293],6044,113040.0,2
https://github.com/squid-cache/squid/commit/35a1b223314eddb67b631cb0224d6e03a2360c77,13 Sep 2011,"SMP Caching: Core changes, IPC primitives, Shared memory cache, and Rock Store

Core changes
------------

* Added MemObject::expectedReplySize() and used it instead of object_sz.

When deciding whether an object with a known content length can be
swapped out, do not wait until the object is completely received and its
size (mem_obj->object_sz) becomes known (while asking the store to
recheck in vain with every incoming chunk). Instead, use the known
content length, if any, to make the decision.

This optimizes the common case where the complete object is eventually
received and swapped out, preventing accumulating potentially large
objects in RAM while waiting for the end of the response. Should not
affect objects with unknown content length.

Side-effect1: probably fixes several cases of unknowingly using negative
(unknown) mem_obj->object_sz in calculations. I added a few assertions
to double check some of the remaining object_sz/objectLen() uses.

Side-effect2: When expectedReplySize() is stored on disk as StoreEntry
metadata, it may help to detect truncated entries when the writer
process dies before completing the swapout.


* Removed mem->swapout.memnode in favor of mem->swapout.queue_offset.

The code used swapout.memnode pointer to keep track of the last page
that was swapped out. The code was semi-buggy because it could reset the
pointer to NULL if no new data came in before the call to doPages().
Perhaps the code relied on the assumption that the caller will never
doPages if there is no new data, but I am not sure that assumption was
correct in all cases (it could be that I broke the calling code, of course).

Moreover, the page pointer was kept without any protection from page
disappearing during asynchronous swapout. There were ""Evil hack time""
comments discussing how the page might disappear.

Fortunately, we already have mem->swapout.queue_offset that can be fed
to getBlockContainingLocation to find the page that needs to be swapped
out. There is no need to keep the page pointer around. The
queue_offset-based math is the same so we are not adding any overheads
by using that offset (in fact, we are removing some minor computations).


* Added ""close how?"" parameter to storeClose() and friends.

The old code would follow the same path when closing swapout activity
for an aborted entry and when completing a perfectly healthy swapout. In
non-shared case, that could have been OK because the abort code would
then release the entry, removing any half-written entry from the index
and the disk (but I am not sure that release happened fast enough in
100% of cases).

When the index and disk storage is shared among workers, such
""temporary"" inconsistencies result in truncated responses being
delivered by other workers to the user because once the swapout activity
is closed, other workers can start using the entry.

By adding the ""close how?"" parameter to closing methods we allow the
core and SwapDir-specific code to handle aborted swapouts appropriately.

Since swapin code is ""read only"", we do not currently distinguish
between aborted and fully satisfied readers: The readerGone enum value
applies to both cases. If needed, the SwapDir reading code can make that
distinction by analyzing how much was actually swapped in.


* Moved ""can you store this entry?"" code to virtual SwapDir::canStore().

The old code had some of the tests in SwapDir-specific canStore()
methods and some in storeDirSelect*() methods. This resulted in
inconsistencies, code duplication, and extra calculation overheads.
Making this call virtual allows individual cache_dir types to do custom
access controls.

The same method is used for cache_dir load reporting (if it returns
true). Load management needs more work, but the current code is no worse
than the old one in this aspect, and further improvements are outside
this change scope.


* Minimized from-disk StoreEntry loading/unpacking code duplication.

Moved common (and often rather complex!) code from store modules into
storeRebuildLoadEntry, storeRebuildParseEntry, and storeRebuildKeepEntry.


* Do not set object_sz when the entry is aborted because the true object
size (HTTP reply headers + body) is not known in this case. Setting
object_sz may fool client-side code into believing that the object is
complete.

This addresses an old RBC's complaint.


* When swapout initiation fails, mark swapout decision as
MemObject::SwapOut::swImpossible. This prevents the caller code from trying to
swap out again and again because swap_status becomes SWAPOUT_NONE.

TODO: Consider add SWAPOUT_ERROR, STORE_ERROR, and similar states. It
may solve several problems where the code sees _NONE or _OK and thinks
everything is peachy when in fact there was an error.


* Call haveParsedReplyHeaders() before entry->replaceHttpReply().

HaveParsedReplyHeaders() sets the entry public key and various flags (at 
least). ReplaceHttpReply() packs reply headers, starting swapout process.
It feels natural to adjust the entry _before_ we pack/swap it, but I may be
missing some side-effects here.

The change was necessary because we started calling checkCachable() from
swapoutPossible(). If haveParsedReplyHeaders() is not called before we swap
out checks, the entry will still have the private key and will be declared
impossible to cache.


* Extracted the write-to-store step from StoreEntry::replaceHttpReply().

This allows the caller to set the reply for the entry and then update the
entry and the reply before writing them to store. For example, the server-side
haveParsedReplyHeaders() code needs to set the entry timestamps and make the
entry key public before the entry starts swapping out, but the same code also
needs access to entry->getReply() and such for timestampsSet() and similar
code to work correctly.

TODO: Calls to StoreEntry::replaceHttpReply() do not have to be modified
because replaceHttpReply() does write by default. However, it is likely that
callers other than ServerStateData::setFinalReply() should take advantage of
the new split interface because they call timestampsSet() and such after
replaceHttpReply().


* Moved SwapDir::cur_size and n_disk_objects to specific SwapDirs. Removed
updateSize().  Some cache_dirs maintain their own maps and size statistics,
making the one-size-fits-all SwapDir members inappropriate.

* A new SwapDir public method swappedOut() added. It is called from
storeSwapOutFileClosed() to notify SwapDir that an object was swapped
out.

* Change SwapDir::max_size to bytes, make it protected, use maxSize() instead.

Change SwapDir::cur_size to bytes, make it private, use currentSize() instead.

Store Config.Store.avgObjectSize in bytes to avoid repeated and error-prone
KB<->bytes conversions.


* Change Config.cacheSwap.swapDirs and StoreEntry::store() type to SwapDir.

This allows using SwapDir API without dynamic_cast.


* Always call StoreEntry::abort() instead of setting ENTRY_ABORTED manually.

* Rely on entry->abort() side-effects if ENTRY_ABORTED was set.

* Added or updated comments to better document current code.

* Added operator << for dumping StoreEntry summary into the debugging
log. Needs more work to report more info (and not report yet-unknown info).

* Fixed blocking reads that were sometimes reading from random file offsets.

Core ""disk file"" reading code assumed that if the globally stored disk.offset
matches the desired offset, there is no reason to seek. This was probably done
to reduce seek overhead between consecutive reads. Unfortunately, the disk
writing code did not know about that optimization and left F->disk.offset
unchanged after writing.

This may have worked OK for UFS if it never writes to the file it reads from,
but it does not work for store modules that do both kinds of I/O at different
offsets of the same disk file.

Eventually, implement this optimization correctly or remove disk.offset.


IPC primitives
--------------

To make SMP disk and memory caching non-blocking and correct, worker and
disker processes must asynchronously communicate with each other. We are
adding a collection of classes that support such communication.

At the base of the collection is the AtomicWordT template that uses GCC atomic
primitives such as __sync_add_and_fetch() to perform atomic operations on
integral values in memory shared by multiple Squid kids. AtomicWordT is used
to implement non-blocking shared locks, queues, store tables, and page pools.

To avoid blocking or very long searches, many operations are ""optimistic"" in
nature. For example, it is possible that an atomic store map will refuse to
allocate an entry for two processes even though a blocking implementation
would have allowed one of the processes to get the map slot. We speculate that
such conflict resolution is better than blocking locks when it comes to
caching, especially if the conflicts are rare due to large number of cache
entries, fast operations, and relatively small number of kids.


TODO: Eventually, consider breaking locks left by dead kids.



Shared Memory Cache
-------------------

* Added initial shared memory cache implementation (MemStore).

The shared memory cache keeps its own compact index of cached entries using
extended Ipc::StoreMap class (MemStoreMap). The cache also strives to keep its
Root.get() results out of the store_table except during transit.

Eventually, the non-shared/local memory cache should also be implemented
using a MemStore-like class, I think. This will allow to clearly isolate
local from shared memory cache code.

Allow the user to explicitly disable shared memory caching in SMP mode via
memory_cache_shared to squid.conf. Report whether mem_cache is shared.

Disable shared memory caching by default if atomic operations are not
supported. Prohibit shared memory caching if atomic operations are not
supported.

TODO: Better limits/separation for cache and I/O shared memory pages.
Eventually, support shared memory caching of multi-page entries.


Rock Store
----------

Rock Store uses a single [large] database-style file per cache_dir to store
cached responses and metadata. This part of the design is similar to COSS.
Rock Store does not maintain or rely on swap.state ""log"" for recovery.
Instead, the database is scanned in the background to load entries when Squid
starts. Rock Store maintains its own index of cached entries and avoids global
store_table. All entries must be max-size or smaller.

In SMP mode, each Rock cache_dir is given a dedicated Kid processes called
""disker"". All SMP workers communicate with diskers to store misses and load
hits, using shared memory pages and atomic shared memory queues. Disker blocks
when doing disk I/O but workers do not. Any Diskers:Workers ratio is supported
so that the user can find and configure the optimal number of workers and
diskers for a given number of disks and CPU cores.

In non-SMP mode, should use good old blocking disk I/O, without any diskers,
but this has not been tested recently and probably needs more work.

Feature page: http://wiki.squid-cache.org/Features/RockStore

TODO: Disk rate limit to protect Squid from disk overload. More stats.
Multiple readers? Seek optimization? Remove known max-size requirement?",8765,data/crawl/squid/hunk_2453.cpp,,,data/crawl/squid/old_hunk_2453.cpp,data/crawl/squid/new_hunk_2453.cpp,-1,91,,"storeAppendPrintf(&e, ""Readers:         %9d %6.2f%%\n"",
                          readers, (100.0 * readers / locked));","[""addLog""]","[[], [""storeAppendPrintf"", ""&e"", ""Readers"", ""%9d"", ""%6"", ""2f%%\\n"", ""readers"", ""100"", ""0"", ""*"", ""readers"", ""/"", ""locked""]]",[-3228385553864831633],6043,113040.0,2
https://github.com/squid-cache/squid/commit/35a1b223314eddb67b631cb0224d6e03a2360c77,13 Sep 2011,"SMP Caching: Core changes, IPC primitives, Shared memory cache, and Rock Store

Core changes
------------

* Added MemObject::expectedReplySize() and used it instead of object_sz.

When deciding whether an object with a known content length can be
swapped out, do not wait until the object is completely received and its
size (mem_obj->object_sz) becomes known (while asking the store to
recheck in vain with every incoming chunk). Instead, use the known
content length, if any, to make the decision.

This optimizes the common case where the complete object is eventually
received and swapped out, preventing accumulating potentially large
objects in RAM while waiting for the end of the response. Should not
affect objects with unknown content length.

Side-effect1: probably fixes several cases of unknowingly using negative
(unknown) mem_obj->object_sz in calculations. I added a few assertions
to double check some of the remaining object_sz/objectLen() uses.

Side-effect2: When expectedReplySize() is stored on disk as StoreEntry
metadata, it may help to detect truncated entries when the writer
process dies before completing the swapout.


* Removed mem->swapout.memnode in favor of mem->swapout.queue_offset.

The code used swapout.memnode pointer to keep track of the last page
that was swapped out. The code was semi-buggy because it could reset the
pointer to NULL if no new data came in before the call to doPages().
Perhaps the code relied on the assumption that the caller will never
doPages if there is no new data, but I am not sure that assumption was
correct in all cases (it could be that I broke the calling code, of course).

Moreover, the page pointer was kept without any protection from page
disappearing during asynchronous swapout. There were ""Evil hack time""
comments discussing how the page might disappear.

Fortunately, we already have mem->swapout.queue_offset that can be fed
to getBlockContainingLocation to find the page that needs to be swapped
out. There is no need to keep the page pointer around. The
queue_offset-based math is the same so we are not adding any overheads
by using that offset (in fact, we are removing some minor computations).


* Added ""close how?"" parameter to storeClose() and friends.

The old code would follow the same path when closing swapout activity
for an aborted entry and when completing a perfectly healthy swapout. In
non-shared case, that could have been OK because the abort code would
then release the entry, removing any half-written entry from the index
and the disk (but I am not sure that release happened fast enough in
100% of cases).

When the index and disk storage is shared among workers, such
""temporary"" inconsistencies result in truncated responses being
delivered by other workers to the user because once the swapout activity
is closed, other workers can start using the entry.

By adding the ""close how?"" parameter to closing methods we allow the
core and SwapDir-specific code to handle aborted swapouts appropriately.

Since swapin code is ""read only"", we do not currently distinguish
between aborted and fully satisfied readers: The readerGone enum value
applies to both cases. If needed, the SwapDir reading code can make that
distinction by analyzing how much was actually swapped in.


* Moved ""can you store this entry?"" code to virtual SwapDir::canStore().

The old code had some of the tests in SwapDir-specific canStore()
methods and some in storeDirSelect*() methods. This resulted in
inconsistencies, code duplication, and extra calculation overheads.
Making this call virtual allows individual cache_dir types to do custom
access controls.

The same method is used for cache_dir load reporting (if it returns
true). Load management needs more work, but the current code is no worse
than the old one in this aspect, and further improvements are outside
this change scope.


* Minimized from-disk StoreEntry loading/unpacking code duplication.

Moved common (and often rather complex!) code from store modules into
storeRebuildLoadEntry, storeRebuildParseEntry, and storeRebuildKeepEntry.


* Do not set object_sz when the entry is aborted because the true object
size (HTTP reply headers + body) is not known in this case. Setting
object_sz may fool client-side code into believing that the object is
complete.

This addresses an old RBC's complaint.


* When swapout initiation fails, mark swapout decision as
MemObject::SwapOut::swImpossible. This prevents the caller code from trying to
swap out again and again because swap_status becomes SWAPOUT_NONE.

TODO: Consider add SWAPOUT_ERROR, STORE_ERROR, and similar states. It
may solve several problems where the code sees _NONE or _OK and thinks
everything is peachy when in fact there was an error.


* Call haveParsedReplyHeaders() before entry->replaceHttpReply().

HaveParsedReplyHeaders() sets the entry public key and various flags (at 
least). ReplaceHttpReply() packs reply headers, starting swapout process.
It feels natural to adjust the entry _before_ we pack/swap it, but I may be
missing some side-effects here.

The change was necessary because we started calling checkCachable() from
swapoutPossible(). If haveParsedReplyHeaders() is not called before we swap
out checks, the entry will still have the private key and will be declared
impossible to cache.


* Extracted the write-to-store step from StoreEntry::replaceHttpReply().

This allows the caller to set the reply for the entry and then update the
entry and the reply before writing them to store. For example, the server-side
haveParsedReplyHeaders() code needs to set the entry timestamps and make the
entry key public before the entry starts swapping out, but the same code also
needs access to entry->getReply() and such for timestampsSet() and similar
code to work correctly.

TODO: Calls to StoreEntry::replaceHttpReply() do not have to be modified
because replaceHttpReply() does write by default. However, it is likely that
callers other than ServerStateData::setFinalReply() should take advantage of
the new split interface because they call timestampsSet() and such after
replaceHttpReply().


* Moved SwapDir::cur_size and n_disk_objects to specific SwapDirs. Removed
updateSize().  Some cache_dirs maintain their own maps and size statistics,
making the one-size-fits-all SwapDir members inappropriate.

* A new SwapDir public method swappedOut() added. It is called from
storeSwapOutFileClosed() to notify SwapDir that an object was swapped
out.

* Change SwapDir::max_size to bytes, make it protected, use maxSize() instead.

Change SwapDir::cur_size to bytes, make it private, use currentSize() instead.

Store Config.Store.avgObjectSize in bytes to avoid repeated and error-prone
KB<->bytes conversions.


* Change Config.cacheSwap.swapDirs and StoreEntry::store() type to SwapDir.

This allows using SwapDir API without dynamic_cast.


* Always call StoreEntry::abort() instead of setting ENTRY_ABORTED manually.

* Rely on entry->abort() side-effects if ENTRY_ABORTED was set.

* Added or updated comments to better document current code.

* Added operator << for dumping StoreEntry summary into the debugging
log. Needs more work to report more info (and not report yet-unknown info).

* Fixed blocking reads that were sometimes reading from random file offsets.

Core ""disk file"" reading code assumed that if the globally stored disk.offset
matches the desired offset, there is no reason to seek. This was probably done
to reduce seek overhead between consecutive reads. Unfortunately, the disk
writing code did not know about that optimization and left F->disk.offset
unchanged after writing.

This may have worked OK for UFS if it never writes to the file it reads from,
but it does not work for store modules that do both kinds of I/O at different
offsets of the same disk file.

Eventually, implement this optimization correctly or remove disk.offset.


IPC primitives
--------------

To make SMP disk and memory caching non-blocking and correct, worker and
disker processes must asynchronously communicate with each other. We are
adding a collection of classes that support such communication.

At the base of the collection is the AtomicWordT template that uses GCC atomic
primitives such as __sync_add_and_fetch() to perform atomic operations on
integral values in memory shared by multiple Squid kids. AtomicWordT is used
to implement non-blocking shared locks, queues, store tables, and page pools.

To avoid blocking or very long searches, many operations are ""optimistic"" in
nature. For example, it is possible that an atomic store map will refuse to
allocate an entry for two processes even though a blocking implementation
would have allowed one of the processes to get the map slot. We speculate that
such conflict resolution is better than blocking locks when it comes to
caching, especially if the conflicts are rare due to large number of cache
entries, fast operations, and relatively small number of kids.


TODO: Eventually, consider breaking locks left by dead kids.



Shared Memory Cache
-------------------

* Added initial shared memory cache implementation (MemStore).

The shared memory cache keeps its own compact index of cached entries using
extended Ipc::StoreMap class (MemStoreMap). The cache also strives to keep its
Root.get() results out of the store_table except during transit.

Eventually, the non-shared/local memory cache should also be implemented
using a MemStore-like class, I think. This will allow to clearly isolate
local from shared memory cache code.

Allow the user to explicitly disable shared memory caching in SMP mode via
memory_cache_shared to squid.conf. Report whether mem_cache is shared.

Disable shared memory caching by default if atomic operations are not
supported. Prohibit shared memory caching if atomic operations are not
supported.

TODO: Better limits/separation for cache and I/O shared memory pages.
Eventually, support shared memory caching of multi-page entries.


Rock Store
----------

Rock Store uses a single [large] database-style file per cache_dir to store
cached responses and metadata. This part of the design is similar to COSS.
Rock Store does not maintain or rely on swap.state ""log"" for recovery.
Instead, the database is scanned in the background to load entries when Squid
starts. Rock Store maintains its own index of cached entries and avoids global
store_table. All entries must be max-size or smaller.

In SMP mode, each Rock cache_dir is given a dedicated Kid processes called
""disker"". All SMP workers communicate with diskers to store misses and load
hits, using shared memory pages and atomic shared memory queues. Disker blocks
when doing disk I/O but workers do not. Any Diskers:Workers ratio is supported
so that the user can find and configure the optimal number of workers and
diskers for a given number of disks and CPU cores.

In non-SMP mode, should use good old blocking disk I/O, without any diskers,
but this has not been tested recently and probably needs more work.

Feature page: http://wiki.squid-cache.org/Features/RockStore

TODO: Disk rate limit to protect Squid from disk overload. More stats.
Multiple readers? Seek optimization? Remove known max-size requirement?",8765,data/crawl/squid/hunk_2453.cpp,,,data/crawl/squid/old_hunk_2453.cpp,data/crawl/squid/new_hunk_2453.cpp,-1,86,,"storeAppendPrintf(&e, ""Idle:    %9d %6.2f%%\n"",
                      idle, (100.0 * idle / count));","[""addLog""]","[[], [""storeAppendPrintf"", ""&e"", ""Idle"", ""%9d"", ""%6"", ""2f%%\\n"", ""idle"", ""100"", ""0"", ""*"", ""idle"", ""/"", ""count""]]",[-4306081015003892916],6042,113040.0,2
https://github.com/squid-cache/squid/commit/35a1b223314eddb67b631cb0224d6e03a2360c77,13 Sep 2011,"SMP Caching: Core changes, IPC primitives, Shared memory cache, and Rock Store

Core changes
------------

* Added MemObject::expectedReplySize() and used it instead of object_sz.

When deciding whether an object with a known content length can be
swapped out, do not wait until the object is completely received and its
size (mem_obj->object_sz) becomes known (while asking the store to
recheck in vain with every incoming chunk). Instead, use the known
content length, if any, to make the decision.

This optimizes the common case where the complete object is eventually
received and swapped out, preventing accumulating potentially large
objects in RAM while waiting for the end of the response. Should not
affect objects with unknown content length.

Side-effect1: probably fixes several cases of unknowingly using negative
(unknown) mem_obj->object_sz in calculations. I added a few assertions
to double check some of the remaining object_sz/objectLen() uses.

Side-effect2: When expectedReplySize() is stored on disk as StoreEntry
metadata, it may help to detect truncated entries when the writer
process dies before completing the swapout.


* Removed mem->swapout.memnode in favor of mem->swapout.queue_offset.

The code used swapout.memnode pointer to keep track of the last page
that was swapped out. The code was semi-buggy because it could reset the
pointer to NULL if no new data came in before the call to doPages().
Perhaps the code relied on the assumption that the caller will never
doPages if there is no new data, but I am not sure that assumption was
correct in all cases (it could be that I broke the calling code, of course).

Moreover, the page pointer was kept without any protection from page
disappearing during asynchronous swapout. There were ""Evil hack time""
comments discussing how the page might disappear.

Fortunately, we already have mem->swapout.queue_offset that can be fed
to getBlockContainingLocation to find the page that needs to be swapped
out. There is no need to keep the page pointer around. The
queue_offset-based math is the same so we are not adding any overheads
by using that offset (in fact, we are removing some minor computations).


* Added ""close how?"" parameter to storeClose() and friends.

The old code would follow the same path when closing swapout activity
for an aborted entry and when completing a perfectly healthy swapout. In
non-shared case, that could have been OK because the abort code would
then release the entry, removing any half-written entry from the index
and the disk (but I am not sure that release happened fast enough in
100% of cases).

When the index and disk storage is shared among workers, such
""temporary"" inconsistencies result in truncated responses being
delivered by other workers to the user because once the swapout activity
is closed, other workers can start using the entry.

By adding the ""close how?"" parameter to closing methods we allow the
core and SwapDir-specific code to handle aborted swapouts appropriately.

Since swapin code is ""read only"", we do not currently distinguish
between aborted and fully satisfied readers: The readerGone enum value
applies to both cases. If needed, the SwapDir reading code can make that
distinction by analyzing how much was actually swapped in.


* Moved ""can you store this entry?"" code to virtual SwapDir::canStore().

The old code had some of the tests in SwapDir-specific canStore()
methods and some in storeDirSelect*() methods. This resulted in
inconsistencies, code duplication, and extra calculation overheads.
Making this call virtual allows individual cache_dir types to do custom
access controls.

The same method is used for cache_dir load reporting (if it returns
true). Load management needs more work, but the current code is no worse
than the old one in this aspect, and further improvements are outside
this change scope.


* Minimized from-disk StoreEntry loading/unpacking code duplication.

Moved common (and often rather complex!) code from store modules into
storeRebuildLoadEntry, storeRebuildParseEntry, and storeRebuildKeepEntry.


* Do not set object_sz when the entry is aborted because the true object
size (HTTP reply headers + body) is not known in this case. Setting
object_sz may fool client-side code into believing that the object is
complete.

This addresses an old RBC's complaint.


* When swapout initiation fails, mark swapout decision as
MemObject::SwapOut::swImpossible. This prevents the caller code from trying to
swap out again and again because swap_status becomes SWAPOUT_NONE.

TODO: Consider add SWAPOUT_ERROR, STORE_ERROR, and similar states. It
may solve several problems where the code sees _NONE or _OK and thinks
everything is peachy when in fact there was an error.


* Call haveParsedReplyHeaders() before entry->replaceHttpReply().

HaveParsedReplyHeaders() sets the entry public key and various flags (at 
least). ReplaceHttpReply() packs reply headers, starting swapout process.
It feels natural to adjust the entry _before_ we pack/swap it, but I may be
missing some side-effects here.

The change was necessary because we started calling checkCachable() from
swapoutPossible(). If haveParsedReplyHeaders() is not called before we swap
out checks, the entry will still have the private key and will be declared
impossible to cache.


* Extracted the write-to-store step from StoreEntry::replaceHttpReply().

This allows the caller to set the reply for the entry and then update the
entry and the reply before writing them to store. For example, the server-side
haveParsedReplyHeaders() code needs to set the entry timestamps and make the
entry key public before the entry starts swapping out, but the same code also
needs access to entry->getReply() and such for timestampsSet() and similar
code to work correctly.

TODO: Calls to StoreEntry::replaceHttpReply() do not have to be modified
because replaceHttpReply() does write by default. However, it is likely that
callers other than ServerStateData::setFinalReply() should take advantage of
the new split interface because they call timestampsSet() and such after
replaceHttpReply().


* Moved SwapDir::cur_size and n_disk_objects to specific SwapDirs. Removed
updateSize().  Some cache_dirs maintain their own maps and size statistics,
making the one-size-fits-all SwapDir members inappropriate.

* A new SwapDir public method swappedOut() added. It is called from
storeSwapOutFileClosed() to notify SwapDir that an object was swapped
out.

* Change SwapDir::max_size to bytes, make it protected, use maxSize() instead.

Change SwapDir::cur_size to bytes, make it private, use currentSize() instead.

Store Config.Store.avgObjectSize in bytes to avoid repeated and error-prone
KB<->bytes conversions.


* Change Config.cacheSwap.swapDirs and StoreEntry::store() type to SwapDir.

This allows using SwapDir API without dynamic_cast.


* Always call StoreEntry::abort() instead of setting ENTRY_ABORTED manually.

* Rely on entry->abort() side-effects if ENTRY_ABORTED was set.

* Added or updated comments to better document current code.

* Added operator << for dumping StoreEntry summary into the debugging
log. Needs more work to report more info (and not report yet-unknown info).

* Fixed blocking reads that were sometimes reading from random file offsets.

Core ""disk file"" reading code assumed that if the globally stored disk.offset
matches the desired offset, there is no reason to seek. This was probably done
to reduce seek overhead between consecutive reads. Unfortunately, the disk
writing code did not know about that optimization and left F->disk.offset
unchanged after writing.

This may have worked OK for UFS if it never writes to the file it reads from,
but it does not work for store modules that do both kinds of I/O at different
offsets of the same disk file.

Eventually, implement this optimization correctly or remove disk.offset.


IPC primitives
--------------

To make SMP disk and memory caching non-blocking and correct, worker and
disker processes must asynchronously communicate with each other. We are
adding a collection of classes that support such communication.

At the base of the collection is the AtomicWordT template that uses GCC atomic
primitives such as __sync_add_and_fetch() to perform atomic operations on
integral values in memory shared by multiple Squid kids. AtomicWordT is used
to implement non-blocking shared locks, queues, store tables, and page pools.

To avoid blocking or very long searches, many operations are ""optimistic"" in
nature. For example, it is possible that an atomic store map will refuse to
allocate an entry for two processes even though a blocking implementation
would have allowed one of the processes to get the map slot. We speculate that
such conflict resolution is better than blocking locks when it comes to
caching, especially if the conflicts are rare due to large number of cache
entries, fast operations, and relatively small number of kids.


TODO: Eventually, consider breaking locks left by dead kids.



Shared Memory Cache
-------------------

* Added initial shared memory cache implementation (MemStore).

The shared memory cache keeps its own compact index of cached entries using
extended Ipc::StoreMap class (MemStoreMap). The cache also strives to keep its
Root.get() results out of the store_table except during transit.

Eventually, the non-shared/local memory cache should also be implemented
using a MemStore-like class, I think. This will allow to clearly isolate
local from shared memory cache code.

Allow the user to explicitly disable shared memory caching in SMP mode via
memory_cache_shared to squid.conf. Report whether mem_cache is shared.

Disable shared memory caching by default if atomic operations are not
supported. Prohibit shared memory caching if atomic operations are not
supported.

TODO: Better limits/separation for cache and I/O shared memory pages.
Eventually, support shared memory caching of multi-page entries.


Rock Store
----------

Rock Store uses a single [large] database-style file per cache_dir to store
cached responses and metadata. This part of the design is similar to COSS.
Rock Store does not maintain or rely on swap.state ""log"" for recovery.
Instead, the database is scanned in the background to load entries when Squid
starts. Rock Store maintains its own index of cached entries and avoids global
store_table. All entries must be max-size or smaller.

In SMP mode, each Rock cache_dir is given a dedicated Kid processes called
""disker"". All SMP workers communicate with diskers to store misses and load
hits, using shared memory pages and atomic shared memory queues. Disker blocks
when doing disk I/O but workers do not. Any Diskers:Workers ratio is supported
so that the user can find and configure the optimal number of workers and
diskers for a given number of disks and CPU cores.

In non-SMP mode, should use good old blocking disk I/O, without any diskers,
but this has not been tested recently and probably needs more work.

Feature page: http://wiki.squid-cache.org/Features/RockStore

TODO: Disk rate limit to protect Squid from disk overload. More stats.
Multiple readers? Seek optimization? Remove known max-size requirement?",8765,data/crawl/squid/hunk_2453.cpp,,,data/crawl/squid/old_hunk_2453.cpp,data/crawl/squid/new_hunk_2453.cpp,-1,84,,"storeAppendPrintf(&e, ""Writing: %9d %6.2f%%\n"",
                      writeable, (100.0 * writeable / count));","[""addLog""]","[[], [""storeAppendPrintf"", ""&e"", ""Writing"", ""%9d"", ""%6"", ""2f%%\\n"", ""writeable"", ""100"", ""0"", ""*"", ""writeable"", ""/"", ""count""]]",[28401356836327033253],6041,113040.0,2
https://github.com/squid-cache/squid/commit/35a1b223314eddb67b631cb0224d6e03a2360c77,13 Sep 2011,"SMP Caching: Core changes, IPC primitives, Shared memory cache, and Rock Store

Core changes
------------

* Added MemObject::expectedReplySize() and used it instead of object_sz.

When deciding whether an object with a known content length can be
swapped out, do not wait until the object is completely received and its
size (mem_obj->object_sz) becomes known (while asking the store to
recheck in vain with every incoming chunk). Instead, use the known
content length, if any, to make the decision.

This optimizes the common case where the complete object is eventually
received and swapped out, preventing accumulating potentially large
objects in RAM while waiting for the end of the response. Should not
affect objects with unknown content length.

Side-effect1: probably fixes several cases of unknowingly using negative
(unknown) mem_obj->object_sz in calculations. I added a few assertions
to double check some of the remaining object_sz/objectLen() uses.

Side-effect2: When expectedReplySize() is stored on disk as StoreEntry
metadata, it may help to detect truncated entries when the writer
process dies before completing the swapout.


* Removed mem->swapout.memnode in favor of mem->swapout.queue_offset.

The code used swapout.memnode pointer to keep track of the last page
that was swapped out. The code was semi-buggy because it could reset the
pointer to NULL if no new data came in before the call to doPages().
Perhaps the code relied on the assumption that the caller will never
doPages if there is no new data, but I am not sure that assumption was
correct in all cases (it could be that I broke the calling code, of course).

Moreover, the page pointer was kept without any protection from page
disappearing during asynchronous swapout. There were ""Evil hack time""
comments discussing how the page might disappear.

Fortunately, we already have mem->swapout.queue_offset that can be fed
to getBlockContainingLocation to find the page that needs to be swapped
out. There is no need to keep the page pointer around. The
queue_offset-based math is the same so we are not adding any overheads
by using that offset (in fact, we are removing some minor computations).


* Added ""close how?"" parameter to storeClose() and friends.

The old code would follow the same path when closing swapout activity
for an aborted entry and when completing a perfectly healthy swapout. In
non-shared case, that could have been OK because the abort code would
then release the entry, removing any half-written entry from the index
and the disk (but I am not sure that release happened fast enough in
100% of cases).

When the index and disk storage is shared among workers, such
""temporary"" inconsistencies result in truncated responses being
delivered by other workers to the user because once the swapout activity
is closed, other workers can start using the entry.

By adding the ""close how?"" parameter to closing methods we allow the
core and SwapDir-specific code to handle aborted swapouts appropriately.

Since swapin code is ""read only"", we do not currently distinguish
between aborted and fully satisfied readers: The readerGone enum value
applies to both cases. If needed, the SwapDir reading code can make that
distinction by analyzing how much was actually swapped in.


* Moved ""can you store this entry?"" code to virtual SwapDir::canStore().

The old code had some of the tests in SwapDir-specific canStore()
methods and some in storeDirSelect*() methods. This resulted in
inconsistencies, code duplication, and extra calculation overheads.
Making this call virtual allows individual cache_dir types to do custom
access controls.

The same method is used for cache_dir load reporting (if it returns
true). Load management needs more work, but the current code is no worse
than the old one in this aspect, and further improvements are outside
this change scope.


* Minimized from-disk StoreEntry loading/unpacking code duplication.

Moved common (and often rather complex!) code from store modules into
storeRebuildLoadEntry, storeRebuildParseEntry, and storeRebuildKeepEntry.


* Do not set object_sz when the entry is aborted because the true object
size (HTTP reply headers + body) is not known in this case. Setting
object_sz may fool client-side code into believing that the object is
complete.

This addresses an old RBC's complaint.


* When swapout initiation fails, mark swapout decision as
MemObject::SwapOut::swImpossible. This prevents the caller code from trying to
swap out again and again because swap_status becomes SWAPOUT_NONE.

TODO: Consider add SWAPOUT_ERROR, STORE_ERROR, and similar states. It
may solve several problems where the code sees _NONE or _OK and thinks
everything is peachy when in fact there was an error.


* Call haveParsedReplyHeaders() before entry->replaceHttpReply().

HaveParsedReplyHeaders() sets the entry public key and various flags (at 
least). ReplaceHttpReply() packs reply headers, starting swapout process.
It feels natural to adjust the entry _before_ we pack/swap it, but I may be
missing some side-effects here.

The change was necessary because we started calling checkCachable() from
swapoutPossible(). If haveParsedReplyHeaders() is not called before we swap
out checks, the entry will still have the private key and will be declared
impossible to cache.


* Extracted the write-to-store step from StoreEntry::replaceHttpReply().

This allows the caller to set the reply for the entry and then update the
entry and the reply before writing them to store. For example, the server-side
haveParsedReplyHeaders() code needs to set the entry timestamps and make the
entry key public before the entry starts swapping out, but the same code also
needs access to entry->getReply() and such for timestampsSet() and similar
code to work correctly.

TODO: Calls to StoreEntry::replaceHttpReply() do not have to be modified
because replaceHttpReply() does write by default. However, it is likely that
callers other than ServerStateData::setFinalReply() should take advantage of
the new split interface because they call timestampsSet() and such after
replaceHttpReply().


* Moved SwapDir::cur_size and n_disk_objects to specific SwapDirs. Removed
updateSize().  Some cache_dirs maintain their own maps and size statistics,
making the one-size-fits-all SwapDir members inappropriate.

* A new SwapDir public method swappedOut() added. It is called from
storeSwapOutFileClosed() to notify SwapDir that an object was swapped
out.

* Change SwapDir::max_size to bytes, make it protected, use maxSize() instead.

Change SwapDir::cur_size to bytes, make it private, use currentSize() instead.

Store Config.Store.avgObjectSize in bytes to avoid repeated and error-prone
KB<->bytes conversions.


* Change Config.cacheSwap.swapDirs and StoreEntry::store() type to SwapDir.

This allows using SwapDir API without dynamic_cast.


* Always call StoreEntry::abort() instead of setting ENTRY_ABORTED manually.

* Rely on entry->abort() side-effects if ENTRY_ABORTED was set.

* Added or updated comments to better document current code.

* Added operator << for dumping StoreEntry summary into the debugging
log. Needs more work to report more info (and not report yet-unknown info).

* Fixed blocking reads that were sometimes reading from random file offsets.

Core ""disk file"" reading code assumed that if the globally stored disk.offset
matches the desired offset, there is no reason to seek. This was probably done
to reduce seek overhead between consecutive reads. Unfortunately, the disk
writing code did not know about that optimization and left F->disk.offset
unchanged after writing.

This may have worked OK for UFS if it never writes to the file it reads from,
but it does not work for store modules that do both kinds of I/O at different
offsets of the same disk file.

Eventually, implement this optimization correctly or remove disk.offset.


IPC primitives
--------------

To make SMP disk and memory caching non-blocking and correct, worker and
disker processes must asynchronously communicate with each other. We are
adding a collection of classes that support such communication.

At the base of the collection is the AtomicWordT template that uses GCC atomic
primitives such as __sync_add_and_fetch() to perform atomic operations on
integral values in memory shared by multiple Squid kids. AtomicWordT is used
to implement non-blocking shared locks, queues, store tables, and page pools.

To avoid blocking or very long searches, many operations are ""optimistic"" in
nature. For example, it is possible that an atomic store map will refuse to
allocate an entry for two processes even though a blocking implementation
would have allowed one of the processes to get the map slot. We speculate that
such conflict resolution is better than blocking locks when it comes to
caching, especially if the conflicts are rare due to large number of cache
entries, fast operations, and relatively small number of kids.


TODO: Eventually, consider breaking locks left by dead kids.



Shared Memory Cache
-------------------

* Added initial shared memory cache implementation (MemStore).

The shared memory cache keeps its own compact index of cached entries using
extended Ipc::StoreMap class (MemStoreMap). The cache also strives to keep its
Root.get() results out of the store_table except during transit.

Eventually, the non-shared/local memory cache should also be implemented
using a MemStore-like class, I think. This will allow to clearly isolate
local from shared memory cache code.

Allow the user to explicitly disable shared memory caching in SMP mode via
memory_cache_shared to squid.conf. Report whether mem_cache is shared.

Disable shared memory caching by default if atomic operations are not
supported. Prohibit shared memory caching if atomic operations are not
supported.

TODO: Better limits/separation for cache and I/O shared memory pages.
Eventually, support shared memory caching of multi-page entries.


Rock Store
----------

Rock Store uses a single [large] database-style file per cache_dir to store
cached responses and metadata. This part of the design is similar to COSS.
Rock Store does not maintain or rely on swap.state ""log"" for recovery.
Instead, the database is scanned in the background to load entries when Squid
starts. Rock Store maintains its own index of cached entries and avoids global
store_table. All entries must be max-size or smaller.

In SMP mode, each Rock cache_dir is given a dedicated Kid processes called
""disker"". All SMP workers communicate with diskers to store misses and load
hits, using shared memory pages and atomic shared memory queues. Disker blocks
when doing disk I/O but workers do not. Any Diskers:Workers ratio is supported
so that the user can find and configure the optimal number of workers and
diskers for a given number of disks and CPU cores.

In non-SMP mode, should use good old blocking disk I/O, without any diskers,
but this has not been tested recently and probably needs more work.

Feature page: http://wiki.squid-cache.org/Features/RockStore

TODO: Disk rate limit to protect Squid from disk overload. More stats.
Multiple readers? Seek optimization? Remove known max-size requirement?",8765,data/crawl/squid/hunk_2453.cpp,,,data/crawl/squid/old_hunk_2453.cpp,data/crawl/squid/new_hunk_2453.cpp,-1,82,,"storeAppendPrintf(&e, ""Reading: %9d %6.2f%%\n"",
                      readable, (100.0 * readable / count));","[""addLog""]","[[], [""storeAppendPrintf"", ""&e"", ""Reading"", ""%9d"", ""%6"", ""2f%%\\n"", ""readable"", ""100"", ""0"", ""*"", ""readable"", ""/"", ""count""]]",[27701852635395074057],6040,113040.0,2
https://github.com/squid-cache/squid/commit/35a1b223314eddb67b631cb0224d6e03a2360c77,13 Sep 2011,"SMP Caching: Core changes, IPC primitives, Shared memory cache, and Rock Store

Core changes
------------

* Added MemObject::expectedReplySize() and used it instead of object_sz.

When deciding whether an object with a known content length can be
swapped out, do not wait until the object is completely received and its
size (mem_obj->object_sz) becomes known (while asking the store to
recheck in vain with every incoming chunk). Instead, use the known
content length, if any, to make the decision.

This optimizes the common case where the complete object is eventually
received and swapped out, preventing accumulating potentially large
objects in RAM while waiting for the end of the response. Should not
affect objects with unknown content length.

Side-effect1: probably fixes several cases of unknowingly using negative
(unknown) mem_obj->object_sz in calculations. I added a few assertions
to double check some of the remaining object_sz/objectLen() uses.

Side-effect2: When expectedReplySize() is stored on disk as StoreEntry
metadata, it may help to detect truncated entries when the writer
process dies before completing the swapout.


* Removed mem->swapout.memnode in favor of mem->swapout.queue_offset.

The code used swapout.memnode pointer to keep track of the last page
that was swapped out. The code was semi-buggy because it could reset the
pointer to NULL if no new data came in before the call to doPages().
Perhaps the code relied on the assumption that the caller will never
doPages if there is no new data, but I am not sure that assumption was
correct in all cases (it could be that I broke the calling code, of course).

Moreover, the page pointer was kept without any protection from page
disappearing during asynchronous swapout. There were ""Evil hack time""
comments discussing how the page might disappear.

Fortunately, we already have mem->swapout.queue_offset that can be fed
to getBlockContainingLocation to find the page that needs to be swapped
out. There is no need to keep the page pointer around. The
queue_offset-based math is the same so we are not adding any overheads
by using that offset (in fact, we are removing some minor computations).


* Added ""close how?"" parameter to storeClose() and friends.

The old code would follow the same path when closing swapout activity
for an aborted entry and when completing a perfectly healthy swapout. In
non-shared case, that could have been OK because the abort code would
then release the entry, removing any half-written entry from the index
and the disk (but I am not sure that release happened fast enough in
100% of cases).

When the index and disk storage is shared among workers, such
""temporary"" inconsistencies result in truncated responses being
delivered by other workers to the user because once the swapout activity
is closed, other workers can start using the entry.

By adding the ""close how?"" parameter to closing methods we allow the
core and SwapDir-specific code to handle aborted swapouts appropriately.

Since swapin code is ""read only"", we do not currently distinguish
between aborted and fully satisfied readers: The readerGone enum value
applies to both cases. If needed, the SwapDir reading code can make that
distinction by analyzing how much was actually swapped in.


* Moved ""can you store this entry?"" code to virtual SwapDir::canStore().

The old code had some of the tests in SwapDir-specific canStore()
methods and some in storeDirSelect*() methods. This resulted in
inconsistencies, code duplication, and extra calculation overheads.
Making this call virtual allows individual cache_dir types to do custom
access controls.

The same method is used for cache_dir load reporting (if it returns
true). Load management needs more work, but the current code is no worse
than the old one in this aspect, and further improvements are outside
this change scope.


* Minimized from-disk StoreEntry loading/unpacking code duplication.

Moved common (and often rather complex!) code from store modules into
storeRebuildLoadEntry, storeRebuildParseEntry, and storeRebuildKeepEntry.


* Do not set object_sz when the entry is aborted because the true object
size (HTTP reply headers + body) is not known in this case. Setting
object_sz may fool client-side code into believing that the object is
complete.

This addresses an old RBC's complaint.


* When swapout initiation fails, mark swapout decision as
MemObject::SwapOut::swImpossible. This prevents the caller code from trying to
swap out again and again because swap_status becomes SWAPOUT_NONE.

TODO: Consider add SWAPOUT_ERROR, STORE_ERROR, and similar states. It
may solve several problems where the code sees _NONE or _OK and thinks
everything is peachy when in fact there was an error.


* Call haveParsedReplyHeaders() before entry->replaceHttpReply().

HaveParsedReplyHeaders() sets the entry public key and various flags (at 
least). ReplaceHttpReply() packs reply headers, starting swapout process.
It feels natural to adjust the entry _before_ we pack/swap it, but I may be
missing some side-effects here.

The change was necessary because we started calling checkCachable() from
swapoutPossible(). If haveParsedReplyHeaders() is not called before we swap
out checks, the entry will still have the private key and will be declared
impossible to cache.


* Extracted the write-to-store step from StoreEntry::replaceHttpReply().

This allows the caller to set the reply for the entry and then update the
entry and the reply before writing them to store. For example, the server-side
haveParsedReplyHeaders() code needs to set the entry timestamps and make the
entry key public before the entry starts swapping out, but the same code also
needs access to entry->getReply() and such for timestampsSet() and similar
code to work correctly.

TODO: Calls to StoreEntry::replaceHttpReply() do not have to be modified
because replaceHttpReply() does write by default. However, it is likely that
callers other than ServerStateData::setFinalReply() should take advantage of
the new split interface because they call timestampsSet() and such after
replaceHttpReply().


* Moved SwapDir::cur_size and n_disk_objects to specific SwapDirs. Removed
updateSize().  Some cache_dirs maintain their own maps and size statistics,
making the one-size-fits-all SwapDir members inappropriate.

* A new SwapDir public method swappedOut() added. It is called from
storeSwapOutFileClosed() to notify SwapDir that an object was swapped
out.

* Change SwapDir::max_size to bytes, make it protected, use maxSize() instead.

Change SwapDir::cur_size to bytes, make it private, use currentSize() instead.

Store Config.Store.avgObjectSize in bytes to avoid repeated and error-prone
KB<->bytes conversions.


* Change Config.cacheSwap.swapDirs and StoreEntry::store() type to SwapDir.

This allows using SwapDir API without dynamic_cast.


* Always call StoreEntry::abort() instead of setting ENTRY_ABORTED manually.

* Rely on entry->abort() side-effects if ENTRY_ABORTED was set.

* Added or updated comments to better document current code.

* Added operator << for dumping StoreEntry summary into the debugging
log. Needs more work to report more info (and not report yet-unknown info).

* Fixed blocking reads that were sometimes reading from random file offsets.

Core ""disk file"" reading code assumed that if the globally stored disk.offset
matches the desired offset, there is no reason to seek. This was probably done
to reduce seek overhead between consecutive reads. Unfortunately, the disk
writing code did not know about that optimization and left F->disk.offset
unchanged after writing.

This may have worked OK for UFS if it never writes to the file it reads from,
but it does not work for store modules that do both kinds of I/O at different
offsets of the same disk file.

Eventually, implement this optimization correctly or remove disk.offset.


IPC primitives
--------------

To make SMP disk and memory caching non-blocking and correct, worker and
disker processes must asynchronously communicate with each other. We are
adding a collection of classes that support such communication.

At the base of the collection is the AtomicWordT template that uses GCC atomic
primitives such as __sync_add_and_fetch() to perform atomic operations on
integral values in memory shared by multiple Squid kids. AtomicWordT is used
to implement non-blocking shared locks, queues, store tables, and page pools.

To avoid blocking or very long searches, many operations are ""optimistic"" in
nature. For example, it is possible that an atomic store map will refuse to
allocate an entry for two processes even though a blocking implementation
would have allowed one of the processes to get the map slot. We speculate that
such conflict resolution is better than blocking locks when it comes to
caching, especially if the conflicts are rare due to large number of cache
entries, fast operations, and relatively small number of kids.


TODO: Eventually, consider breaking locks left by dead kids.



Shared Memory Cache
-------------------

* Added initial shared memory cache implementation (MemStore).

The shared memory cache keeps its own compact index of cached entries using
extended Ipc::StoreMap class (MemStoreMap). The cache also strives to keep its
Root.get() results out of the store_table except during transit.

Eventually, the non-shared/local memory cache should also be implemented
using a MemStore-like class, I think. This will allow to clearly isolate
local from shared memory cache code.

Allow the user to explicitly disable shared memory caching in SMP mode via
memory_cache_shared to squid.conf. Report whether mem_cache is shared.

Disable shared memory caching by default if atomic operations are not
supported. Prohibit shared memory caching if atomic operations are not
supported.

TODO: Better limits/separation for cache and I/O shared memory pages.
Eventually, support shared memory caching of multi-page entries.


Rock Store
----------

Rock Store uses a single [large] database-style file per cache_dir to store
cached responses and metadata. This part of the design is similar to COSS.
Rock Store does not maintain or rely on swap.state ""log"" for recovery.
Instead, the database is scanned in the background to load entries when Squid
starts. Rock Store maintains its own index of cached entries and avoids global
store_table. All entries must be max-size or smaller.

In SMP mode, each Rock cache_dir is given a dedicated Kid processes called
""disker"". All SMP workers communicate with diskers to store misses and load
hits, using shared memory pages and atomic shared memory queues. Disker blocks
when doing disk I/O but workers do not. Any Diskers:Workers ratio is supported
so that the user can find and configure the optimal number of workers and
diskers for a given number of disks and CPU cores.

In non-SMP mode, should use good old blocking disk I/O, without any diskers,
but this has not been tested recently and probably needs more work.

Feature page: http://wiki.squid-cache.org/Features/RockStore

TODO: Disk rate limit to protect Squid from disk overload. More stats.
Multiple readers? Seek optimization? Remove known max-size requirement?",8765,data/crawl/squid/hunk_2453.cpp,,,data/crawl/squid/old_hunk_2453.cpp,data/crawl/squid/new_hunk_2453.cpp,-1,77,,"storeAppendPrintf(&e, ""Available locks: %9d\n"", count);","[""addLog""]","[[], [""storeAppendPrintf"", ""&e"", ""Available"", ""locks"", ""%9d\\n"", ""count""]]",[10076423060490463942],6039,113040.0,2
https://github.com/squid-cache/squid/commit/35a1b223314eddb67b631cb0224d6e03a2360c77,13 Sep 2011,"SMP Caching: Core changes, IPC primitives, Shared memory cache, and Rock Store

Core changes
------------

* Added MemObject::expectedReplySize() and used it instead of object_sz.

When deciding whether an object with a known content length can be
swapped out, do not wait until the object is completely received and its
size (mem_obj->object_sz) becomes known (while asking the store to
recheck in vain with every incoming chunk). Instead, use the known
content length, if any, to make the decision.

This optimizes the common case where the complete object is eventually
received and swapped out, preventing accumulating potentially large
objects in RAM while waiting for the end of the response. Should not
affect objects with unknown content length.

Side-effect1: probably fixes several cases of unknowingly using negative
(unknown) mem_obj->object_sz in calculations. I added a few assertions
to double check some of the remaining object_sz/objectLen() uses.

Side-effect2: When expectedReplySize() is stored on disk as StoreEntry
metadata, it may help to detect truncated entries when the writer
process dies before completing the swapout.


* Removed mem->swapout.memnode in favor of mem->swapout.queue_offset.

The code used swapout.memnode pointer to keep track of the last page
that was swapped out. The code was semi-buggy because it could reset the
pointer to NULL if no new data came in before the call to doPages().
Perhaps the code relied on the assumption that the caller will never
doPages if there is no new data, but I am not sure that assumption was
correct in all cases (it could be that I broke the calling code, of course).

Moreover, the page pointer was kept without any protection from page
disappearing during asynchronous swapout. There were ""Evil hack time""
comments discussing how the page might disappear.

Fortunately, we already have mem->swapout.queue_offset that can be fed
to getBlockContainingLocation to find the page that needs to be swapped
out. There is no need to keep the page pointer around. The
queue_offset-based math is the same so we are not adding any overheads
by using that offset (in fact, we are removing some minor computations).


* Added ""close how?"" parameter to storeClose() and friends.

The old code would follow the same path when closing swapout activity
for an aborted entry and when completing a perfectly healthy swapout. In
non-shared case, that could have been OK because the abort code would
then release the entry, removing any half-written entry from the index
and the disk (but I am not sure that release happened fast enough in
100% of cases).

When the index and disk storage is shared among workers, such
""temporary"" inconsistencies result in truncated responses being
delivered by other workers to the user because once the swapout activity
is closed, other workers can start using the entry.

By adding the ""close how?"" parameter to closing methods we allow the
core and SwapDir-specific code to handle aborted swapouts appropriately.

Since swapin code is ""read only"", we do not currently distinguish
between aborted and fully satisfied readers: The readerGone enum value
applies to both cases. If needed, the SwapDir reading code can make that
distinction by analyzing how much was actually swapped in.


* Moved ""can you store this entry?"" code to virtual SwapDir::canStore().

The old code had some of the tests in SwapDir-specific canStore()
methods and some in storeDirSelect*() methods. This resulted in
inconsistencies, code duplication, and extra calculation overheads.
Making this call virtual allows individual cache_dir types to do custom
access controls.

The same method is used for cache_dir load reporting (if it returns
true). Load management needs more work, but the current code is no worse
than the old one in this aspect, and further improvements are outside
this change scope.


* Minimized from-disk StoreEntry loading/unpacking code duplication.

Moved common (and often rather complex!) code from store modules into
storeRebuildLoadEntry, storeRebuildParseEntry, and storeRebuildKeepEntry.


* Do not set object_sz when the entry is aborted because the true object
size (HTTP reply headers + body) is not known in this case. Setting
object_sz may fool client-side code into believing that the object is
complete.

This addresses an old RBC's complaint.


* When swapout initiation fails, mark swapout decision as
MemObject::SwapOut::swImpossible. This prevents the caller code from trying to
swap out again and again because swap_status becomes SWAPOUT_NONE.

TODO: Consider add SWAPOUT_ERROR, STORE_ERROR, and similar states. It
may solve several problems where the code sees _NONE or _OK and thinks
everything is peachy when in fact there was an error.


* Call haveParsedReplyHeaders() before entry->replaceHttpReply().

HaveParsedReplyHeaders() sets the entry public key and various flags (at 
least). ReplaceHttpReply() packs reply headers, starting swapout process.
It feels natural to adjust the entry _before_ we pack/swap it, but I may be
missing some side-effects here.

The change was necessary because we started calling checkCachable() from
swapoutPossible(). If haveParsedReplyHeaders() is not called before we swap
out checks, the entry will still have the private key and will be declared
impossible to cache.


* Extracted the write-to-store step from StoreEntry::replaceHttpReply().

This allows the caller to set the reply for the entry and then update the
entry and the reply before writing them to store. For example, the server-side
haveParsedReplyHeaders() code needs to set the entry timestamps and make the
entry key public before the entry starts swapping out, but the same code also
needs access to entry->getReply() and such for timestampsSet() and similar
code to work correctly.

TODO: Calls to StoreEntry::replaceHttpReply() do not have to be modified
because replaceHttpReply() does write by default. However, it is likely that
callers other than ServerStateData::setFinalReply() should take advantage of
the new split interface because they call timestampsSet() and such after
replaceHttpReply().


* Moved SwapDir::cur_size and n_disk_objects to specific SwapDirs. Removed
updateSize().  Some cache_dirs maintain their own maps and size statistics,
making the one-size-fits-all SwapDir members inappropriate.

* A new SwapDir public method swappedOut() added. It is called from
storeSwapOutFileClosed() to notify SwapDir that an object was swapped
out.

* Change SwapDir::max_size to bytes, make it protected, use maxSize() instead.

Change SwapDir::cur_size to bytes, make it private, use currentSize() instead.

Store Config.Store.avgObjectSize in bytes to avoid repeated and error-prone
KB<->bytes conversions.


* Change Config.cacheSwap.swapDirs and StoreEntry::store() type to SwapDir.

This allows using SwapDir API without dynamic_cast.


* Always call StoreEntry::abort() instead of setting ENTRY_ABORTED manually.

* Rely on entry->abort() side-effects if ENTRY_ABORTED was set.

* Added or updated comments to better document current code.

* Added operator << for dumping StoreEntry summary into the debugging
log. Needs more work to report more info (and not report yet-unknown info).

* Fixed blocking reads that were sometimes reading from random file offsets.

Core ""disk file"" reading code assumed that if the globally stored disk.offset
matches the desired offset, there is no reason to seek. This was probably done
to reduce seek overhead between consecutive reads. Unfortunately, the disk
writing code did not know about that optimization and left F->disk.offset
unchanged after writing.

This may have worked OK for UFS if it never writes to the file it reads from,
but it does not work for store modules that do both kinds of I/O at different
offsets of the same disk file.

Eventually, implement this optimization correctly or remove disk.offset.


IPC primitives
--------------

To make SMP disk and memory caching non-blocking and correct, worker and
disker processes must asynchronously communicate with each other. We are
adding a collection of classes that support such communication.

At the base of the collection is the AtomicWordT template that uses GCC atomic
primitives such as __sync_add_and_fetch() to perform atomic operations on
integral values in memory shared by multiple Squid kids. AtomicWordT is used
to implement non-blocking shared locks, queues, store tables, and page pools.

To avoid blocking or very long searches, many operations are ""optimistic"" in
nature. For example, it is possible that an atomic store map will refuse to
allocate an entry for two processes even though a blocking implementation
would have allowed one of the processes to get the map slot. We speculate that
such conflict resolution is better than blocking locks when it comes to
caching, especially if the conflicts are rare due to large number of cache
entries, fast operations, and relatively small number of kids.


TODO: Eventually, consider breaking locks left by dead kids.



Shared Memory Cache
-------------------

* Added initial shared memory cache implementation (MemStore).

The shared memory cache keeps its own compact index of cached entries using
extended Ipc::StoreMap class (MemStoreMap). The cache also strives to keep its
Root.get() results out of the store_table except during transit.

Eventually, the non-shared/local memory cache should also be implemented
using a MemStore-like class, I think. This will allow to clearly isolate
local from shared memory cache code.

Allow the user to explicitly disable shared memory caching in SMP mode via
memory_cache_shared to squid.conf. Report whether mem_cache is shared.

Disable shared memory caching by default if atomic operations are not
supported. Prohibit shared memory caching if atomic operations are not
supported.

TODO: Better limits/separation for cache and I/O shared memory pages.
Eventually, support shared memory caching of multi-page entries.


Rock Store
----------

Rock Store uses a single [large] database-style file per cache_dir to store
cached responses and metadata. This part of the design is similar to COSS.
Rock Store does not maintain or rely on swap.state ""log"" for recovery.
Instead, the database is scanned in the background to load entries when Squid
starts. Rock Store maintains its own index of cached entries and avoids global
store_table. All entries must be max-size or smaller.

In SMP mode, each Rock cache_dir is given a dedicated Kid processes called
""disker"". All SMP workers communicate with diskers to store misses and load
hits, using shared memory pages and atomic shared memory queues. Disker blocks
when doing disk I/O but workers do not. Any Diskers:Workers ratio is supported
so that the user can find and configure the optimal number of workers and
diskers for a given number of disks and CPU cores.

In non-SMP mode, should use good old blocking disk I/O, without any diskers,
but this has not been tested recently and probably needs more work.

Feature page: http://wiki.squid-cache.org/Features/RockStore

TODO: Disk rate limit to protect Squid from disk overload. More stats.
Multiple readers? Seek optimization? Remove known max-size requirement?",8765,data/crawl/squid/hunk_2452.cpp,,,data/crawl/squid/old_hunk_2452.cpp,data/crawl/squid/new_hunk_2452.cpp,3,3,"storeAppendPrintf(&entry, "" %""PRIu64"" %d %d"", (max_size >> 10), l1, l2);","storeAppendPrintf(&entry, "" %""PRIu64"" %d %d"", maxSize() >> 20, l1, l2);","[""removeVariable"", ""updateContent"", ""addVariable""]","[[""max_size"", ""10""], [""maxSize"", ""20""]]",[-3176076191504163305],6038,100080.0,2
https://github.com/squid-cache/squid/commit/35a1b223314eddb67b631cb0224d6e03a2360c77,13 Sep 2011,"SMP Caching: Core changes, IPC primitives, Shared memory cache, and Rock Store

Core changes
------------

* Added MemObject::expectedReplySize() and used it instead of object_sz.

When deciding whether an object with a known content length can be
swapped out, do not wait until the object is completely received and its
size (mem_obj->object_sz) becomes known (while asking the store to
recheck in vain with every incoming chunk). Instead, use the known
content length, if any, to make the decision.

This optimizes the common case where the complete object is eventually
received and swapped out, preventing accumulating potentially large
objects in RAM while waiting for the end of the response. Should not
affect objects with unknown content length.

Side-effect1: probably fixes several cases of unknowingly using negative
(unknown) mem_obj->object_sz in calculations. I added a few assertions
to double check some of the remaining object_sz/objectLen() uses.

Side-effect2: When expectedReplySize() is stored on disk as StoreEntry
metadata, it may help to detect truncated entries when the writer
process dies before completing the swapout.


* Removed mem->swapout.memnode in favor of mem->swapout.queue_offset.

The code used swapout.memnode pointer to keep track of the last page
that was swapped out. The code was semi-buggy because it could reset the
pointer to NULL if no new data came in before the call to doPages().
Perhaps the code relied on the assumption that the caller will never
doPages if there is no new data, but I am not sure that assumption was
correct in all cases (it could be that I broke the calling code, of course).

Moreover, the page pointer was kept without any protection from page
disappearing during asynchronous swapout. There were ""Evil hack time""
comments discussing how the page might disappear.

Fortunately, we already have mem->swapout.queue_offset that can be fed
to getBlockContainingLocation to find the page that needs to be swapped
out. There is no need to keep the page pointer around. The
queue_offset-based math is the same so we are not adding any overheads
by using that offset (in fact, we are removing some minor computations).


* Added ""close how?"" parameter to storeClose() and friends.

The old code would follow the same path when closing swapout activity
for an aborted entry and when completing a perfectly healthy swapout. In
non-shared case, that could have been OK because the abort code would
then release the entry, removing any half-written entry from the index
and the disk (but I am not sure that release happened fast enough in
100% of cases).

When the index and disk storage is shared among workers, such
""temporary"" inconsistencies result in truncated responses being
delivered by other workers to the user because once the swapout activity
is closed, other workers can start using the entry.

By adding the ""close how?"" parameter to closing methods we allow the
core and SwapDir-specific code to handle aborted swapouts appropriately.

Since swapin code is ""read only"", we do not currently distinguish
between aborted and fully satisfied readers: The readerGone enum value
applies to both cases. If needed, the SwapDir reading code can make that
distinction by analyzing how much was actually swapped in.


* Moved ""can you store this entry?"" code to virtual SwapDir::canStore().

The old code had some of the tests in SwapDir-specific canStore()
methods and some in storeDirSelect*() methods. This resulted in
inconsistencies, code duplication, and extra calculation overheads.
Making this call virtual allows individual cache_dir types to do custom
access controls.

The same method is used for cache_dir load reporting (if it returns
true). Load management needs more work, but the current code is no worse
than the old one in this aspect, and further improvements are outside
this change scope.


* Minimized from-disk StoreEntry loading/unpacking code duplication.

Moved common (and often rather complex!) code from store modules into
storeRebuildLoadEntry, storeRebuildParseEntry, and storeRebuildKeepEntry.


* Do not set object_sz when the entry is aborted because the true object
size (HTTP reply headers + body) is not known in this case. Setting
object_sz may fool client-side code into believing that the object is
complete.

This addresses an old RBC's complaint.


* When swapout initiation fails, mark swapout decision as
MemObject::SwapOut::swImpossible. This prevents the caller code from trying to
swap out again and again because swap_status becomes SWAPOUT_NONE.

TODO: Consider add SWAPOUT_ERROR, STORE_ERROR, and similar states. It
may solve several problems where the code sees _NONE or _OK and thinks
everything is peachy when in fact there was an error.


* Call haveParsedReplyHeaders() before entry->replaceHttpReply().

HaveParsedReplyHeaders() sets the entry public key and various flags (at 
least). ReplaceHttpReply() packs reply headers, starting swapout process.
It feels natural to adjust the entry _before_ we pack/swap it, but I may be
missing some side-effects here.

The change was necessary because we started calling checkCachable() from
swapoutPossible(). If haveParsedReplyHeaders() is not called before we swap
out checks, the entry will still have the private key and will be declared
impossible to cache.


* Extracted the write-to-store step from StoreEntry::replaceHttpReply().

This allows the caller to set the reply for the entry and then update the
entry and the reply before writing them to store. For example, the server-side
haveParsedReplyHeaders() code needs to set the entry timestamps and make the
entry key public before the entry starts swapping out, but the same code also
needs access to entry->getReply() and such for timestampsSet() and similar
code to work correctly.

TODO: Calls to StoreEntry::replaceHttpReply() do not have to be modified
because replaceHttpReply() does write by default. However, it is likely that
callers other than ServerStateData::setFinalReply() should take advantage of
the new split interface because they call timestampsSet() and such after
replaceHttpReply().


* Moved SwapDir::cur_size and n_disk_objects to specific SwapDirs. Removed
updateSize().  Some cache_dirs maintain their own maps and size statistics,
making the one-size-fits-all SwapDir members inappropriate.

* A new SwapDir public method swappedOut() added. It is called from
storeSwapOutFileClosed() to notify SwapDir that an object was swapped
out.

* Change SwapDir::max_size to bytes, make it protected, use maxSize() instead.

Change SwapDir::cur_size to bytes, make it private, use currentSize() instead.

Store Config.Store.avgObjectSize in bytes to avoid repeated and error-prone
KB<->bytes conversions.


* Change Config.cacheSwap.swapDirs and StoreEntry::store() type to SwapDir.

This allows using SwapDir API without dynamic_cast.


* Always call StoreEntry::abort() instead of setting ENTRY_ABORTED manually.

* Rely on entry->abort() side-effects if ENTRY_ABORTED was set.

* Added or updated comments to better document current code.

* Added operator << for dumping StoreEntry summary into the debugging
log. Needs more work to report more info (and not report yet-unknown info).

* Fixed blocking reads that were sometimes reading from random file offsets.

Core ""disk file"" reading code assumed that if the globally stored disk.offset
matches the desired offset, there is no reason to seek. This was probably done
to reduce seek overhead between consecutive reads. Unfortunately, the disk
writing code did not know about that optimization and left F->disk.offset
unchanged after writing.

This may have worked OK for UFS if it never writes to the file it reads from,
but it does not work for store modules that do both kinds of I/O at different
offsets of the same disk file.

Eventually, implement this optimization correctly or remove disk.offset.


IPC primitives
--------------

To make SMP disk and memory caching non-blocking and correct, worker and
disker processes must asynchronously communicate with each other. We are
adding a collection of classes that support such communication.

At the base of the collection is the AtomicWordT template that uses GCC atomic
primitives such as __sync_add_and_fetch() to perform atomic operations on
integral values in memory shared by multiple Squid kids. AtomicWordT is used
to implement non-blocking shared locks, queues, store tables, and page pools.

To avoid blocking or very long searches, many operations are ""optimistic"" in
nature. For example, it is possible that an atomic store map will refuse to
allocate an entry for two processes even though a blocking implementation
would have allowed one of the processes to get the map slot. We speculate that
such conflict resolution is better than blocking locks when it comes to
caching, especially if the conflicts are rare due to large number of cache
entries, fast operations, and relatively small number of kids.


TODO: Eventually, consider breaking locks left by dead kids.



Shared Memory Cache
-------------------

* Added initial shared memory cache implementation (MemStore).

The shared memory cache keeps its own compact index of cached entries using
extended Ipc::StoreMap class (MemStoreMap). The cache also strives to keep its
Root.get() results out of the store_table except during transit.

Eventually, the non-shared/local memory cache should also be implemented
using a MemStore-like class, I think. This will allow to clearly isolate
local from shared memory cache code.

Allow the user to explicitly disable shared memory caching in SMP mode via
memory_cache_shared to squid.conf. Report whether mem_cache is shared.

Disable shared memory caching by default if atomic operations are not
supported. Prohibit shared memory caching if atomic operations are not
supported.

TODO: Better limits/separation for cache and I/O shared memory pages.
Eventually, support shared memory caching of multi-page entries.


Rock Store
----------

Rock Store uses a single [large] database-style file per cache_dir to store
cached responses and metadata. This part of the design is similar to COSS.
Rock Store does not maintain or rely on swap.state ""log"" for recovery.
Instead, the database is scanned in the background to load entries when Squid
starts. Rock Store maintains its own index of cached entries and avoids global
store_table. All entries must be max-size or smaller.

In SMP mode, each Rock cache_dir is given a dedicated Kid processes called
""disker"". All SMP workers communicate with diskers to store misses and load
hits, using shared memory pages and atomic shared memory queues. Disker blocks
when doing disk I/O but workers do not. Any Diskers:Workers ratio is supported
so that the user can find and configure the optimal number of workers and
diskers for a given number of disks and CPU cores.

In non-SMP mode, should use good old blocking disk I/O, without any diskers,
but this has not been tested recently and probably needs more work.

Feature page: http://wiki.squid-cache.org/Features/RockStore

TODO: Disk rate limit to protect Squid from disk overload. More stats.
Multiple readers? Seek optimization? Remove known max-size requirement?",8765,data/crawl/squid/hunk_2449.cpp,,,data/crawl/squid/old_hunk_2449.cpp,data/crawl/squid/new_hunk_2449.cpp,-1,739,,"storeAppendPrintf(&e, "" READ-ONLY"");","[""addLog""]","[[], [""storeAppendPrintf"", ""&e"", ""READ"", ""ONLY""]]",[-820735672030092498],6037,164880.0,2
https://github.com/squid-cache/squid/commit/35a1b223314eddb67b631cb0224d6e03a2360c77,13 Sep 2011,"SMP Caching: Core changes, IPC primitives, Shared memory cache, and Rock Store

Core changes
------------

* Added MemObject::expectedReplySize() and used it instead of object_sz.

When deciding whether an object with a known content length can be
swapped out, do not wait until the object is completely received and its
size (mem_obj->object_sz) becomes known (while asking the store to
recheck in vain with every incoming chunk). Instead, use the known
content length, if any, to make the decision.

This optimizes the common case where the complete object is eventually
received and swapped out, preventing accumulating potentially large
objects in RAM while waiting for the end of the response. Should not
affect objects with unknown content length.

Side-effect1: probably fixes several cases of unknowingly using negative
(unknown) mem_obj->object_sz in calculations. I added a few assertions
to double check some of the remaining object_sz/objectLen() uses.

Side-effect2: When expectedReplySize() is stored on disk as StoreEntry
metadata, it may help to detect truncated entries when the writer
process dies before completing the swapout.


* Removed mem->swapout.memnode in favor of mem->swapout.queue_offset.

The code used swapout.memnode pointer to keep track of the last page
that was swapped out. The code was semi-buggy because it could reset the
pointer to NULL if no new data came in before the call to doPages().
Perhaps the code relied on the assumption that the caller will never
doPages if there is no new data, but I am not sure that assumption was
correct in all cases (it could be that I broke the calling code, of course).

Moreover, the page pointer was kept without any protection from page
disappearing during asynchronous swapout. There were ""Evil hack time""
comments discussing how the page might disappear.

Fortunately, we already have mem->swapout.queue_offset that can be fed
to getBlockContainingLocation to find the page that needs to be swapped
out. There is no need to keep the page pointer around. The
queue_offset-based math is the same so we are not adding any overheads
by using that offset (in fact, we are removing some minor computations).


* Added ""close how?"" parameter to storeClose() and friends.

The old code would follow the same path when closing swapout activity
for an aborted entry and when completing a perfectly healthy swapout. In
non-shared case, that could have been OK because the abort code would
then release the entry, removing any half-written entry from the index
and the disk (but I am not sure that release happened fast enough in
100% of cases).

When the index and disk storage is shared among workers, such
""temporary"" inconsistencies result in truncated responses being
delivered by other workers to the user because once the swapout activity
is closed, other workers can start using the entry.

By adding the ""close how?"" parameter to closing methods we allow the
core and SwapDir-specific code to handle aborted swapouts appropriately.

Since swapin code is ""read only"", we do not currently distinguish
between aborted and fully satisfied readers: The readerGone enum value
applies to both cases. If needed, the SwapDir reading code can make that
distinction by analyzing how much was actually swapped in.


* Moved ""can you store this entry?"" code to virtual SwapDir::canStore().

The old code had some of the tests in SwapDir-specific canStore()
methods and some in storeDirSelect*() methods. This resulted in
inconsistencies, code duplication, and extra calculation overheads.
Making this call virtual allows individual cache_dir types to do custom
access controls.

The same method is used for cache_dir load reporting (if it returns
true). Load management needs more work, but the current code is no worse
than the old one in this aspect, and further improvements are outside
this change scope.


* Minimized from-disk StoreEntry loading/unpacking code duplication.

Moved common (and often rather complex!) code from store modules into
storeRebuildLoadEntry, storeRebuildParseEntry, and storeRebuildKeepEntry.


* Do not set object_sz when the entry is aborted because the true object
size (HTTP reply headers + body) is not known in this case. Setting
object_sz may fool client-side code into believing that the object is
complete.

This addresses an old RBC's complaint.


* When swapout initiation fails, mark swapout decision as
MemObject::SwapOut::swImpossible. This prevents the caller code from trying to
swap out again and again because swap_status becomes SWAPOUT_NONE.

TODO: Consider add SWAPOUT_ERROR, STORE_ERROR, and similar states. It
may solve several problems where the code sees _NONE or _OK and thinks
everything is peachy when in fact there was an error.


* Call haveParsedReplyHeaders() before entry->replaceHttpReply().

HaveParsedReplyHeaders() sets the entry public key and various flags (at 
least). ReplaceHttpReply() packs reply headers, starting swapout process.
It feels natural to adjust the entry _before_ we pack/swap it, but I may be
missing some side-effects here.

The change was necessary because we started calling checkCachable() from
swapoutPossible(). If haveParsedReplyHeaders() is not called before we swap
out checks, the entry will still have the private key and will be declared
impossible to cache.


* Extracted the write-to-store step from StoreEntry::replaceHttpReply().

This allows the caller to set the reply for the entry and then update the
entry and the reply before writing them to store. For example, the server-side
haveParsedReplyHeaders() code needs to set the entry timestamps and make the
entry key public before the entry starts swapping out, but the same code also
needs access to entry->getReply() and such for timestampsSet() and similar
code to work correctly.

TODO: Calls to StoreEntry::replaceHttpReply() do not have to be modified
because replaceHttpReply() does write by default. However, it is likely that
callers other than ServerStateData::setFinalReply() should take advantage of
the new split interface because they call timestampsSet() and such after
replaceHttpReply().


* Moved SwapDir::cur_size and n_disk_objects to specific SwapDirs. Removed
updateSize().  Some cache_dirs maintain their own maps and size statistics,
making the one-size-fits-all SwapDir members inappropriate.

* A new SwapDir public method swappedOut() added. It is called from
storeSwapOutFileClosed() to notify SwapDir that an object was swapped
out.

* Change SwapDir::max_size to bytes, make it protected, use maxSize() instead.

Change SwapDir::cur_size to bytes, make it private, use currentSize() instead.

Store Config.Store.avgObjectSize in bytes to avoid repeated and error-prone
KB<->bytes conversions.


* Change Config.cacheSwap.swapDirs and StoreEntry::store() type to SwapDir.

This allows using SwapDir API without dynamic_cast.


* Always call StoreEntry::abort() instead of setting ENTRY_ABORTED manually.

* Rely on entry->abort() side-effects if ENTRY_ABORTED was set.

* Added or updated comments to better document current code.

* Added operator << for dumping StoreEntry summary into the debugging
log. Needs more work to report more info (and not report yet-unknown info).

* Fixed blocking reads that were sometimes reading from random file offsets.

Core ""disk file"" reading code assumed that if the globally stored disk.offset
matches the desired offset, there is no reason to seek. This was probably done
to reduce seek overhead between consecutive reads. Unfortunately, the disk
writing code did not know about that optimization and left F->disk.offset
unchanged after writing.

This may have worked OK for UFS if it never writes to the file it reads from,
but it does not work for store modules that do both kinds of I/O at different
offsets of the same disk file.

Eventually, implement this optimization correctly or remove disk.offset.


IPC primitives
--------------

To make SMP disk and memory caching non-blocking and correct, worker and
disker processes must asynchronously communicate with each other. We are
adding a collection of classes that support such communication.

At the base of the collection is the AtomicWordT template that uses GCC atomic
primitives such as __sync_add_and_fetch() to perform atomic operations on
integral values in memory shared by multiple Squid kids. AtomicWordT is used
to implement non-blocking shared locks, queues, store tables, and page pools.

To avoid blocking or very long searches, many operations are ""optimistic"" in
nature. For example, it is possible that an atomic store map will refuse to
allocate an entry for two processes even though a blocking implementation
would have allowed one of the processes to get the map slot. We speculate that
such conflict resolution is better than blocking locks when it comes to
caching, especially if the conflicts are rare due to large number of cache
entries, fast operations, and relatively small number of kids.


TODO: Eventually, consider breaking locks left by dead kids.



Shared Memory Cache
-------------------

* Added initial shared memory cache implementation (MemStore).

The shared memory cache keeps its own compact index of cached entries using
extended Ipc::StoreMap class (MemStoreMap). The cache also strives to keep its
Root.get() results out of the store_table except during transit.

Eventually, the non-shared/local memory cache should also be implemented
using a MemStore-like class, I think. This will allow to clearly isolate
local from shared memory cache code.

Allow the user to explicitly disable shared memory caching in SMP mode via
memory_cache_shared to squid.conf. Report whether mem_cache is shared.

Disable shared memory caching by default if atomic operations are not
supported. Prohibit shared memory caching if atomic operations are not
supported.

TODO: Better limits/separation for cache and I/O shared memory pages.
Eventually, support shared memory caching of multi-page entries.


Rock Store
----------

Rock Store uses a single [large] database-style file per cache_dir to store
cached responses and metadata. This part of the design is similar to COSS.
Rock Store does not maintain or rely on swap.state ""log"" for recovery.
Instead, the database is scanned in the background to load entries when Squid
starts. Rock Store maintains its own index of cached entries and avoids global
store_table. All entries must be max-size or smaller.

In SMP mode, each Rock cache_dir is given a dedicated Kid processes called
""disker"". All SMP workers communicate with diskers to store misses and load
hits, using shared memory pages and atomic shared memory queues. Disker blocks
when doing disk I/O but workers do not. Any Diskers:Workers ratio is supported
so that the user can find and configure the optimal number of workers and
diskers for a given number of disks and CPU cores.

In non-SMP mode, should use good old blocking disk I/O, without any diskers,
but this has not been tested recently and probably needs more work.

Feature page: http://wiki.squid-cache.org/Features/RockStore

TODO: Disk rate limit to protect Squid from disk overload. More stats.
Multiple readers? Seek optimization? Remove known max-size requirement?",8765,data/crawl/squid/hunk_2449.cpp,,,data/crawl/squid/old_hunk_2449.cpp,data/crawl/squid/new_hunk_2449.cpp,-1,736,,"storeAppendPrintf(&e, "" SELECTED"");","[""addLog""]","[[], [""storeAppendPrintf"", ""&e"", ""SELECTED""]]",[1926652460407466335],6036,164880.0,2
https://github.com/squid-cache/squid/commit/35a1b223314eddb67b631cb0224d6e03a2360c77,13 Sep 2011,"SMP Caching: Core changes, IPC primitives, Shared memory cache, and Rock Store

Core changes
------------

* Added MemObject::expectedReplySize() and used it instead of object_sz.

When deciding whether an object with a known content length can be
swapped out, do not wait until the object is completely received and its
size (mem_obj->object_sz) becomes known (while asking the store to
recheck in vain with every incoming chunk). Instead, use the known
content length, if any, to make the decision.

This optimizes the common case where the complete object is eventually
received and swapped out, preventing accumulating potentially large
objects in RAM while waiting for the end of the response. Should not
affect objects with unknown content length.

Side-effect1: probably fixes several cases of unknowingly using negative
(unknown) mem_obj->object_sz in calculations. I added a few assertions
to double check some of the remaining object_sz/objectLen() uses.

Side-effect2: When expectedReplySize() is stored on disk as StoreEntry
metadata, it may help to detect truncated entries when the writer
process dies before completing the swapout.


* Removed mem->swapout.memnode in favor of mem->swapout.queue_offset.

The code used swapout.memnode pointer to keep track of the last page
that was swapped out. The code was semi-buggy because it could reset the
pointer to NULL if no new data came in before the call to doPages().
Perhaps the code relied on the assumption that the caller will never
doPages if there is no new data, but I am not sure that assumption was
correct in all cases (it could be that I broke the calling code, of course).

Moreover, the page pointer was kept without any protection from page
disappearing during asynchronous swapout. There were ""Evil hack time""
comments discussing how the page might disappear.

Fortunately, we already have mem->swapout.queue_offset that can be fed
to getBlockContainingLocation to find the page that needs to be swapped
out. There is no need to keep the page pointer around. The
queue_offset-based math is the same so we are not adding any overheads
by using that offset (in fact, we are removing some minor computations).


* Added ""close how?"" parameter to storeClose() and friends.

The old code would follow the same path when closing swapout activity
for an aborted entry and when completing a perfectly healthy swapout. In
non-shared case, that could have been OK because the abort code would
then release the entry, removing any half-written entry from the index
and the disk (but I am not sure that release happened fast enough in
100% of cases).

When the index and disk storage is shared among workers, such
""temporary"" inconsistencies result in truncated responses being
delivered by other workers to the user because once the swapout activity
is closed, other workers can start using the entry.

By adding the ""close how?"" parameter to closing methods we allow the
core and SwapDir-specific code to handle aborted swapouts appropriately.

Since swapin code is ""read only"", we do not currently distinguish
between aborted and fully satisfied readers: The readerGone enum value
applies to both cases. If needed, the SwapDir reading code can make that
distinction by analyzing how much was actually swapped in.


* Moved ""can you store this entry?"" code to virtual SwapDir::canStore().

The old code had some of the tests in SwapDir-specific canStore()
methods and some in storeDirSelect*() methods. This resulted in
inconsistencies, code duplication, and extra calculation overheads.
Making this call virtual allows individual cache_dir types to do custom
access controls.

The same method is used for cache_dir load reporting (if it returns
true). Load management needs more work, but the current code is no worse
than the old one in this aspect, and further improvements are outside
this change scope.


* Minimized from-disk StoreEntry loading/unpacking code duplication.

Moved common (and often rather complex!) code from store modules into
storeRebuildLoadEntry, storeRebuildParseEntry, and storeRebuildKeepEntry.


* Do not set object_sz when the entry is aborted because the true object
size (HTTP reply headers + body) is not known in this case. Setting
object_sz may fool client-side code into believing that the object is
complete.

This addresses an old RBC's complaint.


* When swapout initiation fails, mark swapout decision as
MemObject::SwapOut::swImpossible. This prevents the caller code from trying to
swap out again and again because swap_status becomes SWAPOUT_NONE.

TODO: Consider add SWAPOUT_ERROR, STORE_ERROR, and similar states. It
may solve several problems where the code sees _NONE or _OK and thinks
everything is peachy when in fact there was an error.


* Call haveParsedReplyHeaders() before entry->replaceHttpReply().

HaveParsedReplyHeaders() sets the entry public key and various flags (at 
least). ReplaceHttpReply() packs reply headers, starting swapout process.
It feels natural to adjust the entry _before_ we pack/swap it, but I may be
missing some side-effects here.

The change was necessary because we started calling checkCachable() from
swapoutPossible(). If haveParsedReplyHeaders() is not called before we swap
out checks, the entry will still have the private key and will be declared
impossible to cache.


* Extracted the write-to-store step from StoreEntry::replaceHttpReply().

This allows the caller to set the reply for the entry and then update the
entry and the reply before writing them to store. For example, the server-side
haveParsedReplyHeaders() code needs to set the entry timestamps and make the
entry key public before the entry starts swapping out, but the same code also
needs access to entry->getReply() and such for timestampsSet() and similar
code to work correctly.

TODO: Calls to StoreEntry::replaceHttpReply() do not have to be modified
because replaceHttpReply() does write by default. However, it is likely that
callers other than ServerStateData::setFinalReply() should take advantage of
the new split interface because they call timestampsSet() and such after
replaceHttpReply().


* Moved SwapDir::cur_size and n_disk_objects to specific SwapDirs. Removed
updateSize().  Some cache_dirs maintain their own maps and size statistics,
making the one-size-fits-all SwapDir members inappropriate.

* A new SwapDir public method swappedOut() added. It is called from
storeSwapOutFileClosed() to notify SwapDir that an object was swapped
out.

* Change SwapDir::max_size to bytes, make it protected, use maxSize() instead.

Change SwapDir::cur_size to bytes, make it private, use currentSize() instead.

Store Config.Store.avgObjectSize in bytes to avoid repeated and error-prone
KB<->bytes conversions.


* Change Config.cacheSwap.swapDirs and StoreEntry::store() type to SwapDir.

This allows using SwapDir API without dynamic_cast.


* Always call StoreEntry::abort() instead of setting ENTRY_ABORTED manually.

* Rely on entry->abort() side-effects if ENTRY_ABORTED was set.

* Added or updated comments to better document current code.

* Added operator << for dumping StoreEntry summary into the debugging
log. Needs more work to report more info (and not report yet-unknown info).

* Fixed blocking reads that were sometimes reading from random file offsets.

Core ""disk file"" reading code assumed that if the globally stored disk.offset
matches the desired offset, there is no reason to seek. This was probably done
to reduce seek overhead between consecutive reads. Unfortunately, the disk
writing code did not know about that optimization and left F->disk.offset
unchanged after writing.

This may have worked OK for UFS if it never writes to the file it reads from,
but it does not work for store modules that do both kinds of I/O at different
offsets of the same disk file.

Eventually, implement this optimization correctly or remove disk.offset.


IPC primitives
--------------

To make SMP disk and memory caching non-blocking and correct, worker and
disker processes must asynchronously communicate with each other. We are
adding a collection of classes that support such communication.

At the base of the collection is the AtomicWordT template that uses GCC atomic
primitives such as __sync_add_and_fetch() to perform atomic operations on
integral values in memory shared by multiple Squid kids. AtomicWordT is used
to implement non-blocking shared locks, queues, store tables, and page pools.

To avoid blocking or very long searches, many operations are ""optimistic"" in
nature. For example, it is possible that an atomic store map will refuse to
allocate an entry for two processes even though a blocking implementation
would have allowed one of the processes to get the map slot. We speculate that
such conflict resolution is better than blocking locks when it comes to
caching, especially if the conflicts are rare due to large number of cache
entries, fast operations, and relatively small number of kids.


TODO: Eventually, consider breaking locks left by dead kids.



Shared Memory Cache
-------------------

* Added initial shared memory cache implementation (MemStore).

The shared memory cache keeps its own compact index of cached entries using
extended Ipc::StoreMap class (MemStoreMap). The cache also strives to keep its
Root.get() results out of the store_table except during transit.

Eventually, the non-shared/local memory cache should also be implemented
using a MemStore-like class, I think. This will allow to clearly isolate
local from shared memory cache code.

Allow the user to explicitly disable shared memory caching in SMP mode via
memory_cache_shared to squid.conf. Report whether mem_cache is shared.

Disable shared memory caching by default if atomic operations are not
supported. Prohibit shared memory caching if atomic operations are not
supported.

TODO: Better limits/separation for cache and I/O shared memory pages.
Eventually, support shared memory caching of multi-page entries.


Rock Store
----------

Rock Store uses a single [large] database-style file per cache_dir to store
cached responses and metadata. This part of the design is similar to COSS.
Rock Store does not maintain or rely on swap.state ""log"" for recovery.
Instead, the database is scanned in the background to load entries when Squid
starts. Rock Store maintains its own index of cached entries and avoids global
store_table. All entries must be max-size or smaller.

In SMP mode, each Rock cache_dir is given a dedicated Kid processes called
""disker"". All SMP workers communicate with diskers to store misses and load
hits, using shared memory pages and atomic shared memory queues. Disker blocks
when doing disk I/O but workers do not. Any Diskers:Workers ratio is supported
so that the user can find and configure the optimal number of workers and
diskers for a given number of disks and CPU cores.

In non-SMP mode, should use good old blocking disk I/O, without any diskers,
but this has not been tested recently and probably needs more work.

Feature page: http://wiki.squid-cache.org/Features/RockStore

TODO: Disk rate limit to protect Squid from disk overload. More stats.
Multiple readers? Seek optimization? Remove known max-size requirement?",8765,data/crawl/squid/hunk_2449.cpp,,,data/crawl/squid/old_hunk_2449.cpp,data/crawl/squid/new_hunk_2449.cpp,-1,733,,"storeAppendPrintf(&e, ""Flags:"");","[""addLog""]","[[], [""storeAppendPrintf"", ""&e"", ""Flags""]]",[11239233795413876392],6035,164880.0,2
https://github.com/squid-cache/squid/commit/35a1b223314eddb67b631cb0224d6e03a2360c77,13 Sep 2011,"SMP Caching: Core changes, IPC primitives, Shared memory cache, and Rock Store

Core changes
------------

* Added MemObject::expectedReplySize() and used it instead of object_sz.

When deciding whether an object with a known content length can be
swapped out, do not wait until the object is completely received and its
size (mem_obj->object_sz) becomes known (while asking the store to
recheck in vain with every incoming chunk). Instead, use the known
content length, if any, to make the decision.

This optimizes the common case where the complete object is eventually
received and swapped out, preventing accumulating potentially large
objects in RAM while waiting for the end of the response. Should not
affect objects with unknown content length.

Side-effect1: probably fixes several cases of unknowingly using negative
(unknown) mem_obj->object_sz in calculations. I added a few assertions
to double check some of the remaining object_sz/objectLen() uses.

Side-effect2: When expectedReplySize() is stored on disk as StoreEntry
metadata, it may help to detect truncated entries when the writer
process dies before completing the swapout.


* Removed mem->swapout.memnode in favor of mem->swapout.queue_offset.

The code used swapout.memnode pointer to keep track of the last page
that was swapped out. The code was semi-buggy because it could reset the
pointer to NULL if no new data came in before the call to doPages().
Perhaps the code relied on the assumption that the caller will never
doPages if there is no new data, but I am not sure that assumption was
correct in all cases (it could be that I broke the calling code, of course).

Moreover, the page pointer was kept without any protection from page
disappearing during asynchronous swapout. There were ""Evil hack time""
comments discussing how the page might disappear.

Fortunately, we already have mem->swapout.queue_offset that can be fed
to getBlockContainingLocation to find the page that needs to be swapped
out. There is no need to keep the page pointer around. The
queue_offset-based math is the same so we are not adding any overheads
by using that offset (in fact, we are removing some minor computations).


* Added ""close how?"" parameter to storeClose() and friends.

The old code would follow the same path when closing swapout activity
for an aborted entry and when completing a perfectly healthy swapout. In
non-shared case, that could have been OK because the abort code would
then release the entry, removing any half-written entry from the index
and the disk (but I am not sure that release happened fast enough in
100% of cases).

When the index and disk storage is shared among workers, such
""temporary"" inconsistencies result in truncated responses being
delivered by other workers to the user because once the swapout activity
is closed, other workers can start using the entry.

By adding the ""close how?"" parameter to closing methods we allow the
core and SwapDir-specific code to handle aborted swapouts appropriately.

Since swapin code is ""read only"", we do not currently distinguish
between aborted and fully satisfied readers: The readerGone enum value
applies to both cases. If needed, the SwapDir reading code can make that
distinction by analyzing how much was actually swapped in.


* Moved ""can you store this entry?"" code to virtual SwapDir::canStore().

The old code had some of the tests in SwapDir-specific canStore()
methods and some in storeDirSelect*() methods. This resulted in
inconsistencies, code duplication, and extra calculation overheads.
Making this call virtual allows individual cache_dir types to do custom
access controls.

The same method is used for cache_dir load reporting (if it returns
true). Load management needs more work, but the current code is no worse
than the old one in this aspect, and further improvements are outside
this change scope.


* Minimized from-disk StoreEntry loading/unpacking code duplication.

Moved common (and often rather complex!) code from store modules into
storeRebuildLoadEntry, storeRebuildParseEntry, and storeRebuildKeepEntry.


* Do not set object_sz when the entry is aborted because the true object
size (HTTP reply headers + body) is not known in this case. Setting
object_sz may fool client-side code into believing that the object is
complete.

This addresses an old RBC's complaint.


* When swapout initiation fails, mark swapout decision as
MemObject::SwapOut::swImpossible. This prevents the caller code from trying to
swap out again and again because swap_status becomes SWAPOUT_NONE.

TODO: Consider add SWAPOUT_ERROR, STORE_ERROR, and similar states. It
may solve several problems where the code sees _NONE or _OK and thinks
everything is peachy when in fact there was an error.


* Call haveParsedReplyHeaders() before entry->replaceHttpReply().

HaveParsedReplyHeaders() sets the entry public key and various flags (at 
least). ReplaceHttpReply() packs reply headers, starting swapout process.
It feels natural to adjust the entry _before_ we pack/swap it, but I may be
missing some side-effects here.

The change was necessary because we started calling checkCachable() from
swapoutPossible(). If haveParsedReplyHeaders() is not called before we swap
out checks, the entry will still have the private key and will be declared
impossible to cache.


* Extracted the write-to-store step from StoreEntry::replaceHttpReply().

This allows the caller to set the reply for the entry and then update the
entry and the reply before writing them to store. For example, the server-side
haveParsedReplyHeaders() code needs to set the entry timestamps and make the
entry key public before the entry starts swapping out, but the same code also
needs access to entry->getReply() and such for timestampsSet() and similar
code to work correctly.

TODO: Calls to StoreEntry::replaceHttpReply() do not have to be modified
because replaceHttpReply() does write by default. However, it is likely that
callers other than ServerStateData::setFinalReply() should take advantage of
the new split interface because they call timestampsSet() and such after
replaceHttpReply().


* Moved SwapDir::cur_size and n_disk_objects to specific SwapDirs. Removed
updateSize().  Some cache_dirs maintain their own maps and size statistics,
making the one-size-fits-all SwapDir members inappropriate.

* A new SwapDir public method swappedOut() added. It is called from
storeSwapOutFileClosed() to notify SwapDir that an object was swapped
out.

* Change SwapDir::max_size to bytes, make it protected, use maxSize() instead.

Change SwapDir::cur_size to bytes, make it private, use currentSize() instead.

Store Config.Store.avgObjectSize in bytes to avoid repeated and error-prone
KB<->bytes conversions.


* Change Config.cacheSwap.swapDirs and StoreEntry::store() type to SwapDir.

This allows using SwapDir API without dynamic_cast.


* Always call StoreEntry::abort() instead of setting ENTRY_ABORTED manually.

* Rely on entry->abort() side-effects if ENTRY_ABORTED was set.

* Added or updated comments to better document current code.

* Added operator << for dumping StoreEntry summary into the debugging
log. Needs more work to report more info (and not report yet-unknown info).

* Fixed blocking reads that were sometimes reading from random file offsets.

Core ""disk file"" reading code assumed that if the globally stored disk.offset
matches the desired offset, there is no reason to seek. This was probably done
to reduce seek overhead between consecutive reads. Unfortunately, the disk
writing code did not know about that optimization and left F->disk.offset
unchanged after writing.

This may have worked OK for UFS if it never writes to the file it reads from,
but it does not work for store modules that do both kinds of I/O at different
offsets of the same disk file.

Eventually, implement this optimization correctly or remove disk.offset.


IPC primitives
--------------

To make SMP disk and memory caching non-blocking and correct, worker and
disker processes must asynchronously communicate with each other. We are
adding a collection of classes that support such communication.

At the base of the collection is the AtomicWordT template that uses GCC atomic
primitives such as __sync_add_and_fetch() to perform atomic operations on
integral values in memory shared by multiple Squid kids. AtomicWordT is used
to implement non-blocking shared locks, queues, store tables, and page pools.

To avoid blocking or very long searches, many operations are ""optimistic"" in
nature. For example, it is possible that an atomic store map will refuse to
allocate an entry for two processes even though a blocking implementation
would have allowed one of the processes to get the map slot. We speculate that
such conflict resolution is better than blocking locks when it comes to
caching, especially if the conflicts are rare due to large number of cache
entries, fast operations, and relatively small number of kids.


TODO: Eventually, consider breaking locks left by dead kids.



Shared Memory Cache
-------------------

* Added initial shared memory cache implementation (MemStore).

The shared memory cache keeps its own compact index of cached entries using
extended Ipc::StoreMap class (MemStoreMap). The cache also strives to keep its
Root.get() results out of the store_table except during transit.

Eventually, the non-shared/local memory cache should also be implemented
using a MemStore-like class, I think. This will allow to clearly isolate
local from shared memory cache code.

Allow the user to explicitly disable shared memory caching in SMP mode via
memory_cache_shared to squid.conf. Report whether mem_cache is shared.

Disable shared memory caching by default if atomic operations are not
supported. Prohibit shared memory caching if atomic operations are not
supported.

TODO: Better limits/separation for cache and I/O shared memory pages.
Eventually, support shared memory caching of multi-page entries.


Rock Store
----------

Rock Store uses a single [large] database-style file per cache_dir to store
cached responses and metadata. This part of the design is similar to COSS.
Rock Store does not maintain or rely on swap.state ""log"" for recovery.
Instead, the database is scanned in the background to load entries when Squid
starts. Rock Store maintains its own index of cached entries and avoids global
store_table. All entries must be max-size or smaller.

In SMP mode, each Rock cache_dir is given a dedicated Kid processes called
""disker"". All SMP workers communicate with diskers to store misses and load
hits, using shared memory pages and atomic shared memory queues. Disker blocks
when doing disk I/O but workers do not. Any Diskers:Workers ratio is supported
so that the user can find and configure the optimal number of workers and
diskers for a given number of disks and CPU cores.

In non-SMP mode, should use good old blocking disk I/O, without any diskers,
but this has not been tested recently and probably needs more work.

Feature page: http://wiki.squid-cache.org/Features/RockStore

TODO: Disk rate limit to protect Squid from disk overload. More stats.
Multiple readers? Seek optimization? Remove known max-size requirement?",8765,data/crawl/squid/hunk_2449.cpp,,,data/crawl/squid/old_hunk_2449.cpp,data/crawl/squid/new_hunk_2449.cpp,-1,730,,"storeAppendPrintf(&e, ""Pending operations: %d out of %d\n"",
                      store_open_disk_fd, Config.max_open_disk_fds);","[""addLog""]","[[], [""storeAppendPrintf"", ""&e"", ""Pending"", ""operations"", ""%d"", ""out"", ""of"", ""%d\\n"", ""store_open_disk_fd"", ""Config"", ""max_open_disk_fds""]]",[27645512080306915259],6034,164880.0,2
https://github.com/squid-cache/squid/commit/35a1b223314eddb67b631cb0224d6e03a2360c77,13 Sep 2011,"SMP Caching: Core changes, IPC primitives, Shared memory cache, and Rock Store

Core changes
------------

* Added MemObject::expectedReplySize() and used it instead of object_sz.

When deciding whether an object with a known content length can be
swapped out, do not wait until the object is completely received and its
size (mem_obj->object_sz) becomes known (while asking the store to
recheck in vain with every incoming chunk). Instead, use the known
content length, if any, to make the decision.

This optimizes the common case where the complete object is eventually
received and swapped out, preventing accumulating potentially large
objects in RAM while waiting for the end of the response. Should not
affect objects with unknown content length.

Side-effect1: probably fixes several cases of unknowingly using negative
(unknown) mem_obj->object_sz in calculations. I added a few assertions
to double check some of the remaining object_sz/objectLen() uses.

Side-effect2: When expectedReplySize() is stored on disk as StoreEntry
metadata, it may help to detect truncated entries when the writer
process dies before completing the swapout.


* Removed mem->swapout.memnode in favor of mem->swapout.queue_offset.

The code used swapout.memnode pointer to keep track of the last page
that was swapped out. The code was semi-buggy because it could reset the
pointer to NULL if no new data came in before the call to doPages().
Perhaps the code relied on the assumption that the caller will never
doPages if there is no new data, but I am not sure that assumption was
correct in all cases (it could be that I broke the calling code, of course).

Moreover, the page pointer was kept without any protection from page
disappearing during asynchronous swapout. There were ""Evil hack time""
comments discussing how the page might disappear.

Fortunately, we already have mem->swapout.queue_offset that can be fed
to getBlockContainingLocation to find the page that needs to be swapped
out. There is no need to keep the page pointer around. The
queue_offset-based math is the same so we are not adding any overheads
by using that offset (in fact, we are removing some minor computations).


* Added ""close how?"" parameter to storeClose() and friends.

The old code would follow the same path when closing swapout activity
for an aborted entry and when completing a perfectly healthy swapout. In
non-shared case, that could have been OK because the abort code would
then release the entry, removing any half-written entry from the index
and the disk (but I am not sure that release happened fast enough in
100% of cases).

When the index and disk storage is shared among workers, such
""temporary"" inconsistencies result in truncated responses being
delivered by other workers to the user because once the swapout activity
is closed, other workers can start using the entry.

By adding the ""close how?"" parameter to closing methods we allow the
core and SwapDir-specific code to handle aborted swapouts appropriately.

Since swapin code is ""read only"", we do not currently distinguish
between aborted and fully satisfied readers: The readerGone enum value
applies to both cases. If needed, the SwapDir reading code can make that
distinction by analyzing how much was actually swapped in.


* Moved ""can you store this entry?"" code to virtual SwapDir::canStore().

The old code had some of the tests in SwapDir-specific canStore()
methods and some in storeDirSelect*() methods. This resulted in
inconsistencies, code duplication, and extra calculation overheads.
Making this call virtual allows individual cache_dir types to do custom
access controls.

The same method is used for cache_dir load reporting (if it returns
true). Load management needs more work, but the current code is no worse
than the old one in this aspect, and further improvements are outside
this change scope.


* Minimized from-disk StoreEntry loading/unpacking code duplication.

Moved common (and often rather complex!) code from store modules into
storeRebuildLoadEntry, storeRebuildParseEntry, and storeRebuildKeepEntry.


* Do not set object_sz when the entry is aborted because the true object
size (HTTP reply headers + body) is not known in this case. Setting
object_sz may fool client-side code into believing that the object is
complete.

This addresses an old RBC's complaint.


* When swapout initiation fails, mark swapout decision as
MemObject::SwapOut::swImpossible. This prevents the caller code from trying to
swap out again and again because swap_status becomes SWAPOUT_NONE.

TODO: Consider add SWAPOUT_ERROR, STORE_ERROR, and similar states. It
may solve several problems where the code sees _NONE or _OK and thinks
everything is peachy when in fact there was an error.


* Call haveParsedReplyHeaders() before entry->replaceHttpReply().

HaveParsedReplyHeaders() sets the entry public key and various flags (at 
least). ReplaceHttpReply() packs reply headers, starting swapout process.
It feels natural to adjust the entry _before_ we pack/swap it, but I may be
missing some side-effects here.

The change was necessary because we started calling checkCachable() from
swapoutPossible(). If haveParsedReplyHeaders() is not called before we swap
out checks, the entry will still have the private key and will be declared
impossible to cache.


* Extracted the write-to-store step from StoreEntry::replaceHttpReply().

This allows the caller to set the reply for the entry and then update the
entry and the reply before writing them to store. For example, the server-side
haveParsedReplyHeaders() code needs to set the entry timestamps and make the
entry key public before the entry starts swapping out, but the same code also
needs access to entry->getReply() and such for timestampsSet() and similar
code to work correctly.

TODO: Calls to StoreEntry::replaceHttpReply() do not have to be modified
because replaceHttpReply() does write by default. However, it is likely that
callers other than ServerStateData::setFinalReply() should take advantage of
the new split interface because they call timestampsSet() and such after
replaceHttpReply().


* Moved SwapDir::cur_size and n_disk_objects to specific SwapDirs. Removed
updateSize().  Some cache_dirs maintain their own maps and size statistics,
making the one-size-fits-all SwapDir members inappropriate.

* A new SwapDir public method swappedOut() added. It is called from
storeSwapOutFileClosed() to notify SwapDir that an object was swapped
out.

* Change SwapDir::max_size to bytes, make it protected, use maxSize() instead.

Change SwapDir::cur_size to bytes, make it private, use currentSize() instead.

Store Config.Store.avgObjectSize in bytes to avoid repeated and error-prone
KB<->bytes conversions.


* Change Config.cacheSwap.swapDirs and StoreEntry::store() type to SwapDir.

This allows using SwapDir API without dynamic_cast.


* Always call StoreEntry::abort() instead of setting ENTRY_ABORTED manually.

* Rely on entry->abort() side-effects if ENTRY_ABORTED was set.

* Added or updated comments to better document current code.

* Added operator << for dumping StoreEntry summary into the debugging
log. Needs more work to report more info (and not report yet-unknown info).

* Fixed blocking reads that were sometimes reading from random file offsets.

Core ""disk file"" reading code assumed that if the globally stored disk.offset
matches the desired offset, there is no reason to seek. This was probably done
to reduce seek overhead between consecutive reads. Unfortunately, the disk
writing code did not know about that optimization and left F->disk.offset
unchanged after writing.

This may have worked OK for UFS if it never writes to the file it reads from,
but it does not work for store modules that do both kinds of I/O at different
offsets of the same disk file.

Eventually, implement this optimization correctly or remove disk.offset.


IPC primitives
--------------

To make SMP disk and memory caching non-blocking and correct, worker and
disker processes must asynchronously communicate with each other. We are
adding a collection of classes that support such communication.

At the base of the collection is the AtomicWordT template that uses GCC atomic
primitives such as __sync_add_and_fetch() to perform atomic operations on
integral values in memory shared by multiple Squid kids. AtomicWordT is used
to implement non-blocking shared locks, queues, store tables, and page pools.

To avoid blocking or very long searches, many operations are ""optimistic"" in
nature. For example, it is possible that an atomic store map will refuse to
allocate an entry for two processes even though a blocking implementation
would have allowed one of the processes to get the map slot. We speculate that
such conflict resolution is better than blocking locks when it comes to
caching, especially if the conflicts are rare due to large number of cache
entries, fast operations, and relatively small number of kids.


TODO: Eventually, consider breaking locks left by dead kids.



Shared Memory Cache
-------------------

* Added initial shared memory cache implementation (MemStore).

The shared memory cache keeps its own compact index of cached entries using
extended Ipc::StoreMap class (MemStoreMap). The cache also strives to keep its
Root.get() results out of the store_table except during transit.

Eventually, the non-shared/local memory cache should also be implemented
using a MemStore-like class, I think. This will allow to clearly isolate
local from shared memory cache code.

Allow the user to explicitly disable shared memory caching in SMP mode via
memory_cache_shared to squid.conf. Report whether mem_cache is shared.

Disable shared memory caching by default if atomic operations are not
supported. Prohibit shared memory caching if atomic operations are not
supported.

TODO: Better limits/separation for cache and I/O shared memory pages.
Eventually, support shared memory caching of multi-page entries.


Rock Store
----------

Rock Store uses a single [large] database-style file per cache_dir to store
cached responses and metadata. This part of the design is similar to COSS.
Rock Store does not maintain or rely on swap.state ""log"" for recovery.
Instead, the database is scanned in the background to load entries when Squid
starts. Rock Store maintains its own index of cached entries and avoids global
store_table. All entries must be max-size or smaller.

In SMP mode, each Rock cache_dir is given a dedicated Kid processes called
""disker"". All SMP workers communicate with diskers to store misses and load
hits, using shared memory pages and atomic shared memory queues. Disker blocks
when doing disk I/O but workers do not. Any Diskers:Workers ratio is supported
so that the user can find and configure the optimal number of workers and
diskers for a given number of disks and CPU cores.

In non-SMP mode, should use good old blocking disk I/O, without any diskers,
but this has not been tested recently and probably needs more work.

Feature page: http://wiki.squid-cache.org/Features/RockStore

TODO: Disk rate limit to protect Squid from disk overload. More stats.
Multiple readers? Seek optimization? Remove known max-size requirement?",8765,data/crawl/squid/hunk_2449.cpp,,,data/crawl/squid/old_hunk_2449.cpp,data/crawl/squid/new_hunk_2449.cpp,-1,719,,"storeAppendPrintf(&e, ""Current entries: %9d %.2f%%\n"",
                              entryCount, (100.0 * entryCount / limit));","[""addLog""]","[[], [""storeAppendPrintf"", ""&e"", ""Current"", ""entries"", ""%9d"", ""%"", ""2f%%\\n"", ""entryCount"", ""100"", ""0"", ""*"", ""entryCount"", ""/"", ""limit""]]",[17939152812405458496],6033,110880.0,2
https://github.com/squid-cache/squid/commit/35a1b223314eddb67b631cb0224d6e03a2360c77,13 Sep 2011,"SMP Caching: Core changes, IPC primitives, Shared memory cache, and Rock Store

Core changes
------------

* Added MemObject::expectedReplySize() and used it instead of object_sz.

When deciding whether an object with a known content length can be
swapped out, do not wait until the object is completely received and its
size (mem_obj->object_sz) becomes known (while asking the store to
recheck in vain with every incoming chunk). Instead, use the known
content length, if any, to make the decision.

This optimizes the common case where the complete object is eventually
received and swapped out, preventing accumulating potentially large
objects in RAM while waiting for the end of the response. Should not
affect objects with unknown content length.

Side-effect1: probably fixes several cases of unknowingly using negative
(unknown) mem_obj->object_sz in calculations. I added a few assertions
to double check some of the remaining object_sz/objectLen() uses.

Side-effect2: When expectedReplySize() is stored on disk as StoreEntry
metadata, it may help to detect truncated entries when the writer
process dies before completing the swapout.


* Removed mem->swapout.memnode in favor of mem->swapout.queue_offset.

The code used swapout.memnode pointer to keep track of the last page
that was swapped out. The code was semi-buggy because it could reset the
pointer to NULL if no new data came in before the call to doPages().
Perhaps the code relied on the assumption that the caller will never
doPages if there is no new data, but I am not sure that assumption was
correct in all cases (it could be that I broke the calling code, of course).

Moreover, the page pointer was kept without any protection from page
disappearing during asynchronous swapout. There were ""Evil hack time""
comments discussing how the page might disappear.

Fortunately, we already have mem->swapout.queue_offset that can be fed
to getBlockContainingLocation to find the page that needs to be swapped
out. There is no need to keep the page pointer around. The
queue_offset-based math is the same so we are not adding any overheads
by using that offset (in fact, we are removing some minor computations).


* Added ""close how?"" parameter to storeClose() and friends.

The old code would follow the same path when closing swapout activity
for an aborted entry and when completing a perfectly healthy swapout. In
non-shared case, that could have been OK because the abort code would
then release the entry, removing any half-written entry from the index
and the disk (but I am not sure that release happened fast enough in
100% of cases).

When the index and disk storage is shared among workers, such
""temporary"" inconsistencies result in truncated responses being
delivered by other workers to the user because once the swapout activity
is closed, other workers can start using the entry.

By adding the ""close how?"" parameter to closing methods we allow the
core and SwapDir-specific code to handle aborted swapouts appropriately.

Since swapin code is ""read only"", we do not currently distinguish
between aborted and fully satisfied readers: The readerGone enum value
applies to both cases. If needed, the SwapDir reading code can make that
distinction by analyzing how much was actually swapped in.


* Moved ""can you store this entry?"" code to virtual SwapDir::canStore().

The old code had some of the tests in SwapDir-specific canStore()
methods and some in storeDirSelect*() methods. This resulted in
inconsistencies, code duplication, and extra calculation overheads.
Making this call virtual allows individual cache_dir types to do custom
access controls.

The same method is used for cache_dir load reporting (if it returns
true). Load management needs more work, but the current code is no worse
than the old one in this aspect, and further improvements are outside
this change scope.


* Minimized from-disk StoreEntry loading/unpacking code duplication.

Moved common (and often rather complex!) code from store modules into
storeRebuildLoadEntry, storeRebuildParseEntry, and storeRebuildKeepEntry.


* Do not set object_sz when the entry is aborted because the true object
size (HTTP reply headers + body) is not known in this case. Setting
object_sz may fool client-side code into believing that the object is
complete.

This addresses an old RBC's complaint.


* When swapout initiation fails, mark swapout decision as
MemObject::SwapOut::swImpossible. This prevents the caller code from trying to
swap out again and again because swap_status becomes SWAPOUT_NONE.

TODO: Consider add SWAPOUT_ERROR, STORE_ERROR, and similar states. It
may solve several problems where the code sees _NONE or _OK and thinks
everything is peachy when in fact there was an error.


* Call haveParsedReplyHeaders() before entry->replaceHttpReply().

HaveParsedReplyHeaders() sets the entry public key and various flags (at 
least). ReplaceHttpReply() packs reply headers, starting swapout process.
It feels natural to adjust the entry _before_ we pack/swap it, but I may be
missing some side-effects here.

The change was necessary because we started calling checkCachable() from
swapoutPossible(). If haveParsedReplyHeaders() is not called before we swap
out checks, the entry will still have the private key and will be declared
impossible to cache.


* Extracted the write-to-store step from StoreEntry::replaceHttpReply().

This allows the caller to set the reply for the entry and then update the
entry and the reply before writing them to store. For example, the server-side
haveParsedReplyHeaders() code needs to set the entry timestamps and make the
entry key public before the entry starts swapping out, but the same code also
needs access to entry->getReply() and such for timestampsSet() and similar
code to work correctly.

TODO: Calls to StoreEntry::replaceHttpReply() do not have to be modified
because replaceHttpReply() does write by default. However, it is likely that
callers other than ServerStateData::setFinalReply() should take advantage of
the new split interface because they call timestampsSet() and such after
replaceHttpReply().


* Moved SwapDir::cur_size and n_disk_objects to specific SwapDirs. Removed
updateSize().  Some cache_dirs maintain their own maps and size statistics,
making the one-size-fits-all SwapDir members inappropriate.

* A new SwapDir public method swappedOut() added. It is called from
storeSwapOutFileClosed() to notify SwapDir that an object was swapped
out.

* Change SwapDir::max_size to bytes, make it protected, use maxSize() instead.

Change SwapDir::cur_size to bytes, make it private, use currentSize() instead.

Store Config.Store.avgObjectSize in bytes to avoid repeated and error-prone
KB<->bytes conversions.


* Change Config.cacheSwap.swapDirs and StoreEntry::store() type to SwapDir.

This allows using SwapDir API without dynamic_cast.


* Always call StoreEntry::abort() instead of setting ENTRY_ABORTED manually.

* Rely on entry->abort() side-effects if ENTRY_ABORTED was set.

* Added or updated comments to better document current code.

* Added operator << for dumping StoreEntry summary into the debugging
log. Needs more work to report more info (and not report yet-unknown info).

* Fixed blocking reads that were sometimes reading from random file offsets.

Core ""disk file"" reading code assumed that if the globally stored disk.offset
matches the desired offset, there is no reason to seek. This was probably done
to reduce seek overhead between consecutive reads. Unfortunately, the disk
writing code did not know about that optimization and left F->disk.offset
unchanged after writing.

This may have worked OK for UFS if it never writes to the file it reads from,
but it does not work for store modules that do both kinds of I/O at different
offsets of the same disk file.

Eventually, implement this optimization correctly or remove disk.offset.


IPC primitives
--------------

To make SMP disk and memory caching non-blocking and correct, worker and
disker processes must asynchronously communicate with each other. We are
adding a collection of classes that support such communication.

At the base of the collection is the AtomicWordT template that uses GCC atomic
primitives such as __sync_add_and_fetch() to perform atomic operations on
integral values in memory shared by multiple Squid kids. AtomicWordT is used
to implement non-blocking shared locks, queues, store tables, and page pools.

To avoid blocking or very long searches, many operations are ""optimistic"" in
nature. For example, it is possible that an atomic store map will refuse to
allocate an entry for two processes even though a blocking implementation
would have allowed one of the processes to get the map slot. We speculate that
such conflict resolution is better than blocking locks when it comes to
caching, especially if the conflicts are rare due to large number of cache
entries, fast operations, and relatively small number of kids.


TODO: Eventually, consider breaking locks left by dead kids.



Shared Memory Cache
-------------------

* Added initial shared memory cache implementation (MemStore).

The shared memory cache keeps its own compact index of cached entries using
extended Ipc::StoreMap class (MemStoreMap). The cache also strives to keep its
Root.get() results out of the store_table except during transit.

Eventually, the non-shared/local memory cache should also be implemented
using a MemStore-like class, I think. This will allow to clearly isolate
local from shared memory cache code.

Allow the user to explicitly disable shared memory caching in SMP mode via
memory_cache_shared to squid.conf. Report whether mem_cache is shared.

Disable shared memory caching by default if atomic operations are not
supported. Prohibit shared memory caching if atomic operations are not
supported.

TODO: Better limits/separation for cache and I/O shared memory pages.
Eventually, support shared memory caching of multi-page entries.


Rock Store
----------

Rock Store uses a single [large] database-style file per cache_dir to store
cached responses and metadata. This part of the design is similar to COSS.
Rock Store does not maintain or rely on swap.state ""log"" for recovery.
Instead, the database is scanned in the background to load entries when Squid
starts. Rock Store maintains its own index of cached entries and avoids global
store_table. All entries must be max-size or smaller.

In SMP mode, each Rock cache_dir is given a dedicated Kid processes called
""disker"". All SMP workers communicate with diskers to store misses and load
hits, using shared memory pages and atomic shared memory queues. Disker blocks
when doing disk I/O but workers do not. Any Diskers:Workers ratio is supported
so that the user can find and configure the optimal number of workers and
diskers for a given number of disks and CPU cores.

In non-SMP mode, should use good old blocking disk I/O, without any diskers,
but this has not been tested recently and probably needs more work.

Feature page: http://wiki.squid-cache.org/Features/RockStore

TODO: Disk rate limit to protect Squid from disk overload. More stats.
Multiple readers? Seek optimization? Remove known max-size requirement?",8765,data/crawl/squid/hunk_2449.cpp,,,data/crawl/squid/old_hunk_2449.cpp,data/crawl/squid/new_hunk_2449.cpp,-1,538,,"fatalf(""Rock cache_dir at %s failed to open db file: %s"", filePath,
               xstrerror());","[""addLog""]","[[], [""fatalf"", ""Rock"", ""cache_dir"", ""at"", ""%s"", ""failed"", ""to"", ""open"", ""db"", ""file"", ""%s"", ""filePath"", ""xstrerror""]]",[-13325161431553486176],6032,5040.0,2
https://github.com/squid-cache/squid/commit/35a1b223314eddb67b631cb0224d6e03a2360c77,13 Sep 2011,"SMP Caching: Core changes, IPC primitives, Shared memory cache, and Rock Store

Core changes
------------

* Added MemObject::expectedReplySize() and used it instead of object_sz.

When deciding whether an object with a known content length can be
swapped out, do not wait until the object is completely received and its
size (mem_obj->object_sz) becomes known (while asking the store to
recheck in vain with every incoming chunk). Instead, use the known
content length, if any, to make the decision.

This optimizes the common case where the complete object is eventually
received and swapped out, preventing accumulating potentially large
objects in RAM while waiting for the end of the response. Should not
affect objects with unknown content length.

Side-effect1: probably fixes several cases of unknowingly using negative
(unknown) mem_obj->object_sz in calculations. I added a few assertions
to double check some of the remaining object_sz/objectLen() uses.

Side-effect2: When expectedReplySize() is stored on disk as StoreEntry
metadata, it may help to detect truncated entries when the writer
process dies before completing the swapout.


* Removed mem->swapout.memnode in favor of mem->swapout.queue_offset.

The code used swapout.memnode pointer to keep track of the last page
that was swapped out. The code was semi-buggy because it could reset the
pointer to NULL if no new data came in before the call to doPages().
Perhaps the code relied on the assumption that the caller will never
doPages if there is no new data, but I am not sure that assumption was
correct in all cases (it could be that I broke the calling code, of course).

Moreover, the page pointer was kept without any protection from page
disappearing during asynchronous swapout. There were ""Evil hack time""
comments discussing how the page might disappear.

Fortunately, we already have mem->swapout.queue_offset that can be fed
to getBlockContainingLocation to find the page that needs to be swapped
out. There is no need to keep the page pointer around. The
queue_offset-based math is the same so we are not adding any overheads
by using that offset (in fact, we are removing some minor computations).


* Added ""close how?"" parameter to storeClose() and friends.

The old code would follow the same path when closing swapout activity
for an aborted entry and when completing a perfectly healthy swapout. In
non-shared case, that could have been OK because the abort code would
then release the entry, removing any half-written entry from the index
and the disk (but I am not sure that release happened fast enough in
100% of cases).

When the index and disk storage is shared among workers, such
""temporary"" inconsistencies result in truncated responses being
delivered by other workers to the user because once the swapout activity
is closed, other workers can start using the entry.

By adding the ""close how?"" parameter to closing methods we allow the
core and SwapDir-specific code to handle aborted swapouts appropriately.

Since swapin code is ""read only"", we do not currently distinguish
between aborted and fully satisfied readers: The readerGone enum value
applies to both cases. If needed, the SwapDir reading code can make that
distinction by analyzing how much was actually swapped in.


* Moved ""can you store this entry?"" code to virtual SwapDir::canStore().

The old code had some of the tests in SwapDir-specific canStore()
methods and some in storeDirSelect*() methods. This resulted in
inconsistencies, code duplication, and extra calculation overheads.
Making this call virtual allows individual cache_dir types to do custom
access controls.

The same method is used for cache_dir load reporting (if it returns
true). Load management needs more work, but the current code is no worse
than the old one in this aspect, and further improvements are outside
this change scope.


* Minimized from-disk StoreEntry loading/unpacking code duplication.

Moved common (and often rather complex!) code from store modules into
storeRebuildLoadEntry, storeRebuildParseEntry, and storeRebuildKeepEntry.


* Do not set object_sz when the entry is aborted because the true object
size (HTTP reply headers + body) is not known in this case. Setting
object_sz may fool client-side code into believing that the object is
complete.

This addresses an old RBC's complaint.


* When swapout initiation fails, mark swapout decision as
MemObject::SwapOut::swImpossible. This prevents the caller code from trying to
swap out again and again because swap_status becomes SWAPOUT_NONE.

TODO: Consider add SWAPOUT_ERROR, STORE_ERROR, and similar states. It
may solve several problems where the code sees _NONE or _OK and thinks
everything is peachy when in fact there was an error.


* Call haveParsedReplyHeaders() before entry->replaceHttpReply().

HaveParsedReplyHeaders() sets the entry public key and various flags (at 
least). ReplaceHttpReply() packs reply headers, starting swapout process.
It feels natural to adjust the entry _before_ we pack/swap it, but I may be
missing some side-effects here.

The change was necessary because we started calling checkCachable() from
swapoutPossible(). If haveParsedReplyHeaders() is not called before we swap
out checks, the entry will still have the private key and will be declared
impossible to cache.


* Extracted the write-to-store step from StoreEntry::replaceHttpReply().

This allows the caller to set the reply for the entry and then update the
entry and the reply before writing them to store. For example, the server-side
haveParsedReplyHeaders() code needs to set the entry timestamps and make the
entry key public before the entry starts swapping out, but the same code also
needs access to entry->getReply() and such for timestampsSet() and similar
code to work correctly.

TODO: Calls to StoreEntry::replaceHttpReply() do not have to be modified
because replaceHttpReply() does write by default. However, it is likely that
callers other than ServerStateData::setFinalReply() should take advantage of
the new split interface because they call timestampsSet() and such after
replaceHttpReply().


* Moved SwapDir::cur_size and n_disk_objects to specific SwapDirs. Removed
updateSize().  Some cache_dirs maintain their own maps and size statistics,
making the one-size-fits-all SwapDir members inappropriate.

* A new SwapDir public method swappedOut() added. It is called from
storeSwapOutFileClosed() to notify SwapDir that an object was swapped
out.

* Change SwapDir::max_size to bytes, make it protected, use maxSize() instead.

Change SwapDir::cur_size to bytes, make it private, use currentSize() instead.

Store Config.Store.avgObjectSize in bytes to avoid repeated and error-prone
KB<->bytes conversions.


* Change Config.cacheSwap.swapDirs and StoreEntry::store() type to SwapDir.

This allows using SwapDir API without dynamic_cast.


* Always call StoreEntry::abort() instead of setting ENTRY_ABORTED manually.

* Rely on entry->abort() side-effects if ENTRY_ABORTED was set.

* Added or updated comments to better document current code.

* Added operator << for dumping StoreEntry summary into the debugging
log. Needs more work to report more info (and not report yet-unknown info).

* Fixed blocking reads that were sometimes reading from random file offsets.

Core ""disk file"" reading code assumed that if the globally stored disk.offset
matches the desired offset, there is no reason to seek. This was probably done
to reduce seek overhead between consecutive reads. Unfortunately, the disk
writing code did not know about that optimization and left F->disk.offset
unchanged after writing.

This may have worked OK for UFS if it never writes to the file it reads from,
but it does not work for store modules that do both kinds of I/O at different
offsets of the same disk file.

Eventually, implement this optimization correctly or remove disk.offset.


IPC primitives
--------------

To make SMP disk and memory caching non-blocking and correct, worker and
disker processes must asynchronously communicate with each other. We are
adding a collection of classes that support such communication.

At the base of the collection is the AtomicWordT template that uses GCC atomic
primitives such as __sync_add_and_fetch() to perform atomic operations on
integral values in memory shared by multiple Squid kids. AtomicWordT is used
to implement non-blocking shared locks, queues, store tables, and page pools.

To avoid blocking or very long searches, many operations are ""optimistic"" in
nature. For example, it is possible that an atomic store map will refuse to
allocate an entry for two processes even though a blocking implementation
would have allowed one of the processes to get the map slot. We speculate that
such conflict resolution is better than blocking locks when it comes to
caching, especially if the conflicts are rare due to large number of cache
entries, fast operations, and relatively small number of kids.


TODO: Eventually, consider breaking locks left by dead kids.



Shared Memory Cache
-------------------

* Added initial shared memory cache implementation (MemStore).

The shared memory cache keeps its own compact index of cached entries using
extended Ipc::StoreMap class (MemStoreMap). The cache also strives to keep its
Root.get() results out of the store_table except during transit.

Eventually, the non-shared/local memory cache should also be implemented
using a MemStore-like class, I think. This will allow to clearly isolate
local from shared memory cache code.

Allow the user to explicitly disable shared memory caching in SMP mode via
memory_cache_shared to squid.conf. Report whether mem_cache is shared.

Disable shared memory caching by default if atomic operations are not
supported. Prohibit shared memory caching if atomic operations are not
supported.

TODO: Better limits/separation for cache and I/O shared memory pages.
Eventually, support shared memory caching of multi-page entries.


Rock Store
----------

Rock Store uses a single [large] database-style file per cache_dir to store
cached responses and metadata. This part of the design is similar to COSS.
Rock Store does not maintain or rely on swap.state ""log"" for recovery.
Instead, the database is scanned in the background to load entries when Squid
starts. Rock Store maintains its own index of cached entries and avoids global
store_table. All entries must be max-size or smaller.

In SMP mode, each Rock cache_dir is given a dedicated Kid processes called
""disker"". All SMP workers communicate with diskers to store misses and load
hits, using shared memory pages and atomic shared memory queues. Disker blocks
when doing disk I/O but workers do not. Any Diskers:Workers ratio is supported
so that the user can find and configure the optimal number of workers and
diskers for a given number of disks and CPU cores.

In non-SMP mode, should use good old blocking disk I/O, without any diskers,
but this has not been tested recently and probably needs more work.

Feature page: http://wiki.squid-cache.org/Features/RockStore

TODO: Disk rate limit to protect Squid from disk overload. More stats.
Multiple readers? Seek optimization? Remove known max-size requirement?",8765,data/crawl/squid/hunk_2449.cpp,,,data/crawl/squid/old_hunk_2449.cpp,data/crawl/squid/new_hunk_2449.cpp,-1,535,,"fatalf(""Rock cache_dir failed to initialize db file: %s"", filePath);","[""addLog""]","[[], [""fatalf"", ""Rock"", ""cache_dir"", ""failed"", ""to"", ""initialize"", ""db"", ""file"", ""%s"", ""filePath""]]",[-10087827577497050811],6031,164880.0,2
https://github.com/squid-cache/squid/commit/35a1b223314eddb67b631cb0224d6e03a2360c77,13 Sep 2011,"SMP Caching: Core changes, IPC primitives, Shared memory cache, and Rock Store

Core changes
------------

* Added MemObject::expectedReplySize() and used it instead of object_sz.

When deciding whether an object with a known content length can be
swapped out, do not wait until the object is completely received and its
size (mem_obj->object_sz) becomes known (while asking the store to
recheck in vain with every incoming chunk). Instead, use the known
content length, if any, to make the decision.

This optimizes the common case where the complete object is eventually
received and swapped out, preventing accumulating potentially large
objects in RAM while waiting for the end of the response. Should not
affect objects with unknown content length.

Side-effect1: probably fixes several cases of unknowingly using negative
(unknown) mem_obj->object_sz in calculations. I added a few assertions
to double check some of the remaining object_sz/objectLen() uses.

Side-effect2: When expectedReplySize() is stored on disk as StoreEntry
metadata, it may help to detect truncated entries when the writer
process dies before completing the swapout.


* Removed mem->swapout.memnode in favor of mem->swapout.queue_offset.

The code used swapout.memnode pointer to keep track of the last page
that was swapped out. The code was semi-buggy because it could reset the
pointer to NULL if no new data came in before the call to doPages().
Perhaps the code relied on the assumption that the caller will never
doPages if there is no new data, but I am not sure that assumption was
correct in all cases (it could be that I broke the calling code, of course).

Moreover, the page pointer was kept without any protection from page
disappearing during asynchronous swapout. There were ""Evil hack time""
comments discussing how the page might disappear.

Fortunately, we already have mem->swapout.queue_offset that can be fed
to getBlockContainingLocation to find the page that needs to be swapped
out. There is no need to keep the page pointer around. The
queue_offset-based math is the same so we are not adding any overheads
by using that offset (in fact, we are removing some minor computations).


* Added ""close how?"" parameter to storeClose() and friends.

The old code would follow the same path when closing swapout activity
for an aborted entry and when completing a perfectly healthy swapout. In
non-shared case, that could have been OK because the abort code would
then release the entry, removing any half-written entry from the index
and the disk (but I am not sure that release happened fast enough in
100% of cases).

When the index and disk storage is shared among workers, such
""temporary"" inconsistencies result in truncated responses being
delivered by other workers to the user because once the swapout activity
is closed, other workers can start using the entry.

By adding the ""close how?"" parameter to closing methods we allow the
core and SwapDir-specific code to handle aborted swapouts appropriately.

Since swapin code is ""read only"", we do not currently distinguish
between aborted and fully satisfied readers: The readerGone enum value
applies to both cases. If needed, the SwapDir reading code can make that
distinction by analyzing how much was actually swapped in.


* Moved ""can you store this entry?"" code to virtual SwapDir::canStore().

The old code had some of the tests in SwapDir-specific canStore()
methods and some in storeDirSelect*() methods. This resulted in
inconsistencies, code duplication, and extra calculation overheads.
Making this call virtual allows individual cache_dir types to do custom
access controls.

The same method is used for cache_dir load reporting (if it returns
true). Load management needs more work, but the current code is no worse
than the old one in this aspect, and further improvements are outside
this change scope.


* Minimized from-disk StoreEntry loading/unpacking code duplication.

Moved common (and often rather complex!) code from store modules into
storeRebuildLoadEntry, storeRebuildParseEntry, and storeRebuildKeepEntry.


* Do not set object_sz when the entry is aborted because the true object
size (HTTP reply headers + body) is not known in this case. Setting
object_sz may fool client-side code into believing that the object is
complete.

This addresses an old RBC's complaint.


* When swapout initiation fails, mark swapout decision as
MemObject::SwapOut::swImpossible. This prevents the caller code from trying to
swap out again and again because swap_status becomes SWAPOUT_NONE.

TODO: Consider add SWAPOUT_ERROR, STORE_ERROR, and similar states. It
may solve several problems where the code sees _NONE or _OK and thinks
everything is peachy when in fact there was an error.


* Call haveParsedReplyHeaders() before entry->replaceHttpReply().

HaveParsedReplyHeaders() sets the entry public key and various flags (at 
least). ReplaceHttpReply() packs reply headers, starting swapout process.
It feels natural to adjust the entry _before_ we pack/swap it, but I may be
missing some side-effects here.

The change was necessary because we started calling checkCachable() from
swapoutPossible(). If haveParsedReplyHeaders() is not called before we swap
out checks, the entry will still have the private key and will be declared
impossible to cache.


* Extracted the write-to-store step from StoreEntry::replaceHttpReply().

This allows the caller to set the reply for the entry and then update the
entry and the reply before writing them to store. For example, the server-side
haveParsedReplyHeaders() code needs to set the entry timestamps and make the
entry key public before the entry starts swapping out, but the same code also
needs access to entry->getReply() and such for timestampsSet() and similar
code to work correctly.

TODO: Calls to StoreEntry::replaceHttpReply() do not have to be modified
because replaceHttpReply() does write by default. However, it is likely that
callers other than ServerStateData::setFinalReply() should take advantage of
the new split interface because they call timestampsSet() and such after
replaceHttpReply().


* Moved SwapDir::cur_size and n_disk_objects to specific SwapDirs. Removed
updateSize().  Some cache_dirs maintain their own maps and size statistics,
making the one-size-fits-all SwapDir members inappropriate.

* A new SwapDir public method swappedOut() added. It is called from
storeSwapOutFileClosed() to notify SwapDir that an object was swapped
out.

* Change SwapDir::max_size to bytes, make it protected, use maxSize() instead.

Change SwapDir::cur_size to bytes, make it private, use currentSize() instead.

Store Config.Store.avgObjectSize in bytes to avoid repeated and error-prone
KB<->bytes conversions.


* Change Config.cacheSwap.swapDirs and StoreEntry::store() type to SwapDir.

This allows using SwapDir API without dynamic_cast.


* Always call StoreEntry::abort() instead of setting ENTRY_ABORTED manually.

* Rely on entry->abort() side-effects if ENTRY_ABORTED was set.

* Added or updated comments to better document current code.

* Added operator << for dumping StoreEntry summary into the debugging
log. Needs more work to report more info (and not report yet-unknown info).

* Fixed blocking reads that were sometimes reading from random file offsets.

Core ""disk file"" reading code assumed that if the globally stored disk.offset
matches the desired offset, there is no reason to seek. This was probably done
to reduce seek overhead between consecutive reads. Unfortunately, the disk
writing code did not know about that optimization and left F->disk.offset
unchanged after writing.

This may have worked OK for UFS if it never writes to the file it reads from,
but it does not work for store modules that do both kinds of I/O at different
offsets of the same disk file.

Eventually, implement this optimization correctly or remove disk.offset.


IPC primitives
--------------

To make SMP disk and memory caching non-blocking and correct, worker and
disker processes must asynchronously communicate with each other. We are
adding a collection of classes that support such communication.

At the base of the collection is the AtomicWordT template that uses GCC atomic
primitives such as __sync_add_and_fetch() to perform atomic operations on
integral values in memory shared by multiple Squid kids. AtomicWordT is used
to implement non-blocking shared locks, queues, store tables, and page pools.

To avoid blocking or very long searches, many operations are ""optimistic"" in
nature. For example, it is possible that an atomic store map will refuse to
allocate an entry for two processes even though a blocking implementation
would have allowed one of the processes to get the map slot. We speculate that
such conflict resolution is better than blocking locks when it comes to
caching, especially if the conflicts are rare due to large number of cache
entries, fast operations, and relatively small number of kids.


TODO: Eventually, consider breaking locks left by dead kids.



Shared Memory Cache
-------------------

* Added initial shared memory cache implementation (MemStore).

The shared memory cache keeps its own compact index of cached entries using
extended Ipc::StoreMap class (MemStoreMap). The cache also strives to keep its
Root.get() results out of the store_table except during transit.

Eventually, the non-shared/local memory cache should also be implemented
using a MemStore-like class, I think. This will allow to clearly isolate
local from shared memory cache code.

Allow the user to explicitly disable shared memory caching in SMP mode via
memory_cache_shared to squid.conf. Report whether mem_cache is shared.

Disable shared memory caching by default if atomic operations are not
supported. Prohibit shared memory caching if atomic operations are not
supported.

TODO: Better limits/separation for cache and I/O shared memory pages.
Eventually, support shared memory caching of multi-page entries.


Rock Store
----------

Rock Store uses a single [large] database-style file per cache_dir to store
cached responses and metadata. This part of the design is similar to COSS.
Rock Store does not maintain or rely on swap.state ""log"" for recovery.
Instead, the database is scanned in the background to load entries when Squid
starts. Rock Store maintains its own index of cached entries and avoids global
store_table. All entries must be max-size or smaller.

In SMP mode, each Rock cache_dir is given a dedicated Kid processes called
""disker"". All SMP workers communicate with diskers to store misses and load
hits, using shared memory pages and atomic shared memory queues. Disker blocks
when doing disk I/O but workers do not. Any Diskers:Workers ratio is supported
so that the user can find and configure the optimal number of workers and
diskers for a given number of disks and CPU cores.

In non-SMP mode, should use good old blocking disk I/O, without any diskers,
but this has not been tested recently and probably needs more work.

Feature page: http://wiki.squid-cache.org/Features/RockStore

TODO: Disk rate limit to protect Squid from disk overload. More stats.
Multiple readers? Seek optimization? Remove known max-size requirement?",8765,data/crawl/squid/hunk_2449.cpp,,,data/crawl/squid/old_hunk_2449.cpp,data/crawl/squid/new_hunk_2449.cpp,-1,335,,"fatal(""Rock store requires a positive max-size"");","[""addLog""]","[[], [""fatal"", ""Rock"", ""store"", ""requires"", ""a"", ""positive"", ""max"", ""size""]]",[-2511445573136777763],6030,164880.0,2
https://github.com/squid-cache/squid/commit/35a1b223314eddb67b631cb0224d6e03a2360c77,13 Sep 2011,"SMP Caching: Core changes, IPC primitives, Shared memory cache, and Rock Store

Core changes
------------

* Added MemObject::expectedReplySize() and used it instead of object_sz.

When deciding whether an object with a known content length can be
swapped out, do not wait until the object is completely received and its
size (mem_obj->object_sz) becomes known (while asking the store to
recheck in vain with every incoming chunk). Instead, use the known
content length, if any, to make the decision.

This optimizes the common case where the complete object is eventually
received and swapped out, preventing accumulating potentially large
objects in RAM while waiting for the end of the response. Should not
affect objects with unknown content length.

Side-effect1: probably fixes several cases of unknowingly using negative
(unknown) mem_obj->object_sz in calculations. I added a few assertions
to double check some of the remaining object_sz/objectLen() uses.

Side-effect2: When expectedReplySize() is stored on disk as StoreEntry
metadata, it may help to detect truncated entries when the writer
process dies before completing the swapout.


* Removed mem->swapout.memnode in favor of mem->swapout.queue_offset.

The code used swapout.memnode pointer to keep track of the last page
that was swapped out. The code was semi-buggy because it could reset the
pointer to NULL if no new data came in before the call to doPages().
Perhaps the code relied on the assumption that the caller will never
doPages if there is no new data, but I am not sure that assumption was
correct in all cases (it could be that I broke the calling code, of course).

Moreover, the page pointer was kept without any protection from page
disappearing during asynchronous swapout. There were ""Evil hack time""
comments discussing how the page might disappear.

Fortunately, we already have mem->swapout.queue_offset that can be fed
to getBlockContainingLocation to find the page that needs to be swapped
out. There is no need to keep the page pointer around. The
queue_offset-based math is the same so we are not adding any overheads
by using that offset (in fact, we are removing some minor computations).


* Added ""close how?"" parameter to storeClose() and friends.

The old code would follow the same path when closing swapout activity
for an aborted entry and when completing a perfectly healthy swapout. In
non-shared case, that could have been OK because the abort code would
then release the entry, removing any half-written entry from the index
and the disk (but I am not sure that release happened fast enough in
100% of cases).

When the index and disk storage is shared among workers, such
""temporary"" inconsistencies result in truncated responses being
delivered by other workers to the user because once the swapout activity
is closed, other workers can start using the entry.

By adding the ""close how?"" parameter to closing methods we allow the
core and SwapDir-specific code to handle aborted swapouts appropriately.

Since swapin code is ""read only"", we do not currently distinguish
between aborted and fully satisfied readers: The readerGone enum value
applies to both cases. If needed, the SwapDir reading code can make that
distinction by analyzing how much was actually swapped in.


* Moved ""can you store this entry?"" code to virtual SwapDir::canStore().

The old code had some of the tests in SwapDir-specific canStore()
methods and some in storeDirSelect*() methods. This resulted in
inconsistencies, code duplication, and extra calculation overheads.
Making this call virtual allows individual cache_dir types to do custom
access controls.

The same method is used for cache_dir load reporting (if it returns
true). Load management needs more work, but the current code is no worse
than the old one in this aspect, and further improvements are outside
this change scope.


* Minimized from-disk StoreEntry loading/unpacking code duplication.

Moved common (and often rather complex!) code from store modules into
storeRebuildLoadEntry, storeRebuildParseEntry, and storeRebuildKeepEntry.


* Do not set object_sz when the entry is aborted because the true object
size (HTTP reply headers + body) is not known in this case. Setting
object_sz may fool client-side code into believing that the object is
complete.

This addresses an old RBC's complaint.


* When swapout initiation fails, mark swapout decision as
MemObject::SwapOut::swImpossible. This prevents the caller code from trying to
swap out again and again because swap_status becomes SWAPOUT_NONE.

TODO: Consider add SWAPOUT_ERROR, STORE_ERROR, and similar states. It
may solve several problems where the code sees _NONE or _OK and thinks
everything is peachy when in fact there was an error.


* Call haveParsedReplyHeaders() before entry->replaceHttpReply().

HaveParsedReplyHeaders() sets the entry public key and various flags (at 
least). ReplaceHttpReply() packs reply headers, starting swapout process.
It feels natural to adjust the entry _before_ we pack/swap it, but I may be
missing some side-effects here.

The change was necessary because we started calling checkCachable() from
swapoutPossible(). If haveParsedReplyHeaders() is not called before we swap
out checks, the entry will still have the private key and will be declared
impossible to cache.


* Extracted the write-to-store step from StoreEntry::replaceHttpReply().

This allows the caller to set the reply for the entry and then update the
entry and the reply before writing them to store. For example, the server-side
haveParsedReplyHeaders() code needs to set the entry timestamps and make the
entry key public before the entry starts swapping out, but the same code also
needs access to entry->getReply() and such for timestampsSet() and similar
code to work correctly.

TODO: Calls to StoreEntry::replaceHttpReply() do not have to be modified
because replaceHttpReply() does write by default. However, it is likely that
callers other than ServerStateData::setFinalReply() should take advantage of
the new split interface because they call timestampsSet() and such after
replaceHttpReply().


* Moved SwapDir::cur_size and n_disk_objects to specific SwapDirs. Removed
updateSize().  Some cache_dirs maintain their own maps and size statistics,
making the one-size-fits-all SwapDir members inappropriate.

* A new SwapDir public method swappedOut() added. It is called from
storeSwapOutFileClosed() to notify SwapDir that an object was swapped
out.

* Change SwapDir::max_size to bytes, make it protected, use maxSize() instead.

Change SwapDir::cur_size to bytes, make it private, use currentSize() instead.

Store Config.Store.avgObjectSize in bytes to avoid repeated and error-prone
KB<->bytes conversions.


* Change Config.cacheSwap.swapDirs and StoreEntry::store() type to SwapDir.

This allows using SwapDir API without dynamic_cast.


* Always call StoreEntry::abort() instead of setting ENTRY_ABORTED manually.

* Rely on entry->abort() side-effects if ENTRY_ABORTED was set.

* Added or updated comments to better document current code.

* Added operator << for dumping StoreEntry summary into the debugging
log. Needs more work to report more info (and not report yet-unknown info).

* Fixed blocking reads that were sometimes reading from random file offsets.

Core ""disk file"" reading code assumed that if the globally stored disk.offset
matches the desired offset, there is no reason to seek. This was probably done
to reduce seek overhead between consecutive reads. Unfortunately, the disk
writing code did not know about that optimization and left F->disk.offset
unchanged after writing.

This may have worked OK for UFS if it never writes to the file it reads from,
but it does not work for store modules that do both kinds of I/O at different
offsets of the same disk file.

Eventually, implement this optimization correctly or remove disk.offset.


IPC primitives
--------------

To make SMP disk and memory caching non-blocking and correct, worker and
disker processes must asynchronously communicate with each other. We are
adding a collection of classes that support such communication.

At the base of the collection is the AtomicWordT template that uses GCC atomic
primitives such as __sync_add_and_fetch() to perform atomic operations on
integral values in memory shared by multiple Squid kids. AtomicWordT is used
to implement non-blocking shared locks, queues, store tables, and page pools.

To avoid blocking or very long searches, many operations are ""optimistic"" in
nature. For example, it is possible that an atomic store map will refuse to
allocate an entry for two processes even though a blocking implementation
would have allowed one of the processes to get the map slot. We speculate that
such conflict resolution is better than blocking locks when it comes to
caching, especially if the conflicts are rare due to large number of cache
entries, fast operations, and relatively small number of kids.


TODO: Eventually, consider breaking locks left by dead kids.



Shared Memory Cache
-------------------

* Added initial shared memory cache implementation (MemStore).

The shared memory cache keeps its own compact index of cached entries using
extended Ipc::StoreMap class (MemStoreMap). The cache also strives to keep its
Root.get() results out of the store_table except during transit.

Eventually, the non-shared/local memory cache should also be implemented
using a MemStore-like class, I think. This will allow to clearly isolate
local from shared memory cache code.

Allow the user to explicitly disable shared memory caching in SMP mode via
memory_cache_shared to squid.conf. Report whether mem_cache is shared.

Disable shared memory caching by default if atomic operations are not
supported. Prohibit shared memory caching if atomic operations are not
supported.

TODO: Better limits/separation for cache and I/O shared memory pages.
Eventually, support shared memory caching of multi-page entries.


Rock Store
----------

Rock Store uses a single [large] database-style file per cache_dir to store
cached responses and metadata. This part of the design is similar to COSS.
Rock Store does not maintain or rely on swap.state ""log"" for recovery.
Instead, the database is scanned in the background to load entries when Squid
starts. Rock Store maintains its own index of cached entries and avoids global
store_table. All entries must be max-size or smaller.

In SMP mode, each Rock cache_dir is given a dedicated Kid processes called
""disker"". All SMP workers communicate with diskers to store misses and load
hits, using shared memory pages and atomic shared memory queues. Disker blocks
when doing disk I/O but workers do not. Any Diskers:Workers ratio is supported
so that the user can find and configure the optimal number of workers and
diskers for a given number of disks and CPU cores.

In non-SMP mode, should use good old blocking disk I/O, without any diskers,
but this has not been tested recently and probably needs more work.

Feature page: http://wiki.squid-cache.org/Features/RockStore

TODO: Disk rate limit to protect Squid from disk overload. More stats.
Multiple readers? Seek optimization? Remove known max-size requirement?",8765,data/crawl/squid/hunk_2449.cpp,,,data/crawl/squid/old_hunk_2449.cpp,data/crawl/squid/new_hunk_2449.cpp,-1,326,,"storeAppendPrintf(e, "" swap-timeout=%""PRId64,
                          static_cast<int64_t>(fileConfig.ioTimeout));","[""addLog""]","[[], [""storeAppendPrintf"", ""e"", ""swap"", ""timeout"", ""%"", ""PRId64"", ""static_cast"", ""int64_t"", ""fileConfig"", ""ioTimeout""]]",[20147318930528290067],6029,2160.0,2
https://github.com/squid-cache/squid/commit/35a1b223314eddb67b631cb0224d6e03a2360c77,13 Sep 2011,"SMP Caching: Core changes, IPC primitives, Shared memory cache, and Rock Store

Core changes
------------

* Added MemObject::expectedReplySize() and used it instead of object_sz.

When deciding whether an object with a known content length can be
swapped out, do not wait until the object is completely received and its
size (mem_obj->object_sz) becomes known (while asking the store to
recheck in vain with every incoming chunk). Instead, use the known
content length, if any, to make the decision.

This optimizes the common case where the complete object is eventually
received and swapped out, preventing accumulating potentially large
objects in RAM while waiting for the end of the response. Should not
affect objects with unknown content length.

Side-effect1: probably fixes several cases of unknowingly using negative
(unknown) mem_obj->object_sz in calculations. I added a few assertions
to double check some of the remaining object_sz/objectLen() uses.

Side-effect2: When expectedReplySize() is stored on disk as StoreEntry
metadata, it may help to detect truncated entries when the writer
process dies before completing the swapout.


* Removed mem->swapout.memnode in favor of mem->swapout.queue_offset.

The code used swapout.memnode pointer to keep track of the last page
that was swapped out. The code was semi-buggy because it could reset the
pointer to NULL if no new data came in before the call to doPages().
Perhaps the code relied on the assumption that the caller will never
doPages if there is no new data, but I am not sure that assumption was
correct in all cases (it could be that I broke the calling code, of course).

Moreover, the page pointer was kept without any protection from page
disappearing during asynchronous swapout. There were ""Evil hack time""
comments discussing how the page might disappear.

Fortunately, we already have mem->swapout.queue_offset that can be fed
to getBlockContainingLocation to find the page that needs to be swapped
out. There is no need to keep the page pointer around. The
queue_offset-based math is the same so we are not adding any overheads
by using that offset (in fact, we are removing some minor computations).


* Added ""close how?"" parameter to storeClose() and friends.

The old code would follow the same path when closing swapout activity
for an aborted entry and when completing a perfectly healthy swapout. In
non-shared case, that could have been OK because the abort code would
then release the entry, removing any half-written entry from the index
and the disk (but I am not sure that release happened fast enough in
100% of cases).

When the index and disk storage is shared among workers, such
""temporary"" inconsistencies result in truncated responses being
delivered by other workers to the user because once the swapout activity
is closed, other workers can start using the entry.

By adding the ""close how?"" parameter to closing methods we allow the
core and SwapDir-specific code to handle aborted swapouts appropriately.

Since swapin code is ""read only"", we do not currently distinguish
between aborted and fully satisfied readers: The readerGone enum value
applies to both cases. If needed, the SwapDir reading code can make that
distinction by analyzing how much was actually swapped in.


* Moved ""can you store this entry?"" code to virtual SwapDir::canStore().

The old code had some of the tests in SwapDir-specific canStore()
methods and some in storeDirSelect*() methods. This resulted in
inconsistencies, code duplication, and extra calculation overheads.
Making this call virtual allows individual cache_dir types to do custom
access controls.

The same method is used for cache_dir load reporting (if it returns
true). Load management needs more work, but the current code is no worse
than the old one in this aspect, and further improvements are outside
this change scope.


* Minimized from-disk StoreEntry loading/unpacking code duplication.

Moved common (and often rather complex!) code from store modules into
storeRebuildLoadEntry, storeRebuildParseEntry, and storeRebuildKeepEntry.


* Do not set object_sz when the entry is aborted because the true object
size (HTTP reply headers + body) is not known in this case. Setting
object_sz may fool client-side code into believing that the object is
complete.

This addresses an old RBC's complaint.


* When swapout initiation fails, mark swapout decision as
MemObject::SwapOut::swImpossible. This prevents the caller code from trying to
swap out again and again because swap_status becomes SWAPOUT_NONE.

TODO: Consider add SWAPOUT_ERROR, STORE_ERROR, and similar states. It
may solve several problems where the code sees _NONE or _OK and thinks
everything is peachy when in fact there was an error.


* Call haveParsedReplyHeaders() before entry->replaceHttpReply().

HaveParsedReplyHeaders() sets the entry public key and various flags (at 
least). ReplaceHttpReply() packs reply headers, starting swapout process.
It feels natural to adjust the entry _before_ we pack/swap it, but I may be
missing some side-effects here.

The change was necessary because we started calling checkCachable() from
swapoutPossible(). If haveParsedReplyHeaders() is not called before we swap
out checks, the entry will still have the private key and will be declared
impossible to cache.


* Extracted the write-to-store step from StoreEntry::replaceHttpReply().

This allows the caller to set the reply for the entry and then update the
entry and the reply before writing them to store. For example, the server-side
haveParsedReplyHeaders() code needs to set the entry timestamps and make the
entry key public before the entry starts swapping out, but the same code also
needs access to entry->getReply() and such for timestampsSet() and similar
code to work correctly.

TODO: Calls to StoreEntry::replaceHttpReply() do not have to be modified
because replaceHttpReply() does write by default. However, it is likely that
callers other than ServerStateData::setFinalReply() should take advantage of
the new split interface because they call timestampsSet() and such after
replaceHttpReply().


* Moved SwapDir::cur_size and n_disk_objects to specific SwapDirs. Removed
updateSize().  Some cache_dirs maintain their own maps and size statistics,
making the one-size-fits-all SwapDir members inappropriate.

* A new SwapDir public method swappedOut() added. It is called from
storeSwapOutFileClosed() to notify SwapDir that an object was swapped
out.

* Change SwapDir::max_size to bytes, make it protected, use maxSize() instead.

Change SwapDir::cur_size to bytes, make it private, use currentSize() instead.

Store Config.Store.avgObjectSize in bytes to avoid repeated and error-prone
KB<->bytes conversions.


* Change Config.cacheSwap.swapDirs and StoreEntry::store() type to SwapDir.

This allows using SwapDir API without dynamic_cast.


* Always call StoreEntry::abort() instead of setting ENTRY_ABORTED manually.

* Rely on entry->abort() side-effects if ENTRY_ABORTED was set.

* Added or updated comments to better document current code.

* Added operator << for dumping StoreEntry summary into the debugging
log. Needs more work to report more info (and not report yet-unknown info).

* Fixed blocking reads that were sometimes reading from random file offsets.

Core ""disk file"" reading code assumed that if the globally stored disk.offset
matches the desired offset, there is no reason to seek. This was probably done
to reduce seek overhead between consecutive reads. Unfortunately, the disk
writing code did not know about that optimization and left F->disk.offset
unchanged after writing.

This may have worked OK for UFS if it never writes to the file it reads from,
but it does not work for store modules that do both kinds of I/O at different
offsets of the same disk file.

Eventually, implement this optimization correctly or remove disk.offset.


IPC primitives
--------------

To make SMP disk and memory caching non-blocking and correct, worker and
disker processes must asynchronously communicate with each other. We are
adding a collection of classes that support such communication.

At the base of the collection is the AtomicWordT template that uses GCC atomic
primitives such as __sync_add_and_fetch() to perform atomic operations on
integral values in memory shared by multiple Squid kids. AtomicWordT is used
to implement non-blocking shared locks, queues, store tables, and page pools.

To avoid blocking or very long searches, many operations are ""optimistic"" in
nature. For example, it is possible that an atomic store map will refuse to
allocate an entry for two processes even though a blocking implementation
would have allowed one of the processes to get the map slot. We speculate that
such conflict resolution is better than blocking locks when it comes to
caching, especially if the conflicts are rare due to large number of cache
entries, fast operations, and relatively small number of kids.


TODO: Eventually, consider breaking locks left by dead kids.



Shared Memory Cache
-------------------

* Added initial shared memory cache implementation (MemStore).

The shared memory cache keeps its own compact index of cached entries using
extended Ipc::StoreMap class (MemStoreMap). The cache also strives to keep its
Root.get() results out of the store_table except during transit.

Eventually, the non-shared/local memory cache should also be implemented
using a MemStore-like class, I think. This will allow to clearly isolate
local from shared memory cache code.

Allow the user to explicitly disable shared memory caching in SMP mode via
memory_cache_shared to squid.conf. Report whether mem_cache is shared.

Disable shared memory caching by default if atomic operations are not
supported. Prohibit shared memory caching if atomic operations are not
supported.

TODO: Better limits/separation for cache and I/O shared memory pages.
Eventually, support shared memory caching of multi-page entries.


Rock Store
----------

Rock Store uses a single [large] database-style file per cache_dir to store
cached responses and metadata. This part of the design is similar to COSS.
Rock Store does not maintain or rely on swap.state ""log"" for recovery.
Instead, the database is scanned in the background to load entries when Squid
starts. Rock Store maintains its own index of cached entries and avoids global
store_table. All entries must be max-size or smaller.

In SMP mode, each Rock cache_dir is given a dedicated Kid processes called
""disker"". All SMP workers communicate with diskers to store misses and load
hits, using shared memory pages and atomic shared memory queues. Disker blocks
when doing disk I/O but workers do not. Any Diskers:Workers ratio is supported
so that the user can find and configure the optimal number of workers and
diskers for a given number of disks and CPU cores.

In non-SMP mode, should use good old blocking disk I/O, without any diskers,
but this has not been tested recently and probably needs more work.

Feature page: http://wiki.squid-cache.org/Features/RockStore

TODO: Disk rate limit to protect Squid from disk overload. More stats.
Multiple readers? Seek optimization? Remove known max-size requirement?",8765,data/crawl/squid/hunk_2449.cpp,,,data/crawl/squid/old_hunk_2449.cpp,data/crawl/squid/new_hunk_2449.cpp,-1,277,,"fatal(""negative Rock cache_dir size value"");","[""addLog""]","[[], [""fatal"", ""negative"", ""Rock"", ""cache_dir"", ""size"", ""value""]]",[-19892525860174460993],6028,164880.0,2
https://github.com/squid-cache/squid/commit/35a1b223314eddb67b631cb0224d6e03a2360c77,13 Sep 2011,"SMP Caching: Core changes, IPC primitives, Shared memory cache, and Rock Store

Core changes
------------

* Added MemObject::expectedReplySize() and used it instead of object_sz.

When deciding whether an object with a known content length can be
swapped out, do not wait until the object is completely received and its
size (mem_obj->object_sz) becomes known (while asking the store to
recheck in vain with every incoming chunk). Instead, use the known
content length, if any, to make the decision.

This optimizes the common case where the complete object is eventually
received and swapped out, preventing accumulating potentially large
objects in RAM while waiting for the end of the response. Should not
affect objects with unknown content length.

Side-effect1: probably fixes several cases of unknowingly using negative
(unknown) mem_obj->object_sz in calculations. I added a few assertions
to double check some of the remaining object_sz/objectLen() uses.

Side-effect2: When expectedReplySize() is stored on disk as StoreEntry
metadata, it may help to detect truncated entries when the writer
process dies before completing the swapout.


* Removed mem->swapout.memnode in favor of mem->swapout.queue_offset.

The code used swapout.memnode pointer to keep track of the last page
that was swapped out. The code was semi-buggy because it could reset the
pointer to NULL if no new data came in before the call to doPages().
Perhaps the code relied on the assumption that the caller will never
doPages if there is no new data, but I am not sure that assumption was
correct in all cases (it could be that I broke the calling code, of course).

Moreover, the page pointer was kept without any protection from page
disappearing during asynchronous swapout. There were ""Evil hack time""
comments discussing how the page might disappear.

Fortunately, we already have mem->swapout.queue_offset that can be fed
to getBlockContainingLocation to find the page that needs to be swapped
out. There is no need to keep the page pointer around. The
queue_offset-based math is the same so we are not adding any overheads
by using that offset (in fact, we are removing some minor computations).


* Added ""close how?"" parameter to storeClose() and friends.

The old code would follow the same path when closing swapout activity
for an aborted entry and when completing a perfectly healthy swapout. In
non-shared case, that could have been OK because the abort code would
then release the entry, removing any half-written entry from the index
and the disk (but I am not sure that release happened fast enough in
100% of cases).

When the index and disk storage is shared among workers, such
""temporary"" inconsistencies result in truncated responses being
delivered by other workers to the user because once the swapout activity
is closed, other workers can start using the entry.

By adding the ""close how?"" parameter to closing methods we allow the
core and SwapDir-specific code to handle aborted swapouts appropriately.

Since swapin code is ""read only"", we do not currently distinguish
between aborted and fully satisfied readers: The readerGone enum value
applies to both cases. If needed, the SwapDir reading code can make that
distinction by analyzing how much was actually swapped in.


* Moved ""can you store this entry?"" code to virtual SwapDir::canStore().

The old code had some of the tests in SwapDir-specific canStore()
methods and some in storeDirSelect*() methods. This resulted in
inconsistencies, code duplication, and extra calculation overheads.
Making this call virtual allows individual cache_dir types to do custom
access controls.

The same method is used for cache_dir load reporting (if it returns
true). Load management needs more work, but the current code is no worse
than the old one in this aspect, and further improvements are outside
this change scope.


* Minimized from-disk StoreEntry loading/unpacking code duplication.

Moved common (and often rather complex!) code from store modules into
storeRebuildLoadEntry, storeRebuildParseEntry, and storeRebuildKeepEntry.


* Do not set object_sz when the entry is aborted because the true object
size (HTTP reply headers + body) is not known in this case. Setting
object_sz may fool client-side code into believing that the object is
complete.

This addresses an old RBC's complaint.


* When swapout initiation fails, mark swapout decision as
MemObject::SwapOut::swImpossible. This prevents the caller code from trying to
swap out again and again because swap_status becomes SWAPOUT_NONE.

TODO: Consider add SWAPOUT_ERROR, STORE_ERROR, and similar states. It
may solve several problems where the code sees _NONE or _OK and thinks
everything is peachy when in fact there was an error.


* Call haveParsedReplyHeaders() before entry->replaceHttpReply().

HaveParsedReplyHeaders() sets the entry public key and various flags (at 
least). ReplaceHttpReply() packs reply headers, starting swapout process.
It feels natural to adjust the entry _before_ we pack/swap it, but I may be
missing some side-effects here.

The change was necessary because we started calling checkCachable() from
swapoutPossible(). If haveParsedReplyHeaders() is not called before we swap
out checks, the entry will still have the private key and will be declared
impossible to cache.


* Extracted the write-to-store step from StoreEntry::replaceHttpReply().

This allows the caller to set the reply for the entry and then update the
entry and the reply before writing them to store. For example, the server-side
haveParsedReplyHeaders() code needs to set the entry timestamps and make the
entry key public before the entry starts swapping out, but the same code also
needs access to entry->getReply() and such for timestampsSet() and similar
code to work correctly.

TODO: Calls to StoreEntry::replaceHttpReply() do not have to be modified
because replaceHttpReply() does write by default. However, it is likely that
callers other than ServerStateData::setFinalReply() should take advantage of
the new split interface because they call timestampsSet() and such after
replaceHttpReply().


* Moved SwapDir::cur_size and n_disk_objects to specific SwapDirs. Removed
updateSize().  Some cache_dirs maintain their own maps and size statistics,
making the one-size-fits-all SwapDir members inappropriate.

* A new SwapDir public method swappedOut() added. It is called from
storeSwapOutFileClosed() to notify SwapDir that an object was swapped
out.

* Change SwapDir::max_size to bytes, make it protected, use maxSize() instead.

Change SwapDir::cur_size to bytes, make it private, use currentSize() instead.

Store Config.Store.avgObjectSize in bytes to avoid repeated and error-prone
KB<->bytes conversions.


* Change Config.cacheSwap.swapDirs and StoreEntry::store() type to SwapDir.

This allows using SwapDir API without dynamic_cast.


* Always call StoreEntry::abort() instead of setting ENTRY_ABORTED manually.

* Rely on entry->abort() side-effects if ENTRY_ABORTED was set.

* Added or updated comments to better document current code.

* Added operator << for dumping StoreEntry summary into the debugging
log. Needs more work to report more info (and not report yet-unknown info).

* Fixed blocking reads that were sometimes reading from random file offsets.

Core ""disk file"" reading code assumed that if the globally stored disk.offset
matches the desired offset, there is no reason to seek. This was probably done
to reduce seek overhead between consecutive reads. Unfortunately, the disk
writing code did not know about that optimization and left F->disk.offset
unchanged after writing.

This may have worked OK for UFS if it never writes to the file it reads from,
but it does not work for store modules that do both kinds of I/O at different
offsets of the same disk file.

Eventually, implement this optimization correctly or remove disk.offset.


IPC primitives
--------------

To make SMP disk and memory caching non-blocking and correct, worker and
disker processes must asynchronously communicate with each other. We are
adding a collection of classes that support such communication.

At the base of the collection is the AtomicWordT template that uses GCC atomic
primitives such as __sync_add_and_fetch() to perform atomic operations on
integral values in memory shared by multiple Squid kids. AtomicWordT is used
to implement non-blocking shared locks, queues, store tables, and page pools.

To avoid blocking or very long searches, many operations are ""optimistic"" in
nature. For example, it is possible that an atomic store map will refuse to
allocate an entry for two processes even though a blocking implementation
would have allowed one of the processes to get the map slot. We speculate that
such conflict resolution is better than blocking locks when it comes to
caching, especially if the conflicts are rare due to large number of cache
entries, fast operations, and relatively small number of kids.


TODO: Eventually, consider breaking locks left by dead kids.



Shared Memory Cache
-------------------

* Added initial shared memory cache implementation (MemStore).

The shared memory cache keeps its own compact index of cached entries using
extended Ipc::StoreMap class (MemStoreMap). The cache also strives to keep its
Root.get() results out of the store_table except during transit.

Eventually, the non-shared/local memory cache should also be implemented
using a MemStore-like class, I think. This will allow to clearly isolate
local from shared memory cache code.

Allow the user to explicitly disable shared memory caching in SMP mode via
memory_cache_shared to squid.conf. Report whether mem_cache is shared.

Disable shared memory caching by default if atomic operations are not
supported. Prohibit shared memory caching if atomic operations are not
supported.

TODO: Better limits/separation for cache and I/O shared memory pages.
Eventually, support shared memory caching of multi-page entries.


Rock Store
----------

Rock Store uses a single [large] database-style file per cache_dir to store
cached responses and metadata. This part of the design is similar to COSS.
Rock Store does not maintain or rely on swap.state ""log"" for recovery.
Instead, the database is scanned in the background to load entries when Squid
starts. Rock Store maintains its own index of cached entries and avoids global
store_table. All entries must be max-size or smaller.

In SMP mode, each Rock cache_dir is given a dedicated Kid processes called
""disker"". All SMP workers communicate with diskers to store misses and load
hits, using shared memory pages and atomic shared memory queues. Disker blocks
when doing disk I/O but workers do not. Any Diskers:Workers ratio is supported
so that the user can find and configure the optimal number of workers and
diskers for a given number of disks and CPU cores.

In non-SMP mode, should use good old blocking disk I/O, without any diskers,
but this has not been tested recently and probably needs more work.

Feature page: http://wiki.squid-cache.org/Features/RockStore

TODO: Disk rate limit to protect Squid from disk overload. More stats.
Multiple readers? Seek optimization? Remove known max-size requirement?",8765,data/crawl/squid/hunk_2449.cpp,,,data/crawl/squid/old_hunk_2449.cpp,data/crawl/squid/new_hunk_2449.cpp,-1,219,,"fatal(""Rock Store missing a required DiskIO module"");","[""addLog""]","[[], [""fatal"", ""Rock"", ""Store"", ""missing"", ""a"", ""required"", ""DiskIO"", ""module""]]",[-13394768537372903099],6027,161280.0,2
https://github.com/squid-cache/squid/commit/35a1b223314eddb67b631cb0224d6e03a2360c77,13 Sep 2011,"SMP Caching: Core changes, IPC primitives, Shared memory cache, and Rock Store

Core changes
------------

* Added MemObject::expectedReplySize() and used it instead of object_sz.

When deciding whether an object with a known content length can be
swapped out, do not wait until the object is completely received and its
size (mem_obj->object_sz) becomes known (while asking the store to
recheck in vain with every incoming chunk). Instead, use the known
content length, if any, to make the decision.

This optimizes the common case where the complete object is eventually
received and swapped out, preventing accumulating potentially large
objects in RAM while waiting for the end of the response. Should not
affect objects with unknown content length.

Side-effect1: probably fixes several cases of unknowingly using negative
(unknown) mem_obj->object_sz in calculations. I added a few assertions
to double check some of the remaining object_sz/objectLen() uses.

Side-effect2: When expectedReplySize() is stored on disk as StoreEntry
metadata, it may help to detect truncated entries when the writer
process dies before completing the swapout.


* Removed mem->swapout.memnode in favor of mem->swapout.queue_offset.

The code used swapout.memnode pointer to keep track of the last page
that was swapped out. The code was semi-buggy because it could reset the
pointer to NULL if no new data came in before the call to doPages().
Perhaps the code relied on the assumption that the caller will never
doPages if there is no new data, but I am not sure that assumption was
correct in all cases (it could be that I broke the calling code, of course).

Moreover, the page pointer was kept without any protection from page
disappearing during asynchronous swapout. There were ""Evil hack time""
comments discussing how the page might disappear.

Fortunately, we already have mem->swapout.queue_offset that can be fed
to getBlockContainingLocation to find the page that needs to be swapped
out. There is no need to keep the page pointer around. The
queue_offset-based math is the same so we are not adding any overheads
by using that offset (in fact, we are removing some minor computations).


* Added ""close how?"" parameter to storeClose() and friends.

The old code would follow the same path when closing swapout activity
for an aborted entry and when completing a perfectly healthy swapout. In
non-shared case, that could have been OK because the abort code would
then release the entry, removing any half-written entry from the index
and the disk (but I am not sure that release happened fast enough in
100% of cases).

When the index and disk storage is shared among workers, such
""temporary"" inconsistencies result in truncated responses being
delivered by other workers to the user because once the swapout activity
is closed, other workers can start using the entry.

By adding the ""close how?"" parameter to closing methods we allow the
core and SwapDir-specific code to handle aborted swapouts appropriately.

Since swapin code is ""read only"", we do not currently distinguish
between aborted and fully satisfied readers: The readerGone enum value
applies to both cases. If needed, the SwapDir reading code can make that
distinction by analyzing how much was actually swapped in.


* Moved ""can you store this entry?"" code to virtual SwapDir::canStore().

The old code had some of the tests in SwapDir-specific canStore()
methods and some in storeDirSelect*() methods. This resulted in
inconsistencies, code duplication, and extra calculation overheads.
Making this call virtual allows individual cache_dir types to do custom
access controls.

The same method is used for cache_dir load reporting (if it returns
true). Load management needs more work, but the current code is no worse
than the old one in this aspect, and further improvements are outside
this change scope.


* Minimized from-disk StoreEntry loading/unpacking code duplication.

Moved common (and often rather complex!) code from store modules into
storeRebuildLoadEntry, storeRebuildParseEntry, and storeRebuildKeepEntry.


* Do not set object_sz when the entry is aborted because the true object
size (HTTP reply headers + body) is not known in this case. Setting
object_sz may fool client-side code into believing that the object is
complete.

This addresses an old RBC's complaint.


* When swapout initiation fails, mark swapout decision as
MemObject::SwapOut::swImpossible. This prevents the caller code from trying to
swap out again and again because swap_status becomes SWAPOUT_NONE.

TODO: Consider add SWAPOUT_ERROR, STORE_ERROR, and similar states. It
may solve several problems where the code sees _NONE or _OK and thinks
everything is peachy when in fact there was an error.


* Call haveParsedReplyHeaders() before entry->replaceHttpReply().

HaveParsedReplyHeaders() sets the entry public key and various flags (at 
least). ReplaceHttpReply() packs reply headers, starting swapout process.
It feels natural to adjust the entry _before_ we pack/swap it, but I may be
missing some side-effects here.

The change was necessary because we started calling checkCachable() from
swapoutPossible(). If haveParsedReplyHeaders() is not called before we swap
out checks, the entry will still have the private key and will be declared
impossible to cache.


* Extracted the write-to-store step from StoreEntry::replaceHttpReply().

This allows the caller to set the reply for the entry and then update the
entry and the reply before writing them to store. For example, the server-side
haveParsedReplyHeaders() code needs to set the entry timestamps and make the
entry key public before the entry starts swapping out, but the same code also
needs access to entry->getReply() and such for timestampsSet() and similar
code to work correctly.

TODO: Calls to StoreEntry::replaceHttpReply() do not have to be modified
because replaceHttpReply() does write by default. However, it is likely that
callers other than ServerStateData::setFinalReply() should take advantage of
the new split interface because they call timestampsSet() and such after
replaceHttpReply().


* Moved SwapDir::cur_size and n_disk_objects to specific SwapDirs. Removed
updateSize().  Some cache_dirs maintain their own maps and size statistics,
making the one-size-fits-all SwapDir members inappropriate.

* A new SwapDir public method swappedOut() added. It is called from
storeSwapOutFileClosed() to notify SwapDir that an object was swapped
out.

* Change SwapDir::max_size to bytes, make it protected, use maxSize() instead.

Change SwapDir::cur_size to bytes, make it private, use currentSize() instead.

Store Config.Store.avgObjectSize in bytes to avoid repeated and error-prone
KB<->bytes conversions.


* Change Config.cacheSwap.swapDirs and StoreEntry::store() type to SwapDir.

This allows using SwapDir API without dynamic_cast.


* Always call StoreEntry::abort() instead of setting ENTRY_ABORTED manually.

* Rely on entry->abort() side-effects if ENTRY_ABORTED was set.

* Added or updated comments to better document current code.

* Added operator << for dumping StoreEntry summary into the debugging
log. Needs more work to report more info (and not report yet-unknown info).

* Fixed blocking reads that were sometimes reading from random file offsets.

Core ""disk file"" reading code assumed that if the globally stored disk.offset
matches the desired offset, there is no reason to seek. This was probably done
to reduce seek overhead between consecutive reads. Unfortunately, the disk
writing code did not know about that optimization and left F->disk.offset
unchanged after writing.

This may have worked OK for UFS if it never writes to the file it reads from,
but it does not work for store modules that do both kinds of I/O at different
offsets of the same disk file.

Eventually, implement this optimization correctly or remove disk.offset.


IPC primitives
--------------

To make SMP disk and memory caching non-blocking and correct, worker and
disker processes must asynchronously communicate with each other. We are
adding a collection of classes that support such communication.

At the base of the collection is the AtomicWordT template that uses GCC atomic
primitives such as __sync_add_and_fetch() to perform atomic operations on
integral values in memory shared by multiple Squid kids. AtomicWordT is used
to implement non-blocking shared locks, queues, store tables, and page pools.

To avoid blocking or very long searches, many operations are ""optimistic"" in
nature. For example, it is possible that an atomic store map will refuse to
allocate an entry for two processes even though a blocking implementation
would have allowed one of the processes to get the map slot. We speculate that
such conflict resolution is better than blocking locks when it comes to
caching, especially if the conflicts are rare due to large number of cache
entries, fast operations, and relatively small number of kids.


TODO: Eventually, consider breaking locks left by dead kids.



Shared Memory Cache
-------------------

* Added initial shared memory cache implementation (MemStore).

The shared memory cache keeps its own compact index of cached entries using
extended Ipc::StoreMap class (MemStoreMap). The cache also strives to keep its
Root.get() results out of the store_table except during transit.

Eventually, the non-shared/local memory cache should also be implemented
using a MemStore-like class, I think. This will allow to clearly isolate
local from shared memory cache code.

Allow the user to explicitly disable shared memory caching in SMP mode via
memory_cache_shared to squid.conf. Report whether mem_cache is shared.

Disable shared memory caching by default if atomic operations are not
supported. Prohibit shared memory caching if atomic operations are not
supported.

TODO: Better limits/separation for cache and I/O shared memory pages.
Eventually, support shared memory caching of multi-page entries.


Rock Store
----------

Rock Store uses a single [large] database-style file per cache_dir to store
cached responses and metadata. This part of the design is similar to COSS.
Rock Store does not maintain or rely on swap.state ""log"" for recovery.
Instead, the database is scanned in the background to load entries when Squid
starts. Rock Store maintains its own index of cached entries and avoids global
store_table. All entries must be max-size or smaller.

In SMP mode, each Rock cache_dir is given a dedicated Kid processes called
""disker"". All SMP workers communicate with diskers to store misses and load
hits, using shared memory pages and atomic shared memory queues. Disker blocks
when doing disk I/O but workers do not. Any Diskers:Workers ratio is supported
so that the user can find and configure the optimal number of workers and
diskers for a given number of disks and CPU cores.

In non-SMP mode, should use good old blocking disk I/O, without any diskers,
but this has not been tested recently and probably needs more work.

Feature page: http://wiki.squid-cache.org/Features/RockStore

TODO: Disk rate limit to protect Squid from disk overload. More stats.
Multiple readers? Seek optimization? Remove known max-size requirement?",8765,data/crawl/squid/hunk_2449.cpp,,,data/crawl/squid/old_hunk_2449.cpp,data/crawl/squid/new_hunk_2449.cpp,-1,193,,"fatal(""Rock Store db initialization error"");","[""addLog""]","[[], [""fatal"", ""Rock"", ""Store"", ""db"", ""initialization"", ""error""]]",[-9114977151103468163],6026,164880.0,2
https://github.com/squid-cache/squid/commit/35a1b223314eddb67b631cb0224d6e03a2360c77,13 Sep 2011,"SMP Caching: Core changes, IPC primitives, Shared memory cache, and Rock Store

Core changes
------------

* Added MemObject::expectedReplySize() and used it instead of object_sz.

When deciding whether an object with a known content length can be
swapped out, do not wait until the object is completely received and its
size (mem_obj->object_sz) becomes known (while asking the store to
recheck in vain with every incoming chunk). Instead, use the known
content length, if any, to make the decision.

This optimizes the common case where the complete object is eventually
received and swapped out, preventing accumulating potentially large
objects in RAM while waiting for the end of the response. Should not
affect objects with unknown content length.

Side-effect1: probably fixes several cases of unknowingly using negative
(unknown) mem_obj->object_sz in calculations. I added a few assertions
to double check some of the remaining object_sz/objectLen() uses.

Side-effect2: When expectedReplySize() is stored on disk as StoreEntry
metadata, it may help to detect truncated entries when the writer
process dies before completing the swapout.


* Removed mem->swapout.memnode in favor of mem->swapout.queue_offset.

The code used swapout.memnode pointer to keep track of the last page
that was swapped out. The code was semi-buggy because it could reset the
pointer to NULL if no new data came in before the call to doPages().
Perhaps the code relied on the assumption that the caller will never
doPages if there is no new data, but I am not sure that assumption was
correct in all cases (it could be that I broke the calling code, of course).

Moreover, the page pointer was kept without any protection from page
disappearing during asynchronous swapout. There were ""Evil hack time""
comments discussing how the page might disappear.

Fortunately, we already have mem->swapout.queue_offset that can be fed
to getBlockContainingLocation to find the page that needs to be swapped
out. There is no need to keep the page pointer around. The
queue_offset-based math is the same so we are not adding any overheads
by using that offset (in fact, we are removing some minor computations).


* Added ""close how?"" parameter to storeClose() and friends.

The old code would follow the same path when closing swapout activity
for an aborted entry and when completing a perfectly healthy swapout. In
non-shared case, that could have been OK because the abort code would
then release the entry, removing any half-written entry from the index
and the disk (but I am not sure that release happened fast enough in
100% of cases).

When the index and disk storage is shared among workers, such
""temporary"" inconsistencies result in truncated responses being
delivered by other workers to the user because once the swapout activity
is closed, other workers can start using the entry.

By adding the ""close how?"" parameter to closing methods we allow the
core and SwapDir-specific code to handle aborted swapouts appropriately.

Since swapin code is ""read only"", we do not currently distinguish
between aborted and fully satisfied readers: The readerGone enum value
applies to both cases. If needed, the SwapDir reading code can make that
distinction by analyzing how much was actually swapped in.


* Moved ""can you store this entry?"" code to virtual SwapDir::canStore().

The old code had some of the tests in SwapDir-specific canStore()
methods and some in storeDirSelect*() methods. This resulted in
inconsistencies, code duplication, and extra calculation overheads.
Making this call virtual allows individual cache_dir types to do custom
access controls.

The same method is used for cache_dir load reporting (if it returns
true). Load management needs more work, but the current code is no worse
than the old one in this aspect, and further improvements are outside
this change scope.


* Minimized from-disk StoreEntry loading/unpacking code duplication.

Moved common (and often rather complex!) code from store modules into
storeRebuildLoadEntry, storeRebuildParseEntry, and storeRebuildKeepEntry.


* Do not set object_sz when the entry is aborted because the true object
size (HTTP reply headers + body) is not known in this case. Setting
object_sz may fool client-side code into believing that the object is
complete.

This addresses an old RBC's complaint.


* When swapout initiation fails, mark swapout decision as
MemObject::SwapOut::swImpossible. This prevents the caller code from trying to
swap out again and again because swap_status becomes SWAPOUT_NONE.

TODO: Consider add SWAPOUT_ERROR, STORE_ERROR, and similar states. It
may solve several problems where the code sees _NONE or _OK and thinks
everything is peachy when in fact there was an error.


* Call haveParsedReplyHeaders() before entry->replaceHttpReply().

HaveParsedReplyHeaders() sets the entry public key and various flags (at 
least). ReplaceHttpReply() packs reply headers, starting swapout process.
It feels natural to adjust the entry _before_ we pack/swap it, but I may be
missing some side-effects here.

The change was necessary because we started calling checkCachable() from
swapoutPossible(). If haveParsedReplyHeaders() is not called before we swap
out checks, the entry will still have the private key and will be declared
impossible to cache.


* Extracted the write-to-store step from StoreEntry::replaceHttpReply().

This allows the caller to set the reply for the entry and then update the
entry and the reply before writing them to store. For example, the server-side
haveParsedReplyHeaders() code needs to set the entry timestamps and make the
entry key public before the entry starts swapping out, but the same code also
needs access to entry->getReply() and such for timestampsSet() and similar
code to work correctly.

TODO: Calls to StoreEntry::replaceHttpReply() do not have to be modified
because replaceHttpReply() does write by default. However, it is likely that
callers other than ServerStateData::setFinalReply() should take advantage of
the new split interface because they call timestampsSet() and such after
replaceHttpReply().


* Moved SwapDir::cur_size and n_disk_objects to specific SwapDirs. Removed
updateSize().  Some cache_dirs maintain their own maps and size statistics,
making the one-size-fits-all SwapDir members inappropriate.

* A new SwapDir public method swappedOut() added. It is called from
storeSwapOutFileClosed() to notify SwapDir that an object was swapped
out.

* Change SwapDir::max_size to bytes, make it protected, use maxSize() instead.

Change SwapDir::cur_size to bytes, make it private, use currentSize() instead.

Store Config.Store.avgObjectSize in bytes to avoid repeated and error-prone
KB<->bytes conversions.


* Change Config.cacheSwap.swapDirs and StoreEntry::store() type to SwapDir.

This allows using SwapDir API without dynamic_cast.


* Always call StoreEntry::abort() instead of setting ENTRY_ABORTED manually.

* Rely on entry->abort() side-effects if ENTRY_ABORTED was set.

* Added or updated comments to better document current code.

* Added operator << for dumping StoreEntry summary into the debugging
log. Needs more work to report more info (and not report yet-unknown info).

* Fixed blocking reads that were sometimes reading from random file offsets.

Core ""disk file"" reading code assumed that if the globally stored disk.offset
matches the desired offset, there is no reason to seek. This was probably done
to reduce seek overhead between consecutive reads. Unfortunately, the disk
writing code did not know about that optimization and left F->disk.offset
unchanged after writing.

This may have worked OK for UFS if it never writes to the file it reads from,
but it does not work for store modules that do both kinds of I/O at different
offsets of the same disk file.

Eventually, implement this optimization correctly or remove disk.offset.


IPC primitives
--------------

To make SMP disk and memory caching non-blocking and correct, worker and
disker processes must asynchronously communicate with each other. We are
adding a collection of classes that support such communication.

At the base of the collection is the AtomicWordT template that uses GCC atomic
primitives such as __sync_add_and_fetch() to perform atomic operations on
integral values in memory shared by multiple Squid kids. AtomicWordT is used
to implement non-blocking shared locks, queues, store tables, and page pools.

To avoid blocking or very long searches, many operations are ""optimistic"" in
nature. For example, it is possible that an atomic store map will refuse to
allocate an entry for two processes even though a blocking implementation
would have allowed one of the processes to get the map slot. We speculate that
such conflict resolution is better than blocking locks when it comes to
caching, especially if the conflicts are rare due to large number of cache
entries, fast operations, and relatively small number of kids.


TODO: Eventually, consider breaking locks left by dead kids.



Shared Memory Cache
-------------------

* Added initial shared memory cache implementation (MemStore).

The shared memory cache keeps its own compact index of cached entries using
extended Ipc::StoreMap class (MemStoreMap). The cache also strives to keep its
Root.get() results out of the store_table except during transit.

Eventually, the non-shared/local memory cache should also be implemented
using a MemStore-like class, I think. This will allow to clearly isolate
local from shared memory cache code.

Allow the user to explicitly disable shared memory caching in SMP mode via
memory_cache_shared to squid.conf. Report whether mem_cache is shared.

Disable shared memory caching by default if atomic operations are not
supported. Prohibit shared memory caching if atomic operations are not
supported.

TODO: Better limits/separation for cache and I/O shared memory pages.
Eventually, support shared memory caching of multi-page entries.


Rock Store
----------

Rock Store uses a single [large] database-style file per cache_dir to store
cached responses and metadata. This part of the design is similar to COSS.
Rock Store does not maintain or rely on swap.state ""log"" for recovery.
Instead, the database is scanned in the background to load entries when Squid
starts. Rock Store maintains its own index of cached entries and avoids global
store_table. All entries must be max-size or smaller.

In SMP mode, each Rock cache_dir is given a dedicated Kid processes called
""disker"". All SMP workers communicate with diskers to store misses and load
hits, using shared memory pages and atomic shared memory queues. Disker blocks
when doing disk I/O but workers do not. Any Diskers:Workers ratio is supported
so that the user can find and configure the optimal number of workers and
diskers for a given number of disks and CPU cores.

In non-SMP mode, should use good old blocking disk I/O, without any diskers,
but this has not been tested recently and probably needs more work.

Feature page: http://wiki.squid-cache.org/Features/RockStore

TODO: Disk rate limit to protect Squid from disk overload. More stats.
Multiple readers? Seek optimization? Remove known max-size requirement?",8765,data/crawl/squid/hunk_2448.cpp,,,data/crawl/squid/old_hunk_2448.cpp,data/crawl/squid/new_hunk_2448.cpp,-1,199,,"fatalf(""Rock cache_dir[%d] rebuild of %s failed: %s."",
           sd->index, sd->filePath, msg);","[""addLog""]","[[], [""fatalf"", ""Rock"", ""cache_dir[%d]"", ""rebuild"", ""of"", ""%s"", ""failed"", ""%s"", ""sd"", ""index"", ""sd"", ""filePath"", ""msg""]]",[-7228532738415009027],6025,164880.0,2
https://github.com/squid-cache/squid/commit/35a1b223314eddb67b631cb0224d6e03a2360c77,13 Sep 2011,"SMP Caching: Core changes, IPC primitives, Shared memory cache, and Rock Store

Core changes
------------

* Added MemObject::expectedReplySize() and used it instead of object_sz.

When deciding whether an object with a known content length can be
swapped out, do not wait until the object is completely received and its
size (mem_obj->object_sz) becomes known (while asking the store to
recheck in vain with every incoming chunk). Instead, use the known
content length, if any, to make the decision.

This optimizes the common case where the complete object is eventually
received and swapped out, preventing accumulating potentially large
objects in RAM while waiting for the end of the response. Should not
affect objects with unknown content length.

Side-effect1: probably fixes several cases of unknowingly using negative
(unknown) mem_obj->object_sz in calculations. I added a few assertions
to double check some of the remaining object_sz/objectLen() uses.

Side-effect2: When expectedReplySize() is stored on disk as StoreEntry
metadata, it may help to detect truncated entries when the writer
process dies before completing the swapout.


* Removed mem->swapout.memnode in favor of mem->swapout.queue_offset.

The code used swapout.memnode pointer to keep track of the last page
that was swapped out. The code was semi-buggy because it could reset the
pointer to NULL if no new data came in before the call to doPages().
Perhaps the code relied on the assumption that the caller will never
doPages if there is no new data, but I am not sure that assumption was
correct in all cases (it could be that I broke the calling code, of course).

Moreover, the page pointer was kept without any protection from page
disappearing during asynchronous swapout. There were ""Evil hack time""
comments discussing how the page might disappear.

Fortunately, we already have mem->swapout.queue_offset that can be fed
to getBlockContainingLocation to find the page that needs to be swapped
out. There is no need to keep the page pointer around. The
queue_offset-based math is the same so we are not adding any overheads
by using that offset (in fact, we are removing some minor computations).


* Added ""close how?"" parameter to storeClose() and friends.

The old code would follow the same path when closing swapout activity
for an aborted entry and when completing a perfectly healthy swapout. In
non-shared case, that could have been OK because the abort code would
then release the entry, removing any half-written entry from the index
and the disk (but I am not sure that release happened fast enough in
100% of cases).

When the index and disk storage is shared among workers, such
""temporary"" inconsistencies result in truncated responses being
delivered by other workers to the user because once the swapout activity
is closed, other workers can start using the entry.

By adding the ""close how?"" parameter to closing methods we allow the
core and SwapDir-specific code to handle aborted swapouts appropriately.

Since swapin code is ""read only"", we do not currently distinguish
between aborted and fully satisfied readers: The readerGone enum value
applies to both cases. If needed, the SwapDir reading code can make that
distinction by analyzing how much was actually swapped in.


* Moved ""can you store this entry?"" code to virtual SwapDir::canStore().

The old code had some of the tests in SwapDir-specific canStore()
methods and some in storeDirSelect*() methods. This resulted in
inconsistencies, code duplication, and extra calculation overheads.
Making this call virtual allows individual cache_dir types to do custom
access controls.

The same method is used for cache_dir load reporting (if it returns
true). Load management needs more work, but the current code is no worse
than the old one in this aspect, and further improvements are outside
this change scope.


* Minimized from-disk StoreEntry loading/unpacking code duplication.

Moved common (and often rather complex!) code from store modules into
storeRebuildLoadEntry, storeRebuildParseEntry, and storeRebuildKeepEntry.


* Do not set object_sz when the entry is aborted because the true object
size (HTTP reply headers + body) is not known in this case. Setting
object_sz may fool client-side code into believing that the object is
complete.

This addresses an old RBC's complaint.


* When swapout initiation fails, mark swapout decision as
MemObject::SwapOut::swImpossible. This prevents the caller code from trying to
swap out again and again because swap_status becomes SWAPOUT_NONE.

TODO: Consider add SWAPOUT_ERROR, STORE_ERROR, and similar states. It
may solve several problems where the code sees _NONE or _OK and thinks
everything is peachy when in fact there was an error.


* Call haveParsedReplyHeaders() before entry->replaceHttpReply().

HaveParsedReplyHeaders() sets the entry public key and various flags (at 
least). ReplaceHttpReply() packs reply headers, starting swapout process.
It feels natural to adjust the entry _before_ we pack/swap it, but I may be
missing some side-effects here.

The change was necessary because we started calling checkCachable() from
swapoutPossible(). If haveParsedReplyHeaders() is not called before we swap
out checks, the entry will still have the private key and will be declared
impossible to cache.


* Extracted the write-to-store step from StoreEntry::replaceHttpReply().

This allows the caller to set the reply for the entry and then update the
entry and the reply before writing them to store. For example, the server-side
haveParsedReplyHeaders() code needs to set the entry timestamps and make the
entry key public before the entry starts swapping out, but the same code also
needs access to entry->getReply() and such for timestampsSet() and similar
code to work correctly.

TODO: Calls to StoreEntry::replaceHttpReply() do not have to be modified
because replaceHttpReply() does write by default. However, it is likely that
callers other than ServerStateData::setFinalReply() should take advantage of
the new split interface because they call timestampsSet() and such after
replaceHttpReply().


* Moved SwapDir::cur_size and n_disk_objects to specific SwapDirs. Removed
updateSize().  Some cache_dirs maintain their own maps and size statistics,
making the one-size-fits-all SwapDir members inappropriate.

* A new SwapDir public method swappedOut() added. It is called from
storeSwapOutFileClosed() to notify SwapDir that an object was swapped
out.

* Change SwapDir::max_size to bytes, make it protected, use maxSize() instead.

Change SwapDir::cur_size to bytes, make it private, use currentSize() instead.

Store Config.Store.avgObjectSize in bytes to avoid repeated and error-prone
KB<->bytes conversions.


* Change Config.cacheSwap.swapDirs and StoreEntry::store() type to SwapDir.

This allows using SwapDir API without dynamic_cast.


* Always call StoreEntry::abort() instead of setting ENTRY_ABORTED manually.

* Rely on entry->abort() side-effects if ENTRY_ABORTED was set.

* Added or updated comments to better document current code.

* Added operator << for dumping StoreEntry summary into the debugging
log. Needs more work to report more info (and not report yet-unknown info).

* Fixed blocking reads that were sometimes reading from random file offsets.

Core ""disk file"" reading code assumed that if the globally stored disk.offset
matches the desired offset, there is no reason to seek. This was probably done
to reduce seek overhead between consecutive reads. Unfortunately, the disk
writing code did not know about that optimization and left F->disk.offset
unchanged after writing.

This may have worked OK for UFS if it never writes to the file it reads from,
but it does not work for store modules that do both kinds of I/O at different
offsets of the same disk file.

Eventually, implement this optimization correctly or remove disk.offset.


IPC primitives
--------------

To make SMP disk and memory caching non-blocking and correct, worker and
disker processes must asynchronously communicate with each other. We are
adding a collection of classes that support such communication.

At the base of the collection is the AtomicWordT template that uses GCC atomic
primitives such as __sync_add_and_fetch() to perform atomic operations on
integral values in memory shared by multiple Squid kids. AtomicWordT is used
to implement non-blocking shared locks, queues, store tables, and page pools.

To avoid blocking or very long searches, many operations are ""optimistic"" in
nature. For example, it is possible that an atomic store map will refuse to
allocate an entry for two processes even though a blocking implementation
would have allowed one of the processes to get the map slot. We speculate that
such conflict resolution is better than blocking locks when it comes to
caching, especially if the conflicts are rare due to large number of cache
entries, fast operations, and relatively small number of kids.


TODO: Eventually, consider breaking locks left by dead kids.



Shared Memory Cache
-------------------

* Added initial shared memory cache implementation (MemStore).

The shared memory cache keeps its own compact index of cached entries using
extended Ipc::StoreMap class (MemStoreMap). The cache also strives to keep its
Root.get() results out of the store_table except during transit.

Eventually, the non-shared/local memory cache should also be implemented
using a MemStore-like class, I think. This will allow to clearly isolate
local from shared memory cache code.

Allow the user to explicitly disable shared memory caching in SMP mode via
memory_cache_shared to squid.conf. Report whether mem_cache is shared.

Disable shared memory caching by default if atomic operations are not
supported. Prohibit shared memory caching if atomic operations are not
supported.

TODO: Better limits/separation for cache and I/O shared memory pages.
Eventually, support shared memory caching of multi-page entries.


Rock Store
----------

Rock Store uses a single [large] database-style file per cache_dir to store
cached responses and metadata. This part of the design is similar to COSS.
Rock Store does not maintain or rely on swap.state ""log"" for recovery.
Instead, the database is scanned in the background to load entries when Squid
starts. Rock Store maintains its own index of cached entries and avoids global
store_table. All entries must be max-size or smaller.

In SMP mode, each Rock cache_dir is given a dedicated Kid processes called
""disker"". All SMP workers communicate with diskers to store misses and load
hits, using shared memory pages and atomic shared memory queues. Disker blocks
when doing disk I/O but workers do not. Any Diskers:Workers ratio is supported
so that the user can find and configure the optimal number of workers and
diskers for a given number of disks and CPU cores.

In non-SMP mode, should use good old blocking disk I/O, without any diskers,
but this has not been tested recently and probably needs more work.

Feature page: http://wiki.squid-cache.org/Features/RockStore

TODO: Disk rate limit to protect Squid from disk overload. More stats.
Multiple readers? Seek optimization? Remove known max-size requirement?",8765,data/crawl/squid/hunk_2448.cpp,,,data/crawl/squid/old_hunk_2448.cpp,data/crawl/squid/new_hunk_2448.cpp,-1,44,,"mustStop(""non-disker"");","[""addLog""]","[[], [""mustStop"", ""non"", ""disker""]]",[-4728106322975519727],6024,156960.0,2
https://github.com/squid-cache/squid/commit/35a1b223314eddb67b631cb0224d6e03a2360c77,13 Sep 2011,"SMP Caching: Core changes, IPC primitives, Shared memory cache, and Rock Store

Core changes
------------

* Added MemObject::expectedReplySize() and used it instead of object_sz.

When deciding whether an object with a known content length can be
swapped out, do not wait until the object is completely received and its
size (mem_obj->object_sz) becomes known (while asking the store to
recheck in vain with every incoming chunk). Instead, use the known
content length, if any, to make the decision.

This optimizes the common case where the complete object is eventually
received and swapped out, preventing accumulating potentially large
objects in RAM while waiting for the end of the response. Should not
affect objects with unknown content length.

Side-effect1: probably fixes several cases of unknowingly using negative
(unknown) mem_obj->object_sz in calculations. I added a few assertions
to double check some of the remaining object_sz/objectLen() uses.

Side-effect2: When expectedReplySize() is stored on disk as StoreEntry
metadata, it may help to detect truncated entries when the writer
process dies before completing the swapout.


* Removed mem->swapout.memnode in favor of mem->swapout.queue_offset.

The code used swapout.memnode pointer to keep track of the last page
that was swapped out. The code was semi-buggy because it could reset the
pointer to NULL if no new data came in before the call to doPages().
Perhaps the code relied on the assumption that the caller will never
doPages if there is no new data, but I am not sure that assumption was
correct in all cases (it could be that I broke the calling code, of course).

Moreover, the page pointer was kept without any protection from page
disappearing during asynchronous swapout. There were ""Evil hack time""
comments discussing how the page might disappear.

Fortunately, we already have mem->swapout.queue_offset that can be fed
to getBlockContainingLocation to find the page that needs to be swapped
out. There is no need to keep the page pointer around. The
queue_offset-based math is the same so we are not adding any overheads
by using that offset (in fact, we are removing some minor computations).


* Added ""close how?"" parameter to storeClose() and friends.

The old code would follow the same path when closing swapout activity
for an aborted entry and when completing a perfectly healthy swapout. In
non-shared case, that could have been OK because the abort code would
then release the entry, removing any half-written entry from the index
and the disk (but I am not sure that release happened fast enough in
100% of cases).

When the index and disk storage is shared among workers, such
""temporary"" inconsistencies result in truncated responses being
delivered by other workers to the user because once the swapout activity
is closed, other workers can start using the entry.

By adding the ""close how?"" parameter to closing methods we allow the
core and SwapDir-specific code to handle aborted swapouts appropriately.

Since swapin code is ""read only"", we do not currently distinguish
between aborted and fully satisfied readers: The readerGone enum value
applies to both cases. If needed, the SwapDir reading code can make that
distinction by analyzing how much was actually swapped in.


* Moved ""can you store this entry?"" code to virtual SwapDir::canStore().

The old code had some of the tests in SwapDir-specific canStore()
methods and some in storeDirSelect*() methods. This resulted in
inconsistencies, code duplication, and extra calculation overheads.
Making this call virtual allows individual cache_dir types to do custom
access controls.

The same method is used for cache_dir load reporting (if it returns
true). Load management needs more work, but the current code is no worse
than the old one in this aspect, and further improvements are outside
this change scope.


* Minimized from-disk StoreEntry loading/unpacking code duplication.

Moved common (and often rather complex!) code from store modules into
storeRebuildLoadEntry, storeRebuildParseEntry, and storeRebuildKeepEntry.


* Do not set object_sz when the entry is aborted because the true object
size (HTTP reply headers + body) is not known in this case. Setting
object_sz may fool client-side code into believing that the object is
complete.

This addresses an old RBC's complaint.


* When swapout initiation fails, mark swapout decision as
MemObject::SwapOut::swImpossible. This prevents the caller code from trying to
swap out again and again because swap_status becomes SWAPOUT_NONE.

TODO: Consider add SWAPOUT_ERROR, STORE_ERROR, and similar states. It
may solve several problems where the code sees _NONE or _OK and thinks
everything is peachy when in fact there was an error.


* Call haveParsedReplyHeaders() before entry->replaceHttpReply().

HaveParsedReplyHeaders() sets the entry public key and various flags (at 
least). ReplaceHttpReply() packs reply headers, starting swapout process.
It feels natural to adjust the entry _before_ we pack/swap it, but I may be
missing some side-effects here.

The change was necessary because we started calling checkCachable() from
swapoutPossible(). If haveParsedReplyHeaders() is not called before we swap
out checks, the entry will still have the private key and will be declared
impossible to cache.


* Extracted the write-to-store step from StoreEntry::replaceHttpReply().

This allows the caller to set the reply for the entry and then update the
entry and the reply before writing them to store. For example, the server-side
haveParsedReplyHeaders() code needs to set the entry timestamps and make the
entry key public before the entry starts swapping out, but the same code also
needs access to entry->getReply() and such for timestampsSet() and similar
code to work correctly.

TODO: Calls to StoreEntry::replaceHttpReply() do not have to be modified
because replaceHttpReply() does write by default. However, it is likely that
callers other than ServerStateData::setFinalReply() should take advantage of
the new split interface because they call timestampsSet() and such after
replaceHttpReply().


* Moved SwapDir::cur_size and n_disk_objects to specific SwapDirs. Removed
updateSize().  Some cache_dirs maintain their own maps and size statistics,
making the one-size-fits-all SwapDir members inappropriate.

* A new SwapDir public method swappedOut() added. It is called from
storeSwapOutFileClosed() to notify SwapDir that an object was swapped
out.

* Change SwapDir::max_size to bytes, make it protected, use maxSize() instead.

Change SwapDir::cur_size to bytes, make it private, use currentSize() instead.

Store Config.Store.avgObjectSize in bytes to avoid repeated and error-prone
KB<->bytes conversions.


* Change Config.cacheSwap.swapDirs and StoreEntry::store() type to SwapDir.

This allows using SwapDir API without dynamic_cast.


* Always call StoreEntry::abort() instead of setting ENTRY_ABORTED manually.

* Rely on entry->abort() side-effects if ENTRY_ABORTED was set.

* Added or updated comments to better document current code.

* Added operator << for dumping StoreEntry summary into the debugging
log. Needs more work to report more info (and not report yet-unknown info).

* Fixed blocking reads that were sometimes reading from random file offsets.

Core ""disk file"" reading code assumed that if the globally stored disk.offset
matches the desired offset, there is no reason to seek. This was probably done
to reduce seek overhead between consecutive reads. Unfortunately, the disk
writing code did not know about that optimization and left F->disk.offset
unchanged after writing.

This may have worked OK for UFS if it never writes to the file it reads from,
but it does not work for store modules that do both kinds of I/O at different
offsets of the same disk file.

Eventually, implement this optimization correctly or remove disk.offset.


IPC primitives
--------------

To make SMP disk and memory caching non-blocking and correct, worker and
disker processes must asynchronously communicate with each other. We are
adding a collection of classes that support such communication.

At the base of the collection is the AtomicWordT template that uses GCC atomic
primitives such as __sync_add_and_fetch() to perform atomic operations on
integral values in memory shared by multiple Squid kids. AtomicWordT is used
to implement non-blocking shared locks, queues, store tables, and page pools.

To avoid blocking or very long searches, many operations are ""optimistic"" in
nature. For example, it is possible that an atomic store map will refuse to
allocate an entry for two processes even though a blocking implementation
would have allowed one of the processes to get the map slot. We speculate that
such conflict resolution is better than blocking locks when it comes to
caching, especially if the conflicts are rare due to large number of cache
entries, fast operations, and relatively small number of kids.


TODO: Eventually, consider breaking locks left by dead kids.



Shared Memory Cache
-------------------

* Added initial shared memory cache implementation (MemStore).

The shared memory cache keeps its own compact index of cached entries using
extended Ipc::StoreMap class (MemStoreMap). The cache also strives to keep its
Root.get() results out of the store_table except during transit.

Eventually, the non-shared/local memory cache should also be implemented
using a MemStore-like class, I think. This will allow to clearly isolate
local from shared memory cache code.

Allow the user to explicitly disable shared memory caching in SMP mode via
memory_cache_shared to squid.conf. Report whether mem_cache is shared.

Disable shared memory caching by default if atomic operations are not
supported. Prohibit shared memory caching if atomic operations are not
supported.

TODO: Better limits/separation for cache and I/O shared memory pages.
Eventually, support shared memory caching of multi-page entries.


Rock Store
----------

Rock Store uses a single [large] database-style file per cache_dir to store
cached responses and metadata. This part of the design is similar to COSS.
Rock Store does not maintain or rely on swap.state ""log"" for recovery.
Instead, the database is scanned in the background to load entries when Squid
starts. Rock Store maintains its own index of cached entries and avoids global
store_table. All entries must be max-size or smaller.

In SMP mode, each Rock cache_dir is given a dedicated Kid processes called
""disker"". All SMP workers communicate with diskers to store misses and load
hits, using shared memory pages and atomic shared memory queues. Disker blocks
when doing disk I/O but workers do not. Any Diskers:Workers ratio is supported
so that the user can find and configure the optimal number of workers and
diskers for a given number of disks and CPU cores.

In non-SMP mode, should use good old blocking disk I/O, without any diskers,
but this has not been tested recently and probably needs more work.

Feature page: http://wiki.squid-cache.org/Features/RockStore

TODO: Disk rate limit to protect Squid from disk overload. More stats.
Multiple readers? Seek optimization? Remove known max-size requirement?",8765,data/crawl/squid/hunk_2447.cpp,,,data/crawl/squid/old_hunk_2447.cpp,data/crawl/squid/new_hunk_2447.cpp,6,13,"storeAppendPrintf(&entry, "" %lu"", (max_size >> 10));","storeAppendPrintf(&entry, "" %""PRIu64, maxSize() >> 20);","[""removeVariable"", ""updateContent"", ""addVariable""]","[[""%lu"", ""max_size"", ""10""], [""%"", ""PRIu64"", ""maxSize"", ""20""]]",[8831920183529050756],6023,100080.0,2
https://github.com/squid-cache/squid/commit/35a1b223314eddb67b631cb0224d6e03a2360c77,13 Sep 2011,"SMP Caching: Core changes, IPC primitives, Shared memory cache, and Rock Store

Core changes
------------

* Added MemObject::expectedReplySize() and used it instead of object_sz.

When deciding whether an object with a known content length can be
swapped out, do not wait until the object is completely received and its
size (mem_obj->object_sz) becomes known (while asking the store to
recheck in vain with every incoming chunk). Instead, use the known
content length, if any, to make the decision.

This optimizes the common case where the complete object is eventually
received and swapped out, preventing accumulating potentially large
objects in RAM while waiting for the end of the response. Should not
affect objects with unknown content length.

Side-effect1: probably fixes several cases of unknowingly using negative
(unknown) mem_obj->object_sz in calculations. I added a few assertions
to double check some of the remaining object_sz/objectLen() uses.

Side-effect2: When expectedReplySize() is stored on disk as StoreEntry
metadata, it may help to detect truncated entries when the writer
process dies before completing the swapout.


* Removed mem->swapout.memnode in favor of mem->swapout.queue_offset.

The code used swapout.memnode pointer to keep track of the last page
that was swapped out. The code was semi-buggy because it could reset the
pointer to NULL if no new data came in before the call to doPages().
Perhaps the code relied on the assumption that the caller will never
doPages if there is no new data, but I am not sure that assumption was
correct in all cases (it could be that I broke the calling code, of course).

Moreover, the page pointer was kept without any protection from page
disappearing during asynchronous swapout. There were ""Evil hack time""
comments discussing how the page might disappear.

Fortunately, we already have mem->swapout.queue_offset that can be fed
to getBlockContainingLocation to find the page that needs to be swapped
out. There is no need to keep the page pointer around. The
queue_offset-based math is the same so we are not adding any overheads
by using that offset (in fact, we are removing some minor computations).


* Added ""close how?"" parameter to storeClose() and friends.

The old code would follow the same path when closing swapout activity
for an aborted entry and when completing a perfectly healthy swapout. In
non-shared case, that could have been OK because the abort code would
then release the entry, removing any half-written entry from the index
and the disk (but I am not sure that release happened fast enough in
100% of cases).

When the index and disk storage is shared among workers, such
""temporary"" inconsistencies result in truncated responses being
delivered by other workers to the user because once the swapout activity
is closed, other workers can start using the entry.

By adding the ""close how?"" parameter to closing methods we allow the
core and SwapDir-specific code to handle aborted swapouts appropriately.

Since swapin code is ""read only"", we do not currently distinguish
between aborted and fully satisfied readers: The readerGone enum value
applies to both cases. If needed, the SwapDir reading code can make that
distinction by analyzing how much was actually swapped in.


* Moved ""can you store this entry?"" code to virtual SwapDir::canStore().

The old code had some of the tests in SwapDir-specific canStore()
methods and some in storeDirSelect*() methods. This resulted in
inconsistencies, code duplication, and extra calculation overheads.
Making this call virtual allows individual cache_dir types to do custom
access controls.

The same method is used for cache_dir load reporting (if it returns
true). Load management needs more work, but the current code is no worse
than the old one in this aspect, and further improvements are outside
this change scope.


* Minimized from-disk StoreEntry loading/unpacking code duplication.

Moved common (and often rather complex!) code from store modules into
storeRebuildLoadEntry, storeRebuildParseEntry, and storeRebuildKeepEntry.


* Do not set object_sz when the entry is aborted because the true object
size (HTTP reply headers + body) is not known in this case. Setting
object_sz may fool client-side code into believing that the object is
complete.

This addresses an old RBC's complaint.


* When swapout initiation fails, mark swapout decision as
MemObject::SwapOut::swImpossible. This prevents the caller code from trying to
swap out again and again because swap_status becomes SWAPOUT_NONE.

TODO: Consider add SWAPOUT_ERROR, STORE_ERROR, and similar states. It
may solve several problems where the code sees _NONE or _OK and thinks
everything is peachy when in fact there was an error.


* Call haveParsedReplyHeaders() before entry->replaceHttpReply().

HaveParsedReplyHeaders() sets the entry public key and various flags (at 
least). ReplaceHttpReply() packs reply headers, starting swapout process.
It feels natural to adjust the entry _before_ we pack/swap it, but I may be
missing some side-effects here.

The change was necessary because we started calling checkCachable() from
swapoutPossible(). If haveParsedReplyHeaders() is not called before we swap
out checks, the entry will still have the private key and will be declared
impossible to cache.


* Extracted the write-to-store step from StoreEntry::replaceHttpReply().

This allows the caller to set the reply for the entry and then update the
entry and the reply before writing them to store. For example, the server-side
haveParsedReplyHeaders() code needs to set the entry timestamps and make the
entry key public before the entry starts swapping out, but the same code also
needs access to entry->getReply() and such for timestampsSet() and similar
code to work correctly.

TODO: Calls to StoreEntry::replaceHttpReply() do not have to be modified
because replaceHttpReply() does write by default. However, it is likely that
callers other than ServerStateData::setFinalReply() should take advantage of
the new split interface because they call timestampsSet() and such after
replaceHttpReply().


* Moved SwapDir::cur_size and n_disk_objects to specific SwapDirs. Removed
updateSize().  Some cache_dirs maintain their own maps and size statistics,
making the one-size-fits-all SwapDir members inappropriate.

* A new SwapDir public method swappedOut() added. It is called from
storeSwapOutFileClosed() to notify SwapDir that an object was swapped
out.

* Change SwapDir::max_size to bytes, make it protected, use maxSize() instead.

Change SwapDir::cur_size to bytes, make it private, use currentSize() instead.

Store Config.Store.avgObjectSize in bytes to avoid repeated and error-prone
KB<->bytes conversions.


* Change Config.cacheSwap.swapDirs and StoreEntry::store() type to SwapDir.

This allows using SwapDir API without dynamic_cast.


* Always call StoreEntry::abort() instead of setting ENTRY_ABORTED manually.

* Rely on entry->abort() side-effects if ENTRY_ABORTED was set.

* Added or updated comments to better document current code.

* Added operator << for dumping StoreEntry summary into the debugging
log. Needs more work to report more info (and not report yet-unknown info).

* Fixed blocking reads that were sometimes reading from random file offsets.

Core ""disk file"" reading code assumed that if the globally stored disk.offset
matches the desired offset, there is no reason to seek. This was probably done
to reduce seek overhead between consecutive reads. Unfortunately, the disk
writing code did not know about that optimization and left F->disk.offset
unchanged after writing.

This may have worked OK for UFS if it never writes to the file it reads from,
but it does not work for store modules that do both kinds of I/O at different
offsets of the same disk file.

Eventually, implement this optimization correctly or remove disk.offset.


IPC primitives
--------------

To make SMP disk and memory caching non-blocking and correct, worker and
disker processes must asynchronously communicate with each other. We are
adding a collection of classes that support such communication.

At the base of the collection is the AtomicWordT template that uses GCC atomic
primitives such as __sync_add_and_fetch() to perform atomic operations on
integral values in memory shared by multiple Squid kids. AtomicWordT is used
to implement non-blocking shared locks, queues, store tables, and page pools.

To avoid blocking or very long searches, many operations are ""optimistic"" in
nature. For example, it is possible that an atomic store map will refuse to
allocate an entry for two processes even though a blocking implementation
would have allowed one of the processes to get the map slot. We speculate that
such conflict resolution is better than blocking locks when it comes to
caching, especially if the conflicts are rare due to large number of cache
entries, fast operations, and relatively small number of kids.


TODO: Eventually, consider breaking locks left by dead kids.



Shared Memory Cache
-------------------

* Added initial shared memory cache implementation (MemStore).

The shared memory cache keeps its own compact index of cached entries using
extended Ipc::StoreMap class (MemStoreMap). The cache also strives to keep its
Root.get() results out of the store_table except during transit.

Eventually, the non-shared/local memory cache should also be implemented
using a MemStore-like class, I think. This will allow to clearly isolate
local from shared memory cache code.

Allow the user to explicitly disable shared memory caching in SMP mode via
memory_cache_shared to squid.conf. Report whether mem_cache is shared.

Disable shared memory caching by default if atomic operations are not
supported. Prohibit shared memory caching if atomic operations are not
supported.

TODO: Better limits/separation for cache and I/O shared memory pages.
Eventually, support shared memory caching of multi-page entries.


Rock Store
----------

Rock Store uses a single [large] database-style file per cache_dir to store
cached responses and metadata. This part of the design is similar to COSS.
Rock Store does not maintain or rely on swap.state ""log"" for recovery.
Instead, the database is scanned in the background to load entries when Squid
starts. Rock Store maintains its own index of cached entries and avoids global
store_table. All entries must be max-size or smaller.

In SMP mode, each Rock cache_dir is given a dedicated Kid processes called
""disker"". All SMP workers communicate with diskers to store misses and load
hits, using shared memory pages and atomic shared memory queues. Disker blocks
when doing disk I/O but workers do not. Any Diskers:Workers ratio is supported
so that the user can find and configure the optimal number of workers and
diskers for a given number of disks and CPU cores.

In non-SMP mode, should use good old blocking disk I/O, without any diskers,
but this has not been tested recently and probably needs more work.

Feature page: http://wiki.squid-cache.org/Features/RockStore

TODO: Disk rate limit to protect Squid from disk overload. More stats.
Multiple readers? Seek optimization? Remove known max-size requirement?",8765,data/crawl/squid/hunk_2443.cpp,,,data/crawl/squid/old_hunk_2443.cpp,data/crawl/squid/new_hunk_2443.cpp,5,5,"storeAppendPrintf(&sentry, ""Percent Used: %0.2f%%\n"",
                      (100.0 * (double)cur_size / (double)max_size) );","storeAppendPrintf(&sentry, ""Percent Used: %0.2f%%\n"",
                      Math::doublePercent(currentSize(), maxSize()) );","[""removeVariable"", ""removeContent"", ""addVariable""]","[[""100"", ""0"", ""*"", ""double"", ""cur_size"", ""/"", ""double"", ""max_size""], [""Math"", ""doublePercent"", ""currentSize"", ""maxSize""]]",[-12451043446310186508],6022,0.0,2
https://github.com/squid-cache/squid/commit/35a1b223314eddb67b631cb0224d6e03a2360c77,13 Sep 2011,"SMP Caching: Core changes, IPC primitives, Shared memory cache, and Rock Store

Core changes
------------

* Added MemObject::expectedReplySize() and used it instead of object_sz.

When deciding whether an object with a known content length can be
swapped out, do not wait until the object is completely received and its
size (mem_obj->object_sz) becomes known (while asking the store to
recheck in vain with every incoming chunk). Instead, use the known
content length, if any, to make the decision.

This optimizes the common case where the complete object is eventually
received and swapped out, preventing accumulating potentially large
objects in RAM while waiting for the end of the response. Should not
affect objects with unknown content length.

Side-effect1: probably fixes several cases of unknowingly using negative
(unknown) mem_obj->object_sz in calculations. I added a few assertions
to double check some of the remaining object_sz/objectLen() uses.

Side-effect2: When expectedReplySize() is stored on disk as StoreEntry
metadata, it may help to detect truncated entries when the writer
process dies before completing the swapout.


* Removed mem->swapout.memnode in favor of mem->swapout.queue_offset.

The code used swapout.memnode pointer to keep track of the last page
that was swapped out. The code was semi-buggy because it could reset the
pointer to NULL if no new data came in before the call to doPages().
Perhaps the code relied on the assumption that the caller will never
doPages if there is no new data, but I am not sure that assumption was
correct in all cases (it could be that I broke the calling code, of course).

Moreover, the page pointer was kept without any protection from page
disappearing during asynchronous swapout. There were ""Evil hack time""
comments discussing how the page might disappear.

Fortunately, we already have mem->swapout.queue_offset that can be fed
to getBlockContainingLocation to find the page that needs to be swapped
out. There is no need to keep the page pointer around. The
queue_offset-based math is the same so we are not adding any overheads
by using that offset (in fact, we are removing some minor computations).


* Added ""close how?"" parameter to storeClose() and friends.

The old code would follow the same path when closing swapout activity
for an aborted entry and when completing a perfectly healthy swapout. In
non-shared case, that could have been OK because the abort code would
then release the entry, removing any half-written entry from the index
and the disk (but I am not sure that release happened fast enough in
100% of cases).

When the index and disk storage is shared among workers, such
""temporary"" inconsistencies result in truncated responses being
delivered by other workers to the user because once the swapout activity
is closed, other workers can start using the entry.

By adding the ""close how?"" parameter to closing methods we allow the
core and SwapDir-specific code to handle aborted swapouts appropriately.

Since swapin code is ""read only"", we do not currently distinguish
between aborted and fully satisfied readers: The readerGone enum value
applies to both cases. If needed, the SwapDir reading code can make that
distinction by analyzing how much was actually swapped in.


* Moved ""can you store this entry?"" code to virtual SwapDir::canStore().

The old code had some of the tests in SwapDir-specific canStore()
methods and some in storeDirSelect*() methods. This resulted in
inconsistencies, code duplication, and extra calculation overheads.
Making this call virtual allows individual cache_dir types to do custom
access controls.

The same method is used for cache_dir load reporting (if it returns
true). Load management needs more work, but the current code is no worse
than the old one in this aspect, and further improvements are outside
this change scope.


* Minimized from-disk StoreEntry loading/unpacking code duplication.

Moved common (and often rather complex!) code from store modules into
storeRebuildLoadEntry, storeRebuildParseEntry, and storeRebuildKeepEntry.


* Do not set object_sz when the entry is aborted because the true object
size (HTTP reply headers + body) is not known in this case. Setting
object_sz may fool client-side code into believing that the object is
complete.

This addresses an old RBC's complaint.


* When swapout initiation fails, mark swapout decision as
MemObject::SwapOut::swImpossible. This prevents the caller code from trying to
swap out again and again because swap_status becomes SWAPOUT_NONE.

TODO: Consider add SWAPOUT_ERROR, STORE_ERROR, and similar states. It
may solve several problems where the code sees _NONE or _OK and thinks
everything is peachy when in fact there was an error.


* Call haveParsedReplyHeaders() before entry->replaceHttpReply().

HaveParsedReplyHeaders() sets the entry public key and various flags (at 
least). ReplaceHttpReply() packs reply headers, starting swapout process.
It feels natural to adjust the entry _before_ we pack/swap it, but I may be
missing some side-effects here.

The change was necessary because we started calling checkCachable() from
swapoutPossible(). If haveParsedReplyHeaders() is not called before we swap
out checks, the entry will still have the private key and will be declared
impossible to cache.


* Extracted the write-to-store step from StoreEntry::replaceHttpReply().

This allows the caller to set the reply for the entry and then update the
entry and the reply before writing them to store. For example, the server-side
haveParsedReplyHeaders() code needs to set the entry timestamps and make the
entry key public before the entry starts swapping out, but the same code also
needs access to entry->getReply() and such for timestampsSet() and similar
code to work correctly.

TODO: Calls to StoreEntry::replaceHttpReply() do not have to be modified
because replaceHttpReply() does write by default. However, it is likely that
callers other than ServerStateData::setFinalReply() should take advantage of
the new split interface because they call timestampsSet() and such after
replaceHttpReply().


* Moved SwapDir::cur_size and n_disk_objects to specific SwapDirs. Removed
updateSize().  Some cache_dirs maintain their own maps and size statistics,
making the one-size-fits-all SwapDir members inappropriate.

* A new SwapDir public method swappedOut() added. It is called from
storeSwapOutFileClosed() to notify SwapDir that an object was swapped
out.

* Change SwapDir::max_size to bytes, make it protected, use maxSize() instead.

Change SwapDir::cur_size to bytes, make it private, use currentSize() instead.

Store Config.Store.avgObjectSize in bytes to avoid repeated and error-prone
KB<->bytes conversions.


* Change Config.cacheSwap.swapDirs and StoreEntry::store() type to SwapDir.

This allows using SwapDir API without dynamic_cast.


* Always call StoreEntry::abort() instead of setting ENTRY_ABORTED manually.

* Rely on entry->abort() side-effects if ENTRY_ABORTED was set.

* Added or updated comments to better document current code.

* Added operator << for dumping StoreEntry summary into the debugging
log. Needs more work to report more info (and not report yet-unknown info).

* Fixed blocking reads that were sometimes reading from random file offsets.

Core ""disk file"" reading code assumed that if the globally stored disk.offset
matches the desired offset, there is no reason to seek. This was probably done
to reduce seek overhead between consecutive reads. Unfortunately, the disk
writing code did not know about that optimization and left F->disk.offset
unchanged after writing.

This may have worked OK for UFS if it never writes to the file it reads from,
but it does not work for store modules that do both kinds of I/O at different
offsets of the same disk file.

Eventually, implement this optimization correctly or remove disk.offset.


IPC primitives
--------------

To make SMP disk and memory caching non-blocking and correct, worker and
disker processes must asynchronously communicate with each other. We are
adding a collection of classes that support such communication.

At the base of the collection is the AtomicWordT template that uses GCC atomic
primitives such as __sync_add_and_fetch() to perform atomic operations on
integral values in memory shared by multiple Squid kids. AtomicWordT is used
to implement non-blocking shared locks, queues, store tables, and page pools.

To avoid blocking or very long searches, many operations are ""optimistic"" in
nature. For example, it is possible that an atomic store map will refuse to
allocate an entry for two processes even though a blocking implementation
would have allowed one of the processes to get the map slot. We speculate that
such conflict resolution is better than blocking locks when it comes to
caching, especially if the conflicts are rare due to large number of cache
entries, fast operations, and relatively small number of kids.


TODO: Eventually, consider breaking locks left by dead kids.



Shared Memory Cache
-------------------

* Added initial shared memory cache implementation (MemStore).

The shared memory cache keeps its own compact index of cached entries using
extended Ipc::StoreMap class (MemStoreMap). The cache also strives to keep its
Root.get() results out of the store_table except during transit.

Eventually, the non-shared/local memory cache should also be implemented
using a MemStore-like class, I think. This will allow to clearly isolate
local from shared memory cache code.

Allow the user to explicitly disable shared memory caching in SMP mode via
memory_cache_shared to squid.conf. Report whether mem_cache is shared.

Disable shared memory caching by default if atomic operations are not
supported. Prohibit shared memory caching if atomic operations are not
supported.

TODO: Better limits/separation for cache and I/O shared memory pages.
Eventually, support shared memory caching of multi-page entries.


Rock Store
----------

Rock Store uses a single [large] database-style file per cache_dir to store
cached responses and metadata. This part of the design is similar to COSS.
Rock Store does not maintain or rely on swap.state ""log"" for recovery.
Instead, the database is scanned in the background to load entries when Squid
starts. Rock Store maintains its own index of cached entries and avoids global
store_table. All entries must be max-size or smaller.

In SMP mode, each Rock cache_dir is given a dedicated Kid processes called
""disker"". All SMP workers communicate with diskers to store misses and load
hits, using shared memory pages and atomic shared memory queues. Disker blocks
when doing disk I/O but workers do not. Any Diskers:Workers ratio is supported
so that the user can find and configure the optimal number of workers and
diskers for a given number of disks and CPU cores.

In non-SMP mode, should use good old blocking disk I/O, without any diskers,
but this has not been tested recently and probably needs more work.

Feature page: http://wiki.squid-cache.org/Features/RockStore

TODO: Disk rate limit to protect Squid from disk overload. More stats.
Multiple readers? Seek optimization? Remove known max-size requirement?",8765,data/crawl/squid/hunk_2443.cpp,,,data/crawl/squid/old_hunk_2443.cpp,data/crawl/squid/new_hunk_2443.cpp,3,3,"storeAppendPrintf(&sentry, ""Maximum Size: %lu KB\n"", max_size);","storeAppendPrintf(&sentry, ""Maximum Size: %""PRIu64"" KB\n"", maxSize() >> 10);","[""removeVariable"", ""updateContent"", ""addContent"", ""addVariable""]","[[""%lu"", ""max_size""], [""%"", ""PRIu64"", ""maxSize"", ""10""]]",[8838064220441106210],6021,100080.0,2
https://github.com/squid-cache/squid/commit/35a1b223314eddb67b631cb0224d6e03a2360c77,13 Sep 2011,"SMP Caching: Core changes, IPC primitives, Shared memory cache, and Rock Store

Core changes
------------

* Added MemObject::expectedReplySize() and used it instead of object_sz.

When deciding whether an object with a known content length can be
swapped out, do not wait until the object is completely received and its
size (mem_obj->object_sz) becomes known (while asking the store to
recheck in vain with every incoming chunk). Instead, use the known
content length, if any, to make the decision.

This optimizes the common case where the complete object is eventually
received and swapped out, preventing accumulating potentially large
objects in RAM while waiting for the end of the response. Should not
affect objects with unknown content length.

Side-effect1: probably fixes several cases of unknowingly using negative
(unknown) mem_obj->object_sz in calculations. I added a few assertions
to double check some of the remaining object_sz/objectLen() uses.

Side-effect2: When expectedReplySize() is stored on disk as StoreEntry
metadata, it may help to detect truncated entries when the writer
process dies before completing the swapout.


* Removed mem->swapout.memnode in favor of mem->swapout.queue_offset.

The code used swapout.memnode pointer to keep track of the last page
that was swapped out. The code was semi-buggy because it could reset the
pointer to NULL if no new data came in before the call to doPages().
Perhaps the code relied on the assumption that the caller will never
doPages if there is no new data, but I am not sure that assumption was
correct in all cases (it could be that I broke the calling code, of course).

Moreover, the page pointer was kept without any protection from page
disappearing during asynchronous swapout. There were ""Evil hack time""
comments discussing how the page might disappear.

Fortunately, we already have mem->swapout.queue_offset that can be fed
to getBlockContainingLocation to find the page that needs to be swapped
out. There is no need to keep the page pointer around. The
queue_offset-based math is the same so we are not adding any overheads
by using that offset (in fact, we are removing some minor computations).


* Added ""close how?"" parameter to storeClose() and friends.

The old code would follow the same path when closing swapout activity
for an aborted entry and when completing a perfectly healthy swapout. In
non-shared case, that could have been OK because the abort code would
then release the entry, removing any half-written entry from the index
and the disk (but I am not sure that release happened fast enough in
100% of cases).

When the index and disk storage is shared among workers, such
""temporary"" inconsistencies result in truncated responses being
delivered by other workers to the user because once the swapout activity
is closed, other workers can start using the entry.

By adding the ""close how?"" parameter to closing methods we allow the
core and SwapDir-specific code to handle aborted swapouts appropriately.

Since swapin code is ""read only"", we do not currently distinguish
between aborted and fully satisfied readers: The readerGone enum value
applies to both cases. If needed, the SwapDir reading code can make that
distinction by analyzing how much was actually swapped in.


* Moved ""can you store this entry?"" code to virtual SwapDir::canStore().

The old code had some of the tests in SwapDir-specific canStore()
methods and some in storeDirSelect*() methods. This resulted in
inconsistencies, code duplication, and extra calculation overheads.
Making this call virtual allows individual cache_dir types to do custom
access controls.

The same method is used for cache_dir load reporting (if it returns
true). Load management needs more work, but the current code is no worse
than the old one in this aspect, and further improvements are outside
this change scope.


* Minimized from-disk StoreEntry loading/unpacking code duplication.

Moved common (and often rather complex!) code from store modules into
storeRebuildLoadEntry, storeRebuildParseEntry, and storeRebuildKeepEntry.


* Do not set object_sz when the entry is aborted because the true object
size (HTTP reply headers + body) is not known in this case. Setting
object_sz may fool client-side code into believing that the object is
complete.

This addresses an old RBC's complaint.


* When swapout initiation fails, mark swapout decision as
MemObject::SwapOut::swImpossible. This prevents the caller code from trying to
swap out again and again because swap_status becomes SWAPOUT_NONE.

TODO: Consider add SWAPOUT_ERROR, STORE_ERROR, and similar states. It
may solve several problems where the code sees _NONE or _OK and thinks
everything is peachy when in fact there was an error.


* Call haveParsedReplyHeaders() before entry->replaceHttpReply().

HaveParsedReplyHeaders() sets the entry public key and various flags (at 
least). ReplaceHttpReply() packs reply headers, starting swapout process.
It feels natural to adjust the entry _before_ we pack/swap it, but I may be
missing some side-effects here.

The change was necessary because we started calling checkCachable() from
swapoutPossible(). If haveParsedReplyHeaders() is not called before we swap
out checks, the entry will still have the private key and will be declared
impossible to cache.


* Extracted the write-to-store step from StoreEntry::replaceHttpReply().

This allows the caller to set the reply for the entry and then update the
entry and the reply before writing them to store. For example, the server-side
haveParsedReplyHeaders() code needs to set the entry timestamps and make the
entry key public before the entry starts swapping out, but the same code also
needs access to entry->getReply() and such for timestampsSet() and similar
code to work correctly.

TODO: Calls to StoreEntry::replaceHttpReply() do not have to be modified
because replaceHttpReply() does write by default. However, it is likely that
callers other than ServerStateData::setFinalReply() should take advantage of
the new split interface because they call timestampsSet() and such after
replaceHttpReply().


* Moved SwapDir::cur_size and n_disk_objects to specific SwapDirs. Removed
updateSize().  Some cache_dirs maintain their own maps and size statistics,
making the one-size-fits-all SwapDir members inappropriate.

* A new SwapDir public method swappedOut() added. It is called from
storeSwapOutFileClosed() to notify SwapDir that an object was swapped
out.

* Change SwapDir::max_size to bytes, make it protected, use maxSize() instead.

Change SwapDir::cur_size to bytes, make it private, use currentSize() instead.

Store Config.Store.avgObjectSize in bytes to avoid repeated and error-prone
KB<->bytes conversions.


* Change Config.cacheSwap.swapDirs and StoreEntry::store() type to SwapDir.

This allows using SwapDir API without dynamic_cast.


* Always call StoreEntry::abort() instead of setting ENTRY_ABORTED manually.

* Rely on entry->abort() side-effects if ENTRY_ABORTED was set.

* Added or updated comments to better document current code.

* Added operator << for dumping StoreEntry summary into the debugging
log. Needs more work to report more info (and not report yet-unknown info).

* Fixed blocking reads that were sometimes reading from random file offsets.

Core ""disk file"" reading code assumed that if the globally stored disk.offset
matches the desired offset, there is no reason to seek. This was probably done
to reduce seek overhead between consecutive reads. Unfortunately, the disk
writing code did not know about that optimization and left F->disk.offset
unchanged after writing.

This may have worked OK for UFS if it never writes to the file it reads from,
but it does not work for store modules that do both kinds of I/O at different
offsets of the same disk file.

Eventually, implement this optimization correctly or remove disk.offset.


IPC primitives
--------------

To make SMP disk and memory caching non-blocking and correct, worker and
disker processes must asynchronously communicate with each other. We are
adding a collection of classes that support such communication.

At the base of the collection is the AtomicWordT template that uses GCC atomic
primitives such as __sync_add_and_fetch() to perform atomic operations on
integral values in memory shared by multiple Squid kids. AtomicWordT is used
to implement non-blocking shared locks, queues, store tables, and page pools.

To avoid blocking or very long searches, many operations are ""optimistic"" in
nature. For example, it is possible that an atomic store map will refuse to
allocate an entry for two processes even though a blocking implementation
would have allowed one of the processes to get the map slot. We speculate that
such conflict resolution is better than blocking locks when it comes to
caching, especially if the conflicts are rare due to large number of cache
entries, fast operations, and relatively small number of kids.


TODO: Eventually, consider breaking locks left by dead kids.



Shared Memory Cache
-------------------

* Added initial shared memory cache implementation (MemStore).

The shared memory cache keeps its own compact index of cached entries using
extended Ipc::StoreMap class (MemStoreMap). The cache also strives to keep its
Root.get() results out of the store_table except during transit.

Eventually, the non-shared/local memory cache should also be implemented
using a MemStore-like class, I think. This will allow to clearly isolate
local from shared memory cache code.

Allow the user to explicitly disable shared memory caching in SMP mode via
memory_cache_shared to squid.conf. Report whether mem_cache is shared.

Disable shared memory caching by default if atomic operations are not
supported. Prohibit shared memory caching if atomic operations are not
supported.

TODO: Better limits/separation for cache and I/O shared memory pages.
Eventually, support shared memory caching of multi-page entries.


Rock Store
----------

Rock Store uses a single [large] database-style file per cache_dir to store
cached responses and metadata. This part of the design is similar to COSS.
Rock Store does not maintain or rely on swap.state ""log"" for recovery.
Instead, the database is scanned in the background to load entries when Squid
starts. Rock Store maintains its own index of cached entries and avoids global
store_table. All entries must be max-size or smaller.

In SMP mode, each Rock cache_dir is given a dedicated Kid processes called
""disker"". All SMP workers communicate with diskers to store misses and load
hits, using shared memory pages and atomic shared memory queues. Disker blocks
when doing disk I/O but workers do not. Any Diskers:Workers ratio is supported
so that the user can find and configure the optimal number of workers and
diskers for a given number of disks and CPU cores.

In non-SMP mode, should use good old blocking disk I/O, without any diskers,
but this has not been tested recently and probably needs more work.

Feature page: http://wiki.squid-cache.org/Features/RockStore

TODO: Disk rate limit to protect Squid from disk overload. More stats.
Multiple readers? Seek optimization? Remove known max-size requirement?",8765,data/crawl/squid/hunk_2438.cpp,,,data/crawl/squid/old_hunk_2438.cpp,data/crawl/squid/new_hunk_2438.cpp,-1,371,,"fatal(""memory_cache_shared is on, but no support for shared memory detected"");","[""addLog""]","[[], [""fatal"", ""memory_cache_shared"", ""is"", ""on"", ""but"", ""no"", ""support"", ""for"", ""shared"", ""memory"", ""detected""]]",[-3577178566331241110],6020,11520.0,2
https://github.com/squid-cache/squid/commit/35a1b223314eddb67b631cb0224d6e03a2360c77,13 Sep 2011,"SMP Caching: Core changes, IPC primitives, Shared memory cache, and Rock Store

Core changes
------------

* Added MemObject::expectedReplySize() and used it instead of object_sz.

When deciding whether an object with a known content length can be
swapped out, do not wait until the object is completely received and its
size (mem_obj->object_sz) becomes known (while asking the store to
recheck in vain with every incoming chunk). Instead, use the known
content length, if any, to make the decision.

This optimizes the common case where the complete object is eventually
received and swapped out, preventing accumulating potentially large
objects in RAM while waiting for the end of the response. Should not
affect objects with unknown content length.

Side-effect1: probably fixes several cases of unknowingly using negative
(unknown) mem_obj->object_sz in calculations. I added a few assertions
to double check some of the remaining object_sz/objectLen() uses.

Side-effect2: When expectedReplySize() is stored on disk as StoreEntry
metadata, it may help to detect truncated entries when the writer
process dies before completing the swapout.


* Removed mem->swapout.memnode in favor of mem->swapout.queue_offset.

The code used swapout.memnode pointer to keep track of the last page
that was swapped out. The code was semi-buggy because it could reset the
pointer to NULL if no new data came in before the call to doPages().
Perhaps the code relied on the assumption that the caller will never
doPages if there is no new data, but I am not sure that assumption was
correct in all cases (it could be that I broke the calling code, of course).

Moreover, the page pointer was kept without any protection from page
disappearing during asynchronous swapout. There were ""Evil hack time""
comments discussing how the page might disappear.

Fortunately, we already have mem->swapout.queue_offset that can be fed
to getBlockContainingLocation to find the page that needs to be swapped
out. There is no need to keep the page pointer around. The
queue_offset-based math is the same so we are not adding any overheads
by using that offset (in fact, we are removing some minor computations).


* Added ""close how?"" parameter to storeClose() and friends.

The old code would follow the same path when closing swapout activity
for an aborted entry and when completing a perfectly healthy swapout. In
non-shared case, that could have been OK because the abort code would
then release the entry, removing any half-written entry from the index
and the disk (but I am not sure that release happened fast enough in
100% of cases).

When the index and disk storage is shared among workers, such
""temporary"" inconsistencies result in truncated responses being
delivered by other workers to the user because once the swapout activity
is closed, other workers can start using the entry.

By adding the ""close how?"" parameter to closing methods we allow the
core and SwapDir-specific code to handle aborted swapouts appropriately.

Since swapin code is ""read only"", we do not currently distinguish
between aborted and fully satisfied readers: The readerGone enum value
applies to both cases. If needed, the SwapDir reading code can make that
distinction by analyzing how much was actually swapped in.


* Moved ""can you store this entry?"" code to virtual SwapDir::canStore().

The old code had some of the tests in SwapDir-specific canStore()
methods and some in storeDirSelect*() methods. This resulted in
inconsistencies, code duplication, and extra calculation overheads.
Making this call virtual allows individual cache_dir types to do custom
access controls.

The same method is used for cache_dir load reporting (if it returns
true). Load management needs more work, but the current code is no worse
than the old one in this aspect, and further improvements are outside
this change scope.


* Minimized from-disk StoreEntry loading/unpacking code duplication.

Moved common (and often rather complex!) code from store modules into
storeRebuildLoadEntry, storeRebuildParseEntry, and storeRebuildKeepEntry.


* Do not set object_sz when the entry is aborted because the true object
size (HTTP reply headers + body) is not known in this case. Setting
object_sz may fool client-side code into believing that the object is
complete.

This addresses an old RBC's complaint.


* When swapout initiation fails, mark swapout decision as
MemObject::SwapOut::swImpossible. This prevents the caller code from trying to
swap out again and again because swap_status becomes SWAPOUT_NONE.

TODO: Consider add SWAPOUT_ERROR, STORE_ERROR, and similar states. It
may solve several problems where the code sees _NONE or _OK and thinks
everything is peachy when in fact there was an error.


* Call haveParsedReplyHeaders() before entry->replaceHttpReply().

HaveParsedReplyHeaders() sets the entry public key and various flags (at 
least). ReplaceHttpReply() packs reply headers, starting swapout process.
It feels natural to adjust the entry _before_ we pack/swap it, but I may be
missing some side-effects here.

The change was necessary because we started calling checkCachable() from
swapoutPossible(). If haveParsedReplyHeaders() is not called before we swap
out checks, the entry will still have the private key and will be declared
impossible to cache.


* Extracted the write-to-store step from StoreEntry::replaceHttpReply().

This allows the caller to set the reply for the entry and then update the
entry and the reply before writing them to store. For example, the server-side
haveParsedReplyHeaders() code needs to set the entry timestamps and make the
entry key public before the entry starts swapping out, but the same code also
needs access to entry->getReply() and such for timestampsSet() and similar
code to work correctly.

TODO: Calls to StoreEntry::replaceHttpReply() do not have to be modified
because replaceHttpReply() does write by default. However, it is likely that
callers other than ServerStateData::setFinalReply() should take advantage of
the new split interface because they call timestampsSet() and such after
replaceHttpReply().


* Moved SwapDir::cur_size and n_disk_objects to specific SwapDirs. Removed
updateSize().  Some cache_dirs maintain their own maps and size statistics,
making the one-size-fits-all SwapDir members inappropriate.

* A new SwapDir public method swappedOut() added. It is called from
storeSwapOutFileClosed() to notify SwapDir that an object was swapped
out.

* Change SwapDir::max_size to bytes, make it protected, use maxSize() instead.

Change SwapDir::cur_size to bytes, make it private, use currentSize() instead.

Store Config.Store.avgObjectSize in bytes to avoid repeated and error-prone
KB<->bytes conversions.


* Change Config.cacheSwap.swapDirs and StoreEntry::store() type to SwapDir.

This allows using SwapDir API without dynamic_cast.


* Always call StoreEntry::abort() instead of setting ENTRY_ABORTED manually.

* Rely on entry->abort() side-effects if ENTRY_ABORTED was set.

* Added or updated comments to better document current code.

* Added operator << for dumping StoreEntry summary into the debugging
log. Needs more work to report more info (and not report yet-unknown info).

* Fixed blocking reads that were sometimes reading from random file offsets.

Core ""disk file"" reading code assumed that if the globally stored disk.offset
matches the desired offset, there is no reason to seek. This was probably done
to reduce seek overhead between consecutive reads. Unfortunately, the disk
writing code did not know about that optimization and left F->disk.offset
unchanged after writing.

This may have worked OK for UFS if it never writes to the file it reads from,
but it does not work for store modules that do both kinds of I/O at different
offsets of the same disk file.

Eventually, implement this optimization correctly or remove disk.offset.


IPC primitives
--------------

To make SMP disk and memory caching non-blocking and correct, worker and
disker processes must asynchronously communicate with each other. We are
adding a collection of classes that support such communication.

At the base of the collection is the AtomicWordT template that uses GCC atomic
primitives such as __sync_add_and_fetch() to perform atomic operations on
integral values in memory shared by multiple Squid kids. AtomicWordT is used
to implement non-blocking shared locks, queues, store tables, and page pools.

To avoid blocking or very long searches, many operations are ""optimistic"" in
nature. For example, it is possible that an atomic store map will refuse to
allocate an entry for two processes even though a blocking implementation
would have allowed one of the processes to get the map slot. We speculate that
such conflict resolution is better than blocking locks when it comes to
caching, especially if the conflicts are rare due to large number of cache
entries, fast operations, and relatively small number of kids.


TODO: Eventually, consider breaking locks left by dead kids.



Shared Memory Cache
-------------------

* Added initial shared memory cache implementation (MemStore).

The shared memory cache keeps its own compact index of cached entries using
extended Ipc::StoreMap class (MemStoreMap). The cache also strives to keep its
Root.get() results out of the store_table except during transit.

Eventually, the non-shared/local memory cache should also be implemented
using a MemStore-like class, I think. This will allow to clearly isolate
local from shared memory cache code.

Allow the user to explicitly disable shared memory caching in SMP mode via
memory_cache_shared to squid.conf. Report whether mem_cache is shared.

Disable shared memory caching by default if atomic operations are not
supported. Prohibit shared memory caching if atomic operations are not
supported.

TODO: Better limits/separation for cache and I/O shared memory pages.
Eventually, support shared memory caching of multi-page entries.


Rock Store
----------

Rock Store uses a single [large] database-style file per cache_dir to store
cached responses and metadata. This part of the design is similar to COSS.
Rock Store does not maintain or rely on swap.state ""log"" for recovery.
Instead, the database is scanned in the background to load entries when Squid
starts. Rock Store maintains its own index of cached entries and avoids global
store_table. All entries must be max-size or smaller.

In SMP mode, each Rock cache_dir is given a dedicated Kid processes called
""disker"". All SMP workers communicate with diskers to store misses and load
hits, using shared memory pages and atomic shared memory queues. Disker blocks
when doing disk I/O but workers do not. Any Diskers:Workers ratio is supported
so that the user can find and configure the optimal number of workers and
diskers for a given number of disks and CPU cores.

In non-SMP mode, should use good old blocking disk I/O, without any diskers,
but this has not been tested recently and probably needs more work.

Feature page: http://wiki.squid-cache.org/Features/RockStore

TODO: Disk rate limit to protect Squid from disk overload. More stats.
Multiple readers? Seek optimization? Remove known max-size requirement?",8765,data/crawl/squid/hunk_2438.cpp,,,data/crawl/squid/old_hunk_2438.cpp,data/crawl/squid/new_hunk_2438.cpp,-1,369,,"fatal(""memory_cache_shared is on, but no support for atomic operations detected"");","[""addLog""]","[[], [""fatal"", ""memory_cache_shared"", ""is"", ""on"", ""but"", ""no"", ""support"", ""for"", ""atomic"", ""operations"", ""detected""]]",[5114139703971541903],6019,79920.0,2
https://github.com/squid-cache/squid/commit/35a1b223314eddb67b631cb0224d6e03a2360c77,13 Sep 2011,"SMP Caching: Core changes, IPC primitives, Shared memory cache, and Rock Store

Core changes
------------

* Added MemObject::expectedReplySize() and used it instead of object_sz.

When deciding whether an object with a known content length can be
swapped out, do not wait until the object is completely received and its
size (mem_obj->object_sz) becomes known (while asking the store to
recheck in vain with every incoming chunk). Instead, use the known
content length, if any, to make the decision.

This optimizes the common case where the complete object is eventually
received and swapped out, preventing accumulating potentially large
objects in RAM while waiting for the end of the response. Should not
affect objects with unknown content length.

Side-effect1: probably fixes several cases of unknowingly using negative
(unknown) mem_obj->object_sz in calculations. I added a few assertions
to double check some of the remaining object_sz/objectLen() uses.

Side-effect2: When expectedReplySize() is stored on disk as StoreEntry
metadata, it may help to detect truncated entries when the writer
process dies before completing the swapout.


* Removed mem->swapout.memnode in favor of mem->swapout.queue_offset.

The code used swapout.memnode pointer to keep track of the last page
that was swapped out. The code was semi-buggy because it could reset the
pointer to NULL if no new data came in before the call to doPages().
Perhaps the code relied on the assumption that the caller will never
doPages if there is no new data, but I am not sure that assumption was
correct in all cases (it could be that I broke the calling code, of course).

Moreover, the page pointer was kept without any protection from page
disappearing during asynchronous swapout. There were ""Evil hack time""
comments discussing how the page might disappear.

Fortunately, we already have mem->swapout.queue_offset that can be fed
to getBlockContainingLocation to find the page that needs to be swapped
out. There is no need to keep the page pointer around. The
queue_offset-based math is the same so we are not adding any overheads
by using that offset (in fact, we are removing some minor computations).


* Added ""close how?"" parameter to storeClose() and friends.

The old code would follow the same path when closing swapout activity
for an aborted entry and when completing a perfectly healthy swapout. In
non-shared case, that could have been OK because the abort code would
then release the entry, removing any half-written entry from the index
and the disk (but I am not sure that release happened fast enough in
100% of cases).

When the index and disk storage is shared among workers, such
""temporary"" inconsistencies result in truncated responses being
delivered by other workers to the user because once the swapout activity
is closed, other workers can start using the entry.

By adding the ""close how?"" parameter to closing methods we allow the
core and SwapDir-specific code to handle aborted swapouts appropriately.

Since swapin code is ""read only"", we do not currently distinguish
between aborted and fully satisfied readers: The readerGone enum value
applies to both cases. If needed, the SwapDir reading code can make that
distinction by analyzing how much was actually swapped in.


* Moved ""can you store this entry?"" code to virtual SwapDir::canStore().

The old code had some of the tests in SwapDir-specific canStore()
methods and some in storeDirSelect*() methods. This resulted in
inconsistencies, code duplication, and extra calculation overheads.
Making this call virtual allows individual cache_dir types to do custom
access controls.

The same method is used for cache_dir load reporting (if it returns
true). Load management needs more work, but the current code is no worse
than the old one in this aspect, and further improvements are outside
this change scope.


* Minimized from-disk StoreEntry loading/unpacking code duplication.

Moved common (and often rather complex!) code from store modules into
storeRebuildLoadEntry, storeRebuildParseEntry, and storeRebuildKeepEntry.


* Do not set object_sz when the entry is aborted because the true object
size (HTTP reply headers + body) is not known in this case. Setting
object_sz may fool client-side code into believing that the object is
complete.

This addresses an old RBC's complaint.


* When swapout initiation fails, mark swapout decision as
MemObject::SwapOut::swImpossible. This prevents the caller code from trying to
swap out again and again because swap_status becomes SWAPOUT_NONE.

TODO: Consider add SWAPOUT_ERROR, STORE_ERROR, and similar states. It
may solve several problems where the code sees _NONE or _OK and thinks
everything is peachy when in fact there was an error.


* Call haveParsedReplyHeaders() before entry->replaceHttpReply().

HaveParsedReplyHeaders() sets the entry public key and various flags (at 
least). ReplaceHttpReply() packs reply headers, starting swapout process.
It feels natural to adjust the entry _before_ we pack/swap it, but I may be
missing some side-effects here.

The change was necessary because we started calling checkCachable() from
swapoutPossible(). If haveParsedReplyHeaders() is not called before we swap
out checks, the entry will still have the private key and will be declared
impossible to cache.


* Extracted the write-to-store step from StoreEntry::replaceHttpReply().

This allows the caller to set the reply for the entry and then update the
entry and the reply before writing them to store. For example, the server-side
haveParsedReplyHeaders() code needs to set the entry timestamps and make the
entry key public before the entry starts swapping out, but the same code also
needs access to entry->getReply() and such for timestampsSet() and similar
code to work correctly.

TODO: Calls to StoreEntry::replaceHttpReply() do not have to be modified
because replaceHttpReply() does write by default. However, it is likely that
callers other than ServerStateData::setFinalReply() should take advantage of
the new split interface because they call timestampsSet() and such after
replaceHttpReply().


* Moved SwapDir::cur_size and n_disk_objects to specific SwapDirs. Removed
updateSize().  Some cache_dirs maintain their own maps and size statistics,
making the one-size-fits-all SwapDir members inappropriate.

* A new SwapDir public method swappedOut() added. It is called from
storeSwapOutFileClosed() to notify SwapDir that an object was swapped
out.

* Change SwapDir::max_size to bytes, make it protected, use maxSize() instead.

Change SwapDir::cur_size to bytes, make it private, use currentSize() instead.

Store Config.Store.avgObjectSize in bytes to avoid repeated and error-prone
KB<->bytes conversions.


* Change Config.cacheSwap.swapDirs and StoreEntry::store() type to SwapDir.

This allows using SwapDir API without dynamic_cast.


* Always call StoreEntry::abort() instead of setting ENTRY_ABORTED manually.

* Rely on entry->abort() side-effects if ENTRY_ABORTED was set.

* Added or updated comments to better document current code.

* Added operator << for dumping StoreEntry summary into the debugging
log. Needs more work to report more info (and not report yet-unknown info).

* Fixed blocking reads that were sometimes reading from random file offsets.

Core ""disk file"" reading code assumed that if the globally stored disk.offset
matches the desired offset, there is no reason to seek. This was probably done
to reduce seek overhead between consecutive reads. Unfortunately, the disk
writing code did not know about that optimization and left F->disk.offset
unchanged after writing.

This may have worked OK for UFS if it never writes to the file it reads from,
but it does not work for store modules that do both kinds of I/O at different
offsets of the same disk file.

Eventually, implement this optimization correctly or remove disk.offset.


IPC primitives
--------------

To make SMP disk and memory caching non-blocking and correct, worker and
disker processes must asynchronously communicate with each other. We are
adding a collection of classes that support such communication.

At the base of the collection is the AtomicWordT template that uses GCC atomic
primitives such as __sync_add_and_fetch() to perform atomic operations on
integral values in memory shared by multiple Squid kids. AtomicWordT is used
to implement non-blocking shared locks, queues, store tables, and page pools.

To avoid blocking or very long searches, many operations are ""optimistic"" in
nature. For example, it is possible that an atomic store map will refuse to
allocate an entry for two processes even though a blocking implementation
would have allowed one of the processes to get the map slot. We speculate that
such conflict resolution is better than blocking locks when it comes to
caching, especially if the conflicts are rare due to large number of cache
entries, fast operations, and relatively small number of kids.


TODO: Eventually, consider breaking locks left by dead kids.



Shared Memory Cache
-------------------

* Added initial shared memory cache implementation (MemStore).

The shared memory cache keeps its own compact index of cached entries using
extended Ipc::StoreMap class (MemStoreMap). The cache also strives to keep its
Root.get() results out of the store_table except during transit.

Eventually, the non-shared/local memory cache should also be implemented
using a MemStore-like class, I think. This will allow to clearly isolate
local from shared memory cache code.

Allow the user to explicitly disable shared memory caching in SMP mode via
memory_cache_shared to squid.conf. Report whether mem_cache is shared.

Disable shared memory caching by default if atomic operations are not
supported. Prohibit shared memory caching if atomic operations are not
supported.

TODO: Better limits/separation for cache and I/O shared memory pages.
Eventually, support shared memory caching of multi-page entries.


Rock Store
----------

Rock Store uses a single [large] database-style file per cache_dir to store
cached responses and metadata. This part of the design is similar to COSS.
Rock Store does not maintain or rely on swap.state ""log"" for recovery.
Instead, the database is scanned in the background to load entries when Squid
starts. Rock Store maintains its own index of cached entries and avoids global
store_table. All entries must be max-size or smaller.

In SMP mode, each Rock cache_dir is given a dedicated Kid processes called
""disker"". All SMP workers communicate with diskers to store misses and load
hits, using shared memory pages and atomic shared memory queues. Disker blocks
when doing disk I/O but workers do not. Any Diskers:Workers ratio is supported
so that the user can find and configure the optimal number of workers and
diskers for a given number of disks and CPU cores.

In non-SMP mode, should use good old blocking disk I/O, without any diskers,
but this has not been tested recently and probably needs more work.

Feature page: http://wiki.squid-cache.org/Features/RockStore

TODO: Disk rate limit to protect Squid from disk overload. More stats.
Multiple readers? Seek optimization? Remove known max-size requirement?",8765,data/crawl/squid/hunk_2438.cpp,,,data/crawl/squid/old_hunk_2438.cpp,data/crawl/squid/new_hunk_2438.cpp,-1,192,,"fatal(""MemStore::get(key,callback,data) should not be called"");","[""addLog""]","[[], [""fatal"", ""MemStore"", ""get"", ""key"", ""callback"", ""data"", ""should"", ""not"", ""be"", ""called""]]",[3864778167489770400],6018,110880.0,2
https://github.com/squid-cache/squid/commit/35a1b223314eddb67b631cb0224d6e03a2360c77,13 Sep 2011,"SMP Caching: Core changes, IPC primitives, Shared memory cache, and Rock Store

Core changes
------------

* Added MemObject::expectedReplySize() and used it instead of object_sz.

When deciding whether an object with a known content length can be
swapped out, do not wait until the object is completely received and its
size (mem_obj->object_sz) becomes known (while asking the store to
recheck in vain with every incoming chunk). Instead, use the known
content length, if any, to make the decision.

This optimizes the common case where the complete object is eventually
received and swapped out, preventing accumulating potentially large
objects in RAM while waiting for the end of the response. Should not
affect objects with unknown content length.

Side-effect1: probably fixes several cases of unknowingly using negative
(unknown) mem_obj->object_sz in calculations. I added a few assertions
to double check some of the remaining object_sz/objectLen() uses.

Side-effect2: When expectedReplySize() is stored on disk as StoreEntry
metadata, it may help to detect truncated entries when the writer
process dies before completing the swapout.


* Removed mem->swapout.memnode in favor of mem->swapout.queue_offset.

The code used swapout.memnode pointer to keep track of the last page
that was swapped out. The code was semi-buggy because it could reset the
pointer to NULL if no new data came in before the call to doPages().
Perhaps the code relied on the assumption that the caller will never
doPages if there is no new data, but I am not sure that assumption was
correct in all cases (it could be that I broke the calling code, of course).

Moreover, the page pointer was kept without any protection from page
disappearing during asynchronous swapout. There were ""Evil hack time""
comments discussing how the page might disappear.

Fortunately, we already have mem->swapout.queue_offset that can be fed
to getBlockContainingLocation to find the page that needs to be swapped
out. There is no need to keep the page pointer around. The
queue_offset-based math is the same so we are not adding any overheads
by using that offset (in fact, we are removing some minor computations).


* Added ""close how?"" parameter to storeClose() and friends.

The old code would follow the same path when closing swapout activity
for an aborted entry and when completing a perfectly healthy swapout. In
non-shared case, that could have been OK because the abort code would
then release the entry, removing any half-written entry from the index
and the disk (but I am not sure that release happened fast enough in
100% of cases).

When the index and disk storage is shared among workers, such
""temporary"" inconsistencies result in truncated responses being
delivered by other workers to the user because once the swapout activity
is closed, other workers can start using the entry.

By adding the ""close how?"" parameter to closing methods we allow the
core and SwapDir-specific code to handle aborted swapouts appropriately.

Since swapin code is ""read only"", we do not currently distinguish
between aborted and fully satisfied readers: The readerGone enum value
applies to both cases. If needed, the SwapDir reading code can make that
distinction by analyzing how much was actually swapped in.


* Moved ""can you store this entry?"" code to virtual SwapDir::canStore().

The old code had some of the tests in SwapDir-specific canStore()
methods and some in storeDirSelect*() methods. This resulted in
inconsistencies, code duplication, and extra calculation overheads.
Making this call virtual allows individual cache_dir types to do custom
access controls.

The same method is used for cache_dir load reporting (if it returns
true). Load management needs more work, but the current code is no worse
than the old one in this aspect, and further improvements are outside
this change scope.


* Minimized from-disk StoreEntry loading/unpacking code duplication.

Moved common (and often rather complex!) code from store modules into
storeRebuildLoadEntry, storeRebuildParseEntry, and storeRebuildKeepEntry.


* Do not set object_sz when the entry is aborted because the true object
size (HTTP reply headers + body) is not known in this case. Setting
object_sz may fool client-side code into believing that the object is
complete.

This addresses an old RBC's complaint.


* When swapout initiation fails, mark swapout decision as
MemObject::SwapOut::swImpossible. This prevents the caller code from trying to
swap out again and again because swap_status becomes SWAPOUT_NONE.

TODO: Consider add SWAPOUT_ERROR, STORE_ERROR, and similar states. It
may solve several problems where the code sees _NONE or _OK and thinks
everything is peachy when in fact there was an error.


* Call haveParsedReplyHeaders() before entry->replaceHttpReply().

HaveParsedReplyHeaders() sets the entry public key and various flags (at 
least). ReplaceHttpReply() packs reply headers, starting swapout process.
It feels natural to adjust the entry _before_ we pack/swap it, but I may be
missing some side-effects here.

The change was necessary because we started calling checkCachable() from
swapoutPossible(). If haveParsedReplyHeaders() is not called before we swap
out checks, the entry will still have the private key and will be declared
impossible to cache.


* Extracted the write-to-store step from StoreEntry::replaceHttpReply().

This allows the caller to set the reply for the entry and then update the
entry and the reply before writing them to store. For example, the server-side
haveParsedReplyHeaders() code needs to set the entry timestamps and make the
entry key public before the entry starts swapping out, but the same code also
needs access to entry->getReply() and such for timestampsSet() and similar
code to work correctly.

TODO: Calls to StoreEntry::replaceHttpReply() do not have to be modified
because replaceHttpReply() does write by default. However, it is likely that
callers other than ServerStateData::setFinalReply() should take advantage of
the new split interface because they call timestampsSet() and such after
replaceHttpReply().


* Moved SwapDir::cur_size and n_disk_objects to specific SwapDirs. Removed
updateSize().  Some cache_dirs maintain their own maps and size statistics,
making the one-size-fits-all SwapDir members inappropriate.

* A new SwapDir public method swappedOut() added. It is called from
storeSwapOutFileClosed() to notify SwapDir that an object was swapped
out.

* Change SwapDir::max_size to bytes, make it protected, use maxSize() instead.

Change SwapDir::cur_size to bytes, make it private, use currentSize() instead.

Store Config.Store.avgObjectSize in bytes to avoid repeated and error-prone
KB<->bytes conversions.


* Change Config.cacheSwap.swapDirs and StoreEntry::store() type to SwapDir.

This allows using SwapDir API without dynamic_cast.


* Always call StoreEntry::abort() instead of setting ENTRY_ABORTED manually.

* Rely on entry->abort() side-effects if ENTRY_ABORTED was set.

* Added or updated comments to better document current code.

* Added operator << for dumping StoreEntry summary into the debugging
log. Needs more work to report more info (and not report yet-unknown info).

* Fixed blocking reads that were sometimes reading from random file offsets.

Core ""disk file"" reading code assumed that if the globally stored disk.offset
matches the desired offset, there is no reason to seek. This was probably done
to reduce seek overhead between consecutive reads. Unfortunately, the disk
writing code did not know about that optimization and left F->disk.offset
unchanged after writing.

This may have worked OK for UFS if it never writes to the file it reads from,
but it does not work for store modules that do both kinds of I/O at different
offsets of the same disk file.

Eventually, implement this optimization correctly or remove disk.offset.


IPC primitives
--------------

To make SMP disk and memory caching non-blocking and correct, worker and
disker processes must asynchronously communicate with each other. We are
adding a collection of classes that support such communication.

At the base of the collection is the AtomicWordT template that uses GCC atomic
primitives such as __sync_add_and_fetch() to perform atomic operations on
integral values in memory shared by multiple Squid kids. AtomicWordT is used
to implement non-blocking shared locks, queues, store tables, and page pools.

To avoid blocking or very long searches, many operations are ""optimistic"" in
nature. For example, it is possible that an atomic store map will refuse to
allocate an entry for two processes even though a blocking implementation
would have allowed one of the processes to get the map slot. We speculate that
such conflict resolution is better than blocking locks when it comes to
caching, especially if the conflicts are rare due to large number of cache
entries, fast operations, and relatively small number of kids.


TODO: Eventually, consider breaking locks left by dead kids.



Shared Memory Cache
-------------------

* Added initial shared memory cache implementation (MemStore).

The shared memory cache keeps its own compact index of cached entries using
extended Ipc::StoreMap class (MemStoreMap). The cache also strives to keep its
Root.get() results out of the store_table except during transit.

Eventually, the non-shared/local memory cache should also be implemented
using a MemStore-like class, I think. This will allow to clearly isolate
local from shared memory cache code.

Allow the user to explicitly disable shared memory caching in SMP mode via
memory_cache_shared to squid.conf. Report whether mem_cache is shared.

Disable shared memory caching by default if atomic operations are not
supported. Prohibit shared memory caching if atomic operations are not
supported.

TODO: Better limits/separation for cache and I/O shared memory pages.
Eventually, support shared memory caching of multi-page entries.


Rock Store
----------

Rock Store uses a single [large] database-style file per cache_dir to store
cached responses and metadata. This part of the design is similar to COSS.
Rock Store does not maintain or rely on swap.state ""log"" for recovery.
Instead, the database is scanned in the background to load entries when Squid
starts. Rock Store maintains its own index of cached entries and avoids global
store_table. All entries must be max-size or smaller.

In SMP mode, each Rock cache_dir is given a dedicated Kid processes called
""disker"". All SMP workers communicate with diskers to store misses and load
hits, using shared memory pages and atomic shared memory queues. Disker blocks
when doing disk I/O but workers do not. Any Diskers:Workers ratio is supported
so that the user can find and configure the optimal number of workers and
diskers for a given number of disks and CPU cores.

In non-SMP mode, should use good old blocking disk I/O, without any diskers,
but this has not been tested recently and probably needs more work.

Feature page: http://wiki.squid-cache.org/Features/RockStore

TODO: Disk rate limit to protect Squid from disk overload. More stats.
Multiple readers? Seek optimization? Remove known max-size requirement?",8765,data/crawl/squid/hunk_2438.cpp,,,data/crawl/squid/old_hunk_2438.cpp,data/crawl/squid/new_hunk_2438.cpp,-1,58,,"storeAppendPrintf(&e, ""Maximum Size: %.0f KB\n"", Config.memMaxSize/1024.0);","[""addLog""]","[[], [""storeAppendPrintf"", ""&e"", ""Maximum"", ""Size"", ""%"", ""0f"", ""KB\\n"", ""Config"", ""memMaxSize/1024"", ""0""]]",[16115452904683357215],6017,110880.0,2
https://github.com/squid-cache/squid/commit/32b28f499200e7636380cf067e08bd943a6753e3,06 Oct 2011,"Added max-swap-rate=swaps/sec option to Rock cache_dir.

The option limits the rate of Rock disk access to smooth out OS disk commit
activity and to avoid blocking Rock diskers (or even other processes) on I/O.
Should be used when swap demand exceeds disk performance limits but the
underlying file system does not slow down incoming I/Os until the situation
gets out of control.

Warn if Rock disker delays are significant.",216,data/crawl/squid/hunk_2429.cpp,,,data/crawl/squid/old_hunk_2429.cpp,data/crawl/squid/new_hunk_2429.cpp,-1,43,,"storeAppendPrintf(e, "" max-swap-rate=%d"", fileConfig.ioRate);","[""addLog""]","[[], [""storeAppendPrintf"", ""e"", ""max"", ""swap"", ""rate"", ""%d"", ""fileConfig"", ""ioRate""]]",[2168093689010028722],6016,15120.0,2
https://github.com/squid-cache/squid/commit/b3a4ba82b557dbacc409928bbdb732237f413da5,06 Oct 2011,"Polished SMP caching code, primarily to stay out of the way in non-SMP mode.

Do not start useless diskers. Do not assume Rock cache_dirs are present.
Do not require IpcIo DiskIO module to build Rock store.
Check IPC I/O pages limits in Rock store only when using a disker.
Warn about Rock cache_dir disk space waste.
Warn if shared memory cache is enabled in non-SMP mode.
Fake shared memory segments if needed (e.g., we are using Rock cache_dirs with
  no POSIX shared memory support) and possible (e.g., no SMP).",357,data/crawl/squid/hunk_2427.cpp,,,data/crawl/squid/old_hunk_2427.cpp,data/crawl/squid/new_hunk_2427.cpp,-1,71,,"fatalf(""%s failed"", context);","[""addLog""]","[[], [""fatalf"", ""%s"", ""failed"", ""context""]]",[-5663475199645673505],6015,1440.0,2
https://github.com/squid-cache/squid/commit/b3a4ba82b557dbacc409928bbdb732237f413da5,06 Oct 2011,"Polished SMP caching code, primarily to stay out of the way in non-SMP mode.

Do not start useless diskers. Do not assume Rock cache_dirs are present.
Do not require IpcIo DiskIO module to build Rock store.
Check IPC I/O pages limits in Rock store only when using a disker.
Warn about Rock cache_dir disk space waste.
Warn if shared memory cache is enabled in non-SMP mode.
Fake shared memory segments if needed (e.g., we are using Rock cache_dirs with
  no POSIX shared memory support) and possible (e.g., no SMP).",357,data/crawl/squid/hunk_2427.cpp,,,data/crawl/squid/old_hunk_2427.cpp,data/crawl/squid/new_hunk_2427.cpp,-1,56,,"fatalf(""Fake segment not found: %s"", theName.termedBuf());","[""addLog""]","[[], [""fatalf"", ""Fake"", ""segment"", ""not"", ""found"", ""%s"", ""theName"", ""termedBuf""]]",[15731515074102340704],6014,1440.0,2
https://github.com/squid-cache/squid/commit/b3a4ba82b557dbacc409928bbdb732237f413da5,06 Oct 2011,"Polished SMP caching code, primarily to stay out of the way in non-SMP mode.

Do not start useless diskers. Do not assume Rock cache_dirs are present.
Do not require IpcIo DiskIO module to build Rock store.
Check IPC I/O pages limits in Rock store only when using a disker.
Warn about Rock cache_dir disk space waste.
Warn if shared memory cache is enabled in non-SMP mode.
Fake shared memory segments if needed (e.g., we are using Rock cache_dirs with
  no POSIX shared memory support) and possible (e.g., no SMP).",357,data/crawl/squid/hunk_2427.cpp,,,data/crawl/squid/old_hunk_2427.cpp,data/crawl/squid/new_hunk_2427.cpp,-1,39,,"fatalf(""Duplicate fake segment creation: %s"", theName.termedBuf());","[""addLog""]","[[], [""fatalf"", ""Duplicate"", ""fake"", ""segment"", ""creation"", ""%s"", ""theName"", ""termedBuf""]]",[10663551848230666060],6013,1440.0,2
https://github.com/squid-cache/squid/commit/c031952f278d7a8cf2d7043aa8f32ad004af980e,03 Dec 2011,Fix arguments to swaplog renaming calls,4,data/crawl/squid/hunk_2391.cpp,,,data/crawl/squid/old_hunk_2391.cpp,data/crawl/squid/new_hunk_2391.cpp,10,10,"fatalf(""Failed to open swap log "", swaplog_path);","fatalf(""Failed to open swap log %s"", swaplog_path);","[""updateContent""]","[[], [""%s""]]",[4736028453042782],6012,792000.0,2
https://github.com/squid-cache/squid/commit/b073fc4bde37d3b0dd2f820f90c801d7dada1338,30 Dec 2011,"Cache Manager migration support

 * Add a little bit of XHR script to the CGI cachemgr front page which
probes each of the managed proxies for http:// and https:// capabilities
and produces web links to their internal managers.

 * Reserve the template name MGR_INDEX for use by cachemgr scripts.
But do not distribute any preset template. This allows manager apps to
provide their own static template with linked scripts and objects.

 * The error page system is updated to create a blanket message
indicating missing template instead of aborting Squid if a template is
not even installed.",122,data/crawl/squid/hunk_2362.cpp,,,data/crawl/squid/old_hunk_2362.cpp,data/crawl/squid/new_hunk_2362.cpp,-1,34,,"printf(""</script>\n"");","[""addLog""]","[[], [""printf"", ""/script"", ""\\n""]]",[2030380380745911200],6011,0.0,2
https://github.com/squid-cache/squid/commit/081edc2de252e852d0a8e02891fb36d7919a92ef,07 Jan 2012,"Cleanup: update most of the existing stub files to use the STUB.h framework

There are still several sections to be done. Including adding library API
stubs. However these are the ones which can be done immediately without 
breaking or re-writing existing unit tests.",2058,data/crawl/squid/hunk_2358.cpp,,,data/crawl/squid/old_hunk_2358.cpp,data/crawl/squid/new_hunk_2358.cpp,6,-1,"fprintf(stderr, ""Fatal: %s"",message);",,"[""removeLog""]","[[""fprintf"", ""stderr"", ""Fatal"", ""%s"", ""message""], []]",[25714727152405944387],6010,0.0,2
https://github.com/squid-cache/squid/commit/65d448bc848526838ea2d5cea65d72a341896f08,25 Apr 2012,"SourceLayout: port config and select-loop priority polishing

- renames http_port_list to AnyP::PortCfg
- de-duplicate https_port_list into AnyP::PortCfg
- shuffles related globals and defines into anyp/PortCfg.*
- renames MAXHTTPPORTS to MAXTCPLISTENPORTS to suit its actual coverage of HTTP and HTTPS ports.
- shuffled config port clone function into a method.
- rename ICP/HTCP/SNMP API functions to consistent *OpenPorts() and *ClosePorts()


  NP:following applies to incoming_* and *_poll_cnt directives.
- renames *_icp_* to *_udp_*
- renames *_http_* to *_tcp_*
- shuffles duplicated struct SquidConf options into a shared structure
- shuffles related defines into comm/Loops.h
- documents options better

- various other cosmetic syntax tweaks and polish

One bug fix:
  comm_dns_incoming was not being propigated in StatsHist copy/clone.
  Now is. I seem to remember mention of something similar being zero before,
  but can't find the bug report.",1098,data/crawl/squid/hunk_2321.cpp,,,data/crawl/squid/old_hunk_2321.cpp,data/crawl/squid/new_hunk_2321.cpp,15,15,"storeAppendPrintf(sentry, ""HTTP Messages handled per comm_select_http_incoming() call:\n"");","storeAppendPrintf(sentry, ""HTTP Messages handled per comm_select_tcp_incoming() call:\n"");","[""updateContent""]","[[""comm_select_http_incoming""], [""comm_select_tcp_incoming""]]",[-11014821049465247678],6009,0.0,2
https://github.com/squid-cache/squid/commit/65d448bc848526838ea2d5cea65d72a341896f08,25 Apr 2012,"SourceLayout: port config and select-loop priority polishing

- renames http_port_list to AnyP::PortCfg
- de-duplicate https_port_list into AnyP::PortCfg
- shuffles related globals and defines into anyp/PortCfg.*
- renames MAXHTTPPORTS to MAXTCPLISTENPORTS to suit its actual coverage of HTTP and HTTPS ports.
- shuffled config port clone function into a method.
- rename ICP/HTCP/SNMP API functions to consistent *OpenPorts() and *ClosePorts()


  NP:following applies to incoming_* and *_poll_cnt directives.
- renames *_icp_* to *_udp_*
- renames *_http_* to *_tcp_*
- shuffles duplicated struct SquidConf options into a shared structure
- shuffles related defines into comm/Loops.h
- documents options better

- various other cosmetic syntax tweaks and polish

One bug fix:
  comm_dns_incoming was not being propigated in StatsHist copy/clone.
  Now is. I seem to remember mention of something similar being zero before,
  but can't find the bug report.",1098,data/crawl/squid/hunk_2321.cpp,,,data/crawl/squid/old_hunk_2321.cpp,data/crawl/squid/new_hunk_2321.cpp,11,11,"storeAppendPrintf(sentry, ""ICP Messages handled per comm_select_icp_incoming() call:\n"");","storeAppendPrintf(sentry, ""ICP Messages handled per comm_select_udp_incoming() call:\n"");","[""updateContent""]","[[""comm_select_icp_incoming""], [""comm_select_udp_incoming""]]",[7669300460943962457],6008,0.0,2
https://github.com/squid-cache/squid/commit/95dc7ff44bb6598cf09020f2ac9b66f0cb28f8e5,17 Jul 2012,Changed increment operators from postfix to prefix form.,541,data/crawl/squid/hunk_2170.cpp,,,data/crawl/squid/old_hunk_2170.cpp,data/crawl/squid/new_hunk_2170.cpp,4,4,"storeAppendPrintf(s, ""\ttry#%d"", j + 1);","storeAppendPrintf(s, ""\ttry#%d"", j);","[""removeVariable"", ""removeContent""]","[[""1""], []]",[-6272018864],6007,0.0,2
https://github.com/squid-cache/squid/commit/2f6fcab1f37182a2b52350efb42a63c9cf949568,18 Jul 2012,"Bug 3551: store_rebuild.cc:116: ""store_errors == 0"" assertion

Fail with an explanation instead of asserting. The assertion fails when a ufs
cache_dir's swap.state has inconsistencies AND the user starts Squid with a -S
command line option. Normally, such inconsistencies are ignored and many of
them are benign.  For example, a missing cache file with an ADD record in
swap.state is such an inconsistency.

The -S option was meant to help developers troubleshoot inconsistencies by
analyzing core dumps, but (a) admins treat assertions as Squid bugs and file
bug reports and (b) in most cases, it is really difficult to find the
inconsistency when Squid asserts after detecting all of them (and leaving the
detection context).

We now explicitly tell the admin what their options are and quit instead of
asserting.

TODO: Consider adding a ufs cache_dir option that checks for and removes
inconsistencies instead of not checking at all (default) or checking and
quitting (-S). This is difficult because some valid cache entries may look
inconsistent while they are being updated and some invalid cache entries
are not visible to Squid without a full directory scan.",8,data/crawl/squid/hunk_2098.cpp,,,data/crawl/squid/old_hunk_2098.cpp,data/crawl/squid/new_hunk_2098.cpp,-1,4,,"fatalf(""Quitting after finding %d cache index inconsistencies. "" \
                   ""Removing cache index will force its slow rebuild. "" \
                   ""Removing -S will let Squid start with an inconsistent "" \
                   ""cache index (at your own risk).\n"", store_errors);","[""addLog""]","[[], [""fatalf"", ""Quitting"", ""after"", ""finding"", ""%d"", ""cache"", ""index"", ""inconsistencies"", ""\\"", ""Removing"", ""cache"", ""index"", ""will"", ""force"", ""its"", ""slow"", ""rebuild"", ""\\"", ""Removing"", ""S"", ""will"", ""let"", ""Squid"", ""start"", ""with"", ""an"", ""inconsistent"", ""\\"", ""cache"", ""index"", ""at"", ""your"", ""own"", ""risk"", ""\\n"", ""store_errors""]]",[-68049633540404360435],6006,0.0,2
https://github.com/squid-cache/squid/commit/7456a5c9d27ec42413ac84927c7f9158434d87ae,26 Jul 2012,Consolidate external_acl_form config dumping a bit and add missing percent dumper.,25,data/crawl/squid/hunk_2084.cpp,,,data/crawl/squid/old_hunk_2084.cpp,data/crawl/squid/new_hunk_2084.cpp,17,5,"storeAppendPrintf(sentry, "" %%USER_CERT_%s"", format->header);","DUMP_EXT_ACL_TYPE_FMT(USER_CERT, "" %%USER_CERT_%s"", format->header);","[""updateVariable"", ""updateLog""]","[[""storeAppendPrintf"", ""sentry""], [""DUMP_EXT_ACL_TYPE_FMT"", ""USER_CERT""]]",[-4202360543490785724],6005,0.0,2
https://github.com/squid-cache/squid/commit/7456a5c9d27ec42413ac84927c7f9158434d87ae,26 Jul 2012,Consolidate external_acl_form config dumping a bit and add missing percent dumper.,25,data/crawl/squid/hunk_2084.cpp,,,data/crawl/squid/old_hunk_2084.cpp,data/crawl/squid/new_hunk_2084.cpp,13,6,"storeAppendPrintf(sentry, "" %%USER_CERT_%s"", format->header);","DUMP_EXT_ACL_TYPE_FMT(CA_CERT, "" %%CA_CERT_%s"", format->header);","[""updateVariable"", ""updateLog"", ""updateContent""]","[[""storeAppendPrintf"", ""sentry"", ""%%USER_CERT_%s""], [""DUMP_EXT_ACL_TYPE_FMT"", ""CA_CERT"", ""%%CA_CERT_%s""]]",[-18601656213840574156],6004,0.0,2
https://github.com/squid-cache/squid/commit/7456a5c9d27ec42413ac84927c7f9158434d87ae,26 Jul 2012,Consolidate external_acl_form config dumping a bit and add missing percent dumper.,25,data/crawl/squid/hunk_2084.cpp,,,data/crawl/squid/old_hunk_2084.cpp,data/crawl/squid/new_hunk_2084.cpp,9,4,"storeAppendPrintf(sentry, "" %%USER_CERTCHAIN"");","DUMP_EXT_ACL_TYPE_FMT(USER_CERTCHAIN_RAW, "" %%USER_CERTCHAIN_RAW"");","[""updateVariable"", ""updateLog"", ""updateContent""]","[[""storeAppendPrintf"", ""sentry"", ""%%USER_CERTCHAIN""], [""DUMP_EXT_ACL_TYPE_FMT"", ""USER_CERTCHAIN_RAW"", ""%%USER_CERTCHAIN_RAW""]]",[-637458935919107222],6003,0.0,2
https://github.com/squid-cache/squid/commit/7456a5c9d27ec42413ac84927c7f9158434d87ae,26 Jul 2012,Consolidate external_acl_form config dumping a bit and add missing percent dumper.,25,data/crawl/squid/hunk_2084.cpp,,,data/crawl/squid/old_hunk_2084.cpp,data/crawl/squid/new_hunk_2084.cpp,5,3,"storeAppendPrintf(sentry, "" %%USER_CERT"");","DUMP_EXT_ACL_TYPE_FMT(USER_CERT_RAW, "" %%USER_CERT_RAW"");","[""updateVariable"", ""updateLog"", ""updateContent""]","[[""storeAppendPrintf"", ""sentry"", ""%%USER_CERT""], [""DUMP_EXT_ACL_TYPE_FMT"", ""USER_CERT_RAW"", ""%%USER_CERT_RAW""]]",[-765317581501053930],6002,0.0,2
https://github.com/squid-cache/squid/commit/0bf57f33e5b7001cc680e9d978a027f6264faa60,01 Aug 2012,More GCC 4.2 dependency fixes,48,data/crawl/squid/hunk_2081.cpp,,,data/crawl/squid/old_hunk_2081.cpp,data/crawl/squid/new_hunk_2081.cpp,-1,13,,"printf(""Ssl::Config::Config No implemented\n"");","[""addLog""]","[[], [""printf"", ""Ssl"", ""Config"", ""Config"", ""No"", ""implemented\\n""]]",[8982539660085370158],6001,0.0,2
https://github.com/squid-cache/squid/commit/2cef0ca6fdbc43e495f2b33be1ec0205bf173ba1,14 Sep 2012,"Initial SSL server certificate validator implementation
http://wiki.squid-cache.org/Features/SslServerCertValidator",361,data/crawl/squid/hunk_2050.cpp,,,data/crawl/squid/old_hunk_2050.cpp,data/crawl/squid/new_hunk_2050.cpp,-1,74,,"fatal(""SSL servers not responding for 3 minutes"");","[""addLog""]","[[], [""fatal"", ""SSL"", ""servers"", ""not"", ""responding"", ""for"", ""3"", ""minutes""]]",[10265288295909900330],6000,479520.0,2
https://github.com/squid-cache/squid/commit/1b32d93c7506a07285526e5b3028523c96db8c45,05 Oct 2012,"SourceFormat merge: removed CVS-Id tags, removed unnecessary extern and SQUIDCEXTERN declarations",641,data/crawl/squid/hunk_1979.cpp,,,data/crawl/squid/old_hunk_1979.cpp,data/crawl/squid/new_hunk_1979.cpp,3,3,"printf( ""#\n# Currently active values for %s:\n# %s\n"",
                ::programname, ::RCS_ID );","printf( ""#\n# Currently active values for %s:\n"",
                ::programname);","[""removeVariable"", ""updateContent""]","[[""%s\\n"", ""RCS_ID""], []]",[-13045972254499432572],5999,720.0,2
https://github.com/squid-cache/squid/commit/1b32d93c7506a07285526e5b3028523c96db8c45,05 Oct 2012,"SourceFormat merge: removed CVS-Id tags, removed unnecessary extern and SQUIDCEXTERN declarations",641,data/crawl/squid/hunk_1978.cpp,,,data/crawl/squid/old_hunk_1978.cpp,data/crawl/squid/new_hunk_1978.cpp,3,3,"printf( ""\n%s\nUsage:\t%s\t[-a] [-c cf] [-d l] [-(f|F) fn | -(e|E) re] ""
            ""[-p h[:p]]\n\t\t[-P #] [-s] [-v] [-C dir [-H]] [-n]\n\n"",
            ::RCS_ID, ::programname );","printf( ""\nUsage:\t%s\t[-a] [-c cf] [-d l] [-(f|F) fn | -(e|E) re] ""
            ""[-p h[:p]]\n\t\t[-P #] [-s] [-v] [-C dir [-H]] [-n]\n\n"",
            ::programname );","[""removeVariable"", ""updateContent""]","[[""\\n%s\\nUsage"", ""RCS_ID""], [""\\nUsage""]]",[-17886702890374580284],5998,720.0,2
https://github.com/squid-cache/squid/commit/4629f000085591c9200fb70a3e46ed2b212e6fb3,05 Oct 2012,Move fatal family of functions to own implementation and stub files.,344,data/crawl/squid/hunk_1973.cpp,,,data/crawl/squid/old_hunk_1973.cpp,data/crawl/squid/new_hunk_1973.cpp,15,-1,"fprintf(debug_log, ""Squid Cache (Version %s): Terminated abnormally.\n"",
            version_string);",,"[""removeLog""]","[[""fprintf"", ""debug_log"", ""Squid"", ""Cache"", ""Version"", ""%s"", ""Terminated"", ""abnormally"", ""\\n"", ""version_string""], []]",[12433727906166587168],5997,720.0,2
https://github.com/squid-cache/squid/commit/4629f000085591c9200fb70a3e46ed2b212e6fb3,05 Oct 2012,Move fatal family of functions to own implementation and stub files.,344,data/crawl/squid/hunk_1973.cpp,,,data/crawl/squid/old_hunk_1973.cpp,data/crawl/squid/new_hunk_1973.cpp,13,-1,"fprintf(stderr, ""FATAL: %s\n"", message);",,"[""removeLog""]","[[""fprintf"", ""stderr"", ""FATAL"", ""%s\\n"", ""message""], []]",[19574497941444277743],5996,720.0,2
https://github.com/squid-cache/squid/commit/4629f000085591c9200fb70a3e46ed2b212e6fb3,05 Oct 2012,Move fatal family of functions to own implementation and stub files.,344,data/crawl/squid/hunk_1973.cpp,,,data/crawl/squid/old_hunk_1973.cpp,data/crawl/squid/new_hunk_1973.cpp,10,-1,"fprintf(debug_log, ""FATAL: %s\n"", message);",,"[""removeLog""]","[[""fprintf"", ""debug_log"", ""FATAL"", ""%s\\n"", ""message""], []]",[11907917122135995086],5995,720.0,2
https://github.com/squid-cache/squid/commit/4629f000085591c9200fb70a3e46ed2b212e6fb3,05 Oct 2012,Move fatal family of functions to own implementation and stub files.,344,data/crawl/squid/hunk_1969.cpp,,,data/crawl/squid/old_hunk_1969.cpp,data/crawl/squid/new_hunk_1969.cpp,-1,55,,"fprintf(debug_log, ""Squid Cache (Version %s): Terminated abnormally.\n"",
            version_string);","[""addLog""]","[[], [""fprintf"", ""debug_log"", ""Squid"", ""Cache"", ""Version"", ""%s"", ""Terminated"", ""abnormally"", ""\\n"", ""version_string""]]",[-12433727906166587168],5994,720.0,2
https://github.com/squid-cache/squid/commit/4629f000085591c9200fb70a3e46ed2b212e6fb3,05 Oct 2012,Move fatal family of functions to own implementation and stub files.,344,data/crawl/squid/hunk_1969.cpp,,,data/crawl/squid/old_hunk_1969.cpp,data/crawl/squid/new_hunk_1969.cpp,-1,50,,"fprintf(debug_log, ""FATAL: %s\n"", message);","[""addLog""]","[[], [""fprintf"", ""debug_log"", ""FATAL"", ""%s\\n"", ""message""]]",[-11907917122135995086],5993,720.0,2
https://github.com/squid-cache/squid/commit/7bbefa01f63575cc8104addbbc65765c5e186e5d,07 Nov 2012,"Use Notes objects for key=pair handling in HelperReply

* NTLM/Negotiate auth are expeted to return OK/ERR/BH/TT codes and key=pair.
  The old result lines are still received, but converted to the new format
  silently.

* new key accepted:
 'token=' for passing NTLM and Negotiate auth tokens

* some undocumented old tags accepted by external_acl_type are now ignored:
 'error=' replaced by 'message='
 'passwd=' replaced by 'password='
 'login=' replaced by 'user='
These were replaced some time ago and never formally documented.",317,data/crawl/squid/hunk_1950.cpp,,,data/crawl/squid/old_hunk_1950.cpp,data/crawl/squid/new_hunk_1950.cpp,10,11,auth_user_request->denyMessage(blob);,auth_user_request->denyMessage(errNote->values[0]->value.termedBuf());,"[""removeVariable"", ""addContent"", ""addVariable""]","[[""blob""], [""errNote"", ""values[0]"", ""value"", ""termedBuf""]]",[-3977919164146439671],5992,0.0,2
https://github.com/squid-cache/squid/commit/637c35b2073582f30a4601f98b19fc5fc9c6e976,13 Nov 2012,merge from SslServerCertValidator r12332,16798,data/crawl/squid/hunk_1915.cpp,,,data/crawl/squid/old_hunk_1915.cpp,data/crawl/squid/new_hunk_1915.cpp,8,6,"fprintf(stderr, ""Usage:\n%s [-A|D UserGroup][-O DefaultDomain][-d]\n""
            ""-A can specify a Windows Local Group name allowed to authenticate\n""
            ""-D can specify a Windows Local Group name not allowed to authenticate\n""
            ""-O can specify the default Domain against to authenticate\n""
            ""-d enable debugging.\n""
            ""-h this message\n\n"",
            my_program_name);","fprintf(stderr, ""Usage:\n%s [-A|D UserGroup][-O DefaultDomain][-d]\n""
            ""-A can specify a Windows Local Group name allowed to authenticate\n""
            ""-D can specify a Windows Local Group name not allowed to authenticate\n""
            ""-O can specify the default Domain against to authenticate\n""
            ""-d enable debugging.\n""
            ""-h this message\n\n"",
            name);","[""updateVariable""]","[[""my_program_name""], [""name""]]",[-1202192614971270799],5991,0.0,2
https://github.com/squid-cache/squid/commit/62f1035b7153a9ffa5c0981cb13d7f8afcbe7419,24 Nov 2012,merge from parent,266,data/crawl/squid/hunk_1901.cpp,,,data/crawl/squid/old_hunk_1901.cpp,data/crawl/squid/new_hunk_1901.cpp,3,3,"fatal(""SSL servers not responding for 3 minutes"");","fatal(""ssl_crtvd queue being overloaded for long time"");","[""updateContent""]","[[""SSL"", ""servers"", ""not"", ""responding"", ""3"", ""minutes""], [""ssl_crtvd"", ""queue"", ""being"", ""overloaded"", ""long"", ""time""]]",[3594822499813893252],5990,0.0,2
https://github.com/squid-cache/squid/commit/fc6df0c3a619d283bcd0f755409d5f3ec9554007,04 Dec 2012,merge from parent SslServerCertValidator r12337,2116,data/crawl/squid/hunk_1821.cpp,,,data/crawl/squid/old_hunk_1821.cpp,data/crawl/squid/new_hunk_1821.cpp,-1,16,,"fprintf(stderr, ""digest_file_auth: missing user name at line %u in '%s'\n"", lineCount, passwordFile);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""digest_file_auth"", ""missing"", ""user"", ""name"", ""at"", ""line"", ""%u"", ""in"", ""%s"", ""\\n"", ""lineCount"", ""passwordFile""]]",[5708589278656383728],5989,0.0,2
https://github.com/squid-cache/squid/commit/b2d7d4beac04fd6d0ec2e5bd5ba03cb68943d6ed,16 Jan 2013,"squidpurge: display friendly errors on missing command line options

Currently the tool will crash with a segmentation fault if any one of
several command switches which are expected to have a mandatory argument
are in fact followed by nothing.
 Detect these cases and display a message about what is missing.

 Detected by Coverity Scan. Issue 740378",31,data/crawl/squid/hunk_1797.cpp,,,data/crawl/squid/old_hunk_1797.cpp,data/crawl/squid/new_hunk_1797.cpp,-1,4,,"fprintf( stderr, ""%c requires a regex pattern argument!\n"", option );","[""addLog""]","[[], [""fprintf"", ""stderr"", ""%c"", ""requires"", ""a"", ""regex"", ""pattern"", ""argument"", ""\\n"", ""option""]]",[-38554215623888027321],5988,0.0,2
https://github.com/squid-cache/squid/commit/814f9a2eab3f8f5c78c7ea654700cd7dc1bc5046,03 Feb 2013,"Fix several uninitialized object members in unit tests

 Detected by Coverity Scan. Issues 740581, 740582, 740583, 740584",30,data/crawl/squid/hunk_1785.cpp,,,data/crawl/squid/old_hunk_1785.cpp,data/crawl/squid/new_hunk_1785.cpp,3,-1,"printf(""Ssl::Config::Config No implemented\n"");",,"[""removeLog""]","[[""printf"", ""Ssl"", ""Config"", ""Config"", ""No"", ""implemented\\n""], []]",[-8982539660085370158],5987,0.0,2
https://github.com/squid-cache/squid/commit/02c8dde5cc20d7594afac26284c0119167d19721,11 Feb 2013,"SourceLayout: Shuffle and collate the log result codes symbols

This collates all the small definitions spread around Squid for defining
and handling the TCP_* and UDP_* result code tags logged by Squid.

* log_type enumeration shuffled from enums.h
* log_type increment operator shuffled from client_db
* log_type strings shuffled from Format:: and built automatically
* is-HIT lookup test shuffled from ICP

Due to LogTags.cc being automatically built from the enum list we define
the shuffled functions as inline. This is not a problem due to their small
size. When the LogTags type is converted to a class thay can be de-inlined.",251,data/crawl/squid/hunk_1780.cpp,,,data/crawl/squid/old_hunk_1780.cpp,data/crawl/squid/new_hunk_1780.cpp,3,3,"storeAppendPrintf(sentry, ""        %-20.20s %7d %3d%%\n"",Format::log_tags[l], c->Icp.result_hist[l], Math::intPercent(c->Icp.result_hist[l], c->Icp.n_requests));","storeAppendPrintf(sentry, ""        %-20.20s %7d %3d%%\n"",LogTags_str[l], c->Icp.result_hist[l], Math::intPercent(c->Icp.result_hist[l], c->Icp.n_requests));","[""updateVariable"", ""removeVariable""]","[[""Format"", ""log_tags[l]""], [""LogTags_str[l]""]]",[-8841229894577852715],5986,0.0,2
https://github.com/squid-cache/squid/commit/fb0c2f1700b650d40c64d77f2bd17e29809216e5,11 May 2013,"Bug 3389: Auto-reconnect for tcp access_log.

Major changes:

1. Squid reconnects to TCP logger as needed. Squid keeps trying to connect
forever, using a hard-coded 0.5 second delay between attempts.

2. Squid buffers log records while there is no connectivity. The buffering
limit is configurable.

3. On buffer overflows, Squid worker either dies or starts dropping log
records. The choice is configurable.

4. The tcp logging module honors buffered_logs setting. Old code was flushing
each record.

5. Squid reports changes in logging state to cache.log. Except for every 100th
consecutive connection failures, routine connection retries are not reported
at level 1, to reduce noise level.

6. A new access_log configuration format/style has been added. It allows us to
easily add named options such as buffer-size or on-error. The same format can
be used to add module-specific options in the future, but doing so would
require changes to the high-level logging code. All old configuration
formats/styles are still supported.

7. squid.conf buffered_log option documentation now reflects reality. It used
to talk about cache.log but I do not think Squid uses that option for
cache.log maintenance.


Known minor side-effects of these changes:

i) All access_log logs can now be configured to bypass errors because the old
""fatal"" flag is now configurable via log-specific on-error option in
squid.conf. The default is still ""die"". I have not checked whether modules
other than TCP logger honor that flag.

ii) All access_log logs now use 8*MAX_URL (64KB) instead of a 4*MAX_URL (32KB)
or smaller buffer size by default. The ICAP logger was using 2*MAX_URL buffer
size. The TCP logger was using 64KB buffer size before so no change for TCP. I
decided that it is better to raise the default buffering level for some logs
rather than decrease it for other logs, but it is not clear what the best
default is. The buffer size is now configurable via buffer-size so admins can
control it on individual log basis.

iii) Some access_log configuration styles overlap. To resolve ambiguities,
Squid may need to assume that the first logging ACL name (if any) does not
contain '=' and is not equal to an existing logformat name. It is possible to
use 'all' as the first ACL name if these heuristics cause problems.


TODO: We have attempted to solve more TCP logging problems, but it turns out
that correct solutions would require fixing higher-level logging code, not
specific to TCP logger or Bug 3389 scope. Those unsolved problems include:

A. During reconfiguration, all logs are closed and reopened, even if there
have been no changes to their configuration that necessitate such a drastic
action (or no changes at all!). For TCP logger, this means that the old
connection is used to flush remaining buffered records (if any), and the new
connection is used to log new records, possibly at the same time. Nathan wrote
clever code that keeps logging going using the same job/connection. However,
we had to yank that code out because it clashed with higher-level logging
state in subtle ways.

B. During shutdown, all connections are put in the closing state before logs
are told to flush remaining records. For TCP logger, this means that the
remaining buffered records (if any) are lost. The correct fix may require
rearranging shutdown sequence AND letting EventLoop run during shutdown (among
other things).

C. When logger connectivity is lost, Squid does not notice the problem until
the second TCP socket write (or later). This results in lost records. This is
due to TCP-level buffering. I suspect the only cure for this is adding
logger-to-Squid ""I got your records"" feedback, which requires changes in the
logging protocol (currently there is no logger-to-Squid communication at all).",1037,data/crawl/squid/hunk_1756.cpp,,,data/crawl/squid/old_hunk_1756.cpp,data/crawl/squid/new_hunk_1756.cpp,-1,450,,"fatalf(""Invalid TCP logging address '%s'\n"", lf->path);","[""addLog""]","[[], [""fatalf"", ""Invalid"", ""TCP"", ""logging"", ""address"", ""%s"", ""\\n"", ""lf"", ""path""]]",[-15998919467314472544],5985,804960.0,2
https://github.com/squid-cache/squid/commit/fb0c2f1700b650d40c64d77f2bd17e29809216e5,11 May 2013,"Bug 3389: Auto-reconnect for tcp access_log.

Major changes:

1. Squid reconnects to TCP logger as needed. Squid keeps trying to connect
forever, using a hard-coded 0.5 second delay between attempts.

2. Squid buffers log records while there is no connectivity. The buffering
limit is configurable.

3. On buffer overflows, Squid worker either dies or starts dropping log
records. The choice is configurable.

4. The tcp logging module honors buffered_logs setting. Old code was flushing
each record.

5. Squid reports changes in logging state to cache.log. Except for every 100th
consecutive connection failures, routine connection retries are not reported
at level 1, to reduce noise level.

6. A new access_log configuration format/style has been added. It allows us to
easily add named options such as buffer-size or on-error. The same format can
be used to add module-specific options in the future, but doing so would
require changes to the high-level logging code. All old configuration
formats/styles are still supported.

7. squid.conf buffered_log option documentation now reflects reality. It used
to talk about cache.log but I do not think Squid uses that option for
cache.log maintenance.


Known minor side-effects of these changes:

i) All access_log logs can now be configured to bypass errors because the old
""fatal"" flag is now configurable via log-specific on-error option in
squid.conf. The default is still ""die"". I have not checked whether modules
other than TCP logger honor that flag.

ii) All access_log logs now use 8*MAX_URL (64KB) instead of a 4*MAX_URL (32KB)
or smaller buffer size by default. The ICAP logger was using 2*MAX_URL buffer
size. The TCP logger was using 64KB buffer size before so no change for TCP. I
decided that it is better to raise the default buffering level for some logs
rather than decrease it for other logs, but it is not clear what the best
default is. The buffer size is now configurable via buffer-size so admins can
control it on individual log basis.

iii) Some access_log configuration styles overlap. To resolve ambiguities,
Squid may need to assume that the first logging ACL name (if any) does not
contain '=' and is not equal to an existing logformat name. It is possible to
use 'all' as the first ACL name if these heuristics cause problems.


TODO: We have attempted to solve more TCP logging problems, but it turns out
that correct solutions would require fixing higher-level logging code, not
specific to TCP logger or Bug 3389 scope. Those unsolved problems include:

A. During reconfiguration, all logs are closed and reopened, even if there
have been no changes to their configuration that necessitate such a drastic
action (or no changes at all!). For TCP logger, this means that the old
connection is used to flush remaining buffered records (if any), and the new
connection is used to log new records, possibly at the same time. Nathan wrote
clever code that keeps logging going using the same job/connection. However,
we had to yank that code out because it clashed with higher-level logging
state in subtle ways.

B. During shutdown, all connections are put in the closing state before logs
are told to flush remaining records. For TCP logger, this means that the
remaining buffered records (if any) are lost. The correct fix may require
rearranging shutdown sequence AND letting EventLoop run during shutdown (among
other things).

C. When logger connectivity is lost, Squid does not notice the problem until
the second TCP socket write (or later). This results in lost records. This is
due to TCP-level buffering. I suspect the only cure for this is adding
logger-to-Squid ""I got your records"" feedback, which requires changes in the
logging protocol (currently there is no logger-to-Squid communication at all).",1037,data/crawl/squid/hunk_1755.cpp,,,data/crawl/squid/old_hunk_1755.cpp,data/crawl/squid/new_hunk_1755.cpp,219,-1,"fatalf(""Cannot open '%s' for writing.\n""
                   ""\tThe parent directory must be writeable by the\n""
                   ""\tuser '%s', which is the cache_effective_user\n""
                   ""\tset in squid.conf."", path, Config.effectiveUser);",,"[""removeLog""]","[[""fatalf"", ""Cannot"", ""open"", ""%s"", ""for"", ""writing"", ""\\n"", ""\\tThe"", ""parent"", ""directory"", ""must"", ""be"", ""writeable"", ""by"", ""the\\n"", ""\\tuser"", ""%s"", ""which"", ""is"", ""the"", ""cache_effective_user\\n"", ""\\tset"", ""in"", ""squid"", ""conf"", ""path"", ""Config"", ""effectiveUser""], []]",[-3071125531774423807],5984,911520.0,2
https://github.com/squid-cache/squid/commit/fb0c2f1700b650d40c64d77f2bd17e29809216e5,11 May 2013,"Bug 3389: Auto-reconnect for tcp access_log.

Major changes:

1. Squid reconnects to TCP logger as needed. Squid keeps trying to connect
forever, using a hard-coded 0.5 second delay between attempts.

2. Squid buffers log records while there is no connectivity. The buffering
limit is configurable.

3. On buffer overflows, Squid worker either dies or starts dropping log
records. The choice is configurable.

4. The tcp logging module honors buffered_logs setting. Old code was flushing
each record.

5. Squid reports changes in logging state to cache.log. Except for every 100th
consecutive connection failures, routine connection retries are not reported
at level 1, to reduce noise level.

6. A new access_log configuration format/style has been added. It allows us to
easily add named options such as buffer-size or on-error. The same format can
be used to add module-specific options in the future, but doing so would
require changes to the high-level logging code. All old configuration
formats/styles are still supported.

7. squid.conf buffered_log option documentation now reflects reality. It used
to talk about cache.log but I do not think Squid uses that option for
cache.log maintenance.


Known minor side-effects of these changes:

i) All access_log logs can now be configured to bypass errors because the old
""fatal"" flag is now configurable via log-specific on-error option in
squid.conf. The default is still ""die"". I have not checked whether modules
other than TCP logger honor that flag.

ii) All access_log logs now use 8*MAX_URL (64KB) instead of a 4*MAX_URL (32KB)
or smaller buffer size by default. The ICAP logger was using 2*MAX_URL buffer
size. The TCP logger was using 64KB buffer size before so no change for TCP. I
decided that it is better to raise the default buffering level for some logs
rather than decrease it for other logs, but it is not clear what the best
default is. The buffer size is now configurable via buffer-size so admins can
control it on individual log basis.

iii) Some access_log configuration styles overlap. To resolve ambiguities,
Squid may need to assume that the first logging ACL name (if any) does not
contain '=' and is not equal to an existing logformat name. It is possible to
use 'all' as the first ACL name if these heuristics cause problems.


TODO: We have attempted to solve more TCP logging problems, but it turns out
that correct solutions would require fixing higher-level logging code, not
specific to TCP logger or Bug 3389 scope. Those unsolved problems include:

A. During reconfiguration, all logs are closed and reopened, even if there
have been no changes to their configuration that necessitate such a drastic
action (or no changes at all!). For TCP logger, this means that the old
connection is used to flush remaining buffered records (if any), and the new
connection is used to log new records, possibly at the same time. Nathan wrote
clever code that keeps logging going using the same job/connection. However,
we had to yank that code out because it clashed with higher-level logging
state in subtle ways.

B. During shutdown, all connections are put in the closing state before logs
are told to flush remaining records. For TCP logger, this means that the
remaining buffered records (if any) are lost. The correct fix may require
rearranging shutdown sequence AND letting EventLoop run during shutdown (among
other things).

C. When logger connectivity is lost, Squid does not notice the problem until
the second TCP socket write (or later). This results in lost records. This is
due to TCP-level buffering. I suspect the only cure for this is adding
logger-to-Squid ""I got your records"" feedback, which requires changes in the
logging protocol (currently there is no logger-to-Squid communication at all).",1037,data/crawl/squid/hunk_1755.cpp,,,data/crawl/squid/old_hunk_1755.cpp,data/crawl/squid/new_hunk_1755.cpp,215,-1,"fatalf(""Cannot open '%s' because\n""
                   ""\tthe parent directory does not exist.\n""
                   ""\tPlease create the directory.\n"", path);",,"[""removeLog""]","[[""fatalf"", ""Cannot"", ""open"", ""%s"", ""because\\n"", ""\\tthe"", ""parent"", ""directory"", ""does"", ""not"", ""exist"", ""\\n"", ""\\tPlease"", ""create"", ""the"", ""directory"", ""\\n"", ""path""], []]",[-1166021827210040158],5983,911520.0,2
https://github.com/squid-cache/squid/commit/61017a886b4884845571007b5745664e3d346ebc,28 May 2013,"Improve ACL handling. Support all-of and any-of ACL types.

This commit encapsulated many significant ACL changes, including:

* Expressiveness: Two new boolean ACLs (all-of and any-of) that allow
admins to group ACLs as needed, to express complex conditions more
naturally, with fewer squid.conf lines. Conditions such as ""(a or b) and
(c or d)"" are easily expressed now. Explicit groups of ACLs of different
types can now be configured, named, and used in any ACL expression.

* Correctness and performance: When a slow ACL (that has suspended
checks to wait for an async lookup) is ready to resume checking, Squid
resumes checking from that ACL, instead of rechecking all ACLs for the
same action (or the same squid.conf directive) again.

* Internals: Store ACL-related configurations as an expression tree,
streamlining the code and clearing the way for future math-style/natural
ACL conditions support. The usual boolean operators (and, or, and not)
form intermediate nodes while good old configurable ACLs become tree
leaves. The new all-of and any-of ACLs use the boolean operators (and
also become intermediate nodes, of course).",1943,data/crawl/squid/hunk_1747.cpp,,,data/crawl/squid/old_hunk_1747.cpp,data/crawl/squid/new_hunk_1747.cpp,18,22,"storeAppendPrintf(entry, ""\n"");",wordlistDestroy(&lines);,"[""updateVariable"", ""updateLog"", ""removeContent"", ""addVariable""]","[[""storeAppendPrintf"", ""entry"", ""\\n""], [""wordlistDestroy"", ""&lines""]]",[-3381203888913771330],5982,10800.0,2
https://github.com/squid-cache/squid/commit/61017a886b4884845571007b5745664e3d346ebc,28 May 2013,"Improve ACL handling. Support all-of and any-of ACL types.

This commit encapsulated many significant ACL changes, including:

* Expressiveness: Two new boolean ACLs (all-of and any-of) that allow
admins to group ACLs as needed, to express complex conditions more
naturally, with fewer squid.conf lines. Conditions such as ""(a or b) and
(c or d)"" are easily expressed now. Explicit groups of ACLs of different
types can now be configured, named, and used in any ACL expression.

* Correctness and performance: When a slow ACL (that has suspended
checks to wait for an async lookup) is ready to resume checking, Squid
resumes checking from that ACL, instead of rechecking all ACLs for the
same action (or the same squid.conf directive) again.

* Internals: Store ACL-related configurations as an expression tree,
streamlining the code and clearing the way for future math-style/natural
ACL conditions support. The usual boolean operators (and, or, and not)
form intermediate nodes while good old configurable ACLs become tree
leaves. The new all-of and any-of ACLs use the boolean operators (and
also become intermediate nodes, of course).",1943,data/crawl/squid/hunk_1747.cpp,,,data/crawl/squid/old_hunk_1747.cpp,data/crawl/squid/new_hunk_1747.cpp,15,-1,"storeAppendPrintf(entry, ""%s "", Ssl::bumpMode(sb->allow.kind));",,"[""removeLog""]","[[""storeAppendPrintf"", ""entry"", ""%s"", ""Ssl"", ""bumpMode"", ""sb"", ""allow"", ""kind""], []]",[-13922051435011257693],5981,10800.0,2
https://github.com/squid-cache/squid/commit/61017a886b4884845571007b5745664e3d346ebc,28 May 2013,"Improve ACL handling. Support all-of and any-of ACL types.

This commit encapsulated many significant ACL changes, including:

* Expressiveness: Two new boolean ACLs (all-of and any-of) that allow
admins to group ACLs as needed, to express complex conditions more
naturally, with fewer squid.conf lines. Conditions such as ""(a or b) and
(c or d)"" are easily expressed now. Explicit groups of ACLs of different
types can now be configured, named, and used in any ACL expression.

* Correctness and performance: When a slow ACL (that has suspended
checks to wait for an async lookup) is ready to resume checking, Squid
resumes checking from that ACL, instead of rechecking all ACLs for the
same action (or the same squid.conf directive) again.

* Internals: Store ACL-related configurations as an expression tree,
streamlining the code and clearing the way for future math-style/natural
ACL conditions support. The usual boolean operators (and, or, and not)
form intermediate nodes while good old configurable ACLs become tree
leaves. The new all-of and any-of ACLs use the boolean operators (and
also become intermediate nodes, of course).",1943,data/crawl/squid/hunk_1746.cpp,,,data/crawl/squid/old_hunk_1746.cpp,data/crawl/squid/new_hunk_1746.cpp,22,19,"storeAppendPrintf(entry, ""\n"");","aclParseAccessLine(cfg_directive, LegacyParser, head);","[""updateVariable"", ""updateLog"", ""removeContent"", ""addVariable""]","[[""storeAppendPrintf"", ""entry"", ""\\n""], [""aclParseAccessLine"", ""cfg_directive"", ""LegacyParser"", ""head""]]",[3474875733453744446],5980,10800.0,2
https://github.com/squid-cache/squid/commit/61017a886b4884845571007b5745664e3d346ebc,28 May 2013,"Improve ACL handling. Support all-of and any-of ACL types.

This commit encapsulated many significant ACL changes, including:

* Expressiveness: Two new boolean ACLs (all-of and any-of) that allow
admins to group ACLs as needed, to express complex conditions more
naturally, with fewer squid.conf lines. Conditions such as ""(a or b) and
(c or d)"" are easily expressed now. Explicit groups of ACLs of different
types can now be configured, named, and used in any ACL expression.

* Correctness and performance: When a slow ACL (that has suspended
checks to wait for an async lookup) is ready to resume checking, Squid
resumes checking from that ACL, instead of rechecking all ACLs for the
same action (or the same squid.conf directive) again.

* Internals: Store ACL-related configurations as an expression tree,
streamlining the code and clearing the way for future math-style/natural
ACL conditions support. The usual boolean operators (and, or, and not)
form intermediate nodes while good old configurable ACLs become tree
leaves. The new all-of and any-of ACLs use the boolean operators (and
also become intermediate nodes, of course).",1943,data/crawl/squid/hunk_1746.cpp,,,data/crawl/squid/old_hunk_1746.cpp,data/crawl/squid/new_hunk_1746.cpp,18,12,"storeAppendPrintf(entry, ""%s %s"",
                          name,
                          l->allow ? ""Allow"" : ""Deny"");","dump_wordlist(entry, lines);","[""updateLog"", ""removeVariable"", ""removeContent"", ""addVariable""]","[[""storeAppendPrintf"", ""%s"", ""%s"", ""name"", ""l"", ""allow"", ""Allow"", ""Deny""], [""dump_wordlist"", ""lines""]]",[7782690655297505449],5979,10800.0,2
https://github.com/squid-cache/squid/commit/61017a886b4884845571007b5745664e3d346ebc,28 May 2013,"Improve ACL handling. Support all-of and any-of ACL types.

This commit encapsulated many significant ACL changes, including:

* Expressiveness: Two new boolean ACLs (all-of and any-of) that allow
admins to group ACLs as needed, to express complex conditions more
naturally, with fewer squid.conf lines. Conditions such as ""(a or b) and
(c or d)"" are easily expressed now. Explicit groups of ACLs of different
types can now be configured, named, and used in any ACL expression.

* Correctness and performance: When a slow ACL (that has suspended
checks to wait for an async lookup) is ready to resume checking, Squid
resumes checking from that ACL, instead of rechecking all ACLs for the
same action (or the same squid.conf directive) again.

* Internals: Store ACL-related configurations as an expression tree,
streamlining the code and clearing the way for future math-style/natural
ACL conditions support. The usual boolean operators (and, or, and not)
form intermediate nodes while good old configurable ACLs become tree
leaves. The new all-of and any-of ACLs use the boolean operators (and
also become intermediate nodes, of course).",1943,data/crawl/squid/hunk_1746.cpp,,,data/crawl/squid/old_hunk_1746.cpp,data/crawl/squid/new_hunk_1746.cpp,6,5,"storeAppendPrintf(entry, "" %s%s"",
                          l->op ? null_string : ""!"",
                          l->_acl->name);",wordlistDestroy(&values);,"[""updateLog"", ""removeVariable"", ""removeContent"", ""addVariable""]","[[""storeAppendPrintf"", ""entry"", ""%s%s"", ""l"", ""op"", ""null_string"", ""l"", ""_acl"", ""name""], [""wordlistDestroy"", ""&values""]]",[-18998403630877164485],5978,10800.0,2
https://github.com/squid-cache/squid/commit/61017a886b4884845571007b5745664e3d346ebc,28 May 2013,"Improve ACL handling. Support all-of and any-of ACL types.

This commit encapsulated many significant ACL changes, including:

* Expressiveness: Two new boolean ACLs (all-of and any-of) that allow
admins to group ACLs as needed, to express complex conditions more
naturally, with fewer squid.conf lines. Conditions such as ""(a or b) and
(c or d)"" are easily expressed now. Explicit groups of ACLs of different
types can now be configured, named, and used in any ACL expression.

* Correctness and performance: When a slow ACL (that has suspended
checks to wait for an async lookup) is ready to resume checking, Squid
resumes checking from that ACL, instead of rechecking all ACLs for the
same action (or the same squid.conf directive) again.

* Internals: Store ACL-related configurations as an expression tree,
streamlining the code and clearing the way for future math-style/natural
ACL conditions support. The usual boolean operators (and, or, and not)
form intermediate nodes while good old configurable ACLs become tree
leaves. The new all-of and any-of ACLs use the boolean operators (and
also become intermediate nodes, of course).",1943,data/crawl/squid/hunk_1745.cpp,,,data/crawl/squid/old_hunk_1745.cpp,data/crawl/squid/new_hunk_1745.cpp,19,6,"storeAppendPrintf(entry, ""%s "", v->key);","storeAppendPrintf(entry, ""%s "", word->key);","[""updateVariable""]","[[""v""], [""word""]]",[-3668921474724384787],5977,10800.0,2
https://github.com/squid-cache/squid/commit/61017a886b4884845571007b5745664e3d346ebc,28 May 2013,"Improve ACL handling. Support all-of and any-of ACL types.

This commit encapsulated many significant ACL changes, including:

* Expressiveness: Two new boolean ACLs (all-of and any-of) that allow
admins to group ACLs as needed, to express complex conditions more
naturally, with fewer squid.conf lines. Conditions such as ""(a or b) and
(c or d)"" are easily expressed now. Explicit groups of ACLs of different
types can now be configured, named, and used in any ACL expression.

* Correctness and performance: When a slow ACL (that has suspended
checks to wait for an async lookup) is ready to resume checking, Squid
resumes checking from that ACL, instead of rechecking all ACLs for the
same action (or the same squid.conf directive) again.

* Internals: Store ACL-related configurations as an expression tree,
streamlining the code and clearing the way for future math-style/natural
ACL conditions support. The usual boolean operators (and, or, and not)
form intermediate nodes while good old configurable ACLs become tree
leaves. The new all-of and any-of ACLs use the boolean operators (and
also become intermediate nodes, of course).",1943,data/crawl/squid/hunk_1744.cpp,,,data/crawl/squid/old_hunk_1744.cpp,data/crawl/squid/new_hunk_1744.cpp,-1,73,,"ctxTree.Printf(""%s %s"", cfg_directive, label);","[""addLog""]","[[], [""ctxTree"", ""Printf"", ""%s"", ""%s"", ""cfg_directive"", ""label""]]",[78828581701807399],5976,10800.0,2
https://github.com/squid-cache/squid/commit/61017a886b4884845571007b5745664e3d346ebc,28 May 2013,"Improve ACL handling. Support all-of and any-of ACL types.

This commit encapsulated many significant ACL changes, including:

* Expressiveness: Two new boolean ACLs (all-of and any-of) that allow
admins to group ACLs as needed, to express complex conditions more
naturally, with fewer squid.conf lines. Conditions such as ""(a or b) and
(c or d)"" are easily expressed now. Explicit groups of ACLs of different
types can now be configured, named, and used in any ACL expression.

* Correctness and performance: When a slow ACL (that has suspended
checks to wait for an async lookup) is ready to resume checking, Squid
resumes checking from that ACL, instead of rechecking all ACLs for the
same action (or the same squid.conf directive) again.

* Internals: Store ACL-related configurations as an expression tree,
streamlining the code and clearing the way for future math-style/natural
ACL conditions support. The usual boolean operators (and, or, and not)
form intermediate nodes while good old configurable ACLs become tree
leaves. The new all-of and any-of ACLs use the boolean operators (and
also become intermediate nodes, of course).",1943,data/crawl/squid/hunk_1744.cpp,,,data/crawl/squid/old_hunk_1744.cpp,data/crawl/squid/new_hunk_1744.cpp,-1,64,,"ctxLine.Printf(""(%s %s line)"", cfg_directive, label);","[""addLog""]","[[], [""ctxLine"", ""Printf"", ""%s"", ""%s"", ""line"", ""cfg_directive"", ""label""]]",[496266979652663115],5975,10800.0,2
https://github.com/squid-cache/squid/commit/61017a886b4884845571007b5745664e3d346ebc,28 May 2013,"Improve ACL handling. Support all-of and any-of ACL types.

This commit encapsulated many significant ACL changes, including:

* Expressiveness: Two new boolean ACLs (all-of and any-of) that allow
admins to group ACLs as needed, to express complex conditions more
naturally, with fewer squid.conf lines. Conditions such as ""(a or b) and
(c or d)"" are easily expressed now. Explicit groups of ACLs of different
types can now be configured, named, and used in any ACL expression.

* Correctness and performance: When a slow ACL (that has suspended
checks to wait for an async lookup) is ready to resume checking, Squid
resumes checking from that ACL, instead of rechecking all ACLs for the
same action (or the same squid.conf directive) again.

* Internals: Store ACL-related configurations as an expression tree,
streamlining the code and clearing the way for future math-style/natural
ACL conditions support. The usual boolean operators (and, or, and not)
form intermediate nodes while good old configurable ACLs become tree
leaves. The new all-of and any-of ACLs use the boolean operators (and
also become intermediate nodes, of course).",1943,data/crawl/squid/hunk_1744.cpp,,,data/crawl/squid/old_hunk_1744.cpp,data/crawl/squid/new_hunk_1744.cpp,-1,28,,"ctxBuf.Printf(""%s#%d"", directive, ruleId);","[""addLog""]","[[], [""ctxBuf"", ""Printf"", ""%s"", ""%d"", ""directive"", ""ruleId""]]",[265076709881841043],5974,10800.0,2
https://github.com/squid-cache/squid/commit/61017a886b4884845571007b5745664e3d346ebc,28 May 2013,"Improve ACL handling. Support all-of and any-of ACL types.

This commit encapsulated many significant ACL changes, including:

* Expressiveness: Two new boolean ACLs (all-of and any-of) that allow
admins to group ACLs as needed, to express complex conditions more
naturally, with fewer squid.conf lines. Conditions such as ""(a or b) and
(c or d)"" are easily expressed now. Explicit groups of ACLs of different
types can now be configured, named, and used in any ACL expression.

* Correctness and performance: When a slow ACL (that has suspended
checks to wait for an async lookup) is ready to resume checking, Squid
resumes checking from that ACL, instead of rechecking all ACLs for the
same action (or the same squid.conf directive) again.

* Internals: Store ACL-related configurations as an expression tree,
streamlining the code and clearing the way for future math-style/natural
ACL conditions support. The usual boolean operators (and, or, and not)
form intermediate nodes while good old configurable ACLs become tree
leaves. The new all-of and any-of ACLs use the boolean operators (and
also become intermediate nodes, of course).",1943,data/crawl/squid/hunk_1742.cpp,,,data/crawl/squid/old_hunk_1742.cpp,data/crawl/squid/new_hunk_1742.cpp,-1,73,,"lineCtx.Printf(""(%s line #%d)"", name, lineId);","[""addLog""]","[[], [""lineCtx"", ""Printf"", ""%s"", ""line"", ""%d"", ""name"", ""lineId""]]",[-2156007022240409318],5973,10800.0,2
https://github.com/squid-cache/squid/commit/61017a886b4884845571007b5745664e3d346ebc,28 May 2013,"Improve ACL handling. Support all-of and any-of ACL types.

This commit encapsulated many significant ACL changes, including:

* Expressiveness: Two new boolean ACLs (all-of and any-of) that allow
admins to group ACLs as needed, to express complex conditions more
naturally, with fewer squid.conf lines. Conditions such as ""(a or b) and
(c or d)"" are easily expressed now. Explicit groups of ACLs of different
types can now be configured, named, and used in any ACL expression.

* Correctness and performance: When a slow ACL (that has suspended
checks to wait for an async lookup) is ready to resume checking, Squid
resumes checking from that ACL, instead of rechecking all ACLs for the
same action (or the same squid.conf directive) again.

* Internals: Store ACL-related configurations as an expression tree,
streamlining the code and clearing the way for future math-style/natural
ACL conditions support. The usual boolean operators (and, or, and not)
form intermediate nodes while good old configurable ACLs become tree
leaves. The new all-of and any-of ACLs use the boolean operators (and
also become intermediate nodes, of course).",1943,data/crawl/squid/hunk_1742.cpp,,,data/crawl/squid/old_hunk_1742.cpp,data/crawl/squid/new_hunk_1742.cpp,-1,56,,"wholeCtx.Printf(""(%s lines)"", name);","[""addLog""]","[[], [""wholeCtx"", ""Printf"", ""%s"", ""lines"", ""name""]]",[7606425805528478266],5972,10800.0,2
https://github.com/squid-cache/squid/commit/133906f560762d68bc2c8eb677584dcd4ccae8f2,04 Jun 2013,"Bug 2066: squid does not do chdir() after chroot()

The earlier workaround applied only fixed 1 of the 3 places performing
chroot().
 This makes chroot and chdir integral parts of setting up Squids running
directory and alters teh chroot() calls to be mainSetCwnd() calls. Which
fixes several potential problems with core dumps from squid -z or -k
executions ending up in unexpected locations, regardless of whether
chroot() and coredump_dir are configured.

 Detected by Coverity Scan. Issue 740335.",44,data/crawl/squid/hunk_1703.cpp,,,data/crawl/squid/old_hunk_1703.cpp,data/crawl/squid/new_hunk_1703.cpp,5,3,"fatal(""failed to chroot"");",mainSetCwd();,"[""updateLog"", ""removeContent""]","[[""fatal"", ""failed"", ""to"", ""chroot""], [""mainSetCwd""]]",[14299995205023066435],5971,0.0,2
https://github.com/squid-cache/squid/commit/bce61b006f1ea12de90966ae6b7ff88372d905cf,01 Aug 2013,"Add dns_multicast_local to control mDNS operation

Enable admin control over whether mDNS operates or not. Set the default
to OFF due to .arpa reverse-DNS requests causing a rise in traffic from
this feature even on networks without mDNS responders setup.

Also, polish cachemgr idns report to show for queued queries which
resolver type and query the entry is involving. mDNS can cause a queue
to exist as some lookups timeout on the mDNS resolvers.",52,data/crawl/squid/hunk_1693.cpp,,,data/crawl/squid/old_hunk_1693.cpp,data/crawl/squid/new_hunk_1693.cpp,15,17,"storeAppendPrintf(sentry, ""DNS jumbo-grams: %zd Bytes\n"", Config.dns.packet_max);","storeAppendPrintf(sentry, ""\nDNS jumbo-grams: %zd Bytes\n"", Config.dns.packet_max);","[""updateContent""]","[[""DNS""], [""\\nDNS""]]",[1698993661374556400],5970,0.0,2
https://github.com/squid-cache/squid/commit/73656056cdcface25c015c755e9a3688acd404fc,30 Sep 2013,"Remove COSS

This storage type has been superceded by Rock storage since 3.2.",3034,data/crawl/squid/hunk_1683.cpp,,,data/crawl/squid/old_hunk_1683.cpp,data/crawl/squid/new_hunk_1683.cpp,1014,-1,"fatal(""COSS requires max-size to be set to something other than -1!\n"");",,"[""removeLog""]","[[""fatal"", ""COSS"", ""requires"", ""max"", ""size"", ""to"", ""be"", ""set"", ""to"", ""something"", ""other"", ""than"", ""1"", ""\\n""], []]",[-6478755802956658214],5969,0.0,2
https://github.com/squid-cache/squid/commit/73656056cdcface25c015c755e9a3688acd404fc,30 Sep 2013,"Remove COSS

This storage type has been superceded by Rock storage since 3.2.",3034,data/crawl/squid/hunk_1683.cpp,,,data/crawl/squid/old_hunk_1683.cpp,data/crawl/squid/new_hunk_1683.cpp,999,-1,"fatal(""storeCossDirParse: invalid size value"");",,"[""removeLog""]","[[""fatal"", ""storeCossDirParse"", ""invalid"", ""size"", ""value""], []]",[27578349261546309526],5968,0.0,2
https://github.com/squid-cache/squid/commit/73656056cdcface25c015c755e9a3688acd404fc,30 Sep 2013,"Remove COSS

This storage type has been superceded by Rock storage since 3.2.",3034,data/crawl/squid/hunk_1683.cpp,,,data/crawl/squid/old_hunk_1683.cpp,data/crawl/squid/new_hunk_1683.cpp,969,-1,"storeAppendPrintf(&sentry, ""\n"");",,"[""removeLog""]","[[""storeAppendPrintf"", ""&sentry"", ""\\n""], []]",[-9350268740893478495],5967,0.0,2
https://github.com/squid-cache/squid/commit/17852883df926d74fb04fe5d2bbfa281090574a8,01 Oct 2013,"Remove dnsserver and external DNS helper API

The external DNS helper API places limits on Squid DNS lookups per second
low enough to noticably affect the HTTP requests per second which can be
served.

Request for comments about proposed removal 2 years ago produced feedback
stating that the helper was needed for local name resolution. This is
now available since 3.4 mDNS extensions.

A more recent request for reasons for keeping the helper API have
produced only two responses over the period of several months. Both
indicating that the API is no longer necessary for the business cases of
a year or so ago.

As such and because the helper fails to operate sufficiently on several
major operating systems and the API is difficult to maintain it is being
removed as of Squid-3.5.",1269,data/crawl/squid/hunk_1681.cpp,,,data/crawl/squid/old_hunk_1681.cpp,data/crawl/squid/new_hunk_1681.cpp,419,-1,"fprintf(stderr, ""Too many -s options, only %d are allowed\n"", MAXNS);",,"[""removeLog""]","[[""fprintf"", ""stderr"", ""Too"", ""many"", ""s"", ""options"", ""only"", ""%d"", ""are"", ""allowed\\n"", ""MAXNS""], []]",[11357842607344951248],5966,0.0,2
https://github.com/squid-cache/squid/commit/17852883df926d74fb04fe5d2bbfa281090574a8,01 Oct 2013,"Remove dnsserver and external DNS helper API

The external DNS helper API places limits on Squid DNS lookups per second
low enough to noticably affect the HTTP requests per second which can be
served.

Request for comments about proposed removal 2 years ago produced feedback
stating that the helper was needed for local name resolution. This is
now available since 3.4 mDNS extensions.

A more recent request for reasons for keeping the helper API have
produced only two responses over the period of several months. Both
indicating that the API is no longer necessary for the business cases of
a year or so ago.

As such and because the helper fails to operate sufficiently on several
major operating systems and the API is difficult to maintain it is being
removed as of Squid-3.5.",1269,data/crawl/squid/hunk_1681.cpp,,,data/crawl/squid/old_hunk_1681.cpp,data/crawl/squid/new_hunk_1681.cpp,185,-1,"printf(""$alive\n"");",,"[""removeLog""]","[[""printf"", ""alive\\n""], []]",[-8819062403088672437],5965,4075200.0,2
https://github.com/squid-cache/squid/commit/77f6d1d2986563d71ab09a413bdca3a61dc81422,18 Oct 2013,"Append ""Connection: close"" to OPTIONS requests when icap_persistent_connections
is off.

This brings OPTIONS requests behavior inline with REQMOD and RESPMOD.",4,data/crawl/squid/hunk_1677.cpp,,,data/crawl/squid/old_hunk_1677.cpp,data/crawl/squid/new_hunk_1677.cpp,-1,5,,"buf.Printf(""Connection: close\r\n"");","[""addLog""]","[[], [""buf"", ""Printf"", ""Connection"", ""close\\r\\n""]]",[8698708085008139558],5964,2071440.0,2
https://github.com/squid-cache/squid/commit/fa2301d26b90cbd1298eb7740e8827c7746cd9d2,01 Jan 2014,"Initial Large Rock and Collapsed Forwarding support.

Large Rock: Support disk (and shared memory) caching of responses exceeding
one db slot (or one shared memory page) in size. A single db slot/page size is
still limited to 32KB (smaller values can be configured for disk caches using
the newly added cache_dir slot-size option). Removal of old rock cache dir
(followed by squid-z) is required -- the on-disk db structure has changed.

Collapsed Forwarding: Optionally merge concurrent cachable requests for the
same URI earlier: After the request headers have been parsed (as before), but
now _before_ the response headers have been received. Merging of requests
received by different SMP workers is supported. Controlled by the new
collapsed_forwarding directive in squid.conf. Disabled by default because all
but one of the merged requests have to be delayed (until the response headers
are received) for the merging to work, which may be worse than forwarding all
concurrent requests immediately. The overall feature idea and request
eligibility conditions are based on Collapsed Forwarding in Squid2.


Summary of other important changes (merged branch log contains the details):

* Tightened StoreEntry locking. Split StoreEntry::lock() into ""just lock"" and
  ""update entry reference time"" interfaces, addressing an old XXX.  Improved
  entry lock/unlock debugging. Needs more work.

* Adjusted StoreIOState::write() API to allow callers detect write errors.

* Simplified MemObject::write() API to remove an essentially unused callback.

* Mark client streams that sent everything as STREAM_COMPLETE. The old code
  used STREAM_UNPLANNED_COMPLETE if the completed stream was associated with a
  non-persistent connection, which did not make sense to me and, IIRC, led to
  store entry aborts even though the entries were not damaged in any way.

* mem_hdr::hasContigousContentRange() now returns true for empty ranges.

* Support ""appending"" ReadWriteLock state that can be shared by readers and
  the writer. The writer promises not to update key metadata (except growing
  object size and next pointers) and readers promise to be careful when
  reading growing slices.

* Fixed StoreEntry::mayStartSwapOut() logic to handle terminated swapouts.

* Improved STORE_MEM_CLIENT detection and documented known (and mostly old)
  StoreEntry::storeClientType() problems.

* Removed StoreEntry::hidden_mem_obj hack.

* Polished StoreEntry debugging to report more info, less noise. Use e: prefix.

* Added a script to extract store entry(ies) debugging from cache.log.",6196,data/crawl/squid/hunk_1645.cpp,,,data/crawl/squid/old_hunk_1645.cpp,data/crawl/squid/new_hunk_1645.cpp,-1,19,,"createError(""write"");","[""addLog""]","[[], [""createError"", ""write""]]",[1574950929732431149],5963,0.0,2
https://github.com/squid-cache/squid/commit/fa2301d26b90cbd1298eb7740e8827c7746cd9d2,01 Jan 2014,"Initial Large Rock and Collapsed Forwarding support.

Large Rock: Support disk (and shared memory) caching of responses exceeding
one db slot (or one shared memory page) in size. A single db slot/page size is
still limited to 32KB (smaller values can be configured for disk caches using
the newly added cache_dir slot-size option). Removal of old rock cache dir
(followed by squid-z) is required -- the on-disk db structure has changed.

Collapsed Forwarding: Optionally merge concurrent cachable requests for the
same URI earlier: After the request headers have been parsed (as before), but
now _before_ the response headers have been received. Merging of requests
received by different SMP workers is supported. Controlled by the new
collapsed_forwarding directive in squid.conf. Disabled by default because all
but one of the merged requests have to be delayed (until the response headers
are received) for the merging to work, which may be worse than forwarding all
concurrent requests immediately. The overall feature idea and request
eligibility conditions are based on Collapsed Forwarding in Squid2.


Summary of other important changes (merged branch log contains the details):

* Tightened StoreEntry locking. Split StoreEntry::lock() into ""just lock"" and
  ""update entry reference time"" interfaces, addressing an old XXX.  Improved
  entry lock/unlock debugging. Needs more work.

* Adjusted StoreIOState::write() API to allow callers detect write errors.

* Simplified MemObject::write() API to remove an essentially unused callback.

* Mark client streams that sent everything as STREAM_COMPLETE. The old code
  used STREAM_UNPLANNED_COMPLETE if the completed stream was associated with a
  non-persistent connection, which did not make sense to me and, IIRC, led to
  store entry aborts even though the entries were not damaged in any way.

* mem_hdr::hasContigousContentRange() now returns true for empty ranges.

* Support ""appending"" ReadWriteLock state that can be shared by readers and
  the writer. The writer promises not to update key metadata (except growing
  object size and next pointers) and readers promise to be careful when
  reading growing slices.

* Fixed StoreEntry::mayStartSwapOut() logic to handle terminated swapouts.

* Improved STORE_MEM_CLIENT detection and documented known (and mostly old)
  StoreEntry::storeClientType() problems.

* Removed StoreEntry::hidden_mem_obj hack.

* Polished StoreEntry debugging to report more info, less noise. Use e: prefix.

* Added a script to extract store entry(ies) debugging from cache.log.",6196,data/crawl/squid/hunk_1645.cpp,,,data/crawl/squid/old_hunk_1645.cpp,data/crawl/squid/new_hunk_1645.cpp,21,-1,"fatal(""Rock Store db creation error"");",,"[""removeLog""]","[[""fatal"", ""Rock"", ""Store"", ""db"", ""creation"", ""error""], []]",[1759631197158767042],5962,0.0,2
https://github.com/squid-cache/squid/commit/fa2301d26b90cbd1298eb7740e8827c7746cd9d2,01 Jan 2014,"Initial Large Rock and Collapsed Forwarding support.

Large Rock: Support disk (and shared memory) caching of responses exceeding
one db slot (or one shared memory page) in size. A single db slot/page size is
still limited to 32KB (smaller values can be configured for disk caches using
the newly added cache_dir slot-size option). Removal of old rock cache dir
(followed by squid-z) is required -- the on-disk db structure has changed.

Collapsed Forwarding: Optionally merge concurrent cachable requests for the
same URI earlier: After the request headers have been parsed (as before), but
now _before_ the response headers have been received. Merging of requests
received by different SMP workers is supported. Controlled by the new
collapsed_forwarding directive in squid.conf. Disabled by default because all
but one of the merged requests have to be delayed (until the response headers
are received) for the merging to work, which may be worse than forwarding all
concurrent requests immediately. The overall feature idea and request
eligibility conditions are based on Collapsed Forwarding in Squid2.


Summary of other important changes (merged branch log contains the details):

* Tightened StoreEntry locking. Split StoreEntry::lock() into ""just lock"" and
  ""update entry reference time"" interfaces, addressing an old XXX.  Improved
  entry lock/unlock debugging. Needs more work.

* Adjusted StoreIOState::write() API to allow callers detect write errors.

* Simplified MemObject::write() API to remove an essentially unused callback.

* Mark client streams that sent everything as STREAM_COMPLETE. The old code
  used STREAM_UNPLANNED_COMPLETE if the completed stream was associated with a
  non-persistent connection, which did not make sense to me and, IIRC, led to
  store entry aborts even though the entries were not damaged in any way.

* mem_hdr::hasContigousContentRange() now returns true for empty ranges.

* Support ""appending"" ReadWriteLock state that can be shared by readers and
  the writer. The writer promises not to update key metadata (except growing
  object size and next pointers) and readers promise to be careful when
  reading growing slices.

* Fixed StoreEntry::mayStartSwapOut() logic to handle terminated swapouts.

* Improved STORE_MEM_CLIENT detection and documented known (and mostly old)
  StoreEntry::storeClientType() problems.

* Removed StoreEntry::hidden_mem_obj hack.

* Polished StoreEntry debugging to report more info, less noise. Use e: prefix.

* Added a script to extract store entry(ies) debugging from cache.log.",6196,data/crawl/squid/hunk_1641.cpp,,,data/crawl/squid/old_hunk_1641.cpp,data/crawl/squid/new_hunk_1641.cpp,-1,79,,"storeAppendPrintf(&e, ""Current entries: %"" PRId64 "" %.2f%%\n"",
                              currentCount(), (100.0 * currentCount() / limit));","[""addLog""]","[[], [""storeAppendPrintf"", ""&e"", ""Current"", ""entries"", ""%"", ""PRId64"", ""%"", ""2f%%\\n"", ""currentCount"", ""100"", ""0"", ""*"", ""currentCount"", ""/"", ""limit""]]",[14363340019230894414],5961,605520.0,2
https://github.com/squid-cache/squid/commit/fa2301d26b90cbd1298eb7740e8827c7746cd9d2,01 Jan 2014,"Initial Large Rock and Collapsed Forwarding support.

Large Rock: Support disk (and shared memory) caching of responses exceeding
one db slot (or one shared memory page) in size. A single db slot/page size is
still limited to 32KB (smaller values can be configured for disk caches using
the newly added cache_dir slot-size option). Removal of old rock cache dir
(followed by squid-z) is required -- the on-disk db structure has changed.

Collapsed Forwarding: Optionally merge concurrent cachable requests for the
same URI earlier: After the request headers have been parsed (as before), but
now _before_ the response headers have been received. Merging of requests
received by different SMP workers is supported. Controlled by the new
collapsed_forwarding directive in squid.conf. Disabled by default because all
but one of the merged requests have to be delayed (until the response headers
are received) for the merging to work, which may be worse than forwarding all
concurrent requests immediately. The overall feature idea and request
eligibility conditions are based on Collapsed Forwarding in Squid2.


Summary of other important changes (merged branch log contains the details):

* Tightened StoreEntry locking. Split StoreEntry::lock() into ""just lock"" and
  ""update entry reference time"" interfaces, addressing an old XXX.  Improved
  entry lock/unlock debugging. Needs more work.

* Adjusted StoreIOState::write() API to allow callers detect write errors.

* Simplified MemObject::write() API to remove an essentially unused callback.

* Mark client streams that sent everything as STREAM_COMPLETE. The old code
  used STREAM_UNPLANNED_COMPLETE if the completed stream was associated with a
  non-persistent connection, which did not make sense to me and, IIRC, led to
  store entry aborts even though the entries were not damaged in any way.

* mem_hdr::hasContigousContentRange() now returns true for empty ranges.

* Support ""appending"" ReadWriteLock state that can be shared by readers and
  the writer. The writer promises not to update key metadata (except growing
  object size and next pointers) and readers promise to be careful when
  reading growing slices.

* Fixed StoreEntry::mayStartSwapOut() logic to handle terminated swapouts.

* Improved STORE_MEM_CLIENT detection and documented known (and mostly old)
  StoreEntry::storeClientType() problems.

* Removed StoreEntry::hidden_mem_obj hack.

* Polished StoreEntry debugging to report more info, less noise. Use e: prefix.

* Added a script to extract store entry(ies) debugging from cache.log.",6196,data/crawl/squid/hunk_1640.cpp,,,data/crawl/squid/old_hunk_1640.cpp,data/crawl/squid/new_hunk_1640.cpp,-1,7,,"storeAppendPrintf(&e, ""Used slots:      %9d %.2f%%\n"",
                                  usedSlots, (100.0 * usedSlots / limit));","[""addLog""]","[[], [""storeAppendPrintf"", ""&e"", ""Used"", ""slots"", ""%9d"", ""%"", ""2f%%\\n"", ""usedSlots"", ""100"", ""0"", ""*"", ""usedSlots"", ""/"", ""limit""]]",[-8376104729506686106],5960,0.0,2
https://github.com/squid-cache/squid/commit/5a429fae7f03095c8cc7d75f37905674014e3358,13 Feb 2014,"Bug 4001: remove use of strsep()

The strsep() function is not defined by POSIX. Additionally
auto-tools has been having some obscure issues detecting
or linking the provided implementation into libcompat on
Windows and Solaris respectively. Which are the two known
OS requiring it.

Investigation of its use in Squid revealed that it can be
replaced with strcspan() which is both portable and more
efficient since it also removes the need for several
strdup()/free() operations used to protect Squid from
strsep() memory fiddling.",222,data/crawl/squid/hunk_1608.cpp,,,data/crawl/squid/old_hunk_1608.cpp,data/crawl/squid/new_hunk_1608.cpp,66,60,"fatalf(""parse_wccp2_service_ports: port value '%s' isn't valid (1..65535)\n"", port);","fatalf(""parse_wccp2_service_ports: port value '%s' isn't valid (1..65535)\n"", tmp);","[""updateVariable""]","[[""port""], [""tmp""]]",[-5637794708503497213],5959,0.0,2
https://github.com/squid-cache/squid/commit/95c25f6682acfdbb45b3056bc8aa247e3fc4c88e,16 Feb 2014,"squidclient: support verbosity levels

This makes the -v option repeatable. By default no debug is displayed.
Each time -v is repeated the level of debug message verbosity is raised.

Three levels of verbosity are currently defined:
 0 - no output except ERROR messages.
 1 - display HTTP request sent
 2 - display actions taken connecting to server",105,data/crawl/squid/hunk_1604.cpp,,,data/crawl/squid/old_hunk_1604.cpp,data/crawl/squid/new_hunk_1604.cpp,45,42,"fprintf(stderr, ""Connecting... %s(%s)\n"", hostname, iaddr.toStr(ipbuf, MAX_IPSTRLEN));","debugVerbose(2, ""Connecting... "" << hostname << "" ("" << iaddr << "")"");","[""moveContent"", ""updateLog"", ""moveVariable"", ""removeVariable"", ""addContent"", ""updateContent"", ""addVariable""]","[[""fprintf"", ""stderr"", ""%s"", ""%s"", ""\\n"", ""toStr"", ""ipbuf"", ""MAX_IPSTRLEN""], [""debugVerbose"", ""2""]]",[12372780201389925814],5958,0.0,2
https://github.com/squid-cache/squid/commit/95c25f6682acfdbb45b3056bc8aa247e3fc4c88e,16 Feb 2014,"squidclient: support verbosity levels

This makes the -v option repeatable. By default no debug is displayed.
Each time -v is repeated the level of debug message verbosity is raised.

Three levels of verbosity are currently defined:
 0 - no output except ERROR messages.
 1 - display HTTP request sent
 2 - display actions taken connecting to server",105,data/crawl/squid/hunk_1604.cpp,,,data/crawl/squid/old_hunk_1604.cpp,data/crawl/squid/new_hunk_1604.cpp,17,-1,"fprintf(stderr, ""client: ERROR: Cannot resolve %s: Host unknown.\n"", hostname);",,"[""removeLog""]","[[""fprintf"", ""stderr"", ""client"", ""ERROR"", ""Cannot"", ""resolve"", ""%s"", ""Host"", ""unknown"", ""\\n"", ""hostname""], []]",[-14961183109610632870],5957,0.0,2
https://github.com/squid-cache/squid/commit/ae61f2a70b4839175e1896fb984276ec9b122686,17 Mar 2014,Remove XMALLOC_TRACE and references to sbrk(2),348,data/crawl/squid/hunk_1578.cpp,,,data/crawl/squid/old_hunk_1578.cpp,data/crawl/squid/new_hunk_1578.cpp,5,-1,"storeAppendPrintf(sentry, ""\tProcess Data Segment Size via sbrk(): %.0f KB\n"",
                      stats.proc_data_seg / 1024);",,"[""removeLog""]","[[""storeAppendPrintf"", ""sentry"", ""\\tProcess"", ""Data"", ""Segment"", ""Size"", ""via"", ""sbrk"", ""%"", ""0f"", ""KB\\n"", ""stats"", ""proc_data_seg"", ""/"", ""1024""], []]",[4361111679131633204],5956,720.0,2
https://github.com/squid-cache/squid/commit/ae61f2a70b4839175e1896fb984276ec9b122686,17 Mar 2014,Remove XMALLOC_TRACE and references to sbrk(2),348,data/crawl/squid/hunk_1577.cpp,,,data/crawl/squid/old_hunk_1577.cpp,data/crawl/squid/new_hunk_1577.cpp,7,-1,"fatal(""Need to configure --enable-xmalloc-debug-trace to use -m option"");",,"[""removeLog""]","[[""fatal"", ""Need"", ""to"", ""configure"", ""enable"", ""xmalloc"", ""debug"", ""trace"", ""to"", ""use"", ""m"", ""option""], []]",[-8377785382164987977],5955,720.0,2
https://github.com/squid-cache/squid/commit/4e4c52effcd62c2fdcce4703dd9e839a80864d1a,17 Mar 2014,"Undo trunk r13270: ""Refactor Vector and Stack to STL counterparts""
to avoid stability issues related to std::vector migration.",824,data/crawl/squid/hunk_1564.cpp,,,data/crawl/squid/old_hunk_1564.cpp,data/crawl/squid/new_hunk_1564.cpp,-1,438,,"fatal (""domain error"");","[""addLog""]","[[], [""fatal"", ""domain"", ""error""]]",[11742947046656841780],5954,2934720.0,2
https://github.com/squid-cache/squid/commit/903d27daf52f98a660ca9559faae9545672f6bf9,19 Mar 2014,"xmalloc cleanup: remove code relying on XMALLOC_TRACE, XMALLOC_DEBUG, and mallinfo(3).",545,data/crawl/squid/hunk_1561.cpp,,,data/crawl/squid/old_hunk_1561.cpp,data/crawl/squid/new_hunk_1561.cpp,60,-1,"fprintf(debug_log, ""\tbytes used in maintaining the free tree:\t%d\n"",
            mp.treeoverhead);",,"[""removeLog""]","[[""fprintf"", ""debug_log"", ""\\tbytes"", ""used"", ""in"", ""maintaining"", ""the"", ""free"", ""tree"", ""\\t%d\\n"", ""mp"", ""treeoverhead""], []]",[4437604774626414335],5953,1440.0,2
https://github.com/squid-cache/squid/commit/903d27daf52f98a660ca9559faae9545672f6bf9,19 Mar 2014,"xmalloc cleanup: remove code relying on XMALLOC_TRACE, XMALLOC_DEBUG, and mallinfo(3).",545,data/crawl/squid/hunk_1561.cpp,,,data/crawl/squid/old_hunk_1561.cpp,data/crawl/squid/new_hunk_1561.cpp,57,-1,"fprintf(debug_log, ""\tnumber of ordinary blocks allocated:\t%d\n"",
            mp.allocated);",,"[""removeLog""]","[[""fprintf"", ""debug_log"", ""\\tnumber"", ""of"", ""ordinary"", ""blocks"", ""allocated"", ""\\t%d\\n"", ""mp"", ""allocated""], []]",[8680093383938280547],5952,1440.0,2
https://github.com/squid-cache/squid/commit/903d27daf52f98a660ca9559faae9545672f6bf9,19 Mar 2014,"xmalloc cleanup: remove code relying on XMALLOC_TRACE, XMALLOC_DEBUG, and mallinfo(3).",545,data/crawl/squid/hunk_1561.cpp,,,data/crawl/squid/old_hunk_1561.cpp,data/crawl/squid/new_hunk_1561.cpp,54,-1,"fprintf(debug_log, ""\tspace (including overhead) allocated in ord. blks:\t%d\n"",
            mp.uordbytes);",,"[""removeLog""]","[[""fprintf"", ""debug_log"", ""\\tspace"", ""including"", ""overhead"", ""allocated"", ""in"", ""ord"", ""blks"", ""\\t%d\\n"", ""mp"", ""uordbytes""], []]",[-1626640044612799957],5951,1440.0,2
https://github.com/squid-cache/squid/commit/903d27daf52f98a660ca9559faae9545672f6bf9,19 Mar 2014,"xmalloc cleanup: remove code relying on XMALLOC_TRACE, XMALLOC_DEBUG, and mallinfo(3).",545,data/crawl/squid/hunk_1561.cpp,,,data/crawl/squid/old_hunk_1561.cpp,data/crawl/squid/new_hunk_1561.cpp,51,-1,"fprintf(debug_log, ""\tsmall block rounding factor:\t%d\n"",
            mp.grain);",,"[""removeLog""]","[[""fprintf"", ""debug_log"", ""\\tsmall"", ""block"", ""rounding"", ""factor"", ""\\t%d\\n"", ""mp"", ""grain""], []]",[7646364347420526518],5950,1440.0,2
https://github.com/squid-cache/squid/commit/903d27daf52f98a660ca9559faae9545672f6bf9,19 Mar 2014,"xmalloc cleanup: remove code relying on XMALLOC_TRACE, XMALLOC_DEBUG, and mallinfo(3).",545,data/crawl/squid/hunk_1561.cpp,,,data/crawl/squid/old_hunk_1561.cpp,data/crawl/squid/new_hunk_1561.cpp,48,-1,"fprintf(debug_log, ""\tnumber of small blocks in a holding block:\t%d\n"",
            mp.nlblks);",,"[""removeLog""]","[[""fprintf"", ""debug_log"", ""\\tnumber"", ""of"", ""small"", ""blocks"", ""in"", ""a"", ""holding"", ""block"", ""\\t%d\\n"", ""mp"", ""nlblks""], []]",[32449563171746089574],5949,1440.0,2
https://github.com/squid-cache/squid/commit/903d27daf52f98a660ca9559faae9545672f6bf9,19 Mar 2014,"xmalloc cleanup: remove code relying on XMALLOC_TRACE, XMALLOC_DEBUG, and mallinfo(3).",545,data/crawl/squid/hunk_1561.cpp,,,data/crawl/squid/old_hunk_1561.cpp,data/crawl/squid/new_hunk_1561.cpp,45,-1,"fprintf(debug_log, ""\tmax size of small blocks:\t%d\n"",
            mp.mxfast);",,"[""removeLog""]","[[""fprintf"", ""debug_log"", ""\\tmax"", ""size"", ""of"", ""small"", ""blocks"", ""\\t%d\\n"", ""mp"", ""mxfast""], []]",[35088113408219765843],5948,1440.0,2
https://github.com/squid-cache/squid/commit/903d27daf52f98a660ca9559faae9545672f6bf9,19 Mar 2014,"xmalloc cleanup: remove code relying on XMALLOC_TRACE, XMALLOC_DEBUG, and mallinfo(3).",545,data/crawl/squid/hunk_1561.cpp,,,data/crawl/squid/old_hunk_1561.cpp,data/crawl/squid/new_hunk_1561.cpp,40,-1,"fprintf(debug_log, ""\tTotal free:            %6d KB %d%%\n"",
            t >> 10, Math::intPercent(t, mp.arena));",,"[""removeLog""]","[[""fprintf"", ""debug_log"", ""\\tTotal"", ""free"", ""%6d"", ""KB"", ""%d%%\\n"", ""t"", ""10"", ""Math"", ""intPercent"", ""t"", ""mp"", ""arena""], []]",[26563108913685024918],5947,1440.0,2
https://github.com/squid-cache/squid/commit/903d27daf52f98a660ca9559faae9545672f6bf9,19 Mar 2014,"xmalloc cleanup: remove code relying on XMALLOC_TRACE, XMALLOC_DEBUG, and mallinfo(3).",545,data/crawl/squid/hunk_1561.cpp,,,data/crawl/squid/old_hunk_1561.cpp,data/crawl/squid/new_hunk_1561.cpp,35,-1,"fprintf(debug_log, ""\tTotal in use:          %6d KB %d%%\n"",
            t >> 10, Math::intPercent(t, mp.arena));",,"[""removeLog""]","[[""fprintf"", ""debug_log"", ""\\tTotal"", ""in"", ""use"", ""%6d"", ""KB"", ""%d%%\\n"", ""t"", ""10"", ""Math"", ""intPercent"", ""t"", ""mp"", ""arena""], []]",[28661396896443626667],5946,1440.0,2
https://github.com/squid-cache/squid/commit/903d27daf52f98a660ca9559faae9545672f6bf9,19 Mar 2014,"xmalloc cleanup: remove code relying on XMALLOC_TRACE, XMALLOC_DEBUG, and mallinfo(3).",545,data/crawl/squid/hunk_1561.cpp,,,data/crawl/squid/old_hunk_1561.cpp,data/crawl/squid/new_hunk_1561.cpp,30,-1,"fprintf(debug_log, ""\tFree Ordinary blocks:  %6ld KB\n"",
            (long)mp.fordblks >> 10);",,"[""removeLog""]","[[""fprintf"", ""debug_log"", ""\\tFree"", ""Ordinary"", ""blocks"", ""%6ld"", ""KB\\n"", ""long"", ""mp"", ""fordblks"", ""10""], []]",[-3696458613398606106],5945,1440.0,2
https://github.com/squid-cache/squid/commit/903d27daf52f98a660ca9559faae9545672f6bf9,19 Mar 2014,"xmalloc cleanup: remove code relying on XMALLOC_TRACE, XMALLOC_DEBUG, and mallinfo(3).",545,data/crawl/squid/hunk_1561.cpp,,,data/crawl/squid/old_hunk_1561.cpp,data/crawl/squid/new_hunk_1561.cpp,27,-1,"fprintf(debug_log, ""\tFree Small blocks:     %6ld KB\n"",
            (long)mp.fsmblks >> 10);",,"[""removeLog""]","[[""fprintf"", ""debug_log"", ""\\tFree"", ""Small"", ""blocks"", ""%6ld"", ""KB\\n"", ""long"", ""mp"", ""fsmblks"", ""10""], []]",[-851347067915971090],5944,1440.0,2
https://github.com/squid-cache/squid/commit/903d27daf52f98a660ca9559faae9545672f6bf9,19 Mar 2014,"xmalloc cleanup: remove code relying on XMALLOC_TRACE, XMALLOC_DEBUG, and mallinfo(3).",545,data/crawl/squid/hunk_1561.cpp,,,data/crawl/squid/old_hunk_1561.cpp,data/crawl/squid/new_hunk_1561.cpp,24,-1,"fprintf(debug_log, ""\tHolding blocks:        %6ld KB %6ld blks\n"",
            (long)mp.hblkhd >> 10, (long)mp.hblks);",,"[""removeLog""]","[[""fprintf"", ""debug_log"", ""\\tHolding"", ""blocks"", ""%6ld"", ""KB"", ""%6ld"", ""blks\\n"", ""long"", ""mp"", ""hblkhd"", ""10"", ""long"", ""mp"", ""hblks""], []]",[-16637744034500243513],5943,1440.0,2
https://github.com/squid-cache/squid/commit/903d27daf52f98a660ca9559faae9545672f6bf9,19 Mar 2014,"xmalloc cleanup: remove code relying on XMALLOC_TRACE, XMALLOC_DEBUG, and mallinfo(3).",545,data/crawl/squid/hunk_1561.cpp,,,data/crawl/squid/old_hunk_1561.cpp,data/crawl/squid/new_hunk_1561.cpp,21,-1,"fprintf(debug_log, ""\tSmall blocks:          %6ld KB %6ld blks\n"",
            (long)mp.usmblks >> 10, (long)mp.smblks);",,"[""removeLog""]","[[""fprintf"", ""debug_log"", ""\\tSmall"", ""blocks"", ""%6ld"", ""KB"", ""%6ld"", ""blks\\n"", ""long"", ""mp"", ""usmblks"", ""10"", ""long"", ""mp"", ""smblks""], []]",[-11182242598704048855],5942,1440.0,2
https://github.com/squid-cache/squid/commit/903d27daf52f98a660ca9559faae9545672f6bf9,19 Mar 2014,"xmalloc cleanup: remove code relying on XMALLOC_TRACE, XMALLOC_DEBUG, and mallinfo(3).",545,data/crawl/squid/hunk_1561.cpp,,,data/crawl/squid/old_hunk_1561.cpp,data/crawl/squid/new_hunk_1561.cpp,18,-1,"fprintf(debug_log, ""\tOrdinary blocks:       %6ld KB %6ld blks\n"",
            (long)mp.uordblks >> 10, (long)mp.ordblks);",,"[""removeLog""]","[[""fprintf"", ""debug_log"", ""\\tOrdinary"", ""blocks"", ""%6ld"", ""KB"", ""%6ld"", ""blks\\n"", ""long"", ""mp"", ""uordblks"", ""10"", ""long"", ""mp"", ""ordblks""], []]",[-25666444452083495121],5941,1440.0,2
https://github.com/squid-cache/squid/commit/903d27daf52f98a660ca9559faae9545672f6bf9,19 Mar 2014,"xmalloc cleanup: remove code relying on XMALLOC_TRACE, XMALLOC_DEBUG, and mallinfo(3).",545,data/crawl/squid/hunk_1561.cpp,,,data/crawl/squid/old_hunk_1561.cpp,data/crawl/squid/new_hunk_1561.cpp,15,-1,"fprintf(debug_log, ""\ttotal space in arena:  %6ld KB\n"",
            (long)mp.arena >> 10);",,"[""removeLog""]","[[""fprintf"", ""debug_log"", ""\\ttotal"", ""space"", ""in"", ""arena"", ""%6ld"", ""KB\\n"", ""long"", ""mp"", ""arena"", ""10""], []]",[-8169537094661904368],5940,1440.0,2
https://github.com/squid-cache/squid/commit/903d27daf52f98a660ca9559faae9545672f6bf9,19 Mar 2014,"xmalloc cleanup: remove code relying on XMALLOC_TRACE, XMALLOC_DEBUG, and mallinfo(3).",545,data/crawl/squid/hunk_1561.cpp,,,data/crawl/squid/old_hunk_1561.cpp,data/crawl/squid/new_hunk_1561.cpp,13,-1,"fprintf(debug_log, ""Memory usage for "" APP_SHORTNAME "" via mallinfo():\n"");",,"[""removeLog""]","[[""fprintf"", ""debug_log"", ""Memory"", ""usage"", ""for"", ""APP_SHORTNAME"", ""via"", ""mallinfo"", ""\\n""], []]",[15983539200800316853],5939,1440.0,2
https://github.com/squid-cache/squid/commit/903d27daf52f98a660ca9559faae9545672f6bf9,19 Mar 2014,"xmalloc cleanup: remove code relying on XMALLOC_TRACE, XMALLOC_DEBUG, and mallinfo(3).",545,data/crawl/squid/hunk_1560.cpp,,,data/crawl/squid/old_hunk_1560.cpp,data/crawl/squid/new_hunk_1560.cpp,84,-1,"storeAppendPrintf(sentry, ""\tmemPool unaccounted:   %6.0f KB %3.0f%%\n"",
                          (t - stats.mem_pool_allocated) / 1024,
                          Math::doublePercent(iFree, t));",,"[""removeLog""]","[[""storeAppendPrintf"", ""sentry"", ""\\tmemPool"", ""unaccounted"", ""%6"", ""0f"", ""KB"", ""%3"", ""0f%%\\n"", ""t"", ""stats"", ""mem_pool_allocated"", ""/"", ""1024"", ""Math"", ""doublePercent"", ""iFree"", ""t""], []]",[-23117677697911464902],5938,1440.0,2
https://github.com/squid-cache/squid/commit/903d27daf52f98a660ca9559faae9545672f6bf9,19 Mar 2014,"xmalloc cleanup: remove code relying on XMALLOC_TRACE, XMALLOC_DEBUG, and mallinfo(3).",545,data/crawl/squid/hunk_1560.cpp,,,data/crawl/squid/old_hunk_1560.cpp,data/crawl/squid/new_hunk_1560.cpp,79,-1,"storeAppendPrintf(sentry, ""\tmemPool accounted:     %6.0f KB %3.0f%%\n"",
                          stats.mem_pool_allocated / 1024,
                          Math::doublePercent(stats.mem_pool_allocated, t));",,"[""removeLog""]","[[""storeAppendPrintf"", ""sentry"", ""\\tmemPool"", ""accounted"", ""%6"", ""0f"", ""KB"", ""%3"", ""0f%%\\n"", ""stats"", ""mem_pool_allocated"", ""/"", ""1024"", ""Math"", ""doublePercent"", ""stats"", ""mem_pool_allocated"", ""t""], []]",[-17143081602212288408],5937,1440.0,2
https://github.com/squid-cache/squid/commit/903d27daf52f98a660ca9559faae9545672f6bf9,19 Mar 2014,"xmalloc cleanup: remove code relying on XMALLOC_TRACE, XMALLOC_DEBUG, and mallinfo(3).",545,data/crawl/squid/hunk_1560.cpp,,,data/crawl/squid/old_hunk_1560.cpp,data/crawl/squid/new_hunk_1560.cpp,65,-1,"storeAppendPrintf(sentry, ""\tTotal accounted:       %6.0f KB %3.0f%%\n"",
                      stats.total_accounted / 1024, Math::doublePercent(stats.total_accounted, t));",,"[""removeLog""]","[[""storeAppendPrintf"", ""sentry"", ""\\tTotal"", ""accounted"", ""%6"", ""0f"", ""KB"", ""%3"", ""0f%%\\n"", ""stats"", ""total_accounted"", ""/"", ""1024"", ""Math"", ""doublePercent"", ""stats"", ""total_accounted"", ""t""], []]",[15429019081346183167],5936,1440.0,2
https://github.com/squid-cache/squid/commit/903d27daf52f98a660ca9559faae9545672f6bf9,19 Mar 2014,"xmalloc cleanup: remove code relying on XMALLOC_TRACE, XMALLOC_DEBUG, and mallinfo(3).",545,data/crawl/squid/hunk_1560.cpp,,,data/crawl/squid/old_hunk_1560.cpp,data/crawl/squid/new_hunk_1560.cpp,55,-1,"storeAppendPrintf(sentry, ""\tbytes used in maintaining the free tree:\t%.0f\n"",
                      stats.mp_treeoverhead);",,"[""removeLog""]","[[""storeAppendPrintf"", ""sentry"", ""\\tbytes"", ""used"", ""in"", ""maintaining"", ""the"", ""free"", ""tree"", ""\\t%"", ""0f\\n"", ""stats"", ""mp_treeoverhead""], []]",[-11142334043727656599],5935,1440.0,2
https://github.com/squid-cache/squid/commit/903d27daf52f98a660ca9559faae9545672f6bf9,19 Mar 2014,"xmalloc cleanup: remove code relying on XMALLOC_TRACE, XMALLOC_DEBUG, and mallinfo(3).",545,data/crawl/squid/hunk_1560.cpp,,,data/crawl/squid/old_hunk_1560.cpp,data/crawl/squid/new_hunk_1560.cpp,52,-1,"storeAppendPrintf(sentry, ""\tnumber of ordinary blocks allocated:\t%.0f\n"",
                      stats.mp_allocated);",,"[""removeLog""]","[[""storeAppendPrintf"", ""sentry"", ""\\tnumber"", ""of"", ""ordinary"", ""blocks"", ""allocated"", ""\\t%"", ""0f\\n"", ""stats"", ""mp_allocated""], []]",[-9950130031576322525],5934,1440.0,2
https://github.com/squid-cache/squid/commit/903d27daf52f98a660ca9559faae9545672f6bf9,19 Mar 2014,"xmalloc cleanup: remove code relying on XMALLOC_TRACE, XMALLOC_DEBUG, and mallinfo(3).",545,data/crawl/squid/hunk_1560.cpp,,,data/crawl/squid/old_hunk_1560.cpp,data/crawl/squid/new_hunk_1560.cpp,49,-1,"storeAppendPrintf(sentry, ""\tspace (including overhead) allocated in ord. blks:\t%.0f\n""
                      ,stats.mp_uordbytes);",,"[""removeLog""]","[[""storeAppendPrintf"", ""sentry"", ""\\tspace"", ""including"", ""overhead"", ""allocated"", ""in"", ""ord"", ""blks"", ""\\t%"", ""0f\\n"", ""stats"", ""mp_uordbytes""], []]",[-26557395624662448517],5933,1440.0,2
https://github.com/squid-cache/squid/commit/903d27daf52f98a660ca9559faae9545672f6bf9,19 Mar 2014,"xmalloc cleanup: remove code relying on XMALLOC_TRACE, XMALLOC_DEBUG, and mallinfo(3).",545,data/crawl/squid/hunk_1560.cpp,,,data/crawl/squid/old_hunk_1560.cpp,data/crawl/squid/new_hunk_1560.cpp,47,-1,"storeAppendPrintf(sentry, ""\tsmall block rounding factor:\t%.0f\n"", stats.mp_grain);",,"[""removeLog""]","[[""storeAppendPrintf"", ""sentry"", ""\\tsmall"", ""block"", ""rounding"", ""factor"", ""\\t%"", ""0f\\n"", ""stats"", ""mp_grain""], []]",[-20624358704110470222],5932,1440.0,2
https://github.com/squid-cache/squid/commit/903d27daf52f98a660ca9559faae9545672f6bf9,19 Mar 2014,"xmalloc cleanup: remove code relying on XMALLOC_TRACE, XMALLOC_DEBUG, and mallinfo(3).",545,data/crawl/squid/hunk_1560.cpp,,,data/crawl/squid/old_hunk_1560.cpp,data/crawl/squid/new_hunk_1560.cpp,44,-1,"storeAppendPrintf(sentry, ""\tnumber of small blocks in a holding block:\t%.0f\n"",
                      stats.mp_nlblks);",,"[""removeLog""]","[[""storeAppendPrintf"", ""sentry"", ""\\tnumber"", ""of"", ""small"", ""blocks"", ""in"", ""a"", ""holding"", ""block"", ""\\t%"", ""0f\\n"", ""stats"", ""mp_nlblks""], []]",[13964139412169167520],5931,1440.0,2
https://github.com/squid-cache/squid/commit/903d27daf52f98a660ca9559faae9545672f6bf9,19 Mar 2014,"xmalloc cleanup: remove code relying on XMALLOC_TRACE, XMALLOC_DEBUG, and mallinfo(3).",545,data/crawl/squid/hunk_1560.cpp,,,data/crawl/squid/old_hunk_1560.cpp,data/crawl/squid/new_hunk_1560.cpp,42,-1,"storeAppendPrintf(sentry, ""\tmax size of small blocks:\t%.0f\n"", stats.mp_mxfast);",,"[""removeLog""]","[[""storeAppendPrintf"", ""sentry"", ""\\tmax"", ""size"", ""of"", ""small"", ""blocks"", ""\\t%"", ""0f\\n"", ""stats"", ""mp_mxfast""], []]",[10009231251425043875],5930,1440.0,2
https://github.com/squid-cache/squid/commit/903d27daf52f98a660ca9559faae9545672f6bf9,19 Mar 2014,"xmalloc cleanup: remove code relying on XMALLOC_TRACE, XMALLOC_DEBUG, and mallinfo(3).",545,data/crawl/squid/hunk_1560.cpp,,,data/crawl/squid/old_hunk_1560.cpp,data/crawl/squid/new_hunk_1560.cpp,37,-1,"storeAppendPrintf(sentry, ""\tTotal size:            %6.0f KB\n"",
                      t / 1024);",,"[""removeLog""]","[[""storeAppendPrintf"", ""sentry"", ""\\tTotal"", ""size"", ""%6"", ""0f"", ""KB\\n"", ""t"", ""/"", ""1024""], []]",[574638977980686102],5929,1440.0,2
https://github.com/squid-cache/squid/commit/903d27daf52f98a660ca9559faae9545672f6bf9,19 Mar 2014,"xmalloc cleanup: remove code relying on XMALLOC_TRACE, XMALLOC_DEBUG, and mallinfo(3).",545,data/crawl/squid/hunk_1560.cpp,,,data/crawl/squid/old_hunk_1560.cpp,data/crawl/squid/new_hunk_1560.cpp,32,-1,"storeAppendPrintf(sentry, ""\tTotal free:            %6.0f KB %.0f%%\n"",
                      t / 1024, Math::doublePercent(t, stats.mp_arena + stats.mp_hblkhd));",,"[""removeLog""]","[[""storeAppendPrintf"", ""sentry"", ""\\tTotal"", ""free"", ""%6"", ""0f"", ""KB"", ""%"", ""0f%%\\n"", ""t"", ""/"", ""1024"", ""Math"", ""doublePercent"", ""t"", ""stats"", ""mp_arena"", ""stats"", ""mp_hblkhd""], []]",[9786769578400036968],5928,1440.0,2
https://github.com/squid-cache/squid/commit/903d27daf52f98a660ca9559faae9545672f6bf9,19 Mar 2014,"xmalloc cleanup: remove code relying on XMALLOC_TRACE, XMALLOC_DEBUG, and mallinfo(3).",545,data/crawl/squid/hunk_1560.cpp,,,data/crawl/squid/old_hunk_1560.cpp,data/crawl/squid/new_hunk_1560.cpp,27,-1,"storeAppendPrintf(sentry, ""\tTotal in use:          %6.0f KB %.0f%%\n"",
                      t / 1024, Math::doublePercent(t, stats.mp_arena + stats.mp_hblkhd));",,"[""removeLog""]","[[""storeAppendPrintf"", ""sentry"", ""\\tTotal"", ""in"", ""use"", ""%6"", ""0f"", ""KB"", ""%"", ""0f%%\\n"", ""t"", ""/"", ""1024"", ""Math"", ""doublePercent"", ""t"", ""stats"", ""mp_arena"", ""stats"", ""mp_hblkhd""], []]",[11885057561158638717],5927,1440.0,2
https://github.com/squid-cache/squid/commit/903d27daf52f98a660ca9559faae9545672f6bf9,19 Mar 2014,"xmalloc cleanup: remove code relying on XMALLOC_TRACE, XMALLOC_DEBUG, and mallinfo(3).",545,data/crawl/squid/hunk_1560.cpp,,,data/crawl/squid/old_hunk_1560.cpp,data/crawl/squid/new_hunk_1560.cpp,22,-1,"storeAppendPrintf(sentry, ""\tFree Ordinary blocks:  %6.0f KB\n"",
                      stats.mp_fordblks / 1024);",,"[""removeLog""]","[[""storeAppendPrintf"", ""sentry"", ""\\tFree"", ""Ordinary"", ""blocks"", ""%6"", ""0f"", ""KB\\n"", ""stats"", ""mp_fordblks"", ""/"", ""1024""], []]",[-10150840200879831285],5926,1440.0,2
https://github.com/squid-cache/squid/commit/903d27daf52f98a660ca9559faae9545672f6bf9,19 Mar 2014,"xmalloc cleanup: remove code relying on XMALLOC_TRACE, XMALLOC_DEBUG, and mallinfo(3).",545,data/crawl/squid/hunk_1560.cpp,,,data/crawl/squid/old_hunk_1560.cpp,data/crawl/squid/new_hunk_1560.cpp,19,-1,"storeAppendPrintf(sentry, ""\tFree Small blocks:     %6.0f KB\n"",
                      stats.mp_fsmblks / 1024);",,"[""removeLog""]","[[""storeAppendPrintf"", ""sentry"", ""\\tFree"", ""Small"", ""blocks"", ""%6"", ""0f"", ""KB\\n"", ""stats"", ""mp_fsmblks"", ""/"", ""1024""], []]",[-3787712041626260371],5925,1440.0,2
https://github.com/squid-cache/squid/commit/903d27daf52f98a660ca9559faae9545672f6bf9,19 Mar 2014,"xmalloc cleanup: remove code relying on XMALLOC_TRACE, XMALLOC_DEBUG, and mallinfo(3).",545,data/crawl/squid/hunk_1560.cpp,,,data/crawl/squid/old_hunk_1560.cpp,data/crawl/squid/new_hunk_1560.cpp,16,-1,"storeAppendPrintf(sentry, ""\tHolding blocks:        %6.0f KB %6.0f blks\n"",
                      stats.mp_hblkhd / 1024, stats.mp_hblks);",,"[""removeLog""]","[[""storeAppendPrintf"", ""sentry"", ""\\tHolding"", ""blocks"", ""%6"", ""0f"", ""KB"", ""%6"", ""0f"", ""blks\\n"", ""stats"", ""mp_hblkhd"", ""/"", ""1024"", ""stats"", ""mp_hblks""], []]",[-3058022245175031284],5924,1440.0,2
https://github.com/squid-cache/squid/commit/903d27daf52f98a660ca9559faae9545672f6bf9,19 Mar 2014,"xmalloc cleanup: remove code relying on XMALLOC_TRACE, XMALLOC_DEBUG, and mallinfo(3).",545,data/crawl/squid/hunk_1560.cpp,,,data/crawl/squid/old_hunk_1560.cpp,data/crawl/squid/new_hunk_1560.cpp,13,-1,"storeAppendPrintf(sentry, ""\tSmall blocks:          %6.0f KB %6.0f blks\n"",
                      stats.mp_usmblks / 1024, stats.mp_smblks);",,"[""removeLog""]","[[""storeAppendPrintf"", ""sentry"", ""\\tSmall"", ""blocks"", ""%6"", ""0f"", ""KB"", ""%6"", ""0f"", ""blks\\n"", ""stats"", ""mp_usmblks"", ""/"", ""1024"", ""stats"", ""mp_smblks""], []]",[-12361897320007719158],5923,1440.0,2
https://github.com/squid-cache/squid/commit/903d27daf52f98a660ca9559faae9545672f6bf9,19 Mar 2014,"xmalloc cleanup: remove code relying on XMALLOC_TRACE, XMALLOC_DEBUG, and mallinfo(3).",545,data/crawl/squid/hunk_1560.cpp,,,data/crawl/squid/old_hunk_1560.cpp,data/crawl/squid/new_hunk_1560.cpp,10,-1,"storeAppendPrintf(sentry, ""\tOrdinary blocks:       %6.0f KB %6.0f blks\n"",
                      stats.mp_uordblks / 1024, stats.mp_ordblks);",,"[""removeLog""]","[[""storeAppendPrintf"", ""sentry"", ""\\tOrdinary"", ""blocks"", ""%6"", ""0f"", ""KB"", ""%6"", ""0f"", ""blks\\n"", ""stats"", ""mp_uordblks"", ""/"", ""1024"", ""stats"", ""mp_ordblks""], []]",[-6027658247339076144],5922,1440.0,2
https://github.com/squid-cache/squid/commit/903d27daf52f98a660ca9559faae9545672f6bf9,19 Mar 2014,"xmalloc cleanup: remove code relying on XMALLOC_TRACE, XMALLOC_DEBUG, and mallinfo(3).",545,data/crawl/squid/hunk_1560.cpp,,,data/crawl/squid/old_hunk_1560.cpp,data/crawl/squid/new_hunk_1560.cpp,7,-1,"storeAppendPrintf(sentry, ""\tTotal space in arena:  %6.0f KB\n"",
                      stats.mp_arena / 1024);",,"[""removeLog""]","[[""storeAppendPrintf"", ""sentry"", ""\\tTotal"", ""space"", ""in"", ""arena"", ""%6"", ""0f"", ""KB\\n"", ""stats"", ""mp_arena"", ""/"", ""1024""], []]",[-11412024203849660947],5921,1440.0,2
https://github.com/squid-cache/squid/commit/903d27daf52f98a660ca9559faae9545672f6bf9,19 Mar 2014,"xmalloc cleanup: remove code relying on XMALLOC_TRACE, XMALLOC_DEBUG, and mallinfo(3).",545,data/crawl/squid/hunk_1560.cpp,,,data/crawl/squid/old_hunk_1560.cpp,data/crawl/squid/new_hunk_1560.cpp,5,-1,"storeAppendPrintf(sentry, ""Memory usage for %s via mallinfo():\n"",APP_SHORTNAME);",,"[""removeLog""]","[[""storeAppendPrintf"", ""sentry"", ""Memory"", ""usage"", ""for"", ""%s"", ""via"", ""mallinfo"", ""\\n"", ""APP_SHORTNAME""], []]",[3650913822186346232],5920,1440.0,2
https://github.com/squid-cache/squid/commit/0e2f538320899fc48509259cd045bb6febc8c5f7,24 Mar 2014,"Parser-NG: Convert the ConnStateData input buffer to SBuf

Prepare the way to efficiently parse client requests using SBuf based
parser-ng.

IoCallback stores a raw-pointer to the ConnStateData::In::buf member
object rather than an SBuf reference to the backing MemBlob or char*
store so that only the short (blocking) FD_READ_METHOD() call needs to
provide any synchronous guarantees. We also particularly need a direct
(raw) pointer to the ConnStateData member to prevent the possible
read/consume collisions causing problems with the ConnStateData callback
and avoid having to merge two separate SBuf.",212,data/crawl/squid/hunk_1553.cpp,,,data/crawl/squid/old_hunk_1553.cpp,data/crawl/squid/new_hunk_1553.cpp,3,3,"storeAppendPrintf(s, ""\tin: buf %p, offset %ld, size %ld\n"",
                              conn->in.buf, (long int) conn->in.notYetUsed, (long int) conn->in.allocatedSize);","storeAppendPrintf(s, ""\tin: buf %p, used %ld, free %ld\n"",
                              conn->in.buf.c_str(), (long int) conn->in.buf.length(), (long int) conn->in.buf.spaceSize());","[""updateVariable"", ""moveVariable"", ""updateContent"", ""addVariable""]","[[""offset"", ""size"", ""notYetUsed"", ""allocatedSize""], [""used"", ""free"", ""c_str"", ""buf"", ""length"", ""buf"", ""spaceSize""]]",[11759551581990471576],5919,12240.0,2
https://github.com/squid-cache/squid/commit/4795daa2059af1e226cea497a3612a900af9afc5,12 Apr 2014,Use SBufList instead of wordlist to collect data for mgr:config,529,data/crawl/squid/hunk_1537.cpp,,,data/crawl/squid/old_hunk_1537.cpp,data/crawl/squid/new_hunk_1537.cpp,14,12,"mb.Printf("" %s"", arg->key);","s.Printf("" %s"", arg->key);","[""updateLog""]","[[""mb""], [""s""]]",[-13952069101081717],5918,0.0,2
https://github.com/squid-cache/squid/commit/4795daa2059af1e226cea497a3612a900af9afc5,12 Apr 2014,Use SBufList instead of wordlist to collect data for mgr:config,529,data/crawl/squid/hunk_1537.cpp,,,data/crawl/squid/old_hunk_1537.cpp,data/crawl/squid/new_hunk_1537.cpp,11,8,"mb.Printf(""%s"", acl->def->name);",(SBuf(acl->def->name);,"[""addLog"", ""removeContent"", ""removeLog""]","[[""mb"", ""Printf"", ""%s""], [""SBuf""]]",[-9096470574643612590],5917,0.0,2
https://github.com/squid-cache/squid/commit/4795daa2059af1e226cea497a3612a900af9afc5,12 Apr 2014,Use SBufList instead of wordlist to collect data for mgr:config,529,data/crawl/squid/hunk_1535.cpp,,,data/crawl/squid/old_hunk_1535.cpp,data/crawl/squid/new_hunk_1535.cpp,11,7,"storeAppendPrintf(entry, ""%s "", word->key);","entry->append(i->rawContent(), i->length());","[""addLog"", ""updateVariable"", ""moveVariable"", ""removeVariable"", ""removeContent"", ""addVariable"", ""removeLog""]","[[""storeAppendPrintf"", ""%s"", ""word"", ""key""], [""append"", ""i"", ""rawContent"", ""i"", ""length""]]",[-3565010422423315136],5916,0.0,2
https://github.com/squid-cache/squid/commit/4795daa2059af1e226cea497a3612a900af9afc5,12 Apr 2014,Use SBufList instead of wordlist to collect data for mgr:config,529,data/crawl/squid/hunk_1532.cpp,,,data/crawl/squid/old_hunk_1532.cpp,data/crawl/squid/new_hunk_1532.cpp,-1,11,,"s.Printf(""%d"", limit);","[""addLog""]","[[], [""s"", ""Printf"", ""%d"", ""limit""]]",[6998163688246880198],5915,0.0,2
https://github.com/squid-cache/squid/commit/4795daa2059af1e226cea497a3612a900af9afc5,12 Apr 2014,Use SBufList instead of wordlist to collect data for mgr:config,529,data/crawl/squid/hunk_1531.cpp,,,data/crawl/squid/old_hunk_1531.cpp,data/crawl/squid/new_hunk_1531.cpp,-1,19,,"sb.Printf(""%d-%d"", element.start, element.end-1);","[""addLog""]","[[], [""sb"", ""Printf"", ""%d"", ""%d"", ""element"", ""start"", ""element"", ""end"", ""1""]]",[-8663878316470563323],5914,720.0,2
https://github.com/squid-cache/squid/commit/4795daa2059af1e226cea497a3612a900af9afc5,12 Apr 2014,Use SBufList instead of wordlist to collect data for mgr:config,529,data/crawl/squid/hunk_1531.cpp,,,data/crawl/squid/old_hunk_1531.cpp,data/crawl/squid/new_hunk_1531.cpp,-1,17,,"sb.Printf(""%d"", element.start);","[""addLog""]","[[], [""sb"", ""Printf"", ""%d"", ""element"", ""start""]]",[1986732946095713913],5913,720.0,2
https://github.com/squid-cache/squid/commit/4795daa2059af1e226cea497a3612a900af9afc5,12 Apr 2014,Use SBufList instead of wordlist to collect data for mgr:config,529,data/crawl/squid/hunk_1530.cpp,,,data/crawl/squid/old_hunk_1530.cpp,data/crawl/squid/new_hunk_1530.cpp,-1,12,,"rv.Printf(""%d-%d"", status1, status2);","[""addLog""]","[[], [""rv"", ""Printf"", ""%d"", ""%d"", ""status1"", ""status2""]]",[-7082387250247571946],5912,720.0,2
https://github.com/squid-cache/squid/commit/4795daa2059af1e226cea497a3612a900af9afc5,12 Apr 2014,Use SBufList instead of wordlist to collect data for mgr:config,529,data/crawl/squid/hunk_1529.cpp,,,data/crawl/squid/old_hunk_1529.cpp,data/crawl/squid/new_hunk_1529.cpp,-1,12,,"s.Printf(""%d"", ldata->element);","[""addLog""]","[[], [""s"", ""Printf"", ""%d"", ""ldata"", ""element""]]",[4840519784852425282],5911,720.0,2
https://github.com/squid-cache/squid/commit/3616c90cbfa0c2dac5a985c4c406df55f7caa89a,31 May 2014,"Cleanup: de-duplicate auth_param program parameter code

Moves the ""program"" parse and dump code into Auth::Config.

Also, changes API to Auth::Config::dump() to not dump any config settings
for schemes which are not configured with a ""program"". Including scheme
specific settings.

Also, fixes missing Digest ""utf8"" parameter in config dump.",119,data/crawl/squid/hunk_1374.cpp,,,data/crawl/squid/old_hunk_1374.cpp,data/crawl/squid/new_hunk_1374.cpp,14,9,"storeAppendPrintf(entry, ""\n%s %s keep_alive %s\n"", name, ""negotiate"", keep_alive ? ""on"" : ""off"");","storeAppendPrintf(entry, ""%s negotiate keep_alive %s\n"", name, keep_alive ? ""on"" : ""off"");","[""updateContent"", ""removeContent""]","[[""\\n%s""], []]",[5161623540654415274],5910,0.0,2
https://github.com/squid-cache/squid/commit/d1f3d8f885784c89a822c35ddf6537aab3a3b925,06 Aug 2014,merge from trunk r13526,34418,data/crawl/squid/hunk_1298.cpp,,,data/crawl/squid/old_hunk_1298.cpp,data/crawl/squid/new_hunk_1298.cpp,9,9,"storeAppendPrintf(sentry,""Service Name: %s\n"", service_name);",SQUIDSBUFPRINT(service_name);,"[""updateLog"", ""removeVariable"", ""removeContent""]","[[""storeAppendPrintf"", ""sentry"", ""Service"", ""Name"", ""%s\\n""], [""SQUIDSBUFPRINT""]]",[-13055689665980448312],5909,16560.0,2
https://github.com/squid-cache/squid/commit/d1f3d8f885784c89a822c35ddf6537aab3a3b925,06 Aug 2014,merge from trunk r13526,34418,data/crawl/squid/hunk_1298.cpp,,,data/crawl/squid/old_hunk_1298.cpp,data/crawl/squid/new_hunk_1298.cpp,3,3,"storeAppendPrintf(sentry,""\nRunning as %s Windows System Service on %s\n"",
                          Service_name, WIN32_OS_string);","storeAppendPrintf(sentry,""\nRunning as "" SQUIDSBUFPH "" Windows System Service on %s\n"",
                          SQUIDBUFPRINT(service_name), WIN32_OS_string);","[""updateVariable"", ""addContent"", ""updateContent"", ""addVariable""]","[[""%s"", ""Service_name""], [""SQUIDSBUFPH"", ""SQUIDBUFPRINT"", ""service_name""]]",[13138555306269701660],5908,16560.0,2
https://github.com/squid-cache/squid/commit/d1f3d8f885784c89a822c35ddf6537aab3a3b925,06 Aug 2014,merge from trunk r13526,34418,data/crawl/squid/hunk_1296.cpp,,,data/crawl/squid/old_hunk_1296.cpp,data/crawl/squid/new_hunk_1296.cpp,3,3,"printf(""Service Name: %s\n"", service_name);",SQUIDSBUFPRINT(service_name);,"[""updateLog"", ""removeContent""]","[[""printf"", ""Service"", ""Name"", ""%s\\n""], [""SQUIDSBUFPRINT""]]",[-14224284335821252037],5907,16560.0,2
https://github.com/squid-cache/squid/commit/d1f3d8f885784c89a822c35ddf6537aab3a3b925,06 Aug 2014,merge from trunk r13526,34418,data/crawl/squid/hunk_1295.cpp,,,data/crawl/squid/old_hunk_1295.cpp,data/crawl/squid/new_hunk_1295.cpp,-1,13,,"fatal(""A service name is required for the -n option"");","[""addLog""]","[[], [""fatal"", ""A"", ""service"", ""name"", ""is"", ""required"", ""for"", ""the"", ""n"", ""option""]]",[-16682936928836781457],5906,16560.0,2
https://github.com/squid-cache/squid/commit/d1f3d8f885784c89a822c35ddf6537aab3a3b925,06 Aug 2014,merge from trunk r13526,34418,data/crawl/squid/hunk_1295.cpp,,,data/crawl/squid/old_hunk_1295.cpp,data/crawl/squid/new_hunk_1295.cpp,-1,10,,"fatalf(""Service name (-n option) must be limited to 32 characters but got %u"", service_name.length());","[""addLog""]","[[], [""fatalf"", ""Service"", ""name"", ""n"", ""option"", ""must"", ""be"", ""limited"", ""to"", ""32"", ""characters"", ""but"", ""got"", ""%u"", ""service_name"", ""length""]]",[10065668742628401412],5905,16560.0,2
https://github.com/squid-cache/squid/commit/d1f3d8f885784c89a822c35ddf6537aab3a3b925,06 Aug 2014,merge from trunk r13526,34418,data/crawl/squid/hunk_1295.cpp,,,data/crawl/squid/old_hunk_1295.cpp,data/crawl/squid/new_hunk_1295.cpp,-1,8,,"fatalf(""Expected alphanumeric service name for the -n option but got: "" SQUIDSBUFPH, SQUIDSBUFPRINT(service_name));","[""addLog""]","[[], [""fatalf"", ""Expected"", ""alphanumeric"", ""service"", ""name"", ""for"", ""the"", ""n"", ""option"", ""but"", ""got"", ""SQUIDSBUFPH"", ""SQUIDSBUFPRINT"", ""service_name""]]",[20872305973606847936],5904,16560.0,2
https://github.com/squid-cache/squid/commit/d1f3d8f885784c89a822c35ddf6537aab3a3b925,06 Aug 2014,merge from trunk r13526,34418,data/crawl/squid/hunk_1291.cpp,,,data/crawl/squid/old_hunk_1291.cpp,data/crawl/squid/new_hunk_1291.cpp,7,-1,"storeAppendPrintf(entry, ""%s %s"", name, ""ntlm"");",,"[""removeLog""]","[[""storeAppendPrintf"", ""entry"", ""%s"", ""%s"", ""name"", ""ntlm""], []]",[4410757366150936668],5903,48240.0,2
https://github.com/squid-cache/squid/commit/d1f3d8f885784c89a822c35ddf6537aab3a3b925,06 Aug 2014,merge from trunk r13526,34418,data/crawl/squid/hunk_1290.cpp,,,data/crawl/squid/old_hunk_1290.cpp,data/crawl/squid/new_hunk_1290.cpp,16,9,"storeAppendPrintf(entry, ""%s %s keep_alive %s\n"", name, ""negotiate"", keep_alive ? ""on"" : ""off"");","storeAppendPrintf(entry, ""%s negotiate keep_alive %s\n"", name, keep_alive ? ""on"" : ""off"");","[""updateContent"", ""removeContent""]","[[""%s""], []]",[-4736028453042782],5902,0.0,2
https://github.com/squid-cache/squid/commit/d1f3d8f885784c89a822c35ddf6537aab3a3b925,06 Aug 2014,merge from trunk r13526,34418,data/crawl/squid/hunk_1290.cpp,,,data/crawl/squid/old_hunk_1290.cpp,data/crawl/squid/new_hunk_1290.cpp,7,-1,"storeAppendPrintf(entry, ""%s %s"", name, ""negotiate"");",,"[""removeLog""]","[[""storeAppendPrintf"", ""entry"", ""%s"", ""%s"", ""name"", ""negotiate""], []]",[3575485793157778682],5901,48240.0,2
https://github.com/squid-cache/squid/commit/d1f3d8f885784c89a822c35ddf6537aab3a3b925,06 Aug 2014,merge from trunk r13526,34418,data/crawl/squid/hunk_1289.cpp,,,data/crawl/squid/old_hunk_1289.cpp,data/crawl/squid/new_hunk_1289.cpp,8,8,"httpHeaderPutStrf(&rep->header, hdrType, ""Digest realm=\""%s\"", nonce=\""%s\"", qop=\""%s\"", stale=%s"", digestAuthRealm, authenticateDigestNonceNonceb64(nonce), QOP_AUTH, stale ? ""true"" : ""false"");","httpHeaderPutStrf(&rep->header, hdrType, ""Digest realm=\"""" SQUIDSBUFPH ""\"", nonce=\""%s\"", qop=\""%s\"", stale=%s"",
                      SQUIDSBUFPRINT(realm), authenticateDigestNonceNonceb64(nonce), QOP_AUTH, stale ? ""true"" : ""false"");","[""updateVariable"", ""addContent"", ""updateContent"", ""addVariable""]","[[""%s\\"", ""digestAuthRealm""], [""SQUIDSBUFPH"", ""\\"", ""SQUIDSBUFPRINT"", ""realm""]]",[-2228081973403018496],5900,48240.0,2
https://github.com/squid-cache/squid/commit/d1f3d8f885784c89a822c35ddf6537aab3a3b925,06 Aug 2014,merge from trunk r13526,34418,data/crawl/squid/hunk_1288.cpp,,,data/crawl/squid/old_hunk_1288.cpp,data/crawl/squid/new_hunk_1288.cpp,8,13,"storeAppendPrintf(entry, ""%s %s"", name, ""digest"");","storeAppendPrintf(entry, ""%s digest utf8 %s\n"", name, utf8 ? ""on"" : ""off"");","[""moveContent"", ""updateContent"", ""addContent"", ""addVariable""]","[[""%s""], [""utf8"", ""%s\\n"", ""utf8"", ""on"", ""off""]]",[23226950631263767211],5899,48240.0,2
https://github.com/squid-cache/squid/commit/d1f3d8f885784c89a822c35ddf6537aab3a3b925,06 Aug 2014,merge from trunk r13526,34418,data/crawl/squid/hunk_1287.cpp,,,data/crawl/squid/old_hunk_1287.cpp,data/crawl/squid/new_hunk_1287.cpp,12,-1,"storeAppendPrintf(entry, ""%s %s"", name, ""basic"");",,"[""removeLog""]","[[""storeAppendPrintf"", ""entry"", ""%s"", ""%s"", ""name"", ""basic""], []]",[8766986006470311312],5898,48240.0,2
https://github.com/squid-cache/squid/commit/d1f3d8f885784c89a822c35ddf6537aab3a3b925,06 Aug 2014,merge from trunk r13526,34418,data/crawl/squid/hunk_1286.cpp,,,data/crawl/squid/old_hunk_1286.cpp,data/crawl/squid/new_hunk_1286.cpp,4,4,"httpHeaderPutStrf(&rep->header, hdrType, ""Basic realm=\""%s\"""", basicAuthRealm);","httpHeaderPutStrf(&rep->header, hdrType, ""Basic realm=\"""" SQUIDSBUFPH ""\"""", SQUIDSBUFPRINT(realm));","[""updateVariable"", ""updateContent"", ""addContent"", ""addVariable""]","[[""%s\\"", ""basicAuthRealm""], [""SQUIDSBUFPH"", ""\\"", ""SQUIDSBUFPRINT"", ""realm""]]",[-1986401751729014183],5897,48240.0,2
https://github.com/squid-cache/squid/commit/d1f3d8f885784c89a822c35ddf6537aab3a3b925,06 Aug 2014,merge from trunk r13526,34418,data/crawl/squid/hunk_1285.cpp,,,data/crawl/squid/old_hunk_1285.cpp,data/crawl/squid/new_hunk_1285.cpp,-1,17,,"storeAppendPrintf(entry, ""%s %s realm "" SQUIDSBUFPH ""\n"", name, scheme->type(), SQUIDSBUFPRINT(realm));","[""addLog""]","[[], [""storeAppendPrintf"", ""entry"", ""%s"", ""%s"", ""realm"", ""SQUIDSBUFPH"", ""\\n"", ""name"", ""scheme"", ""type"", ""SQUIDSBUFPRINT"", ""realm""]]",[-11146865452651975138],5896,48240.0,2
https://github.com/squid-cache/squid/commit/d1f3d8f885784c89a822c35ddf6537aab3a3b925,06 Aug 2014,merge from trunk r13526,34418,data/crawl/squid/hunk_1285.cpp,,,data/crawl/squid/old_hunk_1285.cpp,data/crawl/squid/new_hunk_1285.cpp,-1,10,,"storeAppendPrintf(entry, ""%s %s"", name, scheme->type());","[""addLog""]","[[], [""storeAppendPrintf"", ""entry"", ""%s"", ""%s"", ""name"", ""scheme"", ""type""]]",[-2156865728530222672],5895,48240.0,2
https://github.com/squid-cache/squid/commit/d1f3d8f885784c89a822c35ddf6537aab3a3b925,06 Aug 2014,merge from trunk r13526,34418,data/crawl/squid/hunk_1283.cpp,,,data/crawl/squid/old_hunk_1283.cpp,data/crawl/squid/new_hunk_1283.cpp,20,20,"printf(""\nStatus of %s Service:\n"", service_name);","printf(""\nStatus of "" SQUIDSBUFPH "" Service:\n"", SQUIDSBUFPRINT(service_name));","[""addLog"", ""updateLog"", ""addContent"", ""removeContent"", ""addVariable""]","[[""%s""], [""SQUIDSBUFPH"", ""SQUIDSBUFPRINT""]]",[4754650398254255184],5894,16560.0,2
https://github.com/squid-cache/squid/commit/d1f3d8f885784c89a822c35ddf6537aab3a3b925,06 Aug 2014,merge from trunk r13526,34418,data/crawl/squid/hunk_1282.cpp,,,data/crawl/squid/old_hunk_1282.cpp,data/crawl/squid/new_hunk_1282.cpp,3,3,"printf(""installed successfully as %s Windows System Service.\n"", service_name);",SQUIDSBUFPRINT(service_name);,"[""updateLog"", ""removeContent""]","[[""printf"", ""installed"", ""successfully"", ""as"", ""%s"", ""Windows"", ""System"", ""Service"", ""\\n""], [""SQUIDSBUFPRINT""]]",[-9837387723153645253],5893,16560.0,2
https://github.com/squid-cache/squid/commit/d1f3d8f885784c89a822c35ddf6537aab3a3b925,06 Aug 2014,merge from trunk r13526,34418,data/crawl/squid/hunk_1280.cpp,,,data/crawl/squid/old_hunk_1280.cpp,data/crawl/squid/new_hunk_1280.cpp,3,3,"printf(""Service %s deleted successfully.\n"", service_name);",SQUIDSBUFPRINT(service_name);,"[""updateLog"", ""removeContent""]","[[""printf"", ""Service"", ""%s"", ""deleted"", ""successfully"", ""\\n""], [""SQUIDSBUFPRINT""]]",[-13789856951412544727],5892,16560.0,2
https://github.com/squid-cache/squid/commit/d1f3d8f885784c89a822c35ddf6537aab3a3b925,06 Aug 2014,merge from trunk r13526,34418,data/crawl/squid/hunk_1277.cpp,,,data/crawl/squid/old_hunk_1277.cpp,data/crawl/squid/new_hunk_1277.cpp,35,-1,"fprintf(stderr, ""Could not find User-Agent\n"");",,"[""removeLog""]","[[""fprintf"", ""stderr"", ""Could"", ""not"", ""find"", ""User"", ""Agent\\n""], []]",[-10512210024886632924],5891,28800.0,2
https://github.com/squid-cache/squid/commit/d1f3d8f885784c89a822c35ddf6537aab3a3b925,06 Aug 2014,merge from trunk r13526,34418,data/crawl/squid/hunk_1277.cpp,,,data/crawl/squid/old_hunk_1277.cpp,data/crawl/squid/new_hunk_1277.cpp,31,-1,"fprintf(stderr, ""Could add duplicate User-Agent\n"");",,"[""removeLog""]","[[""fprintf"", ""stderr"", ""Could"", ""add"", ""duplicate"", ""User"", ""Agent\\n""], []]",[-13909107325841701579],5890,28800.0,2
https://github.com/squid-cache/squid/commit/d1f3d8f885784c89a822c35ddf6537aab3a3b925,06 Aug 2014,merge from trunk r13526,34418,data/crawl/squid/hunk_1277.cpp,,,data/crawl/squid/old_hunk_1277.cpp,data/crawl/squid/new_hunk_1277.cpp,27,-1,"fprintf(stderr,""Could not add User-Agent\n"");",,"[""removeLog""]","[[""fprintf"", ""stderr"", ""Could"", ""not"", ""add"", ""User"", ""Agent\\n""], []]",[-12474821137430514673],5889,28800.0,2
https://github.com/squid-cache/squid/commit/d1f3d8f885784c89a822c35ddf6537aab3a3b925,06 Aug 2014,merge from trunk r13526,34418,data/crawl/squid/hunk_1276.cpp,,,data/crawl/squid/old_hunk_1276.cpp,data/crawl/squid/new_hunk_1276.cpp,-1,14,,"fprintf(stdout, ""OK user=\""%s\\%s\"""", domain, user);","[""addLog""]","[[], [""fprintf"", ""stdout"", ""OK"", ""user"", ""\\"", ""%s\\\\%s\\"", ""domain"", ""user""]]",[13789755347171303691],5888,17280.0,2
https://github.com/squid-cache/squid/commit/d1f3d8f885784c89a822c35ddf6537aab3a3b925,06 Aug 2014,merge from trunk r13526,34418,data/crawl/squid/hunk_1275.cpp,,,data/crawl/squid/old_hunk_1275.cpp,data/crawl/squid/new_hunk_1275.cpp,24,24,"printf(""TT %s\n"",c);",SEND_TT(c);,"[""updateLog"", ""removeContent""]","[[""printf"", ""TT"", ""%s\\n""], [""SEND_TT""]]",[-15507664015351607101],5887,17280.0,2
https://github.com/squid-cache/squid/commit/1ab04517e705e2aaa2afc9d45bb3dcb45e6030da,07 Aug 2014,"Converted some of the new FTP code to use SBuf and Tokenizer
instead of MemBuf, String, and c-string manipulations.",496,data/crawl/squid/hunk_1268.cpp,,,data/crawl/squid/old_hunk_1268.cpp,data/crawl/squid/new_hunk_1268.cpp,26,27,"request->header.putStr(HDR_FTP_COMMAND, cmd.termedBuf());","request->header.putStr(HDR_FTP_COMMAND, cmd.c_str());","[""updateVariable""]","[[""termedBuf""], [""c_str""]]",[-6334456970231064875],5886,1440.0,2
https://github.com/squid-cache/squid/commit/1ab04517e705e2aaa2afc9d45bb3dcb45e6030da,07 Aug 2014,"Converted some of the new FTP code to use SBuf and Tokenizer
instead of MemBuf, String, and c-string manipulations.",496,data/crawl/squid/hunk_1267.cpp,,,data/crawl/squid/old_hunk_1267.cpp,data/crawl/squid/new_hunk_1267.cpp,6,5,"mb.Printf(""%s %s%s"", cmd.termedBuf(), params.termedBuf(), Ftp::crlf);","buf.Printf(""%s %s%s"", cmd.termedBuf(), params.termedBuf(), Ftp::crlf);","[""updateLog""]","[[""mb""], [""buf""]]",[313072133005114869],5885,0.0,2
https://github.com/squid-cache/squid/commit/43446566e3092dc7969e72f22b6c1362a4701784,07 Aug 2014,"Fixed HttpHdr::Private/NoCache(v) implementations and optimized their API.

These calls now avoid assertions and extra trailing commas when called with
empty names. The API now allows calling with a String() object, but still
needs more polishing work.


Moved common code from Ftp::Server::setReply and Ftp::Relay::createHttpReply()
into Ftp::HttpReplyWrapper().


Also removed the last non-job callbak from Ftp::Client, polished and synced
new FTP comments with the modern client/server/gateway/relay terminology, as
well as minimized changes compared to trunk.",152,data/crawl/squid/hunk_1266.cpp,,,data/crawl/squid/old_hunk_1266.cpp,data/crawl/squid/new_hunk_1266.cpp,14,-1,"header.putStr(HDR_FTP_REASON, msg);",,"[""removeLog""]","[[""header"", ""putStr"", ""HDR_FTP_REASON"", ""msg""], []]",[-4605338337015075621],5884,2160.0,2
https://github.com/squid-cache/squid/commit/1689cdbc1355cd1281cd3bdc791c1b13cec462fe,12 Aug 2014,Performance optimizations and polish,92,data/crawl/squid/hunk_1233.cpp,,,data/crawl/squid/old_hunk_1233.cpp,data/crawl/squid/new_hunk_1233.cpp,-1,21,,"proxyProtocolError(tok.atEnd() ? ""PROXY/1.0 error: invalid protocol family"" : NULL);","[""addLog""]","[[], [""proxyProtocolError"", ""tok"", ""atEnd"", ""PROXY/1"", ""0"", ""error"", ""invalid"", ""protocol"", ""family"", ""NULL""]]",[-6411332611857061514],5883,22320.0,2
https://github.com/squid-cache/squid/commit/154ea56667e82cf7217580817f9088397a86a694,13 Aug 2014,"Rearrange PROXY/1.0 parser

Add a first pass to confirm LF line terminator and wait for more bytes if
missing.",46,data/crawl/squid/hunk_1231.cpp,,,data/crawl/squid/old_hunk_1231.cpp,data/crawl/squid/new_hunk_1231.cpp,16,-1,"proxyProtocolError(in.buf.length() > 107? ""PROXY/1.0 error: missing CRLF"":NULL);",,"[""removeLog""]","[[""proxyProtocolError"", ""in"", ""buf"", ""length"", ""107"", ""PROXY/1"", ""0"", ""error"", ""missing"", ""CRLF"", ""NULL""], []]",[-27540090278766768736],5882,720.0,2
https://github.com/squid-cache/squid/commit/154ea56667e82cf7217580817f9088397a86a694,13 Aug 2014,"Rearrange PROXY/1.0 parser

Add a first pass to confirm LF line terminator and wait for more bytes if
missing.",46,data/crawl/squid/hunk_1231.cpp,,,data/crawl/squid/old_hunk_1231.cpp,data/crawl/squid/new_hunk_1231.cpp,7,-1,"proxyProtocolError(""PROXY/1.0 error: missing CR"");",,"[""removeLog""]","[[""proxyProtocolError"", ""PROXY/1"", ""0"", ""error"", ""missing"", ""CR""], []]",[-18111147772876735559],5881,720.0,2
https://github.com/squid-cache/squid/commit/c6649f6c62f90053f0bf0f162918a94f1d763b3d,26 Aug 2014,merge from trunk,14018,data/crawl/squid/hunk_1212.cpp,,,data/crawl/squid/old_hunk_1212.cpp,data/crawl/squid/new_hunk_1212.cpp,-1,722,,"request->header.putStr(HDR_FTP_ARGUMENTS, params.c_str());","[""addLog""]","[[], [""request"", ""header"", ""putStr"", ""HDR_FTP_ARGUMENTS"", ""params"", ""c_str""]]",[-12891989420141091774],5880,10800.0,2
https://github.com/squid-cache/squid/commit/c6649f6c62f90053f0bf0f162918a94f1d763b3d,26 Aug 2014,merge from trunk,14018,data/crawl/squid/hunk_1212.cpp,,,data/crawl/squid/old_hunk_1212.cpp,data/crawl/squid/new_hunk_1212.cpp,-1,721,,"request->header.putStr(HDR_FTP_COMMAND, cmd.c_str());","[""addLog""]","[[], [""request"", ""header"", ""putStr"", ""HDR_FTP_COMMAND"", ""cmd"", ""c_str""]]",[-4887081017303346744],5879,10800.0,2
https://github.com/squid-cache/squid/commit/c6649f6c62f90053f0bf0f162918a94f1d763b3d,26 Aug 2014,merge from trunk,14018,data/crawl/squid/hunk_1212.cpp,,,data/crawl/squid/old_hunk_1212.cpp,data/crawl/squid/new_hunk_1212.cpp,-1,596,,abortRequestParsing(errUri);,"[""addLog""]","[[], [""abortRequestParsing"", ""errUri""]]",[-615668499119407073],5878,5040.0,2
https://github.com/squid-cache/squid/commit/c6649f6c62f90053f0bf0f162918a94f1d763b3d,26 Aug 2014,merge from trunk,14018,data/crawl/squid/hunk_1211.cpp,,,data/crawl/squid/old_hunk_1211.cpp,data/crawl/squid/new_hunk_1211.cpp,-1,6,,"fatalf(""Garbage after alphanumeric service name in the -n option value: %s"", optarg);","[""addLog""]","[[], [""fatalf"", ""Garbage"", ""after"", ""alphanumeric"", ""service"", ""name"", ""in"", ""the"", ""n"", ""option"", ""value"", ""%s"", ""optarg""]]",[-11702706294966760169],5877,10800.0,2
https://github.com/squid-cache/squid/commit/c6649f6c62f90053f0bf0f162918a94f1d763b3d,26 Aug 2014,merge from trunk,14018,data/crawl/squid/hunk_1211.cpp,,,data/crawl/squid/old_hunk_1211.cpp,data/crawl/squid/new_hunk_1211.cpp,4,4,"fatalf(""Expected alphanumeric service name for the -n option but got: "" SQUIDSBUFPH, SQUIDSBUFPRINT(service_name));","fatalf(""Expected alphanumeric service name for the -n option but got: %s"", optarg);","[""updateVariable"", ""removeVariable"", ""updateContent""]","[[""SQUIDSBUFPH"", ""SQUIDSBUFPRINT"", ""service_name""], [""%s"", ""optarg""]]",[-10851372947184613018],5876,10800.0,2
https://github.com/squid-cache/squid/commit/c6649f6c62f90053f0bf0f162918a94f1d763b3d,26 Aug 2014,merge from trunk,14018,data/crawl/squid/hunk_1207.cpp,,,data/crawl/squid/old_hunk_1207.cpp,data/crawl/squid/new_hunk_1207.cpp,-1,498,,"buf.Printf(""%s%s"", cmd.termedBuf(), Ftp::crlf);","[""addLog""]","[[], [""buf"", ""Printf"", ""%s%s"", ""cmd"", ""termedBuf"", ""Ftp"", ""crlf""]]",[21145089189143264005],5875,10800.0,2
https://github.com/squid-cache/squid/commit/c6649f6c62f90053f0bf0f162918a94f1d763b3d,26 Aug 2014,merge from trunk,14018,data/crawl/squid/hunk_1207.cpp,,,data/crawl/squid/old_hunk_1207.cpp,data/crawl/squid/new_hunk_1207.cpp,-1,496,,"buf.Printf(""%s %s%s"", cmd.termedBuf(), params.termedBuf(), Ftp::crlf);","[""addLog""]","[[], [""buf"", ""Printf"", ""%s"", ""%s%s"", ""cmd"", ""termedBuf"", ""params"", ""termedBuf"", ""Ftp"", ""crlf""]]",[24129078830910212260],5874,10800.0,2
https://github.com/squid-cache/squid/commit/c6649f6c62f90053f0bf0f162918a94f1d763b3d,26 Aug 2014,merge from trunk,14018,data/crawl/squid/hunk_1207.cpp,,,data/crawl/squid/old_hunk_1207.cpp,data/crawl/squid/new_hunk_1207.cpp,-1,471,,"abortTransaction(""Internal error: FTP relay request with no command"");","[""addLog""]","[[], [""abortTransaction"", ""Internal"", ""error"", ""FTP"", ""relay"", ""request"", ""with"", ""no"", ""command""]]",[-15627042902845683154],5873,10800.0,2
https://github.com/squid-cache/squid/commit/c6649f6c62f90053f0bf0f162918a94f1d763b3d,26 Aug 2014,merge from trunk,14018,data/crawl/squid/hunk_1207.cpp,,,data/crawl/squid/old_hunk_1207.cpp,data/crawl/squid/new_hunk_1207.cpp,-1,393,,"reply->header.putStr(HDR_FTP_PRE, httpHeaderQuoteString(W->key).c_str());","[""addLog""]","[[], [""reply"", ""header"", ""putStr"", ""HDR_FTP_PRE"", ""httpHeaderQuoteString"", ""W"", ""key"", ""c_str""]]",[-11322583016474365019],5872,10800.0,2
https://github.com/squid-cache/squid/commit/c6649f6c62f90053f0bf0f162918a94f1d763b3d,26 Aug 2014,merge from trunk,14018,data/crawl/squid/hunk_1206.cpp,,,data/crawl/squid/old_hunk_1206.cpp,data/crawl/squid/new_hunk_1206.cpp,20,-1,"mustStop(""FtpStateData::abortTransaction"");",,"[""removeLog""]","[[""mustStop"", ""FtpStateData"", ""abortTransaction""], []]",[11011187553986895606],5871,10800.0,2
https://github.com/squid-cache/squid/commit/c6649f6c62f90053f0bf0f162918a94f1d763b3d,26 Aug 2014,merge from trunk,14018,data/crawl/squid/hunk_1205.cpp,,,data/crawl/squid/old_hunk_1205.cpp,data/crawl/squid/new_hunk_1205.cpp,265,-1,"abortTransaction(""zero control reply read"");",,"[""removeLog""]","[[""abortTransaction"", ""zero"", ""control"", ""reply"", ""read""], []]",[15868666021114446515],5870,10800.0,2
https://github.com/squid-cache/squid/commit/c6649f6c62f90053f0bf0f162918a94f1d763b3d,26 Aug 2014,merge from trunk,14018,data/crawl/squid/hunk_1205.cpp,,,data/crawl/squid/old_hunk_1205.cpp,data/crawl/squid/new_hunk_1205.cpp,234,-1,"abortTransaction(""entry aborted during control reply read"");",,"[""removeLog""]","[[""abortTransaction"", ""entry"", ""aborted"", ""during"", ""control"", ""reply"", ""read""], []]",[29038949042844960413],5869,10800.0,2
https://github.com/squid-cache/squid/commit/c6649f6c62f90053f0bf0f162918a94f1d763b3d,26 Aug 2014,merge from trunk,14018,data/crawl/squid/hunk_1204.cpp,,,data/crawl/squid/old_hunk_1204.cpp,data/crawl/squid/new_hunk_1204.cpp,90,-1,"abortTransaction(""entry aborted during dataRead"");",,"[""removeLog""]","[[""abortTransaction"", ""entry"", ""aborted"", ""during"", ""dataRead""], []]",[14041970511130099506],5868,10800.0,2
https://github.com/squid-cache/squid/commit/c6649f6c62f90053f0bf0f162918a94f1d763b3d,26 Aug 2014,merge from trunk,14018,data/crawl/squid/hunk_1203.cpp,,,data/crawl/squid/old_hunk_1203.cpp,data/crawl/squid/new_hunk_1203.cpp,7,-1,"(abortOnBadEntry(""entry went bad while waiting for a timeout"");",,"[""removeLog""]","[[""abortOnBadEntry"", ""entry"", ""went"", ""bad"", ""while"", ""waiting"", ""for"", ""a"", ""timeout""], []]",[6015737064028494462],5867,10800.0,2
https://github.com/squid-cache/squid/commit/c6649f6c62f90053f0bf0f162918a94f1d763b3d,26 Aug 2014,merge from trunk,14018,data/crawl/squid/hunk_1202.cpp,,,data/crawl/squid/old_hunk_1202.cpp,data/crawl/squid/new_hunk_1202.cpp,12,-1,"mustStop(""FtpStateData::ctrlClosed"");",,"[""removeLog""]","[[""mustStop"", ""FtpStateData"", ""ctrlClosed""], []]",[6481123461370255207],5866,10800.0,2
https://github.com/squid-cache/squid/commit/c6649f6c62f90053f0bf0f162918a94f1d763b3d,26 Aug 2014,merge from trunk,14018,data/crawl/squid/hunk_1199.cpp,,,data/crawl/squid/old_hunk_1199.cpp,data/crawl/squid/new_hunk_1199.cpp,-1,994,,"mustStop(""Ftp::Client::abortTransaction"");","[""addLog""]","[[], [""mustStop"", ""Ftp"", ""Client"", ""abortTransaction""]]",[-15200642082246892159],5865,10800.0,2
https://github.com/squid-cache/squid/commit/c6649f6c62f90053f0bf0f162918a94f1d763b3d,26 Aug 2014,merge from trunk,14018,data/crawl/squid/hunk_1199.cpp,,,data/crawl/squid/old_hunk_1199.cpp,data/crawl/squid/new_hunk_1199.cpp,-1,825,,"mustStop(""Ftp::Client::ctrlClosed"");","[""addLog""]","[[], [""mustStop"", ""Ftp"", ""Client"", ""ctrlClosed""]]",[-10670577989630251760],5864,10800.0,2
https://github.com/squid-cache/squid/commit/c6649f6c62f90053f0bf0f162918a94f1d763b3d,26 Aug 2014,merge from trunk,14018,data/crawl/squid/hunk_1199.cpp,,,data/crawl/squid/old_hunk_1199.cpp,data/crawl/squid/new_hunk_1199.cpp,-1,337,,"abortTransaction(""entry aborted during control reply read"");","[""addLog""]","[[], [""abortTransaction"", ""entry"", ""aborted"", ""during"", ""control"", ""reply"", ""read""]]",[-29038949042844960413],5863,10800.0,2
https://github.com/squid-cache/squid/commit/c6649f6c62f90053f0bf0f162918a94f1d763b3d,26 Aug 2014,merge from trunk,14018,data/crawl/squid/hunk_1196.cpp,,,data/crawl/squid/old_hunk_1196.cpp,data/crawl/squid/new_hunk_1196.cpp,5,6,"fatal(""No HTTP or HTTPS ports configured"");","fatal(""No HTTP, HTTPS, or FTP ports configured"");","[""updateContent""]","[[], [""FTP""]]",[-4177197833218190687],5862,10800.0,2
https://github.com/squid-cache/squid/commit/c6649f6c62f90053f0bf0f162918a94f1d763b3d,26 Aug 2014,merge from trunk,14018,data/crawl/squid/hunk_1194.cpp,,,data/crawl/squid/old_hunk_1194.cpp,data/crawl/squid/new_hunk_1194.cpp,-1,10,,"csd->abortRequestParsing(""error:unsupported-request-method"");","[""addLog""]","[[], [""csd"", ""abortRequestParsing"", ""error"", ""unsupported"", ""request"", ""method""]]",[192712572626876571],5861,5040.0,2
https://github.com/squid-cache/squid/commit/c6649f6c62f90053f0bf0f162918a94f1d763b3d,26 Aug 2014,merge from trunk,14018,data/crawl/squid/hunk_1192.cpp,,,data/crawl/squid/old_hunk_1192.cpp,data/crawl/squid/new_hunk_1192.cpp,-1,3,,"csd->abortRequestParsing(""error:invalid-request"");","[""addLog""]","[[], [""csd"", ""abortRequestParsing"", ""error"", ""invalid"", ""request""]]",[3826909698557543550],5860,5040.0,2
https://github.com/squid-cache/squid/commit/c6649f6c62f90053f0bf0f162918a94f1d763b3d,26 Aug 2014,merge from trunk,14018,data/crawl/squid/hunk_1190.cpp,,,data/crawl/squid/old_hunk_1190.cpp,data/crawl/squid/new_hunk_1190.cpp,-1,3,,"conn->abortRequestParsing(""error:invalid-request"");","[""addLog""]","[[], [""conn"", ""abortRequestParsing"", ""error"", ""invalid"", ""request""]]",[10099321292482107507],5859,5040.0,2
https://github.com/squid-cache/squid/commit/6e96d41538a60ced489d2d3e226117768d0ceaba,02 Sep 2014,"Support receiving PROXY protocol version 1 and 2.

PROXY protocol has been developed by Willy Tarreau of HAProxy for
communicating original src and dst IP:port details between proxies and
load balancers in a protocol-agnostic way.

stunnel, HAProxy and some other HTTP proxying software are already
enabled and by adding support to Squid we can effectively chain these
proxies without having to rely on X-Forwarded-For headers.

This patch adds http_port mode flag (require-proxy-header) to signal the
protocol is in use, parsing and processing logics for the PROXY protocol
headers on new connections, and the proxy_protocol_access control to
manage inbound connections.
 The indirect client security/trust model remains unchanged. As do all
HTTP related logics on the connection once PROXY protocol header has
been received.


Furture Work:
 * support sending PROXY protocol to cache_peers
 * support receiving PROXY protocol on https_port
 * rework the PROXY parse logics as a Parser-NG child parser.",1337,data/crawl/squid/hunk_1181.cpp,,,data/crawl/squid/old_hunk_1181.cpp,data/crawl/squid/new_hunk_1181.cpp,-1,140,,"proxyProtocolError(""PROXY/1.0 error: invalid dst-IP address"");","[""addLog""]","[[], [""proxyProtocolError"", ""PROXY/1"", ""0"", ""error"", ""invalid"", ""dst"", ""IP"", ""address""]]",[-5151170607502140641],5858,37440.0,2
https://github.com/squid-cache/squid/commit/6e96d41538a60ced489d2d3e226117768d0ceaba,02 Sep 2014,"Support receiving PROXY protocol version 1 and 2.

PROXY protocol has been developed by Willy Tarreau of HAProxy for
communicating original src and dst IP:port details between proxies and
load balancers in a protocol-agnostic way.

stunnel, HAProxy and some other HTTP proxying software are already
enabled and by adding support to Squid we can effectively chain these
proxies without having to rely on X-Forwarded-For headers.

This patch adds http_port mode flag (require-proxy-header) to signal the
protocol is in use, parsing and processing logics for the PROXY protocol
headers on new connections, and the proxy_protocol_access control to
manage inbound connections.
 The indirect client security/trust model remains unchanged. As do all
HTTP related logics on the connection once PROXY protocol header has
been received.


Furture Work:
 * support sending PROXY protocol to cache_peers
 * support receiving PROXY protocol on https_port
 * rework the PROXY parse logics as a Parser-NG child parser.",1337,data/crawl/squid/hunk_1181.cpp,,,data/crawl/squid/old_hunk_1181.cpp,data/crawl/squid/new_hunk_1181.cpp,-1,74,,"proxyProtocolError(""PROXY protocol error: invalid header"");","[""addLog""]","[[], [""proxyProtocolError"", ""PROXY"", ""protocol"", ""error"", ""invalid"", ""header""]]",[3080275356647560419],5857,37440.0,2
https://github.com/squid-cache/squid/commit/6e96d41538a60ced489d2d3e226117768d0ceaba,02 Sep 2014,"Support receiving PROXY protocol version 1 and 2.

PROXY protocol has been developed by Willy Tarreau of HAProxy for
communicating original src and dst IP:port details between proxies and
load balancers in a protocol-agnostic way.

stunnel, HAProxy and some other HTTP proxying software are already
enabled and by adding support to Squid we can effectively chain these
proxies without having to rely on X-Forwarded-For headers.

This patch adds http_port mode flag (require-proxy-header) to signal the
protocol is in use, parsing and processing logics for the PROXY protocol
headers on new connections, and the proxy_protocol_access control to
manage inbound connections.
 The indirect client security/trust model remains unchanged. As do all
HTTP related logics on the connection once PROXY protocol header has
been received.


Furture Work:
 * support sending PROXY protocol to cache_peers
 * support receiving PROXY protocol on https_port
 * rework the PROXY parse logics as a Parser-NG child parser.",1337,data/crawl/squid/hunk_1181.cpp,,,data/crawl/squid/old_hunk_1181.cpp,data/crawl/squid/new_hunk_1181.cpp,-1,42,,mustStop(msg);,"[""addLog""]","[[], [""mustStop"", ""msg""]]",[-2674481189511874069],5856,37440.0,2
https://github.com/squid-cache/squid/commit/6e96d41538a60ced489d2d3e226117768d0ceaba,02 Sep 2014,"Support receiving PROXY protocol version 1 and 2.

PROXY protocol has been developed by Willy Tarreau of HAProxy for
communicating original src and dst IP:port details between proxies and
load balancers in a protocol-agnostic way.

stunnel, HAProxy and some other HTTP proxying software are already
enabled and by adding support to Squid we can effectively chain these
proxies without having to rely on X-Forwarded-For headers.

This patch adds http_port mode flag (require-proxy-header) to signal the
protocol is in use, parsing and processing logics for the PROXY protocol
headers on new connections, and the proxy_protocol_access control to
manage inbound connections.
 The indirect client security/trust model remains unchanged. As do all
HTTP related logics on the connection once PROXY protocol header has
been received.


Furture Work:
 * support sending PROXY protocol to cache_peers
 * support receiving PROXY protocol on https_port
 * rework the PROXY parse logics as a Parser-NG child parser.",1337,data/crawl/squid/hunk_1181.cpp,,,data/crawl/squid/old_hunk_1181.cpp,data/crawl/squid/new_hunk_1181.cpp,-1,12,,"proxyProtocolError(""PROXY client not permitted by default ACL"");","[""addLog""]","[[], [""proxyProtocolError"", ""PROXY"", ""client"", ""not"", ""permitted"", ""by"", ""default"", ""ACL""]]",[24731452697702004997],5855,20160.0,2
https://github.com/squid-cache/squid/commit/2eb6054faf2503474cb500cdc4cb87aed073744b,29 Oct 2014,"negotiate_kerberos_auth: output group= kv-pair

Output group= if negotiate_kerberos_auth can retrieve AD groups from
Kerberos ticket for further processing by squid to external helpers.",24,data/crawl/squid/hunk_1169.cpp,,,data/crawl/squid/old_hunk_1169.cpp,data/crawl/squid/new_hunk_1169.cpp,7,11,"fprintf(stderr, ""%s| %s: INFO: User %s authenticated\n"", LogTime(),
                        PROGRAM, rfc1738_escape(user));","fprintf(stderr, ""%s| %s: INFO: User %s authenticated\n"", LogTime(),
                        PROGRAM, rfc_user);","[""updateVariable"", ""removeVariable""]","[[""rfc1738_escape"", ""user""], [""rfc_user""]]",[-13757836828617939792],5854,0.0,2
https://github.com/squid-cache/squid/commit/6825b101b1773a3f5abcdc00010cdbce03cb5d63,09 Nov 2014,"Make helper queue size configurable, with consistent defaults and better overflow handling.

This patch adds a queue-size=N option to helpers configuration. This
option allows users to configure the maximum number of queued requests
to busy helpers. We also adjusted the default queue size limits to be
more consistent across all helpers and made Squid more robust on some
queue overflows:

- external_acl helpers
    Make the maximum queue size configurable via queue-size.
    Default to 2*maximum-number-of-children.
    If the queue overflows, then the ACL returns ACCESS_DUNNO.

    Unpatched code uses the number of running children as the maximum
    queue size. If the queue is overloaded, then the ACL returns ACCESS_DUNNO.

-redirector/storeID helpers
    Make the maximum queue size configurable via queue-size.
    Default to 2*maximum-number-of-children.
    If the queue overflows and redirector_bypass configuration option
    is set, then redirector is bypassed. Otherwise, if overloading
    persists for more than 3 minutes squid quits with a FATAL message.
    If the redirector_bypass/storeID_bypass is set then the default queue_size
    is set to 0 for backward compatibility.

    Unpatched code uses 2*number-of-running-children as the maximum queue size.
    If the redirector_bypass/storeID_bypass is set then helper bypassed if all
    of the children are busy.
    If the queue is overloaded and redirector_bypass/storeID_bypass is not set
    then squid quits with a FATAL message.

- ssl_crtd/ssl_crtd_validator helpers.
    Make the maximum queue size configurable via queue-size.
    Default to 2*maximum-number-of-children.
    If the queue overflows, then helpers are bypassed. If overloading persists
    for more than 3 minutes squid quits with a FATAL message.

    The default size limit and overflow behavior has not changed.

- Authentication helpers
    Make the maximum queue size configurable via queue-size.
    Default to 2*maximum-number-of-children.
    If the queue overflows and overloading persists for more than 3 minutes,
    then squid quits with a FATAL message.

    The default size limit and overflow behavior has not changed.

This is a Measurement Factory project",321,data/crawl/squid/hunk_1157.cpp,,,data/crawl/squid/old_hunk_1157.cpp,data/crawl/squid/new_hunk_1157.cpp,5,-1,"fatalf(""Too many queued %s requests"", hlp->id_name);",,"[""removeLog""]","[[""fatalf"", ""Too"", ""many"", ""queued"", ""%s"", ""requests"", ""hlp"", ""id_name""], []]",[11959563550754262868],5853,0.0,2
https://github.com/squid-cache/squid/commit/685277d8fcb4ba6b1f1a66a634937764c31744d4,19 Dec 2014,"negotiate_kerberos_auth: MEMORY keytab and replay cache support

1) Checks for MEMORY: keytab support and reads the keytab from disk into
   MEMORY to improve performance (i.e. read keytab only at startup and
   nerver again)

2) Add option for replay cache type. Allows to set replay cache to none
   to improve performance ( may reduce security a bit )

3) Add option for replay cache directory.  If /var/tmp is not the best
   location you can choose a different location.",492,data/crawl/squid/hunk_1137.cpp,,,data/crawl/squid/old_hunk_1137.cpp,data/crawl/squid/new_hunk_1137.cpp,-1,35,,"fprintf(stderr, ""%s| %s: ERROR: %s: %s\n"", LogTime(), PROGRAM, function, errmsg);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""%s"", ""%s"", ""ERROR"", ""%s"", ""%s\\n"", ""LogTime"", ""PROGRAM"", ""function"", ""errmsg""]]",[-3629167607061028940],5852,322560.0,2
https://github.com/squid-cache/squid/commit/aadbbd7d080ef1662bfd7ea568edbb29f25fdd72,30 Dec 2014,"Crypto-NG: Base64 crypto replacement

The existing Squid base64 code had ambiguous copyright licensing. In
particular it only referenced a dead URL for source copyright
ownership details. In all likelihood this was for an Open Source
implementation, but we dont have sufficient record of the original
license terms to be certain without a long investigation.

It has also been heavily modified and customized over the decades
since importing whih complicates the issue a lot.

It also does not match any of the common industry context-based API
patterns for encoders/decoders.


This patch replaces that logic with GPLv2 licensed code from the
Nettle crypto library. Either linking the library dynamically or in
its absence embedding the logic via our libmiscencoding library.

It also updates all code to the new API, and as a byproduct removes
several layers of deprecated wrapper functions which have grown in
over the years.",839,data/crawl/squid/hunk_1096.cpp,,,data/crawl/squid/old_hunk_1096.cpp,data/crawl/squid/new_hunk_1096.cpp,-1,6,,"httpHeaderPutStrf(hdr_out, header, ""Basic %.*s"", blen, loginbuf);","[""addLog""]","[[], [""httpHeaderPutStrf"", ""hdr_out"", ""header"", ""Basic"", ""%"", ""*s"", ""blen"", ""loginbuf""]]",[-4607372450720250634],5851,0.0,2
https://github.com/squid-cache/squid/commit/836a7ffc27f7934243c8f54aaf95f157d99b1898,31 Dec 2014,ntlm_sspi_auth: convert to new base64 API,40,data/crawl/squid/hunk_1076.cpp,,,data/crawl/squid/old_hunk_1076.cpp,data/crawl/squid/new_hunk_1076.cpp,-1,11,,"fprintf(stderr, ""ERROR: base64 decoding failed for: '%s'\n"", buf);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""ERROR"", ""base64"", ""decoding"", ""failed"", ""for"", ""%s"", ""\\n"", ""buf""]]",[-18460778426510115996],5850,0.0,2
https://github.com/squid-cache/squid/commit/ced8def38409d2e3f76af4428a823678e46d24eb,01 Jan 2015,"Cleanup: fix most 'unused parameter' warnings

... and several bugs hidden by lack of this check:

* url_rewrite_timeout parser/dumper using wrong cf.data.pre
  parameter definition.

* url_rewrite_timeout parser/dumper using wrong object for
  state data.
  Global a Config object instead of parameter object.
  Preventing future use of multiple Config objects. There is
  more to be done as the Timeout value itself is not stored
  as part of the object apparently detailing the timeout.

* request_header_add directive dump() omitting directive
  name in mgr:config output.

* dead code as HTCP packet handlers for NOP, MON, SET

* mime icons download operation incorrectly initialized.
  was using the 'view' access parameter to set download
  access permission.

* peerCountHandleIcpReply() assertions testing validity
  after pointers already used. This would lead to segfault
  on errors, now leading to assertion logging.


Only the default built code was checked and updated at this
time. There are 62 known warnings still appearing due to
parameters being only used inside conditional code, possibly
more issues in code not enabled in this build and certainly
a lot more in the stubs and unit tests which were not checked.",786,data/crawl/squid/hunk_1067.cpp,,,data/crawl/squid/old_hunk_1067.cpp,data/crawl/squid/new_hunk_1067.cpp,40,40,"storeAppendPrintf(entry, "" on_timeout=%s"", onTimedOutActions[Config.onUrlRewriteTimeout.action]);","storeAppendPrintf(entry, "" on_timeout=%s"", onTimedOutActions[config.action]);","[""updateVariable"", ""removeVariable""]","[[""onTimedOutActions[Config"", ""onUrlRewriteTimeout""], [""onTimedOutActions[config""]]",[6644738104762074372],5849,0.0,2
https://github.com/squid-cache/squid/commit/f1a5d07184dcb26486e83590f9993d16b5de05fa,23 Feb 2015,"Remove cache_peer_domain directive

Identical functionality is provided through cache_peer_access.

While this check appears at face value to be simpler than ACLs, the
reality is that:
* the difference is simply the time it takes to initialize and destruct
  an on-stack Checklist,
* processing the checks may take longer than ACLs (linked-list of string
  comparisons vs single tree lookup),
* ACLs are the common case due to their extra flexibility, and
* extra work is being done per-transaction just to check which of the
  two features is in use.

By removing we gain less code and configuration directives to work
around in the long term.",163,data/crawl/squid/hunk_1035.cpp,,,data/crawl/squid/old_hunk_1035.cpp,data/crawl/squid/new_hunk_1035.cpp,4,-1,"storeAppendPrintf(sentry, ""DOMAIN LIST: "");",,"[""removeLog""]","[[""storeAppendPrintf"", ""sentry"", ""DOMAIN"", ""LIST""], []]",[-20444842400479138936],5848,4472640.0,2
https://github.com/squid-cache/squid/commit/6bd62757606d944e54904bfc8555fcbece9958a6,21 Mar 2015,"Shuffle Ssl::parse_options to Security::ParseOptions

The function itself is generic, the options array entries are all
conditional so library agnostic.

Adjust the context creation functions to receive pre-parsed options
instead of the string to avoid circular dependency between libsquidssl
and libsecurity.",444,data/crawl/squid/hunk_920.cpp,,,data/crawl/squid/old_hunk_920.cpp,data/crawl/squid/new_hunk_920.cpp,-1,187,,"fatalf(""Unknown SSL option '%s'"", option);","[""addLog""]","[[], [""fatalf"", ""Unknown"", ""SSL"", ""option"", ""%s"", ""option""]]",[6261211349979421884],5847,3528000.0,2
https://github.com/squid-cache/squid/commit/b97421d24bb568febfcd9f7d78909e3fc435f131,28 Mar 2015,"Parser-NG: Convert the ICAP read buffer to an SBuf.

* Remove the double-buffering hack used to comm_read() ICAP responses as
  c-string then convert to MemBuf for parsing.

* Revert the HttpMsg parser API from MemBuf to c-string parameters.
  The internals did not make much use of the MemBuf abilities and it is
  simpler to retrieve c-string values directly from an SBuf than to go
  via a MemBuf conversion.",256,data/crawl/squid/hunk_911.cpp,,,data/crawl/squid/old_hunk_911.cpp,data/crawl/squid/new_hunk_911.cpp,-1,9,,"mustStop(""unknown ICAP I/O read error"");","[""addLog""]","[[], [""mustStop"", ""unknown"", ""ICAP"", ""I/O"", ""read"", ""error""]]",[-25400331232163992070],5846,44640.0,2
https://github.com/squid-cache/squid/commit/a9423eea589bc093dfb0e32deb5f34d2c635b89f,21 Apr 2015,CBDATA: use class Lock for reference counting,44,data/crawl/squid/hunk_909.cpp,,,data/crawl/squid/old_hunk_909.cpp,data/crawl/squid/new_hunk_909.cpp,3,3,"storeAppendPrintf(sentry, ""%d cbdata entries\n"", cbdataCount);","storeAppendPrintf(sentry, ""%"" PRIu64 "" cbdata entries\n"", cbdataCount);","[""addContent"", ""updateContent"", ""addVariable""]","[[""%d""], [""%"", ""PRIu64""]]",[7232694531339534371],5845,0.0,2
https://github.com/squid-cache/squid/commit/20148bf2fb019708e44acd7f0670818eb6535ede,22 Apr 2015,Revert rev.14029,44,data/crawl/squid/hunk_906.cpp,,,data/crawl/squid/old_hunk_906.cpp,data/crawl/squid/new_hunk_906.cpp,3,3,"storeAppendPrintf(sentry, ""%"" PRIu64 "" cbdata entries\n"", cbdataCount);","storeAppendPrintf(sentry, ""%d cbdata entries\n"", cbdataCount);","[""removeVariable"", ""updateContent"", ""removeContent""]","[[""%"", ""PRIu64""], [""%d""]]",[-7232694531339534371],5844,0.0,2
https://github.com/squid-cache/squid/commit/47429c5a7a28ea74a659a6e37f4f174728b4a857,26 Apr 2015,Shuffle packerPrintf() to be Packer::Printf method,69,data/crawl/squid/hunk_904.cpp,,,data/crawl/squid/old_hunk_904.cpp,data/crawl/squid/new_hunk_904.cpp,-1,10,,"p->Printf(Http1StatusLineFormat, version.major, version.minor, status(), reason());","[""addLog""]","[[], [""p"", ""Printf"", ""Http1StatusLineFormat"", ""version"", ""major"", ""version"", ""minor"", ""status"", ""reason""]]",[2376661629906503829],5843,38880.0,2
https://github.com/squid-cache/squid/commit/47429c5a7a28ea74a659a6e37f4f174728b4a857,26 Apr 2015,Shuffle packerPrintf() to be Packer::Printf method,69,data/crawl/squid/hunk_904.cpp,,,data/crawl/squid/old_hunk_904.cpp,data/crawl/squid/new_hunk_904.cpp,-1,3,,"p->Printf(IcyStatusLineFormat, status(), reason());","[""addLog""]","[[], [""p"", ""Printf"", ""IcyStatusLineFormat"", ""status"", ""reason""]]",[-8877715264555547091],5842,38880.0,2
https://github.com/squid-cache/squid/commit/47429c5a7a28ea74a659a6e37f4f174728b4a857,26 Apr 2015,Shuffle packerPrintf() to be Packer::Printf method,69,data/crawl/squid/hunk_901.cpp,,,data/crawl/squid/old_hunk_901.cpp,data/crawl/squid/new_hunk_901.cpp,-1,3,,"p->Printf(SQUIDSBUFPH "" %s HTTP/%d.%d\r\n"",
              SQUIDSBUFPRINT(method.image()),
              packableURI(full_uri),
              http_ver.major, http_ver.minor);","[""addLog""]","[[], [""p"", ""Printf"", ""SQUIDSBUFPH"", ""%s"", ""HTTP/%d"", ""%d\\r\\n"", ""SQUIDSBUFPRINT"", ""method"", ""image"", ""packableURI"", ""full_uri"", ""http_ver"", ""major"", ""http_ver"", ""minor""]]",[-9467927400313583789],5841,38880.0,2
https://github.com/squid-cache/squid/commit/47429c5a7a28ea74a659a6e37f4f174728b4a857,26 Apr 2015,Shuffle packerPrintf() to be Packer::Printf method,69,data/crawl/squid/hunk_900.cpp,,,data/crawl/squid/old_hunk_900.cpp,data/crawl/squid/new_hunk_900.cpp,-1,3,,"p->Printf(SQUIDSBUFPH "" "" SQUIDSTRINGPH "" HTTP/%d.%d\r\n"",
              SQUIDSBUFPRINT(method.image()), SQUIDSTRINGPRINT(urlpath),
              http_ver.major, http_ver.minor);","[""addLog""]","[[], [""p"", ""Printf"", ""SQUIDSBUFPH"", ""SQUIDSTRINGPH"", ""HTTP/%d"", ""%d\\r\\n"", ""SQUIDSBUFPRINT"", ""method"", ""image"", ""SQUIDSTRINGPRINT"", ""urlpath"", ""http_ver"", ""major"", ""http_ver"", ""minor""]]",[-1397880125173530560],5840,38880.0,2
https://github.com/squid-cache/squid/commit/47429c5a7a28ea74a659a6e37f4f174728b4a857,26 Apr 2015,Shuffle packerPrintf() to be Packer::Printf method,69,data/crawl/squid/hunk_899.cpp,,,data/crawl/squid/old_hunk_899.cpp,data/crawl/squid/new_hunk_899.cpp,-1,19,,"p->Printf("";"" SQUIDSTRINGPH, SQUIDSTRINGPRINT(target));","[""addLog""]","[[], [""p"", ""Printf"", ""SQUIDSTRINGPH"", ""SQUIDSTRINGPRINT"", ""target""]]",[-9077602781423477937],5839,38880.0,2
https://github.com/squid-cache/squid/commit/47429c5a7a28ea74a659a6e37f4f174728b4a857,26 Apr 2015,Shuffle packerPrintf() to be Packer::Printf method,69,data/crawl/squid/hunk_899.cpp,,,data/crawl/squid/old_hunk_899.cpp,data/crawl/squid/new_hunk_899.cpp,-1,12,,"p->Printf(""=\"""" SQUIDSTRINGPH ""\"""", SQUIDSTRINGPRINT(content_));","[""addLog""]","[[], [""p"", ""Printf"", ""\\"", ""SQUIDSTRINGPH"", ""\\"", ""SQUIDSTRINGPRINT"", ""content_""]]",[1404584141389066326],5838,38880.0,2
https://github.com/squid-cache/squid/commit/47429c5a7a28ea74a659a6e37f4f174728b4a857,26 Apr 2015,Shuffle packerPrintf() to be Packer::Printf method,69,data/crawl/squid/hunk_899.cpp,,,data/crawl/squid/old_hunk_899.cpp,data/crawl/squid/new_hunk_899.cpp,-1,9,,"p->Printf(""=%d"", (int) max_age);","[""addLog""]","[[], [""p"", ""Printf"", ""%d"", ""int"", ""max_age""]]",[-8500830365794018438],5837,38880.0,2
https://github.com/squid-cache/squid/commit/47429c5a7a28ea74a659a6e37f4f174728b4a857,26 Apr 2015,Shuffle packerPrintf() to be Packer::Printf method,69,data/crawl/squid/hunk_899.cpp,,,data/crawl/squid/old_hunk_899.cpp,data/crawl/squid/new_hunk_899.cpp,-1,3,,"p->Printf((pcount ? "", "" SQUIDSTRINGPH : SQUIDSTRINGPH),
                         SQUIDSTRINGPRINT(ScFieldsInfo[flag].name));","[""addLog""]","[[], [""p"", ""Printf"", ""pcount"", ""SQUIDSTRINGPH"", ""SQUIDSTRINGPH"", ""SQUIDSTRINGPRINT"", ""ScFieldsInfo[flag]"", ""name""]]",[-9091417885935417465],5836,38880.0,2
https://github.com/squid-cache/squid/commit/47429c5a7a28ea74a659a6e37f4f174728b4a857,26 Apr 2015,Shuffle packerPrintf() to be Packer::Printf method,69,data/crawl/squid/hunk_898.cpp,,,data/crawl/squid/old_hunk_898.cpp,data/crawl/squid/new_hunk_898.cpp,-1,7,,"packer->Printf(""%"" PRId64 ""-%"" PRId64, offset, offset + length - 1);","[""addLog""]","[[], [""packer"", ""Printf"", ""%"", ""PRId64"", ""%"", ""PRId64"", ""offset"", ""offset"", ""length"", ""1""]]",[34418805337471966369],5835,38880.0,2
https://github.com/squid-cache/squid/commit/47429c5a7a28ea74a659a6e37f4f174728b4a857,26 Apr 2015,Shuffle packerPrintf() to be Packer::Printf method,69,data/crawl/squid/hunk_898.cpp,,,data/crawl/squid/old_hunk_898.cpp,data/crawl/squid/new_hunk_898.cpp,-1,5,,"packer->Printf(""%"" PRId64 ""-"", offset);","[""addLog""]","[[], [""packer"", ""Printf"", ""%"", ""PRId64"", ""offset""]]",[13309811026416167631],5834,38880.0,2
https://github.com/squid-cache/squid/commit/47429c5a7a28ea74a659a6e37f4f174728b4a857,26 Apr 2015,Shuffle packerPrintf() to be Packer::Printf method,69,data/crawl/squid/hunk_898.cpp,,,data/crawl/squid/old_hunk_898.cpp,data/crawl/squid/new_hunk_898.cpp,-1,3,,"packer->Printf(""-%"" PRId64,  length);","[""addLog""]","[[], [""packer"", ""Printf"", ""%"", ""PRId64"", ""length""]]",[14699823011110799082],5833,38880.0,2
https://github.com/squid-cache/squid/commit/47429c5a7a28ea74a659a6e37f4f174728b4a857,26 Apr 2015,Shuffle packerPrintf() to be Packer::Printf method,69,data/crawl/squid/hunk_897.cpp,,,data/crawl/squid/old_hunk_897.cpp,data/crawl/squid/new_hunk_897.cpp,-1,5,,"p->Printf(""/%"" PRId64, range->elength);","[""addLog""]","[[], [""p"", ""Printf"", ""/%"", ""PRId64"", ""range"", ""elength""]]",[4996163073457638955],5832,38880.0,2
https://github.com/squid-cache/squid/commit/47429c5a7a28ea74a659a6e37f4f174728b4a857,26 Apr 2015,Shuffle packerPrintf() to be Packer::Printf method,69,data/crawl/squid/hunk_897.cpp,,,data/crawl/squid/old_hunk_897.cpp,data/crawl/squid/new_hunk_897.cpp,-1,3,,"p->Printf(""/*"");","[""addLog""]","[[], [""p"", ""Printf"", ""/*""]]",[7243425605343659885],5831,38880.0,2
https://github.com/squid-cache/squid/commit/47429c5a7a28ea74a659a6e37f4f174728b4a857,26 Apr 2015,Shuffle packerPrintf() to be Packer::Printf method,69,data/crawl/squid/hunk_896.cpp,,,data/crawl/squid/old_hunk_896.cpp,data/crawl/squid/new_hunk_896.cpp,-1,5,,"p->Printf(""bytes %"" PRId64 ""-%"" PRId64,
                     spec->offset, spec->offset + spec->length - 1);","[""addLog""]","[[], [""p"", ""Printf"", ""bytes"", ""%"", ""PRId64"", ""%"", ""PRId64"", ""spec"", ""offset"", ""spec"", ""offset"", ""spec"", ""length"", ""1""]]",[33333980895791996333],5830,38880.0,2
https://github.com/squid-cache/squid/commit/47429c5a7a28ea74a659a6e37f4f174728b4a857,26 Apr 2015,Shuffle packerPrintf() to be Packer::Printf method,69,data/crawl/squid/hunk_896.cpp,,,data/crawl/squid/old_hunk_896.cpp,data/crawl/squid/new_hunk_896.cpp,-1,3,,"p->Printf(""*"");","[""addLog""]","[[], [""p"", ""Printf"", ""*""]]",[7237409574576621747],5829,38880.0,2
https://github.com/squid-cache/squid/commit/47429c5a7a28ea74a659a6e37f4f174728b4a857,26 Apr 2015,Shuffle packerPrintf() to be Packer::Printf method,69,data/crawl/squid/hunk_895.cpp,,,data/crawl/squid/old_hunk_895.cpp,data/crawl/squid/new_hunk_895.cpp,-1,3,,"p->Printf((pcount ? "", "" SQUIDSTRINGPH : SQUIDSTRINGPH),
                     SQUIDSTRINGPRINT(other));","[""addLog""]","[[], [""p"", ""Printf"", ""pcount"", ""SQUIDSTRINGPH"", ""SQUIDSTRINGPH"", ""SQUIDSTRINGPRINT"", ""other""]]",[-1946100465659953972],5828,38880.0,2
https://github.com/squid-cache/squid/commit/47429c5a7a28ea74a659a6e37f4f174728b4a857,26 Apr 2015,Shuffle packerPrintf() to be Packer::Printf method,69,data/crawl/squid/hunk_894.cpp,,,data/crawl/squid/old_hunk_894.cpp,data/crawl/squid/new_hunk_894.cpp,-1,20,,"p->Printf(""=%d"", (int) minFresh());","[""addLog""]","[[], [""p"", ""Printf"", ""%d"", ""int"", ""minFresh""]]",[-5183899013173655959],5827,38880.0,2
https://github.com/squid-cache/squid/commit/47429c5a7a28ea74a659a6e37f4f174728b4a857,26 Apr 2015,Shuffle packerPrintf() to be Packer::Printf method,69,data/crawl/squid/hunk_894.cpp,,,data/crawl/squid/old_hunk_894.cpp,data/crawl/squid/new_hunk_894.cpp,-1,17,,"p->Printf(""=%d"", (int) maxStale());","[""addLog""]","[[], [""p"", ""Printf"", ""%d"", ""int"", ""maxStale""]]",[8207589281074295674],5826,38880.0,2
https://github.com/squid-cache/squid/commit/47429c5a7a28ea74a659a6e37f4f174728b4a857,26 Apr 2015,Shuffle packerPrintf() to be Packer::Printf method,69,data/crawl/squid/hunk_894.cpp,,,data/crawl/squid/old_hunk_894.cpp,data/crawl/squid/new_hunk_894.cpp,-1,11,,"p->Printf(""=%d"", (int) sMaxAge());","[""addLog""]","[[], [""p"", ""Printf"", ""%d"", ""int"", ""sMaxAge""]]",[-5460747625656949564],5825,38880.0,2
https://github.com/squid-cache/squid/commit/47429c5a7a28ea74a659a6e37f4f174728b4a857,26 Apr 2015,Shuffle packerPrintf() to be Packer::Printf method,69,data/crawl/squid/hunk_894.cpp,,,data/crawl/squid/old_hunk_894.cpp,data/crawl/squid/new_hunk_894.cpp,-1,8,,"p->Printf(""=%d"", (int) maxAge());","[""addLog""]","[[], [""p"", ""Printf"", ""%d"", ""int"", ""maxAge""]]",[-5703379641896401018],5824,38880.0,2
https://github.com/squid-cache/squid/commit/47429c5a7a28ea74a659a6e37f4f174728b4a857,26 Apr 2015,Shuffle packerPrintf() to be Packer::Printf method,69,data/crawl/squid/hunk_894.cpp,,,data/crawl/squid/old_hunk_894.cpp,data/crawl/squid/new_hunk_894.cpp,-1,3,,"p->Printf((pcount ? "", %s"": ""%s"") , CcAttrs[flag].name);","[""addLog""]","[[], [""p"", ""Printf"", ""pcount"", ""%s"", ""%s"", ""CcAttrs[flag]"", ""name""]]",[8327898105088171353],5823,38880.0,2
https://github.com/squid-cache/squid/commit/07721490c3ad87e49ef952c07c6bbb0aa323b09b,27 Apr 2015,"Rename Packable::Printf as Packable::appendf

It performs append semantics not replace semantics, and this also paves
the way for SBuf integration.",451,data/crawl/squid/hunk_794.cpp,,,data/crawl/squid/old_hunk_794.cpp,data/crawl/squid/new_hunk_794.cpp,9,9,"outputBuffer.Printf("" %d+%d"", (int)theBuf.contentSize(), (int)theBuf.spaceSize());","outputBuffer.appendf("" %u+%u"", theBuf.contentSize(), theBuf.spaceSize());","[""updateLog"", ""removeVariable"", ""updateContent""]","[[""Printf"", ""%d"", ""%d"", ""int"", ""int""], [""appendf"", ""%u"", ""%u""]]",[14707410958118928288],5822,38160.0,2
https://github.com/squid-cache/squid/commit/bd74680720ec985b36a531a2a1cad2fd5fe26f1f,27 Apr 2015,Add vsnprintf() protection for vargs,15,data/crawl/squid/hunk_791.cpp,,,data/crawl/squid/old_hunk_791.cpp,data/crawl/squid/new_hunk_791.cpp,-1,12,,fatalf( xstrerror(errno));,"[""addLog""]","[[], [""fatalf"", ""xstrerror"", ""errno""]]",[17567734820066566823],5821,0.0,2
https://github.com/squid-cache/squid/commit/1fab834457cac20a8dd64038d0d5aa97dcff0ac9,18 May 2015,Fix build errors in rev.14057 and rev.14058,6,data/crawl/squid/hunk_789.cpp,,,data/crawl/squid/old_hunk_789.cpp,data/crawl/squid/new_hunk_789.cpp,3,3,fatalf( xstrerror(errno));,fatal(xstrerr(errno));,"[""updateVariable"", ""updateLog""]","[[""fatalf"", ""xstrerror""], [""fatal"", ""xstrerr""]]",[-14975703561865561642],5820,0.0,2
https://github.com/squid-cache/squid/commit/1cc44095e2effe69bd74291090c1b7b16cc33426,22 May 2015,"Replacement of sslversion=N by tls-min-version=1.N

Overall the default behaviour is changed from enumerating the protocols
wanted. To enumerating and eliminating the unwanted.


* sslversion= / version= parameter is removed from documentation.

* sslversion= code logics is converted from setting the SSL_*_method()
  function to setting the ssloptions= masking parameters.

Yes this will open a hole for future libraries use of TLSv1.3. However
that is kind of desirable and if it becomes a problem the
ssloptions=NO_TLSv1_3 should be made available.


* The SSL_*_method() logic is all converted to using the flexible
  TLS_*_Method() API when available (OpenSSL 1.1.0) otherwise the
  equivalent SSLv23_*_method() API is used.

That API follows the latest specification behaviour: to send a protocol
frame type that any recipient should be able to parse (library decides
which), while only negotiating the protocol type permitted.


* A new option tls-min-version=1.N is added to server connection
  directives. It controls *only* the TLS version range.

 - http(s)_port directives are not (yet) implemented using
   Security::PeerOptions. For now they are left with options= masking to
   select protocol support.

 - bug in http(s)_port directives version= parameter is fixed. The new
   backward compatibility code accepts version=4|5|6 where the existing
   code did not despite documentation saying it did.

 - SSLv3 is left at the library default unless ssloptions=NO_SSLv3 is used.


* ssloptions= is left alone so anyone can still set the library options
  masks to control SSLv3 enable/disable or specific TLS versions higher
  than the configured minimum.",390,data/crawl/squid/hunk_788.cpp,,,data/crawl/squid/old_hunk_788.cpp,data/crawl/squid/new_hunk_788.cpp,4,-1,"storeAppendPrintf(e, "" version=%d"", s->version);",,"[""removeLog""]","[[""storeAppendPrintf"", ""e"", ""version"", ""%d"", ""s"", ""version""], []]",[-9558444992649947300],5819,1912320.0,2
https://github.com/squid-cache/squid/commit/1071ffed56172406d771265af76d8273ffcdb89e,26 May 2015,"Replace Packer object API with Packable API

Majority of thost patch is symbol renaming to unify the
class method names to the Packable API names.

There is effectively no logical change in this patch
despite appearances because it replaces the Packer object
which provides methods which are just wrappers pointing
to static functions which are in turn wrappers pointing
to storage buffer object methods. With direct calls to
those storage object methods (renamed).

We can now interchangebly use MemBuf or StoreEntry objects
with the packInto(Packable *) functions. Or any other
object which inherits and implements the Packable API.

We also gain 0.1% in performance (+2 RPS) by avoiding the
layers of wrapper funcions and Packer object allocate / 
deallocate cycles.",1141,data/crawl/squid/hunk_780.cpp,,,data/crawl/squid/old_hunk_780.cpp,data/crawl/squid/new_hunk_780.cpp,-1,19,,fatal(xstrerr(errno));,"[""addLog""]","[[], [""fatal"", ""xstrerr"", ""errno""]]",[2592031258201005181],5818,0.0,2
https://github.com/squid-cache/squid/commit/bf3e8d5a0de0f6f59996d1a8fb88402ba2273ede,05 Jun 2015,"SourceLayout: convert helper stats display to Packable API

Requires unifying the classes Helper::Request queues which incidentally
also brings stateful helpers closer to concurrency support",192,data/crawl/squid/hunk_692.cpp,,,data/crawl/squid/old_hunk_692.cpp,data/crawl/squid/new_hunk_692.cpp,65,-1,"storeAppendPrintf(sentry, ""\nFlags key:\n\n"");",,"[""removeLog""]","[[""storeAppendPrintf"", ""sentry"", ""\\nFlags"", ""key"", ""\\n\\n""], []]",[-4873806497635168928],5817,4379040.0,2
https://github.com/squid-cache/squid/commit/bf3e8d5a0de0f6f59996d1a8fb88402ba2273ede,05 Jun 2015,"SourceLayout: convert helper stats display to Packable API

Requires unifying the classes Helper::Request queues which incidentally
also brings stateful helpers closer to concurrency support",192,data/crawl/squid/hunk_692.cpp,,,data/crawl/squid/old_hunk_692.cpp,data/crawl/squid/new_hunk_692.cpp,13,-1,"storeAppendPrintf(sentry, ""   S = SHUTDOWN PENDING\n"");",,"[""removeLog""]","[[""storeAppendPrintf"", ""sentry"", ""S"", ""SHUTDOWN"", ""PENDING\\n""], []]",[-18908474404010787604],5816,0.0,2
https://github.com/squid-cache/squid/commit/bf3e8d5a0de0f6f59996d1a8fb88402ba2273ede,05 Jun 2015,"SourceLayout: convert helper stats display to Packable API

Requires unifying the classes Helper::Request queues which incidentally
also brings stateful helpers closer to concurrency support",192,data/crawl/squid/hunk_690.cpp,,,data/crawl/squid/old_hunk_690.cpp,data/crawl/squid/new_hunk_690.cpp,12,-1,"storeAppendPrintf(sentry, ""program: %s\n"",
                      hlp->cmdline->key);",,"[""removeLog""]","[[""storeAppendPrintf"", ""sentry"", ""program"", ""%s\\n"", ""hlp"", ""cmdline"", ""key""], []]",[-30445718953000698725],5815,0.0,2
https://github.com/squid-cache/squid/commit/5c51bffba7a4fba9ef7b39f381d991e4e02ee490,09 Jun 2015,"Bug 1961 partial: Move HttpRequest host:port to class URL

Moves the host:port authority details into class URL for more
modular URI management. Add URL::authority() member to generate
authority-form URIs from the class URL stored details.

Also, shuffle urlDefaultPort() to AnyP::UriScheme::defaultPort()",626,data/crawl/squid/hunk_687.cpp,,,data/crawl/squid/old_hunk_687.cpp,data/crawl/squid/new_hunk_687.cpp,7,-1,"httpHeaderPutStrf(hdr_out, HDR_HOST, ""%s:%d"",
                              request->GetHost(),
                              (int) request->port);",,"[""removeLog""]","[[""httpHeaderPutStrf"", ""hdr_out"", ""HDR_HOST"", ""%s"", ""%d"", ""request"", ""GetHost"", ""int"", ""request"", ""port""], []]",[945318900776274290],5814,0.0,2
https://github.com/squid-cache/squid/commit/5c51bffba7a4fba9ef7b39f381d991e4e02ee490,09 Jun 2015,"Bug 1961 partial: Move HttpRequest host:port to class URL

Moves the host:port authority details into class URL for more
modular URI management. Add URL::authority() member to generate
authority-form URIs from the class URL stored details.

Also, shuffle urlDefaultPort() to AnyP::UriScheme::defaultPort()",626,data/crawl/squid/hunk_687.cpp,,,data/crawl/squid/old_hunk_687.cpp,data/crawl/squid/new_hunk_687.cpp,5,5,"hdr_out->putStr(HDR_HOST, request->GetHost());","hdr_out->putStr(HDR_HOST, authority.c_str());","[""updateVariable""]","[[""request"", ""GetHost""], [""authority"", ""c_str""]]",[-6342573481631189721],5813,0.0,2
https://github.com/squid-cache/squid/commit/ddd4edb743d82be97fc651d529e04bf55329a50d,22 Jun 2015,"Replace GNU atomics and related hacks with C++11 std::atomic

With C++11 atomic support by the stdlib is not optional. This
resolves issues determining whether GNU atomics are available,
operational 32-bit vs 64-bit, or cross-compiling (bug 4224).",283,data/crawl/squid/hunk_680.cpp,,,data/crawl/squid/old_hunk_680.cpp,data/crawl/squid/new_hunk_680.cpp,8,-1,"fatal(""memory_cache_shared is on, but no support for atomic operations detected"");",,"[""removeLog""]","[[""fatal"", ""memory_cache_shared"", ""is"", ""on"", ""but"", ""no"", ""support"", ""for"", ""atomic"", ""operations"", ""detected""], []]",[-5114139703971541903],5812,14400.0,2
https://github.com/squid-cache/squid/commit/eaba9273ca0d18a75d12c1055b7ed12b8eb2e3df,10 Jul 2015,"Crypto-NG: Use Security::PeerOptions for listening port TLS settings

The bulk of this patch is symbol shuffling to de-duplicate the TLS
settings storage and parsing code.

* Shuffle relevant AnyP::PortCfg settings into a Security::PeerOptions
  member object.
 - removes a lot of duplicate config parsing code.

* Remove the now obsolete and unused Ssl::OpenSSLtoSquidSSLVersion()


The actual logic changes are relatively small:

* Shuffle flags= and options= parsing code from Ssl:: to
  Security::PeerOptions and update to use Tokenizer,
 - fixes performance regression using c_str() on the stored SBuf,
 - fixes performance issue with xstrdup() for option tokens,
 - removes several calls to c-string manipulation.

* Add cachemgr 'config' report dumper of Security::PeerOptions for use
  by all directives using it to dump tls-* parameter names. The old
  parameter names are still accepted, and deprecation will follow in a
  separate patch.
 - fixes bug where cache_peer was not dumping out its SSL/TLS config
  settings at all.

* Change the tls_outgoing_options default value from ""disable"" to setting
  TLS/1.0 minimum version.
  - fixes squid.conf parsing error on default value ""disable"".

* Fix tls-min-version=1.N handling not to alter stored options= config
  string. Now updates the binary representation in parsedOptions directly.

* Expose the TLS context creation and configuration to non-OpenSSL builds.
 - fixes bug where context creation by OpenSSL failed silently.",1036,data/crawl/squid/hunk_660.cpp,,,data/crawl/squid/old_hunk_660.cpp,data/crawl/squid/new_hunk_660.cpp,269,-1,"fatalf(""Unknown ssl flag '%s'"", flag);",,"[""removeLog""]","[[""fatalf"", ""Unknown"", ""ssl"", ""flag"", ""%s"", ""flag""], []]",[-665749761150933206],5811,76320.0,2
https://github.com/squid-cache/squid/commit/eaba9273ca0d18a75d12c1055b7ed12b8eb2e3df,10 Jul 2015,"Crypto-NG: Use Security::PeerOptions for listening port TLS settings

The bulk of this patch is symbol shuffling to de-duplicate the TLS
settings storage and parsing code.

* Shuffle relevant AnyP::PortCfg settings into a Security::PeerOptions
  member object.
 - removes a lot of duplicate config parsing code.

* Remove the now obsolete and unused Ssl::OpenSSLtoSquidSSLVersion()


The actual logic changes are relatively small:

* Shuffle flags= and options= parsing code from Ssl:: to
  Security::PeerOptions and update to use Tokenizer,
 - fixes performance regression using c_str() on the stored SBuf,
 - fixes performance issue with xstrdup() for option tokens,
 - removes several calls to c-string manipulation.

* Add cachemgr 'config' report dumper of Security::PeerOptions for use
  by all directives using it to dump tls-* parameter names. The old
  parameter names are still accepted, and deprecation will follow in a
  separate patch.
 - fixes bug where cache_peer was not dumping out its SSL/TLS config
  settings at all.

* Change the tls_outgoing_options default value from ""disable"" to setting
  TLS/1.0 minimum version.
  - fixes squid.conf parsing error on default value ""disable"".

* Fix tls-min-version=1.N handling not to alter stored options= config
  string. Now updates the binary representation in parsedOptions directly.

* Expose the TLS context creation and configuration to non-OpenSSL builds.
 - fixes bug where context creation by OpenSSL failed silently.",1036,data/crawl/squid/hunk_660.cpp,,,data/crawl/squid/old_hunk_660.cpp,data/crawl/squid/new_hunk_660.cpp,189,-1,"fatalf(""Unknown SSL option '%s'"", option);",,"[""removeLog""]","[[""fatalf"", ""Unknown"", ""SSL"", ""option"", ""%s"", ""option""], []]",[-6261211349979421884],5810,79920.0,2
https://github.com/squid-cache/squid/commit/eaba9273ca0d18a75d12c1055b7ed12b8eb2e3df,10 Jul 2015,"Crypto-NG: Use Security::PeerOptions for listening port TLS settings

The bulk of this patch is symbol shuffling to de-duplicate the TLS
settings storage and parsing code.

* Shuffle relevant AnyP::PortCfg settings into a Security::PeerOptions
  member object.
 - removes a lot of duplicate config parsing code.

* Remove the now obsolete and unused Ssl::OpenSSLtoSquidSSLVersion()


The actual logic changes are relatively small:

* Shuffle flags= and options= parsing code from Ssl:: to
  Security::PeerOptions and update to use Tokenizer,
 - fixes performance regression using c_str() on the stored SBuf,
 - fixes performance issue with xstrdup() for option tokens,
 - removes several calls to c-string manipulation.

* Add cachemgr 'config' report dumper of Security::PeerOptions for use
  by all directives using it to dump tls-* parameter names. The old
  parameter names are still accepted, and deprecation will follow in a
  separate patch.
 - fixes bug where cache_peer was not dumping out its SSL/TLS config
  settings at all.

* Change the tls_outgoing_options default value from ""disable"" to setting
  TLS/1.0 minimum version.
  - fixes squid.conf parsing error on default value ""disable"".

* Fix tls-min-version=1.N handling not to alter stored options= config
  string. Now updates the binary representation in parsedOptions directly.

* Expose the TLS context creation and configuration to non-OpenSSL builds.
 - fixes bug where context creation by OpenSSL failed silently.",1036,data/crawl/squid/hunk_659.cpp,,,data/crawl/squid/old_hunk_659.cpp,data/crawl/squid/new_hunk_659.cpp,-1,211,,"fatalf(""Unknown TLS option '"" SQUIDSBUFPH ""'"", SQUIDSBUFPRINT(tok.remaining()));","[""addLog""]","[[], [""fatalf"", ""Unknown"", ""TLS"", ""option"", ""SQUIDSBUFPH"", ""SQUIDSBUFPRINT"", ""tok"", ""remaining""]]",[14770035583713574852],5809,7200.0,2
https://github.com/squid-cache/squid/commit/eaba9273ca0d18a75d12c1055b7ed12b8eb2e3df,10 Jul 2015,"Crypto-NG: Use Security::PeerOptions for listening port TLS settings

The bulk of this patch is symbol shuffling to de-duplicate the TLS
settings storage and parsing code.

* Shuffle relevant AnyP::PortCfg settings into a Security::PeerOptions
  member object.
 - removes a lot of duplicate config parsing code.

* Remove the now obsolete and unused Ssl::OpenSSLtoSquidSSLVersion()


The actual logic changes are relatively small:

* Shuffle flags= and options= parsing code from Ssl:: to
  Security::PeerOptions and update to use Tokenizer,
 - fixes performance regression using c_str() on the stored SBuf,
 - fixes performance issue with xstrdup() for option tokens,
 - removes several calls to c-string manipulation.

* Add cachemgr 'config' report dumper of Security::PeerOptions for use
  by all directives using it to dump tls-* parameter names. The old
  parameter names are still accepted, and deprecation will follow in a
  separate patch.
 - fixes bug where cache_peer was not dumping out its SSL/TLS config
  settings at all.

* Change the tls_outgoing_options default value from ""disable"" to setting
  TLS/1.0 minimum version.
  - fixes squid.conf parsing error on default value ""disable"".

* Fix tls-min-version=1.N handling not to alter stored options= config
  string. Now updates the binary representation in parsedOptions directly.

* Expose the TLS context creation and configuration to non-OpenSSL builds.
 - fixes bug where context creation by OpenSSL failed silently.",1036,data/crawl/squid/hunk_657.cpp,,,data/crawl/squid/old_hunk_657.cpp,data/crawl/squid/new_hunk_657.cpp,32,-1,"storeAppendPrintf(e, "" sslflags=%s"", s->sslflags);",,"[""removeLog""]","[[""storeAppendPrintf"", ""e"", ""sslflags"", ""%s"", ""s"", ""sslflags""], []]",[-14925440976705579641],5808,1947600.0,2
https://github.com/squid-cache/squid/commit/eaba9273ca0d18a75d12c1055b7ed12b8eb2e3df,10 Jul 2015,"Crypto-NG: Use Security::PeerOptions for listening port TLS settings

The bulk of this patch is symbol shuffling to de-duplicate the TLS
settings storage and parsing code.

* Shuffle relevant AnyP::PortCfg settings into a Security::PeerOptions
  member object.
 - removes a lot of duplicate config parsing code.

* Remove the now obsolete and unused Ssl::OpenSSLtoSquidSSLVersion()


The actual logic changes are relatively small:

* Shuffle flags= and options= parsing code from Ssl:: to
  Security::PeerOptions and update to use Tokenizer,
 - fixes performance regression using c_str() on the stored SBuf,
 - fixes performance issue with xstrdup() for option tokens,
 - removes several calls to c-string manipulation.

* Add cachemgr 'config' report dumper of Security::PeerOptions for use
  by all directives using it to dump tls-* parameter names. The old
  parameter names are still accepted, and deprecation will follow in a
  separate patch.
 - fixes bug where cache_peer was not dumping out its SSL/TLS config
  settings at all.

* Change the tls_outgoing_options default value from ""disable"" to setting
  TLS/1.0 minimum version.
  - fixes squid.conf parsing error on default value ""disable"".

* Fix tls-min-version=1.N handling not to alter stored options= config
  string. Now updates the binary representation in parsedOptions directly.

* Expose the TLS context creation and configuration to non-OpenSSL builds.
 - fixes bug where context creation by OpenSSL failed silently.",1036,data/crawl/squid/hunk_657.cpp,,,data/crawl/squid/old_hunk_657.cpp,data/crawl/squid/new_hunk_657.cpp,23,-1,"storeAppendPrintf(e, "" crlfile=%s"", s->crlfile);",,"[""removeLog""]","[[""storeAppendPrintf"", ""e"", ""crlfile"", ""%s"", ""s"", ""crlfile""], []]",[-22939110181803402459],5807,1947600.0,2
https://github.com/squid-cache/squid/commit/eaba9273ca0d18a75d12c1055b7ed12b8eb2e3df,10 Jul 2015,"Crypto-NG: Use Security::PeerOptions for listening port TLS settings

The bulk of this patch is symbol shuffling to de-duplicate the TLS
settings storage and parsing code.

* Shuffle relevant AnyP::PortCfg settings into a Security::PeerOptions
  member object.
 - removes a lot of duplicate config parsing code.

* Remove the now obsolete and unused Ssl::OpenSSLtoSquidSSLVersion()


The actual logic changes are relatively small:

* Shuffle flags= and options= parsing code from Ssl:: to
  Security::PeerOptions and update to use Tokenizer,
 - fixes performance regression using c_str() on the stored SBuf,
 - fixes performance issue with xstrdup() for option tokens,
 - removes several calls to c-string manipulation.

* Add cachemgr 'config' report dumper of Security::PeerOptions for use
  by all directives using it to dump tls-* parameter names. The old
  parameter names are still accepted, and deprecation will follow in a
  separate patch.
 - fixes bug where cache_peer was not dumping out its SSL/TLS config
  settings at all.

* Change the tls_outgoing_options default value from ""disable"" to setting
  TLS/1.0 minimum version.
  - fixes squid.conf parsing error on default value ""disable"".

* Fix tls-min-version=1.N handling not to alter stored options= config
  string. Now updates the binary representation in parsedOptions directly.

* Expose the TLS context creation and configuration to non-OpenSSL builds.
 - fixes bug where context creation by OpenSSL failed silently.",1036,data/crawl/squid/hunk_657.cpp,,,data/crawl/squid/old_hunk_657.cpp,data/crawl/squid/new_hunk_657.cpp,20,-1,"storeAppendPrintf(e, "" capath=%s"", s->capath);",,"[""removeLog""]","[[""storeAppendPrintf"", ""e"", ""capath"", ""%s"", ""s"", ""capath""], []]",[-11859293668491330937],5806,1947600.0,2
https://github.com/squid-cache/squid/commit/eaba9273ca0d18a75d12c1055b7ed12b8eb2e3df,10 Jul 2015,"Crypto-NG: Use Security::PeerOptions for listening port TLS settings

The bulk of this patch is symbol shuffling to de-duplicate the TLS
settings storage and parsing code.

* Shuffle relevant AnyP::PortCfg settings into a Security::PeerOptions
  member object.
 - removes a lot of duplicate config parsing code.

* Remove the now obsolete and unused Ssl::OpenSSLtoSquidSSLVersion()


The actual logic changes are relatively small:

* Shuffle flags= and options= parsing code from Ssl:: to
  Security::PeerOptions and update to use Tokenizer,
 - fixes performance regression using c_str() on the stored SBuf,
 - fixes performance issue with xstrdup() for option tokens,
 - removes several calls to c-string manipulation.

* Add cachemgr 'config' report dumper of Security::PeerOptions for use
  by all directives using it to dump tls-* parameter names. The old
  parameter names are still accepted, and deprecation will follow in a
  separate patch.
 - fixes bug where cache_peer was not dumping out its SSL/TLS config
  settings at all.

* Change the tls_outgoing_options default value from ""disable"" to setting
  TLS/1.0 minimum version.
  - fixes squid.conf parsing error on default value ""disable"".

* Fix tls-min-version=1.N handling not to alter stored options= config
  string. Now updates the binary representation in parsedOptions directly.

* Expose the TLS context creation and configuration to non-OpenSSL builds.
 - fixes bug where context creation by OpenSSL failed silently.",1036,data/crawl/squid/hunk_657.cpp,,,data/crawl/squid/old_hunk_657.cpp,data/crawl/squid/new_hunk_657.cpp,17,-1,"storeAppendPrintf(e, "" cafile=%s"", s->cafile);",,"[""removeLog""]","[[""storeAppendPrintf"", ""e"", ""cafile"", ""%s"", ""s"", ""cafile""], []]",[-18965929520452225931],5805,1947600.0,2
https://github.com/squid-cache/squid/commit/eaba9273ca0d18a75d12c1055b7ed12b8eb2e3df,10 Jul 2015,"Crypto-NG: Use Security::PeerOptions for listening port TLS settings

The bulk of this patch is symbol shuffling to de-duplicate the TLS
settings storage and parsing code.

* Shuffle relevant AnyP::PortCfg settings into a Security::PeerOptions
  member object.
 - removes a lot of duplicate config parsing code.

* Remove the now obsolete and unused Ssl::OpenSSLtoSquidSSLVersion()


The actual logic changes are relatively small:

* Shuffle flags= and options= parsing code from Ssl:: to
  Security::PeerOptions and update to use Tokenizer,
 - fixes performance regression using c_str() on the stored SBuf,
 - fixes performance issue with xstrdup() for option tokens,
 - removes several calls to c-string manipulation.

* Add cachemgr 'config' report dumper of Security::PeerOptions for use
  by all directives using it to dump tls-* parameter names. The old
  parameter names are still accepted, and deprecation will follow in a
  separate patch.
 - fixes bug where cache_peer was not dumping out its SSL/TLS config
  settings at all.

* Change the tls_outgoing_options default value from ""disable"" to setting
  TLS/1.0 minimum version.
  - fixes squid.conf parsing error on default value ""disable"".

* Fix tls-min-version=1.N handling not to alter stored options= config
  string. Now updates the binary representation in parsedOptions directly.

* Expose the TLS context creation and configuration to non-OpenSSL builds.
 - fixes bug where context creation by OpenSSL failed silently.",1036,data/crawl/squid/hunk_657.cpp,,,data/crawl/squid/old_hunk_657.cpp,data/crawl/squid/new_hunk_657.cpp,14,-1,"storeAppendPrintf(e, "" cipher=%s"", s->cipher);",,"[""removeLog""]","[[""storeAppendPrintf"", ""e"", ""cipher"", ""%s"", ""s"", ""cipher""], []]",[627383025728602375],5804,1947600.0,2
https://github.com/squid-cache/squid/commit/eaba9273ca0d18a75d12c1055b7ed12b8eb2e3df,10 Jul 2015,"Crypto-NG: Use Security::PeerOptions for listening port TLS settings

The bulk of this patch is symbol shuffling to de-duplicate the TLS
settings storage and parsing code.

* Shuffle relevant AnyP::PortCfg settings into a Security::PeerOptions
  member object.
 - removes a lot of duplicate config parsing code.

* Remove the now obsolete and unused Ssl::OpenSSLtoSquidSSLVersion()


The actual logic changes are relatively small:

* Shuffle flags= and options= parsing code from Ssl:: to
  Security::PeerOptions and update to use Tokenizer,
 - fixes performance regression using c_str() on the stored SBuf,
 - fixes performance issue with xstrdup() for option tokens,
 - removes several calls to c-string manipulation.

* Add cachemgr 'config' report dumper of Security::PeerOptions for use
  by all directives using it to dump tls-* parameter names. The old
  parameter names are still accepted, and deprecation will follow in a
  separate patch.
 - fixes bug where cache_peer was not dumping out its SSL/TLS config
  settings at all.

* Change the tls_outgoing_options default value from ""disable"" to setting
  TLS/1.0 minimum version.
  - fixes squid.conf parsing error on default value ""disable"".

* Fix tls-min-version=1.N handling not to alter stored options= config
  string. Now updates the binary representation in parsedOptions directly.

* Expose the TLS context creation and configuration to non-OpenSSL builds.
 - fixes bug where context creation by OpenSSL failed silently.",1036,data/crawl/squid/hunk_657.cpp,,,data/crawl/squid/old_hunk_657.cpp,data/crawl/squid/new_hunk_657.cpp,11,-1,"storeAppendPrintf(e, "" options=%s"", s->options);",,"[""removeLog""]","[[""storeAppendPrintf"", ""e"", ""options"", ""%s"", ""s"", ""options""], []]",[-7893954684300028237],5803,1947600.0,2
https://github.com/squid-cache/squid/commit/eaba9273ca0d18a75d12c1055b7ed12b8eb2e3df,10 Jul 2015,"Crypto-NG: Use Security::PeerOptions for listening port TLS settings

The bulk of this patch is symbol shuffling to de-duplicate the TLS
settings storage and parsing code.

* Shuffle relevant AnyP::PortCfg settings into a Security::PeerOptions
  member object.
 - removes a lot of duplicate config parsing code.

* Remove the now obsolete and unused Ssl::OpenSSLtoSquidSSLVersion()


The actual logic changes are relatively small:

* Shuffle flags= and options= parsing code from Ssl:: to
  Security::PeerOptions and update to use Tokenizer,
 - fixes performance regression using c_str() on the stored SBuf,
 - fixes performance issue with xstrdup() for option tokens,
 - removes several calls to c-string manipulation.

* Add cachemgr 'config' report dumper of Security::PeerOptions for use
  by all directives using it to dump tls-* parameter names. The old
  parameter names are still accepted, and deprecation will follow in a
  separate patch.
 - fixes bug where cache_peer was not dumping out its SSL/TLS config
  settings at all.

* Change the tls_outgoing_options default value from ""disable"" to setting
  TLS/1.0 minimum version.
  - fixes squid.conf parsing error on default value ""disable"".

* Fix tls-min-version=1.N handling not to alter stored options= config
  string. Now updates the binary representation in parsedOptions directly.

* Expose the TLS context creation and configuration to non-OpenSSL builds.
 - fixes bug where context creation by OpenSSL failed silently.",1036,data/crawl/squid/hunk_657.cpp,,,data/crawl/squid/old_hunk_657.cpp,data/crawl/squid/new_hunk_657.cpp,5,-1,"storeAppendPrintf(e, "" cert=%s"", s->cert);",,"[""removeLog""]","[[""storeAppendPrintf"", ""e"", ""cert"", ""%s"", ""s"", ""cert""], []]",[-16132876345930463543],5802,1947600.0,2
https://github.com/squid-cache/squid/commit/858c5afb99c9594aaf3169f905da635ef8d74f96,13 Jul 2015,"Cleanup: Shuffle Squid result codes (aka log tags) into class LogTags

This begins the migration of result codes from enumeration to a
set of flags whih can combine into much more flexible logging of
transation activity than hard-coded labels enumerating every
individual code path.

The existing ABORTED and TIMEDOUT state flags are also moved into
the new class as an example of how such flags would operate.",284,data/crawl/squid/hunk_652.cpp,,,data/crawl/squid/old_hunk_652.cpp,data/crawl/squid/new_hunk_652.cpp,3,3,"storeAppendPrintf(s, ""logType %s\n"", LogTags_str[http->logType]);","storeAppendPrintf(s, ""logType %s\n"", http->logType.c_str());","[""moveVariable"", ""removeVariable"", ""addVariable""]","[[""LogTags_str[http"", ""logType]""], [""http"", ""logType"", ""c_str""]]",[16264547057607872496],5801,23040.0,2
https://github.com/squid-cache/squid/commit/789217a2d102b1c99734afd7d48e4d4210ec009d,04 Aug 2015,"Renamed http_hdr_type to Http::HdrType, fixed some HdrType-int implicit conversions",1702,data/crawl/squid/hunk_623.cpp,,,data/crawl/squid/old_hunk_623.cpp,data/crawl/squid/new_hunk_623.cpp,4,4,"request->header.putStr(HDR_FTP_ARGUMENTS, params.c_str());","request->header.putStr(Http::HdrType::FTP_ARGUMENTS, params.c_str());","[""removeVariable"", ""addVariable""]","[[""HDR_FTP_ARGUMENTS""], [""Http"", ""HdrType"", ""FTP_ARGUMENTS""]]",[12213792289752032158],5800,0.0,2
https://github.com/squid-cache/squid/commit/789217a2d102b1c99734afd7d48e4d4210ec009d,04 Aug 2015,"Renamed http_hdr_type to Http::HdrType, fixed some HdrType-int implicit conversions",1702,data/crawl/squid/hunk_623.cpp,,,data/crawl/squid/old_hunk_623.cpp,data/crawl/squid/new_hunk_623.cpp,3,3,"request->header.putStr(HDR_FTP_COMMAND, cmd.c_str());","request->header.putStr(Http::HdrType::FTP_COMMAND, cmd.c_str());","[""removeVariable"", ""addVariable""]","[[""HDR_FTP_COMMAND""], [""Http"", ""HdrType"", ""FTP_COMMAND""]]",[6067555520411879372],5799,0.0,2
https://github.com/squid-cache/squid/commit/789217a2d102b1c99734afd7d48e4d4210ec009d,04 Aug 2015,"Renamed http_hdr_type to Http::HdrType, fixed some HdrType-int implicit conversions",1702,data/crawl/squid/hunk_611.cpp,,,data/crawl/squid/old_hunk_611.cpp,data/crawl/squid/new_hunk_611.cpp,9,9,"rep->header.putStr(HDR_CONTENT_LANGUAGE, err_language);","rep->header.putStr(Http::HdrType::CONTENT_LANGUAGE, err_language);","[""removeVariable"", ""addVariable""]","[[""HDR_CONTENT_LANGUAGE""], [""Http"", ""HdrType"", ""CONTENT_LANGUAGE""]]",[1626935096847391812],5798,0.0,2
https://github.com/squid-cache/squid/commit/789217a2d102b1c99734afd7d48e4d4210ec009d,04 Aug 2015,"Renamed http_hdr_type to Http::HdrType, fixed some HdrType-int implicit conversions",1702,data/crawl/squid/hunk_606.cpp,,,data/crawl/squid/old_hunk_606.cpp,data/crawl/squid/new_hunk_606.cpp,3,3,"reply->header.putStr(HDR_CONTENT_ENCODING, mime_enc);","reply->header.putStr(Http::HdrType::CONTENT_ENCODING, mime_enc);","[""removeVariable"", ""addVariable""]","[[""HDR_CONTENT_ENCODING""], [""Http"", ""HdrType"", ""CONTENT_ENCODING""]]",[9051340907168150958],5797,0.0,2
https://github.com/squid-cache/squid/commit/789217a2d102b1c99734afd7d48e4d4210ec009d,04 Aug 2015,"Renamed http_hdr_type to Http::HdrType, fixed some HdrType-int implicit conversions",1702,data/crawl/squid/hunk_604.cpp,,,data/crawl/squid/old_hunk_604.cpp,data/crawl/squid/new_hunk_604.cpp,17,17,"hdr->putStr(HDR_VIA, strVia.termedBuf());","hdr->putStr(Http::HdrType::VIA, strVia.termedBuf());","[""removeVariable"", ""addVariable""]","[[""HDR_VIA""], [""Http"", ""HdrType"", ""VIA""]]",[1945226063156498928],5796,0.0,2
https://github.com/squid-cache/squid/commit/789217a2d102b1c99734afd7d48e4d4210ec009d,04 Aug 2015,"Renamed http_hdr_type to Http::HdrType, fixed some HdrType-int implicit conversions",1702,data/crawl/squid/hunk_595.cpp,,,data/crawl/squid/old_hunk_595.cpp,data/crawl/squid/new_hunk_595.cpp,8,8,"hdr->putStr(HDR_CONTENT_TYPE, ctype);","hdr->putStr(Http::HdrType::CONTENT_TYPE, ctype);","[""removeVariable"", ""addVariable""]","[[""HDR_CONTENT_TYPE""], [""Http"", ""HdrType"", ""CONTENT_TYPE""]]",[22912001061348578708],5795,0.0,2
https://github.com/squid-cache/squid/commit/789217a2d102b1c99734afd7d48e4d4210ec009d,04 Aug 2015,"Renamed http_hdr_type to Http::HdrType, fixed some HdrType-int implicit conversions",1702,data/crawl/squid/hunk_595.cpp,,,data/crawl/squid/old_hunk_595.cpp,data/crawl/squid/new_hunk_595.cpp,3,3,"hdr->putStr(HDR_SERVER, visible_appname_string);","hdr->putStr(Http::HdrType::SERVER, visible_appname_string);","[""removeVariable"", ""addVariable""]","[[""HDR_SERVER""], [""Http"", ""HdrType"", ""SERVER""]]",[16194839928274547414],5794,0.0,2
https://github.com/squid-cache/squid/commit/789217a2d102b1c99734afd7d48e4d4210ec009d,04 Aug 2015,"Renamed http_hdr_type to Http::HdrType, fixed some HdrType-int implicit conversions",1702,data/crawl/squid/hunk_592.cpp,,,data/crawl/squid/old_hunk_592.cpp,data/crawl/squid/new_hunk_592.cpp,3,3,"putStr(HDR_WARNING, buf);","putStr(Http::HdrType::WARNING, buf);","[""removeVariable"", ""addVariable""]","[[""HDR_WARNING""], [""Http"", ""HdrType"", ""WARNING""]]",[7832491314551335464],5793,0.0,2
https://github.com/squid-cache/squid/commit/af845cee67e3dc2a58f93a9ac7d9ce091ea4fa00,11 Sep 2015,"Bug 4292: negotiate_wrapper: Unreleased Resources

FILE* handles need to be closed on exit. Shuffle the processing loop logics
to a static function to avoid code duplication from all the requires close
points.

Also, use the available global flag debug_enabled instead of local variable
to avoid having to pass it down explicitly.",337,data/crawl/squid/hunk_580.cpp,,,data/crawl/squid/old_hunk_580.cpp,data/crawl/squid/new_hunk_580.cpp,62,-1,"fprintf(stdout, ""BH Invalid negotiate request\n"");",,"[""removeLog""]","[[""fprintf"", ""stdout"", ""BH"", ""Invalid"", ""negotiate"", ""request\\n""], []]",[18267803172806194414],5792,1537920.0,2
https://github.com/squid-cache/squid/commit/af845cee67e3dc2a58f93a9ac7d9ce091ea4fa00,11 Sep 2015,"Bug 4292: negotiate_wrapper: Unreleased Resources

FILE* handles need to be closed on exit. Shuffle the processing loop logics
to a static function to avoid code duplication from all the requires close
points.

Also, use the available global flag debug_enabled instead of local variable
to avoid having to pass it down explicitly.",337,data/crawl/squid/hunk_580.cpp,,,data/crawl/squid/old_hunk_580.cpp,data/crawl/squid/new_hunk_580.cpp,60,-1,"fprintf(stderr, ""%s| %s: Invalid negotiate request [%s]\n"",
                        LogTime(), PROGRAM, buf);",,"[""removeLog""]","[[""fprintf"", ""stderr"", ""%s"", ""%s"", ""Invalid"", ""negotiate"", ""request"", ""[%s]\\n"", ""LogTime"", ""PROGRAM"", ""buf""], []]",[24305751704748737954],5791,1537920.0,2
https://github.com/squid-cache/squid/commit/af845cee67e3dc2a58f93a9ac7d9ce091ea4fa00,11 Sep 2015,"Bug 4292: negotiate_wrapper: Unreleased Resources

FILE* handles need to be closed on exit. Shuffle the processing loop logics
to a static function to avoid code duplication from all the requires close
points.

Also, use the available global flag debug_enabled instead of local variable
to avoid having to pass it down explicitly.",337,data/crawl/squid/hunk_580.cpp,,,data/crawl/squid/old_hunk_580.cpp,data/crawl/squid/new_hunk_580.cpp,48,-1,"fprintf(stdout, ""BH quit command\n"");",,"[""removeLog""]","[[""fprintf"", ""stdout"", ""BH"", ""quit"", ""command\\n""], []]",[2382764984285885200],5790,1537920.0,2
https://github.com/squid-cache/squid/commit/af845cee67e3dc2a58f93a9ac7d9ce091ea4fa00,11 Sep 2015,"Bug 4292: negotiate_wrapper: Unreleased Resources

FILE* handles need to be closed on exit. Shuffle the processing loop logics
to a static function to avoid code duplication from all the requires close
points.

Also, use the available global flag debug_enabled instead of local variable
to avoid having to pass it down explicitly.",337,data/crawl/squid/hunk_580.cpp,,,data/crawl/squid/old_hunk_580.cpp,data/crawl/squid/new_hunk_580.cpp,35,-1,"fprintf(stderr, ""%s| %s: Invalid request\n"", LogTime(),
                        PROGRAM);",,"[""removeLog""]","[[""fprintf"", ""stderr"", ""%s"", ""%s"", ""Invalid"", ""request\\n"", ""LogTime"", ""PROGRAM""], []]",[11683222101142235699],5789,1537920.0,2
https://github.com/squid-cache/squid/commit/af845cee67e3dc2a58f93a9ac7d9ce091ea4fa00,11 Sep 2015,"Bug 4292: negotiate_wrapper: Unreleased Resources

FILE* handles need to be closed on exit. Shuffle the processing loop logics
to a static function to avoid code duplication from all the requires close
points.

Also, use the available global flag debug_enabled instead of local variable
to avoid having to pass it down explicitly.",337,data/crawl/squid/hunk_580.cpp,,,data/crawl/squid/old_hunk_580.cpp,data/crawl/squid/new_hunk_580.cpp,29,-1,"fprintf(stdout, ""BH Oversized message\n"");",,"[""removeLog""]","[[""fprintf"", ""stdout"", ""BH"", ""Oversized"", ""message\\n""], []]",[13401837287885866005],5788,1537920.0,2
https://github.com/squid-cache/squid/commit/af845cee67e3dc2a58f93a9ac7d9ce091ea4fa00,11 Sep 2015,"Bug 4292: negotiate_wrapper: Unreleased Resources

FILE* handles need to be closed on exit. Shuffle the processing loop logics
to a static function to avoid code duplication from all the requires close
points.

Also, use the available global flag debug_enabled instead of local variable
to avoid having to pass it down explicitly.",337,data/crawl/squid/hunk_580.cpp,,,data/crawl/squid/old_hunk_580.cpp,data/crawl/squid/new_hunk_580.cpp,27,-1,"fprintf(stderr, ""%s| %s: Oversized message\n"", LogTime(),
                        PROGRAM);",,"[""removeLog""]","[[""fprintf"", ""stderr"", ""%s"", ""%s"", ""Oversized"", ""message\\n"", ""LogTime"", ""PROGRAM""], []]",[10148544130211447693],5787,1537920.0,2
https://github.com/squid-cache/squid/commit/af845cee67e3dc2a58f93a9ac7d9ce091ea4fa00,11 Sep 2015,"Bug 4292: negotiate_wrapper: Unreleased Resources

FILE* handles need to be closed on exit. Shuffle the processing loop logics
to a static function to avoid code duplication from all the requires close
points.

Also, use the available global flag debug_enabled instead of local variable
to avoid having to pass it down explicitly.",337,data/crawl/squid/hunk_580.cpp,,,data/crawl/squid/old_hunk_580.cpp,data/crawl/squid/new_hunk_580.cpp,23,-1,"fprintf(stderr, ""%s| %s: Got '%s' from squid (length: %d).\n"",
                        LogTime(), PROGRAM, buf, length);",,"[""removeLog""]","[[""fprintf"", ""stderr"", ""%s"", ""%s"", ""Got"", ""%s"", ""from"", ""squid"", ""length"", ""%d"", ""\\n"", ""LogTime"", ""PROGRAM"", ""buf"", ""length""], []]",[3528819456225505226],5786,1537920.0,2
https://github.com/squid-cache/squid/commit/af845cee67e3dc2a58f93a9ac7d9ce091ea4fa00,11 Sep 2015,"Bug 4292: negotiate_wrapper: Unreleased Resources

FILE* handles need to be closed on exit. Shuffle the processing loop logics
to a static function to avoid code duplication from all the requires close
points.

Also, use the available global flag debug_enabled instead of local variable
to avoid having to pass it down explicitly.",337,data/crawl/squid/hunk_580.cpp,,,data/crawl/squid/old_hunk_580.cpp,data/crawl/squid/new_hunk_580.cpp,7,-1,"fprintf(stderr,
                            ""%s| %s: fgets() failed! dying..... errno=%d (%s)\n"",
                            LogTime(), PROGRAM, ferror(stdin),
                            strerror(ferror(stdin)));",,"[""removeLog""]","[[""fprintf"", ""stderr"", ""%s"", ""%s"", ""fgets"", ""failed"", ""dying"", ""errno"", ""%d"", ""%s"", ""\\n"", ""LogTime"", ""PROGRAM"", ""ferror"", ""stdin"", ""strerror"", ""ferror"", ""stdin""], []]",[20226450349386740227],5785,1537920.0,2
https://github.com/squid-cache/squid/commit/af845cee67e3dc2a58f93a9ac7d9ce091ea4fa00,11 Sep 2015,"Bug 4292: negotiate_wrapper: Unreleased Resources

FILE* handles need to be closed on exit. Shuffle the processing loop logics
to a static function to avoid code duplication from all the requires close
points.

Also, use the available global flag debug_enabled instead of local variable
to avoid having to pass it down explicitly.",337,data/crawl/squid/hunk_574.cpp,,,data/crawl/squid/old_hunk_574.cpp,data/crawl/squid/new_hunk_574.cpp,-1,165,,"fprintf(stderr, ""%s| %s: Return '%s'\n"",
                    LogTime(), PROGRAM, buff);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""%s"", ""%s"", ""Return"", ""%s"", ""\\n"", ""LogTime"", ""PROGRAM"", ""buff""]]",[-4984282105989616312],5784,1159200.0,2
https://github.com/squid-cache/squid/commit/af845cee67e3dc2a58f93a9ac7d9ce091ea4fa00,11 Sep 2015,"Bug 4292: negotiate_wrapper: Unreleased Resources

FILE* handles need to be closed on exit. Shuffle the processing loop logics
to a static function to avoid code duplication from all the requires close
points.

Also, use the available global flag debug_enabled instead of local variable
to avoid having to pass it down explicitly.",337,data/crawl/squid/hunk_574.cpp,,,data/crawl/squid/old_hunk_574.cpp,data/crawl/squid/new_hunk_574.cpp,-1,163,,"fprintf(stdout,""%s"",buff);","[""addLog""]","[[], [""fprintf"", ""stdout"", ""%s"", ""buff""]]",[-12601965087582735048],5783,1159200.0,2
https://github.com/squid-cache/squid/commit/af845cee67e3dc2a58f93a9ac7d9ce091ea4fa00,11 Sep 2015,"Bug 4292: negotiate_wrapper: Unreleased Resources

FILE* handles need to be closed on exit. Shuffle the processing loop logics
to a static function to avoid code duplication from all the requires close
points.

Also, use the available global flag debug_enabled instead of local variable
to avoid having to pass it down explicitly.",337,data/crawl/squid/hunk_574.cpp,,,data/crawl/squid/old_hunk_574.cpp,data/crawl/squid/new_hunk_574.cpp,-1,158,,"fprintf(stderr, ""%s| %s: Error reading Kerberos helper response\n"",
                        LogTime(), PROGRAM);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""%s"", ""%s"", ""Error"", ""reading"", ""Kerberos"", ""helper"", ""response\\n"", ""LogTime"", ""PROGRAM""]]",[-4723970024690683777],5782,1159200.0,2
https://github.com/squid-cache/squid/commit/af845cee67e3dc2a58f93a9ac7d9ce091ea4fa00,11 Sep 2015,"Bug 4292: negotiate_wrapper: Unreleased Resources

FILE* handles need to be closed on exit. Shuffle the processing loop logics
to a static function to avoid code duplication from all the requires close
points.

Also, use the available global flag debug_enabled instead of local variable
to avoid having to pass it down explicitly.",337,data/crawl/squid/hunk_574.cpp,,,data/crawl/squid/old_hunk_574.cpp,data/crawl/squid/new_hunk_574.cpp,-1,153,,"fprintf(stderr,
                            ""fgets() failed! dying..... errno=%d (%s)\n"",
                            ferror(FDKOUT), strerror(ferror(FDKOUT)));","[""addLog""]","[[], [""fprintf"", ""stderr"", ""fgets"", ""failed"", ""dying"", ""errno"", ""%d"", ""%s"", ""\\n"", ""ferror"", ""FDKOUT"", ""strerror"", ""ferror"", ""FDKOUT""]]",[-23130862641428667756],5781,1159200.0,2
https://github.com/squid-cache/squid/commit/af845cee67e3dc2a58f93a9ac7d9ce091ea4fa00,11 Sep 2015,"Bug 4292: negotiate_wrapper: Unreleased Resources

FILE* handles need to be closed on exit. Shuffle the processing loop logics
to a static function to avoid code duplication from all the requires close
points.

Also, use the available global flag debug_enabled instead of local variable
to avoid having to pass it down explicitly.",337,data/crawl/squid/hunk_574.cpp,,,data/crawl/squid/old_hunk_574.cpp,data/crawl/squid/new_hunk_574.cpp,-1,150,,"fprintf(FDKIN, ""%s\n"",buf);","[""addLog""]","[[], [""fprintf"", ""FDKIN"", ""%s\\n"", ""buf""]]",[-679212945824533377],5780,1159200.0,2
https://github.com/squid-cache/squid/commit/af845cee67e3dc2a58f93a9ac7d9ce091ea4fa00,11 Sep 2015,"Bug 4292: negotiate_wrapper: Unreleased Resources

FILE* handles need to be closed on exit. Shuffle the processing loop logics
to a static function to avoid code duplication from all the requires close
points.

Also, use the available global flag debug_enabled instead of local variable
to avoid having to pass it down explicitly.",337,data/crawl/squid/hunk_574.cpp,,,data/crawl/squid/old_hunk_574.cpp,data/crawl/squid/new_hunk_574.cpp,-1,147,,"fprintf(stderr, ""%s| %s: received Kerberos token\n"",
                        LogTime(), PROGRAM);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""%s"", ""%s"", ""received"", ""Kerberos"", ""token\\n"", ""LogTime"", ""PROGRAM""]]",[-3556440401682959523],5779,1159200.0,2
https://github.com/squid-cache/squid/commit/af845cee67e3dc2a58f93a9ac7d9ce091ea4fa00,11 Sep 2015,"Bug 4292: negotiate_wrapper: Unreleased Resources

FILE* handles need to be closed on exit. Shuffle the processing loop logics
to a static function to avoid code duplication from all the requires close
points.

Also, use the available global flag debug_enabled instead of local variable
to avoid having to pass it down explicitly.",337,data/crawl/squid/hunk_574.cpp,,,data/crawl/squid/old_hunk_574.cpp,data/crawl/squid/new_hunk_574.cpp,-1,126,,"fprintf(stderr, ""%s| %s: Error reading NTLM helper response\n"",
                        LogTime(), PROGRAM);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""%s"", ""%s"", ""Error"", ""reading"", ""NTLM"", ""helper"", ""response\\n"", ""LogTime"", ""PROGRAM""]]",[-13450300038191209057],5778,1159200.0,2
https://github.com/squid-cache/squid/commit/af845cee67e3dc2a58f93a9ac7d9ce091ea4fa00,11 Sep 2015,"Bug 4292: negotiate_wrapper: Unreleased Resources

FILE* handles need to be closed on exit. Shuffle the processing loop logics
to a static function to avoid code duplication from all the requires close
points.

Also, use the available global flag debug_enabled instead of local variable
to avoid having to pass it down explicitly.",337,data/crawl/squid/hunk_574.cpp,,,data/crawl/squid/old_hunk_574.cpp,data/crawl/squid/new_hunk_574.cpp,-1,121,,"fprintf(stderr,
                            ""fgets() failed! dying..... errno=%d (%s)\n"",
                            ferror(FDNOUT), strerror(ferror(FDNOUT)));","[""addLog""]","[[], [""fprintf"", ""stderr"", ""fgets"", ""failed"", ""dying"", ""errno"", ""%d"", ""%s"", ""\\n"", ""ferror"", ""FDNOUT"", ""strerror"", ""ferror"", ""FDNOUT""]]",[-17130652640382666338],5777,1159200.0,2
https://github.com/squid-cache/squid/commit/af845cee67e3dc2a58f93a9ac7d9ce091ea4fa00,11 Sep 2015,"Bug 4292: negotiate_wrapper: Unreleased Resources

FILE* handles need to be closed on exit. Shuffle the processing loop logics
to a static function to avoid code duplication from all the requires close
points.

Also, use the available global flag debug_enabled instead of local variable
to avoid having to pass it down explicitly.",337,data/crawl/squid/hunk_574.cpp,,,data/crawl/squid/old_hunk_574.cpp,data/crawl/squid/new_hunk_574.cpp,-1,118,,"fprintf(FDNIN, ""%s\n"",buf);","[""addLog""]","[[], [""fprintf"", ""FDNIN"", ""%s\\n"", ""buf""]]",[-679209945724533170],5776,1159200.0,2
https://github.com/squid-cache/squid/commit/af845cee67e3dc2a58f93a9ac7d9ce091ea4fa00,11 Sep 2015,"Bug 4292: negotiate_wrapper: Unreleased Resources

FILE* handles need to be closed on exit. Shuffle the processing loop logics
to a static function to avoid code duplication from all the requires close
points.

Also, use the available global flag debug_enabled instead of local variable
to avoid having to pass it down explicitly.",337,data/crawl/squid/hunk_574.cpp,,,data/crawl/squid/old_hunk_574.cpp,data/crawl/squid/new_hunk_574.cpp,-1,115,,"fprintf(stderr, ""%s| %s: received type %d NTLM token\n"",
                        LogTime(), PROGRAM, (int) *((unsigned char *) token +
                                                    sizeof ntlmProtocol));","[""addLog""]","[[], [""fprintf"", ""stderr"", ""%s"", ""%s"", ""received"", ""type"", ""%d"", ""NTLM"", ""token\\n"", ""LogTime"", ""PROGRAM"", ""int"", ""*"", ""unsigned"", ""char"", ""*"", ""token"", ""sizeof"", ""ntlmProtocol""]]",[-14761247642423624596],5775,1159200.0,2
https://github.com/squid-cache/squid/commit/af845cee67e3dc2a58f93a9ac7d9ce091ea4fa00,11 Sep 2015,"Bug 4292: negotiate_wrapper: Unreleased Resources

FILE* handles need to be closed on exit. Shuffle the processing loop logics
to a static function to avoid code duplication from all the requires close
points.

Also, use the available global flag debug_enabled instead of local variable
to avoid having to pass it down explicitly.",337,data/crawl/squid/hunk_574.cpp,,,data/crawl/squid/old_hunk_574.cpp,data/crawl/squid/new_hunk_574.cpp,-1,104,,"fprintf(stderr, ""%s| %s: Invalid base64 token [%s]\n"", LogTime(), PROGRAM, buf+3);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""%s"", ""%s"", ""Invalid"", ""base64"", ""token"", ""[%s]\\n"", ""LogTime"", ""PROGRAM"", ""buf"", ""3""]]",[-5372266154016776204],5774,183600.0,2
https://github.com/squid-cache/squid/commit/af845cee67e3dc2a58f93a9ac7d9ce091ea4fa00,11 Sep 2015,"Bug 4292: negotiate_wrapper: Unreleased Resources

FILE* handles need to be closed on exit. Shuffle the processing loop logics
to a static function to avoid code duplication from all the requires close
points.

Also, use the available global flag debug_enabled instead of local variable
to avoid having to pass it down explicitly.",337,data/crawl/squid/hunk_574.cpp,,,data/crawl/squid/old_hunk_574.cpp,data/crawl/squid/new_hunk_574.cpp,-1,94,,"fprintf(stderr, ""%s| %s: Error allocating memory for token\n"", LogTime(), PROGRAM);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""%s"", ""%s"", ""Error"", ""allocating"", ""memory"", ""for"", ""token\\n"", ""LogTime"", ""PROGRAM""]]",[6193949009428647455],5773,1159200.0,2
https://github.com/squid-cache/squid/commit/af845cee67e3dc2a58f93a9ac7d9ce091ea4fa00,11 Sep 2015,"Bug 4292: negotiate_wrapper: Unreleased Resources

FILE* handles need to be closed on exit. Shuffle the processing loop logics
to a static function to avoid code duplication from all the requires close
points.

Also, use the available global flag debug_enabled instead of local variable
to avoid having to pass it down explicitly.",337,data/crawl/squid/hunk_574.cpp,,,data/crawl/squid/old_hunk_574.cpp,data/crawl/squid/new_hunk_574.cpp,-1,90,,"fprintf(stderr, ""%s| %s: Decode '%s' (decoded length: %d).\n"",
                    LogTime(), PROGRAM, buf + 3, (int) length);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""%s"", ""%s"", ""Decode"", ""%s"", ""decoded"", ""length"", ""%d"", ""\\n"", ""LogTime"", ""PROGRAM"", ""buf"", ""3"", ""int"", ""length""]]",[-8963563524286375559],5772,1159200.0,2
https://github.com/squid-cache/squid/commit/971003b0b122cfb0b48c21202e7b3cdd8374c785,26 Sep 2015,"Fix cache_peer login=PASS(THRU) after CVE-2015-5400

The patch for CVE-2015-5400 converts all non-200 peer responses
into 502 Bad Gateway responses when relaying a CONNECT to a peer.

This happens to break login=PASS and login=PASSTHRU behaviour
which relies on the 401 and 407 status being relayed transparently.

We need to relay the auth server responses as-is when login= is
set to PASS or PASSTHRU but then unconditionally close the
connections to prevent CVE-2015-5400 from occuring.",42,data/crawl/squid/hunk_568.cpp,,,data/crawl/squid/old_hunk_568.cpp,data/crawl/squid/new_hunk_568.cpp,3,3,"informUserOfPeerError(""malformed CONNECT response from peer"");","informUserOfPeerError(""malformed CONNECT response from peer"", 0);","[""addContent""]","[[], [""0""]]",[6144018481],5771,0.0,2
https://github.com/squid-cache/squid/commit/d1c95ddadcd9ee36e53af7edd6099a8c078ba2cf,01 Oct 2015,"Bug 4190: assertion 'hash_remove_link' from Auth::User::cacheCleanup

The hash_link based cache depends on raw-ptr key comparisons to store
hash entries. This does not work at all well with SBuf as the key,
since the backing MemBlob behind SBuf can change its memory location.

* replace the implementation of User credentials caching with an STL
  based container class that can handle SBuf.

* revert the global Auth::User cache design to per-scheme caches
  which get combined only when reporting statistics.

* add a RunnersRegistry helper class to control Squid startup,
  reconfigure, and shutdown events activity in regards to the caches.

* suppress useless cache garbage collection events when auth has no
  credentials to cleanup.

* make the cache key dynamic at the caller codes discretion.",670,data/crawl/squid/hunk_565.cpp,,,data/crawl/squid/old_hunk_565.cpp,data/crawl/squid/new_hunk_565.cpp,39,19,"storeAppendPrintf(output, ""%-15s %-9s %-9d %-9d %s\n"",
                          Auth::Type_str[auth_user->auth_type],
                          CredentialState_str[auth_user->credentials()],
                          auth_user->ttl(),
                          static_cast<int32_t>(auth_user->expiretime - squid_curtime + ::Config.authenticateTTL),
                          auth_user->username()
                         );","storeAppendPrintf(output, ""%-15s %-9s %-9d %-9d %s\t"" SQUIDSBUFPH ""\n"",
                          Auth::Type_str[auth_user->auth_type],
                          CredentialState_str[auth_user->credentials()],
                          auth_user->ttl(),
                          static_cast<int32_t>(auth_user->expiretime - squid_curtime + ::Config.authenticateTTL),
                          auth_user->username(),
                          SQUIDSBUFPRINT(auth_user->userKey())
                         );","[""updateContent"", ""addContent"", ""addVariable""]","[[""%s\\n""], [""%s\\t"", ""SQUIDSBUFPH"", ""\\n"", ""SQUIDSBUFPRINT"", ""auth_user"", ""userKey""]]",[16934003893846475150],5770,4320.0,2
https://github.com/squid-cache/squid/commit/d1c95ddadcd9ee36e53af7edd6099a8c078ba2cf,01 Oct 2015,"Bug 4190: assertion 'hash_remove_link' from Auth::User::cacheCleanup

The hash_link based cache depends on raw-ptr key comparisons to store
hash entries. This does not work at all well with SBuf as the key,
since the backing MemBlob behind SBuf can change its memory location.

* replace the implementation of User credentials caching with an STL
  based container class that can handle SBuf.

* revert the global Auth::User cache design to per-scheme caches
  which get combined only when reporting statistics.

* add a RunnersRegistry helper class to control Squid startup,
  reconfigure, and shutdown events activity in regards to the caches.

* suppress useless cache garbage collection events when auth has no
  credentials to cleanup.

* make the cache key dynamic at the caller codes discretion.",670,data/crawl/squid/hunk_565.cpp,,,data/crawl/squid/old_hunk_565.cpp,data/crawl/squid/new_hunk_565.cpp,27,11,"storeAppendPrintf(output, ""\n%-15s %-9s %-9s %-9s %s\n"",
                      ""Type"",
                      ""State"",
                      ""Check TTL"",
                      ""Cache TTL"",
                      ""Username"");","storeAppendPrintf(output, ""\n%-15s %-9s %-9s %-9s %s\t%s\n"",
                      ""Type"",
                      ""State"",
                      ""Check TTL"",
                      ""Cache TTL"",
                      ""Username"", ""Key"");","[""updateContent"", ""addContent""]","[[""%s\\n""], [""%s\\t%s\\n"", ""Key""]]",[8809333121076691718],5769,4320.0,2
https://github.com/squid-cache/squid/commit/d1c95ddadcd9ee36e53af7edd6099a8c078ba2cf,01 Oct 2015,"Bug 4190: assertion 'hash_remove_link' from Auth::User::cacheCleanup

The hash_link based cache depends on raw-ptr key comparisons to store
hash entries. This does not work at all well with SBuf as the key,
since the backing MemBlob behind SBuf can change its memory location.

* replace the implementation of User credentials caching with an STL
  based container class that can handle SBuf.

* revert the global Auth::User cache design to per-scheme caches
  which get combined only when reporting statistics.

* add a RunnersRegistry helper class to control Squid startup,
  reconfigure, and shutdown events activity in regards to the caches.

* suppress useless cache garbage collection events when auth has no
  credentials to cleanup.

* make the cache key dynamic at the caller codes discretion.",670,data/crawl/squid/hunk_565.cpp,,,data/crawl/squid/old_hunk_565.cpp,data/crawl/squid/new_hunk_565.cpp,23,10,"storeAppendPrintf(output, ""Next Garbage Collection in %d seconds.\n"",
                      static_cast<int32_t>(last_discard + ::Config.authenticateGCInterval - squid_curtime));","storeAppendPrintf(output, ""Cached Usernames: %d"", static_cast<int32_t>(userlist.size()));","[""updateVariable"", ""moveVariable"", ""removeVariable"", ""updateContent"", ""addVariable""]","[[""Next"", ""Garbage"", ""Collection"", ""in"", ""seconds"", ""\\n"", ""last_discard"", ""Config"", ""authenticateGCInterval"", ""squid_curtime""], [""Cached"", ""Usernames"", ""userlist"", ""size""]]",[8068786384572661806],5768,20160.0,2
https://github.com/squid-cache/squid/commit/d1c95ddadcd9ee36e53af7edd6099a8c078ba2cf,01 Oct 2015,"Bug 4190: assertion 'hash_remove_link' from Auth::User::cacheCleanup

The hash_link based cache depends on raw-ptr key comparisons to store
hash entries. This does not work at all well with SBuf as the key,
since the backing MemBlob behind SBuf can change its memory location.

* replace the implementation of User credentials caching with an STL
  based container class that can handle SBuf.

* revert the global Auth::User cache design to per-scheme caches
  which get combined only when reporting statistics.

* add a RunnersRegistry helper class to control Squid startup,
  reconfigure, and shutdown events activity in regards to the caches.

* suppress useless cache garbage collection events when auth has no
  credentials to cleanup.

* make the cache key dynamic at the caller codes discretion.",670,data/crawl/squid/hunk_565.cpp,,,data/crawl/squid/old_hunk_565.cpp,data/crawl/squid/new_hunk_565.cpp,22,9,"storeAppendPrintf(output, ""Cached Usernames: %d of %d\n"", proxy_auth_username_cache->count, proxy_auth_username_cache->size);",authenticateCachedUsersList();,"[""updateLog"", ""removeVariable"", ""removeContent""]","[[""storeAppendPrintf"", ""output"", ""Cached"", ""Usernames"", ""%d"", ""of"", ""%d\\n"", ""proxy_auth_username_cache"", ""count"", ""proxy_auth_username_cache"", ""size""], [""authenticateCachedUsersList""]]",[-2467527697564230888],5767,20160.0,2
https://github.com/squid-cache/squid/commit/fbdf945d33765c02929795b8354c6cdd55d67ba4,02 Oct 2015,Cleanup various spelling errors,22,data/crawl/squid/hunk_561.cpp,,,data/crawl/squid/old_hunk_561.cpp,data/crawl/squid/new_hunk_561.cpp,3,3,"fprintf(stderr, ""group1@domain1:group2@domain2:group3@:group4  - A list is build with a colon as seperator\n"");","fprintf(stderr, ""group1@domain1:group2@domain2:group3@:group4  - A list is build with a colon as separator\n"");","[""updateContent""]","[[""seperator\\n""], [""separator\\n""]]",[5727306902760472380],5766,0.0,2
https://github.com/squid-cache/squid/commit/a87b56f3c1acc2ffdd35d60a82abf64ccfc30e7b,11 Oct 2015,"TLS: shuffle EECDH configuration to libsecurity

* add class ServerOptions to libsecurity to manage server specific
  configuration options. Based on class PeerOptions.

* shuffle the DH config parse and dump logics to ServerOptions

* shuffle the DH params pre-loading logic to ServerOptions

* add configuration warning when tls-dh= is used and overrides
  dhparams= logacy configuration. Also, auto-upgrade the config
  settings when dhparams= is dumped in mgr:config report.",357,data/crawl/squid/hunk_558.cpp,,,data/crawl/squid/old_hunk_558.cpp,data/crawl/squid/new_hunk_558.cpp,7,-1,"storeAppendPrintf(e, "" tls-dh=%s"", s->tls_dh);",,"[""removeLog""]","[[""storeAppendPrintf"", ""e"", ""tls"", ""dh"", ""%s"", ""s"", ""tls_dh""], []]",[-11984864398691570101],5765,720.0,2
https://github.com/squid-cache/squid/commit/cd6b1fd1bd9fc68574035857d649b85ba8713e3f,11 Oct 2015,"Support logformat %macros in external_acl_type format

Update the external_acl_type helper interface to use libformat and thus
make any logformat token valid in its format parameter field.

As a result much of the logic surrounding format code parsing, display
and helper query generation has been completely dropped. What remains is
a basic parse loop handling backward compatibility for the unusual
%CERT_* token syntax, space delimiter and field default encodings.


Extensions to logformat resulting from the merger:

* adds \-escape encoding of output fields

* allows {arg} field to be placed before or after the format code.

* extended to accept the old external_acl_type %macros. But not
  documented, these are deprecated and only for backward compatibility.

* extended to support outputting formats without a format-name prefix
  as was required by the original logformat config lines.


The major side effect of this change is that these ACLs now require
AccessLogEntry to be filled out with state data, rather than just the
ACLChecklist object members.

The requires*() mechanism of ACLChecklist has been extended to catch
some cases resulting from missing the ALE entirely. But it cannot catch
the more subtle problem of data members inside the ALE being unset.
To try and catch those a syncAle() mechanism has been added that fills
out missing ALE members and prints out debug warnings about the action.",993,data/crawl/squid/hunk_554.cpp,,,data/crawl/squid/old_hunk_554.cpp,data/crawl/squid/new_hunk_554.cpp,69,-1,"fatal(""unknown external_acl format error"");",,"[""removeLog""]","[[""fatal"", ""unknown"", ""external_acl"", ""format"", ""error""], []]",[-7503529408969980762],5764,97200.0,2
https://github.com/squid-cache/squid/commit/cd6b1fd1bd9fc68574035857d649b85ba8713e3f,11 Oct 2015,"Support logformat %macros in external_acl_type format

Update the external_acl_type helper interface to use libformat and thus
make any logformat token valid in its format parameter field.

As a result much of the logic surrounding format code parsing, display
and helper query generation has been completely dropped. What remains is
a basic parse loop handling backward compatibility for the unusual
%CERT_* token syntax, space delimiter and field default encodings.


Extensions to logformat resulting from the merger:

* adds \-escape encoding of output fields

* allows {arg} field to be placed before or after the format code.

* extended to accept the old external_acl_type %macros. But not
  documented, these are deprecated and only for backward compatibility.

* extended to support outputting formats without a format-name prefix
  as was required by the original logformat config lines.


The major side effect of this change is that these ACLs now require
AccessLogEntry to be filled out with state data, rather than just the
ACLChecklist object members.

The requires*() mechanism of ACLChecklist has been extended to catch
some cases resulting from missing the ALE entirely. But it cannot catch
the more subtle problem of data members inside the ALE being unset.
To try and catch those a syncAle() mechanism has been added that fills
out missing ALE members and prints out debug warnings about the action.",993,data/crawl/squid/hunk_554.cpp,,,data/crawl/squid/old_hunk_554.cpp,data/crawl/squid/new_hunk_554.cpp,22,-1,"storeAppendPrintf(sentry, "" %%<h{%s:%s}"", format->header, format->member);",,"[""removeLog""]","[[""storeAppendPrintf"", ""sentry"", ""%%"", ""h"", ""%s"", ""%s"", ""format"", ""header"", ""format"", ""member""], []]",[-12951319307258242054],5763,97200.0,2
https://github.com/squid-cache/squid/commit/cd6b1fd1bd9fc68574035857d649b85ba8713e3f,11 Oct 2015,"Support logformat %macros in external_acl_type format

Update the external_acl_type helper interface to use libformat and thus
make any logformat token valid in its format parameter field.

As a result much of the logic surrounding format code parsing, display
and helper query generation has been completely dropped. What remains is
a basic parse loop handling backward compatibility for the unusual
%CERT_* token syntax, space delimiter and field default encodings.


Extensions to logformat resulting from the merger:

* adds \-escape encoding of output fields

* allows {arg} field to be placed before or after the format code.

* extended to accept the old external_acl_type %macros. But not
  documented, these are deprecated and only for backward compatibility.

* extended to support outputting formats without a format-name prefix
  as was required by the original logformat config lines.


The major side effect of this change is that these ACLs now require
AccessLogEntry to be filled out with state data, rather than just the
ACLChecklist object members.

The requires*() mechanism of ACLChecklist has been extended to catch
some cases resulting from missing the ALE entirely. But it cannot catch
the more subtle problem of data members inside the ALE being unset.
To try and catch those a syncAle() mechanism has been added that fills
out missing ALE members and prints out debug warnings about the action.",993,data/crawl/squid/hunk_554.cpp,,,data/crawl/squid/old_hunk_554.cpp,data/crawl/squid/new_hunk_554.cpp,18,-1,"storeAppendPrintf(sentry, "" %%<h{%s}"", format->header);",,"[""removeLog""]","[[""storeAppendPrintf"", ""sentry"", ""%%"", ""h"", ""%s"", ""format"", ""header""], []]",[-3131119370651702705],5762,97200.0,2
https://github.com/squid-cache/squid/commit/cd6b1fd1bd9fc68574035857d649b85ba8713e3f,11 Oct 2015,"Support logformat %macros in external_acl_type format

Update the external_acl_type helper interface to use libformat and thus
make any logformat token valid in its format parameter field.

As a result much of the logic surrounding format code parsing, display
and helper query generation has been completely dropped. What remains is
a basic parse loop handling backward compatibility for the unusual
%CERT_* token syntax, space delimiter and field default encodings.


Extensions to logformat resulting from the merger:

* adds \-escape encoding of output fields

* allows {arg} field to be placed before or after the format code.

* extended to accept the old external_acl_type %macros. But not
  documented, these are deprecated and only for backward compatibility.

* extended to support outputting formats without a format-name prefix
  as was required by the original logformat config lines.


The major side effect of this change is that these ACLs now require
AccessLogEntry to be filled out with state data, rather than just the
ACLChecklist object members.

The requires*() mechanism of ACLChecklist has been extended to catch
some cases resulting from missing the ALE entirely. But it cannot catch
the more subtle problem of data members inside the ALE being unset.
To try and catch those a syncAle() mechanism has been added that fills
out missing ALE members and prints out debug warnings about the action.",993,data/crawl/squid/hunk_554.cpp,,,data/crawl/squid/old_hunk_554.cpp,data/crawl/squid/new_hunk_554.cpp,14,-1,"storeAppendPrintf(sentry, "" %%>ha{%s:%s}"", format->header, format->member);",,"[""removeLog""]","[[""storeAppendPrintf"", ""sentry"", ""%%"", ""ha"", ""%s"", ""%s"", ""format"", ""header"", ""format"", ""member""], []]",[-12964631373922322168],5761,97200.0,2
https://github.com/squid-cache/squid/commit/cd6b1fd1bd9fc68574035857d649b85ba8713e3f,11 Oct 2015,"Support logformat %macros in external_acl_type format

Update the external_acl_type helper interface to use libformat and thus
make any logformat token valid in its format parameter field.

As a result much of the logic surrounding format code parsing, display
and helper query generation has been completely dropped. What remains is
a basic parse loop handling backward compatibility for the unusual
%CERT_* token syntax, space delimiter and field default encodings.


Extensions to logformat resulting from the merger:

* adds \-escape encoding of output fields

* allows {arg} field to be placed before or after the format code.

* extended to accept the old external_acl_type %macros. But not
  documented, these are deprecated and only for backward compatibility.

* extended to support outputting formats without a format-name prefix
  as was required by the original logformat config lines.


The major side effect of this change is that these ACLs now require
AccessLogEntry to be filled out with state data, rather than just the
ACLChecklist object members.

The requires*() mechanism of ACLChecklist has been extended to catch
some cases resulting from missing the ALE entirely. But it cannot catch
the more subtle problem of data members inside the ALE being unset.
To try and catch those a syncAle() mechanism has been added that fills
out missing ALE members and prints out debug warnings about the action.",993,data/crawl/squid/hunk_554.cpp,,,data/crawl/squid/old_hunk_554.cpp,data/crawl/squid/new_hunk_554.cpp,10,-1,"storeAppendPrintf(sentry, "" %%>ha{%s}"", format->header);",,"[""removeLog""]","[[""storeAppendPrintf"", ""sentry"", ""%%"", ""ha"", ""%s"", ""format"", ""header""], []]",[-3144431437315782819],5760,97200.0,2
https://github.com/squid-cache/squid/commit/d3b1bee6fff7792f482ff280e8400c6a3e83560f,14 Dec 2015,merge from trunk r14444,9318,data/crawl/squid/hunk_480.cpp,,,data/crawl/squid/old_hunk_480.cpp,data/crawl/squid/new_hunk_480.cpp,7,-1,"printf(""TEST @%d, in=%u: "" SQUIDSBUFPH ""\n"", line, input.length(), SQUIDSBUFPRINT(input));",,"[""removeLog""]","[[""printf"", ""TEST"", ""%d"", ""in"", ""%u"", ""SQUIDSBUFPH"", ""\\n"", ""line"", ""input"", ""length"", ""SQUIDSBUFPRINT"", ""input""], []]",[-11668271068217464555],5759,18720.0,2
https://github.com/squid-cache/squid/commit/d3b1bee6fff7792f482ff280e8400c6a3e83560f,14 Dec 2015,merge from trunk r14444,9318,data/crawl/squid/hunk_469.cpp,,,data/crawl/squid/old_hunk_469.cpp,data/crawl/squid/new_hunk_469.cpp,2,2,"storeAppendPrintf(s, ""\tin: buf %p, used %ld, free %ld\n"",
                              conn->in.buf.c_str(), (long int) conn->in.buf.length(), (long int) conn->in.buf.spaceSize());","storeAppendPrintf(s, ""\tin: buf %p, used %ld, free %ld\n"",
                              conn->inBuf.rawContent(), (long int) conn->inBuf.length(), (long int) conn->inBuf.spaceSize());","[""updateVariable"", ""removeVariable""]","[[""in"", ""buf"", ""c_str"", ""in"", ""buf"", ""in"", ""buf""], [""inBuf"", ""rawContent"", ""inBuf"", ""inBuf""]]",[-18168544405400053205],5758,26640.0,2
https://github.com/squid-cache/squid/commit/d3b1bee6fff7792f482ff280e8400c6a3e83560f,14 Dec 2015,merge from trunk r14444,9318,data/crawl/squid/hunk_468.cpp,,,data/crawl/squid/old_hunk_468.cpp,data/crawl/squid/new_hunk_468.cpp,16,-1,"fatalf(""Failed to allocate SSL context: %s\n"",
               ERR_error_string(ssl_error, NULL));",,"[""removeLog""]","[[""fatalf"", ""Failed"", ""to"", ""allocate"", ""SSL"", ""context"", ""%s\\n"", ""ERR_error_string"", ""ssl_error"", ""NULL""], []]",[3205522229705907561],5757,5040.0,2
https://github.com/squid-cache/squid/commit/d3b1bee6fff7792f482ff280e8400c6a3e83560f,14 Dec 2015,merge from trunk r14444,9318,data/crawl/squid/hunk_465.cpp,,,data/crawl/squid/old_hunk_465.cpp,data/crawl/squid/new_hunk_465.cpp,-1,202,,pipeline.front();,"[""addLog""]","[[], [""pipeline"", ""front""]]",[-11952880401463365318],5756,4320.0,2
https://github.com/squid-cache/squid/commit/d3b1bee6fff7792f482ff280e8400c6a3e83560f,14 Dec 2015,merge from trunk r14444,9318,data/crawl/squid/hunk_458.cpp,,,data/crawl/squid/old_hunk_458.cpp,data/crawl/squid/new_hunk_458.cpp,-1,28,,"fatal(""Failed to allocate TLS client context: No TLS library\n"");","[""addLog""]","[[], [""fatal"", ""Failed"", ""to"", ""allocate"", ""TLS"", ""client"", ""context"", ""No"", ""TLS"", ""library\\n""]]",[-12278005017212920364],5755,6480.0,2
https://github.com/squid-cache/squid/commit/d3b1bee6fff7792f482ff280e8400c6a3e83560f,14 Dec 2015,merge from trunk r14444,9318,data/crawl/squid/hunk_458.cpp,,,data/crawl/squid/old_hunk_458.cpp,data/crawl/squid/new_hunk_458.cpp,-1,24,,"fatalf(""Failed to allocate TLS client context: error=%d\n"", x);","[""addLog""]","[[], [""fatalf"", ""Failed"", ""to"", ""allocate"", ""TLS"", ""client"", ""context"", ""error"", ""%d\\n"", ""x""]]",[18170391452902056583],5754,6480.0,2
https://github.com/squid-cache/squid/commit/d3b1bee6fff7792f482ff280e8400c6a3e83560f,14 Dec 2015,merge from trunk r14444,9318,data/crawl/squid/hunk_458.cpp,,,data/crawl/squid/old_hunk_458.cpp,data/crawl/squid/new_hunk_458.cpp,-1,18,,"fatalf(""Failed to allocate TLS client context: %s\n"", x);","[""addLog""]","[[], [""fatalf"", ""Failed"", ""to"", ""allocate"", ""TLS"", ""client"", ""context"", ""%s\\n"", ""x""]]",[9885269667964676197],5753,6480.0,2
https://github.com/squid-cache/squid/commit/d3b1bee6fff7792f482ff280e8400c6a3e83560f,14 Dec 2015,merge from trunk r14444,9318,data/crawl/squid/hunk_450.cpp,,,data/crawl/squid/old_hunk_450.cpp,data/crawl/squid/new_hunk_450.cpp,11,11,"proxyProtocolError(in.buf.length() > 107? ""PROXY/1.0 error: missing CRLF"" : NULL);","proxyProtocolError(inBuf.length() > 107? ""PROXY/1.0 error: missing CRLF"" : NULL);","[""updateVariable"", ""removeVariable""]","[[""in"", ""buf""], [""inBuf""]]",[-8480006314502522670],5752,26640.0,2
https://github.com/squid-cache/squid/commit/d3b1bee6fff7792f482ff280e8400c6a3e83560f,14 Dec 2015,merge from trunk r14444,9318,data/crawl/squid/hunk_448.cpp,,,data/crawl/squid/old_hunk_448.cpp,data/crawl/squid/new_hunk_448.cpp,3,3,"fatal(""Hit unreachable code in clientWriteComplete\n"");","fatal(""Hit unreachable code in ClientSocketContext::writeComplete\n"");","[""updateContent""]","[[""clientWriteComplete\\n""], [""ClientSocketContext"", ""writeComplete\\n""]]",[-4898555348342993915],5751,4320.0,2
https://github.com/squid-cache/squid/commit/d3b1bee6fff7792f482ff280e8400c6a3e83560f,14 Dec 2015,merge from trunk r14444,9318,data/crawl/squid/hunk_447.cpp,,,data/crawl/squid/old_hunk_447.cpp,data/crawl/squid/new_hunk_447.cpp,8,8,"initiateClose(""STREAM_COMPLETE NOKEEPALIVE"");",finished();,"[""updateLog"", ""removeContent""]","[[""initiateClose"", ""STREAM_COMPLETE"", ""NOKEEPALIVE""], [""finished""]]",[8496373688227724293],5750,13680.0,2
https://github.com/squid-cache/squid/commit/d3b1bee6fff7792f482ff280e8400c6a3e83560f,14 Dec 2015,merge from trunk r14444,9318,data/crawl/squid/hunk_436.cpp,,,data/crawl/squid/old_hunk_436.cpp,data/crawl/squid/new_hunk_436.cpp,-1,3,,"fprintf(stderr,
            ""-r			Strip Kerberos realm from usernames\n"");
}

int;","[""addLog""]","[[], [""fprintf"", ""stderr"", ""r"", ""Strip"", ""Kerberos"", ""realm"", ""from"", ""usernames\\n"", ""int""]]",[-17687010202151829343],5749,18720.0,2
https://github.com/squid-cache/squid/commit/d3b1bee6fff7792f482ff280e8400c6a3e83560f,14 Dec 2015,merge from trunk r14444,9318,data/crawl/squid/hunk_435.cpp,,,data/crawl/squid/old_hunk_435.cpp,data/crawl/squid/new_hunk_435.cpp,177,-1,"fprintf(stderr, PROGRAM_NAME "": WARNING: User '%s' not found in '%s'\n"", login, searchbase);",,"[""removeLog""]","[[""fprintf"", ""stderr"", ""PROGRAM_NAME"", ""WARNING"", ""User"", ""%s"", ""not"", ""found"", ""in"", ""%s"", ""\\n"", ""login"", ""searchbase""], []]",[652222363118987845],5748,27360.0,2
https://github.com/squid-cache/squid/commit/d3b1bee6fff7792f482ff280e8400c6a3e83560f,14 Dec 2015,merge from trunk r14444,9318,data/crawl/squid/hunk_435.cpp,,,data/crawl/squid/old_hunk_435.cpp,data/crawl/squid/new_hunk_435.cpp,168,148,"fprintf(stderr, PROGRAM_NAME "": WARNING: SSL error %d (%s)\n"", sslerr, ldapssl_err2string(sslerr));","debug(""user filter '%s', searchbase '%s'\n"", filter.c_str(), searchbase.c_str());","[""updateLog"", ""removeVariable"", ""updateContent"", ""addVariable""]","[[""fprintf"", ""stderr"", ""PROGRAM_NAME"", ""WARNING"", ""SSL"", ""error"", ""%d"", ""sslerr"", ""ldapssl_err2string"", ""sslerr""], [""debug"", ""user"", ""filter"", ""searchbase"", ""%s"", ""filter"", ""c_str"", ""searchbase"", ""c_str""]]",[46269809388562088925],5747,27360.0,2
https://github.com/squid-cache/squid/commit/d3b1bee6fff7792f482ff280e8400c6a3e83560f,14 Dec 2015,merge from trunk r14444,9318,data/crawl/squid/hunk_435.cpp,,,data/crawl/squid/old_hunk_435.cpp,data/crawl/squid/new_hunk_435.cpp,105,71,"fprintf(stderr, PROGRAM_NAME "": ERROR: Failed to construct LDAP search filter. filter=\""%s\"", user=\""%s\"", group=\""%s\""\n"", filter, member, group);",searchBaseStream.str();,"[""addLog"", ""removeVariable"", ""removeContent"", ""removeLog""]","[[""fprintf"", ""stderr"", ""PROGRAM_NAME"", ""ERROR"", ""Failed"", ""to"", ""construct"", ""LDAP"", ""search"", ""filter"", ""filter"", ""\\"", ""%s\\"", ""user"", ""\\"", ""%s\\"", ""group"", ""\\"", ""%s\\"", ""\\n"", ""filter"", ""member"", ""group""], [""searchBaseStream"", ""str""]]",[-1037921730804843840],5746,27360.0,2
https://github.com/squid-cache/squid/commit/d3b1bee6fff7792f482ff280e8400c6a3e83560f,14 Dec 2015,merge from trunk r14444,9318,data/crawl/squid/hunk_435.cpp,,,data/crawl/squid/old_hunk_435.cpp,data/crawl/squid/new_hunk_435.cpp,82,-1,"fprintf(stderr, ""ERROR: Filter too large\n"");",,"[""removeLog""]","[[""fprintf"", ""stderr"", ""ERROR"", ""Filter"", ""too"", ""large\\n""], []]",[-1201216559385159430],5745,27360.0,2
https://github.com/squid-cache/squid/commit/435c72b07c5b7ebf782049cd2b50abe79a6f7db5,15 Jan 2016,"Bug 4005: Dynamic certificate cache exceeds dynamic_cert_mem_cache_size

* disable the use of system CA by default to verify client connection
  certificates. Since the use of client certificates is rare.

* no change to verification of upstream server or peer certificates.
  Since the use of system CA to sign server certificates is common.

* the new ""default-ca"" configuration option and its documentation are
  updated to make the situation more obvious amongst the other TLS options
  changes in Squid-4.

* the action of the sslflags=NO_DEFAULT_CA is already deprecated, so no
  change when it is used. On port lines it now merely sets the default.

It may be a good idea to also disable system CA use for cache_peer and
ICAPS connections. For now they are left unchanged.",75,data/crawl/squid/hunk_408.cpp,,,data/crawl/squid/old_hunk_408.cpp,data/crawl/squid/new_hunk_408.cpp,-1,5,,"fatalf(""ERROR: previous default-ca settings conflict with %s"", token);","[""addLog""]","[[], [""fatalf"", ""ERROR"", ""previous"", ""default"", ""ca"", ""settings"", ""conflict"", ""with"", ""%s"", ""token""]]",[38334019282850093747],5744,0.0,2
https://github.com/squid-cache/squid/commit/92cfc72f72e0dfd7509337fdee2104d15cb4000f,25 Jan 2016,"Invalid FTP connection handling on blocked content.

FTP client gets stuck after the following chain of events:
 * Client requests a file that will be blocked by ICAP.
 * Squid starts downloading the file from the FTP server
   and sends ""150 Opening..."" to the FTP client.
 * Squid aborts the data connection with the FTP server
   as soon as the ICAP service blocks it.
 * Squid sends ""451 Forbidden"" to the FTP client.
 * The FTP server sends ""500 OOPS: setsockopt: linger"" to Squid.
 * Squid terminates the control connection to the FTP server.
 * Squid establishes a new control connection to the FTP server
   but does not authenticate itself.
 * Further commands from the FTP client do not work any more.

The above and many similar problems exist because Squid handles
FTP client-to-squid and squid-to-FTP server data connections
independently from each other. In many cases, one connection does
not get notified about the problems with the other connection.

This patch:
  - Add Ftp::MasterState::userDataDone to record received
    the FTP client final response status code to sent (or to be send)
    to the client.
  - The Ftp::MasterState::waitForOriginData flag to hold status of the
    squid-to-server side. If the squid-to-server side is not finishes
    yet this is true.
  - Send a control reply to the FTP client only after the data transfered
    on both server and client sides.
  - Split Client::abortTransaction to Client::abortOnData and to
    Client::abortAll()
  - Implement the Ftp::Relay::abortOnData() and Ftp::Relay::Abort()
    (i.e., StoreEntry abort handler) to avoid closing the control
    connection when the data connection is closed unexpectedly.

This is a Measurement Factory project.",221,data/crawl/squid/hunk_400.cpp,,,data/crawl/squid/old_hunk_400.cpp,data/crawl/squid/new_hunk_400.cpp,7,7,"writeCustomReply(451, ""Server error; transfer aborted"");",userDataCompletionCheckpoint(451);,"[""updateLog"", ""removeContent""]","[[""writeCustomReply"", ""Server"", ""error"", ""transfer"", ""aborted""], [""userDataCompletionCheckpoint""]]",[-3986962145599181620],5743,0.0,2
https://github.com/squid-cache/squid/commit/92cfc72f72e0dfd7509337fdee2104d15cb4000f,25 Jan 2016,"Invalid FTP connection handling on blocked content.

FTP client gets stuck after the following chain of events:
 * Client requests a file that will be blocked by ICAP.
 * Squid starts downloading the file from the FTP server
   and sends ""150 Opening..."" to the FTP client.
 * Squid aborts the data connection with the FTP server
   as soon as the ICAP service blocks it.
 * Squid sends ""451 Forbidden"" to the FTP client.
 * The FTP server sends ""500 OOPS: setsockopt: linger"" to Squid.
 * Squid terminates the control connection to the FTP server.
 * Squid establishes a new control connection to the FTP server
   but does not authenticate itself.
 * Further commands from the FTP client do not work any more.

The above and many similar problems exist because Squid handles
FTP client-to-squid and squid-to-FTP server data connections
independently from each other. In many cases, one connection does
not get notified about the problems with the other connection.

This patch:
  - Add Ftp::MasterState::userDataDone to record received
    the FTP client final response status code to sent (or to be send)
    to the client.
  - The Ftp::MasterState::waitForOriginData flag to hold status of the
    squid-to-server side. If the squid-to-server side is not finishes
    yet this is true.
  - Send a control reply to the FTP client only after the data transfered
    on both server and client sides.
  - Split Client::abortTransaction to Client::abortOnData and to
    Client::abortAll()
  - Implement the Ftp::Relay::abortOnData() and Ftp::Relay::Abort()
    (i.e., StoreEntry abort handler) to avoid closing the control
    connection when the data connection is closed unexpectedly.

This is a Measurement Factory project.",221,data/crawl/squid/hunk_376.cpp,,,data/crawl/squid/old_hunk_376.cpp,data/crawl/squid/new_hunk_376.cpp,-1,6,,abortAll(reason);,"[""addLog""]","[[], [""abortAll"", ""reason""]]",[-1798597281080182211],5742,0.0,2
https://github.com/squid-cache/squid/commit/898d1a09e1d9e8f39de5d34df6793197c0fc8dc4,31 Jan 2016,"SourceLayout: rename ClientSocketContext to Http::Stream

 ... and provided through http/libsquid-http.la.

The name is chosen to match the RFC7540 HTTP/2 ""stream"" terminology.
Which defines a stream as a bi-directional transaction, including request,
reply and all related 1xx informational and/or control messages.

That same word ""stream"" is also used in RFC7230 briefly to describe the
same ""transaction"" scope and details. But not formalized until RFC7540.

Http::Stream's may be initiated by a client HTTP request, Squid internally,
or in HTTP/2 a server PUSH_PROMISE frame.

There are no logic changes in this. Just symbol renaming and move.",1958,data/crawl/squid/hunk_369.cpp,,,data/crawl/squid/old_hunk_369.cpp,data/crawl/squid/new_hunk_369.cpp,-1,483,,"httpHeaderPutStrf(hdr, Http::HdrType::CONTENT_TYPE,
                              ""multipart/byteranges; boundary=\"""" SQUIDSTRINGPH ""\"""",
                              SQUIDSTRINGPRINT(http->range_iter.boundary));","[""addLog""]","[[], [""httpHeaderPutStrf"", ""hdr"", ""Http"", ""HdrType"", ""CONTENT_TYPE"", ""multipart/byteranges"", ""boundary"", ""\\"", ""SQUIDSTRINGPH"", ""\\"", ""SQUIDSTRINGPRINT"", ""http"", ""range_iter"", ""boundary""]]",[21143325136975783723],5741,15840.0,2
https://github.com/squid-cache/squid/commit/898d1a09e1d9e8f39de5d34df6793197c0fc8dc4,31 Jan 2016,"SourceLayout: rename ClientSocketContext to Http::Stream

 ... and provided through http/libsquid-http.la.

The name is chosen to match the RFC7540 HTTP/2 ""stream"" terminology.
Which defines a stream as a bi-directional transaction, including request,
reply and all related 1xx informational and/or control messages.

That same word ""stream"" is also used in RFC7230 briefly to describe the
same ""transaction"" scope and details. But not formalized until RFC7540.

Http::Stream's may be initiated by a client HTTP request, Squid internally,
or in HTTP/2 a server PUSH_PROMISE frame.

There are no logic changes in this. Just symbol renaming and move.",1958,data/crawl/squid/hunk_369.cpp,,,data/crawl/squid/old_hunk_369.cpp,data/crawl/squid/new_hunk_369.cpp,-1,253,,"fatal (""unreachable code\n"");","[""addLog""]","[[], [""fatal"", ""unreachable"", ""code\\n""]]",[-11845206034455773657],5740,15840.0,2
https://github.com/squid-cache/squid/commit/898d1a09e1d9e8f39de5d34df6793197c0fc8dc4,31 Jan 2016,"SourceLayout: rename ClientSocketContext to Http::Stream

 ... and provided through http/libsquid-http.la.

The name is chosen to match the RFC7540 HTTP/2 ""stream"" terminology.
Which defines a stream as a bi-directional transaction, including request,
reply and all related 1xx informational and/or control messages.

That same word ""stream"" is also used in RFC7230 briefly to describe the
same ""transaction"" scope and details. But not formalized until RFC7540.

Http::Stream's may be initiated by a client HTTP request, Squid internally,
or in HTTP/2 a server PUSH_PROMISE frame.

There are no logic changes in this. Just symbol renaming and move.",1958,data/crawl/squid/hunk_369.cpp,,,data/crawl/squid/old_hunk_369.cpp,data/crawl/squid/new_hunk_369.cpp,-1,93,,"initiateClose(""STREAM_UNPLANNED_COMPLETE"");","[""addLog""]","[[], [""initiateClose"", ""STREAM_UNPLANNED_COMPLETE""]]",[9768814549245201169],5739,15840.0,2
https://github.com/squid-cache/squid/commit/898d1a09e1d9e8f39de5d34df6793197c0fc8dc4,31 Jan 2016,"SourceLayout: rename ClientSocketContext to Http::Stream

 ... and provided through http/libsquid-http.la.

The name is chosen to match the RFC7540 HTTP/2 ""stream"" terminology.
Which defines a stream as a bi-directional transaction, including request,
reply and all related 1xx informational and/or control messages.

That same word ""stream"" is also used in RFC7230 briefly to describe the
same ""transaction"" scope and details. But not formalized until RFC7540.

Http::Stream's may be initiated by a client HTTP request, Squid internally,
or in HTTP/2 a server PUSH_PROMISE frame.

There are no logic changes in this. Just symbol renaming and move.",1958,data/crawl/squid/hunk_365.cpp,,,data/crawl/squid/old_hunk_365.cpp,data/crawl/squid/new_hunk_365.cpp,45,-1,"initiateClose(""STREAM_FAILED"");",,"[""removeLog""]","[[""initiateClose"", ""STREAM_FAILED""], []]",[774983655038102417],5738,15840.0,2
https://github.com/squid-cache/squid/commit/898d1a09e1d9e8f39de5d34df6793197c0fc8dc4,31 Jan 2016,"SourceLayout: rename ClientSocketContext to Http::Stream

 ... and provided through http/libsquid-http.la.

The name is chosen to match the RFC7540 HTTP/2 ""stream"" terminology.
Which defines a stream as a bi-directional transaction, including request,
reply and all related 1xx informational and/or control messages.

That same word ""stream"" is also used in RFC7230 briefly to describe the
same ""transaction"" scope and details. But not formalized until RFC7540.

Http::Stream's may be initiated by a client HTTP request, Squid internally,
or in HTTP/2 a server PUSH_PROMISE frame.

There are no logic changes in this. Just symbol renaming and move.",1958,data/crawl/squid/hunk_365.cpp,,,data/crawl/squid/old_hunk_365.cpp,data/crawl/squid/new_hunk_365.cpp,41,-1,"initiateClose(""STREAM_UNPLANNED_COMPLETE"");",,"[""removeLog""]","[[""initiateClose"", ""STREAM_UNPLANNED_COMPLETE""], []]",[-9768814549245201169],5737,15840.0,2
https://github.com/squid-cache/squid/commit/898d1a09e1d9e8f39de5d34df6793197c0fc8dc4,31 Jan 2016,"SourceLayout: rename ClientSocketContext to Http::Stream

 ... and provided through http/libsquid-http.la.

The name is chosen to match the RFC7540 HTTP/2 ""stream"" terminology.
Which defines a stream as a bi-directional transaction, including request,
reply and all related 1xx informational and/or control messages.

That same word ""stream"" is also used in RFC7230 briefly to describe the
same ""transaction"" scope and details. But not formalized until RFC7540.

Http::Stream's may be initiated by a client HTTP request, Squid internally,
or in HTTP/2 a server PUSH_PROMISE frame.

There are no logic changes in this. Just symbol renaming and move.",1958,data/crawl/squid/hunk_365.cpp,,,data/crawl/squid/old_hunk_365.cpp,data/crawl/squid/new_hunk_365.cpp,19,-1,"initiateClose(""failure or true request status"");",,"[""removeLog""]","[[""initiateClose"", ""failure"", ""or"", ""true"", ""request"", ""status""], []]",[6969606714274698964],5736,15840.0,2
https://github.com/squid-cache/squid/commit/898d1a09e1d9e8f39de5d34df6793197c0fc8dc4,31 Jan 2016,"SourceLayout: rename ClientSocketContext to Http::Stream

 ... and provided through http/libsquid-http.la.

The name is chosen to match the RFC7540 HTTP/2 ""stream"" terminology.
Which defines a stream as a bi-directional transaction, including request,
reply and all related 1xx informational and/or control messages.

That same word ""stream"" is also used in RFC7230 briefly to describe the
same ""transaction"" scope and details. But not formalized until RFC7540.

Http::Stream's may be initiated by a client HTTP request, Squid internally,
or in HTTP/2 a server PUSH_PROMISE frame.

There are no logic changes in this. Just symbol renaming and move.",1958,data/crawl/squid/hunk_364.cpp,,,data/crawl/squid/old_hunk_364.cpp,data/crawl/squid/new_hunk_364.cpp,158,-1,"fatal (""unreachable code\n"");",,"[""removeLog""]","[[""fatal"", ""unreachable"", ""code\\n""], []]",[11845206034455773657],5735,15840.0,2
https://github.com/squid-cache/squid/commit/898d1a09e1d9e8f39de5d34df6793197c0fc8dc4,31 Jan 2016,"SourceLayout: rename ClientSocketContext to Http::Stream

 ... and provided through http/libsquid-http.la.

The name is chosen to match the RFC7540 HTTP/2 ""stream"" terminology.
Which defines a stream as a bi-directional transaction, including request,
reply and all related 1xx informational and/or control messages.

That same word ""stream"" is also used in RFC7230 briefly to describe the
same ""transaction"" scope and details. But not formalized until RFC7540.

Http::Stream's may be initiated by a client HTTP request, Squid internally,
or in HTTP/2 a server PUSH_PROMISE frame.

There are no logic changes in this. Just symbol renaming and move.",1958,data/crawl/squid/hunk_363.cpp,,,data/crawl/squid/old_hunk_363.cpp,data/crawl/squid/new_hunk_363.cpp,94,-1,"httpHeaderPutStrf(hdr, Http::HdrType::CONTENT_TYPE,
                              ""multipart/byteranges; boundary=\"""" SQUIDSTRINGPH ""\"""",
                              SQUIDSTRINGPRINT(http->range_iter.boundary));",,"[""removeLog""]","[[""httpHeaderPutStrf"", ""hdr"", ""Http"", ""HdrType"", ""CONTENT_TYPE"", ""multipart/byteranges"", ""boundary"", ""\\"", ""SQUIDSTRINGPH"", ""\\"", ""SQUIDSTRINGPRINT"", ""http"", ""range_iter"", ""boundary""], []]",[-21143325136975783723],5734,15840.0,2
https://github.com/squid-cache/squid/commit/0bffe3cec1400f4d69724552e77e77878defd8a3,23 May 2016,"Sync with trunk-r14686

- Replaces with newer versions of BinaryTokenizer and HandshakeParser classes
- Modifications to use latest Handshake parser from trunk.
- Get HandshakeParser::serverCertificates, HandshakeParser::parseServerCertificates and HandshakeParser::ParseCertificate implementation from lp:fast-sni branch",6170,data/crawl/squid/hunk_201.cpp,,,data/crawl/squid/old_hunk_201.cpp,data/crawl/squid/new_hunk_201.cpp,2,2,"storeAppendPrintf(sentry, ""IPcache Entries In Use:  %d\n"",
                      memInUse(MEM_IPCACHE_ENTRY));","storeAppendPrintf(sentry, ""IPcache Entries In Use:  %d\n"",
                      ipcache_entry::UseCount());","[""removeVariable"", ""addVariable""]","[[""memInUse"", ""MEM_IPCACHE_ENTRY""], [""ipcache_entry"", ""UseCount""]]",[-12799315290253497123],5733,7200.0,2
https://github.com/squid-cache/squid/commit/0bffe3cec1400f4d69724552e77e77878defd8a3,23 May 2016,"Sync with trunk-r14686

- Replaces with newer versions of BinaryTokenizer and HandshakeParser classes
- Modifications to use latest Handshake parser from trunk.
- Get HandshakeParser::serverCertificates, HandshakeParser::parseServerCertificates and HandshakeParser::ParseCertificate implementation from lp:fast-sni branch",6170,data/crawl/squid/hunk_199.cpp,,,data/crawl/squid/old_hunk_199.cpp,data/crawl/squid/new_hunk_199.cpp,-1,25,,"fatalf(""shared_memory_locking on but failed to mlock(%s, %"" PRId64 ""): %s\n"",
               theName.termedBuf(),static_cast<int64_t>(theSize), xstrerr(savedError));","[""addLog""]","[[], [""fatalf"", ""shared_memory_locking"", ""on"", ""but"", ""failed"", ""to"", ""mlock"", ""%s"", ""%"", ""PRId64"", ""%s\\n"", ""theName"", ""termedBuf"", ""static_cast"", ""int64_t"", ""theSize"", ""xstrerr"", ""savedError""]]",[4467300852808184852],5732,7200.0,2
https://github.com/squid-cache/squid/commit/0bffe3cec1400f4d69724552e77e77878defd8a3,23 May 2016,"Sync with trunk-r14686

- Replaces with newer versions of BinaryTokenizer and HandshakeParser classes
- Modifications to use latest Handshake parser from trunk.
- Get HandshakeParser::serverCertificates, HandshakeParser::parseServerCertificates and HandshakeParser::ParseCertificate implementation from lp:fast-sni branch",6170,data/crawl/squid/hunk_196.cpp,,,data/crawl/squid/old_hunk_196.cpp,data/crawl/squid/new_hunk_196.cpp,22,24,"fatalf(""Ipc::Mem::Segment::create failed to ftruncate(%s): %s\n"",
               theName.termedBuf(), xstrerr(savedError));","fatalf(""Ipc::Mem::Segment::create failed to ftruncate(%s): %s\n"",
               theName.termedBuf(), xstrerr(xerrno));","[""updateVariable""]","[[""savedError""], [""xerrno""]]",[2617411435797190167],5731,7200.0,2
https://github.com/squid-cache/squid/commit/0bffe3cec1400f4d69724552e77e77878defd8a3,23 May 2016,"Sync with trunk-r14686

- Replaces with newer versions of BinaryTokenizer and HandshakeParser classes
- Modifications to use latest Handshake parser from trunk.
- Get HandshakeParser::serverCertificates, HandshakeParser::parseServerCertificates and HandshakeParser::ParseCertificate implementation from lp:fast-sni branch",6170,data/crawl/squid/hunk_188.cpp,,,data/crawl/squid/old_hunk_188.cpp,data/crawl/squid/new_hunk_188.cpp,2,2,"storeAppendPrintf(sentry, ""FQDNcache Entries In Use: %d\n"",
                      memInUse(MEM_FQDNCACHE_ENTRY));","storeAppendPrintf(sentry, ""FQDNcache Entries In Use: %d\n"",
                      fqdncache_entry::UseCount());","[""removeVariable"", ""addVariable""]","[[""memInUse"", ""MEM_FQDNCACHE_ENTRY""], [""fqdncache_entry"", ""UseCount""]]",[-12751165572427847079],5730,7200.0,2
https://github.com/squid-cache/squid/commit/212e5aee4a29820cbdb0cab6dc98ba4e8b4ba3c4,01 Aug 2016,merge from trunk-r14768,3260,data/crawl/squid/hunk_154.cpp,,,data/crawl/squid/old_hunk_154.cpp,data/crawl/squid/new_hunk_154.cpp,-1,66,,"rep->header.putStr(Http::HdrType::HDR_X_ACCELERATOR_VARY, vary.termedBuf());","[""addLog""]","[[], [""rep"", ""header"", ""putStr"", ""Http"", ""HdrType"", ""HDR_X_ACCELERATOR_VARY"", ""vary"", ""termedBuf""]]",[814484456151971239],5729,6480.0,2
https://github.com/squid-cache/squid/commit/212e5aee4a29820cbdb0cab6dc98ba4e8b4ba3c4,01 Aug 2016,merge from trunk-r14768,3260,data/crawl/squid/hunk_154.cpp,,,data/crawl/squid/old_hunk_154.cpp,data/crawl/squid/new_hunk_154.cpp,-1,57,,"rep->header.putStr(Http::HdrType::VARY, vary.termedBuf());","[""addLog""]","[[], [""rep"", ""header"", ""putStr"", ""Http"", ""HdrType"", ""VARY"", ""vary"", ""termedBuf""]]",[-8134077890312363753],5728,6480.0,2
https://github.com/squid-cache/squid/commit/212e5aee4a29820cbdb0cab6dc98ba4e8b4ba3c4,01 Aug 2016,merge from trunk-r14768,3260,data/crawl/squid/hunk_153.cpp,,,data/crawl/squid/old_hunk_153.cpp,data/crawl/squid/new_hunk_153.cpp,46,19,"rep->header.putStr(Http::HdrType::HDR_X_ACCELERATOR_VARY, vary.termedBuf());",forcePublicKey(newKey);,"[""addLog"", ""removeVariable"", ""addVariable"", ""removeLog""]","[[""rep"", ""header"", ""putStr"", ""Http"", ""HdrType"", ""HDR_X_ACCELERATOR_VARY"", ""vary"", ""termedBuf""], [""forcePublicKey"", ""newKey""]]",[14179122037915579811],5727,6480.0,2
https://github.com/squid-cache/squid/commit/212e5aee4a29820cbdb0cab6dc98ba4e8b4ba3c4,01 Aug 2016,merge from trunk-r14768,3260,data/crawl/squid/hunk_153.cpp,,,data/crawl/squid/old_hunk_153.cpp,data/crawl/squid/new_hunk_153.cpp,37,16,"rep->header.putStr(Http::HdrType::VARY, vary.termedBuf());","!storeKeyHashCmp(key, newKey);","[""addLog"", ""removeVariable"", ""addVariable"", ""removeLog""]","[[""rep"", ""header"", ""putStr"", ""Http"", ""HdrType"", ""VARY"", ""vary"", ""termedBuf""], [""storeKeyHashCmp"", ""key"", ""newKey""]]",[13893915046768551035],5726,6480.0,2
https://github.com/squid-cache/squid/commit/212e5aee4a29820cbdb0cab6dc98ba4e8b4ba3c4,01 Aug 2016,merge from trunk-r14768,3260,data/crawl/squid/hunk_152.cpp,,,data/crawl/squid/old_hunk_152.cpp,data/crawl/squid/new_hunk_152.cpp,-1,28,,"mustStop(""Security::PeerConnector TLS socket initialize failed"");","[""addLog""]","[[], [""mustStop"", ""Security"", ""PeerConnector"", ""TLS"", ""socket"", ""initialize"", ""failed""]]",[-6006443342477954325],5725,3600.0,2
https://github.com/squid-cache/squid/commit/212e5aee4a29820cbdb0cab6dc98ba4e8b4ba3c4,01 Aug 2016,merge from trunk-r14768,3260,data/crawl/squid/hunk_148.cpp,,,data/crawl/squid/old_hunk_148.cpp,data/crawl/squid/new_hunk_148.cpp,8,8,"storeAppendPrintf(e, ""\t deletion attempts: %d\n"",
                      cd->del_count
                     );","storeAppendPrintf(e, ""\t deletion attempts: %"" PRIu64 ""\n"",
                      cd->del_count
                     );","[""updateContent"", ""addContent"", ""addVariable""]","[[""%d\\n""], [""%"", ""PRIu64"", ""\\n""]]",[1104258391187974023],5724,14400.0,2
https://github.com/squid-cache/squid/commit/212e5aee4a29820cbdb0cab6dc98ba4e8b4ba3c4,01 Aug 2016,merge from trunk-r14768,3260,data/crawl/squid/hunk_148.cpp,,,data/crawl/squid/old_hunk_148.cpp,data/crawl/squid/new_hunk_148.cpp,3,3,"storeAppendPrintf(e, ""\t entries: count: %d capacity: %d util: %d%%\n"",
                      cd->count,
                      cd->capacity,
                      xpercentInt(cd->count, cd->capacity)
                     );","storeAppendPrintf(e, ""\t entries: count: %"" PRIu64 "" capacity: %"" PRIu64 "" util: %d%%\n"",
                      cd->count,
                      cd->capacity,
                      xpercentInt(cd->count, cd->capacity)
                     );","[""updateContent"", ""addContent"", ""addVariable""]","[[""%d"", ""%d""], [""%"", ""PRIu64"", ""%"", ""PRIu64""]]",[14465389062679068742],5723,14400.0,2
https://github.com/squid-cache/squid/commit/6f9f8f9d10ce1fedbd52f4362c6982d5308a9c4d,01 Aug 2016,"Fetch missing certificates

Many web servers do not have complete certificate chains. Many browsers use
certificate extensions of the server certificate and download the missing
intermediate certificates automatically from the Internet.
This patch add this feature to Squid.

The information for missing issuer certificates provided by the Authority
Information Access X509 extension. This describes the format and the location
of additional information provided by the issuer of the certificate.

This patch:
  - Implements a class Downloader as an independet AsyncJob class. This new
    class can be used by internal squid subsystems to download objects from
    the network.
  - Modify Ssl::PeerConnector class to use new Downloader class to
    retrieve missing certificates from the net. The URIs of missing
    certificates from the Authority Information Access X509 extension.
  - Implements a new basic certificates parser based on openSSL for the
    TLS handshake messages parser.
  - Modify the Ssl::ServerBio class to:
     * Buffer the Server Hello message and not pass it to the openSSL library
       until downloading missing certificates, if any, is finished.
     * Extract server certificates from server hello message.
       This is required to check if there are missing certificates, and if yes
       give the chance to squid to download missing certificates and complete
       certificate chains before pass them for processing to openSSL

TODO:
  - Add support for certs-only CMS message.
    From  RFC 4325:
    ""Where the information is available via HTTP or FTP, accessLocation
    MUST be a uniformResourceIdentifier and the URI MUST point to either
    a single DER encoded certificate as specified in [RFC2585] or a
    collection of certificates in a BER or DER encoded ""certs-only"" CMS
    message as specified in [RFC2797]. ""
    ...
    ""Conforming applications that support HTTP or FTP for accessing
    certificates MUST be able to accept individual DER encoded
    certificates and SHOULD be able to accept ""certs-only"" CMS messages.""

This is a Measurement Factory project",808,data/crawl/squid/hunk_147.cpp,,,data/crawl/squid/old_hunk_147.cpp,data/crawl/squid/new_hunk_147.cpp,-1,125,,"request->header.putStr(Http::HdrType::HOST, request->url.host());","[""addLog""]","[[], [""request"", ""header"", ""putStr"", ""Http"", ""HdrType"", ""HOST"", ""request"", ""url"", ""host""]]",[8982126471591930796],5722,204480.0,2
https://github.com/squid-cache/squid/commit/c438bcf10742e773a8e602a398c884ea54080336,20 Nov 2016,"C++11: Remove GnuRegex and all -lregex related code

Squid is now exclusively using the STL std::regex API provided on all
operating systems in a portable manner.

We no longer have any need of detecting if the system is providing a
libregex, or user has configured one, or if it actually works, or how
to call it, or use the GnuRegex code as a backup when one of those
complex details goes wrong.",5393,data/crawl/squid/hunk_130.cpp,,,data/crawl/squid/old_hunk_130.cpp,data/crawl/squid/new_hunk_130.cpp,-1,12,,"fprintf(stderr, ""%s:%lu: invalid regular expression\n"", optarg, lineno);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""%s"", ""%lu"", ""invalid"", ""regular"", ""expression\\n"", ""optarg"", ""lineno""]]",[-37920854530838474060],5721,347040.0,2
https://github.com/squid-cache/squid/commit/c438bcf10742e773a8e602a398c884ea54080336,20 Nov 2016,"C++11: Remove GnuRegex and all -lregex related code

Squid is now exclusively using the STL std::regex API provided on all
operating systems in a portable manner.

We no longer have any need of detecting if the system is providing a
libregex, or user has configured one, or if it actually works, or how
to call it, or use the GnuRegex code as a backup when one of those
complex details goes wrong.",5393,data/crawl/squid/hunk_129.cpp,,,data/crawl/squid/old_hunk_129.cpp,data/crawl/squid/new_hunk_129.cpp,-1,11,,"fprintf(stderr, ""%c contains invalid regular expression: %s\n"", option, optarg);","[""addLog""]","[[], [""fprintf"", ""stderr"", ""%c"", ""contains"", ""invalid"", ""regular"", ""expression"", ""%s\\n"", ""option"", ""optarg""]]",[-22393255325246936138],5720,347040.0,2
https://github.com/squid-cache/squid/commit/c438bcf10742e773a8e602a398c884ea54080336,20 Nov 2016,"C++11: Remove GnuRegex and all -lregex related code

Squid is now exclusively using the STL std::regex API provided on all
operating systems in a portable manner.

We no longer have any need of detecting if the system is providing a
libregex, or user has configured one, or if it actually works, or how
to call it, or use the GnuRegex code as a backup when one of those
complex details goes wrong.",5393,data/crawl/squid/hunk_128.cpp,,,data/crawl/squid/old_hunk_128.cpp,data/crawl/squid/new_hunk_128.cpp,40,-1,"fprintf( stderr, ""unable to execute re \""%s\""\n+ on line \""%s\"": %s\n"",
                 data, check, buffer );",,"[""removeLog""]","[[""fprintf"", ""stderr"", ""unable"", ""to"", ""execute"", ""re"", ""\\"", ""%s\\"", ""\\n"", ""on"", ""line"", ""\\"", ""%s\\"", ""%s\\n"", ""data"", ""check"", ""buffer""], []]",[12868624580167603209],5719,347040.0,2
https://github.com/squid-cache/squid/commit/c438bcf10742e773a8e602a398c884ea54080336,20 Nov 2016,"C++11: Remove GnuRegex and all -lregex related code

Squid is now exclusively using the STL std::regex API provided on all
operating systems in a portable manner.

We no longer have any need of detecting if the system is providing a
libregex, or user has configured one, or if it actually works, or how
to call it, or use the GnuRegex code as a backup when one of those
complex details goes wrong.",5393,data/crawl/squid/hunk_128.cpp,,,data/crawl/squid/old_hunk_128.cpp,data/crawl/squid/new_hunk_128.cpp,21,-1,"fprintf( stderr, ""unable to compile re \""%s\"": %s\n"", what, buffer );",,"[""removeLog""]","[[""fprintf"", ""stderr"", ""unable"", ""to"", ""compile"", ""re"", ""\\"", ""%s\\"", ""%s\\n"", ""what"", ""buffer""], []]",[3281625968545951533],5718,347040.0,2
https://github.com/squid-cache/squid/commit/c438bcf10742e773a8e602a398c884ea54080336,20 Nov 2016,"C++11: Remove GnuRegex and all -lregex related code

Squid is now exclusively using the STL std::regex API provided on all
operating systems in a portable manner.

We no longer have any need of detecting if the system is providing a
libregex, or user has configured one, or if it actually works, or how
to call it, or use the GnuRegex code as a backup when one of those
complex details goes wrong.",5393,data/crawl/squid/hunk_127.cpp,,,data/crawl/squid/old_hunk_127.cpp,data/crawl/squid/new_hunk_127.cpp,17,9,"fprintf( debug, ""# match from %d-%d on line %s"",
                                      (int)subs[0].rm_so, (int)subs[0].rm_eo,
                                      line );","fprintf( debug, ""# match '%s' on line %s"", subs[0].str().c_str(), line);","[""updateVariable"", ""removeVariable"", ""updateContent"", ""removeContent"", ""addVariable""]","[[""from"", ""%d"", ""%d"", ""int"", ""rm_so"", ""int"", ""subs[0]"", ""rm_eo""], [""%s"", ""str"", ""c_str""]]",[18700499392016040342],5717,347040.0,2
https://github.com/squid-cache/squid/commit/c438bcf10742e773a8e602a398c884ea54080336,20 Nov 2016,"C++11: Remove GnuRegex and all -lregex related code

Squid is now exclusively using the STL std::regex API provided on all
operating systems in a portable manner.

We no longer have any need of detecting if the system is providing a
libregex, or user has configured one, or if it actually works, or how
to call it, or use the GnuRegex code as a backup when one of those
complex details goes wrong.",5393,data/crawl/squid/hunk_127.cpp,,,data/crawl/squid/old_hunk_127.cpp,data/crawl/squid/new_hunk_127.cpp,8,-1,"fprintf( stderr, ""while matching \""%s\"" against %s%s\n"",
                         expression, line, buffer );",,"[""removeLog""]","[[""fprintf"", ""stderr"", ""while"", ""matching"", ""\\"", ""%s\\"", ""against"", ""%s%s\\n"", ""expression"", ""line"", ""buffer""], []]",[-2788216991202310185],5716,347040.0,2
https://github.com/squid-cache/squid/commit/c438bcf10742e773a8e602a398c884ea54080336,20 Nov 2016,"C++11: Remove GnuRegex and all -lregex related code

Squid is now exclusively using the STL std::regex API provided on all
operating systems in a portable manner.

We no longer have any need of detecting if the system is providing a
libregex, or user has configured one, or if it actually works, or how
to call it, or use the GnuRegex code as a backup when one of those
complex details goes wrong.",5393,data/crawl/squid/hunk_126.cpp,,,data/crawl/squid/old_hunk_126.cpp,data/crawl/squid/new_hunk_126.cpp,9,-1,"fprintf( stderr, ""regular expression \""%s\"": %s\n"", expression, buffer );",,"[""removeLog""]","[[""fprintf"", ""stderr"", ""regular"", ""expression"", ""\\"", ""%s\\"", ""%s\\n"", ""expression"", ""buffer""], []]",[23498982089002190601],5715,347040.0,2
https://github.com/squid-cache/squid/commit/c2afddd8f98c17c7a9e03d504b97847065d744e1,30 Nov 2016,"Revert C++11 std::regex changes

CentOS 7 (and thus probably also RHEL 7) still have difficulty using
GCC 5+ compiler necessary for this C++11 code to be used reliably.

see http://lists.squid-cache.org/pipermail/squid-dev/2015-July/002884.html",5399,data/crawl/squid/hunk_121.cpp,,,data/crawl/squid/old_hunk_121.cpp,data/crawl/squid/new_hunk_121.cpp,-1,40,,"fprintf( stderr, ""unable to execute re \""%s\""\n+ on line \""%s\"": %s\n"",
                 data, check, buffer );","[""addLog""]","[[], [""fprintf"", ""stderr"", ""unable"", ""to"", ""execute"", ""re"", ""\\"", ""%s\\"", ""\\n"", ""on"", ""line"", ""\\"", ""%s\\"", ""%s\\n"", ""data"", ""check"", ""buffer""]]",[-12868624580167603209],5714,1682640.0,2
https://github.com/squid-cache/squid/commit/c2afddd8f98c17c7a9e03d504b97847065d744e1,30 Nov 2016,"Revert C++11 std::regex changes

CentOS 7 (and thus probably also RHEL 7) still have difficulty using
GCC 5+ compiler necessary for this C++11 code to be used reliably.

see http://lists.squid-cache.org/pipermail/squid-dev/2015-July/002884.html",5399,data/crawl/squid/hunk_121.cpp,,,data/crawl/squid/old_hunk_121.cpp,data/crawl/squid/new_hunk_121.cpp,-1,21,,"fprintf( stderr, ""unable to compile re \""%s\"": %s\n"", what, buffer );","[""addLog""]","[[], [""fprintf"", ""stderr"", ""unable"", ""to"", ""compile"", ""re"", ""\\"", ""%s\\"", ""%s\\n"", ""what"", ""buffer""]]",[-3281625968545951533],5713,1682640.0,2
https://github.com/squid-cache/squid/commit/c2afddd8f98c17c7a9e03d504b97847065d744e1,30 Nov 2016,"Revert C++11 std::regex changes

CentOS 7 (and thus probably also RHEL 7) still have difficulty using
GCC 5+ compiler necessary for this C++11 code to be used reliably.

see http://lists.squid-cache.org/pipermail/squid-dev/2015-July/002884.html",5399,data/crawl/squid/hunk_120.cpp,,,data/crawl/squid/old_hunk_120.cpp,data/crawl/squid/new_hunk_120.cpp,-1,8,,"fprintf( stderr, ""while matching \""%s\"" against %s%s\n"",
                         expression, line, buffer );","[""addLog""]","[[], [""fprintf"", ""stderr"", ""while"", ""matching"", ""\\"", ""%s\\"", ""against"", ""%s%s\\n"", ""expression"", ""line"", ""buffer""]]",[2788216991202310185],5712,1682640.0,2
https://github.com/squid-cache/squid/commit/c2afddd8f98c17c7a9e03d504b97847065d744e1,30 Nov 2016,"Revert C++11 std::regex changes

CentOS 7 (and thus probably also RHEL 7) still have difficulty using
GCC 5+ compiler necessary for this C++11 code to be used reliably.

see http://lists.squid-cache.org/pipermail/squid-dev/2015-July/002884.html",5399,data/crawl/squid/hunk_119.cpp,,,data/crawl/squid/old_hunk_119.cpp,data/crawl/squid/new_hunk_119.cpp,-1,9,,"fprintf( stderr, ""regular expression \""%s\"": %s\n"", expression, buffer );","[""addLog""]","[[], [""fprintf"", ""stderr"", ""regular"", ""expression"", ""\\"", ""%s\\"", ""%s\\n"", ""expression"", ""buffer""]]",[-23498982089002190601],5711,1682640.0,2
https://github.com/squid-cache/squid/commit/50ad1e256824307b27dae0fbb078d65df8e2f816,21 Dec 2016,"Cleanup: Refactor libauth Config object(s)

Refactoring the Auth::Config objects to get v5 building again.

The object storing auth_param settings is renamed to SchemeConfig.

A new Auth::Config object is added. The objects holding auth_param,
auth_schemes and other authenticate_* directives settings are stored
there instead of just auth_params.

Lots of outdated doxygen docs that have more up to date copies elsewhere
are removed. The ""\ingroup AuthAPI"" are left for now since some auth
things are not yet in the Auth:: namespace, but other auth related
groups are dropped completely.

Code parsing and dumping auth_param lines has been de-duplicated. Along
with the keep_alive and utf8 settings, which are shared by multiple
schemes. This allows dropping several virtual methods from NTLM and
Negotiate scheme objects.

An auth/forward.h file is added for predefines. Some initial Auth::
symbols are listed there. It is not complete, but others can be added as
needed later.

Some unnecessary includes have been removed. There are probably more. I
just did the obvious ones related to the new auth/forward.h and
auth/Config.h files at this time.",1335,data/crawl/squid/hunk_108.cpp,,,data/crawl/squid/old_hunk_108.cpp,data/crawl/squid/new_hunk_108.cpp,9,-1,"storeAppendPrintf(entry, ""%s ntlm keep_alive %s\n"", name, keep_alive ? ""on"" : ""off"");",,"[""removeLog""]","[[""storeAppendPrintf"", ""entry"", ""%s"", ""ntlm"", ""keep_alive"", ""%s\\n"", ""name"", ""keep_alive"", ""on"", ""off""], []]",[-2565911168582275027],5710,720.0,2
https://github.com/squid-cache/squid/commit/50ad1e256824307b27dae0fbb078d65df8e2f816,21 Dec 2016,"Cleanup: Refactor libauth Config object(s)

Refactoring the Auth::Config objects to get v5 building again.

The object storing auth_param settings is renamed to SchemeConfig.

A new Auth::Config object is added. The objects holding auth_param,
auth_schemes and other authenticate_* directives settings are stored
there instead of just auth_params.

Lots of outdated doxygen docs that have more up to date copies elsewhere
are removed. The ""\ingroup AuthAPI"" are left for now since some auth
things are not yet in the Auth:: namespace, but other auth related
groups are dropped completely.

Code parsing and dumping auth_param lines has been de-duplicated. Along
with the keep_alive and utf8 settings, which are shared by multiple
schemes. This allows dropping several virtual methods from NTLM and
Negotiate scheme objects.

An auth/forward.h file is added for predefines. Some initial Auth::
symbols are listed there. It is not complete, but others can be added as
needed later.

Some unnecessary includes have been removed. There are probably more. I
just did the obvious ones related to the new auth/forward.h and
auth/Config.h files at this time.",1335,data/crawl/squid/hunk_107.cpp,,,data/crawl/squid/old_hunk_107.cpp,data/crawl/squid/new_hunk_107.cpp,9,-1,"storeAppendPrintf(entry, ""%s negotiate keep_alive %s\n"", name, keep_alive ? ""on"" : ""off"");",,"[""removeLog""]","[[""storeAppendPrintf"", ""entry"", ""%s"", ""negotiate"", ""keep_alive"", ""%s\\n"", ""name"", ""keep_alive"", ""on"", ""off""], []]",[-3401182741575433013],5709,720.0,2
https://github.com/squid-cache/squid/commit/50ad1e256824307b27dae0fbb078d65df8e2f816,21 Dec 2016,"Cleanup: Refactor libauth Config object(s)

Refactoring the Auth::Config objects to get v5 building again.

The object storing auth_param settings is renamed to SchemeConfig.

A new Auth::Config object is added. The objects holding auth_param,
auth_schemes and other authenticate_* directives settings are stored
there instead of just auth_params.

Lots of outdated doxygen docs that have more up to date copies elsewhere
are removed. The ""\ingroup AuthAPI"" are left for now since some auth
things are not yet in the Auth:: namespace, but other auth related
groups are dropped completely.

Code parsing and dumping auth_param lines has been de-duplicated. Along
with the keep_alive and utf8 settings, which are shared by multiple
schemes. This allows dropping several virtual methods from NTLM and
Negotiate scheme objects.

An auth/forward.h file is added for predefines. Some initial Auth::
symbols are listed there. It is not complete, but others can be added as
needed later.

Some unnecessary includes have been removed. There are probably more. I
just did the obvious ones related to the new auth/forward.h and
auth/Config.h files at this time.",1335,data/crawl/squid/hunk_106.cpp,,,data/crawl/squid/old_hunk_106.cpp,data/crawl/squid/new_hunk_106.cpp,12,-1,"storeAppendPrintf(entry, ""%s digest utf8 %s\n"", name, utf8 ? ""on"" : ""off"");",,"[""removeLog""]","[[""storeAppendPrintf"", ""entry"", ""%s"", ""digest"", ""utf8"", ""%s\\n"", ""name"", ""utf8"", ""on"", ""off""], []]",[-20501869205042293250],5708,720.0,2
https://github.com/squid-cache/squid/commit/50ad1e256824307b27dae0fbb078d65df8e2f816,21 Dec 2016,"Cleanup: Refactor libauth Config object(s)

Refactoring the Auth::Config objects to get v5 building again.

The object storing auth_param settings is renamed to SchemeConfig.

A new Auth::Config object is added. The objects holding auth_param,
auth_schemes and other authenticate_* directives settings are stored
there instead of just auth_params.

Lots of outdated doxygen docs that have more up to date copies elsewhere
are removed. The ""\ingroup AuthAPI"" are left for now since some auth
things are not yet in the Auth:: namespace, but other auth related
groups are dropped completely.

Code parsing and dumping auth_param lines has been de-duplicated. Along
with the keep_alive and utf8 settings, which are shared by multiple
schemes. This allows dropping several virtual methods from NTLM and
Negotiate scheme objects.

An auth/forward.h file is added for predefines. Some initial Auth::
symbols are listed there. It is not complete, but others can be added as
needed later.

Some unnecessary includes have been removed. There are probably more. I
just did the obvious ones related to the new auth/forward.h and
auth/Config.h files at this time.",1335,data/crawl/squid/hunk_105.cpp,,,data/crawl/squid/old_hunk_105.cpp,data/crawl/squid/new_hunk_105.cpp,10,-1,"storeAppendPrintf(entry, ""%s basic utf8 %s\n"", name, utf8 ? ""on"" : ""off"");",,"[""removeLog""]","[[""storeAppendPrintf"", ""entry"", ""%s"", ""basic"", ""utf8"", ""%s\\n"", ""name"", ""utf8"", ""on"", ""off""], []]",[-14459964624793455899],5707,720.0,2
https://github.com/squid-cache/squid/commit/50ad1e256824307b27dae0fbb078d65df8e2f816,21 Dec 2016,"Cleanup: Refactor libauth Config object(s)

Refactoring the Auth::Config objects to get v5 building again.

The object storing auth_param settings is renamed to SchemeConfig.

A new Auth::Config object is added. The objects holding auth_param,
auth_schemes and other authenticate_* directives settings are stored
there instead of just auth_params.

Lots of outdated doxygen docs that have more up to date copies elsewhere
are removed. The ""\ingroup AuthAPI"" are left for now since some auth
things are not yet in the Auth:: namespace, but other auth related
groups are dropped completely.

Code parsing and dumping auth_param lines has been de-duplicated. Along
with the keep_alive and utf8 settings, which are shared by multiple
schemes. This allows dropping several virtual methods from NTLM and
Negotiate scheme objects.

An auth/forward.h file is added for predefines. Some initial Auth::
symbols are listed there. It is not complete, but others can be added as
needed later.

Some unnecessary includes have been removed. There are probably more. I
just did the obvious ones related to the new auth/forward.h and
auth/Config.h files at this time.",1335,data/crawl/squid/hunk_104.cpp,,,data/crawl/squid/old_hunk_104.cpp,data/crawl/squid/new_hunk_104.cpp,-1,72,,"fatalf(""auth_schemes: required authentication method '%s' is not configured"", proxy_auth);","[""addLog""]","[[], [""fatalf"", ""auth_schemes"", ""required"", ""authentication"", ""method"", ""%s"", ""is"", ""not"", ""configured"", ""proxy_auth""]]",[-3174685343921212292],5706,7920.0,2
https://github.com/squid-cache/squid/commit/6f9a30f86fd6046d371dbdeab23a2781219f0a04,30 Jan 2017,"Fix Auth::UserRequest::denyMessage() misuse.

This method was improperly used in contexts where actually
Auth::UserRequest::setDenyMessage() expected. Probably the reason was
that both denyMessage() and getDenyMessage() were not constant,
provoking such 'misuse'.

Also placed some common code into UserRequest::denyMessageFromHelper(),
eliminating code duplication. Though there are still many places
where code is duplicated inside auth/ntlm/UserRequest.cc and
auth/negotiate/UserRequest.cc.",69,data/crawl/squid/hunk_81.cpp,,,data/crawl/squid/old_hunk_81.cpp,data/crawl/squid/new_hunk_81.cpp,5,-1,auth_user_request->denyMessage(errNote.c_str());,,"[""removeLog""]","[[""auth_user_request"", ""denyMessage"", ""errNote"", ""c_str""], []]",[722369976778917829],5705,0.0,2
https://github.com/squid-cache/squid/commit/3f5b28fe18637452647d7000a0ac21103f8b660e,05 Feb 2017,"Crypto-NG: initial GnuTLS support for encrypted server connections

Make significant changes to how the options= config settings are
handled internally since GnuTLS does not expose the priority_t
implementation details like OpenSSL. They are also applied to the
session object instead of to the context.

The Security::SessionPointer is converted to std::shared_ptr. This is
required because GnuTLS does not expose the locking like OpenSSL. Since
we store the SessionPointer to fde::Table::ssl we can always access it
from there one way or another and there is actually no need for OpenSSL
locking sessions now.

Most of the remaining session lifecycle logic is moved to
security/Session.* and given a generic API. Only some client-connection
and SSL-Bump related setup remains in ssl/.

A fair amount more debug is added along with some text changes doing
s/SSL/TLS/ in code comments and debug outputs.",780,data/crawl/squid/hunk_74.cpp,,,data/crawl/squid/old_hunk_74.cpp,data/crawl/squid/new_hunk_74.cpp,-1,21,,"fatalf(""Unknown TLS option '%s'"", err);","[""addLog""]","[[], [""fatalf"", ""Unknown"", ""TLS"", ""option"", ""%s"", ""err""]]",[-204188894663230612],5704,30960.0,2
https://github.com/squid-cache/squid/commit/40fc161851f5809741ddb4774e7c366d23323a97,05 Feb 2017,Sync from v5 r15034,2231,data/crawl/squid/hunk_66.cpp,,,data/crawl/squid/old_hunk_66.cpp,data/crawl/squid/new_hunk_66.cpp,15,-1,"storeAppendPrintf(sentry, ""Memory Used: %d bytes\n"", (int) DelayPools::MemoryUsed);",,"[""removeLog""]","[[""storeAppendPrintf"", ""sentry"", ""Memory"", ""Used"", ""%d"", ""bytes\\n"", ""int"", ""DelayPools"", ""MemoryUsed""], []]",[-20010407864835808745],5703,8640.0,2
https://github.com/squid-cache/squid/commit/40fc161851f5809741ddb4774e7c366d23323a97,05 Feb 2017,Sync from v5 r15034,2231,data/crawl/squid/hunk_56.cpp,,,data/crawl/squid/old_hunk_56.cpp,data/crawl/squid/new_hunk_56.cpp,-1,11,,setDenyMessage(messageNote.c_str());,"[""addLog""]","[[], [""setDenyMessage"", ""messageNote"", ""c_str""]]",[-226304927560905051],5702,4320.0,2
https://github.com/squid-cache/squid/commit/40fc161851f5809741ddb4774e7c366d23323a97,05 Feb 2017,Sync from v5 r15034,2231,data/crawl/squid/hunk_54.cpp,,,data/crawl/squid/old_hunk_54.cpp,data/crawl/squid/new_hunk_54.cpp,-1,174,,"fatalf(""FATAL: Missing annotation kv pair"");","[""addLog""]","[[], [""fatalf"", ""FATAL"", ""Missing"", ""annotation"", ""kv"", ""pair""]]",[4385817703251897094],5701,4320.0,2
https://github.com/squid-cache/squid/commit/40fc161851f5809741ddb4774e7c366d23323a97,05 Feb 2017,Sync from v5 r15034,2231,data/crawl/squid/hunk_54.cpp,,,data/crawl/squid/old_hunk_54.cpp,data/crawl/squid/new_hunk_54.cpp,-1,142,,"fatalf(""FATAL: Missing note value"");","[""addLog""]","[[], [""fatalf"", ""FATAL"", ""Missing"", ""note"", ""value""]]",[-5998824402352469382],5700,4320.0,2
https://github.com/squid-cache/squid/commit/40fc161851f5809741ddb4774e7c366d23323a97,05 Feb 2017,Sync from v5 r15034,2231,data/crawl/squid/hunk_54.cpp,,,data/crawl/squid/old_hunk_54.cpp,data/crawl/squid/new_hunk_54.cpp,-1,136,,"fatalf(""FATAL: Missing note key"");","[""addLog""]","[[], [""fatalf"", ""FATAL"", ""Missing"", ""note"", ""key""]]",[10605660967497066978],5699,4320.0,2
https://github.com/squid-cache/squid/commit/40fc161851f5809741ddb4774e7c366d23323a97,05 Feb 2017,Sync from v5 r15034,2231,data/crawl/squid/hunk_54.cpp,,,data/crawl/squid/old_hunk_54.cpp,data/crawl/squid/new_hunk_54.cpp,-1,72,,"storeAppendPrintf(entry, ""%s %.*s %s"",
                          k, key().length(), key().rawContent(), ConfigParser::QuoteString(SBufToString(v->value())));","[""addLog""]","[[], [""storeAppendPrintf"", ""entry"", ""%s"", ""%"", ""*s"", ""%s"", ""k"", ""key"", ""length"", ""key"", ""rawContent"", ""ConfigParser"", ""QuoteString"", ""SBufToString"", ""v"", ""value""]]",[29694995795933971076],5698,4320.0,2
https://github.com/squid-cache/squid/commit/40fc161851f5809741ddb4774e7c366d23323a97,05 Feb 2017,Sync from v5 r15034,2231,data/crawl/squid/hunk_54.cpp,,,data/crawl/squid/old_hunk_54.cpp,data/crawl/squid/new_hunk_54.cpp,91,-1,"storeAppendPrintf(entry, ""%s "" SQUIDSTRINGPH "" %s"",
                              key, SQUIDSTRINGPRINT((*m)->key), ConfigParser::QuoteString((*v)->value));",,"[""removeLog""]","[[""storeAppendPrintf"", ""entry"", ""%s"", ""SQUIDSTRINGPH"", ""%s"", ""key"", ""SQUIDSTRINGPRINT"", ""*m"", ""key"", ""ConfigParser"", ""QuoteString"", ""*v"", ""value""], []]",[561083083629220026],5697,4320.0,2
https://github.com/squid-cache/squid/commit/40fc161851f5809741ddb4774e7c366d23323a97,05 Feb 2017,Sync from v5 r15034,2231,data/crawl/squid/hunk_54.cpp,,,data/crawl/squid/old_hunk_54.cpp,data/crawl/squid/new_hunk_54.cpp,74,113,"fatalf(""%s:%d: meta key \""%s\"" is a reserved %s name"",
                       cfg_filename, config_lineno, note->key.termedBuf(),
                       descr ? descr : """");","fatalf(""%s:%d: meta key \""%.*s\"" is a reserved %s name"",
                       cfg_filename, config_lineno, key.length(), key.rawContent(),
                       descr ? descr : """");","[""updateVariable"", ""removeVariable"", ""updateContent"", ""addVariable""]","[[""%s\\"", ""note"", ""termedBuf""], [""%"", ""*s\\"", ""length"", ""key"", ""rawContent""]]",[34190132613708413875],5696,4320.0,2
https://github.com/squid-cache/squid/commit/5d3aafbed3edd9d4cc50d9f276010c51c6b942fe,20 Feb 2017,Sync with v5 rev.15058,1995,data/crawl/squid/hunk_44.cpp,,,data/crawl/squid/old_hunk_44.cpp,data/crawl/squid/new_hunk_44.cpp,12,12,"storeAppendPrintf(sentry, ""Address: %s\n"", hashKeyStr(&c->hash));","storeAppendPrintf(sentry, ""Address: %s\n"", hashKeyStr(hash));","[""removeVariable"", ""addVariable""]","[[""&c""], []]",[-4864029222043795],5695,720.0,2
https://github.com/squid-cache/squid/commit/5d3aafbed3edd9d4cc50d9f276010c51c6b942fe,20 Feb 2017,Sync with v5 rev.15058,1995,data/crawl/squid/hunk_43.cpp,,,data/crawl/squid/old_hunk_43.cpp,data/crawl/squid/new_hunk_43.cpp,-1,7,,"fprintf(stderr, ""\t-r filtered realm\t\t\tonly honor Squid requests for this realm. Mandatory if the password is alone in\n\t\t\t\t\t\tthe password attribute, acting as the implicit realm\n"");","[""addLog""]","[[], [""fprintf"", ""stderr"", ""\\t"", ""r"", ""filtered"", ""realm\\t\\t\\tonly"", ""honor"", ""Squid"", ""requests"", ""for"", ""this"", ""realm"", ""Mandatory"", ""if"", ""the"", ""password"", ""is"", ""alone"", ""in\\n\\t\\t\\t\\t\\t\\tthe"", ""password"", ""attribute"", ""acting"", ""as"", ""the"", ""implicit"", ""realm\\n""]]",[-42330768901208094744],5694,8640.0,2
https://github.com/squid-cache/squid/commit/5d3aafbed3edd9d4cc50d9f276010c51c6b942fe,20 Feb 2017,Sync with v5 rev.15058,1995,data/crawl/squid/hunk_43.cpp,,,data/crawl/squid/old_hunk_43.cpp,data/crawl/squid/new_hunk_43.cpp,6,6,"fprintf(stderr, ""\t-l password realm delimiter(REQUIRED)\tCharater(s) that devides the password attribute\n\t\t\t\t\t\tin realm and password tokens, default ':' realm:password\n"");","fprintf(stderr, ""\t-l password realm delimiter(REQUIRED)\tCharacter(s) that divides the password attribute\n\t\t\t\t\t\tin realm and password tokens, default ':' realm:password, could be\n\t\t\t\t\t\tempty string if the password is alone in the password attribute\n"");","[""updateContent""]","[[""\\tCharater"", ""devides"", ""password\\n""], [""\\tCharacter"", ""divides"", ""password"", ""could"", ""be\\n\\t\\t\\t\\t\\t\\tempty"", ""string"", ""if"", ""the"", ""password"", ""is"", ""alone"", ""in"", ""the"", ""password"", ""attribute\\n""]]",[-33956360195853114003],5693,8640.0,2
https://github.com/squid-cache/squid/commit/5d3aafbed3edd9d4cc50d9f276010c51c6b942fe,20 Feb 2017,Sync with v5 rev.15058,1995,data/crawl/squid/hunk_42.cpp,,,data/crawl/squid/old_hunk_42.cpp,data/crawl/squid/new_hunk_42.cpp,-1,14,,"exceptionMsg.Printf(""failed to parse annotation value %s"", theValue.c_str());","[""addLog""]","[[], [""exceptionMsg"", ""Printf"", ""failed"", ""to"", ""parse"", ""annotation"", ""value"", ""%s"", ""theValue"", ""c_str""]]",[-28827324347155546862],5692,4320.0,2
https://github.com/squid-cache/squid/commit/5d3aafbed3edd9d4cc50d9f276010c51c6b942fe,20 Feb 2017,Sync with v5 rev.15058,1995,data/crawl/squid/hunk_41.cpp,,,data/crawl/squid/old_hunk_41.cpp,data/crawl/squid/new_hunk_41.cpp,-1,104,,"storeAppendPrintf(entry, ""response_delay_pool parameters %"" PRId64 "" %"" PRId64 "" %"" PRId64 "" %"" PRId64 "" %d\n"",
                      individualRestore, individualMaximum, aggregateRestore, aggregateMaximum, initialBucketLevel);","[""addLog""]","[[], [""storeAppendPrintf"", ""entry"", ""response_delay_pool"", ""parameters"", ""%"", ""PRId64"", ""%"", ""PRId64"", ""%"", ""PRId64"", ""%"", ""PRId64"", ""%d\\n"", ""individualRestore"", ""individualMaximum"", ""aggregateRestore"", ""aggregateMaximum"", ""initialBucketLevel""]]",[33644276115130802244],5691,720.0,2
https://github.com/squid-cache/squid/commit/5d3aafbed3edd9d4cc50d9f276010c51c6b942fe,20 Feb 2017,Sync with v5 rev.15058,1995,data/crawl/squid/hunk_40.cpp,,,data/crawl/squid/old_hunk_40.cpp,data/crawl/squid/new_hunk_40.cpp,24,32,"storeAppendPrintf(entry, ""%s %d\n"", name, (int)pools.size());","storeAppendPrintf(entry, ""%s %d\n"", name, static_cast<int>(pools_.size()));","[""updateVariable"", ""moveVariable"", ""removeVariable""]","[[""pools""], [""static_cast"", ""pools_""]]",[9398466892426568605],5690,720.0,2
https://github.com/squid-cache/squid/commit/e99fa721fc2a16026d284336fabe66db4518c3e5,23 May 2017,"Make PID file check/creation atomic to avoid associated race conditions.

After this change, if N Squid instances are concurrently started shortly
after time TS, then exactly one Squid instance (X) will run (and have
the corresponding PID file). If another Squid instance has already been
running (with the corresponding PID file) at TS, then X will be that
""old"" Squid instance. If no Squid instances were running at TS, then X
will be one of those new N Squids started after TS.

Lack of atomic PID file operations caused unexpected Squid behavior:
* Mismatch between started Squid instance and stored PID file.
* Unexpected crashes due to failed allocation of shared resources,
  such as listening TCP ports or shared memory segments.

A new File class guarantees atomic PID file operations using locks. We
tried to generalize/reuse Ssl::Lock from the certificate generation
helper, but that was a bad idea: Helpers cannot use a lot of Squid code
(e.g., debugs(), TextException, SBuf, and enter_suid()), and the old
Ssl::Lock class cannot support shared locking without a major rewrite.

File locks on Solaris cannot work well (see bug #4212 comment #14), but
those problems do not affect PID file management code. Solaris- and
Windows-specific File code has not been tested and may not build.

Failure to write a PID file is now fatal. It used to be fatal only when
Squid was started with the -C command line option. In the increasingly
SMP world, running without a PID file leads to difficult-to-triage
errors. An admin who does not care about PID files should disable them.

Squid now exits with a non-zero error code if another Squid is running.


Also removed PID file rewriting during reconfiguration in non-daemon
mode. Squid daemons do not support PID file reconfiguration since trunk
r13867, but that revision (accidentally?) left behind half-broken
reconfiguration code for non-daemon mode. Fixing that code is difficult,
and supporting PID reconfigure in non-daemons is probably unnecessary.

Also fixed ""is Squid running?"" check when kill(0) does not have
permissions to signal the other instance. This does happen when Squid is
started (e.g., on the command line) by a different user than the user
Squid normally runs as or, perhaps, when the other Squid instance enters
a privileged section at the time of the check (untested). The bug could
result in undelivered signals or multiple running Squid instances.

These changes do not alter partially broken enter/leave_suid() behavior
of main.cc. That old code will need to be fixed separately!

PID file-related cache.log messages have changed slightly to improve
consistency with other DBG_IMPORTANT messages and to simplify code.
Squid no longer lies about creating a non-configured PID file. TODO:
Consider lowering the importance of these benign/boring messages.


* Terminal errors should throw instead of calling exit()

Squid used to call exit() in many PID-related error cases. Using exit()
as an error handling mechanism creates several problems:

1. exit() does not unwind the stack, possibly executing atexit()
   handlers in the wrong (e.g., privileged) context, possibly leaving
   some RAII-controller resources in bad state, and complicating triage;
2. Using exit() complicates code by adding a yet another error handling
   mechanism to the (appropriate) exceptions and assertions.
3. Spreading exit() calls around the code obscures unreachable code
   areas, complicates unifying exit codes, and confuses code checkers.

Long-term, it is best to use exceptions for nearly all error handling.
Reaching that goal will take time, but we can and should move in that
direction: The adjusted SquidMainSafe() treats exceptions as fatal
errors, without dumping core or assuming that no exception can reach
SquidMainSafe() on purpose. This trivial-looking change significantly
simplified (and otherwise improved) PID-file handling code!

The fatal()-related code suffers from similar (and other) problems, but
we did not need to touch it.

TODO: Audit catch(...) and exit() cases [in main.cc] to take advantage
of the new SquidMainSafe() code supporting the throw-on-errors approach.",1038,data/crawl/squid/hunk_33.cpp,,,data/crawl/squid/old_hunk_33.cpp,data/crawl/squid/new_hunk_33.cpp,18,-1,"fprintf(stderr, ""%s: ERROR: Could not send "", APP_SHORTNAME);",,"[""removeLog""]","[[""fprintf"", ""stderr"", ""%s"", ""ERROR"", ""Could"", ""not"", ""send"", ""APP_SHORTNAME""], []]",[-8346943337819867353],5689,0.0,2
https://github.com/squid-cache/squid/commit/4ec218d55249c6edd2a4fe4511212a721c98394b,22 Jul 2017,"Cleaned up net_db structures. Made Coverity happier? (#27)

Fixes false positive by Coverity Scan. Issue 1415048 (RESOURCE_LEAK)?

No runtime testing.",22,data/crawl/squid/hunk_11.cpp,,,data/crawl/squid/old_hunk_11.cpp,data/crawl/squid/new_hunk_11.cpp,3,3,"logfilePrintf(lf, "" %s"", hashKeyStr(&x->hash));","logfilePrintf(lf, "" %s"", hashKeyStr(x));","[""removeVariable"", ""addVariable""]","[[""&x"", ""hash""], [""x""]]",[-7804452891477761235],5688,0.0,2
https://github.com/squid-cache/squid/commit/51e09c08a5e6c582e7d93af99a8f2cfcb14ea9e6,01 Feb 2018,"TLS: GnuTLS implementation for listening ports and client connections (#81)

Move the http_port cert= and key= options logic to libsecurity and add GnuTLS implementation for PEM file loading. Also adds some extra debugging to clarify listening port initialization problems with the PEM files.

Enable most of the http(s)_port listening socket logic to always build except where OpenSSL-specific dependency still exists. It may seem reasonable to leave it optionally excluded for minimal builds, however a minimal proxy that does not support HTTPS in any way is increasingly useless in the modern web so preference is given to building the generic TLS related code. This also simplifies the required testing to detect code portability issues.

GnuTLS implementation is added for https_port configured with static cert=/key= parameters and the resulting TLS handshake behaviour. Squid built with GnuTLS can now act as useful parent proxies behind a SSL-Bump'ing frontend or for other clients which require a TLS explicit proxy.

Also fixes the definitions for the CertPointer and PrivateKeyPointer.",769,data/crawl/squid/hunk_3.cpp,,,data/crawl/squid/old_hunk_3.cpp,data/crawl/squid/new_hunk_3.cpp,-1,16,,"fatalf(""%s_port %s initialization error"", portType, port.s.toUrl(buf, sizeof(buf)));","[""addLog""]","[[], [""fatalf"", ""%s_port"", ""%s"", ""initialization"", ""error"", ""portType"", ""port"", ""s"", ""toUrl"", ""buf"", ""sizeof"", ""buf""]]",[17945467262283022975],5687,65520.0,2
