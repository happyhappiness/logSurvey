----++++Makefile.am
@@ -876,6 +876,14 @@ hugepages_la_SOURCES = src/hugepages.c
 hugepages_la_LDFLAGS = $(PLUGIN_LDFLAGS)
 endif
 
+if BUILD_PLUGIN_INTEL_PMU
+pkglib_LTLIBRARIES += intel_pmu.la
+intel_pmu_la_SOURCES = src/intel_pmu.c
+intel_pmu_la_CFLAGS = $(AM_CFLAGS) $(BUILD_WITH_LIBJEVENTS_CPPFLAGS)
+intel_pmu_la_LDFLAGS = $(PLUGIN_LDFLAGS) $(BUILD_WITH_LIBJEVENTS_LDFLAGS)
+intel_pmu_la_LIBADD = $(BUILD_WITH_LIBJEVENTS_LIBS)
+endif
+
 if BUILD_PLUGIN_INTEL_RDT
 pkglib_LTLIBRARIES += intel_rdt.la
 intel_rdt_la_SOURCES = src/intel_rdt.c
----++++README
@@ -140,6 +140,11 @@ Features
       hugepages can be found here:
       https://www.kernel.org/doc/Documentation/vm/hugetlbpage.txt.
 
+    - intel_pmu
+      The intel_pmu plugin reads performance counters provided by the Linux
+      kernel perf interface. The plugin uses jevents library to resolve named
+      events to perf events and access perf interface.
+
     - intel_rdt
       The intel_rdt plugin collects information provided by monitoring features
       of Intel Resource Director Technology (Intel(R) RDT) like Cache Monitoring
@@ -240,7 +245,7 @@ Features
 
     - netapp
       Plugin to query performance values from a NetApp storage system using the
-      “Manage ONTAP” SDK provided by NetApp.
+      “Manage ONTAP” SDK provided by NetApp.
 
     - netlink
       Very detailed Linux network interface and routing statistics. You can get
@@ -779,6 +784,13 @@ Prerequisites
     For querying iptables counters.
     &lt;http://netfilter.org/&gt;
 
+  * libjevents (optional)
+    The jevents library is used by the `intel_pmu&#39; plugin to access the Linux
+    kernel perf interface.
+    Note: the library should be build with -fPIC flag to be linked with
+    intel_pmu shared object correctly.
+    &lt;https://github.com/andikleen/pmu-tools&gt;
+
   * libjvm (optional)
     Library that encapsulates the `Java Virtual Machine&#39; (JVM). This library is
     used by the `java&#39; plugin to execute Java bytecode.
----++++configure.ac
@@ -4364,6 +4364,77 @@ then
 fi
 # }}}
 
+# --with-libjevents {{{
+with_libjevents_cppflags=&quot;&quot;
+with_libjevents_ldflags=&quot;&quot;
+AC_ARG_WITH(libjevents, [AS_HELP_STRING([--with-libjevents@&lt;:@=PREFIX@:&gt;@], [Path to libjevents.])],
+[
+  if test &quot;x$withval&quot; != &quot;xno&quot; &amp;&amp; test &quot;x$withval&quot; != &quot;xyes&quot;
+  then
+    with_libjevents_cppflags=&quot;-I$withval/include&quot;
+    with_libjevents_ldflags=&quot;-L$withval/lib&quot;
+    with_libjevents=&quot;yes&quot;
+  else
+    with_libjevents=&quot;$withval&quot;
+  fi
+],
+[
+  with_libjevents=&quot;yes&quot;
+])
+if test &quot;x$with_libjevents&quot; = &quot;xyes&quot;
+then
+  SAVE_CPPFLAGS=&quot;$CPPFLAGS&quot;
+  CPPFLAGS=&quot;$CPPFLAGS $with_libjevents_cppflags&quot;
+
+  AC_CHECK_HEADERS(jevents.h, [with_libjevents=&quot;yes&quot;], [with_libjevents=&quot;no (jevents.h not found)&quot;])
+
+  CPPFLAGS=&quot;$SAVE_CPPFLAGS&quot;
+fi
+if test &quot;x$with_libjevents&quot; = &quot;xyes&quot;
+then
+  SAVE_CPPFLAGS=&quot;$CPPFLAGS&quot;
+  SAVE_LDFLAGS=&quot;$LDFLAGS&quot;
+  CPPFLAGS=&quot;$CPPFLAGS $with_libjevents_cppflags&quot;
+  LDFLAGS=&quot;$LDFLAGS $with_libjevents_ldflags&quot;
+
+  AC_CHECK_LIB(jevents, json_events, [with_libjevents=&quot;yes&quot;], [with_libjevents=&quot;no (Can&#39;t find libjevents)&quot;])
+
+  CPPFLAGS=&quot;$SAVE_CPPFLAGS&quot;
+  LDFLAGS=&quot;$SAVE_LDFLAGS&quot;
+fi
+if test &quot;x$with_libjevents&quot; = &quot;xyes&quot;
+then
+  SAVE_CPPFLAGS=&quot;$CPPFLAGS&quot;
+  SAVE_LDFLAGS=&quot;$LDFLAGS&quot;
+  SAVE_LIBS=&quot;$LIBS&quot;
+  CPPFLAGS=&quot;$CPPFLAGS -fPIC&quot;
+  LDFLAGS=&quot;$LDFLAGS -shared&quot;
+  LIBS=&quot;-ljevents&quot;
+  AC_LINK_IFELSE([AC_LANG_SOURCE(
+    [[
+      #include &lt;stdio.h&gt;
+      #include &quot;jevents.h&quot;
+      void print_cpu(void){
+        printf(&quot;%s&quot;, get_cpu_str());
+      }
+    ]]
+  )],
+  [with_libjevents=&quot;yes&quot;], [with_libjevents=&quot;no (could not link to libjevents. Check jevents is compiled with -fPIC.)&quot;])
+  CPPFLAGS=&quot;$SAVE_CPPFLAGS&quot;
+  LDFLAGS=&quot;$SAVE_LDFLAGS&quot;
+  LIBS=&quot;$SAVE_LIBS&quot;
+fi
+if test &quot;x$with_libjevents&quot; = &quot;xyes&quot;
+then
+  BUILD_WITH_LIBJEVENTS_CPPFLAGS=&quot;$with_libjevents_cppflags&quot;
+  BUILD_WITH_LIBJEVENTS_LDFLAGS=&quot;$with_libjevents_ldflags&quot;
+  BUILD_WITH_LIBJEVENTS_LIBS=&quot;-ljevents&quot;
+  AC_SUBST(BUILD_WITH_LIBJEVENTS_CPPFLAGS)
+  AC_SUBST(BUILD_WITH_LIBJEVENTS_LDFLAGS)
+  AC_SUBST(BUILD_WITH_LIBJEVENTS_LIBS)
+fi
+# }}}
+
 # --with-libprotobuf {{{
 with_libprotobuf_cppflags=&quot;&quot;
 with_libprotobuf_ldflags=&quot;&quot;
@@ -6014,6 +6085,7 @@ plugin_fscache=&quot;no&quot;
 plugin_gps=&quot;no&quot;
 plugin_grpc=&quot;no&quot;
 plugin_hugepages=&quot;no&quot;
+plugin_intel_pmu=&quot;no&quot;
 plugin_intel_rdt=&quot;no&quot;
 plugin_interface=&quot;no&quot;
 plugin_ipc=&quot;no&quot;
@@ -6422,6 +6494,7 @@ AC_PLUGIN([gps],                 [$plugin_gps],             [GPS plugin])
 AC_PLUGIN([grpc],                [$plugin_grpc],            [gRPC plugin])
 AC_PLUGIN([hddtemp],             [yes],                     [Query hddtempd])
 AC_PLUGIN([hugepages],           [$plugin_hugepages],       [Hugepages statistics])
+AC_PLUGIN([intel_pmu],           [$with_libjevents],        [Intel performance monitor plugin])
 AC_PLUGIN([intel_rdt],           [$with_libpqos],           [Intel RDT monitor plugin])
 AC_PLUGIN([interface],           [$plugin_interface],       [Interface traffic statistics])
 AC_PLUGIN([ipc],                 [$plugin_ipc],             [IPC statistics])
@@ -6752,6 +6825,7 @@ AC_MSG_RESULT([    libhiredis  . . . . . $with_libhiredis])
 AC_MSG_RESULT([    libi2c-dev  . . . . . $with_libi2c])
 AC_MSG_RESULT([    libiokit  . . . . . . $with_libiokit])
 AC_MSG_RESULT([    libiptc . . . . . . . $with_libiptc])
+AC_MSG_RESULT([    libjevents  . . . . . $with_libjevents])
 AC_MSG_RESULT([    libjvm  . . . . . . . $with_java])
 AC_MSG_RESULT([    libkstat  . . . . . . $with_kstat])
 AC_MSG_RESULT([    libkvm  . . . . . . . $with_libkvm])
@@ -6849,6 +6923,7 @@ AC_MSG_RESULT([    gps . . . . . . . . . $enable_gps])
 AC_MSG_RESULT([    grpc  . . . . . . . . $enable_grpc])
 AC_MSG_RESULT([    hddtemp . . . . . . . $enable_hddtemp])
 AC_MSG_RESULT([    hugepages . . . . . . $enable_hugepages])
+AC_MSG_RESULT([    intel_pmu . . . . . . $enable_intel_pmu])
 AC_MSG_RESULT([    intel_rdt . . . . . . $enable_intel_rdt])
 AC_MSG_RESULT([    interface . . . . . . $enable_interface])
 AC_MSG_RESULT([    ipc . . . . . . . . . $enable_ipc])
----++++contrib/systemd.collectd.service
@@ -11,6 +11,20 @@ EnvironmentFile=-/etc/default/collectd
 ProtectSystem=full
 ProtectHome=true
 
+# Some plugins require access to data located in a specified folder, to access
+# this data you&#39;ll have to specify the path by using the Environment directive
+# below.
+#
+# Here&#39;s a (incomplete) list of the plugins known environment requirements:
+#   intel_pmu       XDG_CACHE_HOME
+#
+# Example, if you use the intel_pmu plugin and cache is located in the /opt
+# directory:
+# Environment=XDG_CACHE_HOME=/opt
+#
+# By default, the HOME directory is chosen:
+Environment=
+
 # A few plugins won&#39;t work without some privileges, which you&#39;ll have to
 # specify using the CapabilityBoundingSet directive below.
 #
@@ -19,6 +33,7 @@ ProtectHome=true
 #   dns             CAP_NET_RAW
 #   exec            CAP_SETUID CAP_SETGID
 #   intel_rdt       CAP_SYS_RAWIO
+#   intel_pmu       CAP_SYS_ADMIN
 #   iptables        CAP_NET_ADMIN
 #   ping            CAP_NET_RAW
 #   smart           CAP_SYS_RAWIO
----++++src/collectd.conf.in
@@ -129,6 +129,7 @@
 #@BUILD_PLUGIN_GRPC_TRUE@LoadPlugin grpc
 #@BUILD_PLUGIN_HDDTEMP_TRUE@LoadPlugin hddtemp
 #@BUILD_PLUGIN_HUGEPAGES_TRUE@LoadPlugin hugepages
+#@BUILD_PLUGIN_INTEL_PMU_TRUE@LoadPlugin intel_pmu
 #@BUILD_PLUGIN_INTEL_RDT_TRUE@LoadPlugin intel_rdt
 @BUILD_PLUGIN_INTERFACE_TRUE@@BUILD_PLUGIN_INTERFACE_TRUE@LoadPlugin interface
 #@BUILD_PLUGIN_IPC_TRUE@LoadPlugin ipc
@@ -646,6 +647,13 @@
 #    ValuesPercentage false
 #&lt;/Plugin&gt;
 
+#&lt;Plugin intel_pmu&gt;
+#    HWCacheEvents true
+#    KernelPMUEvents true
+#    SWEvents true
+#    HWSpecificEvents &quot;L2_RQSTS.CODE_RD_HIT,L2_RQSTS.CODE_RD_MISS&quot;
+#&lt;/Plugin&gt;
+
 #&lt;Plugin &quot;intel_rdt&quot;&gt;
 #  Cores &quot;0-2&quot;
 #&lt;/Plugin&gt;
----++++src/collectd.conf.pod
@@ -3082,6 +3082,86 @@ Defaults to B&lt;false&gt;.
 
 =back
 
+=head2 Plugin C&lt;intel_pmu&gt;
+
+The I&lt;intel_pmu&gt; plugin collects performance counters data on Intel CPUs using
+Linux perf interface. All events are reported on a per core basis.
+
+B&lt;Synopsis:&gt;
+
+  &lt;Plugin intel_pmu&gt;
+    HWCacheEvents true
+    KernelPMUEvents true
+    SWEvents true
+    HWSpecificEvents &quot;L2_RQSTS.CODE_RD_HIT,L2_RQSTS.CODE_RD_MISS&quot;
+  &lt;/Plugin&gt;
+
+B&lt;Options:&gt;
+
+=over 4
+
+=item B&lt;HWCacheEvents&gt; B&lt;false&gt;|B&lt;true&gt;
+
+Enable or disable measuring of hardware CPU cache events:
+  - L1-dcache-loads
+  - L1-dcache-load-misses
+  - L1-dcache-stores
+  - L1-dcache-store-misses
+  - L1-dcache-prefetches
+  - L1-dcache-prefetch-misses
+  - L1-icache-loads
+  - L1-icache-load-misses
+  - L1-icache-prefetches
+  - L1-icache-prefetch-misses
+  - LLC-loads
+  - LLC-load-misses
+  - LLC-stores
+  - LLC-store-misses
+  - LLC-prefetches
+  - LLC-prefetch-misses
+  - dTLB-loads
+  - dTLB-load-misses
+  - dTLB-stores
+  - dTLB-store-misses
+  - dTLB-prefetches
+  - dTLB-prefetch-misses
+  - iTLB-loads
+  - iTLB-load-misses
+  - branch-loads
+  - branch-load-misses
+
+=item B&lt;KernelPMUEvents&gt; B&lt;false&gt;|B&lt;true&gt;
+
+Enable or disable measuring of the following events:
+  - cpu-cycles
+  - instructions
+  - cache-references
+  - cache-misses
+  - branches
+  - branch-misses
+  - bus-cycles
+
+=item B&lt;SWEvents&gt; B&lt;false&gt;|B&lt;true&gt;
+
+Enable or disable measuring of software events provided by kernel:
+  - cpu-clock
+  - task-clock
+  - context-switches
+  - cpu-migrations
+  - page-faults
+  - minor-faults
+  - major-faults
+  - alignment-faults
+  - emulation-faults
+
+=item B&lt;HWSpecificEvents&gt; I&lt;events&gt;
+
+This field is a list of comma separated event names. To be able to monitor all
+Intel CPU specific events JSON event list file should be downloaded.
+Use the pmu-tools event_download.py script for this.
+
+=back
+
 =head2 Plugin C&lt;intel_rdt&gt;
 
 The I&lt;intel_rdt&gt; plugin collects information provided by monitoring features of
----++++GitHub