@@ -127,7 +127,7 @@ SwapDir::canStore(const StoreEntry &e, int64_t diskSpaceNeeded, int &load) const
     if (flags.read_only)
         return false; // cannot write at all
 
-    if (currentSize() > max_size << 10)
+    if (currentSize() > maxSize())
         return false; // already overflowing
 
     /* Return 999 (99.9%) constant load; TODO: add a named constant for this */
@@ -179,9 +179,10 @@ class SwapDir : public Store
 private:
     uint64_t cur_size;        ///< currently used space in the storage area
 
+protected:
+    uint64_t max_size;        ///< maximum allocatable size of the storage area
+
 public:
-    // TODO: store max_size in bytes
-    uint64_t max_size;        ///< maximum allocatable size of the storage area in kiloBytes
     uint64_t n_disk_objects;  ///< total number of objects stored
     char *path;
     int index;			/* This entry's index into the swapDirs array */
@@ -608,7 +608,7 @@ configDoConfigure(void)
     if (0 == Store::Root().maxSize())
         /* people might want a zero-sized cache on purpose */
         (void) 0;
-    else if (Store::Root().maxSize() < (Config.memMaxSize >> 10))
+    else if (Store::Root().maxSize() < Config.memMaxSize)
         /* This is bogus. folk with NULL caches will want this */
         debugs(3, 0, "WARNING cache_mem is larger than total disk cache space!");
 
@@ -924,13 +924,12 @@ CossSwapDir::create()
     swap = open(stripePath(), O_WRONLY | O_CREAT | O_TRUNC | O_BINARY, 0600);
 
     /* TODO just set the file size */
-    /* swap size is in K */
-    char *block[1024];
+    char block[1024];
+    Must(maxSize() % sizeof(block) == 0);
+    memset(block, '\0', sizeof(block));
 
-    memset(&block, '\0', 1024);
-
-    for (uint64_t offset = 0; offset < max_size; ++offset) {
-        if (write (swap, block, 1024) < 1024) {
+    for (uint64_t offset = 0; offset < maxSize(); offset += sizeof(block)) {
+        if (write (swap, block, sizeof(block)) != sizeof(block)) {
             debugs (47, 0, "Failed to create COSS swap space in " << path);
         }
     }
@@ -982,12 +981,11 @@ CossSwapDir::callback()
 void
 CossSwapDir::statfs(StoreEntry & sentry) const
 {
-    const double currentSizeInKB = currentSize() / 1024.0;
     storeAppendPrintf(&sentry, "\n");
-    storeAppendPrintf(&sentry, "Maximum Size: %lu KB\n", max_size);
-    storeAppendPrintf(&sentry, "Current Size: %.2f KB\n", currentSizeInKB);
+    storeAppendPrintf(&sentry, "Maximum Size: %"PRIu64" KB\n", maxSize() >> 10);
+    storeAppendPrintf(&sentry, "Current Size: %.2f KB\n", currentSize() / 1024.0);
     storeAppendPrintf(&sentry, "Percent Used: %0.2f%%\n",
-                      Math::doublePercent(currentSizeInKB, max_size) );
+                      Math::doublePercent(currentSize(), maxSize()) );
     storeAppendPrintf(&sentry, "Number of object collisions: %d\n", (int) numcollisions);
 #if 0
     /* is this applicable? I Hope not .. */
@@ -1011,21 +1009,15 @@ CossSwapDir::statfs(StoreEntry & sentry) const
 void
 CossSwapDir::parse(int anIndex, char *aPath)
 {
-    unsigned int i;
-    unsigned int size;
-    off_t max_offset;
-
-    i = GetInteger();
-    size = i << 10;		/* Mbytes to Kbytes */
-
-    if (size <= 0)
+    const int i = GetInteger();
+    if (i <= 0)
         fatal("storeCossDirParse: invalid size value");
 
     index = anIndex;
 
     path = xstrdup(aPath);
 
-    max_size = size;
+    max_size = i << 20; // MBytes to Bytes
 
     parseOptions(0);
 
@@ -1045,12 +1037,12 @@ CossSwapDir::parse(int anIndex, char *aPath)
      * largest possible sfileno, assuming sfileno is a 25-bit
      * signed integer, as defined in structs.h.
      */
-    max_offset = (off_t) 0xFFFFFF << blksz_bits;
+    const uint64_t max_offset = (uint64_t) 0xFFFFFF << blksz_bits;
 
-    if ((off_t)max_size > (max_offset>>10)) {
+    if (maxSize() > max_offset) {
         debugs(47, 0, "COSS block-size = " << (1<<blksz_bits) << " bytes");
         debugs(47,0, "COSS largest file offset = " << (max_offset >> 10) << " KB");
-        debugs(47, 0, "COSS cache_dir size = " << max_size << " KB");
+        debugs(47, 0, "COSS cache_dir size = " << (maxSize() >> 10) << " KB");
         fatal("COSS cache_dir size exceeds largest offset\n");
     }
 }
@@ -1059,19 +1051,16 @@ CossSwapDir::parse(int anIndex, char *aPath)
 void
 CossSwapDir::reconfigure(int index, char *path)
 {
-    unsigned int i;
-    unsigned int size;
-
-    i = GetInteger();
-    size = i << 10;		/* Mbytes to Kbytes */
-
-    if (size <= 0)
+    const int i = GetInteger();
+    if (i <= 0)
         fatal("storeCossDirParse: invalid size value");
 
-    if (size == (size_t)max_size)
-        debugs(3, 1, "Cache COSS dir '" << path << "' size remains unchanged at " << size << " KB");
+    const uint64_t size = i << 20; // MBytes to Bytes
+
+    if (size == maxSize())
+        debugs(3, 1, "Cache COSS dir '" << path << "' size remains unchanged at " << i << " MB");
     else {
-        debugs(3, 1, "Cache COSS dir '" << path << "' size changed to " << size << " KB");
+        debugs(3, 1, "Cache COSS dir '" << path << "' size changed to " << i << " MB");
         max_size = size;
     }
 
@@ -1089,7 +1078,7 @@ CossSwapDir::swappedOut(const StoreEntry &e)
 void
 CossSwapDir::dump(StoreEntry &entry)const
 {
-    storeAppendPrintf(&entry, " %lu", (max_size >> 10));
+    storeAppendPrintf(&entry, " %"PRIu64, maxSize() >> 20);
     dumpOptions(&entry);
 }
 
@@ -83,8 +83,7 @@ CossSwapDir::allocate(const StoreEntry * e, int which)
         allocsize = e->objectLen() + e->mem_obj->swap_hdr_sz;
 
     /* Check if we have overflowed the disk .. */
-    /* max_size is int, so cast to (off_t) *before* bit-shifting */
-    if ((current_offset + allocsize) > ((off_t)max_size << 10)) {
+    if (current_offset + allocsize > static_cast<int64_t>(maxSize())) {
         /*
          * tried to allocate past the end of the disk, so wrap
          * back to the beginning
@@ -19,7 +19,6 @@
 #include "fs/rock/RockIoRequests.h"
 #include "fs/rock/RockRebuild.h"
 
-// must be divisible by 1024 due to cur_size and max_size KB madness
 const int64_t Rock::SwapDir::HeaderSize = 16*1024;
 
 Rock::SwapDir::SwapDir(): ::SwapDir("rock"), filePath(NULL), io(NULL), map(NULL)
@@ -127,7 +126,7 @@ int64_t
 Rock::SwapDir::entryLimitAllowed() const
 {
     const int64_t eLimitLo = map ? map->entryLimit() : 0; // dynamic shrinking unsupported
-    const int64_t eWanted = (maximumSize() - HeaderSize)/maxObjectSize();
+    const int64_t eWanted = (maxSize() - HeaderSize)/maxObjectSize();
     return min(max(eLimitLo, eWanted), entryLimitHigh());
 }
 
@@ -162,11 +161,12 @@ Rock::SwapDir::create()
 
 #if SLOWLY_FILL_WITH_ZEROS
     /* TODO just set the file size */
-    char block[1024]; // max_size is in KB so this is one unit of max_size
+    char block[1024];
+    Must(maxSize() % sizeof(block) == 0);
     memset(block, '\0', sizeof(block));
 
     const int swap = open(filePath, O_WRONLY|O_CREAT|O_TRUNC|O_BINARY, 0600);
-    for (off_t offset = 0; offset < max_size; ++offset) {
+    for (off_t offset = 0; offset < maxSize(); offset += sizeof(block)) {
         if (write(swap, block, sizeof(block)) != sizeof(block)) {
             debugs(47,0, "Failed to create Rock Store db in " << filePath <<
                 ": " << xstrerror());
@@ -182,7 +182,7 @@ Rock::SwapDir::create()
         fatal("Rock Store db creation error");
     }
 
-    if (ftruncate(swap, maximumSize()) != 0) {
+    if (ftruncate(swap, maxSize()) != 0) {
         debugs(47,0, "Failed to initialize Rock Store db in " << filePath <<
             "; truncate error: " << xstrerror());
         fatal("Rock Store db creation error");
@@ -272,9 +272,10 @@ Rock::SwapDir::reconfigure(int, char *)
 void
 Rock::SwapDir::parseSize()
 {
-    max_size = GetInteger() << 10; // MBytes to KBytes
-    if (max_size < 0)
+    const int i = GetInteger();
+    if (i < 0)
         fatal("negative Rock cache_dir size value");
+    max_size = i << 20; // MBytes to Bytes
 }
 
 /// check the results of the configuration; only level-0 debugging works here
@@ -289,20 +290,21 @@ Rock::SwapDir::validateOptions()
     */
 
     /* XXX: misplaced, map is not yet created
+    // XXX: max_size is in Bytes now
     // Note: We could try to shrink max_size now. It is stored in KB so we
     // may not be able to make it match the end of the last entry exactly.
     const int64_t mapRoundWasteMx = max_objsize*sizeof(long)*8;
     const int64_t sizeRoundWasteMx = 1024; // max_size stored in KB
     const int64_t roundingWasteMx = max(mapRoundWasteMx, sizeRoundWasteMx);
-    const int64_t totalWaste = maximumSize() - diskOffsetLimit();
-    assert(diskOffsetLimit() <= maximumSize());
+    const int64_t totalWaste = maxSize() - diskOffsetLimit();
+    assert(diskOffsetLimit() <= maxSize());
 
     // warn if maximum db size is not reachable due to sfileno limit
     if (map->entryLimit() == entryLimitHigh() && totalWaste > roundingWasteMx) {
         debugs(47, 0, "Rock store cache_dir[" << index << "]:");
         debugs(47, 0, "\tmaximum number of entries: " << map->entryLimit());
         debugs(47, 0, "\tmaximum entry size: " << max_objsize << " bytes");
-        debugs(47, 0, "\tmaximum db size: " << maximumSize() << " bytes");
+        debugs(47, 0, "\tmaximum db size: " << maxSize() << " bytes");
         debugs(47, 0, "\tusable db size:  " << diskOffsetLimit() << " bytes");
         debugs(47, 0, "\tdisk space waste: " << totalWaste << " bytes");
         debugs(47, 0, "WARNING: Rock store config wastes space.");
@@ -481,7 +483,7 @@ Rock::SwapDir::ioCompletedNotification()
 
     // TODO: lower debugging level
     debugs(47,1, "Rock cache_dir[" << index << "] limits: " << 
-        std::setw(12) << maximumSize() << " disk bytes and " <<
+        std::setw(12) << maxSize() << " disk bytes and " <<
         std::setw(7) << map->entryLimit() << " entries");
 
     rebuild();
@@ -643,12 +645,11 @@ Rock::SwapDir::ignoreReferences(StoreEntry &e)
 void
 Rock::SwapDir::statfs(StoreEntry &e) const
 {
-    const double currentSizeInKB = currentSize() / 1024.0;
     storeAppendPrintf(&e, "\n");
-    storeAppendPrintf(&e, "Maximum Size: %"PRIu64" KB\n", max_size);
+    storeAppendPrintf(&e, "Maximum Size: %"PRIu64" KB\n", maxSize() >> 10);
     storeAppendPrintf(&e, "Current Size: %.2f KB %.2f%%\n",
-                      currentSizeInKB,
-                      Math::doublePercent(currentSizeInKB, max_size));
+                      currentSize() / 1024.0,
+                      Math::doublePercent(currentSize(), maxSize()));
 
     if (map) {
         const int limit = map->entryLimit();
@@ -35,9 +35,6 @@ class SwapDir: public ::SwapDir, public IORequestor
     int64_t entryLimitHigh() const { return 0xFFFFFF; } /// Core sfileno maximum
     int64_t entryLimitAllowed() const;
 
-    // TODO: change cur_size and max_size type to stop this madness
-    int64_t maximumSize() const { return static_cast<int64_t>(max_size) << 10; }
-
     typedef Ipc::StoreMapWithExtras<DbCellHeader> DirMap;
 
 protected:
@@ -80,14 +80,14 @@ UFSSwapDir::parseSizeL1L2()
     if (i <= 0)
         fatal("UFSSwapDir::parseSizeL1L2: invalid size value");
 
-    size_t size = i << 10;		/* Mbytes to kbytes */
+    const uint64_t size = i << 20; // MBytes to Bytes
 
     /* just reconfigure it */
     if (reconfiguring) {
-        if (size == max_size)
-            debugs(3, 2, "Cache dir '" << path << "' size remains unchanged at " << size << " KB");
+        if (size == maxSize())
+            debugs(3, 2, "Cache dir '" << path << "' size remains unchanged at " << i << " MB");
         else
-            debugs(3, 1, "Cache dir '" << path << "' size changed to " << size << " KB");
+            debugs(3, 1, "Cache dir '" << path << "' size changed to " << i << " MB");
     }
 
     max_size = size;
@@ -314,13 +314,12 @@ UFSSwapDir::statfs(StoreEntry & sentry) const
     int totl_in = 0;
     int free_in = 0;
     int x;
-    const double currentSizeInKB = currentSize() / 1024.0;
     storeAppendPrintf(&sentry, "First level subdirectories: %d\n", l1);
     storeAppendPrintf(&sentry, "Second level subdirectories: %d\n", l2);
-    storeAppendPrintf(&sentry, "Maximum Size: %"PRIu64" KB\n", max_size);
-    storeAppendPrintf(&sentry, "Current Size: %.2f KB\n", currentSizeInKB);
+    storeAppendPrintf(&sentry, "Maximum Size: %"PRIu64" KB\n", maxSize() >> 10);
+    storeAppendPrintf(&sentry, "Current Size: %.2f KB\n", currentSize() / 1024.0);
     storeAppendPrintf(&sentry, "Percent Used: %0.2f%%\n",
-                      Math::doublePercent(currentSizeInKB, max_size));
+                      Math::doublePercent(currentSize(), maxSize()));
     storeAppendPrintf(&sentry, "Filemap bits in use: %d of %d (%d%%)\n",
                       map->n_files_in_map, map->max_n_files,
                       Math::intPercent(map->n_files_in_map, map->max_n_files));
@@ -366,7 +365,7 @@ UFSSwapDir::maintain()
 
     RemovalPurgeWalker *walker;
 
-    double f = (double) (currentSize() / 1024.0 - minSize()) / (max_size - minSize());
+    double f = (double) (currentSize() - minSize()) / (maxSize() - minSize());
 
     f = f < 0.0 ? 0.0 : f > 1.0 ? 1.0 : f;
 
@@ -383,7 +382,7 @@ UFSSwapDir::maintain()
     walker = repl->PurgeInit(repl, max_scan);
 
     while (1) {
-        if (currentSize() < minSize() << 10)
+        if (currentSize() < minSize())
             break;
 
         if (removed >= max_remove)
@@ -1330,7 +1329,7 @@ UFSSwapDir::replacementRemove(StoreEntry * e)
 void
 UFSSwapDir::dump(StoreEntry & entry) const
 {
-    storeAppendPrintf(&entry, " %"PRIu64" %d %d", (max_size >> 10), l1, l2);
+    storeAppendPrintf(&entry, " %"PRIu64" %d %d", maxSize() >> 20, l1, l2);
     dumpOptions(&entry);
 }
 
@@ -131,7 +131,7 @@ snmp_confFn(variable_list * Var, snint * ErrP)
 
         case CONF_ST_SWMAXSZ:
             Answer = snmp_var_new_integer(Var->name, Var->name_length,
-                                          (snint) (Store::Root().maxSize() >> 10),
+                                          (snint) (Store::Root().maxSize() >> 20),
                                           ASN_INTEGER);
             break;
 
@@ -1236,8 +1236,8 @@ StoreController::maintain()
     if (Store::Root().currentSize() > Store::Root().maxSize()) {
         if (squid_curtime - last_warn_time > 10) {
             debugs(20, 0, "WARNING: Disk space over limit: "
-                   << Store::Root().currentSize() << " KB > "
-                   << Store::Root().maxSize() << " KB");
+                   << Store::Root().currentSize() / 1024.0 << " KB > "
+                   << (Store::Root().maxSize() >> 10) << " KB");
             last_warn_time = squid_curtime;
         }
     }
@@ -506,7 +506,7 @@ storeDigestCalcCap(void)
      * the bits are off). However, we do not have a formula to calculate the
      * number of _entries_ we want to pre-allocate for.
      */
-    const int hi_cap = Store::Root().maxSize() / Config.Store.avgObjectSize;
+    const int hi_cap = (Store::Root().maxSize() >> 10) / Config.Store.avgObjectSize;
     const int lo_cap = 1 + (Store::Root().currentSize() >> 10) / Config.Store.avgObjectSize;
     const int e_count = StoreEntry::inUseCount();
     int cap = e_count ? e_count :hi_cap;
@@ -236,7 +236,7 @@ storeDirSelectSwapDirRoundRobin(const StoreEntry * e)
 static int
 storeDirSelectSwapDirLeastLoad(const StoreEntry * e)
 {
-    uint64_t most_free = 0;
+    int64_t most_free = 0;
     ssize_t least_objsize = -1;
     int least_load = INT_MAX;
     int load;
@@ -263,7 +263,7 @@ storeDirSelectSwapDirLeastLoad(const StoreEntry * e)
         if (load > least_load)
             continue;
 
-        const uint64_t cur_free = (SD->max_size << 10) - SD->currentSize();
+        const int64_t cur_free = SD->maxSize() - SD->currentSize();
 
         /* If the load is equal, then look in more details */
         if (load == least_load) {
@@ -339,17 +339,16 @@ SwapDir::updateSize(int64_t size, int sign)
 void
 StoreController::stat(StoreEntry &output) const
 {
-    const double currentSizeInKB = currentSize() / 1024.0;
     storeAppendPrintf(&output, "Store Directory Statistics:\n");
     storeAppendPrintf(&output, "Store Entries          : %lu\n",
                       (unsigned long int)StoreEntry::inUseCount());
     storeAppendPrintf(&output, "Maximum Swap Size      : %"PRIu64" KB\n",
-                      maxSize());
+                      maxSize() >> 10);
     storeAppendPrintf(&output, "Current Store Swap Size: %.2f KB\n",
-                      currentSizeInKB);
+                      currentSize() / 1024.0);
     storeAppendPrintf(&output, "Current Capacity       : %.2f%% used, %.2f%% free\n",
-                      Math::doublePercent(currentSizeInKB, maxSize()),
-                      Math::doublePercent((maxSize() - currentSizeInKB), maxSize()));
+                      Math::doublePercent(currentSize(), maxSize()),
+                      Math::doublePercent((maxSize() - currentSize()), maxSize()));
 
     if (memStore)
         memStore->stat(output);
@@ -394,10 +393,10 @@ StoreController::maxObjectSize() const
 void
 SwapDir::diskFull()
 {
-    if (currentSize() >= max_size << 10)
+    if (currentSize() >= maxSize())
         return;
 
-    max_size = currentSize() >> 10;
+    max_size = currentSize();
 
     debugs(20, 1, "WARNING: Shrinking cache_dir #" << index << " to " << currentSize() / 1024.0 << " KB");
 }
@@ -872,8 +871,8 @@ StoreHashIndex::init()
     /* Calculate size of hash table (maximum currently 64k buckets).  */
     /* this is very bogus, its specific to the any Store maintaining an
      * in-core index, not global */
-    size_t buckets = (Store::Root().maxSize() + ( Config.memMaxSize >> 10)) / Config.Store.avgObjectSize;
-    debugs(20, 1, "Swap maxSize " << Store::Root().maxSize() <<
+    size_t buckets = ((Store::Root().maxSize() + Config.memMaxSize) >> 10) / Config.Store.avgObjectSize;
+    debugs(20, 1, "Swap maxSize " << (Store::Root().maxSize() >> 10) <<
            " + " << ( Config.memMaxSize >> 10) << " KB, estimated " << buckets << " objects");
     buckets /= Config.Store.objectsPerBucket;
     debugs(20, 1, "Target number of buckets: " << buckets);
@@ -882,7 +881,7 @@ StoreHashIndex::init()
     store_hash_buckets = storeKeyHashBuckets(buckets);
     debugs(20, 1, "Using " << store_hash_buckets << " Store buckets");
     debugs(20, 1, "Max Mem  size: " << ( Config.memMaxSize >> 10) << " KB");
-    debugs(20, 1, "Max Swap size: " << Store::Root().maxSize() << " KB");
+    debugs(20, 1, "Max Swap size: " << (Store::Root().maxSize() >> 10) << " KB");
 
     store_table = hash_create(storeKeyHashCmp,
                               store_hash_buckets, storeKeyHashHash);