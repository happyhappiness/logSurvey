@@ -4,93 +4,134 @@ Thank you!
 
     Adam Ciarcinski
     Adrian Chadd <adrian@squid-cache.org>
+    Aecio F. <aecioneto@gmail.com>
     Alan Mizrahi <alan@mizrahi.com.ve>
+    Alan Nastac <mrness@gentoo.org>
+    Aleksa <susulic@gmail.com>
+    Aleksa ??u??uli?? <susulic@gmail.com>
     Alexander B. Demenshin <aldem@barnet.kharkov.ua>
     Alexander Komyagin <komyagin@altell.ru>
+    Alexander Lukyanov <lav@netis.ru>
     Alexander Lukyanov <lav@yar.ru>
     Alexandre Chappaz <alexandrechappaz@gmail.com>
+    Alexandre SIMON <alexandre.simon@ciril.fr>
+    Alex Dowad <alexinbeijing@gmail.com>
     Alexey Veselovsky <alexey.veselovsky@eykontech.com>
     Alexis Robert <alexis.robert@gmail.com>
     Alex Rousskov <rousskov@measurement-factory.com>
+    Alex Rousskov <rousskov@squid-cache.org>
     Alin Nastac <mrness@gentoo.org>
     Alter <alter@alter.org.ua>
     Amos Jeffries <amosjeffries@squid-cache.org>
     Amos Jeffries <squid3@treenet.co.nz>
+    Amos <squid3@treenet.co.nz>
     Anatoli <me@anatoli.ws>
     Andrea Gagliardi <andrea@netlite.it>
     Andreas Jaeger <aj@suse.com>
     Andreas Lamprecht <Andreas.Lamprecht@siemens.at>
     Andres Kroonmaa <andre@ml.ee>
+    Andrew Balabohin
     Andrew Beverley <andy@andybev.com>
     Andrew Doran <ad@interlude.eu.org>
+    Andrew Evdokimov <ae@elahi.ru>
     Andrew Hoying <andrew_hoying@blm.gov>
     Andrew Tridgell
     Andrey Shorin <tolsty@tushino.com>
+    Anonymous Pootle User
     Anonymous <redskilldough@gmail.com>
     Ansgar Hockmann <Ansgar.Hockmann@hrz.uni-dortmund.de>
     Anthony Baxter <arb@connect.com.au>
     Antonino Iannella
+    Arjan de Vet <Arjan.deVet@adv.IAEhv.nl>
     Arjan de Vet <Arjan.deVet@adv.iae.nl>
     Arkin <arkin.yang@gmail.com>
     Arno Streuli <astreuli@gmail.com>
+    Arthur <arthur@psw.ro>
+    Arthur <arthurtumanyan@yahoo.com>
     Arthur Tumanyan <arthurtumanyan@yahoo.com>
     Assar Westerlund <assar@pdc.kth.se>
     Automatic source maintenance <squidadm@squid-cache.org>
     Axel Westerhold <ml.awesterhold@dts.de>
+    Barry Dobyns <barry@dobyns.com>
     Benjamin Kerensa <bkerensa@ubuntu.com>
-    benno@jeamland.net
+    Benno Rice <benno@jeamland.net>
     Benno Rice <benno@squid-cache.org>
     Bernard <fli4l.charrier@free.fr>
     Bertrand Jacquin <beber@meleeweb.net>
     Bill Welliver
     Bojan Smojver <bojan@rexursive.com>
     Brad Smith <brad@comstyle.com>
+    Bratislav <batailic@gmail.com>
     Brian Degenhardt <bmd@mp3.com>
     Brian Denehy <B-Denehy@adfa.oz.au>
     Brian <hiryuu@envisiongames.net>
     Bruce Murphy <pack-squid@rattus.net>
     Carson Gaspar (carson@lehman.com, carson@cs.columbia.edu)
+    Cephas <squidwin@gmail.com>
+    Chad E. Naugle <chad.naugle@travimp.com>
+    Chad Naugle <chad.naugle@travimp.com>
     Changming <me@sunchangming.com>
+    Chao <chao_83@126.com>
     Chris Hills <chaz@chaz6.com>
+    Christian Wittmer <chris@computersalat.de>
     Christopher Kerr
+    Christophe Saout <christophe@saout.de>
     Christoph Lechleitner <lech@ibcl.at>
+    Christos Tsantilas <christos@chtsanti.net>
     Christos Tsantilas <chtsanti@users.sourceforge.net>
     Cloyce <cloyce.spradling@sun.com>
+    Clytie Siddall <clytie@riverland.net.au>
+    Colin Coe <colin.coe@gmail.com>
     Constantin Rack
     Cord Beermann <cord@cc.fh-lippe.de>
     Daniel Beschorner <daniel.beschorner@evlks.de>
     Daniel O'Callaghan <danny@miriworld.its.unimelb.EDU.AU>
+    Daniel Walter <d.walter@0x90.at>
+    Dan Searle <dan.searle@censornet.com>
+    David Hill <david.hill@ubisoft.com>
     David Isaacs <david.isaacs@sbhs.nsw.edu.au>
     David J N Begley
     David Luyer <david@luyer.net>
     David Luyer <luyer@ucs.uwa.edu.au>
+    David Parks <davidparks21@yahoo.com>
+    Declan White <declanw@is.bbc.co.uk>
+    Dennis Felippa <dennis@infologika.com.br>
     Dennis Glatting
-    Dhaval Varia
+    Dhaval Varia <dhavalkvaria@gmail.com>
     Diego Woitasen <diegows@xtech.com.ar>
-    Dmitry Kurochkin
+    D Kazarov <d.y.kazarov@mail.ru>
+    Dmitry Kurochkin <dmitry.kurochkin@measurement-factory.com>
     Don Hopkins <dhopkins@DonHopkins.com>
     Doug Dixon <doug.dixon@gmail.com>
     Doug Urner <dlu@bsdi.com>
     Dragutin Cirkovic <painkiller@gromnet.net>
+    drserge <drserge@inbox.ru>
     Dr. Tilmann Bubeck <t.bubeck@reinform.de>
     Duane Wessels <wessels@squid-cache.org>
     Dustin J. Mitchell
     Ed Knowles <ed@fatboy.geog.unsw.edu.au>
+    Edward Chernenko <edwardspec@gmail.com>
     Edward Moy <moy@parc.xerox.com>
+    Eldar Akchurin <al.akchurin@googlemail.com>
     Eliezer Croitoru <eliezer@ngtech.co.il>
     Elmar Vonlanthen <Elmar.Vonlanthen@united-security-providers.ch>
     Emilio Casbas <ecasbas@unav.es>
     Endre Balint Nagy <bne@CareNet.hu>
+    Eray Aslan <eraya@a21an.org>
     Eray Aslan <eray.aslan@caf.com.tr>
     Eric Stern <estern@logisense.com>
     Erik Hofman <erik.hofman@a1.nl>
     Eugene Gladchenko <eugene@donpac.ru>
     Evan Jones <ejones@uwaterloo.ca>
+    Evgeni <etg@setcom.bg>
     Eygene Ryabinkin <rea@freebsd.org>
+    Fabian Hugelshofer <fh@open.ch>
     fancyrabbit <fancyrabbit@gmail.com>
     Felix Meschberger <felix.meschberger@day.com>
+    Feshchuk Yuriy <swopster@meta.ua>
     Finn Thain <fthain@telegraphics.com.au>
     Flavio Pescuma <flavio@marasystems.com>
+    Florent <fcarli@gmail.com>
     folkert <folkert@vanheusden.com>
     Francesco Chemolli <kinkie@squid-cache.org>
     Francesco <kinkie@squid-cache.org>
@@ -100,13 +141,18 @@ Thank you!
     Frank Balluffi
     Frank Schmirler <squid@schmirler.de>
     Frederic Bourgeois <fredbmail@free.fr>
+    Fred <fred.maranhao@gmail.com>
+    F Wolff <friedel@translate.org.za>
+    Fyodor <fygrave@gmail.com>
     Geoff Keating <Geoff.Keating@anu.edu.au>
     George Michaelson <ggm@connect.com.au>
     Georgy Salnikov <sge@nmr.nioch.nsc.ru>
     Gerard Eviston
     Gerben Wierda <Gerben_Wierda@RnA.nl>
+    Gergely <mail.gery@gmail.com>
     Giancarlo Razzolini <linux-fan@onda.com.br>
     Gilles Espinasse <g.esp@free.fr>
+    gkeeling <grm___k@hotmail.com>
     Glen Gibb <grg@ridley.unimelb.edu.au>
     Glenn Chisholm <glenn@ircache.net>
     Glen Newton <glen.newton@nrc.ca>
@@ -116,21 +162,29 @@ Thank you!
     Graham Keeling <graham@equiinet.com>
     Guido Serassio <guido.serassio@acmeconsulting.it>
     Guido Serassio <serassio@squid-cache.org>
+    Gustavo Zacarias <gustavo@zacarias.com.ar>
+    Guy Helmer <ghelmer@palisadesys.com>
     Hank Hampel <hh@nr-city.net>
     Hasso Tepper <hasso@estpak.ee>
-    Henrik Nordstr?m <henrik@hlaptop.localdomain>
+    helix84 <helix84@centrum.sk>
     Henrik Nordstrom <henrik@henriknordstrom.net>
     Henrik Nordstrom <hno@squid-cache.org>
     Hide Nagaoka <hide@cc.meisei-u.ac.jp>
-    hno
+    HONDA Hirofumi <honda.hirofumi@nttcom.co.jp>
+    Hussam Al-Tayeb <hussam@visp.net.lb>
     Ian Castle <ian.castle@coldcomfortfarm.net>
     Ian Turner <vectro@pipeline.com>
     Igor Vinokurov <igor@cs.ibank.ru>
+    IIDA Yosiaki <y-iida@secom.co.jp>
+    isaac <isaacarsenal@gmail.com>
     Isnard <isnardjaquet@gmail.com>
+    Ivan Mas??r <helix84@centrum.sk>
     Jakob Bohm <jb-debbugs@wisemo.com>
     Jakub Wilk <ubanus@users.sf.net>
+    James Bowe <minijb@gmail.com>
     James Brotchie <brotchie@gmail.com>
     James R Grinter <jrg@demon.net>
+    Jan Klemkow <j.klemkow@wemelug.de>
     Jan Niehusmann <jan@anduin.gondor.mcs.de>
     Jan Sievers <sievers@zedat.fu-berlin.de>
     Jean-Francois Micouleau <Jean-Francois.Micouleau@utc.fr>
@@ -139,39 +193,54 @@ Thank you!
     Jens-S. V?ckler <voeckler@rvs.uni-hannover.de>
     Jeremy Allison
     Jerry Murdock <jmurdock@itraktech.com>
+    Jiri Skala <jaskalnik@gmail.com>
+    Jiri Skala <jskala@redhat.com>
     Joachim Bauch <jojo@fistofbenztown.de>
     Joachim Bauch (mail@joachim-bauch.de)
     Joao Alves Neto <alves_joao@hotmail.com>
     Jochen Obalek
     Jochen Voss <voss@seehuhn.de>
+    Joe Crayne <oh.hellojoe@gmail.com>
     Joe Ramey <ramey@csc.ti.com>
     Joe Ramey <ramey@jello.csc.ti.com>
+    Joerg Lehrke <jlehrke@noc.de>
     Johnathan Conley <johnathan.conley@gmail.com>
     John Dilley <jad@hpl.hp.com>
     John Saunders <johns@rd.scitec.com.au>
     John Xue <xgxjohn@gmail.com>
     Jonathan Larmour <JLarmour@origin-at.co.uk>
+    Jonathan Wolfe <jonathan.wolfe@gmail.com>
     Jon Kinred
     Jon Thackray <jrmt@uk.gdscorp.com>
+    Jorge Ivan Burgos Aguilar <jorgeivanburgosaguilar@gmail.com>
+    Jose-Marcio Martins da Cruz <Jose-Marcio.Martins@mines-paristech.fr>
+    Joshua Root <jmr@macports.org>
     Joshua Root <josh+squid@root.id.au>
     JPP <jpp1@frws.com>
+    Juan <jdsq12@yahoo.es>
     Juerg Michel
+    Julien Pinon <jpinon@olfeo.com>
+    Karl Benoit <karl.isatwork@gmail.com>
     Kieran Whitbread <k.j.whitbread@qmul.ac.uk>
-    Kinkie <kinkie@squid-cache.org>
-    kinkie@squid-cache.org
     Klaubert Herr <klaubert@gmail.com>
     Klaus Singvogel <kssingvo@suse.de>
     Kolics Bertold <bertold@tohotom.vein.hu>
     Kostas Anagnostakis <kanag@csi.forth.gr>
     Lab10 <lab10@bt-anlagenbau.at>
     Laszlo Attilla Toth <panther@balabit.hu>
     Leeann Bent <lbent@cs.ucsd.edu>
+    Leonid Evdokimov <leon@darkk.net.ru>
     libit <sambabug.lb@gmail.com>
     Luigi Gangitano <luigi@debian.org>
+    Luis Daniel Lucio Quiroz <dlucio@okay.com.mx>
+    Lukas B??gelei <unknown>
     Luke Howard <lukeh@vurt.schnet.edu.au>
     Lutz Donnerhacke <lutz@iks-jena.de>
     Manu Garg <manugarg@gmail.com>
-    Marcus Kool
+    Marcello Romani <marcello.romani@libero.it>
+    Marcin Wisnicki <mwisnicki@gmail.com>
+    Marco Beck <mbeck@miamod.de>
+    Marcus Kool <marcus.kool@urlfilterdb.com>
     Marc van Selm <selm@cistron.nl>
     Marin Stavrev <mstavrev@gmail.com>
     Marios Makassikis <mmakassikis@gmail.com>
@@ -182,16 +251,20 @@ Thank you!
     Mark Treacy <mark@aone.com.au>
     Markus Gyger <mgyger@itr.ch>
     Markus Moeller <huaraz@moeller.plus.com>
+    Markus Moeller (markus_moeller at compuserve.com)
     Markus Rietzler <markus.rietzler@rzf.fin-nrw.de>
     Markus Stumpf <maex@Space.NET>
     Martin Hamilton <martinh@gnu.org>
     Martin Hamilton <martin@mrrl.lut.ac.uk>
+    Martin Huter <mhuter@barracuda.com>
     Martin Huter <m.huter@phion.com>
     Martin Stolle <martin.stolle@ekom21.de>
     Masashi Fujita <objectx@bandit.co.jp>
     Massimo Zito <zmax.linkedin at gmail dot com>
+    Mathias Fischer <maf@open.ch>
     Matthew Morgan <atcs.matthew@gmail.com>
     Matthias Pitzl <silamael@coronamundi.de>
+    Matthias "Silamael" <Silamael@coronamundi.de>
     Max Okumoto <okumoto@ucsd.edu>
     Merik Karman
     <mgd@swarm.org>
@@ -201,41 +274,54 @@ Thank you!
     Michael O'Reilly <michael@metal.iinet.net.au>
     Michael Pelletier <mikep@comshare.com>
     Michael van Elst
+    Michael Weiser <michael@weiser.dinsnail.net>
     Michal Luscon <mluscon@redhat.com>
     Miguel A.L. Paraz <map@iphil.net>
     Mike Groeneweg <mikeg@scorpion.murdoch.edu.au>
+    Mike Mitchell <mike.mitchell@sas.com>
     Mike Mitchell <Mike.Mitchell@sas.com>
     Mikio Kishi <mkishi@104.net>
+    Milen Pankov <mail@milen.pankov.eu>
     Ming Fu <mfu@watchguard.com>
     Miquel van Smoorenburg <miquels@cistron.nl>
     Moez Mahfoudh <moez.mahfoudh@imag.fr>
+    Mohsen Saeedi <mohsen.saeedi@gmail.com>
     Mukaigawa Shin'ichi <shin@nff.ncl.omron.co.jp>
     Nathan Hoad <nathan@getoffmalawn.com>
     Neil Murray <neil@aone.com.au>
+    nglnx - Rosetta Project
     Niall Doherty <ndoherty@eei.ericsson.se>
     Nick Rogers <ncrogers@gmail.com>
     Nikolai Gorchilov <niki@x3me.net>
     'noloader' <noloader@gmail.com>
+    Ole Christensen <olechristensende@aol.de>
+    Oliver Dumschat <necromot@googlemail.com>
     Oliver Hookins
     Olivier Montanuy
+    Olivier W.
+    OpenSolaris Project
     Oskar Pearson <oskar@is.co.za>
     Paul Z <paulz42@gmail.com>
+    Pavel Timofeev
     Pawel Worach <pawel.worach@gmail.com>
     Pedro Lineu Orso <orso@pop.hsbcbamerindus.com.br>
     Pedro Ribeiro <pribeiro@isel.pt>
     Pete Bentley <pete@demon.net>
-    Peter Eisenhauer <pe@pipetronix.de>
     Peter Hidas <peter.hidas@safeland.hu>
+    Peter Payne
     Peter Pramberger <peter@pramberger.at>
     Philip Allison <philip.allison@smoothwall.net>
     Philippe Lantin <plantin@cobaltgroup.com>
+    Phil Oester <kernel@linuxace.com>
     Pierangelo Masarati <ando@sys-net.it>
+    Pierre LALET <pierre.lalet@cea.fr>
     Pierre-Louis Brenac <brenacp@esiee.fr>
     Pierre-Louis BRENAC <brenacp@esiee.fr>
     Poul-Henning Kamp <phk@login.dknet.dk>
     Priyanka Gupta <priyanka@icelero.com>
     Przemek Czerkas <pczerkas@mgmnet.pl>
     Rabellino Sergio (rabellino@di.unito.it)
+    Rafael Martinez <rmartine@fdi.ucm.es>
     Rafael Martinez Torres <rmartine@fdi.ucm.es>
     Rafal Ramocki <maniac@sistbg.net>
     Rajiv Desai <rajiv@maginatics.com>
@@ -244,67 +330,96 @@ Thank you!
     Ramon de Carvalho <ramondecarvalho@yahoo.com.br>
     Regardt van de Vyver <squid@vdvyver.net>
     Regents of the University of California (UCSD)
+    Reinhard Posmyk <Reinhard.Posmyk@arxes.de>
     Reinhard Sojka <reinhard.sojka@parlament.gv.at>
     Rene Geile <rene.geile@t-online.de>
+    Ren? Geile <rene.geile@t-online.de>
     Reuben Farrelly <reuben@reub.net>
     Richard Huveneers <richard@hekkihek.hacom.nl>
     Richard Huveneers <Richard.Huveneers@hekkihek.hacom.nl>
     Richard Sharpe
     Richard Wall <richard.wall@appliansys.com>
     Robert Collins <rbtcollins@hotmail.com>
     Robert Collins <robertc@robertcollins.net>
+    Robert <Dessa@gmake.de>
     Robert Forster
+    Robert Walsh <robert.walsh@bbn.com>
     Robin Elfrink <robin@a1.nl>
     Rodrigo Campos <rodrigo@geekbunker.org>
     Rodrigo Campos (rodrigo@geekbunker.org)
     Rodrigo Rubira Branco <rodrigo@kernelhacking.com>
     Rodrigo Rubira Branco <rrbranco@br.ibm.com>
     Ron Gomes <rrg@ny.ubs.com>
-    rousskov
+    R Phillips <r.phillips@uq.edu.au>
     Russell Street <r.street@auckland.ac.nz>
     Russell Vincent <vincent@ucthpx.uct.ac.za>
     Ryan Troll <ryan+@andrew.cmu.edu>
     Samba Project
+    Santiago Garcia Mantinan <manty@debian.org>
+    Scott James Remnant <scott@netsplit.com>
     Scott Schram <scott@schram.net>
+    Sean Critica <sean.critica@gmail.com>
+    Sebastian Krahmer <krahmer@suse.com>
     Sebastien Wenske <sebastien@wenske.fr>
+    Sergey Merzlikin <sm@smsoft.ru>
     Sergio Rabellino <rabellino@di.unito.it>
     Shigechika Aikawa <shige@luck.imasy.or.jp>
     Silamael <Silamael@coronamundi.de>
-    squidadm@squid-cache.org
     Stefan Fritsch <sf@sfritsch.de>
     Stefano Cordibella <stefano.cordibella@edalab.it>
     Stephen R. van den Berg <srb@cuci.nl>
+    Stephen Thorne <stephen@thorne.id.au>
     Steve Bennett <S.Bennett@lancaster.ac.uk>
     Steve Hill <steve@opendium.com>
+    Steven Lawrance <squid@moonlightdesign.org>
     Steven Wilton <swilton@q-net.net.au>
     Steve Snyder <swsnyder@snydernet.net>
     Stewart Forster <slf@connect.com.au>
     Stuart Henderson <sthen@openbsd.org>
+    Stuart Henderson <stu@spacehopper.org>
     Susant Sahani <ssahani@redhat.com>
     Svenx <svensven@gmail.com>
     Taavi Talvik <taavi@uninet.ee>
     Taketo Kabe <kabe@shiratori.riec.tohoku.ac.jp>
     The Measurement Factory <info@measurement-factory.com>
+    The Squid Software Foundation
     Thomas De Schampheleire <thomas.de.schampheleire@gmail.com>
     Thomas Hozza <thozza@redhat.com>
     Thomas-Martin Seck <tmseck@netcologne.de>
     Thomas Ristic <thr@bootet.net>
     Thomas Weber <x@4t2.com>
     Tianyin Xu <tixu@cs.ucsd.edu>
+    Tilmann Bubeck <t.bubeck@reinform.de>
+    Tim Brown <squid-cache@machine.org.uk>
+    Timo Teras <timo.teras@iki.fi>
+    Timo Tseras <timo.teras@iki.fi>
     Tim Starling <tstarling@wikimedia.org>
     Todd C. Miller <Todd.Miller@courtesan.com>
     Tomas Hozza <thozza@redhat.com>
     Tony Lorimer <tlorimer@au.mdis.com>
+    Tsantilas Christos <chtsanti@users.sourceforge.net>
+    Unknown
     Unknown FreeBSD Contributor
     Unknown - NetBSD Project
+    Various
+    Various Translators
+    Victor Jose Hernandez Gomez <vjhergom@cic.upo.es>
     Vince Brimhall
     Vincent Regnard
     Vitaliy Matytsyn (main) <vm@if.bank.gov.ua>
     Vitaliy Matytsyn <vm@if.bank.gov.ua>
     vollkommen <vollkommen@gmx.net>
+    Walter <bundestrojaner2@googlemail.com>
+    Wang DaQing <wdq@bigfoot.com>
+    Warren Baker <warren@decoy.co.za>
     Wesha <wesha@iname.com>
     Will Roberts <squid@bigwillystyle42.com>
+    Wojciech Zatorski <zator@bg.szczecin.pl>
     Wojtek Sylwestrzak <W.Sylwestrzak@icm.edu.pl>
     Wolfgang Breyha <wbreyha@gmx.net>
     Wolfgang Nothdurft <wolfgang@linogate.de>
+    Xavier Redon <xavier.redon@polytech-lille.fr>
+    yabuki <yabuki@sraoss.co.jp>
+    Yannick Bergeron <yaberger@ca.ibm.com>
+    Yuhua Wu <ywu@bitglass.com>
     Zhanpeng Chen <lowstz@gmail.com>
@@ -617,6 +617,45 @@ compat/xstrto.cc:
 
 ==============================================================================
 
+errors/:
+
+ *  Translation Snippets provided by Squid Project Translators held in
+ *  copyright for open distribution.
+ *
+ *  Translation Snippets provided by Rosetta Project Translators held in
+ *  copyright for open distribution.
+ *
+ *  Copyright 2009
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ * 1. Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ * 2. Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ * 3. Neither the name of the University nor the names of its contributors
+ *    may be used to endorse or promote products derived from this software
+ *    without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE REGENTS AND CONTRIBUTORS ``AS IS'' AND
+ * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE DISCLAIMED.  IN NO EVENT SHALL THE REGENTS OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
+ * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
+ * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
+ * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
+ * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
+ * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
+ * SUCH DAMAGE.
+
+
+see TRANSLATORS file for current contributing translators holding copyrights.
+
+==============================================================================
+
 errors/errorpage.css:
 
  Stylesheet for Squid Error pages
@@ -1748,12 +1787,6 @@ lib/getopt.c:
 
 ==============================================================================
 
-lib/drand48.c:
-
-From Linux libc-5.4.46.
-
-==============================================================================
-
 lib/radix.c:
 
  *  Adapted from HTSUtils.c in CERN httpd 3.0 (http://info.cern.ch/httpd/)
@@ -1,3 +1,67 @@
+Changes to squid-3.5.6 (03 Jul 2015):
+
+	- Bug 4274: ssl_crtd.8 not being installed
+	- Bug 4193: memory leak on FTP listings
+	- Bug 4183: segfault when freeing https_port clientca on reconfigure or exit
+	- Bug 3875: bad mimeLoadIconFile error handling
+	- Bug 3483: assertion failed store.cc:1866: 'isEmpty()'
+	- Bug 3329: pinned server connection is not closed properly
+	- TLS: Disable client-initiated renegotiation
+	- ext_edirectory_userip_acl: fix uninitialized variable
+	- Support custom OIDs in *_cert ACLs
+	- Fix CONNECT failover to IPv4 after trying broken IPv6 servers
+	- Use relative-URL in errorpage.css for SN.png
+	- Do not blindly forward cache peer CONNECT responses
+	- Fix assertion String.cc:221: "str"
+	- Fix assertion comm.cc:759: "Comm::IsConnOpen(conn)" in ConnStateData::getSslContextDone
+	- Translations: add Spanish US dialect alias
+
+Changes to squid-3.5.5 (28 May 2015):
+
+	- Regression Bug 4132: short_icon_urls with global_internal_static on
+	- Bug 4238: assertion Read.cc:205: "params.data == data"
+	- Bug 4236: SSL negotiation error of 'success'
+	- Bug 3930: assertion 'connIsUsable(http->getConn())'
+	- Fix assertion MemBuf.cc:380: "new_cap > (size_t) capacity" in SSL I/O buffer
+	- Fix assertion errorpage.cc:600: "entry->isEmpty()"
+	- Fix comm_connect_addr on failures returns Comm:OK
+	- Fix missing external ACL helper notes
+	- Fix "Not enough space to hold server hello message" error message
+	- Fix segmentation fault inside Adaptation::Icap::Xaction::swanSong
+	- Prevent unused ssl_crtd helpers being run
+	- ... and some code cleanup and portability updates
+	- ... and several documentation updates
+
+Changes to squid-3.5.4 (01 May 2015):
+
+	- Bug 4234: comm_connect_addr uses errno incorrectly
+	- Bug 4231: fd_open() not correctly handling UDS socket descriptions
+	- Bug 4226: digest_edirectory_auth: found but cannot be built
+	- Bug 4198: assertion failed: client_side.h:364: "sslServerBump == srvBump"
+	- Bug 3775: Disable HTTP/1.1 pipeline feature for pinned connections
+	- Fix require-proxy-header preventing HTTPS proxying and ssl-bump
+	- Fix Negotiate/Kerberos authentication request size exceeds output buffer size
+	- Fix SQUID_X509_V_ERR_DOMAIN_MISMATCH errors while accessing sites with valid certificates
+	- Add server_name ACL matching server name(s) obtained from various sources
+	- Add Kerberos support for MAC OS X 10.x
+	- Support for resuming TLS sessions
+	- ... and some portability and compile fixes
+	- ... and several documentation updates
+	- ... and all fixes from squid 3.4.13
+
+Changes to squid-3.5.3 (28 Mar 2015):
+
+	- Regression Bug 4213: negotiate_kerberos_auth: freeing non-dynamic memory
+	- Regression Bug 4206: Incorrect connection close on expect:100-continue
+	- Bug 4204: ./configure does not abort when required helpers cannot be built
+	- Bug 3805: support shared memory on MacOS X in Mem::IPC::Segment
+	- Bug 2907: high CPU usage on CONNECT when using delay pools
+	- basic_getpwnam_auth: fail authentication on crypt() failures
+	- basic_nis_auth: fail authentication on crypt() failures
+	- ext_kerberos_ldap_group_acl: Heimdal support improvements
+	- ext_wbinfo_group_acl: Perl 5.20 support
+	- ... and several compile issues
+
 Changes to squid-3.5.2 (18 Feb 2015):
 
 	- Regression Bug 4176: Digest auth too many helper lookups
@@ -118,6 +182,12 @@ Changes to squid-3.5.0.1 (17 Oct 2014):
 	- ... and many error page translation updates
 	- ... and much code cleanup and polishing
 
+Changes to squid-3.4.13 (01 May 2015):
+
+	- Bug 4212: ssl_crtd crashes with corrupt database
+	- ... and some documentation updates
+	- ... and all fixes from squid 3.3.14
+
 Changes to squid-3.4.12 (18 Feb 2015):
 
 	- Bug 4066: Digest auth nonce indefinite rollover
@@ -335,6 +405,12 @@ Changes to squid-3.4.0.1 (29 Jul 2013):
 	- ... and many documentation changes
 	- ... and much code cleanup and polishing
 
+Changes to squid-3.3.14 (01 May 2015):
+
+	- Bug 4093: source-maintenance.sh errors and warnings due to wrong tools/options
+	- ... and some documentation updates
+	- ... and all fixes from squid 3.2.14
+
 Changes to squid-3.3.13 (28 Aug 2014):
 
 	- Fix segmentation fault setting up server SSL connnection
@@ -520,6 +596,12 @@ Changes to squid-3.3.0.1 (21 Oct 2012):
 	- ... and many compile error fixes
 	- ... and a very large amount of code polish for faster compilation
 
+Changes to squid-3.2.14 (01 May 2015):
+
+	- Fix 'access_log none' to prevent following logs being used
+	- Fix X509 server certificate domain matching
+	- ... some documentation updates
+
 Changes to squid-3.2.13 (13 Jul 2013):
 
 	- Bug 3869: assertion failed: MemBuf.cc:272: size < capacity
@@ -1,3 +1,11 @@
+/*
+ * Copyright (C) 1996-2015 The Squid Software Foundation and contributors
+ *
+ * Squid software is distributed under GPLv2+ license and includes
+ * contributions from numerous individuals and organizations.
+ * Please see the COPYING and CONTRIBUTORS files for details.
+ */
+
 To build and install the Squid Cache, type:
 
 	% ./configure --prefix=/usr/local/squid
@@ -16,5 +24,5 @@ To run a Cache, you will need to:
 	      % /usr/local/squid/sbin/squid
 
 If you want to use the WWW interface to the Cache Manager, copy
-the cachemgr.cgi program into your httpd server's cgi-bin
+the tools/cachemgr.cgi program into your httpd server's cgi-bin
 directory.
@@ -20,40 +20,38 @@ Uncomment and edit the following lines in /usr/local/squid/etc/squid.conf:
 acl, http_access
 
     Access control lists.  This is important because it prevents people
-    from stealing your network resources.  To fill in the
-    "localnet" ACL, use your network address (for instance 192.168.10.0
-    your CIDR network mask (for instance 255.255.255.0 or /24):
+    from stealing your network resources.
+
+    Edit the "localnet" ACL definition to be your LAN network address
+    ranges in CIDR format. For instance:
 
-        acl manager proto cache_object
-        acl localhost src 127.0.0.1
         acl localnet src 192.168.10.0/24
 
-        http_access deny manager all
-        http_access allow localnet
-        http_access deny all
+    Add any other ACLs and edit the http_access lines to match your policy
+    requirements for use of the proxy. See Squid FAQ for more details.
 
 cache_mgr
 
-    Put here the e-mail address of the manager:
+    Put here the e-mail address of the manager.
+
+==============================================================================
+
+Some configuration lines which are optional but may be needed.
 
 visible_hostname
 
-    The host name you advertise for the cache.
+    The publicly visible host name advertised for the cache. This will
+    be used for URLs generated by Squid for clients to fetch certain
+    objects from.
 
 cache_effective_user
 
     If building your own squid; use ./configure --with-default-user=X
 
-    If you must start Squid as root, find a safe user and group to run
+    You must start Squid as root, with a safe user and group to run
     as after startup (typically "nobody" and "nogroup").  Do not use
     "root", for security reasons.
 
-
-==============================================================================
-
-Some configuration lines which are optional but may be needed.
-
-
 cache_dir ufs /usr/local/squid/var/cache 100 16 256
 
     Add here (first number, here 100) the amount of hard disk space 
@@ -98,5 +96,15 @@ Once you have Squid working from the command line, tell your Unix to
 start Squid at startup (it depends heavily on the Unix you use, you'll
 typically have to modify something in a /etc/rc_something).
 
-This quick start file written by: Stephane Bortzmeyer and Duane
-Wessels.
+==============================================================================
+
+/*
+ * Copyright (C) 1996-2015 The Squid Software Foundation and contributors
+ *
+ * Squid software is distributed under GPLv2+ license and includes
+ * contributions from numerous individuals and organizations.
+ * Please see the COPYING and CONTRIBUTORS files for details.
+ */
+
+This quick start file written by:
+    Stephane Bortzmeyer and Duane Wessels.
@@ -1,34 +1,49 @@
 The following organizations have supported the Squid Project by providing
 their resources or funding various Squid development activities:
 
-@Squid-3.4:
+@Squid-4:
 LaunchPad - http://launchpad.net/
 
-	Provide Bazaar mirroring services and host the Squid-3 developer
+	Provide Bazaar mirroring services and host the Squid-3+ developer
 	project code.
 
-Messagenet - http://messagenet.it/
-
-	Messagenet donated hardware and bandwidth for the wiki server
-	and most continuous integration testing.
-
 RackSpace - http://www.rackspace.com/
 
 	RackSpace donated a number of virtual machines from their cloud
 	infrastructure to support and extend the continuous integration
-	testing infrastructure.
+	testing infrastructure, and since late 2014 to host many of the
+	Squid Project services.
+
+Squid Software Foundation - http://foundation.squid-cache.org/
+
+	The Foundation governs and facilitates Squid project activities,
+	providing the infrastructure and support framework for Squid
+	developers and users.
 
 The Measurement Factory - http://www.measurement-factory.com/
 
 	Measurement Factory has constributed significant resources
-	toward Squid-3 development and server maintenance.
+	toward Squid-3+ development and server maintenance.
 
 Treehouse Networks, NZ - http://treenet.co.nz/
 
 	Treehouse Networks has contributed significant resources
-	toward Squid-3 development and maintenance for their customer
+	toward Squid-3+ development and maintenance for their customer
 	gateways and CDN.
 
+@Squid-3.5:
+Messagenet - http://messagenet.it/
+
+	Messagenet donated hardware and bandwidth for the wiki server
+	and most continuous integration testing until late 2014 when
+	it was converted to a Squid Project core mirror server.
+
+@Squid-3.4:
+anonymoX GmbH - http://anonymox.net/
+
+	anonymoX contributed sponsorship and resources towards resolving
+	and testing bug fixes in high performance Squid-3.4 proxies.
+
 @Squid-3.3:
 iCelero - http://icelero.com/
 
@@ -54,7 +69,8 @@ iiNet Ltd - http://www.iinet.net.au/
 
 Palisade Systems - http://www.palisadesys.com/
 
-	Palisade Systems funded SSL Bump feature development in Squid3.
+	Palisade Systems funded initial SSL Bump feature development
+	in Squid-3.2.
 
 @Squid-3.1:
 Barefruit - http://www.barefruit.com/
@@ -17,8 +17,8 @@ AC_DEFUN([AX_CXX_TYPE_NULLPTR],[
     AC_MSG_RESULT(yes)], [
     HAVE_NULLPTR=no
     AC_MSG_RESULT(no)])
-  if test "x$HAVE_NULLPTR" = xyes; then
-    AC_DEFINE(HAVE_NULLPTR, 1, [Define to 1 if nullptr is supported])
+  if test "x$HAVE_NULLPTR" = xno; then
+    AC_DEFINE(nullptr, NULL, [Leave undefined if nullptr is supported])
   fi
   AC_MSG_CHECKING([whether nullptr_t is supported])
   AC_TRY_COMPILE([#include <cstddef>],[typedef nullptr_t peng;], [
@@ -42,8 +42,36 @@ AC_DEFUN([AX_CXX_TYPE_UNIQUE_PTR],[
     AC_MSG_RESULT(yes)], [
     HAVE_UNIQUE_PTR=no
     AC_MSG_RESULT(no)])
+  if test "x$HAVE_UNIQUE_PTR" = xno; then
+    AC_DEFINE(unique_ptr, auto_ptr, [Leave undefined if std::unique_ptr<T> is supported])
+  fi
   if test "x$HAVE_UNIQUE_PTR" = xyes; then
     AC_DEFINE(HAVE_UNIQUE_PTR, 1, [Define to 1 if std::unique_ptr<T> is supported])
   fi
   AC_LANG_POP
 ])
+
+## Hand crafted for Squid under GPL version 2
+AC_DEFUN([AX_CXX_TYPE_UNIFORM_DISTRIBUTIONS],[
+  AC_REQUIRE([AC_PROG_CXX])
+  AC_LANG_PUSH([C++])
+  AC_MSG_CHECKING([whether std::uniform_int_distribution<T> is supported])
+  AC_TRY_COMPILE([#include <random>],[std::uniform_int_distribution<int> c;], [
+    HAVE_UNIFORM_INT_DISTRIBUTION=yes
+    AC_MSG_RESULT(yes)], [
+    HAVE_UNIFORM_INT_DISTRIBUTION=no
+    AC_MSG_RESULT(no)])
+  if test "x$HAVE_UNIFORM_INT_DISTRIBUTION" = xno; then
+    AC_DEFINE(uniform_int_distributon, tr1::uniform_int, [Leave undefined if std::uniform_int_distribution<T> is supported])
+  fi
+  AC_MSG_CHECKING([whether std::uniform_real_distribution<T> is supported])
+  AC_TRY_COMPILE([#include <random>],[std::uniform_real_distribution<double> c;], [
+    HAVE_UNIFORM_REAL_DISTRIBUTION=yes
+    AC_MSG_RESULT(yes)], [
+    HAVE_UNIFORM_REAL_DISTRIBUTION=no
+    AC_MSG_RESULT(no)])
+  if test "x$HAVE_UNIFORM_REAL_DISTRIBUTION" = xno; then
+    AC_DEFINE(uniform_real_distributon, tr1::uniform_real, [Leave undefined if std::uniform_real_distribution<T> is supported])
+  fi
+  AC_LANG_POP
+])
@@ -79,6 +79,9 @@ AC_DEFUN([SQUID_CHECK_MAX_SKEW_IN_KRB5_CONTEXT],[
 KRB5INT_BEGIN_DECLS
 #endif
 #endif
+#if USE_APPLE_KRB5
+#define KERBEROS_APPLE_DEPRECATED(x)
+#endif
 #include <krb5.h>
 krb5_context kc; kc->max_skew = 1;
       ]])
@@ -100,6 +103,9 @@ AC_DEFUN([SQUID_CHECK_KRB5_CONTEXT_MEMORY_CACHE],[
 KRB5INT_BEGIN_DECLS
 #endif
 #endif
+#if USE_APPLE_KRB5
+#define KERBEROS_APPLE_DEPRECATED(x)
+#endif
 #include <krb5.h>
 int main(int argc, char *argv[])
 {
@@ -127,6 +133,9 @@ AC_DEFUN([SQUID_CHECK_KRB5_CONTEXT_MEMORY_KEYTAB],[
 KRB5INT_BEGIN_DECLS
 #endif
 #endif
+#if USE_APPLE_KRB5
+#define KERBEROS_APPLE_DEPRECATED(x)
+#endif
 #include <krb5.h>
 int main(int argc, char *argv[])
 {
@@ -157,6 +166,9 @@ AC_DEFUN([SQUID_CHECK_WORKING_GSSAPI], [
 #include <gss.h>
 #endif
 #else
+#if USE_APPLE_KRB5
+#define GSSKRB_APPLE_DEPRECATED(x)
+#endif
 #if HAVE_GSSAPI_GSSAPI_H
 #include <gssapi/gssapi.h>
 #elif HAVE_GSSAPI_H
@@ -200,6 +212,9 @@ AC_DEFUN([SQUID_CHECK_SPNEGO_SUPPORT], [
 #include <gss.h>
 #endif
 #else
+#if USE_APPLE_KRB5
+#define GSSKRB_APPLE_DEPRECATED(x)
+#endif
 #if HAVE_GSSAPI_GSSAPI_H
 #include <gssapi/gssapi.h>
 #elif HAVE_GSSAPI_H
@@ -239,6 +254,9 @@ dnl checks that krb5 is functional. Sets squid_cv_working_krb5
 AC_DEFUN([SQUID_CHECK_WORKING_KRB5],[
   AC_CACHE_CHECK([for working krb5], squid_cv_working_krb5, [
     AC_RUN_IFELSE([AC_LANG_SOURCE([[
+#if USE_APPLE_KRB5
+#define KERBEROS_APPLE_DEPRECATED(x)
+#endif
 #if HAVE_KRB5_H
 #if HAVE_BROKEN_SOLARIS_KRB5_H
 #if defined(__cplusplus)
@@ -338,6 +356,9 @@ AC_DEFUN([SQUID_CHECK_KRB5_FUNCS],[
       [Define to 1 if you have krb5_get_init_creds_opt_alloc]),)
   AC_MSG_CHECKING([for krb5_get_init_creds_free requires krb5_context])
   AC_COMPILE_IFELSE([AC_LANG_PROGRAM([[
+        #if USE_APPLE_KRB5
+        #define KERBEROS_APPLE_DEPRECATED(x)
+        #endif
 	#include <krb5.h>
     ]],[[krb5_context context;
 	 krb5_get_init_creds_opt *options;
@@ -106,7 +106,10 @@ AC_DEFUN([SQUID_CHECK_OPENSSL_GETCERTIFICATE_WORKS],[
    AC_DEFINE(SQUID_SSLGETCERTIFICATE_BUGGY, 1)
    AC_MSG_RESULT([yes])
   ],
-  [])
+  [
+   AC_DEFINE(SQUID_SSLGETCERTIFICATE_BUGGY, 0)
+   AC_MSG_RESULT([cross-compile, assuming no])
+  ])
 
   AC_MSG_CHECKING(whether the workaround for SSL_get_certificate works)
   AC_RUN_IFELSE([
@@ -132,7 +135,10 @@ AC_DEFUN([SQUID_CHECK_OPENSSL_GETCERTIFICATE_WORKS],[
   [
    AC_MSG_RESULT([no])
   ],
-[])
+  [
+   AC_DEFINE(SQUID_USE_SSLGETCERTIFICATE_HACK, 0)
+   AC_MSG_RESULT([cross-compile, assuming no])
+  ])
 
 SQUID_STATE_ROLLBACK(check_SSL_get_certificate)
 ])
@@ -28,7 +28,6 @@ libcompat_squid_la_SOURCES = \
 	cppunit.h \
 	debug.cc \
 	debug.h \
-	drand48.h \
 	eui64_aton.h \
 	eui64_aton.c \
 	fdsetsize.h \
@@ -1,64 +0,0 @@
-/*
- * Copyright (C) 1996-2015 The Squid Software Foundation and contributors
- *
- * Squid software is distributed under GPLv2+ license and includes
- * contributions from numerous individuals and organizations.
- * Please see the COPYING and CONTRIBUTORS files for details.
- */
-
-#include "squid.h"
-
-/* borrowed from libc/misc/drand48.c in Linux libc-5.4.46 this quick
- * hack by Martin Hamilton <martinh@gnu.org> to make Squid build on
- * Win32 with GNU-Win32 - sorry, folks! */
-
-#if !HAVE_DRAND48
-
-#define N   16
-#define MASK    ((unsigned)(1 << (N - 1)) + (1 << (N - 1)) - 1)
-#define LOW(x)  ((unsigned)(x) & MASK)
-#define HIGH(x) LOW((x) >> N)
-#define MUL(x, y, z)    { long l = (long)(x) * (long)(y); \
-        (z)[0] = LOW(l); (z)[1] = HIGH(l); }
-#define CARRY(x, y) ((long)(x) + (long)(y) > MASK)
-#define ADDEQU(x, y, z) (z = CARRY(x, (y)), x = LOW(x + (y)))
-#define X0  0x330E
-#define X1  0xABCD
-#define X2  0x1234
-#define A0  0xE66D
-#define A1  0xDEEC
-#define A2  0x5
-#define C   0xB
-
-static void next(void);
-static unsigned x[3] = {X0, X1, X2}, a[3] = {A0, A1, A2}, c = C;
-
-double drand48(void);
-
-double
-drand48(void)
-{
-    static double two16m = 1.0 / (1L << N);
-    next();
-    return (two16m * (two16m * (two16m * x[0] + x[1]) + x[2]));
-}
-
-static void
-next(void)
-{
-    unsigned p[2], q[2], r[2], carry0, carry1;
-
-    MUL(a[0], x[0], p);
-    ADDEQU(p[0], c, carry0);
-    ADDEQU(p[1], carry0, carry1);
-    MUL(a[0], x[1], q);
-    ADDEQU(p[1], q[0], carry0);
-    MUL(a[1], x[0], r);
-    x[2] = LOW(carry0 + carry1 + CARRY(p[1], r[0]) + q[1] + r[1] +
-               a[0] * x[2] + a[1] * x[1] + a[2] * x[0]);
-    x[1] = LOW(p[1] + r[0]);
-    x[0] = LOW(p[0]);
-}
-
-#endif /* HAVE_DRAND48 */
-
@@ -1,18 +0,0 @@
-/*
- * Copyright (C) 1996-2015 The Squid Software Foundation and contributors
- *
- * Squid software is distributed under GPLv2+ license and includes
- * contributions from numerous individuals and organizations.
- * Please see the COPYING and CONTRIBUTORS files for details.
- */
-
-#ifndef _SQUID_DRAND48_H
-#define _SQUID_DRAND48_H
-
-#if !HAVE_DRAND48
-#define HAVE_DRAND48 1
-SQUIDCEXTERN double drand48(void);
-#endif
-
-#endif
-
@@ -108,6 +108,19 @@ testPreCompiler::testIfDefAnd()
 #endif
     CPPUNIT_ASSERT(undefinedAndFalseB);
     CPPUNIT_ASSERT(!undefinedAndTrueB);
+
+#if UNDEFINED_FOO && UNDEFINED_FOO
+    bool undefinedAndUndefinedC = true;
+#else
+    bool undefinedAndUndefinedC = false;
+#endif
+#if !UNDEFINED_FOO && !UNDEFINED_FOO
+    bool notUndefinedAndNotUndefinedC = true;
+#else
+    bool notUndefinedAndNotUndefinedC = false;
+#endif
+    CPPUNIT_ASSERT(!undefinedAndUndefinedC);
+    CPPUNIT_ASSERT(notUndefinedAndNotUndefinedC);
 }
 
 /**
@@ -149,5 +162,17 @@ testPreCompiler::testIfDefOr()
     CPPUNIT_ASSERT(undefinedOrFalseB);
     CPPUNIT_ASSERT(!undefinedOrTrueB);
 
+#if UNDEFINED_FOO || UNDEFINED_FOO
+    bool undefinedOrUndefinedC = true;
+#else
+    bool undefinedOrUndefinedC = false;
+#endif
+#if !UNDEFINED_FOO || !UNDEFINED_FOO
+    bool notUndefinedOrNotUndefinedC = true;
+#else
+    bool notUndefinedOrNotUndefinedC = false;
+#endif
+    CPPUNIT_ASSERT(notUndefinedOrNotUndefinedC);
+    CPPUNIT_ASSERT(!undefinedOrUndefinedC);
 }
 
@@ -49,6 +49,47 @@
 /* Typedefs for missing entries on a system           */
 /******************************************************/
 
+/*
+ * Ensure that standard type limits are defined for use
+ */
+#if __cplusplus >= 201103L
+#include <cstdint>
+#elif HAVE_STDINT_H
+#include <stdint.h>
+#endif
+
+/* explicit bit sizes */
+#if !defined(UINT32_MIN)
+#define UINT32_MIN    0x00000000L
+#endif
+#if !defined(UINT32_MAX)
+#define UINT32_MAX    0xFFFFFFFFL
+#endif
+
+#if !defined(INT_MAX)
+#define INT_MAX    0x7FFFFFFFL // hack but a safe bet (32-bit signed integer)
+#endif
+
+#if !defined(INT64_MIN)
+/* Native 64 bit system without strtoll() */
+#if defined(LONG_MIN) && (SIZEOF_LONG == 8)
+#define INT64_MIN    LONG_MIN
+#else
+/* 32 bit system */
+#define INT64_MIN    (-9223372036854775807LL-1LL)
+#endif
+#endif
+
+#if !defined(INT64_MAX)
+/* Native 64 bit system without strtoll() */
+#if defined(LONG_MAX) && (SIZEOF_LONG == 8)
+#define INT64_MAX    LONG_MAX
+#else
+/* 32 bit system */
+#define INT64_MAX    9223372036854775807LL
+#endif
+#endif
+
 /*
  * ISO C99 Standard printf() macros for 64 bit integers
  * On some 64 bit platform, HP Tru64 is one, for printf must be used
@@ -116,12 +157,8 @@ typedef long mtyp_t;
 #endif
 
 #ifndef NULL
-#if defined(__cplusplus) && HAVE_NULLPTR
-#define NULL nullptr
-#else
 #define NULL 0
 #endif
-#endif
 
 #endif /* SQUID_TYPES_H */
 
@@ -5,7 +5,7 @@
 ## Please see the COPYING and CONTRIBUTORS files for details.
 ##
 
-AC_INIT([Squid Web Proxy],[3.HEAD-BZR],[http://bugs.squid-cache.org/],[squid])
+AC_INIT([Squid Web Proxy],[4.0.0-BZR],[http://bugs.squid-cache.org/],[squid])
 AC_PREREQ(2.61)
 AC_CONFIG_HEADERS([include/autoconf.h])
 AC_CONFIG_AUX_DIR(cfgaux)
@@ -55,7 +55,7 @@ AC_ARG_ENABLE(arch-native,
   SQUID_YESNO([$enableval],
     [Unrecognized argument to --disable-arch-native: $enableval])
 ])
-AC_MSG_NOTICE([CPU -march=native optimization enabled: ${enable_arch_native:=auto}])
+AC_MSG_NOTICE([CPU arch native optimization enabled: ${enable_arch_native:=auto}])
 if test "x${enable_arch_native}" != "xno"; then
   SQUID_CC_CHECK_ARGUMENT([squid_cv_check_marchnative],[-march=native])
 fi
@@ -93,7 +93,7 @@ if test "x$squid_host_os" = "solaris" -a "x$GCC" != "x" ; then
 fi
 
 # Check for C++11 compiler support
-AX_CXX_COMPILE_STDCXX_11([noext],[optional])
+AX_CXX_COMPILE_STDCXX_11([noext],[mandatory])
 
 # test for programs
 AC_PROG_RANLIB
@@ -419,28 +419,6 @@ SQUID_DEFINE_BOOL(_USE_INLINE_,$enable_inline,
 # to be used by sub-commands
 export enable_inline
 
-dnl
-dnl Check for atomic operations support in the compiler
-dnl
-AC_MSG_CHECKING([for GNU atomic operations support])
-AC_RUN_IFELSE([AC_LANG_PROGRAM([[
-    int n = 0;
-]],[[
-    __sync_add_and_fetch(&n, 10); // n becomes 10
-    __sync_fetch_and_add(&n, 20); // n becomes 30
-    __sync_sub_and_fetch(&n, 15); // n becomes 15
-    __sync_bool_compare_and_swap(&n, 15, 201); // n becomes 201
-    __sync_fetch_and_and(&n, 200); // n becomes 200
-    return (n == 200) ? 0 : -1;
-]])],
-[
-    AC_DEFINE(HAVE_ATOMIC_OPS,1,[Define to 1 if you have __sync_add_and_fetch() and such])
-    AC_MSG_RESULT(yes)
-],[
-    AC_MSG_RESULT(no)
-],[ AC_MSG_RESULT(cross-compiler cant tell)
-])
-
 AC_ARG_ENABLE(debug-cbdata,
   AS_HELP_STRING([--enable-debug-cbdata],
       [Provide some debug information in cbdata]), [ 
@@ -542,18 +520,20 @@ SQUID_DEFINE_BOOL(USE_DISKIO,$squid_opt_enable_diskio,
 dnl Some autoconf.h defines we might enable later...
 AC_ARG_WITH(pthreads,AS_HELP_STRING([--without-pthreads],[Disable POSIX Threads]))
 AC_ARG_WITH(aio, AS_HELP_STRING([--without-aio],[Do not use POSIX AIO. Default: auto-detect]))
-AH_TEMPLATE(USE_DISKIO_AIO, [Whether POSIX AIO support is needed. Automatic])
-AH_TEMPLATE(USE_DISKIO_DISKTHREADS, [Whether pthreads support is needed. Automatic])
 ENABLE_WIN32_AIOPS=0
 squid_opt_use_aio=
 squid_opt_use_diskthreads=
 AIOLIB=
 
 dnl Setup the module paths etc.
 DISK_LIBS=
-DISK_OS_LIBS=
 DISK_MODULES=
 DISK_LINKOBJS=
+AH_TEMPLATE(HAVE_DISKIO_MODULE_AIO, [Whether POSIX AIO Disk I/O module is built])
+AH_TEMPLATE(HAVE_DISKIO_MODULE_BLOCKING, [Whether Blocking Disk I/O module is built])
+AH_TEMPLATE(HAVE_DISKIO_MODULE_DISKDAEMON, [Whether DiskDaemon Disk I/O module is built])
+AH_TEMPLATE(HAVE_DISKIO_MODULE_IPCIO, [Whether IpcIo Disk I/O module is built])
+AH_TEMPLATE(HAVE_DISKIO_MODULE_MMAPPED, [Whether Mmapped Disk I/O module is built])
 for module in $squid_disk_module_candidates none; do
   # maybe not needed
   if test "x$module" = "xnone"; then
@@ -563,20 +543,79 @@ for module in $squid_disk_module_candidates none; do
     AC_MSG_ERROR(disk-io $module does not exist)
   fi
   case "$module" in
+
+    AIO)
+      dnl Check for POSIX AIO availability
+      squid_opt_use_aio="yes"
+      AIOLIB=
+      if test "x$with_aio" != "xno"; then
+        have_aio_header=no
+        AC_CHECK_HEADERS(aio.h,[have_aio_header=yes])
+        dnl On some systems POSIX AIO functions are in librt
+        dnl On some systems POSIX AIO functions are in libaio
+        AC_CHECK_LIB(rt,aio_read,[AIOLIB="-lrt"],AC_CHECK_LIB(aio,aio_read,[AIOLIB="-laio"],[]))
+        dnl Enable AIO if the library and headers are found
+        if test "x$AIOLIB" != "x" && test "x$have_aio_header" = "xyes"; then
+          AC_MSG_NOTICE([Native POSIX AIO support detected.])
+          squid_opt_use_aio="yes"
+        else
+          dnl Windows does things differently. We provide wrappers.
+          dnl TODO: Windows really needs its own DiskIO module or its Overlaped IO
+          case "$squid_host_os" in
+            mingw)
+              squid_opt_use_aio="yes"
+              AC_MSG_NOTICE([Windows being built. Maybe-enable POSIX AIO.])
+              ;;
+            *)
+              AC_MSG_NOTICE([Native POSIX AIO support not detected. AIO automatically disabled.])
+              squid_opt_use_aio="no"
+              ;;
+          esac
+        fi
+      else
+        AC_MSG_NOTICE([POSIX AIO support manually disabled.])
+        squid_opt_use_aio="no"
+      fi
+      dnl Use the POSIX AIO pieces if we actually need them.
+      if test "x$squid_opt_use_aio" = "xyes" ; then
+        DISK_MODULES="$DISK_MODULES AIO"
+        DISK_LINKOBJS="$DISK_LINKOBJS DiskIO/AIO/AIODiskIOModule.o"
+        AC_DEFINE([HAVE_DISKIO_MODULE_AIO],1,[POSIX AIO Disk I/O module is built])
+        case "$squid_host_os" in
+          mingw)
+            ENABLE_WIN32_AIO=1
+            AC_MSG_NOTICE([Replacing AIO DiskIO module with: Windows overlapped I/O support])
+            ;;
+          *)
+            AC_MSG_NOTICE([Enabling AIO DiskIO module])
+            ;;
+        esac
+      else
+        AC_MSG_NOTICE([AIO DiskIO Module disabled. Missing POSIX AIO support.])
+      fi
+      ;;
+
+    Blocking)
+      AC_MSG_NOTICE([Enabling Blocking DiskIO module])
+      DISK_MODULES="$DISK_MODULES Blocking"
+      DISK_LINKOBJS="$DISK_LINKOBJS DiskIO/Blocking/BlockingDiskIOModule.o"
+      AC_DEFINE([HAVE_DISKIO_MODULE_BLOCKING],1,[Blocking Disk I/O module is built])
+      ;;
+
     DiskDaemon)
       case "$squid_host_os" in
         mingw)
           AC_MSG_NOTICE(["DiskDaemon not supported on MinGW"])
           ;;
         *)
           AC_MSG_NOTICE([Enabling DiskDaemon DiskIO module])
-          DISK_LIBS="$DISK_LIBS libDiskDaemon.a"
           DISK_MODULES="$DISK_MODULES DiskDaemon"
-          DISK_PROGRAMS="$DISK_PROGRAMS DiskIO/DiskDaemon/diskd"
           DISK_LINKOBJS="$DISK_LINKOBJS DiskIO/DiskDaemon/DiskDaemonDiskIOModule.o"
+          AC_DEFINE([HAVE_DISKIO_MODULE_DISKDAEMON],1,[DiskDaemon Disk I/O module is built])
           ;;
         esac
       ;;
+
     DiskThreads)
       squid_opt_use_diskthreads="yes"
       LIBPTHREADS=
@@ -646,71 +685,24 @@ for module in $squid_disk_module_candidates none; do
           squid_opt_use_diskthreads="no"
         fi
         if test "x$squid_opt_use_diskthreads" = "xyes" ; then
-          AC_DEFINE(USE_DISKIO_DISKTHREADS, 1, [Whether pthreads support is needed. Automatic])
           AC_MSG_NOTICE([Enabling DiskThreads DiskIO module])
-          DISK_LIBS="$DISK_LIBS libDiskThreads.a"
-          DISK_OS_LIBS="$DISK_OS_LIBS $LIBPTHREADS"
           DISK_MODULES="$DISK_MODULES DiskThreads"
           DISK_LINKOBJS="$DISK_LINKOBJS DiskIO/DiskThreads/DiskThreadsDiskIOModule.o"
+          AC_DEFINE([HAVE_DISKIO_MODULE_DISKTHREADS],1,[DiskThreads Disk I/O module is built])
         else
-          AC_DEFINE(USE_DISKIO_DISKTHREADS, 0, [Whether pthreads support is needed. Automatic])
           AC_MSG_NOTICE([Native pthreads support disabled. DiskThreads module automaticaly disabled.])
           SQUID_STATE_ROLLBACK([diskthreads_state])
         fi
       ;;
 
-    AIO)
-      dnl Check for POSIX AIO availability
-      squid_opt_use_aio="yes"
-      AIOLIB=
-      if test "x$with_aio" != "xno"; then
-        have_aio_header=no
-        AC_CHECK_HEADERS(aio.h,[have_aio_header=yes])
-        dnl On some systems POSIX AIO functions are in librt
-        dnl On some systems POSIX AIO functions are in libaio
-        AC_CHECK_LIB(rt,aio_read,[AIOLIB="-lrt"],AC_CHECK_LIB(aio,aio_read,[AIOLIB="-laio"],[]))
-        dnl Enable AIO if the library and headers are found
-        if test "x$AIOLIB" != "x" && test "x$have_aio_header" = "xyes"; then
-          AC_MSG_NOTICE([Native POSIX AIO support detected.])
-          squid_opt_use_aio="yes"
-        else
-          dnl Windows does things differently. We provide wrappers.
-          dnl TODO: Windows really needs its own DiskIO module or its Overlaped IO
-          case "$squid_host_os" in
-            mingw)
-              squid_opt_use_aio="yes"
-              AC_MSG_NOTICE([Windows being built. Maybe-enable POSIX AIO.])
-              ;;
-            *)
-              AC_MSG_NOTICE([Native POSIX AIO support not detected. AIO automatically disabled.])
-              squid_opt_use_aio="no"
-              ;;
-          esac
-        fi
-      else
-        AC_MSG_NOTICE([POSIX AIO support manually disabled.])
-        squid_opt_use_aio="no"
-      fi
-      dnl Use the POSIX AIO pieces if we actually need them.
-      if test "x$squid_opt_use_aio" = "xyes" ; then
-        AC_DEFINE(USE_DISKIO_AIO, 1, [Whether POSIX AIO support is needed. Automatic])
-        DISK_MODULES="$DISK_MODULES AIO"
-        DISK_LIBS="$DISK_LIBS libAIO.a"
-        DISK_LINKOBJS="$DISK_LINKOBJS DiskIO/AIO/AIODiskIOModule.o"
-        case "$squid_host_os" in
-          mingw)
-            ENABLE_WIN32_AIO=1
-            AC_MSG_NOTICE([Replacing AIO DiskIO module with: Windows overlapped I/O support])
-            ;;
-          *)
-            AC_MSG_NOTICE([Enabling AIO DiskIO module])
-            DISK_OS_LIBS="$DISK_OS_LIBS $AIOLIB"
-            ;;
-        esac
-      else
-        AC_DEFINE(USE_DISKIO_AIO, 0, [Whether POSIX AIO support is needed. Automatic])
-        AC_MSG_NOTICE([AIO DiskIO Module disabled. Missing POSIX AIO support.])
+    IpcIo)
+      AC_MSG_NOTICE([Enabling IpcIo DiskIO module])
+      if test "x$ac_cv_search_shm_open" = "xno" ; then
+        AC_MSG_ERROR([DiskIO IpcIo module requires shared memory support])
       fi
+      DISK_MODULES="$DISK_MODULES IpcIo"
+      DISK_LINKOBJS="$DISK_LINKOBJS DiskIO/IpcIo/IpcIoDiskIOModule.o"
+      AC_DEFINE([HAVE_DISKIO_MODULE_IPCIO],1,[IpcIo Disk I/O module is built])
       ;;
 
     Mmapped)
@@ -720,33 +712,15 @@ for module in $squid_disk_module_candidates none; do
         AC_MSG_NOTICE([Mmapped DiskIO is not available on Mingw])
       else
         AC_MSG_NOTICE([Enabling Mmapped DiskIO module])
-        DISK_LIBS="$DISK_LIBS libMmapped.a"
         DISK_MODULES="$DISK_MODULES Mmapped"
         DISK_LINKOBJS="$DISK_LINKOBJS DiskIO/Mmapped/MmappedDiskIOModule.o"
+        AC_DEFINE([HAVE_DISKIO_MODULE_MMAPPED],1,[Mmapped Disk I/O module is built])
       fi
       ;;
 
-    IpcIo)
-      AC_MSG_NOTICE([Enabling IpcIo DiskIO module])
-      if test "x$ac_cv_search_shm_open" = "xno" ; then
-        AC_MSG_ERROR([DiskIO IpcIo module requires shared memory support])
-      fi
-      DISK_LIBS="$DISK_LIBS libIpcIo.a"
-      DISK_MODULES="$DISK_MODULES IpcIo"
-      DISK_LINKOBJS="$DISK_LINKOBJS DiskIO/IpcIo/IpcIoDiskIOModule.o"
-      AC_DEFINE(USE_DISKIO_IPCIO, 1, [Enable DiskIO IpcIo module.])
-      ;;
-
-    Blocking)
-      AC_MSG_NOTICE([Enabling Blocking DiskIO module])
-      DISK_LIBS="$DISK_LIBS libBlocking.a"
-      DISK_MODULES="$DISK_MODULES Blocking"
-      DISK_LINKOBJS="$DISK_LINKOBJS DiskIO/Blocking/BlockingDiskIOModule.o"
-      ;;
-
     *)
       AC_MSG_NOTICE([Enabling $module DiskIO module])
-      DISK_LIBS="$DISK_LIBS lib${module}.a"
+      DISK_LIBS="$DISK_LIBS lib${module}.la"
       DISK_MODULES="$DISK_MODULES ${module}"
       DISK_LINKOBJS="$DISK_LINKOBJS DiskIO/${module}/${module}DiskIOModule.o"
       ;;
@@ -755,11 +729,17 @@ done
 AC_MSG_NOTICE([IO Modules built: $DISK_MODULES])
 AC_SUBST(DISK_MODULES)
 AC_SUBST(DISK_LIBS)
-AC_SUBST(DISK_PROGRAMS)
 AC_SUBST(DISK_LINKOBJS)
-AC_SUBST(DISK_OS_LIBS)
-AM_CONDITIONAL([ENABLE_WIN32_AIOPS], [test "$ENABLE_WIN32_AIOPS" = "1"])
-AM_CONDITIONAL([ENABLE_WIN32_AIO], [test "$ENABLE_WIN32_AIO" = "1"])
+AM_CONDITIONAL([ENABLE_DISKIO_AIO], [test "x$squid_disk_module_candidates_AIO" = "xyes"])
+AC_SUBST(AIOLIB)
+AM_CONDITIONAL([ENABLE_WIN32_AIO], [test "x$squid_disk_module_candidates_AIO" = "xyes" -a "x$ENABLE_WIN32_AIO" = "x1"])
+AM_CONDITIONAL([ENABLE_DISKIO_BLOCKING], [test "x$squid_disk_module_candidates_Blocking" = "xyes"])
+AM_CONDITIONAL([ENABLE_DISKIO_DISKDAEMON], [test "x$squid_disk_module_candidates_DiskDaemon" = "xyes"])
+AM_CONDITIONAL([ENABLE_DISKIO_DISKTHREADS], [test "x$squid_disk_module_candidates_DiskThreads" = "xyes"])
+AC_SUBST(LIBPTHREADS)
+AM_CONDITIONAL([ENABLE_WIN32_AIOPS], [test "x$squid_disk_module_candidates_DiskThreads" = "xyes" -a "x$ENABLE_WIN32_AIOPS" = "x1"])
+AM_CONDITIONAL([ENABLE_DISKIO_IPCIO], [test "x$squid_disk_module_candidates_IpcIo" = "xyes"])
+AM_CONDITIONAL([ENABLE_DISKIO_MMAPPED], [test "x$squid_disk_module_candidates_Mmapped" = "xyes"])
 
 
 dnl Check what Storage formats are wanted.
@@ -1399,6 +1379,7 @@ case "$with_mit_krb5" in
     with_mit_krb5=yes
 esac
 ])
+AH_TEMPLATE(USE_APPLE_KRB5,[Apple Kerberos support is available])
 AH_TEMPLATE(USE_MIT_KRB5,[MIT Kerberos support is available])
 AH_TEMPLATE(USE_SOLARIS_KRB5,[Solaris Kerberos support is available])
 
@@ -1489,6 +1470,7 @@ elif test $ac_with_krb5_count -eq 0 ; then
       krb5confpath="`dirname $ac_cv_path_krb5_config`"
       ac_heimdal="`$ac_cv_path_krb5_config --version 2>/dev/null | grep -c -i heimdal`"
       ac_solaris="`$ac_cv_path_krb5_config --version 2>/dev/null | grep -c -i solaris`"
+      ac_apple="`$ac_cv_path_krb5_config --vendor 2>/dev/null | grep -c -i apple`"
       if test $ac_heimdal -gt 0 ; then
 	with_heimdal_krb5=yes
         ac_with_krb5_count=1
@@ -1497,7 +1479,11 @@ elif test $ac_with_krb5_count -eq 0 ; then
 	with_solaris_krb5=yes
         ac_with_krb5_count=1
       fi
-      if test $ac_heimdal -eq 0 && test $ac_solaris -eq 0 ; then
+      if test $ac_apple -gt 0 ; then
+	with_apple_krb5=yes
+        ac_with_krb5_count=1
+      fi
+      if test $ac_heimdal -eq 0 && test $ac_solaris -eq 0 && test $ac_apple -eq 0; then
 	with_mit_krb5=yes
         ac_with_krb5_count=1
       fi
@@ -1507,7 +1493,7 @@ elif test $ac_with_krb5_count -eq 0 ; then
   fi
 fi
 
-if test "x$with_mit_krb5" = "xyes"; then
+if test "x$with_mit_krb5" = "xyes" || test "x$with_apple_krb5" = "xyes" ; then
   SQUID_STATE_SAVE([squid_krb5_save])
   LIBS="$LIBS $LIB_KRB5_PATH"
 
@@ -1558,10 +1544,15 @@ if test "x$with_mit_krb5" = "xyes"; then
   ])
 
   if test "x$LIB_KRB5_LIBS" != "x"; then
+    if test "x$with_apple_krb5" = "xyes" ; then
+      AC_DEFINE(USE_APPLE_KRB5,1,[Apple Kerberos support is available])
+      KRB5_FLAVOUR="Apple" 
+    else
+      AC_DEFINE(USE_MIT_KRB5,1,[MIT Kerberos support is available])
+      KRB5_FLAVOUR="MIT" 
+    fi
     KRB5LIBS="$LIB_KRB5_PATH $LIB_KRB5_LIBS $KRB5LIBS"
     KRB5INCS="$LIB_KRB5_CFLAGS"
-    AC_DEFINE(USE_MIT_KRB5,1,[MIT Kerberos support is available])
-    KRB5_FLAVOUR="MIT" 
     
     # check for other specific broken implementations
     CXXFLAGS="$CXXFLAGS $KRB5INCS"
@@ -2950,9 +2941,10 @@ AC_CHECK_SIZEOF(size_t)
 AC_CHECK_SIZEOF(off_t)
 AC_CHECK_SIZEOF(size_t)
 
-dnl Some C++0x types we try to use
+dnl Some C++11 types we try to use
 AX_CXX_TYPE_NULLPTR
 AX_CXX_TYPE_UNIQUE_PTR
+AX_CXX_TYPE_UNIFORM_DISTRIBUTIONS
 
 dnl On Solaris 9 x86, gcc may includes a "fixed" set of old system include files
 dnl that is incompatible with the updated Solaris header files.
@@ -3326,7 +3318,6 @@ AC_CHECK_FUNCS(\
 	getspnam \
 	gettimeofday \
 	glob \
-	lrand48 \
 	mallocblksize \
 	mallopt \
 	memcpy \
@@ -3343,7 +3334,6 @@ AC_CHECK_FUNCS(\
 	pthread_setschedparam \
 	pthread_sigmask \
 	putenv \
-	random \
 	regcomp \
 	regexec \
 	regfree \
@@ -3360,16 +3350,13 @@ AC_CHECK_FUNCS(\
 	sigaction \
 	snprintf \
 	socketpair \
-	srand48 \
-	srandom \
 	sysconf \
 	syslog \
 	timegm \
 	vsnprintf \
 )
 dnl ... and some we provide local replacements for
 AC_REPLACE_FUNCS(\
-	drand48 \
 	initgroups \
 	psignal \
 	strerror \
@@ -3862,6 +3849,13 @@ AC_CONFIG_FILES([
 	src/clients/Makefile
 	src/comm/Makefile
 	src/dns/Makefile
+	src/DiskIO/Makefile
+	src/DiskIO/AIO/Makefile
+	src/DiskIO/Blocking/Makefile
+	src/DiskIO/DiskDaemon/Makefile
+	src/DiskIO/DiskThreads/Makefile
+	src/DiskIO/IpcIo/Makefile
+	src/DiskIO/Mmapped/Makefile
 	src/esi/Makefile
 	src/eui/Makefile
 	src/format/Makefile
@@ -3879,6 +3873,7 @@ AC_CONFIG_FILES([
 	src/mgr/Makefile
 	src/parser/Makefile
 	src/repl/Makefile
+	src/security/Makefile
 	src/servers/Makefile
 	src/snmp/Makefile
 	src/ssl/Makefile
@@ -107,7 +107,6 @@ section 56    HTTP Message Body
 section 57    HTTP Status-line
 section 58    HTTP Reply (Response)
 section 59    auto-growing Memory Buffer with printf
-section 60    Packer: A uniform interface to store-like modules
 section 61    Redirector
 section 62    Generic Histogram
 section 63    Low Level Memory Pool Management
@@ -5,9 +5,9 @@
 ## Please see the COPYING and CONTRIBUTORS files for details.
 ##
 
-all: release-3.6.html
+all: release-4.html
 
-DOC= release-3.6
+DOC= release-4
 
 $(DOC).ps: $(DOC).sgml
 	linuxdoc -B latex -o ps $(DOC)
@@ -1,6 +1,6 @@
 <!doctype linuxdoc system>
 <article>
-<title>Squid 3.2.13 release notes</title>
+<title>Squid 3.2.14 release notes</title>
 <author>Squid Developers</author>
 
 <abstract>
@@ -13,7 +13,7 @@ for Applied Network Research and members of the Web Caching community.
 
 <sect>Notice
 <p>
-The Squid Team are pleased to announce the release of Squid-3.2.13.
+The Squid Team are pleased to announce the release of Squid-3.2.14.
 
 This new release is available for download from <url url="http://www.squid-cache.org/Versions/v3/3.2/"> or the
  <url url="http://www.squid-cache.org/Download/http-mirrors.html" name="mirrors">.
@@ -1,6 +1,6 @@
 <!doctype linuxdoc system>
 <article>
-<title>Squid 3.3.13 release notes</title>
+<title>Squid 3.3.14 release notes</title>
 <author>Squid Developers</author>
 
 <abstract>
@@ -13,7 +13,7 @@ for Applied Network Research and members of the Web Caching community.
 
 <sect>Notice
 <p>
-The Squid Team are pleased to announce the release of Squid-3.3.13.
+The Squid Team are pleased to announce the release of Squid-3.3.14.
 
 This new release is available for download from <url url="http://www.squid-cache.org/Versions/v3/3.3/"> or the 
 <url url="http://www.squid-cache.org/Download/http-mirrors.html" name="mirrors">.
@@ -1,6 +1,6 @@
 <!doctype linuxdoc system>
 <article>
-<title>Squid 3.4.12 release notes</title>
+<title>Squid 3.4.13 release notes</title>
 <author>Squid Developers</author>
 
 <abstract>
@@ -13,7 +13,7 @@ for Applied Network Research and members of the Web Caching community.
 
 <sect>Notice
 <p>
-The Squid Team are pleased to announce the release of Squid-3.4.12.
+The Squid Team are pleased to announce the release of Squid-3.4.13.
 
 This new release is available for download from <url url="http://www.squid-cache.org/Versions/v3/3.4/"> or the
  <url url="http://www.squid-cache.org/Download/http-mirrors.html" name="mirrors">.
@@ -1,6 +1,6 @@
 <!doctype linuxdoc system>
 <article>
-<title>Squid 3.5.2 release notes</title>
+<title>Squid 3.5.6 release notes</title>
 <author>Squid Developers</author>
 
 <abstract>
@@ -13,7 +13,7 @@ for Applied Network Research and members of the Web Caching community.
 
 <sect>Notice
 <p>
-The Squid Team are pleased to announce the release of Squid-3.5.2.
+The Squid Team are pleased to announce the release of Squid-3.5.6.
 
 This new release is available for download from <url url="http://www.squid-cache.org/Versions/v3/3.5/"> or the
  <url url="http://www.squid-cache.org/Download/http-mirrors.html" name="mirrors">.
@@ -389,6 +389,9 @@ This section gives a thorough account of those changes in three categories:
 	   for the HTTP transaction so far.
 	<p>New type <em>at_step</em> to match the current SSL-Bump processing step.
 	   Never matches and should not be used outside of <em>ssl_bump</em>.
+	<p>New types <em>ssl::server_name</em> and <em>ssl::server_name_regex</em>
+	   to match server name from various sources (CONNECT authority name,
+	   TLS SNI domain, or X.509 certificate Subject Name).
 
 	<tag>auth_param</tag>
 	<p>New parameter <em>key_extras</em> to send additional parameters to
@@ -2,14 +2,14 @@
 <HTML>
 <HEAD>
  <META NAME="GENERATOR" CONTENT="LinuxDoc-Tools 0.9.69">
- <TITLE>Squid 3.6.0.0 release notes</TITLE>
+ <TITLE>Squid 4.0.0 release notes</TITLE>
 </HEAD>
 <BODY>
-<H1>Squid 3.6.0.0 release notes</H1>
+<H1>Squid 4.0.0 release notes</H1>
 
 <H2>Squid Developers</H2>
 <HR>
-<EM>This document contains the release notes for version 3.6 of Squid.
+<EM>This document contains the release notes for version 4 of Squid.
 Squid is a WWW Cache application developed by the National Laboratory
 for Applied Network Research and members of the Web Caching community.</EM>
 <HR>
@@ -18,13 +18,16 @@ <H2><A NAME="toc1">1.</A> <A HREF="#s1">Notice</A></H2>
 
 <UL>
 <LI><A NAME="toc1.1">1.1</A> <A HREF="#ss1.1">Known issues</A>
-<LI><A NAME="toc1.2">1.2</A> <A HREF="#ss1.2">Changes since earlier releases of Squid-3.6</A>
+<LI><A NAME="toc1.2">1.2</A> <A HREF="#ss1.2">Changes since earlier releases of Squid-4</A>
 </UL>
 <P>
 <H2><A NAME="toc2">2.</A> <A HREF="#s2">Major new features since Squid-3.5</A></H2>
 
 <UL>
 <LI><A NAME="toc2.1">2.1</A> <A HREF="#ss2.1">Configurable helper queue size</A>
+<LI><A NAME="toc2.2">2.2</A> <A HREF="#ss2.2">Helper concurrency channels changes</A>
+<LI><A NAME="toc2.3">2.3</A> <A HREF="#ss2.3">SSLv2 support removal</A>
+<LI><A NAME="toc2.4">2.4</A> <A HREF="#ss2.4">MSNT-multi-domain helper removal</A>
 </UL>
 <P>
 <H2><A NAME="toc3">3.</A> <A HREF="#s3">Changes to squid.conf since Squid-3.5</A></H2>
@@ -55,10 +58,10 @@ <H2><A NAME="toc6">6.</A> <A HREF="#s6">Copyright</A></H2>
 <HR>
 <H2><A NAME="s1">1.</A> <A HREF="#toc1">Notice</A></H2>
 
-<P>The Squid Team are pleased to announce the release of Squid-3.6.0.0 for testing.</P>
+<P>The Squid Team are pleased to announce the release of Squid-4.0.0 for testing.</P>
 <P>This new release is available for download from 
-<A HREF="http://www.squid-cache.org/Versions/v3/3.6/">http://www.squid-cache.org/Versions/v3/3.6/</A> or the
-<A HREF="http://www.squid-cache.org/Mirrors/http-mirrors.html">mirrors</A>.</P>
+<A HREF="http://www.squid-cache.org/Versions/v4/">http://www.squid-cache.org/Versions/v4/</A> or the
+<A HREF="http://www.squid-cache.org/Download/http-mirrors.html">mirrors</A>.</P>
 
 <P>While this release is not deemed ready for production use, we believe it is ready for wider testing by the community.</P>
 
@@ -70,22 +73,25 @@ <H2><A NAME="ss1.1">1.1</A> <A HREF="#toc1.1">Known issues</A>
 </H2>
 
 <P>Although this release is deemed good enough for use in many setups, please note the existence of 
-<A HREF="http://bugs.squid-cache.org/buglist.cgi?query_format=advanced&amp;product=Squid&amp;bug_status=UNCONFIRMED&amp;bug_status=NEW&amp;bug_status=ASSIGNED&amp;bug_status=REOPENED&amp;version=3.6">open bugs against Squid-3.6</A>.</P>
+<A HREF="http://bugs.squid-cache.org/buglist.cgi?query_format=advanced&amp;product=Squid&amp;bug_status=UNCONFIRMED&amp;bug_status=NEW&amp;bug_status=ASSIGNED&amp;bug_status=REOPENED&amp;version=4">open bugs against Squid-4</A>.</P>
 
-<H2><A NAME="ss1.2">1.2</A> <A HREF="#toc1.2">Changes since earlier releases of Squid-3.6</A>
+<H2><A NAME="ss1.2">1.2</A> <A HREF="#toc1.2">Changes since earlier releases of Squid-4</A>
 </H2>
 
-<P>The 3.6 change history can be 
-<A HREF="http://www.squid-cache.org/Versions/v3/3.6/changesets/">viewed here</A>.</P>
+<P>The Squid-4 change history can be 
+<A HREF="http://www.squid-cache.org/Versions/v4/changesets/">viewed here</A>.</P>
 
 
 <H2><A NAME="s2">2.</A> <A HREF="#toc2">Major new features since Squid-3.5</A></H2>
 
-<P>Squid 3.6 represents a new feature release above 3.5.</P>
+<P>Squid 4 represents a new feature release above 3.5.</P>
 
 <P>The most important of these new features are:
 <UL>
-<LI>BLAH</LI>
+<LI>Helper concurrency channels changes</LI>
+<LI>Configurable helper queue size</LI>
+<LI>SSLv2 support removal</LI>
+<LI>MSNT-multi-domain helper removal</LI>
 </UL>
 </P>
 <P>Most user-facing changes are reflected in squid.conf (see below).</P>
@@ -97,6 +103,43 @@ <H2><A NAME="ss2.1">2.1</A> <A HREF="#toc2.1">Configurable helper queue size</A>
 <P>The new queue-size=N option to helpers configuration, allows users 
 to configure the maximum number of queued requests to busy helpers.</P>
 
+<H2><A NAME="ss2.2">2.2</A> <A HREF="#toc2.2">Helper concurrency channels changes</A>
+</H2>
+
+<P> helper-mux.pl we have been distributing for the past few years to
+encourage use of concurrency is no longer compatible with Squid. If
+used it will spawn up to 2^64 helpers and DoS the Squid server.</P>
+
+<P> Helpers utilizing arrays to handle fixed amounts of concurrency
+channels MUST be re-written to use queues and capable of handling a
+64-bit int as index or they will be vulnerable to buffer overrun and
+arbitrary memory accesses.</P>
+
+<P> 32-bit helpers need re-writing to handle the concurrency channel ID
+as a 64-bit integer value. If not updated they will cause proxies to
+return unexpected results or timeout once crossing the 32-bit wrap
+boundary. Leading to undefined behaviour in the client HTTP traffic.</P>
+
+<H2><A NAME="ss2.3">2.3</A> <A HREF="#toc2.3">SSLv2 support removal</A>
+</H2>
+
+<P>Details in 
+<A HREF="https://tools.ietf.org/html/rfc6176">RFC 6176</A></P>
+
+<P>SSLv2 is not fit for purpose. Squid no longer supports being configured with
+any settings regarding this protocol. That includes settings manually disabling
+its use since it is now forced to disable by default. Also settings enabling
+various client/server workarounds specific to SSLv2 are removed.</P>
+
+
+<H2><A NAME="ss2.4">2.4</A> <A HREF="#toc2.4">MSNT-multi-domain helper removal</A>
+</H2>
+
+<P>The <EM>basic_msnt_multi_domain_auth</EM> helper has been removed. The
+<EM>basic_smb_lm_auth</EM> helper performs the same actions without extra
+Perl and Samba dependencies.</P>
+
+
 <H2><A NAME="s3">3.</A> <A HREF="#toc3">Changes to squid.conf since Squid-3.5</A></H2>
 
 <P>There have been changes to Squid's configuration file since Squid-3.5.</P>
@@ -118,6 +161,14 @@ <H2><A NAME="newtags"></A> <A NAME="ss3.1">3.1</A> <A HREF="#toc3.1">New tags</A
 
 <P>
 <DL>
+<DT><B>tls_outgoing_options</B><DD>
+<P>New tag to define TLS security context options for outgoing
+connections. For example to HTTPS servers.</P>
+
+<DT><B>url_rewrite_timeout</B><DD>
+<P>Squid times active requests to redirector. This option sets
+the timeout value and the Squid reaction to a timed out
+request.</P>
 
 </DL>
 </P>
@@ -127,29 +178,48 @@ <H2><A NAME="modifiedtags"></A> <A NAME="ss3.2">3.2</A> <A HREF="#toc3.2">Change
 
 <P>
 <DL>
-<DT><B> auth_param </B><DD>
-<P> New parameter <EM>queue-size=</EM> to set the maximum number
+<DT><B>auth_param</B><DD>
+<P>New parameter <EM>queue-size=</EM> to set the maximum number
 of queued requests.</P>
 
-<DT><B>external_acl_type</B><DD>
+<DT><B>cache_peer</B><DD>
+<P>All <EM>ssloption=</EM> and <EM>sslversion=</EM> values for
+SSLv2 configuration or disabling have been removed.</P>
+<P>Manual squid.conf update may be required on upgrade.</P>
 
-<DT><B></B><DD>
-<P> New parameter <EM>queue-size=</EM> to set the maximum number
+<DT><B>external_acl_type</B><DD>
+<P>New parameter <EM>queue-size=</EM> to set the maximum number
 of queued requests.</P>
 
-<DT><B>url_rewrite_children</B><DD>
+<DT><B>http_port</B><DD>
+<P>All <EM>version=</EM> <EM>option=</EM> values for SSLv2
+configuration or disabling have been removed.</P>
+<P>Manual squid.conf update may be required on upgrade.</P>
 
-<DT><B></B><DD>
-<P> New parameter <EM>queue-size=</EM> to set the maximum number
-of queued requests.</P>
+<DT><B>https_port</B><DD>
+<P>All <EM>version=</EM> <EM>option=</EM> values for SSLv2
+configuration or disabling have been removed.</P>
+<P>Manual squid.conf update may be required on upgrade.</P>
 
 <DT><B>sslcrtd_children</B><DD>
-<P> New parameter <EM>queue-size=</EM> to set the maximum number
+<P>New parameter <EM>queue-size=</EM> to set the maximum number
 of queued requests.</P>
 
 <DT><B>sslcrtvalidator_children</B><DD>
-<P> New parameter <EM>queue-size=</EM> to set the maximum number
+<P>New parameter <EM>queue-size=</EM> to set the maximum number
 of queued requests.</P>
+
+<DT><B>sslproxy_options</B><DD>
+<P>All values for SSLv2 configuration or disabling have been removed.</P>
+<P>Manual squid.conf update may be required on upgrade.</P>
+
+<DT><B>sslproxy_version</B><DD>
+<P>Value '2' for SSLv2-only operation is no longer supported.</P>
+
+<DT><B>url_rewrite_children</B><DD>
+<P>New parameter <EM>queue-size=</EM> to set the maximum number
+of queued requests.</P>
+
 </DL>
 </P>
 
@@ -158,6 +228,38 @@ <H2><A NAME="removedtags"></A> <A NAME="ss3.3">3.3</A> <A HREF="#toc3.3">Removed
 
 <P>
 <DL>
+<DT><B>cache_peer_domain</B><DD>
+<P>Superceded by <EM>cache_peer_access</EM>. Use dstdomain ACL
+in the access control list to restrict domains requested.</P>
+
+<DT><B>refresh_pattern</B><DD>
+<P>Option <EM>ignore-auth</EM> removed. Its original intent was
+to improve caching. HTTP/1.1 permits caching of authenticated
+messages under conditions which Squid does check for and obey.</P>
+
+<DT><B>sslproxy_cafile</B><DD>
+<P>Replaced by <EM>tls_outgoing_options cafile=</EM>.</P>
+
+<DT><B>sslproxy_capath</B><DD>
+<P>Replaced by <EM>tls_outgoing_options capath=</EM>.</P>
+
+<DT><B>sslproxy_cipher</B><DD>
+<P>Replaced by <EM>tls_outgoing_options cipher=</EM>.</P>
+
+<DT><B>sslproxy_client_certificate</B><DD>
+<P>Replaced by <EM>tls_outgoing_options cert=</EM>.</P>
+
+<DT><B>sslproxy_client_key</B><DD>
+<P>Replaced by <EM>tls_outgoing_options key=</EM>.</P>
+
+<DT><B>sslproxy_flags</B><DD>
+<P>Replaced by <EM>tls_outgoing_options flags=</EM>.</P>
+
+<DT><B>sslproxy_options</B><DD>
+<P>Replaced by <EM>tls_outgoing_options options=</EM>.</P>
+
+<DT><B>sslproxy_version</B><DD>
+<P>Replaced by <EM>tls_outgoing_options version=</EM>.</P>
 
 </DL>
 </P>
@@ -193,6 +295,8 @@ <H2><A NAME="modifiedoptions"></A> <A NAME="ss4.2">4.2</A> <A HREF="#toc4.2">Cha
 
 <P>
 <DL>
+<DT><B>--enable-auth-basic</B><DD>
+<P>The <EM>MSNT-multi-domain</EM> helper has been removed.</P>
 
 </DL>
 </P>
@@ -208,7 +312,7 @@ <H2><A NAME="removedoptions"></A> <A NAME="ss4.3">4.3</A> <A HREF="#toc4.3">Remo
 
 <H2><A NAME="s5">5.</A> <A HREF="#toc5">Regressions since Squid-2.7</A></H2>
 
-<P>Some squid.conf options which were available in Squid-2.7 are not yet available in Squid-3.6</P>
+<P>Some squid.conf options which were available in Squid-2.7 are not yet available in Squid-4</P>
 
 <P>If you need something to do then porting one of these from Squid-2 to Squid-3 is most welcome.</P>
 
@@ -1,10 +1,10 @@
 <!doctype linuxdoc system>
 <article>
-<title>Squid 3.6.0.0 release notes</title>
+<title>Squid 4.0.0 release notes</title>
 <author>Squid Developers</author>
 
 <abstract>
-This document contains the release notes for version 3.6 of Squid.
+This document contains the release notes for version 4 of Squid.
 Squid is a WWW Cache application developed by the National Laboratory
 for Applied Network Research and members of the Web Caching community.
 </abstract>
@@ -13,9 +13,9 @@ for Applied Network Research and members of the Web Caching community.
 
 <sect>Notice
 <p>
-The Squid Team are pleased to announce the release of Squid-3.6.0.0 for testing.
+The Squid Team are pleased to announce the release of Squid-4.0.0 for testing.
 
-This new release is available for download from <url url="http://www.squid-cache.org/Versions/v3/3.6/"> or the
+This new release is available for download from <url url="http://www.squid-cache.org/Versions/v4/"> or the
  <url url="http://www.squid-cache.org/Download/http-mirrors.html" name="mirrors">.
 
 <p>While this release is not deemed ready for production use, we believe it is ready for wider testing by the community.
@@ -26,21 +26,21 @@ This new release is available for download from <url url="http://www.squid-cache
 <sect1>Known issues
 <p>
 Although this release is deemed good enough for use in many setups, please note the existence of 
-<url url="http://bugs.squid-cache.org/buglist.cgi?query_format=advanced&amp;product=Squid&amp;bug_status=UNCONFIRMED&amp;bug_status=NEW&amp;bug_status=ASSIGNED&amp;bug_status=REOPENED&amp;version=3.6" name="open bugs against Squid-3.6">.
+<url url="http://bugs.squid-cache.org/buglist.cgi?query_format=advanced&amp;product=Squid&amp;bug_status=UNCONFIRMED&amp;bug_status=NEW&amp;bug_status=ASSIGNED&amp;bug_status=REOPENED&amp;version=4" name="open bugs against Squid-4">.
 
-<sect1>Changes since earlier releases of Squid-3.6
+<sect1>Changes since earlier releases of Squid-4
 <p>
-The 3.6 change history can be <url url="http://www.squid-cache.org/Versions/v3/3.6/changesets/" name="viewed here">.
+The Squid-4 change history can be <url url="http://www.squid-cache.org/Versions/v4/changesets/" name="viewed here">.
 
 
 <sect>Major new features since Squid-3.5
-<p>Squid 3.6 represents a new feature release above 3.5.
+<p>Squid 4 represents a new feature release above 3.5.
 
 <p>The most important of these new features are:
 <itemize>
 	<item>Helper concurrency channels changes
 	<item>Configurable helper queue size
-	<item>SSLv2 support removal
+	<item>SSL support removal
 	<item>MSNT-multi-domain helper removal
 </itemize>
 
@@ -66,14 +66,20 @@ to configure the maximum number of queued requests to busy helpers.
     return unexpected results or timeout once crossing the 32-bit wrap
     boundary. Leading to undefined behaviour in the client HTTP traffic.
 
-<sect1>SSLv2 support removal
+<sect1>SSL support removal
 <p>Details in <url url="https://tools.ietf.org/html/rfc6176" name="RFC 6176">
+   and <url url="https://tools.ietf.org/html/rfc7568" name="RFC 7568">
 
 <p>SSLv2 is not fit for purpose. Squid no longer supports being configured with
 any settings regarding this protocol. That includes settings manually disabling
 its use since it is now forced to disable by default. Also settings enabling
 various client/server workarounds specific to SSLv2 are removed.
 
+<p>SSLv3 is not fit for purpose. Squid still accepts configuration, but use
+is deprecated and will be removed entirely in a future version.
+Squid default behavour is to follow the TLS built in negotiation mechanism
+which prefers the latest TLS version.
+
 
 <sect1>MSNT-multi-domain helper removal
 
@@ -98,6 +104,10 @@ This section gives a thorough account of those changes in three categories:
 <sect1>New tags<label id="newtags">
 <p>
 <descrip>
+	<tag>tls_outgoing_options</tag>
+	<p>New tag to define TLS security context options for outgoing
+	   connections. For example to HTTPS servers.
+
 	<tag>url_rewrite_timeout</tag>
 	<p>Squid times active requests to redirector. This option sets
 	   the timeout value and the Squid reaction to a timed out
@@ -113,24 +123,42 @@ This section gives a thorough account of those changes in three categories:
 	   of queued requests.
 
 	<tag>cache_peer</tag>
-	<p>All <em>ssloption=</em> and <em>sslversion=</em> values for
-	   SSLv2 configuration or disabling have been removed.
+	<p>New option <em>tls-min-version=1.N</em> to set minimum TLS version allowed.
+	<p>All <em>ssloptions=</em> values for SSLv2 configuration or disabling
+	   have been removed.
+	<p>Removed <em>sslversion=</em> option. Use <em>tls-options=</em> instead.
 	<p>Manual squid.conf update may be required on upgrade.
 
-	<tag>external_acl_type<tag>
+	<tag>external_acl_type</tag>
 	<p>New parameter <em>queue-size=</em> to set the maximum number
 	   of queued requests.
 
 	<tag>http_port</tag>
-	<p>All <em>version=</em> <em>option=</em> values for SSLv2
-	   configuration or disabling have been removed.
+	<p>New option <em>tls-min-version=1.N</em> to set minimum TLS version allowed.
+	<p>All <em>option=</em> values for SSLv2 configuration or disabling
+	   have been removed.
+	<p>Removed <em>version=</em> option. Use <em>tls-options=</em> instead.
 	<p>Manual squid.conf update may be required on upgrade.
 
 	<tag>https_port</tag>
-	<p>All <em>version=</em> <em>option=</em> values for SSLv2
+	<p>New option <em>tls-min-version=1.N</em> to set minimum TLS version allowed.
+	<p>All <em>options=</em> values for SSLv2
 	   configuration or disabling have been removed.
+	<p>Removed <em>version=</em> option. Use <em>tls-options=</em> instead.
+	<p>New <em>options=SINGLE_ECDH_USE</em> parameter to enable ephemeral
+	   ECDH key exchange.
+	<p>Deprecated <em>dhparams=</em> option. Use <em>tls-dh=</em> instead.
+	   The new option allows to optionally specify an elliptic curve for
+	   ephemeral ECDH by adding <em>curve-name:</em> in front of the
+	   parameter file name.
 	<p>Manual squid.conf update may be required on upgrade.
 
+	<tag>refresh_pattern</tag>
+	<p>Removed <em>ignore-auth</em>. Its commonly desired behaviour is
+	   performed by default with correct HTTP/1.1 revalidation.
+	<p>Removed <em>ignore-must-revalidate</em>. Other more HTTP compliant
+	   directives can be used to prevent objects from caching.
+
 	<tag>sslcrtd_children</tag>
 	<p>New parameter <em>queue-size=</em> to set the maximum number
 	   of queued requests.
@@ -139,14 +167,7 @@ This section gives a thorough account of those changes in three categories:
 	<p>New parameter <em>queue-size=</em> to set the maximum number
 	   of queued requests.
 
-	<tag>sslproxy_options</tag>
-	<p>All values for SSLv2 configuration or disabling have been removed.
-	<p>Manual squid.conf update may be required on upgrade.
-
-	<tag>sslproxy_version</tag>
-	<p>Value '2' for SSLv2-only operation is no longer supported.
-
-	<tag>url_rewrite_children<tag>
+	<tag>url_rewrite_children</tag>
 	<p>New parameter <em>queue-size=</em> to set the maximum number
 	   of queued requests.
 
@@ -164,6 +185,34 @@ This section gives a thorough account of those changes in three categories:
 	   to improve caching. HTTP/1.1 permits caching of authenticated
 	   messages under conditions which Squid does check for and obey.
 
+	<tag>sslproxy_cafile</tag>
+	<p>Replaced by <em>tls_outgoing_options cafile=</em>.
+
+	<tag>sslproxy_capath</tag>
+	<p>Replaced by <em>tls_outgoing_options capath=</em>.
+
+	<tag>sslproxy_cipher</tag>
+	<p>Replaced by <em>tls_outgoing_options cipher=</em>.
+
+	<tag>sslproxy_client_certificate</tag>
+	<p>Replaced by <em>tls_outgoing_options cert=</em>.
+
+	<tag>sslproxy_client_key</tag>
+	<p>Replaced by <em>tls_outgoing_options key=</em>.
+
+	<tag>sslproxy_flags</tag>
+	<p>Replaced by <em>tls_outgoing_options flags=</em>.
+
+	<tag>sslproxy_options</tag>
+	<p>Replaced by <em>tls_outgoing_options options=</em>.
+	<p>All values for SSLv2 configuration or disabling have been removed.
+	<p>Manual squid.conf update may be required on upgrade.
+
+	<tag>sslproxy_version</tag>
+	<p>Replaced by <em>tls_outgoing_options options=</em>.
+	<p>All values for SSLv2 configuration or disabling have been removed.
+	<p>Manual squid.conf update may be required on upgrade.
+
 </descrip>
 
 
@@ -204,7 +253,7 @@ This section gives an account of those changes in three categories:
 
 <sect>Regressions since Squid-2.7
 
-<p>Some squid.conf options which were available in Squid-2.7 are not yet available in Squid-3.6
+<p>Some squid.conf options which were available in Squid-2.7 are not yet available in Squid-4
 
 <p>If you need something to do then porting one of these from Squid-2 to Squid-3 is most welcome.
 
@@ -197,10 +197,16 @@ rfc7234.txt
 rfc7235.txt
 	Hypertext Transfer Protocol (HTTP/1.1): Authentication
 
-rfc7238.txt
-	The Hypertext Transfer Protocol Status Code 308 (Permanent Redirect)
-
 rfc7239.txt
 	Forwarded HTTP Extension
 	Details the Forwarded: header replacement for X-Forwarded-For
 	and other X-Forwarded-* variants
+
+rfc7538.txt
+	The Hypertext Transfer Protocol Status Code 308 (Permanent Redirect)
+
+rfc7540.txt
+	Hypertext Transfer Protocol Version 2 (HTTP/2)
+	The PRI method, the 421 status code, and the HTTP2-Settings header
+	semantics and syntax for HTTP/1.x messages.
+	Details binary frame syntax and semantics for concurrent messaging.
@@ -5,8 +5,9 @@
 
 
 Internet Engineering Task Force (IETF)                        J. Reschke
-Request for Comments: 7238                                    greenbytes
-Category: Experimental                                         June 2014
+Request for Comments: 7538                                    greenbytes
+Obsoletes: 7238                                               April 2015
+Category: Standards Track
 ISSN: 2070-1721
 
 
@@ -19,25 +20,21 @@ Abstract
 
 Status of This Memo
 
-   This document is not an Internet Standards Track specification; it is
-   published for examination, experimental implementation, and
-   evaluation.
+   This is an Internet Standards Track document.
 
-   This document defines an Experimental Protocol for the Internet
-   community.  This document is a product of the Internet Engineering
-   Task Force (IETF).  It represents the consensus of the IETF
-   community.  It has received public review and has been approved for
-   publication by the Internet Engineering Steering Group (IESG).  Not
-   all documents approved by the IESG are a candidate for any level of
-   Internet Standard; see Section 2 of RFC 5741.
+   This document is a product of the Internet Engineering Task Force
+   (IETF).  It represents the consensus of the IETF community.  It has
+   received public review and has been approved for publication by the
+   Internet Engineering Steering Group (IESG).  Further information on
+   Internet Standards is available in Section 2 of RFC 5741.
 
    Information about the current status of this document, any errata,
    and how to provide feedback on it may be obtained at
-   http://www.rfc-editor.org/info/rfc7238.
+   http://www.rfc-editor.org/info/rfc7538.
 
 Copyright Notice
 
-   Copyright (c) 2014 IETF Trust and the persons identified as the
+   Copyright (c) 2015 IETF Trust and the persons identified as the
    document authors.  All rights reserved.
 
    This document is subject to BCP 78 and the IETF Trust's Legal
@@ -55,23 +52,27 @@ Copyright Notice
 
 
 
-Reschke                       Experimental                      [Page 1]
+
+
+
+Reschke                      Standards Track                    [Page 1]
 
-RFC 7238                  HTTP Status Code 308                 June 2014
+RFC 7538                  HTTP Status Code 308                April 2015
 
 
 Table of Contents
 
-   1.  Introduction  . . . . . . . . . . . . . . . . . . . . . . . . . 2
-   2.  Notational Conventions  . . . . . . . . . . . . . . . . . . . . 2
-   3.  308 Permanent Redirect  . . . . . . . . . . . . . . . . . . . . 2
-   4.  Deployment Considerations . . . . . . . . . . . . . . . . . . . 3
-   5.  Security Considerations . . . . . . . . . . . . . . . . . . . . 4
-   6.  IANA Considerations . . . . . . . . . . . . . . . . . . . . . . 4
-   7.  Acknowledgements  . . . . . . . . . . . . . . . . . . . . . . . 5
-   8.  References  . . . . . . . . . . . . . . . . . . . . . . . . . . 5
-     8.1.  Normative References  . . . . . . . . . . . . . . . . . . . 5
-     8.2.  Informative References  . . . . . . . . . . . . . . . . . . 5
+   1.  Introduction  . . . . . . . . . . . . . . . . . . . . . . . .   2
+   2.  Notational Conventions  . . . . . . . . . . . . . . . . . . .   2
+   3.  308 Permanent Redirect  . . . . . . . . . . . . . . . . . . .   3
+   4.  Deployment Considerations . . . . . . . . . . . . . . . . . .   3
+   5.  Security Considerations . . . . . . . . . . . . . . . . . . .   4
+   6.  IANA Considerations . . . . . . . . . . . . . . . . . . . . .   5
+   7.  References  . . . . . . . . . . . . . . . . . . . . . . . . .   5
+     7.1.  Normative References  . . . . . . . . . . . . . . . . . .   5
+     7.2.  Informative References  . . . . . . . . . . . . . . . . .   5
+   Acknowledgements  . . . . . . . . . . . . . . . . . . . . . . . .   6
+   Author's Address  . . . . . . . . . . . . . . . . . . . . . . . .   6
 
 1.  Introduction
 
@@ -93,29 +94,33 @@ Table of Contents
    | method from POST to GET                   |           |           |
    +-------------------------------------------+-----------+-----------+
 
-   Section 6.4.7 of [RFC7231] states that HTTP does not define a
-   permanent variant of status code 307; this specification adds the
-   status code 308, defining this missing variant (Section 3).
+   Section 6.4.7 of [RFC7231] states that it does not define a permanent
+   variant of status code 307; this specification adds the status code
+   308, defining this missing variant (Section 3).
+
+   This specification contains no technical changes from the
+   Experimental RFC 7238, which it obsoletes.
 
 2.  Notational Conventions
 
    The key words "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT",
    "SHOULD", "SHOULD NOT", "RECOMMENDED", "MAY", and "OPTIONAL" in this
    document are to be interpreted as described in [RFC2119].
 
-3.  308 Permanent Redirect
 
-   The 308 (Permanent Redirect) status code indicates that the target
-   resource has been assigned a new permanent URI and any future
-   references to this resource ought to use one of the enclosed URIs.
 
 
 
-Reschke                       Experimental                      [Page 2]
+Reschke                      Standards Track                    [Page 2]
 
-RFC 7238                  HTTP Status Code 308                 June 2014
+RFC 7538                  HTTP Status Code 308                April 2015
+
 
+3.  308 Permanent Redirect
 
+   The 308 (Permanent Redirect) status code indicates that the target
+   resource has been assigned a new permanent URI and any future
+   references to this resource ought to use one of the enclosed URIs.
    Clients with link editing capabilities ought to automatically re-link
    references to the effective request URI (Section 5.5 of [RFC7230]) to
    one or more of the new references sent by the server, where possible.
@@ -138,49 +143,54 @@ RFC 7238                  HTTP Status Code 308                 June 2014
 4.  Deployment Considerations
 
    Section 6 of [RFC7231] requires recipients to treat unknown 3xx
-   status codes the same way as status code 300 Multiple Choices
+   status codes the same way as status code 300 (Multiple Choices)
    ([RFC7231], Section 6.4.1).  Thus, servers will not be able to rely
    on automatic redirection happening similar to status codes 301, 302,
    or 307.
 
-   Therefore, initial use of status code 308 will be restricted to cases
-   where the server has sufficient confidence in the client's
-   understanding the new code or when a fallback to the semantics of
-   status code 300 is not problematic.  Server implementers are advised
-   not to vary the status code based on characteristics of the request,
-   such as the User-Agent header field ("User-Agent Sniffing") -- doing
-   so usually results in code that is both hard to maintain and hard to
-   debug and would also require special attention to caching (i.e.,
-   setting a "Vary" response header field, as defined in Section 7.1.4
-   of [RFC7231]).
+   Therefore, the use of status code 308 is restricted to cases where
+   the server has sufficient confidence in the client's understanding
+   the new code or when a fallback to the semantics of status code 300
+   is not problematic.  Server implementers are advised not to vary the
+   status code based on characteristics of the request, such as the
+   User-Agent header field ("User-Agent Sniffing") -- doing so usually
+   results in code that is both hard to maintain and hard to debug and
+   would also require special attention to caching (i.e., setting a
+   "Vary" response header field, as defined in Section 7.1.4 of
+   [RFC7231]).
 
-   Note that many existing HTML-based user agents will emulate a refresh
-   when encountering an HTML <meta> refresh directive ([HTML]).  This
-   can be used as another fallback.  For example:
 
-   Client request:
 
-     GET / HTTP/1.1
-     Host: example.com
 
 
 
 
 
-Reschke                       Experimental                      [Page 3]
+
+Reschke                      Standards Track                    [Page 3]
 
-RFC 7238                  HTTP Status Code 308                 June 2014
+RFC 7538                  HTTP Status Code 308                April 2015
+
+
+   Note that many existing HTML-based user agents will emulate a refresh
+   when encountering an HTML <meta> refresh directive ([HTML],
+   Section 4.2.5.3).  This can be used as another fallback.  For
+   example:
+
+   Client request:
+
+     GET / HTTP/1.1
+     Host: example.com
 
 
    Server response:
 
      HTTP/1.1 308 Permanent Redirect
      Content-Type: text/html; charset=UTF-8
      Location: http://example.com/new
-     Content-Length: 454
+     Content-Length: 356
 
-     <!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
-                           "http://www.w3.org/TR/html4/strict.dtd">
+     <!DOCTYPE HTML>
      <html>
         <head>
            <title>Permanent Redirect</title>
@@ -201,88 +211,88 @@ RFC 7238                  HTTP Status Code 308                 June 2014
    All security considerations that apply to HTTP redirects apply to the
    308 status code as well (see Section 9 of [RFC7231]).
 
-6.  IANA Considerations
-
-   The registration below has been added to the "Hypertext Transfer
-   Protocol (HTTP) Status Code Registry" (defined in Section 8.2 of
-   [RFC7231] and located at
-   <http://www.iana.org/assignments/http-status-codes>):
-
-   +-------+--------------------+---------------------------------+
-   | Value | Description        | Reference                       |
-   +-------+--------------------+---------------------------------+
-   | 308   | Permanent Redirect | Section 3 of this specification |
-   +-------+--------------------+---------------------------------+
-
+   Unsecured communication over the Internet is subject to man-in-the-
+   middle modification of messages, including changing status codes or
+   redirect targets.  Use of Transport Layer Security (TLS) is one way
+   to mitigate those attacks.  See Section 9 of [RFC7230] for related
+   attacks on authority and message integrity.
 
 
 
 
 
 
 
-
-
-Reschke                       Experimental                      [Page 4]
+Reschke                      Standards Track                    [Page 4]
 
-RFC 7238                  HTTP Status Code 308                 June 2014
+RFC 7538                  HTTP Status Code 308                April 2015
 
 
-7.  Acknowledgements
+6.  IANA Considerations
 
-   The definition for the new status code 308 reuses text from the
-   HTTP/1.1 definitions of status codes 301 and 307.
+   The "Hypertext Transfer Protocol (HTTP) Status Code Registry"
+   (defined in Section 8.2 of [RFC7231] and located at
+   <http://www.iana.org/assignments/http-status-codes>) has been updated
+   to reference this specification.
 
-   Furthermore, thanks to Ben Campbell, Cyrus Daboo, Eran Hammer-Lahav,
-   Bjoern Hoehrmann, Subramanian Moonesamy, Peter Saint-Andre, and
-   Robert Sparks for feedback on this document.
+   +-------+--------------------+----------------------------------+
+   | Value | Description        | Reference                        |
+   +-------+--------------------+----------------------------------+
+   | 308   | Permanent Redirect | Section 3 of this specification  |
+   +-------+--------------------+----------------------------------+
 
-8.  References
+7.  References
 
-8.1.  Normative References
+7.1.  Normative References
 
    [RFC2119]  Bradner, S., "Key words for use in RFCs to Indicate
-              Requirement Levels", BCP 14, RFC 2119, March 1997.
+              Requirement Levels", BCP 14, RFC 2119, March 1997,
+              <http://www.rfc-editor.org/info/rfc2119>.
 
    [RFC3986]  Berners-Lee, T., Fielding, R., and L. Masinter, "Uniform
-              Resource Identifier (URI): Generic Syntax", STD 66,
-              RFC 3986, January 2005.
+              Resource Identifier (URI): Generic Syntax", STD 66, RFC
+              3986, January 2005,
+              <http://www.rfc-editor.org/info/rfc3986>.
 
    [RFC7230]  Fielding, R., Ed. and J. Reschke, Ed., "Hypertext Transfer
-              Protocol (HTTP/1.1): Message Syntax and Routing",
-              RFC 7230, June 2014.
+              Protocol (HTTP/1.1): Message Syntax and Routing", RFC
+              7230, June 2014, <http://www.rfc-editor.org/info/rfc7230>.
 
    [RFC7231]  Fielding, R., Ed. and J. Reschke, Ed., "Hypertext Transfer
               Protocol (HTTP/1.1): Semantics and Content", RFC 7231,
-              June 2014.
+              June 2014, <http://www.rfc-editor.org/info/rfc7231>.
 
    [RFC7234]  Fielding, R., Ed., Nottingham, M., Ed., and J. Reschke,
               Ed., "Hypertext Transfer Protocol (HTTP/1.1): Caching",
-              RFC 7234, June 2014.
-
-8.2.  Informative References
-
-   [HTML]     Raggett, D., Le Hors, A., and I. Jacobs, "HTML 4.01
-              Specification", W3C Recommendation REC-html401-19991224,
-              December 1999,
-              <http://www.w3.org/TR/1999/REC-html401-19991224>.
-
-              Latest version available at
-              <http://www.w3.org/TR/html401>.
+              RFC 7234, June 2014,
+              <http://www.rfc-editor.org/info/rfc7234>.
 
+7.2.  Informative References
 
+   [HTML]     Hickson, I., Berjon, R., Faulkner, S., Leithead, T., Doyle
+              Navara, E., O'Connor, E., and S. Pfeiffer, "HTML5", W3C
+              Recommendation REC-html5-20141028, October 2014,
+              <http://www.w3.org/TR/2014/REC-html5-20141028/>.
 
+              Latest version available at <http://www.w3.org/TR/html5/>.
 
 
 
 
+Reschke                      Standards Track                    [Page 5]
+
+RFC 7538                  HTTP Status Code 308                April 2015
 
 
+Acknowledgements
 
-Reschke                       Experimental                      [Page 5]
-
-RFC 7238                  HTTP Status Code 308                 June 2014
+   The definition for the new status code 308 reuses text from the
+   HTTP/1.1 definitions of status codes 301 and 307.
 
+   Furthermore, thanks to Ben Campbell, Cyrus Daboo, Adrian Farrell,
+   Eran Hammer-Lahav, Bjoern Hoehrmann, Barry Leiba, Subramanian
+   Moonesamy, Kathleen Moriarty, Peter Saint-Andre, Robert Sparks, and
+   Roy Fielding for feedback on this document.
 
 Author's Address
 
@@ -325,15 +335,5 @@ Author's Address
 
 
 
-
-
-
-
-
-
-
-
-
-
-Reschke                       Experimental                      [Page 6]
+Reschke                      Standards Track                    [Page 6]
 
@@ -1,34 +1,10 @@
 ==============================================================================
 
-SQUID Internet Object Cache  http://www.squid-cache.org
---------------------------------------------------------
-
-  Squid is the result of efforts by numerous individuals from the
-  Internet community.  Development is led by Duane Wessels of the
-  National Laboratory for Applied Network Research and funded by
-  the National Science Foundation.
-
-  This program is free software; you can redistribute it and/or modify
-  it under the terms of the GNU General Public License as published by
-  the Free Software Foundation; either version 2 of the License, or
-  (at your option) any later version.
-
-  This program is distributed in the hope that it will be useful,
-  but WITHOUT ANY WARRANTY; without even the implied warranty of
-  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-  GNU General Public License for more details.
-
-  You should have received a copy of the GNU General Public License
-  along with this program; if not, write to the Free Software
-  Foundation, Inc., 51 Franklin St, Fifth Floor, Boston,
-  MA 02110-1301, USA.
-
-Squid is derived from the ``cached'' software from the ARPA-funded
-Harvest research project.  The Harvest home page is
-http://harvest.cs.colorado.edu/.
-
-Squid is originally derived from the Harvest Information Discovery and
-Access System.
+ * Copyright (C) 1996-2015 The Squid Software Foundation and contributors
+ *
+ * Squid software is distributed under GPLv2+ license and includes
+ * contributions from numerous individuals and organizations.
+ * Please see the COPYING and CONTRIBUTORS files for details.
 
 ==============================================================================
 
@@ -13,7 +13,7 @@ da	da-dk
 de	de-at de-ch de-de de-li de-lu
 el	el-gr
 en	en-au en-bz en-ca en-gb en-ie en-in en-jm en-nz en-ph en-sg en-tt en-uk en-us en-za en-zw
-es	es-ar es-bo es-cl es-co es-cr es-do es-ec es-es es-gt es-hn es-mx es-ni es-pa es-pe es-pr es-py es-sv es-uy es-ve
+es	es-ar es-bo es-cl es-co es-cr es-do es-ec es-es es-gt es-hn es-mx es-ni es-pa es-pe es-pr es-py es-sv es-us es-uy es-ve
 et	et-ee
 fa	fa-fa fa-ir
 fi	fi-fi
@@ -31,7 +31,7 @@ html body {
 	margin-left: 15px;
 	padding: 10px;
 	padding-left: 100px;
-	background: url('http://www.squid-cache.org/Artwork/SN.png') no-repeat left;
+	background: url('/squid-internal-static/icons/SN.png') no-repeat left;
 }
 
 /* initial title */
@@ -7,17 +7,21 @@
 include $(top_srcdir)/src/Common.am
 
 libexec_SCRIPTS	= basic_db_auth
-man_MANS = basic_db_auth.8
+CLEANFILES += basic_db_auth
 EXTRA_DIST= \
-	basic_db_auth.8 \
 	passwd.sql \
 	basic_db_auth.pl.in \
 	required.m4
 
-basic_db_auth.8: basic_db_auth
-	pod2man basic_db_auth basic_db_auth.8
-
 basic_db_auth: basic_db_auth.pl.in
 	$(subst_perlshell)
 
-CLEANFILES += basic_db_auth basic_db_auth.8
+if ENABLE_POD2MAN_DOC
+man_MANS = basic_db_auth.8
+CLEANFILES += basic_db_auth.8
+EXTRA_DIST += basic_db_auth.8
+
+basic_db_auth.8: basic_db_auth
+	pod2man --section=8 basic_db_auth basic_db_auth.8
+
+endif
@@ -5,6 +5,10 @@
 ## Please see the COPYING and CONTRIBUTORS files for details.
 ##
 
-if test "x$PERL" != "x" -a "x$POD2MAN" != "x"; then
+if test "x$PERL" != "x"; then
   BUILD_HELPER="DB"
 fi
+if test "x$POD2MAN" = "x"; then
+  AC_MSG_WARN([pod2man not found. basic_db_auth man(8) page will not be built])
+fi
+
@@ -8,16 +8,20 @@
 include $(top_srcdir)/src/Common.am
 
 libexec_SCRIPTS	= basic_pop3_auth
-man_MANS= basic_pop3_auth.8
+CLEANFILES += basic_pop3_auth
 EXTRA_DIST= \
-	basic_pop3_auth.8 \
 	basic_pop3_auth.pl.in \
 	required.m4
 
 basic_pop3_auth: basic_pop3_auth.pl.in
 	$(subst_perlshell)
 
+if ENABLE_POD2MAN_DOC
+man_MANS = basic_pop3_auth.8
+CLEANFILES += basic_pop3_auth.8
+EXTRA_DIST += basic_pop3_auth.8
+
 basic_pop3_auth.8: basic_pop3_auth
-	pod2man basic_pop3_auth basic_pop3_auth.8
+	pod2man --section=8 basic_pop3_auth basic_pop3_auth.8
 
-CLEANFILES += basic_pop3_auth basic_pop3_auth.8
+endif
@@ -5,6 +5,10 @@
 ## Please see the COPYING and CONTRIBUTORS files for details.
 ##
 
-if test "x$PERL" != "x" -a "x$POD2MAN" != "x"; then
+if test "x$PERL" != "x"; then
   BUILD_HELPER="POP3"
 fi
+if test "x$POD2MAN" = "x"; then
+  AC_MSG_WARN([pod2man not found. basic_pop3_auth man(8) page will not be built])
+fi
+
@@ -63,6 +63,7 @@
 #include <cerrno>
 #include <cstring>
 #include <ctime>
+#include <random>
 #if HAVE_SYS_SOCKET_H
 #include <sys/socket.h>
 #endif
@@ -205,16 +206,11 @@ result_recv(char *buffer, int length)
 static void
 random_vector(char *aVector)
 {
-    int randno;
-    int i;
-
-    srand((time(0) ^ rand()) + rand());
-    for (i = 0; i < AUTH_VECTOR_LEN;) {
-        randno = rand();
-        memcpy(aVector, &randno, sizeof(int));
-        aVector += sizeof(int);
-        i += sizeof(int);
-    }
+    static std::mt19937 mt(time(0));
+    static std::uniform_int_distribution<uint8_t> dist;
+
+    for (int i = 0; i < AUTH_VECTOR_LEN; ++i)
+        aVector[i] = static_cast<char>(dist(mt) & 0xFF);
 }
 
 /* read the config file
@@ -99,7 +99,7 @@ main(int argc, char *argv[])
 
     process_options(argc, argv);
 
-    debug("%s build " __DATE__ ", " __TIME__ " starting up...\n", program_name);
+    debug("%s " VERSION " " SQUID_BUILD_INFO " starting up...\n", program_name);
 
     while (fgets(buf, HELPER_INPUT_BUFFER, stdin) != NULL) {
         char *p;
@@ -115,7 +115,7 @@ main(int argc, char *argv[])
         /* send 'OK' result back to Squid */
         SEND_OK("");
     }
-    debug("%s build " __DATE__ ", " __TIME__ " shutting down...\n", program_name);
+    debug("%s " VERSION " " SQUID_BUILD_INFO " shutting down...\n", program_name);
     exit(0);
 }
 
@@ -19,8 +19,10 @@ if test "x$enable_auth_basic" != "xno" -a "x$enable_auth" = "xno" ; then
     AC_MSG_ERROR([Basic auth requested but auth disabled])
 fi
 #define list of modules to build
+auto_auth_basic_modules=no
 if test "x$enable_auth_basic" = "xyes" ; then
     SQUID_LOOK_FOR_MODULES([$srcdir/helpers/basic_auth],[enable_auth_basic])
+  auto_auth_basic_modules=yes
 fi
 #handle the "none" special case
 if test "x$enable_auth_basic" = "xnone" ; then
@@ -84,7 +86,11 @@ if test "x$enable_auth_basic" != "xno" ; then
 
       if test -d "$srcdir/helpers/basic_auth/$helper"; then
         if test "$BUILD_HELPER" != "$helper"; then
-          AC_MSG_NOTICE([Basic auth helper $helper ... found but cannot be built])
+          if test "x$auto_auth_basic_modules" = "xyes"; then
+            AC_MSG_NOTICE([Basic auth helper $helper ... found but cannot be built])
+          else
+            AC_MSG_ERROR([Basic auth helper $helper ... found but cannot be built])
+          fi
         else
           BASIC_AUTH_HELPERS="$BASIC_AUTH_HELPERS $BUILD_HELPER"
         fi
@@ -23,6 +23,7 @@ digest_edirectory_auth_LDADD = \
 	$(COMPAT_LIB) \
 	$(LDAPLIB) \
 	$(LBERLIB) \
+	$(NETTLELIB) \
 	$(CRYPTLIB) \
 	$(SSLLIB) \
 	$(XTRA_LIBS)
@@ -155,10 +155,6 @@ static int berEncodeLoginData(
     size_t   putDataLen,
     void     *putData)
 {
-    int err = 0;
-    BerElement *requestBer = NULL;
-
-    unsigned int i;
     unsigned int elemCnt = methodIDLen / sizeof(unsigned int);
 
     char    *utf8ObjPtr=NULL;
@@ -174,45 +170,56 @@ static int berEncodeLoginData(
     utf8TagSize = strlen(utf8TagPtr)+1;
 
     /* Allocate a BerElement for the request parameters. */
-    if ((requestBer = ber_alloc()) == NULL) {
-        err = LDAP_ENCODING_ERROR;
-        return err;
-    }
+    BerElement *requestBer = ber_alloc();
+    if (!requestBer)
+        return LDAP_ENCODING_ERROR;
 
     /* BER encode the NMAS Version and the objectDN */
-    err = (ber_printf(requestBer, "{io", NMAS_LDAP_EXT_VERSION, utf8ObjPtr, utf8ObjSize) < 0) ? LDAP_ENCODING_ERROR : 0;
+    if (ber_printf(requestBer, "{io", NMAS_LDAP_EXT_VERSION, utf8ObjPtr, utf8ObjSize) < 0) {
+        ber_free(requestBer, 1);
+        return LDAP_ENCODING_ERROR;
+    }
 
     /* BER encode the MethodID Length and value */
-    if (!err) {
-        err = (ber_printf(requestBer, "{i{", methodIDLen) < 0) ? LDAP_ENCODING_ERROR : 0;
+    if (ber_printf(requestBer, "{i{", methodIDLen) < 0) {
+        ber_free(requestBer, 1);
+        return LDAP_ENCODING_ERROR;
     }
 
-    for (i = 0; !err && i < elemCnt; ++i) {
-        err = (ber_printf(requestBer, "i", methodID[i]) < 0) ? LDAP_ENCODING_ERROR : 0;
+    for (unsigned int i = 0; i < elemCnt; ++i) {
+        if (ber_printf(requestBer, "i", methodID[i]) < 0) {
+            ber_free(requestBer, 1);
+            return LDAP_ENCODING_ERROR;
+        }
     }
 
-    if (!err) {
-        err = (ber_printf(requestBer, "}}", 0) < 0) ? LDAP_ENCODING_ERROR : 0;
+    if (ber_printf(requestBer, "}}", 0) < 0) {
+        ber_free(requestBer, 1);
+        return LDAP_ENCODING_ERROR;
     }
 
     if (putData) {
         /* BER Encode the the tag and data */
-        err = (ber_printf(requestBer, "oio}", utf8TagPtr, utf8TagSize, putDataLen, putData, putDataLen) < 0) ? LDAP_ENCODING_ERROR : 0;
+        if (ber_printf(requestBer, "oio}", utf8TagPtr, utf8TagSize, putDataLen, putData, putDataLen) < 0) {
+            ber_free(requestBer, 1);
+            return LDAP_ENCODING_ERROR;
+        }
     } else {
         /* BER Encode the the tag */
-        err = (ber_printf(requestBer, "o}", utf8TagPtr, utf8TagSize) < 0) ? LDAP_ENCODING_ERROR : 0;
+        if (ber_printf(requestBer, "o}", utf8TagPtr, utf8TagSize) < 0) {
+            ber_free(requestBer, 1);
+            return LDAP_ENCODING_ERROR;
+        }
     }
 
     /* Convert the BER we just built to a berval that we'll send with the extended request. */
-    if (!err && (ber_tag_t)ber_flatten(requestBer, requestBV) == LBER_ERROR) {
-        err = LDAP_ENCODING_ERROR;
-    }
-
-    if (requestBer) {
+    if (static_cast<ber_tag_t>(ber_flatten(requestBer, requestBV)) == LBER_ERROR) {
         ber_free(requestBer, 1);
+        return LDAP_ENCODING_ERROR;
     }
 
-    return err;
+    ber_free(requestBer, 1);
+    return 0; /* no error */
 }
 
 /**********************************************************************
@@ -5,4 +5,4 @@
 ## Please see the COPYING and CONTRIBUTORS files for details.
 ##
 
-AC_CHECK_HEADERS([ldap.h winldap.h],[BUILD_HELPER="LDAP"])
+AC_CHECK_HEADERS([ldap.h winldap.h],[BUILD_HELPER="eDirectory"])
@@ -19,8 +19,10 @@ if test "x$enable_auth_digest" != "xno" -a "x$enable_auth" = "xno" ; then
     AC_MSG_ERROR([Digest auth requested but auth disabled])
 fi
 #define list of modules to build
+auto_auth_digest_modules=no
 if test "x$enable_auth_digest" = "xyes" ; then
     SQUID_LOOK_FOR_MODULES([$srcdir/helpers/digest_auth],[enable_auth_digest])
+  auto_auth_digest_modules=yes
 fi
 #handle the "none" special case
 if test "x$enable_auth_digest" = "xnone" ; then
@@ -53,7 +55,11 @@ if test "x$enable_auth_digest" != "xno" ; then
 
       if test -d "$srcdir/helpers/digest_auth/$helper"; then
         if test "$BUILD_HELPER" != "$helper"; then
-          AC_MSG_NOTICE([Digest auth helper $helper ... found but cannot be built])
+          if test "x$auto_auth_digest_modules" = "xyes"; then
+            AC_MSG_NOTICE([Digest auth helper $helper ... found but cannot be built])
+          else
+            AC_MSG_ERROR([Digest auth helper $helper ... found but cannot be built])
+          fi
         else
           DIGEST_AUTH_HELPERS="$DIGEST_AUTH_HELPERS $BUILD_HELPER"
         fi
@@ -801,8 +801,7 @@ main(int argc, char *argv[])
         if (!DefaultDomain)
             DefaultDomain = xstrdup(machinedomain);
     }
-    debug("External ACL win32 group helper build " __DATE__ ", " __TIME__
-          " starting up...\n");
+    debug("%s " VERSION " " SQUID_BUILD_INFO " starting up...\n", argv[0]);
     if (use_global)
         debug("Domain Global group mode enabled using '%s' as default domain.\n", DefaultDomain);
     if (use_case_insensitive_compare)
@@ -540,8 +540,7 @@ main(int argc, char *argv[])
         if (!DefaultDomain)
             DefaultDomain = xstrdup(machinedomain);
     }
-    debug("External ACL win32 group helper build " __DATE__ ", " __TIME__
-          " starting up...\n");
+    debug("%s " VERSION " " SQUID_BUILD_INFO " starting up...\n", argv[0]);
     if (use_global) {
         debug("Domain Global group mode enabled using '%s' as default domain.\n", DefaultDomain);
     }
@@ -8,15 +8,20 @@
 include $(top_srcdir)/src/Common.am
 
 libexec_SCRIPTS	= ext_sql_session_acl
-CLEANFILES += ext_sql_session_acl ext_sql_session_acl.8
-man_MANS = ext_sql_session_acl.8
+CLEANFILES += ext_sql_session_acl
 EXTRA_DIST= \
-	ext_sql_session_acl.8 \
 	ext_sql_session_acl.pl.in \
 	required.m4
 
-ext_sql_session_acl.8: ext_sql_session_acl
-	pod2man ext_sql_session_acl ext_sql_session_acl.8
-
 ext_sql_session_acl: ext_sql_session_acl.pl.in
 	$(subst_perlshell)
+
+if ENABLE_POD2MAN_DOC
+man_MANS = ext_sql_session_acl.8
+CLEANFILES += ext_sql_session_acl.8
+EXTRA_DIST += ext_sql_session_acl.8
+
+ext_sql_session_acl.8: ext_sql_session_acl
+	pod2man --section=8 ext_sql_session_acl ext_sql_session_acl.8
+
+endif
@@ -5,6 +5,10 @@
 ## Please see the COPYING and CONTRIBUTORS files for details.
 ##
 
-if test "x$PERL" != "x" -a "x$POD2MAN" != "x"; then
+if test "x$PERL" != "x"; then
   BUILD_HELPER="SQL_session"
 fi
+if test "x$POD2MAN" = "x"; then
+  AC_MSG_WARN([pod2man not found. ext_sql_session_acl man(8) page will not be built])
+fi
+
@@ -8,12 +8,20 @@
 include $(top_srcdir)/src/Common.am
 
 libexec_SCRIPTS = ext_delayer_acl
-CLEANFILES += ext_delayer_acl ext_delayer_acl.8
+CLEANFILES += ext_delayer_acl
+EXTRA_DIST= \
+	required.m4 \
+	ext_delayer_acl.pl.in
+
+ext_delayer_acl: ext_delayer_acl.pl.in
+	$(subst_perlshell)
+
+if ENABLE_POD2MAN_DOC
 man_MANS = ext_delayer_acl.8
-EXTRA_DIST = ext_delayer_acl.pl.in ext_delayer_acl.8 required.m4
+CLEANFILES += ext_delayer_acl.8
+EXTRA_DIST += ext_delayer_acl.8
 
 ext_delayer_acl.8: ext_delayer_acl
-	pod2man ext_delayer_acl ext_delayer_acl.8
+	pod2man --section=8 ext_delayer_acl ext_delayer_acl.8
 
-ext_delayer_acl: ext_delayer_acl.pl.in
-	$(subst_perlshell)
+endif
@@ -5,6 +5,10 @@
 ## Please see the COPYING and CONTRIBUTORS files for details.
 ##
 
-if test "x$PERL" != "x" -a "x$POD2MAN" != "x"; then
+if test "x$PERL" != "x"; then
   BUILD_HELPER="delayer"
 fi
+if test "x$POD2MAN" = "x"; then
+  AC_MSG_WARN([pod2man not found. ext_delayer_acl man(8) page will not be built])
+fi
+
@@ -1500,6 +1500,7 @@ MainSafe(int argc, char **argv)
     memset(bufb, '\0', sizeof(bufb));
     memset(bufc, '\0', sizeof(bufc));
     memset(sfmod, '\0', sizeof(sfmod));
+    memset(&sv, 0, sizeof(sv));
 
     InitConf();
     xstrncpy(edui_conf.program, argv[0], sizeof(edui_conf.program));
@@ -7,5 +7,10 @@
 
 if test "x$with_krb5" == "xyes"; then
   BUILD_HELPER="kerberos_ldap_group"
+  if test "x$with_apple_krb5" = "xyes" ; then
+    AC_CHECK_LIB(resolv, [main], [XTRA_LIBS="$XTRA_LIBS -lresolv"],[
+      AC_MSG_ERROR([library 'resolv' is required for Apple Kerberos])
+    ])
+  fi
   SQUID_CHECK_SASL
 fi
@@ -34,6 +34,10 @@
 
 #include <cstring>
 
+#if USE_APPLE_KRB5
+#define KERBEROS_APPLE_DEPRECATED(x)
+#endif
+
 #if HAVE_KRB5_H
 #if HAVE_BROKEN_SOLARIS_KRB5_H
 #warn "Warning! You have a broken Solaris <krb5.h> system header"
@@ -165,7 +165,7 @@ krb5_create_cache(char *domain)
             }
         } else {
             krb5_error_code code2 = 0;
-            creds = (krb5_creds *) xcalloc(1,sizeof(*creds));
+            creds = static_cast<krb5_creds *>(xcalloc(1,sizeof(*creds)));
             while ((krb5_cc_next_cred(kparam.context, kparam.cc[ccindex], &ccursor, creds)) == 0) {
                 code2 = krb5_unparse_name(kparam.context, creds->server, &principal_name);
                 if (code2) {
@@ -174,8 +174,8 @@ krb5_create_cache(char *domain)
                     if (code) {
                         k5_error("Error while destroying ccache",code);
                     }
-                    if (creds)
-                        krb5_free_creds(kparam.context, creds);
+                    assert(creds != NULL);
+                    krb5_free_creds(kparam.context, creds);
                     creds = NULL;
                     safe_free(principal_name);
                     debug((char *) "%s| %s: DEBUG: Reset credential cache to %s\n", LogTime(), PROGRAM, mem_cache);
@@ -207,8 +207,8 @@ krb5_create_cache(char *domain)
                         if (code) {
                             k5_error("Error  while destroying ccache",code);
                         }
-                        if (creds)
-                            krb5_free_creds(kparam.context, creds);
+                        assert(creds != NULL);
+                        krb5_free_creds(kparam.context, creds);
                         creds = NULL;
                         safe_free(principal_name);
                         debug((char *) "%s| %s: DEBUG: Reset credential cache to %s\n", LogTime(), PROGRAM, mem_cache);
@@ -224,9 +224,9 @@ krb5_create_cache(char *domain)
                     }
                     break;
                 }
-                if (creds)
-                    krb5_free_creds(kparam.context, creds);
-                creds = (krb5_creds *) xcalloc(1,sizeof(*creds));
+                assert(creds != NULL);
+                krb5_free_creds(kparam.context, creds);
+                creds = static_cast<krb5_creds *>(xcalloc(1, sizeof(*creds)));
                 safe_free(principal_name);
             }
             if (creds)
@@ -114,11 +114,16 @@ ldap_simple_rebind(
     void *params)
 {
     struct ldap_creds *cp = (struct ldap_creds *) params;
+    struct berval cred;
+    if (cp->pw) {
+        cred.bv_val=cp->pw;
+        cred.bv_len=strlen(cp->pw);
+    }
     whop = whop;
     credp = credp;
     methodp = methodp;
     freeit = freeit;
-    return ldap_bind_s(ld, cp->dn, cp->pw, LDAP_AUTH_SIMPLE);
+    return ldap_sasl_bind_s(ld, cp->dn, LDAP_SASL_SIMPLE, &cred, NULL, NULL, NULL);
 }
 #elif HAVE_LDAP_REBIND_PROC
 #if HAVE_SASL_H || HAVE_SASL_SASL_H || HAVE_SASL_DARWIN
@@ -148,7 +153,12 @@ ldap_simple_rebind(
     void *params)
 {
     struct ldap_creds *cp = (struct ldap_creds *) params;
-    return ldap_bind_s(ld, cp->dn, cp->pw, LDAP_AUTH_SIMPLE);
+    struct berval cred;
+    if (cp->pw) {
+        cred.bv_val=cp->pw;
+        cred.bv_len=strlen(cp->pw);
+    }
+    return ldap_sasl_bind_s(ld, cp->dn, LDAP_SASL_SIMPLE, &cred, NULL, NULL, NULL);
 }
 
 #elif HAVE_LDAP_REBIND_FUNCTION
@@ -188,11 +198,16 @@ ldap_simple_rebind(
     void *params)
 {
     struct ldap_creds *cp = (struct ldap_creds *) params;
+    struct berval cred;
+    if (cp->pw) {
+        cred.bv_val=cp->pw;
+        cred.bv_len=strlen(cp->pw);
+    }
     whop = whop;
     credp = credp;
     methodp = methodp;
     freeit = freeit;
-    return ldap_bind_s(ld, cp->dn, cp->pw, LDAP_AUTH_SIMPLE);
+    return ldap_sasl_bind_s(ld, cp->dn, LDAP_SASL_SIMPLE, &cred, NULL, NULL, NULL);
 }
 #else
 #error "No rebind functione defined"
@@ -202,7 +217,7 @@ ldap_simple_rebind(
 static LDAP_REBIND_PROC ldap_sasl_rebind;
 
 static int
-ldap_sasl_rebind(LDAP *ld, LDAP_CONST char *, ber_tag_t, ber_int_t, void *params)
+ldap_sasl_rebind(LDAP *ld, LDAP_CONST char *, ber_tag_t request, ber_int_t msgid, void *params)
 {
     struct ldap_creds *cp = (struct ldap_creds *) params;
     return tool_sasl_bind(ld, cp->dn, cp->pw);
@@ -212,11 +227,16 @@ ldap_sasl_rebind(LDAP *ld, LDAP_CONST char *, ber_tag_t, ber_int_t, void *params
 static LDAP_REBIND_PROC ldap_simple_rebind;
 
 static int
-ldap_simple_rebind(LDAP * ld, LDAP_CONST char *, ber_tag_t, ber_int_t, void *params)
+ldap_simple_rebind(LDAP *ld, LDAP_CONST char *, ber_tag_t request, ber_int_t msgid, void *params)
 {
 
     struct ldap_creds *cp = (struct ldap_creds *) params;
-    return ldap_bind_s(ld, cp->dn, cp->pw, LDAP_AUTH_SIMPLE);
+    struct berval cred;
+    if (cp->pw) {
+        cred.bv_val=cp->pw;
+        cred.bv_len=strlen(cp->pw);
+    }
+    return ldap_sasl_bind_s(ld, cp->dn, LDAP_SASL_SIMPLE, &cred, NULL, NULL, NULL);
 }
 
 #endif
@@ -745,7 +765,7 @@ tool_ldap_open(struct main_args * margs, char *host, int port, char *ssl)
     xfree(ldapuri);
     if (rc != LDAP_SUCCESS) {
         error((char *) "%s| %s: ERROR: Error while initialising connection to ldap server: %s\n", LogTime(), PROGRAM, ldap_err2string(rc));
-        ldap_unbind(ld);
+        ldap_unbind_ext(ld,NULL,NULL);
         ld = NULL;
         return NULL;
     }
@@ -755,7 +775,7 @@ tool_ldap_open(struct main_args * margs, char *host, int port, char *ssl)
     rc = ldap_set_defaults(ld);
     if (rc != LDAP_SUCCESS) {
         error((char *) "%s| %s: ERROR: Error while setting default options for ldap server: %s\n", LogTime(), PROGRAM, ldap_err2string(rc));
-        ldap_unbind(ld);
+        ldap_unbind_ext(ld, NULL, NULL);
         ld = NULL;
         return NULL;
     }
@@ -767,7 +787,7 @@ tool_ldap_open(struct main_args * margs, char *host, int port, char *ssl)
         rc = ldap_set_ssl_defaults(margs);
         if (rc != LDAP_SUCCESS) {
             error((char *) "%s| %s: ERROR: Error while setting SSL default options for ldap server: %s\n", LogTime(), PROGRAM, ldap_err2string(rc));
-            ldap_unbind(ld);
+            ldap_unbind_ext(ld, NULL, NULL);
             ld = NULL;
             return NULL;
         }
@@ -778,7 +798,7 @@ tool_ldap_open(struct main_args * margs, char *host, int port, char *ssl)
         rc = ldap_start_tls_s(ld, NULL, NULL);
         if (rc != LDAP_SUCCESS) {
             error((char *) "%s| %s: ERROR: Error while setting start_tls for ldap server: %s\n", LogTime(), PROGRAM, ldap_err2string(rc));
-            ldap_unbind(ld);
+            ldap_unbind_ext(ld, NULL, NULL);
             ld = NULL;
             url = (LDAPURLDesc *) xmalloc(sizeof(*url));
             memset(url, 0, sizeof(*url));
@@ -810,14 +830,14 @@ tool_ldap_open(struct main_args * margs, char *host, int port, char *ssl)
             xfree(ldapuri);
             if (rc != LDAP_SUCCESS) {
                 error((char *) "%s| %s: ERROR: Error while initialising connection to ldap server: %s\n", LogTime(), PROGRAM, ldap_err2string(rc));
-                ldap_unbind(ld);
+                ldap_unbind_ext(ld, NULL, NULL);
                 ld = NULL;
                 return NULL;
             }
             rc = ldap_set_defaults(ld);
             if (rc != LDAP_SUCCESS) {
                 error((char *) "%s| %s: ERROR: Error while setting default options for ldap server: %s\n", LogTime(), PROGRAM, ldap_err2string(rc));
-                ldap_unbind(ld);
+                ldap_unbind_ext(ld, NULL, NULL);
                 ld = NULL;
                 return NULL;
             }
@@ -826,14 +846,14 @@ tool_ldap_open(struct main_args * margs, char *host, int port, char *ssl)
         ld = ldapssl_init(host, port, 1);
         if (!ld) {
             error((char *) "%s| %s: ERROR: Error while setting SSL for ldap server: %s\n", LogTime(), PROGRAM, ldapssl_err2string(rc));
-            ldap_unbind(ld);
+            ldap_unbind_ext(ld, NULL, NULL);
             ld = NULL;
             return NULL;
         }
         rc = ldap_set_defaults(ld);
         if (rc != LDAP_SUCCESS) {
             error((char *) "%s| %s: ERROR: Error while setting default options for ldap server: %s\n", LogTime(), PROGRAM, ldap_err2string(rc));
-            ldap_unbind(ld);
+            ldap_unbind_ext(ld, NULL, NULL);
             ld = NULL;
             return NULL;
         }
@@ -940,7 +960,7 @@ get_memberof(struct main_args *margs, char *user, char *domain, char *group)
             rc = tool_sasl_bind(ld, bindp, margs->ssl);
             if (rc != LDAP_SUCCESS) {
                 error((char *) "%s| %s: ERROR: Error while binding to ldap server with SASL/GSSAPI: %s\n", LogTime(), PROGRAM, ldap_err2string(rc));
-                ldap_unbind(ld);
+                ldap_unbind_ext(ld, NULL, NULL);
                 ld = NULL;
                 continue;
             }
@@ -953,7 +973,7 @@ get_memberof(struct main_args *margs, char *user, char *domain, char *group)
                 break;
             }
 #else
-            ldap_unbind(ld);
+            ldap_unbind_ext(ld, NULL, NULL);
             ld = NULL;
             error((char *) "%s| %s: ERROR: SASL not supported on system\n", LogTime(), PROGRAM);
             continue;
@@ -993,7 +1013,11 @@ get_memberof(struct main_args *margs, char *user, char *domain, char *group)
         nhosts = get_hostname_list(&hlist, 0, host);
         xfree(host);
         for (size_t i = 0; i < nhosts; ++i) {
-
+            struct berval cred;
+            if (margs->lpass) {
+                cred.bv_val=margs->lpass;
+                cred.bv_len=strlen(margs->lpass);
+            }
             ld = tool_ldap_open(margs, hlist[i].host, port, ssl);
             if (!ld)
                 continue;
@@ -1002,10 +1026,10 @@ get_memberof(struct main_args *margs, char *user, char *domain, char *group)
              */
 
             debug((char *) "%s| %s: DEBUG: Bind to ldap server with Username/Password\n", LogTime(), PROGRAM);
-            rc = ldap_simple_bind_s(ld, margs->luser, margs->lpass);
+            rc = ldap_sasl_bind_s(ld, margs->luser, LDAP_SASL_SIMPLE, &cred, NULL, NULL, NULL);
             if (rc != LDAP_SUCCESS) {
                 error((char *) "%s| %s: ERROR: Error while binding to ldap server with Username/Password: %s\n", LogTime(), PROGRAM, ldap_err2string(rc));
-                ldap_unbind(ld);
+                ldap_unbind_ext(ld, NULL, NULL);
                 ld = NULL;
                 continue;
             }
@@ -1040,7 +1064,7 @@ get_memberof(struct main_args *margs, char *user, char *domain, char *group)
     rc = check_AD(margs, ld);
     if (rc != LDAP_SUCCESS) {
         error((char *) "%s| %s: ERROR: Error determining ldap server type: %s\n", LogTime(), PROGRAM, ldap_err2string(rc));
-        ldap_unbind(ld);
+        ldap_unbind_ext(ld, NULL, NULL);
         ld = NULL;
         retval = 0;
         goto cleanup;
@@ -1066,7 +1090,7 @@ get_memberof(struct main_args *margs, char *user, char *domain, char *group)
 
     if (rc != LDAP_SUCCESS) {
         error((char *) "%s| %s: ERROR: Error searching ldap server: %s\n", LogTime(), PROGRAM, ldap_err2string(rc));
-        ldap_unbind(ld);
+        ldap_unbind_ext(ld, NULL, NULL);
         ld = NULL;
         retval = 0;
         goto cleanup;
@@ -1151,7 +1175,7 @@ get_memberof(struct main_args *margs, char *user, char *domain, char *group)
         ldap_msgfree(res);
     } else if (ldap_count_entries(ld, res) == 0 && margs->AD) {
         ldap_msgfree(res);
-        ldap_unbind(ld);
+        ldap_unbind_ext(ld, NULL, NULL);
         ld = NULL;
         retval = 0;
         goto cleanup;
@@ -1363,7 +1387,7 @@ get_memberof(struct main_args *margs, char *user, char *domain, char *group)
             safe_free(attr_value);
         }
     }
-    rc = ldap_unbind(ld);
+    rc = ldap_unbind_ext(ld, NULL, NULL);
     ld = NULL;
     if (rc != LDAP_SUCCESS) {
         error((char *) "%s| %s: ERROR: Error unbind ldap server: %s\n", LogTime(), PROGRAM, ldap_err2string(rc));
@@ -11,8 +11,10 @@
 # FIXME: de-duplicate $enable_external_acl_helpers list containing double entries.
 
 #define list of modules to build
+auto_ext_acl_modules=no
 if test "x${enable_external_acl_helpers:=yes}" = "xyes" ;then
   SQUID_LOOK_FOR_MODULES([$srcdir/helpers/external_acl],[enable_external_acl_helpers])
+  auto_ext_acl_modules=yes
 fi
 if test "x$enable_external_acl_helpers" = "xnone" ; then
   enable_external_acl_helpers=""
@@ -68,7 +70,11 @@ if test "x$enable_external_acl_helpers" != "xno" ; then
 
       if test -d "$srcdir/helpers/external_acl/$helper"; then
         if test "$BUILD_HELPER" != "$helper"; then
-          AC_MSG_NOTICE([external acl helper $helper ... found but cannot be built])
+          if test "x$auto_ext_acl_modules" = "xyes"; then
+            AC_MSG_NOTICE([external acl helper $helper ... found but cannot be built])
+          else
+            AC_MSG_ERROR([external acl helper $helper ... found but cannot be built])
+          fi
         else
           EXTERNAL_ACL_HELPERS="$EXTERNAL_ACL_HELPERS $BUILD_HELPER"
         fi
@@ -8,16 +8,20 @@
 include $(top_srcdir)/src/Common.am
 
 libexec_SCRIPTS= ext_wbinfo_group_acl
-man_MANS= ext_wbinfo_group_acl.8
+CLEANFILES += ext_wbinfo_group_acl
 EXTRA_DIST= \
-	ext_wbinfo_group_acl.8 \
 	ext_wbinfo_group_acl.pl.in \
 	required.m4
 
 ext_wbinfo_group_acl: ext_wbinfo_group_acl.pl.in
 	$(subst_perlshell)
 
+if ENABLE_POD2MAN_DOC
+man_MANS = ext_wbinfo_group_acl.8
+CLEANFILES += ext_wbinfo_group_acl.8
+EXTRA_DIST += ext_wbinfo_group_acl.8
+
 ext_wbinfo_group_acl.8: ext_wbinfo_group_acl
-	pod2man ext_wbinfo_group_acl ext_wbinfo_group_acl.8
+	pod2man --section=8 ext_wbinfo_group_acl ext_wbinfo_group_acl.8
 
-CLEANFILES += ext_wbinfo_group_acl.8 ext_wbinfo_group_acl
+endif
@@ -15,6 +15,10 @@ if test "x$WBINFO" = "x"; then
 fi
 
 # allow script install anyway when perl is present
-if test "x$PERL" != "x" -a "x$POD2MAN" != "x"; then
+if test "x$PERL" != "x"; then
   BUILD_HELPER="wbinfo_group"
 fi
+if test "x$POD2MAN" = "x"; then
+  AC_MSG_WARN([pod2man not found. ext_wbinfo_group_acl man(8) page will not be built])
+fi
+
@@ -8,17 +8,22 @@
 include $(top_srcdir)/src/Common.am
 
 libexec_SCRIPTS	= log_db_daemon
-CLEANFILES += log_db_daemon log_db_daemon.8
-man_MANS = log_db_daemon.8
+CLEANFILES += log_db_daemon
 EXTRA_DIST= \
 	required.m4 \
 	doc/views.sql \
 	doc/date_day_column.sql \
-	log_db_daemon.8 \
 	log_db_daemon.pl.in
 
-log_db_daemon.8: log_db_daemon
-	pod2man log_db_daemon log_db_daemon.8
-
 log_db_daemon: log_db_daemon.pl.in
 	$(subst_perlshell)
+
+if ENABLE_POD2MAN_DOC
+man_MANS = log_db_daemon.8
+CLEANFILES += log_db_daemon.8
+EXTRA_DIST += log_db_daemon.8
+
+log_db_daemon.8: log_db_daemon
+	pod2man --section=8 log_db_daemon log_db_daemon.8
+
+endif
@@ -5,6 +5,10 @@
 ## Please see the COPYING and CONTRIBUTORS files for details.
 ##
 
-if test "x$PERL" != "x" -a "x$POD2MAN" != "x"; then
+if test "x$PERL" != "x"; then
   BUILD_HELPER="DB"
 fi
+if test "x$POD2MAN" = "x"; then
+  AC_MSG_WARN([pod2man not found. log_db_daemon man(8) page will not be built])
+fi
+
@@ -105,6 +105,9 @@ main(int argc, char *argv[])
         exit(1);
     }
     setbuf(stdout, NULL);
+    /* XXX stderr should not be closed, but in order to support squid must be
+     * able to collect and manage modules's stderr first.
+     */
     close(2);
     t = open(_PATH_DEVNULL, O_RDWR);
     assert(t > -1);
@@ -119,7 +122,7 @@ main(int argc, char *argv[])
                 /* try to detect the 32-bit file too big write error and rotate */
                 int err = ferror(fp);
                 clearerr(fp);
-                if (err < 0) {
+                if (err != 0) {
                     /* file too big - recover by rotating the logs and starting a new one.
                      * out of device space - recover by rotating and hoping that rotation count drops a big one.
                      */
@@ -11,9 +11,11 @@
 # FIXME: de-duplicate $enable_log_daemon_helpers list containing double entries.
 
 #define list of modules to build
+auto_logdaemon_modules=no
 if test "x${enable_log_daemon_helpers:=yes}" = "xyes" ;then
   enable_log_daemon_helpers=""
   SQUID_LOOK_FOR_MODULES([$srcdir/helpers/log_daemon],[enable_log_daemon_helpers])
+  auto_logdaemon_modules=yes
 fi
 if test "x$enable_log_daemon_helpers" = "xnone" ; then
   enable_log_daemon_helpers=""
@@ -40,7 +42,11 @@ if test "x$enable_log_daemon_helpers" != "xno"; then
 
     if test -d "$srcdir/helpers/log_daemon/$helper"; then
       if test "$BUILD_HELPER" != "$helper"; then
-        AC_MSG_NOTICE([Log daemon helper $helper ... found but cannot be built])
+        if test "x$auto_logdaemon_modules" = "xyes"; then
+          AC_MSG_NOTICE([Log daemon helper $helper ... found but cannot be built])
+        else
+          AC_MSG_ERROR([Log daemon helper $helper ... found but cannot be built])
+        fi
       else
        LOG_DAEMON_HELPERS="$LOG_DAEMON_HELPERS $BUILD_HELPER"
       fi
@@ -302,7 +302,7 @@ main(int argc, char *argv[])
 
     process_options(argc, argv);
 
-    debug("%s build " __DATE__ ", " __TIME__ " starting up...\n", my_program_name);
+    debug("%s " VERSION " " SQUID_BUILD_INFO " starting up...\n", my_program_name);
 
     if (LoadSecurityDll(SSP_NTLM, NEGOTIATE_PACKAGE_NAME) == NULL) {
         fprintf(stderr, "FATAL: %s: can't initialize SSPI, exiting.\n", argv[0]);
@@ -47,6 +47,11 @@
 #include "base64.h"
 #include "util.h"
 
+#if USE_APPLE_KRB5
+#define KERBEROS_APPLE_DEPRECATED(x)
+#define GSSKRB_APPLE_DEPRECATED(x)
+#endif
+
 #if HAVE_KRB5_H
 #if HAVE_BROKEN_SOLARIS_KRB5_H
 #warn "Warning! You have a broken Solaris <krb5.h> system header"
@@ -144,7 +149,6 @@ typedef struct {
     uint32_t pointer;
 } RPC_UNICODE_STRING;
 
-int check_k5_err(krb5_context context, const char *msg, krb5_error_code code);
 void align(int n);
 void getustr(RPC_UNICODE_STRING *string);
 char **getgids(char **Rids, uint32_t GroupIds, uint32_t GroupCount);
@@ -161,4 +165,5 @@ char *get_ad_groups(char *ad_groups, krb5_context context, krb5_pac pac);
 #else
 #define HAVE_PAC_SUPPORT 0
 #endif
+int check_k5_err(krb5_context context, const char *msg, krb5_error_code code);
 
@@ -65,7 +65,6 @@ krb5_error_code krb5_read_keytab(krb5_context context,
                                  krb5_kt_list *kt_list);
 #endif /* HAVE_KRB5_MEMORY_KEYTAB */
 
-#if HAVE_PAC_SUPPORT || HAVE_KRB5_MEMORY_KEYTAB
 int
 check_k5_err(krb5_context context, const char *function, krb5_error_code code)
 {
@@ -85,7 +84,6 @@ check_k5_err(krb5_context context, const char *function, krb5_error_code code)
     }
     return code;
 }
-#endif
 
 char *
 gethost_name(void)
@@ -540,7 +538,7 @@ main(int argc, char *const argv[])
             if (!check_k5_err(context, "krb5_init_context", ret)) {
                 krb5_kt_default_name(context, default_keytab, MAXPATHLEN);
             }
-            keytab_name = default_keytab;
+            keytab_name = xstrdup(default_keytab);
             krb5_free_context(context);
         } else
             keytab_name = xstrdup(keytab_name_env);
@@ -33,6 +33,9 @@
 #include "squid.h"
 
 #if HAVE_GSSAPI
+#if USE_APPLE_KRB5
+#define GSSKRB_APPLE_DEPRECATED(x)
+#endif
 
 #include <cerrno>
 #include <cstring>
@@ -19,8 +19,10 @@ if test "x$enable_auth_negotiate" != "xno" -a "x$enable_auth" = "xno" ; then
     AC_MSG_ERROR([Negotiate auth requested but auth disabled])
 fi
 #define list of modules to build
+auto_auth_negotiate_modules=no
 if test "x$enable_auth_negotiate" = "xyes" ; then
     SQUID_LOOK_FOR_MODULES([$srcdir/helpers/negotiate_auth],[enable_auth_negotiate])
+  auto_auth_negotiate_modules=yes
 fi
 #handle the "none" special case
 if test "x$enable_auth_negotiate" = "xnone" ; then
@@ -53,7 +55,11 @@ if test "x$enable_auth_negotiate" != "xno" ; then
 
       if test -d "$srcdir/helpers/negotiate_auth/$helper"; then
         if test "$BUILD_HELPER" != "$helper"; then
-          AC_MSG_NOTICE([Negotiate auth helper $helper ... found but cannot be built])
+          if test "x$auto_auth_negotiate_modules" = "xyes"; then
+            AC_MSG_NOTICE([Negotiate auth helper $helper ... found but cannot be built])
+          else
+            AC_MSG_ERROR([Negotiate auth helper $helper ... found but cannot be built])
+          fi
         else
           NEGOTIATE_AUTH_HELPERS="$NEGOTIATE_AUTH_HELPERS $BUILD_HELPER"
         fi
@@ -637,7 +637,7 @@ main(int argc, char *argv[])
 
     process_options(argc, argv);
 
-    debug("%s build " __DATE__ ", " __TIME__ " starting up...\n", my_program_name);
+    debug("%s " VERSION " " SQUID_BUILD_INFO " starting up...\n", my_program_name);
 
     if (LoadSecurityDll(SSP_NTLM, NTLM_PACKAGE_NAME) == NULL) {
         fprintf(stderr, "FATAL, can't initialize SSPI, exiting.\n");
@@ -50,12 +50,6 @@
 #if HAVE_GETOPT_H
 #include <getopt.h>
 #endif
-#if HAVE_STDINT_H
-#include <stdint.h>
-#endif
-#if HAVE_INTTYPES_H
-#include <inttypes.h>
-#endif
 
 /* A couple of harmless helper macros */
 #define SEND(X) {debug("sending '%s' to squid\n",X); printf(X "\n");}
@@ -147,7 +141,7 @@ main(int argc, char *argv[])
 
     process_options(argc, argv);
 
-    debug("%s build " __DATE__ ", " __TIME__ " starting up...\n", my_program_name);
+    debug("%s " VERSION " " SQUID_BUILD_INFO " starting up...\n", my_program_name);
 
     while (fgets(buf, HELPER_INPUT_BUFFER, stdin) != NULL) {
         user[0] = '\0';     /*no user code */
@@ -19,8 +19,10 @@ if test "x$enable_auth_ntlm" != "xno" -a "x$enable_auth" = "xno" ; then
     AC_MSG_ERROR([NTLM auth requested but auth disabled])
 fi
 #define list of modules to build
+auto_auth_ntlm_modules=no
 if test "x$enable_auth_ntlm" = "xyes" ; then
     SQUID_LOOK_FOR_MODULES([$srcdir/helpers/ntlm_auth],[enable_auth_ntlm])
+  auto_auth_ntlm_modules=yes
 fi
 #handle the "none" special case
 if test "x$enable_auth_ntlm" = "xnone" ; then
@@ -54,7 +56,11 @@ if test "x$enable_auth_ntlm" != "xno" ; then
 
       if test -d "$srcdir/helpers/ntlm_auth/$helper"; then
         if test "$BUILD_HELPER" != "$helper"; then
-          AC_MSG_NOTICE([NTLM auth helper $helper ... found but cannot be built])
+          if test "x$auto_auth_ntlm_modules" = "xyes"; then
+            AC_MSG_NOTICE([NTLM auth helper $helper ... found but cannot be built])
+          else
+            AC_MSG_ERROR([NTLM auth helper $helper ... found but cannot be built])
+          fi
         else
           NTLM_AUTH_HELPERS="$NTLM_AUTH_HELPERS $BUILD_HELPER"
         fi
@@ -477,7 +477,6 @@ manage_request()
     ntlmhdr *fast_header;
     char buf[NTLM_BLOB_BUFFER_SIZE];
     char decoded[NTLM_BLOB_BUFFER_SIZE];
-    const char *ch;
     char *ch2, *cred = NULL;
 
     if (fgets(buf, NTLM_BLOB_BUFFER_SIZE, stdin) == NULL) {
@@ -489,7 +488,6 @@ manage_request()
     ch2 = (char*)memchr(buf, '\n', NTLM_BLOB_BUFFER_SIZE);  /* safer against overrun than strchr */
     if (ch2) {
         *ch2 = '\0';        /* terminate the string at newline. */
-        ch = ch2;
     }
     debug("ntlm authenticator. Got '%s' from Squid\n", buf);
 
@@ -628,7 +626,7 @@ manage_request()
     }
     if (memcmp(buf, "YR", 2) == 0) {    /* refresh-request */
         dc_disconnect();
-        ch = obtain_challenge();
+        const char *ch = obtain_challenge();
         /* Robert says we can afford to wait forever. I'll trust him on this
          * one */
         while (ch == NULL) {
@@ -647,7 +645,7 @@ manage_request()
 int
 main(int argc, char *argv[])
 {
-    debug("ntlm_auth build " __DATE__ ", " __TIME__ " starting up...\n");
+    debug("%s " VERSION " " SQUID_BUILD_INFO " starting up...\n", argv[0]);
 
     my_program_name = argv[0];
     process_options(argc, argv);
@@ -8,15 +8,20 @@
 include $(top_srcdir)/src/Common.am
 
 libexec_SCRIPTS	= storeid_file_rewrite
-CLEANFILES += storeid_file_rewrite storeid_file_rewrite.8
-man_MANS = storeid_file_rewrite.8
+CLEANFILES += storeid_file_rewrite
 EXTRA_DIST= \
-	storeid_file_rewrite.8 \
 	storeid_file_rewrite.pl.in \
 	required.m4
 
-storeid_file_rewrite.8: storeid_file_rewrite
-	pod2man storeid_file_rewrite storeid_file_rewrite.8
-
 storeid_file_rewrite: storeid_file_rewrite.pl.in
 	$(subst_perlshell)
+
+if ENABLE_POD2MAN_DOC
+man_MANS = storeid_file_rewrite.8
+CLEANFILES += storeid_file_rewrite.8
+EXTRA_DIST += storeid_file_rewrite.8
+
+storeid_file_rewrite.8: storeid_file_rewrite
+	pod2man --section=8 storeid_file_rewrite storeid_file_rewrite.8
+
+endif
@@ -5,6 +5,10 @@
 ## Please see the COPYING and CONTRIBUTORS files for details.
 ##
 
-if test "x$PERL" != "x" -a "x$POD2MAN" != "x"; then
+if test "x$PERL" != "x"; then
   BUILD_HELPER="file"
 fi
+if test "x$POD2MAN" = "x"; then
+  AC_MSG_WARN([pod2man not found. storeid_file_rewrite man(8) page will not be built])
+fi
+
@@ -11,8 +11,10 @@
 # FIXME: de-duplicate $enable_storeid_rewrite_helpers list containing double entries.
 
 #define list of modules to build
+auto_storeid_modules=no
 if test "x${enable_storeid_rewrite_helpers:=yes}" = "xyes" ; then
     SQUID_LOOK_FOR_MODULES([$srcdir/helpers/storeid_rewrite],[enable_storeid_rewrite_helpers])
+  auto_storeid_modules=yes
 fi
 
 enable_storeid_rewrite_helpers="`echo $enable_storeid_rewrite_helpers| sed -e 's/,/ /g;s/  */ /g'`"
@@ -34,7 +36,11 @@ if test "x$enable_storeid_rewrite_helpers" != "xno" ; then
 
     if test -d "$srcdir/helpers/storeid_rewrite/$helper"; then
       if test "$BUILD_HELPER" != "$helper"; then
-        AC_MSG_NOTICE([Store-ID rewrite helper $helper ... found but cannot be built])
+        if test "x$auto_storeid_modules" = "xyes"; then
+          AC_MSG_NOTICE([Store-ID rewrite helper $helper ... found but cannot be built])
+        else
+          AC_MSG_ERROR([Store-ID rewrite helper $helper ... found but cannot be built])
+        fi
       else
         STOREID_REWRITE_HELPERS="$STOREID_REWRITE_HELPERS $BUILD_HELPER"
       fi
@@ -14,17 +14,20 @@ include $(top_srcdir)/src/Common.am
 
 # Perl helper
 libexec_SCRIPTS = url_lfs_rewrite
-man_MANS = url_lfs_rewrite.8
-
+CLEANFILES += url_lfs_rewrite
 EXTRA_DIST= \
 	required.m4 \
-	url_lfs_rewrite.8 \
 	url_lfs_rewrite.pl.in
 
-url_lfs_rewrite.8: url_lfs_rewrite
-	pod2man url_lfs_rewrite url_lfs_rewrite.8
-
 url_lfs_rewrite: url_lfs_rewrite.pl.in
 	$(subst_perlshell)
 
-CLEANFILES += url_lfs_rewrite url_lfs_rewrite.8
+if ENABLE_POD2MAN_DOC
+man_MANS = url_lfs_rewrite.8
+CLEANFILES += url_lfs_rewrite.8
+EXTRA_DIST += url_lfs_rewrite.8
+
+url_lfs_rewrite.8: url_lfs_rewrite
+	pod2man --section=8 url_lfs_rewrite url_lfs_rewrite.8
+
+endif
@@ -5,6 +5,10 @@
 ## Please see the COPYING and CONTRIBUTORS files for details.
 ##
 
-if test "x$PERL" != "x" -a "x$POD2MAN" != "x"; then
+if test "x$PERL" != "x"; then
   BUILD_HELPER="LFS"
 fi
+if test "x$POD2MAN" = "x"; then
+  AC_MSG_WARN([pod2man not found. url_lfs_rewrite man(8) page will not be built])
+fi
+
@@ -104,7 +104,7 @@ main(int argc, char *argv[])
 
     process_options(argc, argv);
 
-    debug("%s build " __DATE__ ", " __TIME__ " starting up...\n", my_program_name);
+    debug("%s " VERSION " " SQUID_BUILD_INFO " starting up...\n", my_program_name);
 
     while (fgets(buf, HELPER_INPUT_BUFFER, stdin) != NULL) {
         char *p;
@@ -127,7 +127,7 @@ main(int argc, char *argv[])
             fprintf(stdout, "%" PRId64 " ERR\n", channelId);
         }
     }
-    debug("%s build " __DATE__ ", " __TIME__ " shutting down...\n", my_program_name);
+    debug("%s " VERSION " " SQUID_BUILD_INFO " shutting down...\n", my_program_name);
     return 0;
 }
 
@@ -11,8 +11,10 @@
 # FIXME: de-duplicate $enable_url_rewrite_helpers list containing double entries.
 
 #define list of modules to build
+auto_urlrewrite_modules=no
 if test "x${enable_url_rewrite_helpers:=yes}" = "xyes" ; then
     SQUID_LOOK_FOR_MODULES([$srcdir/helpers/url_rewrite],[enable_url_rewrite_helpers])
+  auto_urlrewrite_modules=yes
 fi
 
 enable_url_rewrite_helpers="`echo $enable_url_rewrite_helpers| sed -e 's/,/ /g;s/  */ /g'`"
@@ -37,7 +39,11 @@ if test "x$enable_url_rewrite_helpers" != "xno" ; then
 
     if test -d "$srcdir/helpers/url_rewrite/$helper"; then
       if test "$BUILD_HELPER" != "$helper"; then
-        AC_MSG_NOTICE([URL rewrite helper $helper ... found but cannot be built])
+        if test "x$auto_urlrewrite_modules" = "xyes"; then
+          AC_MSG_NOTICE([URL rewrite helper $helper ... found but cannot be built])
+        else
+          AC_MSG_ERROR([URL rewrite helper $helper ... found but cannot be built])
+        fi
       else
         URL_REWRITE_HELPERS="$URL_REWRITE_HELPERS $BUILD_HELPER"
       fi
@@ -66,17 +66,6 @@
 #define SQUID_UDP_SO_RCVBUF SQUID_DETECT_UDP_SO_RCVBUF
 #endif
 
-#if HAVE_RANDOM
-#define squid_random random
-#define squid_srandom srandom
-#elif HAVE_LRAND48
-#define squid_random lrand48
-#define squid_srandom srand48
-#else
-#define squid_random rand
-#define squid_srandom srand
-#endif
-
 /*
  * Determine if this is a leak check build or standard
  */
@@ -343,12 +343,15 @@ main(void)
     }
     printf("done creating hash table: %d\n", hid);
 
+    std::mt19937 mt;
+    std::uniform_int_distribution<> dist(0,16);
+
     while (fgets(buf, BUFSIZ, stdin)) {
         buf[strlen(buf) - 1] = '\0';
         printf("Inserting '%s' for item %p to hash table: %d\n",
                buf, buf, hid);
         hash_insert(hid, xstrdup(buf), (void *) 0x12345678);
-        if (random() % 17 == 0)
+        if (dist(mt) == 0)
             strcpy(todelete, buf);
     }
 
@@ -12,6 +12,7 @@
 #include "squid.h"
 
 #include <cstring>
+#include <random>
 #if HAVE_STRINGS_H
 #include <strings.h>
 #endif
@@ -178,21 +179,16 @@ ntlm_add_to_payload(const ntlmhdr *packet_hdr,
 /* ************************************************************************* */
 
 /*
- * Generates a challenge request nonce. The randomness of the 8 byte
- * challenge strings can be guarenteed to be poor at best.
+ * Generates a challenge request nonce.
  */
 void
 ntlm_make_nonce(char *nonce)
 {
-    static unsigned hash;
-    uint32_t r = static_cast<uint32_t>(rand());
-    r = (hash ^ r) + r;
+    static std::mt19937 mt(time(0));
+    static std::uniform_int_distribution<uint8_t> dist;
 
-    for (int i = 0; i < NTLM_NONCE_LEN; ++i) {
-        nonce[i] = static_cast<char>(r & 0xFF);
-        r = (r >> 2) ^ r;
-    }
-    hash = r;
+    for (int i = 0; i < NTLM_NONCE_LEN; ++i)
+        nonce[i] = static_cast<char>(dist(mt) & 0xFF);
 }
 
 /**
@@ -46,6 +46,7 @@ typedef enum {
     XPROF_HttpHeader_getCc,
     XPROF_HttpHeaderParse,
     XPROF_HttpMsg_httpMsgParseStep,
+    XPROF_HttpParserParseReplyLine,
     XPROF_HttpParserParseReqLine,
     XPROF_httpRequestFree,
     XPROF_HttpServer_parseOneRequest,
@@ -67,14 +67,20 @@ CvtBin(const HASHHEX Hex, HASH Bin)
         else
             Bin[i / 2] |= n;
     }
-    /* FIXME: Coverity detects the below as dead code.
+
+#if HASHHEXLEN != (2*HASHLEN)
+    /*
       Why? :: right here i == 32
         which means the first step of the for loop makes i==16
         and cannot be < HASHLEN (which is also 16)
+
+      But only guaranteed if HASHHEXLEN == 2*HASHLEN
+      This will ensure correct 0-ing of bins no matter what.
     */
     for (i = i / 2; i < HASHLEN; i++) {
         Bin[i] = '\0';
     }
+#endif
 }
 
 /* calculate H(A1) as per spec */
@@ -36,11 +36,13 @@
 #include "rfcnb/rfcnb-util.h"
 #include "rfcnb/std-includes.h"
 
+#if HAVE_SIGNAL_H
+#include <signal.h>
+#endif
 #if HAVE_STRING_H
 #include <string.h>
 #endif
 #include <sys/uio.h>
-#include <sys/signal.h>
 
 int RFCNB_Timeout = 0;          /* Timeout in seconds ... */
 
@@ -204,7 +204,11 @@ int SMB_Figure_Protocol(const char *dialects[], int prot_index)
 {
     int i;
 
-    if (dialects == SMB_Prots) { /* The jobs is easy, just index into table */
+    // prot_index may be a value outside the table SMB_Types[]
+    // which holds data at offsets 0 to 11
+    int ourType = (prot_index < 0 || prot_index > 11);
+
+    if (ourType && dialects == SMB_Prots) { /* The jobs is easy, just index into table */
 
         return(SMB_Types[prot_index]);
     } else { /* Search through SMB_Prots looking for a match */
@@ -63,23 +63,17 @@ class AccessLogEntry: public RefCountable
     {
 
     public:
-        HttpDetails() : method(Http::METHOD_NONE), code(0), content_type(NULL),
-            timedout(false),
-            aborted(false),
+        HttpDetails() :
+            method(Http::METHOD_NONE),
+            code(0),
+            content_type(NULL),
             clientRequestSz(),
             clientReplySz() {}
 
         HttpRequestMethod method;
         int code;
         const char *content_type;
         AnyP::ProtocolVersion version;
-        bool timedout; ///< terminated due to a lifetime or I/O timeout
-        bool aborted; ///< other abnormal termination (e.g., I/O error)
-
-        /// compute suffix for the status access.log field
-        const char *statusSfx() const {
-            return timedout ? "_TIMEDOUT" : (aborted ? "_ABORTED" : "");
-        }
 
         /// counters for the original request received from client
         // TODO calculate header and payload better (by parser)
@@ -140,7 +134,7 @@ class AccessLogEntry: public RefCountable
         CacheDetails() : caddr(),
             highOffset(0),
             objectSize(0),
-            code (LOG_TAG_NONE),
+            code(LOG_TAG_NONE),
             rfc931 (NULL),
             extuser(NULL),
 #if USE_OPENSSL
@@ -74,6 +74,7 @@
 #if USE_OPENSSL
 #include "acl/Certificate.h"
 #include "acl/CertificateData.h"
+#include "acl/ServerName.h"
 #include "acl/SslError.h"
 #include "acl/SslErrorData.h"
 #endif
@@ -177,6 +178,12 @@ ACLStrategised<X509 *> ACLServerCertificate::X509FingerprintRegistryEntry_(new A
 
 ACL::Prototype ACLAtStep::RegistryProtoype(&ACLAtStep::RegistryEntry_, "at_step");
 ACLStrategised<Ssl::BumpStep> ACLAtStep::RegistryEntry_(new ACLAtStepData, ACLAtStepStrategy::Instance(), "at_step");
+
+ACL::Prototype ACLServerName::LiteralRegistryProtoype(&ACLServerName::LiteralRegistryEntry_, "ssl::server_name");
+ACLStrategised<char const *> ACLServerName::LiteralRegistryEntry_(new ACLServerNameData, ACLServerNameStrategy::Instance(), "ssl::server_name");
+ACL::Prototype ACLServerName::RegexRegistryProtoype(&ACLServerName::RegexRegistryEntry_, "ssl::server_name_regex");
+ACLFlag  ServerNameRegexFlags[] = {ACL_F_REGEX_CASE, ACL_F_END};
+ACLStrategised<char const *> ACLServerName::RegexRegistryEntry_(new ACLRegexData, ACLServerNameStrategy::Instance(), "ssl::server_name_regex", ServerNameRegexFlags);
 #endif
 
 #if USE_SQUID_EUI
@@ -11,8 +11,6 @@
 #include "base/TextException.h"
 #include "BodyPipe.h"
 
-CBDATA_CLASS_INIT(BodyPipe);
-
 // BodySink is a BodyConsumer class which  just consume and drops
 // data from a BodyPipe
 class BodySink: public BodyConsumer
@@ -446,19 +444,19 @@ const char *BodyPipe::status() const
 
     outputBuffer.append(" [", 2);
 
-    outputBuffer.Printf("%" PRIu64 "<=%" PRIu64, theGetSize, thePutSize);
+    outputBuffer.appendf("%" PRIu64 "<=%" PRIu64, theGetSize, thePutSize);
     if (theBodySize >= 0)
-        outputBuffer.Printf("<=%" PRId64, theBodySize);
+        outputBuffer.appendf("<=%" PRId64, theBodySize);
     else
         outputBuffer.append("<=?", 3);
 
-    outputBuffer.Printf(" %d+%d", (int)theBuf.contentSize(), (int)theBuf.spaceSize());
+    outputBuffer.appendf(" %" PRId64 "+%" PRId64, static_cast<int64_t>(theBuf.contentSize()), static_cast<int64_t>(theBuf.spaceSize()));
 
-    outputBuffer.Printf(" pipe%p", this);
+    outputBuffer.appendf(" pipe%p", this);
     if (theProducer.set())
-        outputBuffer.Printf(" prod%p", theProducer.get());
+        outputBuffer.appendf(" prod%p", theProducer.get());
     if (theConsumer.set())
-        outputBuffer.Printf(" cons%p", theConsumer.get());
+        outputBuffer.appendf(" cons%p", theConsumer.get());
 
     if (mustAutoConsume)
         outputBuffer.append(" A", 2);
@@ -89,7 +89,7 @@ class BodyPipeCheckout
  */
 class BodyPipe: public RefCountable
 {
-    CBDATA_CLASS(BodyPipe);
+    MEMPROXY_CLASS(BodyPipe);
 
 public:
     typedef RefCount<BodyPipe> Pointer;
@@ -41,17 +41,6 @@ CachePeer::CachePeer() :
     max_conn(0),
     domain(NULL),
 #if USE_OPENSSL
-    use_ssl(0),
-    sslcert(NULL),
-    sslkey(NULL),
-    sslversion(0),
-    ssloptions(NULL),
-    sslcipher(NULL),
-    sslcafile(NULL),
-    sslcapath(NULL),
-    sslcrlfile(NULL),
-    sslflags(NULL),
-    ssldomain(NULL),
     sslContext(NULL),
     sslSession(NULL),
 #endif
@@ -111,16 +100,6 @@ CachePeer::~CachePeer()
     xfree(domain);
 
 #if USE_OPENSSL
-    xfree(sslcert);
-    xfree(sslkey);
-    xfree(ssloptions);
-    xfree(sslcipher);
-    xfree(sslcafile);
-    xfree(sslcapath);
-    xfree(sslcrlfile);
-    xfree(sslflags);
-    xfree(ssldomain);
-
     if (sslContext)
         SSL_CTX_free(sslContext);
 
@@ -14,6 +14,7 @@
 #include "enums.h"
 #include "icp_opcode.h"
 #include "ip/Address.h"
+#include "security/PeerOptions.h"
 
 //TODO: remove, it is unconditionally defined and always used.
 #define PEER_MULTICAST_SIBLINGS 1
@@ -178,20 +179,11 @@ class CachePeer
         bool waitingForClose; ///< a conn must close before we open a standby conn
     } standby; ///< optional "cache_peer standby=limit" feature
     char *domain;       /* Forced domain */
-#if USE_OPENSSL
 
-    int use_ssl;
-    char *sslcert;
-    char *sslkey;
-    int sslversion;
-    char *ssloptions;
-    char *sslcipher;
-    char *sslcafile;
-    char *sslcapath;
-    char *sslcrlfile;
-    char *sslflags;
-    char *ssldomain;
-    SSL_CTX *sslContext;
+    /// security settings for peer connection
+    Security::PeerOptions secure;
+    Security::ContextPointer sslContext;
+#if USE_OPENSSL
     SSL_SESSION *sslSession;
 #endif
 
@@ -1,311 +0,0 @@
-/*
- * Copyright (C) 1996-2015 The Squid Software Foundation and contributors
- *
- * Squid software is distributed under GPLv2+ license and includes
- * contributions from numerous individuals and organizations.
- * Please see the COPYING and CONTRIBUTORS files for details.
- */
-
-#include "squid.h"
-#include "base/TextException.h"
-#include "ChunkedCodingParser.h"
-#include "Debug.h"
-#include "MemBuf.h"
-#include "Parsing.h"
-
-ChunkedCodingParser::Step ChunkedCodingParser::psChunkSize = &ChunkedCodingParser::parseChunkSize;
-ChunkedCodingParser::Step ChunkedCodingParser::psUnusedChunkExtension = &ChunkedCodingParser::parseUnusedChunkExtension;
-ChunkedCodingParser::Step ChunkedCodingParser::psLastChunkExtension = &ChunkedCodingParser::parseLastChunkExtension;
-ChunkedCodingParser::Step ChunkedCodingParser::psChunkBody = &ChunkedCodingParser::parseChunkBody;
-ChunkedCodingParser::Step ChunkedCodingParser::psChunkEnd = &ChunkedCodingParser::parseChunkEnd;
-ChunkedCodingParser::Step ChunkedCodingParser::psTrailer = &ChunkedCodingParser::parseTrailer;
-ChunkedCodingParser::Step ChunkedCodingParser::psMessageEnd = &ChunkedCodingParser::parseMessageEnd;
-
-ChunkedCodingParser::ChunkedCodingParser()
-{
-    reset();
-}
-
-void ChunkedCodingParser::reset()
-{
-    theStep = psChunkSize;
-    theChunkSize = theLeftBodySize = 0;
-    doNeedMoreData = false;
-    theIn = theOut = NULL;
-    useOriginBody = -1;
-    inQuoted = inSlashed = false;
-}
-
-bool ChunkedCodingParser::parse(MemBuf *rawData, MemBuf *parsedContent)
-{
-    Must(rawData && parsedContent);
-    theIn = rawData;
-    theOut = parsedContent;
-
-    // we must reset this all the time so that mayContinue() lets us
-    // output more content if we stopped due to needsMoreSpace() before
-    doNeedMoreData = !theIn->hasContent();
-
-    while (mayContinue()) {
-        (this->*theStep)();
-    }
-
-    return theStep == psMessageEnd;
-}
-
-bool ChunkedCodingParser::needsMoreData() const
-{
-    return doNeedMoreData;
-}
-
-bool ChunkedCodingParser::needsMoreSpace() const
-{
-    assert(theOut);
-    return theStep == psChunkBody && !theOut->hasPotentialSpace();
-}
-
-bool ChunkedCodingParser::mayContinue() const
-{
-    return !needsMoreData() && !needsMoreSpace() && theStep != psMessageEnd;
-}
-
-void ChunkedCodingParser::parseChunkSize()
-{
-    Must(theChunkSize <= 0); // Should(), really
-
-    const char *p = theIn->content();
-    while (p < theIn->space() && xisxdigit(*p)) ++p;
-    if (p >= theIn->space()) {
-        doNeedMoreData = true;
-        return;
-    }
-
-    int64_t size = -1;
-    if (StringToInt64(theIn->content(), size, &p, 16)) {
-        if (size < 0)
-            throw TexcHere("negative chunk size");
-
-        theChunkSize = theLeftBodySize = size;
-        debugs(94,7, "found chunk: " << theChunkSize);
-        // parse chunk extensions only in the last-chunk
-        if (theChunkSize)
-            theStep = psUnusedChunkExtension;
-        else {
-            theIn->consume(p - theIn->content());
-            theStep = psLastChunkExtension;
-        }
-    } else
-        throw TexcHere("corrupted chunk size");
-}
-
-void ChunkedCodingParser::parseUnusedChunkExtension()
-{
-    size_t crlfBeg = 0;
-    size_t crlfEnd = 0;
-    if (findCrlf(crlfBeg, crlfEnd, inQuoted, inSlashed)) {
-        inQuoted = inSlashed = false;
-        theIn->consume(crlfEnd);
-        theStep = theChunkSize ? psChunkBody : psTrailer;
-    } else {
-        theIn->consume(theIn->contentSize());
-        doNeedMoreData = true;
-    }
-}
-
-void ChunkedCodingParser::parseChunkBody()
-{
-    Must(theLeftBodySize > 0); // Should, really
-
-    const size_t availSize = min(theLeftBodySize, (uint64_t)theIn->contentSize());
-    const size_t safeSize = min(availSize, (size_t)theOut->potentialSpaceSize());
-
-    doNeedMoreData = availSize < theLeftBodySize;
-    // and we may also need more space
-
-    theOut->append(theIn->content(), safeSize);
-    theIn->consume(safeSize);
-    theLeftBodySize -= safeSize;
-
-    if (theLeftBodySize == 0)
-        theStep = psChunkEnd;
-    else
-        Must(needsMoreData() || needsMoreSpace());
-}
-
-void ChunkedCodingParser::parseChunkEnd()
-{
-    Must(theLeftBodySize == 0); // Should(), really
-
-    size_t crlfBeg = 0;
-    size_t crlfEnd = 0;
-
-    if (findCrlf(crlfBeg, crlfEnd)) {
-        if (crlfBeg != 0) {
-            throw TexcHere("found data between chunk end and CRLF");
-            return;
-        }
-
-        theIn->consume(crlfEnd);
-        theChunkSize = 0; // done with the current chunk
-        theStep = psChunkSize;
-        return;
-    }
-
-    doNeedMoreData = true;
-}
-
-void ChunkedCodingParser::parseTrailer()
-{
-    Must(theChunkSize == 0); // Should(), really
-
-    while (mayContinue())
-        parseTrailerHeader();
-}
-
-void ChunkedCodingParser::parseTrailerHeader()
-{
-    size_t crlfBeg = 0;
-    size_t crlfEnd = 0;
-
-    if (findCrlf(crlfBeg, crlfEnd)) {
-
-#if TRAILERS_ARE_SUPPORTED
-        if (crlfBeg > 0)
-            theTrailer.append(theIn->content(), crlfEnd);
-#endif
-
-        theIn->consume(crlfEnd);
-
-        if (crlfBeg == 0)
-            theStep = psMessageEnd;
-
-        return;
-    }
-
-    doNeedMoreData = true;
-}
-
-void ChunkedCodingParser::parseMessageEnd()
-{
-    // termination step, should not be called
-    Must(false); // Should(), really
-}
-
-/// Finds next CRLF. Does not store parsing state.
-bool ChunkedCodingParser::findCrlf(size_t &crlfBeg, size_t &crlfEnd)
-{
-    bool quoted = false;
-    bool slashed = false;
-    return findCrlf(crlfBeg, crlfEnd, quoted, slashed);
-}
-
-/// Finds next CRLF. Parsing state stored in quoted and slashed
-/// parameters. Incremental: can resume when more data is available.
-bool ChunkedCodingParser::findCrlf(size_t &crlfBeg, size_t &crlfEnd, bool &quoted, bool &slashed)
-{
-    // XXX: This code was copied, with permission, from another software.
-    // There is a similar and probably better code inside httpHeaderParse
-    // but it seems difficult to isolate due to parsing-unrelated bloat.
-    // Such isolation should probably be done before this class is used
-    // for handling of traffic "more external" than ICAP.
-
-    const char *buf = theIn->content();
-    size_t size = theIn->contentSize();
-
-    ssize_t crOff = -1;
-
-    for (size_t i = 0; i < size; ++i) {
-        if (slashed) {
-            slashed = false;
-            continue;
-        }
-
-        const char c = buf[i];
-
-        // handle quoted strings
-        if (quoted) {
-            if (c == '\\')
-                slashed = true;
-            else if (c == '"')
-                quoted = false;
-
-            continue;
-        } else if (c == '"') {
-            quoted = true;
-            crOff = -1;
-            continue;
-        }
-
-        if (crOff < 0) { // looking for the first CR or LF
-
-            if (c == '\n') {
-                crlfBeg = i;
-                crlfEnd = ++i;
-                return true;
-            }
-
-            if (c == '\r')
-                crOff = i;
-        } else { // skipping CRs, looking for the first LF
-
-            if (c == '\n') {
-                crlfBeg = crOff;
-                crlfEnd = ++i;
-                return true;
-            }
-
-            if (c != '\r')
-                crOff = -1;
-        }
-    }
-
-    return false;
-}
-
-// chunk-extension= *( ";" chunk-ext-name [ "=" chunk-ext-val ] )
-void ChunkedCodingParser::parseLastChunkExtension()
-{
-    size_t crlfBeg = 0;
-    size_t crlfEnd = 0;
-
-    if (!findCrlf(crlfBeg, crlfEnd)) {
-        doNeedMoreData = true;
-        return;
-    }
-
-    const char *const startExt = theIn->content();
-    const char *const endExt = theIn->content() + crlfBeg;
-
-    // chunk-extension starts at startExt and ends with LF at endEx
-    for (const char *p = startExt; p < endExt;) {
-
-        while (*p == ' ' || *p == '\t') ++p; // skip spaces before ';'
-
-        if (*p++ != ';') // each ext name=value pair is preceded with ';'
-            break;
-
-        while (*p == ' ' || *p == '\t') ++p; // skip spaces before name
-
-        if (p >= endExt)
-            break; // malformed extension: ';' without ext name=value pair
-
-        const int extSize = endExt - p;
-        // TODO: we need debugData() stream manipulator to dump data
-        debugs(94,7, "Found chunk extension; size=" << extSize);
-
-        // TODO: support implied *LWS around '='
-        if (extSize > 18 && strncmp(p, "use-original-body=", 18) == 0) {
-            (void)StringToInt64(p+18, useOriginBody, &p, 10);
-            debugs(94, 3, HERE << "use-original-body=" << useOriginBody);
-            break; // remove to support more than just use-original-body
-        } else {
-            debugs(94, 5, HERE << "skipping unknown chunk extension");
-            // TODO: support quoted-string chunk-ext-val
-            while (p < endExt && *p != ';') ++p; // skip until the next ';'
-        }
-    }
-
-    theIn->consume(crlfEnd);
-    theStep = theChunkSize ? psChunkBody : psTrailer;
-}
-
@@ -1,84 +0,0 @@
-/*
- * Copyright (C) 1996-2015 The Squid Software Foundation and contributors
- *
- * Squid software is distributed under GPLv2+ license and includes
- * contributions from numerous individuals and organizations.
- * Please see the COPYING and CONTRIBUTORS files for details.
- */
-
-#ifndef SQUID_CHUNKEDCODINGPARSER_H
-#define SQUID_CHUNKEDCODINGPARSER_H
-
-class MemBuf;
-
-/**
- \ingroup ChunkEncodingAPI Chunked Encoding API
- \par
- * ChunkedCodingParser is an incremental parser for chunked transfer coding
- * used by HTTP and ICAP. The parser shovels content bytes from the raw
- * input buffer into the content output buffer, both caller-supplied.
- * Ignores chunk extensions except for ICAP's ieof.
- * Has a trailer-handling placeholder.
- */
-class ChunkedCodingParser
-{
-
-public:
-    ChunkedCodingParser();
-
-    void reset();
-
-    /**
-     \retval true    complete success
-     \retval false   needs more data
-     \throws ??      error.
-     */
-    bool parse(MemBuf *rawData, MemBuf *parsedContent);
-
-    bool needsMoreData() const;
-    bool needsMoreSpace() const;
-
-private:
-    typedef void (ChunkedCodingParser::*Step)();
-
-private:
-    bool mayContinue() const;
-
-    void parseChunkSize();
-    void parseUnusedChunkExtension();
-    void parseLastChunkExtension();
-    void parseChunkBeg();
-    void parseChunkBody();
-    void parseChunkEnd();
-    void parseTrailer();
-    void parseTrailerHeader();
-    void parseMessageEnd();
-
-    bool findCrlf(size_t &crlfBeg, size_t &crlfEnd);
-    bool findCrlf(size_t &crlfBeg, size_t &crlfEnd, bool &quoted, bool &slashed);
-
-private:
-    static Step psChunkSize;
-    static Step psUnusedChunkExtension;
-    static Step psLastChunkExtension;
-    static Step psChunkBody;
-    static Step psChunkEnd;
-    static Step psTrailer;
-    static Step psMessageEnd;
-
-    MemBuf *theIn;
-    MemBuf *theOut;
-
-    Step theStep;
-    uint64_t theChunkSize;
-    uint64_t theLeftBodySize;
-    bool doNeedMoreData;
-    bool inQuoted; ///< stores parsing state for incremental findCrlf
-    bool inSlashed; ///< stores parsing state for incremental findCrlf
-
-public:
-    int64_t useOriginBody;
-};
-
-#endif /* SQUID_CHUNKEDCODINGPARSER_H */
-
@@ -27,7 +27,7 @@ static const char *const ShmLabel = "cf";
 // TODO: make configurable or compute from squid.conf settings if possible
 static const int QueueCapacity = 1024;
 
-std::auto_ptr<CollapsedForwarding::Queue> CollapsedForwarding::queue;
+std::unique_ptr<CollapsedForwarding::Queue> CollapsedForwarding::queue;
 
 /// IPC queue message
 class CollapsedForwardingMsg
@@ -40,7 +40,7 @@ class CollapsedForwarding
 
 private:
     typedef Ipc::MultiQueue Queue;
-    static std::auto_ptr<Queue> queue; ///< IPC queue
+    static std::unique_ptr<Queue> queue; ///< IPC queue
 };
 
 #endif /* SQUID_COLLAPSED_FORWARDING_H */
@@ -67,9 +67,9 @@ ConfigParser::TokenPutBack(const char *tok)
 char *
 ConfigParser::Undo()
 {
-    LOCAL_ARRAY(char, undoToken, CONFIG_LINE_LIMIT);
+    static char undoToken[CONFIG_LINE_LIMIT];
     if (!Undo_.empty()) {
-        strncpy(undoToken, Undo_.front().c_str(), sizeof(undoToken));
+        xstrncpy(undoToken, Undo_.front().c_str(), sizeof(undoToken));
         undoToken[sizeof(undoToken) - 1] = '\0';
         if (!PreviewMode_)
             Undo_.pop();
@@ -88,7 +88,7 @@ ConfigParser::strtokFile()
     static FILE *wordFile = NULL;
 
     char *t;
-    LOCAL_ARRAY(char, buf, CONFIG_LINE_LIMIT);
+    static char buf[CONFIG_LINE_LIMIT];
 
     if ((t = ConfigParser::Undo()))
         return t;
@@ -126,7 +126,7 @@ ConfigParser::strtokFile()
         }
 
         /* fromFile */
-        if (fgets(buf, CONFIG_LINE_LIMIT, wordFile) == NULL) {
+        if (fgets(buf, sizeof(buf), wordFile) == NULL) {
             /* stop reading from file */
             fclose(wordFile);
             wordFile = NULL;
@@ -218,7 +218,7 @@ ConfigParser::UnQuote(const char *token, const char **next)
 
     if (errorStr) {
         if (PreviewMode_)
-            strncpy(UnQuoted, SQUID_ERROR_TOKEN, sizeof(UnQuoted));
+            xstrncpy(UnQuoted, SQUID_ERROR_TOKEN, sizeof(UnQuoted));
         else {
             debugs(3, DBG_CRITICAL, "FATAL: " << errorStr << ": " << errorPos);
             self_destruct();
@@ -21,9 +21,10 @@
  */
 
 #include "squid.h"
-#include "AIODiskFile.h"
-#include "AIODiskIOStrategy.h"
+#include "Debug.h"
 #include "disk.h"
+#include "DiskIO/AIO/AIODiskFile.h"
+#include "DiskIO/AIO/AIODiskIOStrategy.h"
 #include "DiskIO/IORequestor.h"
 #include "DiskIO/ReadRequest.h"
 #include "DiskIO/WriteRequest.h"
@@ -9,10 +9,10 @@
 #ifndef SQUID_AIODISKFILE_H
 #define SQUID_AIODISKFILE_H
 
-#if USE_DISKIO_AIO
+#if HAVE_DISKIO_MODULE_AIO
 
-#include "async_io.h"
 #include "cbdata.h"
+#include "DiskIO/AIO/async_io.h"
 #include "DiskIO/DiskFile.h"
 #include "SquidString.h"
 
@@ -56,6 +56,6 @@ class AIODiskFile : public DiskFile
     bool error_;
 };
 
-#endif /* USE_DISKIO_AIO */
+#endif /* HAVE_DISKIO_MODULE_AIO */
 #endif /* SQUID_AIODISKFILE_H */
 
@@ -7,8 +7,8 @@
  */
 
 #include "squid.h"
-#include "AIODiskIOModule.h"
-#include "AIODiskIOStrategy.h"
+#include "DiskIO/AIO/AIODiskIOModule.h"
+#include "DiskIO/AIO/AIODiskIOStrategy.h"
 #include "Store.h"
 
 AIODiskIOModule::AIODiskIOModule()
@@ -9,7 +9,7 @@
 #ifndef SQUID_AIODISKIOMODULE_H
 #define SQUID_AIODISKIOMODULE_H
 
-#if USE_DISKIO_AIO
+#if HAVE_DISKIO_MODULE_AIO
 
 #include "DiskIO/DiskIOModule.h"
 
@@ -28,6 +28,6 @@ class AIODiskIOModule : public DiskIOModule
     static AIODiskIOModule Instance;
 };
 
-#endif /* USE_DISKIO_AIO */
+#endif /* HAVE_DISKIO_MODULE_AIO */
 #endif /* SQUID_AIODISKIOMODULE_H */
 
@@ -19,8 +19,8 @@
  */
 
 #include "squid.h"
-#include "AIODiskFile.h"
-#include "AIODiskIOStrategy.h"
+#include "DiskIO/AIO/AIODiskFile.h"
+#include "DiskIO/AIO/AIODiskIOStrategy.h"
 #include "DiskIO/IORequestor.h"
 #include "DiskIO/ReadRequest.h"
 #include "DiskIO/WriteRequest.h"
@@ -101,8 +101,8 @@ int
 AIODiskIOStrategy::callback()
 {
     return 0;
+#if 0
     int i;
-    int completed = 0;
     int retval, reterr;
     FREE *freefunc;
     void *cbdata;
@@ -168,7 +168,8 @@ AIODiskIOStrategy::callback()
         }
     }
 
-    return completed;
+    return 0;
+#endif
 }
 
 void
@@ -6,12 +6,12 @@
  * Please see the COPYING and CONTRIBUTORS files for details.
  */
 
-#ifndef SQUID_AIODISKIOSTRATEGY_H
-#define SQUID_AIODISKIOSTRATEGY_H
+#ifndef SQUID_SRC_DISKIO_AIO_AIODISKIOSTRATEGY_H
+#define SQUID_SRC_DISKIO_AIO_AIODISKIOSTRATEGY_H
 
-#if USE_DISKIO_AIO
+#if HAVE_DISKIO_MODULE_AIO
 
-#include "async_io.h"
+#include "DiskIO/AIO/async_io.h"
 #include "DiskIO/DiskIOStrategy.h"
 
 class AIODiskIOStrategy : public DiskIOStrategy
@@ -51,6 +51,6 @@ class AIODiskIOStrategy : public DiskIOStrategy
     int findSlot();
 };
 
-#endif /* USE_DISKIO_AIO */
-#endif /* SQUID_AIODISKIOSTRATEGY_H */
+#endif /* HAVE_DISKIO_MODULE_AIO */
+#endif /* SQUID_SRC_DISKIO_AIO_AIODISKIOSTRATEGY_H */
 
@@ -0,0 +1,31 @@
+## Copyright (C) 1996-2015 The Squid Software Foundation and contributors
+##
+## Squid software is distributed under GPLv2+ license and includes
+## contributions from numerous individuals and organizations.
+## Please see the COPYING and CONTRIBUTORS files for details.
+##
+
+include $(top_srcdir)/src/Common.am
+include $(top_srcdir)/src/TestHeaders.am
+
+noinst_LTLIBRARIES = libAIO.la
+
+libAIO_la_SOURCES = \
+	async_io.h \
+	AIODiskFile.cc \
+	AIODiskFile.h \
+	AIODiskIOModule.cc \
+	AIODiskIOModule.h \
+	AIODiskIOStrategy.cc \
+	AIODiskIOStrategy.h
+
+if ENABLE_WIN32_AIO
+libAIO_la_SOURCES += \
+	aio_win32.cc \
+	aio_win32.h
+else
+EXTRA_DIST = \
+	aio_win32.cc \
+	aio_win32.h
+endif
+
@@ -9,7 +9,7 @@
 #ifndef __WIN32_AIO_H__
 #define __WIN32_AIO_H__
 
-#if USE_DISKIO_AIO
+#if HAVE_DISKIO_MODULE_AIO
 
 #ifndef off64_t
 typedef int64_t off64_t;
@@ -78,6 +78,6 @@ int aio_open(const char *, int);
 void aio_close(int);
 
 #endif /* _SQUID_WINDOWS_ */
-#endif /* USE_DISKIO_AIO */
+#endif /* HAVE_DISKIO_MODULE_AIO */
 #endif /* __WIN32_AIO_H__ */
 
@@ -9,10 +9,10 @@
 #ifndef __ASYNC_IO_H__
 #define __ASYNC_IO_H__
 
-#if USE_DISKIO_AIO
+#if HAVE_DISKIO_MODULE_AIO
 
 #if _SQUID_WINDOWS_
-#include "aio_win32.h"
+#include "DiskIO/AIO/aio_win32.h"
 #else
 #if HAVE_AIO_H
 #include <aio.h>
@@ -73,6 +73,6 @@ struct _async_queue {
     int aq_numpending;      /* Num of pending ops */
 };
 
-#endif /* USE_DISKIO_AIO */
+#endif /* HAVE_DISKIO_MODULE_AIO */
 #endif /* __ASYNC_IO_H_ */
 
@@ -0,0 +1,19 @@
+## Copyright (C) 1996-2015 The Squid Software Foundation and contributors
+##
+## Squid software is distributed under GPLv2+ license and includes
+## contributions from numerous individuals and organizations.
+## Please see the COPYING and CONTRIBUTORS files for details.
+##
+
+include $(top_srcdir)/src/Common.am
+include $(top_srcdir)/src/TestHeaders.am
+
+noinst_LTLIBRARIES = libBlocking.la
+
+libBlocking_la_SOURCES = \
+	BlockingDiskIOModule.cc \
+	BlockingDiskIOModule.h \
+	BlockingFile.cc \
+	BlockingFile.h \
+	BlockingIOStrategy.cc \
+	BlockingIOStrategy.h
@@ -348,8 +348,11 @@ DiskdFile::readDone(diomsg * M)
     ReadRequest::Pointer readRequest = dynamic_cast<ReadRequest *>(M->requestor);
 
     /* remove the free protection */
-    if (readRequest != NULL)
-        readRequest->unlock();
+    if (readRequest != NULL) {
+        const uint32_t lcount = readRequest->unlock();
+        if (lcount == 0)
+            debugs(79, DBG_IMPORTANT, "invariant check failed: readRequest reference count is 0");
+    }
 
     if (M->status < 0) {
         ++diskd_stats.read.fail;
@@ -372,9 +375,13 @@ DiskdFile::writeDone(diomsg *M)
     debugs(79, 3, "storeDiskdWriteDone: status " << M->status);
     assert (M->requestor);
     WriteRequest::Pointer writeRequest = dynamic_cast<WriteRequest *>(M->requestor);
+
     /* remove the free protection */
-    if (writeRequest != NULL)
-        writeRequest->unlock();
+    if (writeRequest != NULL) {
+        const uint32_t lcount = writeRequest->unlock();
+        if (lcount == 0)
+            debugs(79, DBG_IMPORTANT, "invariant check failed: writeRequest reference count is 0");
+    }
 
     if (M->status < 0) {
         errorOccured = true;
@@ -19,17 +19,13 @@ class SharedMemory
 
 public:
     void put(ssize_t);
-
     void *get(ssize_t *);
-
     void init(int ikey, int magic2);
+    SharedMemory() : nbufs(0), buf(nullptr), inuse_map(nullptr), id(0) {}
 
     int nbufs;
-
     char *buf;
-
     char *inuse_map;
-
     int id;
 };
 
@@ -0,0 +1,37 @@
+## Copyright (C) 1996-2015 The Squid Software Foundation and contributors
+##
+## Squid software is distributed under GPLv2+ license and includes
+## contributions from numerous individuals and organizations.
+## Please see the COPYING and CONTRIBUTORS files for details.
+##
+
+include $(top_srcdir)/src/Common.am
+include $(top_srcdir)/src/TestHeaders.am
+
+noinst_LTLIBRARIES = libDiskDaemon.la
+libexec_PROGRAMS = diskd
+
+libDiskDaemon_la_SOURCES = \
+	diomsg.h \
+	DiskdAction.cc \
+	DiskdAction.h \
+	DiskdFile.cc \
+	DiskdFile.h \
+	DiskdIOStrategy.cc \
+	DiskdIOStrategy.h \
+	DiskDaemonDiskIOModule.cc \
+	DiskDaemonDiskIOModule.h
+
+diskd_SOURCES = diskd.cc
+nodist_diskd_SOURCES = time.cc
+diskd_LDADD = \
+	$(top_builddir)/lib/libmisccontainers.la \
+	$(top_builddir)/lib/libmiscencoding.la \
+	$(top_builddir)/lib/libmiscutil.la \
+	$(COMPAT_LIB) \
+	$(XTRA_LIBS)
+
+time.cc: $(top_srcdir)/src/time.cc
+	cp $(top_srcdir)/src/time.cc time.cc
+
+CLEANFILES += time.cc
@@ -10,6 +10,24 @@
 
 #include "squid.h"
 #include "DiskIOModule.h"
+#if HAVE_DISKIO_MODULE_AIO
+#include "DiskIO/AIO/AIODiskIOModule.h"
+#endif
+#if HAVE_DISKIO_MODULE_BLOCKING
+#include "DiskIO/Blocking/BlockingDiskIOModule.h"
+#endif
+#if HAVE_DISKIO_MODULE_DISKDAEMON
+#include "DiskIO/DiskDaemon/DiskDaemonDiskIOModule.h"
+#endif
+#if HAVE_DISKIO_MODULE_DISKTHREADS
+#include "DiskIO/DiskThreads/DiskThreadsDiskIOModule.h"
+#endif
+#if HAVE_DISKIO_MODULE_IPCIO
+#include "DiskIO/IpcIo/IpcIoDiskIOModule.h"
+#endif
+#if HAVE_DISKIO_MODULE_DISKTHREADS
+#include "DiskIO/Mmapped/MmappedDiskIOModule.h"
+#endif
 
 std::vector<DiskIOModule*> *DiskIOModule::_Modules = NULL;
 
@@ -19,14 +37,31 @@ DiskIOModule::DiskIOModule()
 {
     /** We cannot call ModuleAdd(*this)
      * here as the virtual methods are not yet available.
-     * We leave that to PokeAllModules() later.
+     * We leave that to SetupAllModules() later.
      */
 }
 
 void
 DiskIOModule::SetupAllModules()
 {
-    DiskIOModule::PokeAllModules();
+#if HAVE_DISKIO_MODULE_AIO
+    AIODiskIOModule::GetInstance();
+#endif
+#if HAVE_DISKIO_MODULE_BLOCKING
+    BlockingDiskIOModule::GetInstance();
+#endif
+#if HAVE_DISKIO_MODULE_DISKDAEMON
+    DiskDaemonDiskIOModule::GetInstance();
+#endif
+#if HAVE_DISKIO_MODULE_DISKTHREADS
+    DiskThreadsDiskIOModule::GetInstance();
+#endif
+#if HAVE_DISKIO_MODULE_IPCIO
+    IpcIoDiskIOModule::GetInstance();
+#endif
+#if HAVE_DISKIO_MODULE_MMAPPED
+    MmappedDiskIOModule::GetInstance();
+#endif
 
     for (iterator i = GetModules().begin(); i != GetModules().end(); ++i)
         /* Call the FS to set up capabilities and initialize the FS driver */
@@ -21,13 +21,11 @@ class DiskIOModule
 {
 
 public:
+    /** Poke all compiled modules for self-setup */
     static void SetupAllModules();
     static void ModuleAdd(DiskIOModule &);
     static void FreeAllModules();
 
-    /** Poke all compiled modules for self-setup */
-    static void PokeAllModules();
-
     static DiskIOModule *Find(char const *type);
 
     /** Find *any* usable disk module. This will look for the 'best'
@@ -0,0 +1,32 @@
+## Copyright (C) 1996-2015 The Squid Software Foundation and contributors
+##
+## Squid software is distributed under GPLv2+ license and includes
+## contributions from numerous individuals and organizations.
+## Please see the COPYING and CONTRIBUTORS files for details.
+##
+
+include $(top_srcdir)/src/Common.am
+include $(top_srcdir)/src/TestHeaders.am
+
+noinst_LTLIBRARIES = libDiskThreads.la
+
+libDiskThreads_la_SOURCES = \
+	async_io.cc \
+	CommIO.cc \
+	CommIO.h \
+	DiskThreads.h \
+	DiskThreadsDiskFile.cc \
+	DiskThreadsDiskFile.h \
+	DiskThreadsDiskIOModule.cc \
+	DiskThreadsDiskIOModule.h \
+	DiskThreadsIOStrategy.cc \
+	DiskThreadsIOStrategy.h
+
+if ENABLE_WIN32_AIOPS
+libDiskThreads_la_SOURCES += aiops_win32.cc
+EXTRA_DIST = aiops.cc
+else
+libDiskThreads_la_SOURCES += aiops.cc
+EXTRA_DIST = aiops_win32.cc
+endif
+
@@ -506,13 +506,13 @@ squidaio_queue_request(squidaio_request_t * request)
     }
 
     if (request_queue2.head) {
-        static int filter = 0;
-        static int filter_limit = 8;
+        static uint64_t filter = 0;
+        static uint64_t filter_limit = 8192;
 
         if (++filter >= filter_limit) {
             filter_limit += filter;
             filter = 0;
-            debugs(43, DBG_IMPORTANT, "squidaio_queue_request: WARNING - Queue congestion");
+            debugs(43, DBG_IMPORTANT, "squidaio_queue_request: WARNING - Queue congestion (growing to " << filter_limit << ")");
         }
     }
 
@@ -582,13 +582,13 @@ squidaio_queue_request(squidaio_request_t * request)
     }
 
     if (request_queue2.head) {
-        static int filter = 0;
-        static int filter_limit = 8;
+        static uint64_t filter = 0;
+        static uint64_t filter_limit = 8196;
 
         if (++filter >= filter_limit) {
             filter_limit += filter;
             filter = 0;
-            debugs(43, DBG_IMPORTANT, "squidaio_queue_request: WARNING - Queue congestion");
+            debugs(43, DBG_IMPORTANT, "squidaio_queue_request: WARNING - Queue congestion (growing to " << filter_limit << ")");
         }
     }
 
@@ -45,7 +45,7 @@ static const int QueueCapacity = 1024;
 const double IpcIoFile::Timeout = 7; // seconds;  XXX: ALL,9 may require more
 IpcIoFile::IpcIoFileList IpcIoFile::WaitingForOpen;
 IpcIoFile::IpcIoFilesMap IpcIoFile::IpcIoFiles;
-std::auto_ptr<IpcIoFile::Queue> IpcIoFile::queue;
+std::unique_ptr<IpcIoFile::Queue> IpcIoFile::queue;
 
 bool IpcIoFile::DiskerHandleMoreRequestsScheduled = false;
 
@@ -113,8 +113,7 @@ IpcIoFile::open(int flags, mode_t mode, RefCount<IORequestor> callback)
             IpcIoFiles.insert(std::make_pair(diskId, this)).second;
         Must(inserted);
 
-        queue->localRateLimit() =
-            static_cast<Ipc::QueueReader::Rate::Value>(config.ioRate);
+        queue->localRateLimit().store(config.ioRate);
 
         Ipc::HereIamMessage ann(Ipc::StrandCoord(KidIdentifier, getpid()));
         ann.strand.tag = dbName;
@@ -396,7 +395,7 @@ IpcIoFile::canWait() const
     const int oldestWait = tvSubMsec(oldestIo.start, current_time);
 
     int rateWait = -1; // time in millisecons
-    const Ipc::QueueReader::Rate::Value ioRate = queue->rateLimit(diskId);
+    const int ioRate = queue->rateLimit(diskId).load();
     if (ioRate > 0) {
         // if there are N requests pending, the new one will wait at
         // least N/max-swap-rate seconds
@@ -750,7 +749,7 @@ IpcIoFile::DiskerHandleMoreRequests(void *source)
 bool
 IpcIoFile::WaitBeforePop()
 {
-    const Ipc::QueueReader::Rate::Value ioRate = queue->localRateLimit();
+    const int ioRate = queue->localRateLimit().load();
     const double maxRate = ioRate/1e3; // req/ms
 
     // do we need to enforce configured I/O rate?
@@ -140,7 +140,7 @@ class IpcIoFile: public DiskFile
     static IpcIoFilesMap IpcIoFiles;
 
     typedef Ipc::FewToFewBiQueue Queue;
-    static std::auto_ptr<Queue> queue; ///< IPC queue
+    static std::unique_ptr<Queue> queue; ///< IPC queue
 
     /// whether we are waiting for an event to handle still queued I/O requests
     static bool DiskerHandleMoreRequestsScheduled;
@@ -0,0 +1,19 @@
+## Copyright (C) 1996-2015 The Squid Software Foundation and contributors
+##
+## Squid software is distributed under GPLv2+ license and includes
+## contributions from numerous individuals and organizations.
+## Please see the COPYING and CONTRIBUTORS files for details.
+##
+
+include $(top_srcdir)/src/Common.am
+include $(top_srcdir)/src/TestHeaders.am
+
+noinst_LTLIBRARIES = libIpcIo.la
+
+libIpcIo_la_SOURCES = \
+	IpcIoDiskIOModule.cc \
+	IpcIoDiskIOModule.h \
+	IpcIoFile.cc \
+	IpcIoFile.h \
+	IpcIoIOStrategy.cc \
+	IpcIoIOStrategy.h
@@ -0,0 +1,61 @@
+## Copyright (C) 1996-2015 The Squid Software Foundation and contributors
+##
+## Squid software is distributed under GPLv2+ license and includes
+## contributions from numerous individuals and organizations.
+## Please see the COPYING and CONTRIBUTORS files for details.
+##
+
+include $(top_srcdir)/src/Common.am
+include $(top_srcdir)/src/TestHeaders.am
+
+SUBDIRS=
+DIST_SUBDIRS= AIO Blocking DiskDaemon DiskThreads IpcIo Mmapped
+
+noinst_LTLIBRARIES = libdiskio.la
+
+libdiskio_la_SOURCES = \
+	DiskFile.h \
+	DiskIOModule.cc \
+	DiskIOModule.h \
+	DiskIOStrategy.h \
+	IORequestor.h \
+	ReadRequest.cc \
+	ReadRequest.h \
+	WriteRequest.cc \
+	WriteRequest.h
+
+# Custom DiskIO modules (if any):
+libdiskio_la_LIBADD = $(DISK_LIBS)
+
+# Optional DiskIO modules:
+
+if ENABLE_DISKIO_AIO
+SUBDIRS += AIO
+libdiskio_la_LIBADD += AIO/libAIO.la $(AIOLIB)
+endif
+
+if ENABLE_DISKIO_BLOCKING
+SUBDIRS += Blocking
+libdiskio_la_LIBADD += Blocking/libBlocking.la
+endif
+
+if ENABLE_DISKIO_DISKDAEMON
+SUBDIRS += DiskDaemon
+libdiskio_la_LIBADD += DiskDaemon/libDiskDaemon.la
+endif
+
+if ENABLE_DISKIO_DISKTHREADS
+SUBDIRS += DiskThreads
+libdiskio_la_LIBADD += DiskThreads/libDiskThreads.la $(LIBPTHREADS)
+endif
+
+if ENABLE_DISKIO_IPCIO
+SUBDIRS += IpcIo
+libdiskio_la_LIBADD += IpcIo/libIpcIo.la
+endif
+
+if ENABLE_DISKIO_MMAPPED
+SUBDIRS += Mmapped
+libdiskio_la_LIBADD += Mmapped/libMmapped.la
+endif
+
@@ -0,0 +1,19 @@
+## Copyright (C) 1996-2015 The Squid Software Foundation and contributors
+##
+## Squid software is distributed under GPLv2+ license and includes
+## contributions from numerous individuals and organizations.
+## Please see the COPYING and CONTRIBUTORS files for details.
+##
+
+include $(top_srcdir)/src/Common.am
+include $(top_srcdir)/src/TestHeaders.am
+
+noinst_LTLIBRARIES = libMmapped.la
+
+libMmapped_la_SOURCES = \
+	MmappedDiskIOModule.cc \
+	MmappedDiskIOModule.h \
+	MmappedFile.cc \
+	MmappedFile.h \
+	MmappedIOStrategy.cc \
+	MmappedIOStrategy.h
@@ -1,25 +0,0 @@
-#!/bin/sh
-#
-## Copyright (C) 1996-2015 The Squid Software Foundation and contributors
-##
-## Squid software is distributed under GPLv2+ license and includes
-## contributions from numerous individuals and organizations.
-## Please see the COPYING and CONTRIBUTORS files for details.
-##
-
-echo "/* automatically generated by $0 $*"
-echo " * do not edit"
-echo " */"
-cat `dirname $0`/../../scripts/boilerplate.h
-echo "#include \"squid.h\""
-echo "#include \"DiskIO/DiskIOModule.h\""
-for module in "$@"; do
-   echo "#include \"DiskIO/${module}/${module}DiskIOModule.h\""
-done
-echo ""
-echo "void DiskIOModule::PokeAllModules(void)"
-echo "{"
-for module in "$@"; do
-   echo "    ${module}DiskIOModule::GetInstance();"
-done
-echo "}"
@@ -58,6 +58,8 @@
 #include "ssl/PeerConnector.h"
 #include "ssl/ServerBump.h"
 #include "ssl/support.h"
+#else
+#include "security/EncryptorAnswer.h"
 #endif
 
 #include <cerrno>
@@ -78,7 +80,7 @@ CBDATA_CLASS_INIT(FwdState);
 class FwdStatePeerAnswerDialer: public CallDialer, public Ssl::PeerConnector::CbDialer
 {
 public:
-    typedef void (FwdState::*Method)(Ssl::PeerConnectorAnswer &);
+    typedef void (FwdState::*Method)(Security::EncryptorAnswer &);
 
     FwdStatePeerAnswerDialer(Method method, FwdState *fwd):
         method_(method), fwd_(fwd), answer_() {}
@@ -91,12 +93,12 @@ class FwdStatePeerAnswerDialer: public CallDialer, public Ssl::PeerConnector::Cb
     }
 
     /* Ssl::PeerConnector::CbDialer API */
-    virtual Ssl::PeerConnectorAnswer &answer() { return answer_; }
+    virtual Security::EncryptorAnswer &answer() { return answer_; }
 
 private:
     Method method_;
     CbcPointer<FwdState> fwd_;
-    Ssl::PeerConnectorAnswer answer_;
+    Security::EncryptorAnswer answer_;
 };
 #endif
 
@@ -127,18 +129,24 @@ FwdState::closeServerConnection(const char *reason)
 /**** PUBLIC INTERFACE ********************************************************/
 
 FwdState::FwdState(const Comm::ConnectionPointer &client, StoreEntry * e, HttpRequest * r, const AccessLogEntryPointer &alp):
-    al(alp)
+    entry(e),
+    request(r),
+    al(alp),
+    err(NULL),
+    clientConn(client),
+    start_t(squid_curtime),
+    n_tries(0),
+    pconnRace(raceImpossible)
 {
-    debugs(17, 2, HERE << "Forwarding client request " << client << ", url=" << e->url() );
-    entry = e;
-    clientConn = client;
-    request = r;
+    debugs(17, 2, "Forwarding client request " << client << ", url=" << e->url());
     HTTPMSGLOCK(request);
-    pconnRace = raceImpossible;
-    start_t = squid_curtime;
     serverDestinations.reserve(Config.forward_max_tries);
     e->lock("FwdState");
     EBIT_SET(e->flags, ENTRY_FWD_HDR_WAIT);
+    flags.connected_okay = false;
+    flags.dont_retry = false;
+    flags.forward_completed = false;
+    debugs(17, 3, "FwdState constructed, this=" << this);
 }
 
 // Called once, right after object creation, when it is safe to set self
@@ -259,7 +267,7 @@ FwdState::completed()
 
 FwdState::~FwdState()
 {
-    debugs(17, 3, HERE << "FwdState destructor starting");
+    debugs(17, 3, "FwdState destructor start");
 
     if (! flags.forward_completed)
         completed();
@@ -286,7 +294,7 @@ FwdState::~FwdState()
 
     serverDestinations.clear();
 
-    debugs(17, 3, HERE << "FwdState destructor done");
+    debugs(17, 3, "FwdState destructed, this=" << this);
 }
 
 /**
@@ -392,7 +400,7 @@ FwdState::startConnectionOrFail()
         // Done here before anything else so the errors get logged for
         // this server link regardless of what happens when connecting to it.
         // IF sucessfuly connected this top destination will become the serverConnection().
-        request->hier.note(serverDestinations[0], request->GetHost());
+        request->hier.note(serverDestinations[0], request->url.host());
         request->clearError();
 
         connectStart();
@@ -625,7 +633,7 @@ FwdState::retryOrBail()
 
     request->hier.stopPeerClock(false);
 
-    if (self != NULL && !err && shutting_down) {
+    if (self != NULL && !err && shutting_down && entry->isEmpty()) {
         ErrorState *anErr = new ErrorState(ERR_SHUTTING_DOWN, Http::scServiceUnavailable, request);
         errorAppendEntry(entry, anErr);
     }
@@ -683,34 +691,35 @@ FwdState::connectDone(const Comm::ConnectionPointer &conn, Comm::Flag status, in
 
 #if USE_OPENSSL
     if (!request->flags.pinned) {
-        if ((serverConnection()->getPeer() && serverConnection()->getPeer()->use_ssl) ||
-                (!serverConnection()->getPeer() && request->url.getScheme() == AnyP::PROTO_HTTPS) ||
-                request->flags.sslPeek) {
-
+        const CachePeer *p = serverConnection()->getPeer();
+        const bool peerWantsTls = p && p->secure.encryptTransport;
+        // userWillSslToPeerForUs assumes CONNECT == HTTPS
+        const bool userWillTlsToPeerForUs = p && p->options.originserver &&
+                                            request->method == Http::METHOD_CONNECT;
+        const bool needTlsToPeer = peerWantsTls && !userWillTlsToPeerForUs;
+        const bool needTlsToOrigin = !p && request->url.getScheme() == AnyP::PROTO_HTTPS;
+        if (needTlsToPeer || needTlsToOrigin || request->flags.sslPeek) {
             HttpRequest::Pointer requestPointer = request;
             AsyncCall::Pointer callback = asyncCall(17,4,
                                                     "FwdState::ConnectedToPeer",
                                                     FwdStatePeerAnswerDialer(&FwdState::connectedToPeer, this));
             // Use positive timeout when less than one second is left.
             const time_t sslNegotiationTimeout = max(static_cast<time_t>(1), timeLeft());
-            Ssl::PeerConnector *connector =
-                new Ssl::PeerConnector(requestPointer, serverConnection(), clientConn, callback, sslNegotiationTimeout);
+            Ssl::PeekingPeerConnector *connector =
+                new Ssl::PeekingPeerConnector(requestPointer, serverConnection(), clientConn, callback, sslNegotiationTimeout);
             AsyncJob::Start(connector); // will call our callback
             return;
         }
     }
 #endif
 
-    // should reach ConnStateData before the dispatched Client job starts
-    CallJobHere1(17, 4, request->clientConnectionManager, ConnStateData,
-                 ConnStateData::notePeerConnection, serverConnection());
-
-    dispatch();
+    // if not encrypting just run the post-connect actions
+    Security::EncryptorAnswer nil;
+    connectedToPeer(nil);
 }
 
-#if USE_OPENSSL
 void
-FwdState::connectedToPeer(Ssl::PeerConnectorAnswer &answer)
+FwdState::connectedToPeer(Security::EncryptorAnswer &answer)
 {
     if (ErrorState *error = answer.error.get()) {
         fail(error);
@@ -719,9 +728,12 @@ FwdState::connectedToPeer(Ssl::PeerConnectorAnswer &answer)
         return;
     }
 
+    // should reach ConnStateData before the dispatched Client job starts
+    CallJobHere1(17, 4, request->clientConnectionManager, ConnStateData,
+                 ConnStateData::notePeerConnection, serverConnection());
+
     dispatch();
 }
-#endif
 
 void
 FwdState::connectTimeout(int fd)
@@ -782,7 +794,9 @@ FwdState::connectStart()
 
     request->hier.startPeerClock();
 
-    if (serverDestinations[0]->getPeer() && request->flags.sslBumped) {
+    // Do not fowrward bumped connections to parent proxy unless it is an
+    // origin server
+    if (serverDestinations[0]->getPeer() && !serverDestinations[0]->getPeer()->options.originserver && request->flags.sslBumped) {
         debugs(50, 4, "fwdConnectStart: Ssl bumped connections through parent proxy are not allowed");
         ErrorState *anErr = new ErrorState(ERR_CANNOT_FORWARD, Http::scServiceUnavailable, request);
         fail(anErr);
@@ -840,7 +854,7 @@ FwdState::connectStart()
     // Use pconn to avoid opening a new connection.
     const char *host = NULL;
     if (!serverDestinations[0]->getPeer())
-        host = request->GetHost();
+        host = request->url.host();
 
     Comm::ConnectionPointer temp;
     // Avoid pconns after races so that the same client does not suffer twice.
@@ -918,7 +932,7 @@ FwdState::dispatch()
 
     EBIT_SET(entry->flags, ENTRY_DISPATCHED);
 
-    netdbPingSite(request->GetHost());
+    netdbPingSite(request->url.host());
 
     /* Retrieves remote server TOS or MARK value, and stores it as part of the
      * original client request FD object. It is later used to forward
@@ -1249,7 +1263,7 @@ getOutgoingAddress(HttpRequest * request, Comm::ConnectionPointer conn)
     }
 
     ACLFilledChecklist ch(NULL, request, NULL);
-    ch.dst_peer = conn->getPeer();
+    ch.dst_peer_name = conn->getPeer() ? conn->getPeer()->name : NULL;
     ch.dst_addr = conn->remote;
 
     // TODO use the connection details in ACL.
@@ -16,6 +16,7 @@
 #include "fde.h"
 #include "http/StatusCode.h"
 #include "ip/Address.h"
+#include "security/forward.h"
 #if USE_OPENSSL
 #include "ssl/support.h"
 #endif
@@ -34,7 +35,6 @@ namespace Ssl
 {
 class ErrorDetail;
 class CertValidationResponse;
-class PeerConnectorAnswer;
 };
 #endif
 
@@ -114,9 +114,7 @@ class FwdState : public RefCountable
     void completed();
     void retryOrBail();
     ErrorState *makeConnectingError(const err_type type) const;
-#if USE_OPENSSL
-    void connectedToPeer(Ssl::PeerConnectorAnswer &answer);
-#endif
+    void connectedToPeer(Security::EncryptorAnswer &answer);
     static void RegisterWithCacheManager(void);
 
     /// stops monitoring server connection for closure and updates pconn stats
@@ -39,11 +39,11 @@ HttpBody::setMb(MemBuf * mb_)
 }
 
 void
-HttpBody::packInto(Packer * p) const
+HttpBody::packInto(Packable * p) const
 {
     assert(p);
 
     if (mb->contentSize())
-        packerAppend(p, mb->content(), mb->contentSize());
+        p->append(mb->content(), mb->contentSize());
 }
 
@@ -10,7 +10,6 @@
 #define HTTPBODY_H_
 
 #include "MemBuf.h"
-class Packer;
 
 /** Representation of a short predetermined message
  *
@@ -28,11 +27,12 @@ class HttpBody
      * by the HttpBody.
      */
     void setMb(MemBuf *);
-    /** output the HttpBody contents into the supplied packer
+
+    /** output the HttpBody contents into the supplied container
      *
      * \note content is not cleared by the output operation
      */
-    void packInto(Packer *) const;
+    void packInto(Packable *) const;
 
     /// clear the HttpBody content
     void clear();
@@ -251,7 +251,7 @@ HttpHdrCc::parse(const String & str)
 }
 
 void
-HttpHdrCc::packInto(Packer * p) const
+HttpHdrCc::packInto(Packable * p) const
 {
     // optimization: if the mask is empty do nothing
     if (mask==0)
@@ -265,24 +265,24 @@ HttpHdrCc::packInto(Packer * p) const
         if (isSet(flag) && flag != CC_OTHER) {
 
             /* print option name for all options */
-            packerPrintf(p, (pcount ? ", %s": "%s") , CcAttrs[flag].name);
+            p->appendf((pcount ? ", %s": "%s") , CcAttrs[flag].name);
 
             /* for all options having values, "=value" after the name */
             switch (flag) {
             case CC_MAX_AGE:
-                packerPrintf(p, "=%d", (int) maxAge());
+                p->appendf("=%d", maxAge());
                 break;
             case CC_S_MAXAGE:
-                packerPrintf(p, "=%d", (int) sMaxAge());
+                p->appendf("=%d", sMaxAge());
                 break;
             case CC_MAX_STALE:
                 /* max-stale's value is optional.
                   If we didn't receive it, don't send it */
                 if (maxStale()!=MAX_STALE_ANY)
-                    packerPrintf(p, "=%d", (int) maxStale());
+                    p->appendf("=%d", maxStale());
                 break;
             case CC_MIN_FRESH:
-                packerPrintf(p, "=%d", (int) minFresh());
+                p->appendf("=%d", minFresh());
                 break;
             default:
                 /* do nothing, directive was already printed */
@@ -294,8 +294,7 @@ HttpHdrCc::packInto(Packer * p) const
     }
 
     if (other.size() != 0)
-        packerPrintf(p, (pcount ? ", " SQUIDSTRINGPH : SQUIDSTRINGPH),
-                     SQUIDSTRINGPRINT(other));
+        p->appendf((pcount ? ", " SQUIDSTRINGPH : SQUIDSTRINGPH), SQUIDSTRINGPRINT(other));
 }
 
 void
@@ -13,7 +13,7 @@
 #include "mem/forward.h"
 #include "SquidString.h"
 
-class Packer;
+class Packable;
 
 /** Http Cache-Control header representation
  *
@@ -144,7 +144,7 @@ class HttpHdrCc
     /// check whether the attribute value supplied by id is set
     _SQUID_INLINE_ bool isSet(http_hdr_cc_type id) const;
 
-    void packInto(Packer * p) const;
+    void packInto(Packable * p) const;
 
     /** bit-mask representing what header values are set among those
      * recognized by squid.
@@ -9,6 +9,7 @@
 /* DEBUG: section 68    HTTP Content-Range Header */
 
 #include "squid.h"
+#include "base/Packable.h"
 #include "Debug.h"
 #include "enums.h"
 #include "HttpHdrContRange.h"
@@ -98,16 +99,15 @@ httpHdrRangeRespSpecParseInit(HttpHdrRangeSpec * spec, const char *field, int fl
 }
 
 static void
-httpHdrRangeRespSpecPackInto(const HttpHdrRangeSpec * spec, Packer * p)
+httpHdrRangeRespSpecPackInto(const HttpHdrRangeSpec * spec, Packable * p)
 {
     /* Ensure typecast is safe */
     assert (spec->length >= 0);
 
     if (!known_spec(spec->offset) || !known_spec(spec->length))
-        packerPrintf(p, "*");
+        p->append("*", 1);
     else
-        packerPrintf(p, "bytes %" PRId64 "-%" PRId64,
-                     spec->offset, spec->offset + spec->length - 1);
+        p->appendf("bytes %" PRId64 "-%" PRId64, spec->offset, spec->offset + spec->length - 1);
 }
 
 /*
@@ -200,17 +200,17 @@ httpHdrContRangeDup(const HttpHdrContRange * range)
 }
 
 void
-httpHdrContRangePackInto(const HttpHdrContRange * range, Packer * p)
+httpHdrContRangePackInto(const HttpHdrContRange * range, Packable * p)
 {
     assert(range && p);
     httpHdrRangeRespSpecPackInto(&range->spec, p);
     /* Ensure typecast is safe */
     assert (range->elength >= 0);
 
     if (!known_spec(range->elength))
-        packerPrintf(p, "/*");
+        p->append("/*", 2);
     else
-        packerPrintf(p, "/%" PRId64, range->elength);
+        p->appendf("/%" PRId64, range->elength);
 }
 
 void
@@ -31,7 +31,7 @@ HttpHdrContRange *httpHdrContRangeParseCreate(const char *crange_spec);
 int httpHdrContRangeParseInit(HttpHdrContRange * crange, const char *crange_spec);
 void httpHdrContRangeDestroy(HttpHdrContRange * crange);
 HttpHdrContRange *httpHdrContRangeDup(const HttpHdrContRange * crange);
-void httpHdrContRangePackInto(const HttpHdrContRange * crange, Packer * p);
+void httpHdrContRangePackInto(const HttpHdrContRange * crange, Packable * p);
 /** inits with given spec */
 void httpHdrContRangeSet(HttpHdrContRange *, HttpHdrRangeSpec, int64_t);
 void httpHeaderAddContRange(HttpHeader *, HttpHdrRangeSpec, int64_t);
@@ -105,15 +105,14 @@ HttpHdrRangeSpec::parseInit(const char *field, int flen)
 }
 
 void
-HttpHdrRangeSpec::packInto(Packer * packer) const
+HttpHdrRangeSpec::packInto(Packable * p) const
 {
     if (!known_spec(offset))    /* suffix */
-        packerPrintf(packer, "-%" PRId64,  length);
+        p->appendf("-%" PRId64, length);
     else if (!known_spec(length))       /* trailer */
-        packerPrintf(packer, "%" PRId64 "-", offset);
+        p->appendf("%" PRId64 "-", offset);
     else            /* range */
-        packerPrintf(packer, "%" PRId64 "-%" PRId64,
-                     offset, offset + length - 1);
+        p->appendf("%" PRId64 "-%" PRId64, offset, offset + length - 1);
 }
 
 void
@@ -303,13 +302,13 @@ HttpHdrRange::end() const
 }
 
 void
-HttpHdrRange::packInto(Packer * packer) const
+HttpHdrRange::packInto(Packable * packer) const
 {
     const_iterator pos = begin();
 
     while (pos != end()) {
         if (pos != begin())
-            packerAppend(packer, ",", 1);
+            packer->append(",", 1);
 
         (*pos)->packInto(packer);
 
@@ -235,7 +235,7 @@ HttpHdrSc::HttpHdrSc(const HttpHdrSc &sc)
 }
 
 void
-HttpHdrScTarget::packInto(Packer * p) const
+HttpHdrScTarget::packInto(Packable * p) const
 {
     http_hdr_sc_type flag;
     int pcount = 0;
@@ -245,27 +245,27 @@ HttpHdrScTarget::packInto(Packer * p) const
         if (isSet(flag) && flag != SC_OTHER) {
 
             /* print option name */
-            packerPrintf(p, (pcount ? ", " SQUIDSTRINGPH : SQUIDSTRINGPH),
-                         SQUIDSTRINGPRINT(ScFieldsInfo[flag].name));
+            p->appendf((pcount ? ", " SQUIDSTRINGPH : SQUIDSTRINGPH),
+                       SQUIDSTRINGPRINT(ScFieldsInfo[flag].name));
 
             /* handle options with values */
 
             if (flag == SC_MAX_AGE)
-                packerPrintf(p, "=%d", (int) max_age);
+                p->appendf("=%d", (int) max_age);
 
             if (flag == SC_CONTENT)
-                packerPrintf(p, "=\"" SQUIDSTRINGPH "\"", SQUIDSTRINGPRINT(content_));
+                p->appendf("=\"" SQUIDSTRINGPH "\"", SQUIDSTRINGPRINT(content_));
 
             ++pcount;
         }
     }
 
     if (hasTarget())
-        packerPrintf (p, ";" SQUIDSTRINGPH, SQUIDSTRINGPRINT(target));
+        p->appendf(";" SQUIDSTRINGPH, SQUIDSTRINGPRINT(target));
 }
 
 void
-HttpHdrSc::packInto(Packer * p) const
+HttpHdrSc::packInto(Packable * p) const
 {
     dlink_node *node;
     assert(p);
@@ -25,7 +25,7 @@ class HttpHdrSc
     ~HttpHdrSc();
 
     bool parse(const String *str);
-    void packInto(Packer * p) const;
+    void packInto(Packable * p) const;
     void updateStats(StatHist *) const;
     HttpHdrScTarget * getMergedTarget (const char *ourtarget); //todo: make const?
     void setMaxAge(char const *target, int max_age);
@@ -15,8 +15,8 @@
 #include "SquidString.h"
 #include "typedefs.h"
 
+class Packable;
 class StatHist;
-class Packer;
 class StoreEntry;
 
 /** Representation of HTTP Surogate-Control header field targeted directive
@@ -82,7 +82,7 @@ class HttpHdrScTarget
     String Target() const { return target; }
 
     void mergeWith(const HttpHdrScTarget * new_sc);
-    void packInto (Packer *p) const;
+    void packInto(Packable *p) const;
     void updateStats(StatHist *) const;
 
 private:
@@ -735,7 +735,7 @@ HttpHeader::parse(const char *header_start, size_t hdrLen)
 
 /* packs all the entries using supplied packer */
 void
-HttpHeader::packInto(Packer * p, bool mask_sensitive_info) const
+HttpHeader::packInto(Packable * p, bool mask_sensitive_info) const
 {
     HttpHeaderPos pos = HttpHeaderInitPos;
     const HttpHeaderEntry *e;
@@ -765,8 +765,8 @@ HttpHeader::packInto(Packer * p, bool mask_sensitive_info) const
             break;
         }
         if (maskThisEntry) {
-            packerAppend(p, e->name.rawBuf(), e->name.size());
-            packerAppend(p, ": ** NOT DISPLAYED **\r\n", 23);
+            p->append(e->name.rawBuf(), e->name.size());
+            p->append(": ** NOT DISPLAYED **\r\n", 23);
         } else {
             e->packInto(p);
         }
@@ -1230,76 +1230,64 @@ HttpHeader::putAuth(const char *auth_scheme, const char *realm)
 void
 HttpHeader::putCc(const HttpHdrCc * cc)
 {
-    MemBuf mb;
-    Packer p;
     assert(cc);
     /* remove old directives if any */
     delById(HDR_CACHE_CONTROL);
     /* pack into mb */
+    MemBuf mb;
     mb.init();
-    packerToMemInit(&p, &mb);
-    cc->packInto(&p);
+    cc->packInto(&mb);
     /* put */
     addEntry(new HttpHeaderEntry(HDR_CACHE_CONTROL, NULL, mb.buf));
     /* cleanup */
-    packerClean(&p);
     mb.clean();
 }
 
 void
 HttpHeader::putContRange(const HttpHdrContRange * cr)
 {
-    MemBuf mb;
-    Packer p;
     assert(cr);
     /* remove old directives if any */
     delById(HDR_CONTENT_RANGE);
     /* pack into mb */
+    MemBuf mb;
     mb.init();
-    packerToMemInit(&p, &mb);
-    httpHdrContRangePackInto(cr, &p);
+    httpHdrContRangePackInto(cr, &mb);
     /* put */
     addEntry(new HttpHeaderEntry(HDR_CONTENT_RANGE, NULL, mb.buf));
     /* cleanup */
-    packerClean(&p);
     mb.clean();
 }
 
 void
 HttpHeader::putRange(const HttpHdrRange * range)
 {
-    MemBuf mb;
-    Packer p;
     assert(range);
     /* remove old directives if any */
     delById(HDR_RANGE);
     /* pack into mb */
+    MemBuf mb;
     mb.init();
-    packerToMemInit(&p, &mb);
-    range->packInto(&p);
+    range->packInto(&mb);
     /* put */
     addEntry(new HttpHeaderEntry(HDR_RANGE, NULL, mb.buf));
     /* cleanup */
-    packerClean(&p);
     mb.clean();
 }
 
 void
 HttpHeader::putSc(HttpHdrSc *sc)
 {
-    MemBuf mb;
-    Packer p;
     assert(sc);
     /* remove old directives if any */
     delById(HDR_SURROGATE_CONTROL);
     /* pack into mb */
+    MemBuf mb;
     mb.init();
-    packerToMemInit(&p, &mb);
-    sc->packInto(&p);
+    sc->packInto(&mb);
     /* put */
     addEntry(new HttpHeaderEntry(HDR_SURROGATE_CONTROL, NULL, mb.buf));
     /* cleanup */
-    packerClean(&p);
     mb.clean();
 }
 
@@ -1686,13 +1674,13 @@ HttpHeaderEntry::clone() const
 }
 
 void
-HttpHeaderEntry::packInto(Packer * p) const
+HttpHeaderEntry::packInto(Packable * p) const
 {
     assert(p);
-    packerAppend(p, name.rawBuf(), name.size());
-    packerAppend(p, ": ", 2);
-    packerAppend(p, value.rawBuf(), value.size());
-    packerAppend(p, "\r\n", 2);
+    p->append(name.rawBuf(), name.size());
+    p->append(": ", 2);
+    p->append(value.rawBuf(), value.size());
+    p->append("\r\n", 2);
 }
 
 int
@@ -22,7 +22,7 @@ class HttpHdrCc;
 class HttpHdrContRange;
 class HttpHdrRange;
 class HttpHdrSc;
-class Packer;
+class Packable;
 class StoreEntry;
 class SBuf;
 
@@ -87,7 +87,7 @@ class HttpHeaderEntry
     ~HttpHeaderEntry();
     static HttpHeaderEntry *parse(const char *field_start, const char *field_end);
     HttpHeaderEntry *clone() const;
-    void packInto(Packer *p) const;
+    void packInto(Packable *p) const;
     int getInt() const;
     int64_t getInt64() const;
 
@@ -117,7 +117,7 @@ class HttpHeader
     void compact();
     int reset();
     int parse(const char *header_start, size_t len);
-    void packInto(Packer * p, bool mask_sensitive_info=false) const;
+    void packInto(Packable * p, bool mask_sensitive_info=false) const;
     HttpHeaderEntry *getEntry(HttpHeaderPos * pos) const;
     HttpHeaderEntry *findEntry(http_hdr_type id) const;
     int delByName(const char *name);
@@ -10,13 +10,14 @@
 #define SQUID_HTTPHEADERRANGE_H
 
 #include "mem/forward.h"
-#include "Packer.h"
 #include "Range.h"
 #include "SquidString.h"
 
 #include <vector>
 
 class HttpReply;
+class Packable;
+
 /* http byte-range-spec */
 
 class HttpHdrRangeSpec
@@ -33,7 +34,7 @@ class HttpHdrRangeSpec
     bool parseInit(const char *field, int flen);
     int canonize(int64_t clen);
     void outputInfo( char const *note) const;
-    void packInto(Packer * p) const;
+    void packInto(Packable * p) const;
     bool mergeWith(const HttpHdrRangeSpec * donor);
     int64_t offset;
     int64_t length;
@@ -70,7 +71,7 @@ class HttpHdrRange
     int canonize(HttpReply *rep);
     /* returns true if ranges are valid; inits HttpHdrRange */
     bool parseInit(const String * range_spec);
-    void packInto(Packer * p) const;
+    void packInto(Packable * p) const;
     /* other */
     bool isComplex() const;
     bool willBeComplex() const;
@@ -114,7 +114,7 @@ httpHeaderPutStrvf(HttpHeader * hdr, http_hdr_type id, const char *fmt, va_list
 {
     MemBuf mb;
     mb.init();
-    mb.vPrintf(fmt, vargs);
+    mb.vappendf(fmt, vargs);
     hdr->putStr(id, mb.buf);
     mb.clean();
 }
@@ -125,16 +125,13 @@ httpMsgIsolateStart(const char **parse_start, const char **blk_start, const char
 // zero return means need more data
 // positive return is the size of parsed headers
 bool
-HttpMsg::parse(MemBuf *buf, bool eof, Http::StatusCode *error)
+HttpMsg::parse(const char *buf, const size_t sz, bool eof, Http::StatusCode *error)
 {
     assert(error);
     *error = Http::scNone;
 
-    // httpMsgParseStep() and debugging require 0-termination, unfortunately
-    buf->terminate(); // does not affect content size
-
     // find the end of headers
-    const size_t hdr_len = headersEnd(buf->content(), buf->contentSize());
+    const size_t hdr_len = headersEnd(buf, sz);
 
     // sanity check the start line to see if this is in fact an HTTP message
     if (!sanityCheckStartLine(buf, hdr_len, error)) {
@@ -146,38 +143,37 @@ HttpMsg::parse(MemBuf *buf, bool eof, Http::StatusCode *error)
         return false;
     }
 
-    // TODO: move to httpReplyParseStep()
-    if (hdr_len > Config.maxReplyHeaderSize || (hdr_len <= 0 && (size_t)buf->contentSize() > Config.maxReplyHeaderSize)) {
+    if (hdr_len > Config.maxReplyHeaderSize || (hdr_len <= 0 && sz > Config.maxReplyHeaderSize)) {
         debugs(58, DBG_IMPORTANT, "HttpMsg::parse: Too large reply header (" << hdr_len << " > " << Config.maxReplyHeaderSize);
         *error = Http::scHeaderTooLarge;
         return false;
     }
 
     if (hdr_len <= 0) {
-        debugs(58, 3, "HttpMsg::parse: failed to find end of headers (eof: " << eof << ") in '" << buf->content() << "'");
+        debugs(58, 3, "HttpMsg::parse: failed to find end of headers (eof: " << eof << ") in '" << buf << "'");
 
         if (eof) // iff we have seen the end, this is an error
             *error = Http::scInvalidHeader;
 
         return false;
     }
 
-    const int res = httpMsgParseStep(buf->content(), buf->contentSize(), eof);
+    const int res = httpMsgParseStep(buf, sz, eof);
 
     if (res < 0) { // error
-        debugs(58, 3, "HttpMsg::parse: cannot parse isolated headers in '" << buf->content() << "'");
+        debugs(58, 3, "HttpMsg::parse: cannot parse isolated headers in '" << buf << "'");
         *error = Http::scInvalidHeader;
         return false;
     }
 
     if (res == 0) {
-        debugs(58, 2, "HttpMsg::parse: strange, need more data near '" << buf->content() << "'");
+        debugs(58, 2, "HttpMsg::parse: strange, need more data near '" << buf << "'");
         *error = Http::scInvalidHeader;
         return false; // but this should not happen due to headersEnd() above
     }
 
     assert(res > 0);
-    debugs(58, 9, "HttpMsg::parse success (" << hdr_len << " bytes) near '" << buf->content() << "'");
+    debugs(58, 9, "HttpMsg::parse success (" << hdr_len << " bytes) near '" << buf << "'");
 
     if (hdr_sz != (int)hdr_len) {
         debugs(58, DBG_IMPORTANT, "internal HttpMsg::parse vs. headersEnd error: " <<
@@ -316,11 +312,11 @@ HttpMsg::persistent() const
     }
 }
 
-void HttpMsg::packInto(Packer *p, bool full_uri) const
+void HttpMsg::packInto(Packable *p, bool full_uri) const
 {
     packFirstLineInto(p, full_uri);
     header.packInto(p);
-    packerAppend(p, "\r\n", 2);
+    p->append("\r\n", 2);
 }
 
 void HttpMsg::hdrCacheInit()
@@ -335,9 +331,6 @@ void HttpMsg::hdrCacheInit()
  */
 void HttpMsg::firstLineBuf(MemBuf& mb)
 {
-    Packer p;
-    packerToMemInit(&p, &mb);
-    packFirstLineInto(&p, true);
-    packerClean(&p);
+    packFirstLineInto(&mb, true);
 }
 
@@ -28,7 +28,7 @@ class HttpMsg : public RefCountable
 
     virtual void reset() = 0; // will have body when http*Clean()s are gone
 
-    void packInto(Packer * p, bool full_uri) const;
+    void packInto(Packable * p, bool full_uri) const;
 
     ///< produce a message copy, except for a few connection-specific settings
     virtual HttpMsg *clone() const = 0; ///< \todo rename: not a true copy?
@@ -67,7 +67,7 @@ class HttpMsg : public RefCountable
     // returns true and sets hdr_sz on success
     // returns false and sets *error to zero when needs more data
     // returns false and sets *error to a positive Http::StatusCode on error
-    bool parse(MemBuf *buf, bool eol, Http::StatusCode *error);
+    bool parse(const char *buf, const size_t sz, bool eol, Http::StatusCode *error);
 
     bool parseCharBuf(const char *buf, ssize_t end);
 
@@ -89,9 +89,9 @@ class HttpMsg : public RefCountable
      * \retval true   Status line has no serious problems.
      * \retval false  Status line has a serious problem. Correct response is indicated by error.
      */
-    virtual bool sanityCheckStartLine(MemBuf *buf, const size_t hdr_len, Http::StatusCode *error) = 0;
+    virtual bool sanityCheckStartLine(const char *buf, const size_t hdr_len, Http::StatusCode *error) = 0;
 
-    virtual void packFirstLineInto(Packer * p, bool full_uri) const = 0;
+    virtual void packFirstLineInto(Packable * p, bool full_uri) const = 0;
 
     virtual bool parseFirstLine(const char *blk_start, const char *blk_end) = 0;
 
@@ -108,15 +108,15 @@ HttpReply::clean()
 }
 
 void
-HttpReply::packHeadersInto(Packer * p) const
+HttpReply::packHeadersInto(Packable * p) const
 {
     sline.packInto(p);
     header.packInto(p);
-    packerAppend(p, "\r\n", 2);
+    p->append("\r\n", 2);
 }
 
 void
-HttpReply::packInto(Packer * p)
+HttpReply::packInto(Packable * p)
 {
     packHeadersInto(p);
     body.packInto(p);
@@ -127,12 +127,8 @@ MemBuf *
 HttpReply::pack()
 {
     MemBuf *mb = new MemBuf;
-    Packer p;
-
     mb->init();
-    packerToMemInit(&p, mb);
-    packInto(&p);
-    packerClean(&p);
+    packInto(mb);
     return mb;
 }
 
@@ -411,15 +407,15 @@ HttpReply::bodySize(const HttpRequestMethod& method) const
  * NP: not all error cases are detected yet. Some are left for detection later in parse.
  */
 bool
-HttpReply::sanityCheckStartLine(MemBuf *buf, const size_t hdr_len, Http::StatusCode *error)
+HttpReply::sanityCheckStartLine(const char *buf, const size_t hdr_len, Http::StatusCode *error)
 {
     // hack warning: using psize instead of size here due to type mismatches with MemBuf.
 
     // content is long enough to possibly hold a reply
     // 4 being magic size of a 3-digit number plus space delimiter
-    if ( buf->contentSize() < (protoPrefix.psize() + 4) ) {
+    if (hdr_len < (size_t)(protoPrefix.psize() + 4)) {
         if (hdr_len > 0) {
-            debugs(58, 3, HERE << "Too small reply header (" << hdr_len << " bytes)");
+            debugs(58, 3, "Too small reply header (" << hdr_len << " bytes)");
             *error = Http::scInvalidHeader;
         }
         return false;
@@ -428,13 +424,13 @@ HttpReply::sanityCheckStartLine(MemBuf *buf, const size_t hdr_len, Http::StatusC
     int pos;
     // catch missing or mismatched protocol identifier
     // allow special-case for ICY protocol (non-HTTP identifier) in response to faked HTTP request.
-    if (strncmp(buf->content(), "ICY", 3) == 0) {
+    if (strncmp(buf, "ICY", 3) == 0) {
         protoPrefix = "ICY";
         pos = protoPrefix.psize();
     } else {
 
-        if (protoPrefix.cmp(buf->content(), protoPrefix.size()) != 0) {
-            debugs(58, 3, "HttpReply::sanityCheckStartLine: missing protocol prefix (" << protoPrefix << ") in '" << buf->content() << "'");
+        if (protoPrefix.cmp(buf, protoPrefix.size()) != 0) {
+            debugs(58, 3, "missing protocol prefix (" << protoPrefix << ") in '" << buf << "'");
             *error = Http::scInvalidHeader;
             return false;
         }
@@ -443,21 +439,21 @@ HttpReply::sanityCheckStartLine(MemBuf *buf, const size_t hdr_len, Http::StatusC
         pos = protoPrefix.psize();
 
         // skip arbitrary number of digits and a dot in the verion portion
-        while ( pos <= buf->contentSize() && (*(buf->content()+pos) == '.' || xisdigit(*(buf->content()+pos)) ) ) ++pos;
+        while ((size_t)pos <= hdr_len && (*(buf+pos) == '.' || xisdigit(*(buf+pos)) ) ) ++pos;
 
         // catch missing version info
         if (pos == protoPrefix.psize()) {
-            debugs(58, 3, "HttpReply::sanityCheckStartLine: missing protocol version numbers (ie. " << protoPrefix << "/1.0) in '" << buf->content() << "'");
+            debugs(58, 3, "missing protocol version numbers (ie. " << protoPrefix << "/1.0) in '" << buf << "'");
             *error = Http::scInvalidHeader;
             return false;
         }
     }
 
     // skip arbitrary number of spaces...
-    while (pos <= buf->contentSize() && (char)*(buf->content()+pos) == ' ') ++pos;
+    while ((size_t)pos <= hdr_len && (char)*(buf+pos) == ' ') ++pos;
 
-    if (pos < buf->contentSize() && !xisdigit(*(buf->content()+pos))) {
-        debugs(58, 3, "HttpReply::sanityCheckStartLine: missing or invalid status number in '" << buf->content() << "'");
+    if ((size_t)pos < hdr_len && !xisdigit(*(buf+pos))) {
+        debugs(58, 3, "missing or invalid status number in '" << buf << "'");
         *error = Http::scInvalidHeader;
         return false;
     }
@@ -39,7 +39,7 @@ class HttpReply: public HttpMsg
      \retval false and sets *error to zero when needs more data
      \retval false and sets *error to a positive Http::StatusCode on error
      */
-    virtual bool sanityCheckStartLine(MemBuf *buf, const size_t hdr_len, Http::StatusCode *error);
+    virtual bool sanityCheckStartLine(const char *buf, const size_t hdr_len, Http::StatusCode *error);
 
     /** \par public, readable; never update these or their .hdr equivalents directly */
     time_t date;
@@ -100,7 +100,7 @@ class HttpReply: public HttpMsg
 
     int validatorsMatch (HttpReply const *other) const;
 
-    void packHeadersInto(Packer * p) const;
+    void packHeadersInto(Packable * p) const;
 
     /** Clone this reply.
      *  Could be done as a copy-contructor but we do not want to accidently copy a HttpReply..
@@ -120,7 +120,7 @@ class HttpReply: public HttpMsg
 
     void hdrCacheClean();
 
-    void packInto(Packer * p);
+    void packInto(Packable * p);
 
     /* ez-routines */
     /** \return construct 304 reply and pack it into a MemBuf */
@@ -139,7 +139,7 @@ class HttpReply: public HttpMsg
     mutable int64_t bodySizeMax; /**< cached result of calcMaxBodySize */
 
 protected:
-    virtual void packFirstLineInto(Packer * p, bool) const { sline.packInto(p); }
+    virtual void packFirstLineInto(Packable * p, bool) const { sline.packInto(p); }
 
     virtual bool parseFirstLine(const char *start, const char *end);
 };
@@ -61,22 +61,17 @@ HttpRequest::initHTTP(const HttpRequestMethod& aMethod, AnyP::ProtocolType aProt
 {
     method = aMethod;
     url.setScheme(aProtocol);
-    urlpath = aUrlpath;
+    url.path(aUrlpath);
 }
 
 void
 HttpRequest::init()
 {
     method = Http::METHOD_NONE;
     url.clear();
-    urlpath = NULL;
-    host[0] = '\0';
-    host_is_numeric = -1;
 #if USE_AUTH
     auth_user_request = NULL;
 #endif
-    port = 0;
-    canonical = NULL;
     memset(&flags, '\0', sizeof(flags));
     range = NULL;
     ims = -1;
@@ -124,12 +119,9 @@ HttpRequest::clean()
 #if USE_AUTH
     auth_user_request = NULL;
 #endif
-    safe_free(canonical);
-
     safe_free(vary_headers);
 
     url.clear();
-    urlpath.clean();
 
     header.clean();
 
@@ -176,7 +168,8 @@ HttpRequest::reset()
 HttpRequest *
 HttpRequest::clone() const
 {
-    HttpRequest *copy = new HttpRequest(method, url.getScheme(), urlpath.termedBuf());
+    HttpRequest *copy = new HttpRequest();
+    copy->method = method;
     // TODO: move common cloning clone to Msg::copyTo() or copy ctor
     copy->header.append(&header);
     copy->hdrCacheInit();
@@ -185,13 +178,11 @@ HttpRequest::clone() const
     copy->pstate = pstate; // TODO: should we assert a specific state here?
     copy->body_pipe = body_pipe;
 
+    copy->url.setScheme(url.getScheme());
     copy->url.userInfo(url.userInfo());
-    strncpy(copy->host, host, sizeof(host)); // SQUIDHOSTNAMELEN
-    copy->host_addr = host_addr;
-
-    copy->port = port;
-    // urlPath handled in ctor
-    copy->canonical = canonical ? xstrdup(canonical) : NULL;
+    copy->url.host(url.host());
+    copy->url.port(url.port());
+    copy->url.path(url.path());
 
     // range handled in hdrCacheInit()
     copy->ims = ims;
@@ -269,11 +260,11 @@ HttpRequest::inheritProperties(const HttpMsg *aMsg)
  * NP: Other errors are left for detection later in the parse.
  */
 bool
-HttpRequest::sanityCheckStartLine(MemBuf *buf, const size_t hdr_len, Http::StatusCode *error)
+HttpRequest::sanityCheckStartLine(const char *buf, const size_t hdr_len, Http::StatusCode *error)
 {
     // content is long enough to possibly hold a reply
     // 2 being magic size of a 1-byte request method plus space delimiter
-    if ( buf->contentSize() < 2 ) {
+    if (hdr_len < 2) {
         // this is ony a real error if the headers apparently complete.
         if (hdr_len > 0) {
             debugs(58, 3, HERE << "Too large request header (" << hdr_len << " bytes)");
@@ -284,7 +275,7 @@ HttpRequest::sanityCheckStartLine(MemBuf *buf, const size_t hdr_len, Http::Statu
 
     /* See if the request buffer starts with a non-whitespace HTTP request 'method'. */
     HttpRequestMethod m;
-    m.HttpRequestMethodXXX(buf->content());
+    m.HttpRequestMethodXXX(buf);
     if (m == Http::METHOD_NONE) {
         debugs(73, 3, "HttpRequest::sanityCheckStartLine: did not find HTTP request method");
         *error = Http::scInvalidHeader;
@@ -365,44 +356,42 @@ HttpRequest::parseHeader(Http1::RequestParser &hp)
 void
 HttpRequest::swapOut(StoreEntry * e)
 {
-    Packer p;
     assert(e);
-    packerToStoreInit(&p, e);
-    pack(&p);
-    packerClean(&p);
+    e->buffer();
+    pack(e);
 }
 
 /* packs request-line and headers, appends <crlf> terminator */
 void
-HttpRequest::pack(Packer * p)
+HttpRequest::pack(Packable * p)
 {
     assert(p);
     /* pack request-line */
-    packerPrintf(p, SQUIDSBUFPH " " SQUIDSTRINGPH " HTTP/%d.%d\r\n",
-                 SQUIDSBUFPRINT(method.image()), SQUIDSTRINGPRINT(urlpath),
-                 http_ver.major, http_ver.minor);
+    p->appendf(SQUIDSBUFPH " " SQUIDSBUFPH " HTTP/%d.%d\r\n",
+               SQUIDSBUFPRINT(method.image()), SQUIDSBUFPRINT(url.path()),
+               http_ver.major, http_ver.minor);
     /* headers */
     header.packInto(p);
     /* trailer */
-    packerAppend(p, "\r\n", 2);
+    p->append("\r\n", 2);
 }
 
 /*
  * A wrapper for debugObj()
  */
 void
-httpRequestPack(void *obj, Packer *p)
+httpRequestPack(void *obj, Packable *p)
 {
     HttpRequest *request = static_cast<HttpRequest*>(obj);
     request->pack(p);
 }
 
 /* returns the length of request line + headers + crlf */
 int
-HttpRequest::prefixLen()
+HttpRequest::prefixLen() const
 {
     return method.image().length() + 1 +
-           urlpath.size() + 1 +
+           url.path().length() + 1 +
            4 + 1 + 3 + 2 +
            header.len + 2;
 }
@@ -497,24 +486,16 @@ HttpRequest::clearError()
     errDetail = ERR_DETAIL_NONE;
 }
 
-const char *HttpRequest::packableURI(bool full_uri) const
+void
+HttpRequest::packFirstLineInto(Packable * p, bool full_uri) const
 {
-    if (full_uri)
-        return urlCanonical((HttpRequest*)this);
-
-    if (urlpath.size())
-        return urlpath.termedBuf();
-
-    return "/";
-}
+    const SBuf tmp(full_uri ? effectiveRequestUri() : url.path());
 
-void HttpRequest::packFirstLineInto(Packer * p, bool full_uri) const
-{
     // form HTTP request-line
-    packerPrintf(p, SQUIDSBUFPH " %s HTTP/%d.%d\r\n",
-                 SQUIDSBUFPRINT(method.image()),
-                 packableURI(full_uri),
-                 http_ver.major, http_ver.minor);
+    p->appendf(SQUIDSBUFPH " " SQUIDSBUFPH " HTTP/%d.%d\r\n",
+               SQUIDSBUFPRINT(method.image()),
+               SQUIDSBUFPRINT(tmp),
+               http_ver.major, http_ver.minor);
 }
 
 /*
@@ -687,16 +668,22 @@ HttpRequest::pinnedConnection()
     return NULL;
 }
 
-const char *
+const SBuf
 HttpRequest::storeId()
 {
     if (store_id.size() != 0) {
-        debugs(73, 3, "sent back store_id:" << store_id);
-
-        return store_id.termedBuf();
+        debugs(73, 3, "sent back store_id: " << store_id);
+        return SBuf(store_id);
     }
-    debugs(73, 3, "sent back canonicalUrl:" << urlCanonical(this) );
+    debugs(73, 3, "sent back effectiveRequestUrl: " << effectiveRequestUri());
+    return effectiveRequestUri();
+}
 
-    return urlCanonical(this);
+const SBuf &
+HttpRequest::effectiveRequestUri() const
+{
+    if (method.id() == Http::METHOD_CONNECT)
+        return url.authority(true); // host:port
+    return url.absolute();
 }
 
@@ -10,7 +10,6 @@
 #define SQUID_HTTPREQUEST_H
 
 #include "base/CbcPointer.h"
-#include "Debug.h"
 #include "dns/forward.h"
 #include "err_type.h"
 #include "HierarchyLogEntry.h"
@@ -37,7 +36,7 @@
 class ConnStateData;
 
 /*  Http Request */
-void httpRequestPack(void *obj, Packer *p);
+void httpRequestPack(void *obj, Packable *p);
 
 class HttpHdrRange;
 
@@ -67,26 +66,6 @@ class HttpRequest: public HttpMsg
     /// whether the client is likely to be able to handle a 1xx reply
     bool canHandle1xx() const;
 
-    /* Now that we care what host contains it is better off being protected. */
-    /* HACK: These two methods are only inline to get around Makefile dependancies */
-    /*      caused by HttpRequest being used in places it really shouldn't.        */
-    /*      ideally they would be methods of URL instead. */
-    inline void SetHost(const char *src) {
-        host_addr.setEmpty();
-        host_addr = src;
-        if (host_addr.isAnyAddr()) {
-            xstrncpy(host, src, SQUIDHOSTNAMELEN);
-            host_is_numeric = 0;
-        } else {
-            host_addr.toHostStr(host, SQUIDHOSTNAMELEN);
-            debugs(23, 3, "HttpRequest::SetHost() given IP: " << host_addr);
-            host_is_numeric = 1;
-        }
-        safe_free(canonical); // force its re-build
-    };
-    inline const char* GetHost(void) const { return host; };
-    inline int GetHostIsNumeric(void) const { return host_is_numeric; };
-
 #if USE_ADAPTATION
     /// Returns possibly nil history, creating it if adapt. logging is enabled
     Adaptation::History::Pointer adaptLogHistory() const;
@@ -114,14 +93,9 @@ class HttpRequest: public HttpMsg
 
 public:
     HttpRequestMethod method;
-
-    // TODO expand to include all URI parts
-    URL url; ///< the request URI (scheme and userinfo only)
+    URL url; ///< the request URI
 
 private:
-    char host[SQUIDHOSTNAMELEN];
-    int host_is_numeric;
-
 #if USE_ADAPTATION
     mutable Adaptation::History::Pointer adaptHistory_; ///< per-HTTP transaction info
 #endif
@@ -130,15 +104,12 @@ class HttpRequest: public HttpMsg
 #endif
 
 public:
-    Ip::Address host_addr;
 #if USE_AUTH
     Auth::UserRequest::Pointer auth_user_request;
 #endif
-    unsigned short port;
 
-    String urlpath;
-
-    char *canonical;
+    /// RFC 7230 section 5.5 - Effective Request URI
+    const SBuf &effectiveRequestUri() const;
 
     /**
      * If defined, store_id_program mapped the request URL to this ID.
@@ -216,13 +187,13 @@ class HttpRequest: public HttpMsg
 
     bool bodyNibbled() const; // the request has a [partially] consumed body
 
-    int prefixLen();
+    int prefixLen() const;
 
     void swapOut(StoreEntry * e);
 
-    void pack(Packer * p);
+    void pack(Packable * p);
 
-    static void httpRequestPack(void *obj, Packer *p);
+    static void httpRequestPack(void *obj, Packable *p);
 
     static HttpRequest * CreateFromUrlAndMethod(char * url, const HttpRequestMethod& method);
 
@@ -233,10 +204,9 @@ class HttpRequest: public HttpMsg
     /**
      * Returns the current StoreID for the request as a nul-terminated char*.
      * Always returns the current id for the request
-     * (either the request canonical url or modified ID by the helper).
-     * Does not return NULL.
+     * (either the effective request URI or modified ID by the helper).
      */
-    const char *storeId();
+    const SBuf storeId();
 
     /**
      * The client connection manager, if known;
@@ -250,14 +220,12 @@ class HttpRequest: public HttpMsg
     int64_t getRangeOffsetLimit(); /* the result of this function gets cached in rangeOffsetLimit */
 
 private:
-    const char *packableURI(bool full_uri) const;
-
     mutable int64_t rangeOffsetLimit;  /* caches the result of getRangeOffsetLimit */
 
 protected:
-    virtual void packFirstLineInto(Packer * p, bool full_uri) const;
+    virtual void packFirstLineInto(Packable * p, bool full_uri) const;
 
-    virtual bool sanityCheckStartLine(MemBuf *buf, const size_t hdr_len, Http::StatusCode *error);
+    virtual bool sanityCheckStartLine(const char *buf, const size_t hdr_len, Http::StatusCode *error);
 
     virtual void hdrCacheInit();
 
@@ -123,7 +123,7 @@ void icpCreateAndSend(icp_opcode, int flags, char const *url, int reqnum, int pa
 icp_opcode icpGetCommonOpcode();
 
 /// \ingroup ServerProtocolICPAPI
-int icpUdpSend(int, const Ip::Address &, icp_common_t *, LogTags, int);
+int icpUdpSend(int, const Ip::Address &, icp_common_t *, const LogTags &, int);
 
 /// \ingroup ServerProtocolICPAPI
 LogTags icpLogFromICPCode(icp_opcode opcode);
@@ -0,0 +1,78 @@
+/*
+ * Copyright (C) 1996-2015 The Squid Software Foundation and contributors
+ *
+ * Squid software is distributed under GPLv2+ license and includes
+ * contributions from numerous individuals and organizations.
+ * Please see the COPYING and CONTRIBUTORS files for details.
+ */
+
+#include "squid.h"
+#include "LogTags.h"
+
+// old deprecated tag strings
+const char * LogTags::Str_[] = {
+    "TAG_NONE",
+    "TCP_HIT",
+    "TCP_MISS",
+    "TCP_REFRESH_UNMODIFIED",
+    "TCP_REFRESH_FAIL_OLD",
+    "TCP_REFRESH_FAIL_ERR",
+    "TCP_REFRESH_MODIFIED",
+    "TCP_CLIENT_REFRESH_MISS",
+    "TCP_IMS_HIT",
+    "TCP_SWAPFAIL_MISS",
+    "TCP_NEGATIVE_HIT",
+    "TCP_MEM_HIT",
+    "TCP_DENIED",
+    "TCP_DENIED_REPLY",
+    "TCP_OFFLINE_HIT",
+    "TCP_REDIRECT",
+    "TCP_TUNNEL",
+    "UDP_HIT",
+    "UDP_MISS",
+    "UDP_DENIED",
+    "UDP_INVALID",
+    "UDP_MISS_NOFETCH",
+    "ICP_QUERY",
+    "TYPE_MAX"
+};
+
+/*
+ * This method is documented in http://wiki.squid-cache.org/SquidFaq/SquidLogs#Squid_result_codes
+ * Please keep the wiki up to date
+ */
+const char *
+LogTags::c_str() const
+{
+    static char buf[1024];
+    *buf = 0;
+    int pos = 0;
+
+    // source tags
+    if (oldType && oldType < LOG_TYPE_MAX)
+        pos += snprintf(buf, sizeof(buf), "%s",Str_[oldType]);
+    else
+        pos += snprintf(buf, sizeof(buf), "NONE");
+
+    // error tags
+    if (err.timedout)
+        pos += snprintf(buf+pos,sizeof(buf)-pos, "_TIMEDOUT");
+    if (err.aborted)
+        pos += snprintf(buf+pos,sizeof(buf)-pos, "_ABORTED");
+
+    return buf;
+}
+
+bool
+LogTags::isTcpHit() const
+{
+    return
+        (oldType == LOG_TCP_HIT) ||
+        (oldType == LOG_TCP_IMS_HIT) ||
+        (oldType == LOG_TCP_REFRESH_FAIL_OLD) ||
+        (oldType == LOG_TCP_REFRESH_UNMODIFIED) ||
+        (oldType == LOG_TCP_NEGATIVE_HIT) ||
+        (oldType == LOG_TCP_MEM_HIT) ||
+        (oldType == LOG_TCP_OFFLINE_HIT);
+}
+
@@ -42,29 +42,43 @@ typedef enum {
     LOG_UDP_MISS_NOFETCH,
     LOG_ICP_QUERY,
     LOG_TYPE_MAX
-} LogTags;
+} LogTags_ot;
 
-/// list of string representations for LogTags
-extern const char *LogTags_str[];
-
-/// determine if the log tag code indicates a cache HIT
-inline bool logTypeIsATcpHit(LogTags code)
+class LogTags
 {
-    return
-        (code == LOG_TCP_HIT) ||
-        (code == LOG_TCP_IMS_HIT) ||
-        (code == LOG_TCP_REFRESH_FAIL_OLD) ||
-        (code == LOG_TCP_REFRESH_UNMODIFIED) ||
-        (code == LOG_TCP_NEGATIVE_HIT) ||
-        (code == LOG_TCP_MEM_HIT) ||
-        (code == LOG_TCP_OFFLINE_HIT);
-}
+public:
+    LogTags(LogTags_ot t) : oldType(t) {assert(oldType < LOG_TYPE_MAX);}
+    LogTags &operator =(const LogTags_ot &t) {assert(t < LOG_TYPE_MAX); oldType = t; return *this;}
+
+    /// compute the status access.log field
+    const char *c_str() const;
+
+    /// determine if the log tag code indicates a cache HIT
+    bool isTcpHit() const;
+
+    /// error states terminating the transaction
+    struct Errors {
+        Errors() : timedout(false), aborted(false) {}
+
+        bool timedout; ///< tag: TIMEDOUT - terminated due to a lifetime or I/O timeout
+        bool aborted;  ///< tag: ABORTED  - other abnormal termination (e.g., I/O error)
+    } err;
+
+private:
+    /// list of string representations for LogTags_ot
+    static const char *Str_[];
+
+public: // XXX: only until client_db.cc stats are redesigned.
+
+    // deprecated LogTag enum value
+    LogTags_ot oldType;
+};
 
-/// iterator for LogTags enumeration
-inline LogTags &operator++ (LogTags &aLogType)
+/// iterator for LogTags_ot enumeration
+inline LogTags_ot &operator++ (LogTags_ot &aLogType)
 {
     int tmp = (int)aLogType;
-    aLogType = (LogTags)(++tmp);
+    aLogType = (LogTags_ot)(++tmp);
     return aLogType;
 }
 
@@ -44,8 +44,8 @@ LOADABLE_MODULES_SOURCES = \
 	LoadableModules.h \
 	LoadableModules.cc
 
-SUBDIRS	= mem base anyp helper dns ftp parser comm eui acl format clients servers fs repl
-DIST_SUBDIRS = mem base anyp helper dns ftp parser comm eui acl format clients servers fs repl
+SUBDIRS	= mem base anyp helper dns ftp parser comm eui acl format clients servers fs repl DiskIO
+DIST_SUBDIRS = mem base anyp helper dns ftp parser comm eui acl format clients servers fs repl DiskIO
 
 if ENABLE_AUTH
 SUBDIRS += auth
@@ -55,16 +55,15 @@ check_PROGRAMS+= tests/testACLMaxUserIP
 endif
 DIST_SUBDIRS += auth
 
-SUBDIRS	+= http ip icmp ident log ipc mgr
-DIST_SUBDIRS += http ip icmp ident log ipc mgr
+SUBDIRS	+= http ip icmp ident log ipc mgr security
+DIST_SUBDIRS += http ip icmp ident log ipc mgr security
 
+SSL_LIBS=
 if ENABLE_SSL
 SUBDIRS += ssl
-SSL_LIBS = \
+SSL_LIBS += \
 	ssl/libsslsquid.la \
 	ssl/libsslutil.la
-else
-SSL_LOCAL_LIBS =
 endif
 DIST_SUBDIRS += ssl
 
@@ -90,14 +89,13 @@ DIST_SUBDIRS += adaptation
 
 if USE_ESI
 SUBDIRS += esi
-ESI_LOCAL_LIBS = \
+ESI_LIBS = \
 	esi/libesi.la \
-	$(top_builddir)/lib/libTrie/libTrie.a
-ESI_LIBS = $(ESI_LOCAL_LIBS) \
+	$(top_builddir)/lib/libTrie/libTrie.a \
 	$(XMLLIB) \
 	$(EXPATLIB)
 else
-ESI_LIBS = 
+ESI_LIBS =
 endif
 DIST_SUBDIRS += esi
 
@@ -177,32 +175,9 @@ else
 IPC_SOURCE = SquidIpc.h ipc.cc
 endif
 
-AIO_WIN32_ALL_SOURCES = \
-	DiskIO/AIO/aio_win32.cc \
-	DiskIO/AIO/aio_win32.h
-if ENABLE_WIN32_AIO
-AIO_WIN32_SOURCES = $(AIO_WIN32_ALL_SOURCES)
-else
-AIO_WIN32_SOURCES =
-endif
-
-if ENABLE_WIN32_AIOPS
-AIOPS_SOURCE = DiskIO/DiskThreads/aiops_win32.cc \
-	DiskIO/DiskThreads/CommIO.cc \
-	DiskIO/DiskThreads/CommIO.h
-else
-AIOPS_SOURCE = DiskIO/DiskThreads/aiops.cc \
-	DiskIO/DiskThreads/CommIO.cc \
-	DiskIO/DiskThreads/CommIO.h
-endif
-
-EXTRA_LIBRARIES = libAIO.a libBlocking.a libDiskDaemon.a libDiskThreads.a \
-	libMmapped.a libIpcIo.a
-noinst_LIBRARIES = $(DISK_LIBS)
 noinst_LTLIBRARIES = libsquid.la
 
 EXTRA_PROGRAMS = \
-	DiskIO/DiskDaemon/diskd \
 	unlinkd \
 	recv-announce \
 	tests/testUfs \
@@ -222,7 +197,6 @@ bin_PROGRAMS =
 
 
 libexec_PROGRAMS = \
-	$(DISK_PROGRAMS) \
 	$(UNLINKD)
 
 cf_gen_SOURCES = cf_gen.cc
@@ -237,25 +211,6 @@ AM_CPPFLAGS += -I$(top_builddir)/src
 
 ACL_REGISTRATION_SOURCES = AclRegs.cc AuthReg.cc
 
-DISKIO_SOURCE = \
-	DiskIO/DiskIOModule.cc \
-	DiskIO/ReadRequest.cc \
-	DiskIO/ReadRequest.h \
-	DiskIO/WriteRequest.cc \
-	DiskIO/WriteRequest.h \
-	DiskIO/DiskFile.h \
-	DiskIO/DiskIOStrategy.h \
-	DiskIO/IORequestor.h \
-	DiskIO/DiskIOModule.h \
-	DiskIO/ReadRequest.h
-
-DISKIO_GEN_SOURCE = \
-	DiskIO/DiskIOModules_gen.cc
-
-DiskIO/DiskIOModules_gen.cc: Makefile
-	$(SHELL) $(srcdir)/DiskIO/modules.sh $(DISK_MODULES) > DiskIO/DiskIOModules_gen.cc
-
-
 # common library for all the binaries and tests. This is kindof a catch all
 # and smaller libraries split from this are encouraged. Using lt convenience
 # libraries, dependencies should not be a problem either.
@@ -292,8 +247,6 @@ squid_SOURCES = \
 	carp.cc \
 	cbdata.cc \
 	cbdata.h \
-	ChunkedCodingParser.cc \
-	ChunkedCodingParser.h \
 	client_db.h \
 	client_db.cc \
 	client_side.h \
@@ -331,7 +284,6 @@ squid_SOURCES = \
 	$(DELAY_POOL_SOURCE) \
 	disk.h \
 	disk.cc \
-	$(DISKIO_SOURCE) \
 	dlink.h \
 	dlink.cc \
 	$(DNSSOURCE) \
@@ -420,6 +372,7 @@ squid_SOURCES = \
 	$(LEAKFINDERSOURCE) \
 	SquidList.h \
 	SquidList.cc \
+	LogTags.cc \
 	LogTags.h \
 	lookup_t.h \
 	main.cc \
@@ -441,8 +394,6 @@ squid_SOURCES = \
 	neighbors.cc \
 	Notes.h \
 	Notes.cc \
-	Packer.cc \
-	Packer.h \
 	Parsing.cc \
 	Parsing.h \
 	$(XPROF_STATS_SOURCE) \
@@ -554,7 +505,6 @@ squid_SOURCES = \
 	$(WINSVC_SOURCE)
 
 EXTRA_squid_SOURCES = \
-	$(AIO_WIN32_ALL_SOURCES) \
 	$(all_AUTHMODULES) \
 	ConfigOption.h \
 	$(DELAY_POOL_ALL_SOURCE) \
@@ -586,15 +536,13 @@ BUILT_SOURCES = \
 	globals.cc \
 	hier_code.cc \
 	icp_opcode.cc \
-	LogTags.cc \
 	lookup_t.cc \
 	repl_modules.cc \
 	swap_log_op.cc
 
 CLEANFILES += $(BUILT_SOURCES)
 
 nodist_squid_SOURCES = \
-	$(DISKIO_GEN_SOURCE) \
 	$(BUILT_SOURCES)
 
 squid_LDADD = \
@@ -603,7 +551,6 @@ squid_LDADD = \
 	acl/libacls.la \
 	acl/libstate.la \
 	$(AUTH_LIBS) \
-	$(DISK_LIBS) \
 	acl/libapi.la \
 	clients/libclients.la \
 	servers/libservers.la \
@@ -616,10 +563,12 @@ squid_LDADD = \
 	libsquid.la \
 	ip/libip.la \
 	fs/libfs.la \
+	DiskIO/libdiskio.la \
 	$(SSL_LIBS) \
 	ipc/libipc.la \
 	mgr/libmgr.la \
 	anyp/libanyp.la \
+	security/libsecurity.la \
 	comm/libcomm.la \
 	eui/libeui.la \
 	icmp/libicmp.la icmp/libicmp-core.la \
@@ -628,7 +577,6 @@ squid_LDADD = \
 	$(XTRA_OBJS) \
 	$(DISK_LINKOBJS) \
 	$(REPL_OBJS) \
-	$(DISK_OS_LIBS) \
 	$(NETTLELIB) \
 	$(CRYPTLIB) \
 	$(REGEXLIB) \
@@ -645,30 +593,6 @@ squid_LDADD = \
 	$(KRB5LIBS) \
 	$(COMPAT_LIB) \
 	$(XTRA_LIBS)
-squid_DEPENDENCIES = \
-	$(DISK_LIBS) \
-	$(DISK_LINKOBJS) \
-	$(REPL_OBJS) \
-	$(ADAPTATION_LIBS) \
-	$(ESI_LOCAL_LIBS) \
-	$(SSL_LIBS) \
-	$(AUTH_ACL_LIBS) \
-	ident/libident.la \
-	acl/libacls.la \
-	eui/libeui.la \
-	acl/libstate.la \
-	$(AUTH_LIBS) \
-	acl/libapi.la \
-	base/libbase.la \
-	clients/libclients.la \
-	ftp/libftp.la \
-	libsquid.la \
-	ip/libip.la \
-	fs/libfs.la \
-	format/libformat.la \
-	ipc/libipc.la \
-	mgr/libmgr.la \
-	servers/libservers.la
 
 if ENABLE_LOADABLE_MODULES
 squid_SOURCES += $(LOADABLE_MODULES_SOURCES)
@@ -771,7 +695,7 @@ ufsdump_DEPENDENCIES = \
 	fs/libfs.la \
 	ipc/libipc.la \
 	mgr/libmgr.la \
-	$(DISK_LIBS) \
+	DiskIO/libdiskio.la \
 	$(DISK_LINKOBJS) \
 	$(REPL_OBJS)
 
@@ -811,7 +735,6 @@ EXTRA_DIST = \
 	cf_gen_defines \
 	cf.data.pre \
 	cf.data.depend \
-	DiskIO/modules.sh \
 	mk-globals-c.pl \
 	mk-globals-c.awk \
 	mk-string-arrays.pl \
@@ -821,78 +744,6 @@ EXTRA_DIST = \
 	mib.txt \
 	mime.conf.default
 
-libAIO_a_SOURCES = \
-		$(AIO_WIN32_SOURCES) \
-		DiskIO/AIO/async_io.h \
-		DiskIO/AIO/AIODiskFile.cc \
-		DiskIO/AIO/AIODiskFile.h \
-		DiskIO/AIO/AIODiskIOStrategy.cc \
-		DiskIO/AIO/AIODiskIOStrategy.h \
-		DiskIO/AIO/AIODiskIOModule.cc \
-		DiskIO/AIO/AIODiskIOModule.h
-
-libBlocking_a_SOURCES = \
-		DiskIO/Blocking/BlockingFile.cc \
-		DiskIO/Blocking/BlockingFile.h \
-		DiskIO/Blocking/BlockingIOStrategy.cc \
-		DiskIO/Blocking/BlockingIOStrategy.h \
-		DiskIO/Blocking/BlockingDiskIOModule.cc \
-		DiskIO/Blocking/BlockingDiskIOModule.h 
-
-libMmapped_a_SOURCES = \
-		DiskIO/Mmapped/MmappedFile.cc \
-		DiskIO/Mmapped/MmappedFile.h \
-		DiskIO/Mmapped/MmappedIOStrategy.cc \
-		DiskIO/Mmapped/MmappedIOStrategy.h \
-		DiskIO/Mmapped/MmappedDiskIOModule.cc \
-		DiskIO/Mmapped/MmappedDiskIOModule.h 
-
-libIpcIo_a_SOURCES = \
-		DiskIO/IpcIo/IpcIoFile.cc \
-		DiskIO/IpcIo/IpcIoFile.h \
-		DiskIO/IpcIo/IpcIoIOStrategy.cc \
-		DiskIO/IpcIo/IpcIoIOStrategy.h \
-		DiskIO/IpcIo/IpcIoDiskIOModule.cc \
-		DiskIO/IpcIo/IpcIoDiskIOModule.h 
-
-libDiskDaemon_a_SOURCES = \
-		DiskIO/DiskDaemon/DiskdFile.cc \
-		DiskIO/DiskDaemon/DiskdFile.h \
-		DiskIO/DiskDaemon/DiskdIOStrategy.cc \
-		DiskIO/DiskDaemon/DiskdIOStrategy.h \
-		DiskIO/DiskDaemon/diomsg.h \
-		DiskIO/DiskDaemon/DiskDaemonDiskIOModule.cc \
-		DiskIO/DiskDaemon/DiskDaemonDiskIOModule.h \
-		DiskIO/DiskDaemon/DiskdAction.cc \
-		DiskIO/DiskDaemon/DiskdAction.h
-
-libDiskThreads_a_SOURCES = \
-		$(AIOPS_SOURCE) \
-		DiskIO/DiskThreads/async_io.cc \
-		DiskIO/DiskThreads/DiskThreads.h \
-		DiskIO/DiskThreads/DiskThreadsDiskFile.cc \
-		DiskIO/DiskThreads/DiskThreadsDiskFile.h \
-		DiskIO/DiskThreads/DiskThreadsDiskIOModule.cc \
-		DiskIO/DiskThreads/DiskThreadsDiskIOModule.h \
-		DiskIO/DiskThreads/DiskThreadsIOStrategy.cc \
-		DiskIO/DiskThreads/DiskThreadsIOStrategy.h
-
-EXTRA_libDiskThreads_a_SOURCES = \
-	DiskIO/DiskThreads/aiops.cc \
-	DiskIO/DiskThreads/aiops_win32.cc \
-	DiskIO/DiskThreads/CommIO.cc \
-	DiskIO/DiskThreads/CommIO.h
-
-DiskIO_DiskDaemon_diskd_SOURCES = DiskIO/DiskDaemon/diskd.cc
-nodist_DiskIO_DiskDaemon_diskd_SOURCES = time.cc
-DiskIO_DiskDaemon_diskd_LDADD = \
-	$(top_builddir)/lib/libmisccontainers.la \
-	$(top_builddir)/lib/libmiscencoding.la \
-	$(top_builddir)/lib/libmiscutil.la \
-	$(COMPAT_LIB) \
-	$(XTRA_LIBS)
-
-
 DEFAULT_HTTP_PORT	= 3128
 DEFAULT_ICP_PORT	= 3130
 DEFAULT_PREFIX		= $(prefix)
@@ -931,9 +782,6 @@ err_type.cc: err_type.h mk-string-arrays.awk
 err_detail_type.cc: err_detail_type.h mk-string-arrays.awk
 	$(AWK) -f $(srcdir)/mk-string-arrays.awk < $(srcdir)/err_detail_type.h | sed 's/ERR_DETAIL_//' > $@ || ($(RM) -f $@ && exit 1)
 
-LogTags.cc: LogTags.h mk-string-arrays.awk
-	$(AWK) -f $(srcdir)/mk-string-arrays.awk < $(srcdir)/LogTags.h | sed 's/LOG_//' > $@ || ($(RM) -f $@ && exit 1)
-
 lookup_t.cc: lookup_t.h mk-string-arrays.awk
 	$(AWK) -f $(srcdir)/mk-string-arrays.awk < $(srcdir)/lookup_t.h > $@ || ($(RM) -f $@ && exit 1)
 
@@ -1038,7 +886,6 @@ uninstall-local: squid.conf.default
 	@$(SHELL) $(top_srcdir)/scripts/remove-cfg.sh "$(RM)" $(DESTDIR)$(DEFAULT_CONFIG_FILE) squid.conf.default
 
 CLEANFILES += cf.data squid.conf.default squid.conf.documented \
-	DiskIO/DiskIOModules_gen.cc \
 	test_tools.cc *.a
 
 test_tools.cc: $(top_srcdir)/test-suite/test_tools.cc
@@ -1146,8 +993,6 @@ tests_testHttpReply_SOURCES=\
 	mime_header.cc \
 	Notes.h \
 	Notes.cc \
-	Packer.cc \
-	Packer.h \
 	SquidString.h \
 	SquidTime.h \
 	$(SBUF_SOURCE) \
@@ -1172,6 +1017,7 @@ tests_testHttpReply_SOURCES=\
 	tests/stub_libauth.cc \
 	tests/stub_libcomm.cc \
 	tests/stub_libmgr.cc \
+	tests/stub_libsecurity.cc \
 	tests/stub_libsslsquid.cc \
 	StatCounters.h \
 	StatCounters.cc \
@@ -1221,8 +1067,6 @@ tests_testACLMaxUserIP_SOURCES= \
 	tests/stub_CollapsedForwarding.cc \
 	ConfigOption.cc \
 	ConfigParser.cc \
-	DiskIO/ReadRequest.cc \
-	DiskIO/WriteRequest.cc \
 	tests/stub_ETag.cc \
 	event.cc \
 	fatal.h \
@@ -1253,8 +1097,8 @@ tests_testACLMaxUserIP_SOURCES= \
 	SquidList.h \
 	SquidList.cc \
 	mem_node.cc \
-	Packer.cc \
 	Parsing.cc \
+	tests/stub_libsecurity.cc \
 	SquidMath.cc \
 	StatCounters.cc \
 	StatCounters.h \
@@ -1287,7 +1131,6 @@ tests_testACLMaxUserIP_SOURCES= \
 	tests/stub_client_side.cc \
 	tests/stub_debug.cc \
 	tests/stub_DelayId.cc \
-	tests/stub_DiskIOModule.cc \
 	tests/stub_errorpage.cc \
 	fd.h \
 	tests/stub_fd.cc \
@@ -1296,6 +1139,7 @@ tests_testACLMaxUserIP_SOURCES= \
 	tests/stub_ipc_TypedMsgHdr.cc \
 	tests/stub_libauth.cc \
 	tests/stub_libcomm.cc \
+	tests/stub_libdiskio.cc \
 	tests/stub_libformat.cc \
 	tests/stub_libsslsquid.cc \
 	tests/stub_MemObject.cc \
@@ -1345,7 +1189,6 @@ tests_testACLMaxUserIP_LDADD= \
 	$(top_builddir)/lib/libmisccontainers.la \
 	$(top_builddir)/lib/libmiscencoding.la \
 	$(top_builddir)/lib/libmiscutil.la \
-	$(DISK_OS_LIBS) \
 	$(NETTLELIB) \
 	$(REGEXLIB) \
 	$(SQUID_CPPUNIT_LIBS) \
@@ -1407,7 +1250,6 @@ tests_testCacheManager_SOURCES = \
 	carp.h \
 	tests/stub_carp.cc \
 	cbdata.cc \
-	ChunkedCodingParser.cc \
 	client_db.h \
 	client_db.cc \
 	client_side.h \
@@ -1424,7 +1266,6 @@ tests_testCacheManager_SOURCES = \
 	CpuAffinitySet.cc \
 	CpuAffinitySet.h \
 	$(DELAY_POOL_SOURCE) \
-	$(DISKIO_SOURCE) \
 	disk.h \
 	disk.cc \
 	dlink.h \
@@ -1478,6 +1319,8 @@ tests_testCacheManager_SOURCES = \
 	int.cc \
 	internal.h \
 	internal.cc \
+	LogTags.cc \
+	tests/stub_libsecurity.cc \
 	SquidList.h \
 	SquidList.cc \
 	MasterXaction.cc \
@@ -1495,7 +1338,6 @@ tests_testCacheManager_SOURCES = \
 	neighbors.cc \
 	Notes.cc \
 	Notes.h \
-	Packer.cc \
 	Parsing.cc \
 	pconn.cc \
 	peer_digest.cc \
@@ -1529,6 +1371,7 @@ tests_testCacheManager_SOURCES = \
 	StrList.cc \
 	tests/stub_libauth_acls.cc \
 	tests/stub_libauth.cc \
+	tests/stub_libdiskio.cc \
 	tests/stub_StatHist.cc \
 	stmem.cc \
 	repl_modules.h \
@@ -1572,8 +1415,7 @@ tests_testCacheManager_SOURCES = \
 	wordlist.h \
 	wordlist.cc
 nodist_tests_testCacheManager_SOURCES = \
-	$(BUILT_SOURCES) \
-	$(DISKIO_GEN_SOURCE)
+	$(BUILT_SOURCES)
 # comm.cc only requires comm/libcomm.la until fdc_table is dead.
 tests_testCacheManager_LDADD = \
 	libsquid.la \
@@ -1597,8 +1439,6 @@ tests_testCacheManager_LDADD = \
 	log/liblog.la \
 	format/libformat.la \
 	$(REPL_OBJS) \
-	$(DISK_LIBS) \
-	$(DISK_OS_LIBS) \
 	$(ADAPTATION_LIBS) \
 	$(ESI_LIBS) \
 	$(SSL_LIBS) \
@@ -1633,7 +1473,6 @@ tests_testDiskIO_SOURCES = \
 	ConfigOption.cc \
 	ConfigParser.cc \
 	$(DELAY_POOL_SOURCE) \
-	$(DISKIO_SOURCE) \
 	disk.h \
 	disk.cc \
 	tests/stub_ETag.cc \
@@ -1675,13 +1514,13 @@ tests_testDiskIO_SOURCES = \
 	mem_node.cc \
 	Notes.h \
 	Notes.cc \
-	Packer.cc \
 	Parsing.cc \
 	refresh.h \
 	refresh.cc \
 	RemovalPolicy.cc \
 	RequestFlags.h \
 	RequestFlags.cc \
+	tests/stub_libsecurity.cc \
 	StatCounters.h \
 	StatCounters.cc \
 	StatHist.h \
@@ -1760,7 +1599,6 @@ tests_testDiskIO_SOURCES = \
 	tests/stub_tools.cc
 nodist_tests_testDiskIO_SOURCES= \
 	$(TESTSOURCES) \
-	$(DISKIO_GEN_SOURCE) \
 	SquidMath.cc \
 	SquidMath.h \
 	swap_log_op.cc
@@ -1778,8 +1616,7 @@ tests_testDiskIO_LDADD = \
 	fs/libfs.la \
 	ipc/libipc.la \
 	$(REPL_OBJS) \
-	$(DISK_LIBS) \
-	$(DISK_OS_LIBS) \
+	DiskIO/libdiskio.la \
 	acl/libapi.la \
 	anyp/libanyp.la \
 	mgr/libmgr.la \
@@ -1800,7 +1637,7 @@ tests_testDiskIO_LDADD = \
 
 tests_testDiskIO_LDFLAGS = $(LIBADD_DL)
 tests_testDiskIO_DEPENDENCIES = \
-	$(DISK_LIBS) \
+	DiskIO/libdiskio.la \
 	$(SWAP_TEST_DS) \
 	$(SQUID_CPPUNIT_LA)
 
@@ -1838,7 +1675,6 @@ tests_testEvent_SOURCES = \
 	carp.h \
 	tests/stub_carp.cc \
 	cbdata.cc \
-	ChunkedCodingParser.cc \
 	client_db.h \
 	client_db.cc \
 	client_side.h \
@@ -1856,7 +1692,6 @@ tests_testEvent_SOURCES = \
 	CpuAffinitySet.h \
 	debug.cc \
 	$(DELAY_POOL_SOURCE) \
-	$(DISKIO_SOURCE) \
 	disk.h \
 	disk.cc \
 	dlink.h \
@@ -1917,6 +1752,8 @@ tests_testEvent_SOURCES = \
 	int.cc \
 	internal.h \
 	internal.cc \
+	LogTags.cc \
+	tests/stub_libsecurity.cc \
 	SquidList.h \
 	SquidList.cc \
 	MasterXaction.cc \
@@ -1935,7 +1772,6 @@ tests_testEvent_SOURCES = \
 	neighbors.cc \
 	Notes.cc \
 	Notes.h \
-	Packer.cc \
 	Parsing.cc \
 	pconn.cc \
 	peer_digest.cc \
@@ -1998,6 +1834,7 @@ tests_testEvent_SOURCES = \
 	tests/stub_ipc_Forwarder.cc \
 	tests/stub_libauth_acls.cc \
 	tests/stub_libauth.cc \
+	tests/stub_libdiskio.cc \
 	tests/stub_libeui.cc \
 	tests/stub_store_stats.cc \
 	time.cc \
@@ -2018,8 +1855,7 @@ tests_testEvent_SOURCES = \
 	wordlist.h \
 	wordlist.cc
 nodist_tests_testEvent_SOURCES = \
-	$(BUILT_SOURCES) \
-	$(DISKIO_GEN_SOURCE)
+	$(BUILT_SOURCES)
 tests_testEvent_LDADD = \
 	libsquid.la \
 	clients/libclients.la \
@@ -2048,8 +1884,6 @@ tests_testEvent_LDADD = \
 	$(top_builddir)/lib/libmisccontainers.la \
 	$(top_builddir)/lib/libmiscencoding.la \
 	$(top_builddir)/lib/libmiscutil.la \
-	$(DISK_LIBS) \
-	$(DISK_OS_LIBS) \
 	ipc/libipc.la \
 	mgr/libmgr.la \
 	$(SNMP_LIBS) \
@@ -2084,7 +1918,6 @@ tests_testEventLoop_SOURCES = \
 	carp.h \
 	tests/stub_carp.cc \
 	cbdata.cc \
-	ChunkedCodingParser.cc \
 	client_db.h \
 	client_db.cc \
 	client_side.h \
@@ -2102,7 +1935,6 @@ tests_testEventLoop_SOURCES = \
 	CpuAffinitySet.h \
 	debug.cc \
 	$(DELAY_POOL_SOURCE) \
-	$(DISKIO_SOURCE) \
 	disk.h \
 	disk.cc \
 	dlink.h \
@@ -2163,6 +1995,7 @@ tests_testEventLoop_SOURCES = \
 	int.cc \
 	internal.h \
 	internal.cc \
+	LogTags.cc \
 	SquidList.h \
 	SquidList.cc \
 	MasterXaction.cc \
@@ -2181,7 +2014,6 @@ tests_testEventLoop_SOURCES = \
 	neighbors.cc \
 	Notes.cc \
 	Notes.h \
-	Packer.cc \
 	Parsing.cc \
 	pconn.cc \
 	peer_digest.cc \
@@ -2243,7 +2075,9 @@ tests_testEventLoop_SOURCES = \
 	tests/stub_ipc_Forwarder.cc \
 	tests/stub_libauth_acls.cc \
 	tests/stub_libauth.cc \
+	tests/stub_libdiskio.cc \
 	tests/stub_libeui.cc \
+	tests/stub_libsecurity.cc \
 	tests/stub_store_stats.cc \
 	time.cc \
 	tools.h \
@@ -2263,8 +2097,7 @@ tests_testEventLoop_SOURCES = \
 	wordlist.h \
 	wordlist.cc
 nodist_tests_testEventLoop_SOURCES = \
-	$(BUILT_SOURCES) \
-	$(DISKIO_GEN_SOURCE)
+	$(BUILT_SOURCES)
 tests_testEventLoop_LDADD = \
 	libsquid.la \
 	clients/libclients.la \
@@ -2293,8 +2126,6 @@ tests_testEventLoop_LDADD = \
 	$(top_builddir)/lib/libmisccontainers.la \
 	$(top_builddir)/lib/libmiscencoding.la \
 	$(top_builddir)/lib/libmiscutil.la \
-	$(DISK_LIBS) \
-	$(DISK_OS_LIBS) \
 	ipc/libipc.la \
 	mgr/libmgr.la \
 	$(SNMP_LIBS) \
@@ -2328,7 +2159,6 @@ tests_test_http_range_SOURCES = \
 	carp.h \
 	tests/stub_carp.cc \
 	cbdata.cc \
-	ChunkedCodingParser.cc \
 	client_db.h \
 	client_db.cc \
 	client_side.h \
@@ -2346,7 +2176,6 @@ tests_test_http_range_SOURCES = \
 	CpuAffinitySet.h \
 	debug.cc \
 	$(DELAY_POOL_SOURCE) \
-	$(DISKIO_SOURCE) \
 	disk.h \
 	disk.cc \
 	dlink.h \
@@ -2404,6 +2233,7 @@ tests_test_http_range_SOURCES = \
 	internal.cc \
 	$(IPC_SOURCE) \
 	ipcache.cc \
+	LogTags.cc \
 	SquidList.h \
 	SquidList.cc \
 	MasterXaction.cc \
@@ -2422,7 +2252,6 @@ tests_test_http_range_SOURCES = \
 	neighbors.cc \
 	Notes.cc \
 	Notes.h \
-	Packer.cc \
 	Parsing.cc \
 	peer_digest.cc \
 	peer_proxy_negotiate_auth.h \
@@ -2482,7 +2311,9 @@ tests_test_http_range_SOURCES = \
 	tests/test_http_range.cc \
 	tests/stub_external_acl.cc \
 	tests/stub_ipc_Forwarder.cc \
+	tests/stub_libdiskio.cc \
 	tests/stub_libeui.cc \
+	tests/stub_libsecurity.cc \
 	tests/stub_main_cc.cc \
 	tests/stub_MemStore.cc \
 	tests/stub_store_stats.cc \
@@ -2503,8 +2334,7 @@ tests_test_http_range_SOURCES = \
 	wordlist.h \
 	wordlist.cc
 nodist_tests_test_http_range_SOURCES = \
-	$(BUILT_SOURCES) \
-	$(DISKIO_GEN_SOURCE)
+	$(BUILT_SOURCES)
 tests_test_http_range_LDADD = \
 	libsquid.la \
 	clients/libclients.la \
@@ -2526,8 +2356,6 @@ tests_test_http_range_LDADD = \
 	log/liblog.la \
 	format/libformat.la \
 	$(REPL_OBJS) \
-	$(DISK_LIBS) \
-	$(DISK_OS_LIBS) \
 	$(ADAPTATION_LIBS) \
 	$(ESI_LIBS) \
 	$(SSL_LIBS) \
@@ -2571,6 +2399,7 @@ tests_testHttp1Parser_SOURCES = \
 	tests/stub_debug.cc \
 	tests/stub_event.cc \
 	tests/stub_HelperChildConfig.cc \
+	tests/stub_libsecurity.cc \
 	tests/stub_stmem.cc \
 	tests/stub_store.cc \
 	tests/stub_store_stats.cc \
@@ -2610,10 +2439,10 @@ tests_testHttpRequest_SOURCES = \
 	tests/testHttpRequest.cc \
 	tests/testHttpRequestMethod.h \
 	tests/testHttpRequestMethod.cc \
-	tests/stub_DiskIOModule.cc \
 	tests/stub_libauth.cc \
 	tests/stub_main_cc.cc \
 	tests/stub_ipc_Forwarder.cc \
+	tests/stub_libdiskio.cc \
 	tests/stub_libeui.cc \
 	tests/stub_store_stats.cc \
 	tests/stub_EventLoop.cc \
@@ -2634,7 +2463,6 @@ tests_testHttpRequest_SOURCES = \
 	carp.h \
 	tests/stub_carp.cc \
 	cbdata.cc \
-	ChunkedCodingParser.cc \
 	client_db.h \
 	client_db.cc \
 	client_side.h \
@@ -2700,6 +2528,8 @@ tests_testHttpRequest_SOURCES = \
 	int.cc \
 	internal.h \
 	internal.cc \
+	LogTags.cc \
+	tests/stub_libsecurity.cc \
 	SquidList.h \
 	SquidList.cc \
 	MasterXaction.cc \
@@ -2717,7 +2547,6 @@ tests_testHttpRequest_SOURCES = \
 	neighbors.cc \
 	Notes.cc \
 	Notes.h \
-	Packer.cc \
 	Parsing.cc \
 	pconn.cc \
 	peer_digest.cc \
@@ -2826,7 +2655,6 @@ tests_testHttpRequest_LDADD = \
 	$(top_builddir)/lib/libmisccontainers.la \
 	$(top_builddir)/lib/libmiscencoding.la \
 	$(top_builddir)/lib/libmiscutil.la \
-	$(DISK_OS_LIBS) \
 	$(NETTLELIB) \
 	$(REGEXLIB) \
 	$(SQUID_CPPUNIT_LIBS) \
@@ -2853,8 +2681,6 @@ tests_testStore_SOURCES= \
 	$(DELAY_POOL_SOURCE) \
 	disk.h \
 	disk.cc \
-	DiskIO/ReadRequest.cc \
-	DiskIO/WriteRequest.cc \
 	ETag.cc \
 	event.cc \
 	EventLoop.cc \
@@ -2889,7 +2715,6 @@ tests_testStore_SOURCES= \
 	MemObject.cc \
 	Notes.h \
 	Notes.cc \
-	Packer.cc \
 	Parsing.cc \
 	RemovalPolicy.cc \
 	refresh.h \
@@ -2928,7 +2753,6 @@ tests_testStore_SOURCES= \
 	tests/stub_client_side_request.cc \
 	tests/stub_comm.cc \
 	tests/stub_debug.cc \
-	tests/stub_DiskIOModule.cc \
 	tests/stub_errorpage.cc \
 	fd.h \
 	fde.h \
@@ -2938,7 +2762,9 @@ tests_testStore_SOURCES= \
 	tests/stub_http.cc \
 	tests/stub_libauth.cc \
 	tests/stub_libeui.cc \
+	tests/stub_libdiskio.cc \
 	tests/stub_libformat.cc \
+	tests/stub_libsecurity.cc \
 	tests/stub_libsslsquid.cc \
 	HttpBody.h \
 	HttpBody.cc \
@@ -2998,6 +2824,7 @@ tests_testStore_LDADD= \
 	ipc/libipc.la \
 	anyp/libanyp.la \
 	mem/libmem.la \
+	DiskIO/libdiskio.la \
 	$(top_builddir)/lib/libmisccontainers.la \
 	$(top_builddir)/lib/libmiscencoding.la \
 	$(top_builddir)/lib/libmiscutil.la \
@@ -3029,6 +2856,7 @@ tests_testString_SOURCES = \
 	YesNoNone.h \
 	tests/stub_cache_cf.cc \
 	tests/stub_cache_manager.cc \
+	tests/stub_cbdata.cc \
 	tests/stub_debug.cc \
 	tests/stub_HelperChildConfig.cc \
 	tools.h \
@@ -3054,7 +2882,6 @@ tests_testString_DEPENDENCIES = \
 
 SWAP_TEST_DS =\
 	repl_modules.o \
-	$(DISK_LIBS) \
 	ident/libident.la \
 	acl/libacls.la \
 	acl/libstate.la \
@@ -3063,6 +2890,7 @@ SWAP_TEST_DS =\
 	libsquid.la \
 	ip/libip.la \
 	fs/libfs.la \
+	DiskIO/libdiskio.la \
 	ipc/libipc.la \
 	mgr/libmgr.la \
 	$(REPL_OBJS) \
@@ -3088,6 +2916,7 @@ tests_testUfs_SOURCES = \
 	internal.h \
 	tests/stub_internal.cc \
 	tests/stub_libformat.cc \
+	tests/stub_libsecurity.cc \
 	tests/stub_stat.cc \
 	store_rebuild.h \
 	tests/stub_store_rebuild.cc \
@@ -3170,7 +2999,6 @@ tests_testUfs_SOURCES = \
 	ClientInfo.h \
 	MemBuf.cc \
 	HttpHdrContRange.cc \
-	Packer.cc \
 	HttpHeaderFieldStat.h \
 	HttpHdrCc.h \
 	HttpHdrCc.cc \
@@ -3199,12 +3027,10 @@ tests_testUfs_SOURCES = \
 	tests/testStoreSupport.h \
 	time.cc \
 	wordlist.h \
-	wordlist.cc \
-	$(DISKIO_SOURCE)
+	wordlist.cc
 
 nodist_tests_testUfs_SOURCES = \
 	$(TESTSOURCES) \
-	$(DISKIO_GEN_SOURCE) \
 	SquidMath.cc \
 	SquidMath.h \
 	swap_log_op.cc
@@ -3222,8 +3048,7 @@ tests_testUfs_LDADD = \
 	mgr/libmgr.la \
 	$(REPL_OBJS) \
 	acl/libacls.la \
-	$(DISK_LIBS) \
-	$(DISK_OS_LIBS) \
+	DiskIO/libdiskio.la \
 	acl/libapi.la \
 	$(SSL_LIBS) \
 	ipc/libipc.la \
@@ -3307,7 +3132,6 @@ tests_testRock_SOURCES = \
 	mem_node.cc \
 	Notes.h \
 	Notes.cc \
-	Packer.cc \
 	Parsing.cc \
 	RemovalPolicy.cc \
 	RequestFlags.cc \
@@ -3366,6 +3190,7 @@ tests_testRock_SOURCES = \
 	tests/stub_libformat.cc \
 	tests/stub_libicmp.cc \
 	tests/stub_libmgr.cc \
+	tests/stub_libsecurity.cc \
 	tests/stub_MemStore.cc \
 	mime.h \
 	tests/stub_mime.cc \
@@ -3383,10 +3208,8 @@ tests_testRock_SOURCES = \
 	wordlist.h \
 	wordlist.cc \
 	$(DELAY_POOL_SOURCE) \
-	$(DISKIO_SOURCE) \
 	$(UNLINKDSOURCE)
 nodist_tests_testRock_SOURCES = \
-	$(DISKIO_GEN_SOURCE) \
 	swap_log_op.cc \
 	SquidMath.cc \
 	SquidMath.h \
@@ -3400,8 +3223,7 @@ tests_testRock_LDADD = \
 	fs/libfs.la \
 	$(COMMON_LIBS) \
 	$(REPL_OBJS) \
-	$(DISK_LIBS) \
-	$(DISK_OS_LIBS) \
+	DiskIO/libdiskio.la \
 	acl/libacls.la \
 	acl/libapi.la \
 	acl/libstate.la \
@@ -3443,7 +3265,6 @@ tests_testURL_SOURCES = \
 	carp.h \
 	tests/stub_carp.cc \
 	cbdata.cc \
-	ChunkedCodingParser.cc \
 	client_db.h \
 	client_db.cc \
 	client_side.h \
@@ -3462,8 +3283,6 @@ tests_testURL_SOURCES = \
 	$(DELAY_POOL_SOURCE) \
 	disk.h \
 	disk.cc \
-	DiskIO/ReadRequest.cc \
-	DiskIO/WriteRequest.cc \
 	dlink.h \
 	dlink.cc \
 	$(DNSSOURCE) \
@@ -3519,6 +3338,7 @@ tests_testURL_SOURCES = \
 	int.cc \
 	internal.h \
 	internal.cc \
+	LogTags.cc \
 	SquidList.h \
 	SquidList.cc \
 	MasterXaction.cc \
@@ -3537,7 +3357,6 @@ tests_testURL_SOURCES = \
 	neighbors.cc \
 	Notes.h \
 	Notes.cc \
-	Packer.cc \
 	Parsing.cc \
 	pconn.cc \
 	peer_digest.cc \
@@ -3596,9 +3415,10 @@ tests_testURL_SOURCES = \
 	tests/stub_SwapDir.cc \
 	MemStore.cc \
 	tests/stub_debug.cc \
-	tests/stub_DiskIOModule.cc \
 	tests/stub_libauth_acls.cc \
 	tests/stub_libauth.cc \
+	tests/stub_libdiskio.cc \
+	tests/stub_libsecurity.cc \
 	tests/stub_main_cc.cc \
 	tests/stub_ipc_Forwarder.cc \
 	tests/stub_store_stats.cc \
@@ -3649,7 +3469,6 @@ tests_testURL_LDADD = \
 	icmp/libicmp.la icmp/libicmp-core.la \
 	comm/libcomm.la \
 	log/liblog.la \
-	$(DISK_OS_LIBS) \
 	format/libformat.la \
 	$(REGEXLIB) \
 	$(REPL_OBJS) \
@@ -3687,6 +3506,7 @@ tests_testSBuf_SOURCES= \
 	tests/stub_libmem.cc \
 	tests/stub_cache_cf.cc \
 	tests/stub_cache_manager.cc \
+	tests/stub_cbdata.cc \
 	tests/stub_store.cc \
 	tests/stub_store_stats.cc \
 	tests/stub_tools.cc \
@@ -3770,6 +3590,7 @@ tests_testConfigParser_SOURCES = \
 	YesNoNone.h \
 	tests/stub_cache_cf.cc \
 	tests/stub_cache_manager.cc \
+	tests/stub_cbdata.cc \
 	tests/stub_debug.cc \
 	tests/stub_HelperChildConfig.cc \
 	tools.h \
@@ -222,7 +222,7 @@ void MemBuf::truncate(mb_size_t tailSize)
  * calls memcpy, appends exactly size bytes,
  * extends buffer or creates buffer if needed.
  */
-void MemBuf::append(const char *newContent, mb_size_t sz)
+void MemBuf::append(const char *newContent, int sz)
 {
     assert(sz >= 0);
     assert(buf || (0==capacity && 0==size));
@@ -262,21 +262,11 @@ void MemBuf::terminate()
     *space() = '\0';
 }
 
-/* calls memBufVPrintf */
-void
-MemBuf::Printf(const char *fmt,...)
-{
-    va_list args;
-    va_start(args, fmt);
-    vPrintf(fmt, args);
-    va_end(args);
-}
-
 /**
- * vPrintf for other printf()'s to use; calls vsnprintf, extends buf if needed
+ * vappendf for other printf()'s to use; calls vsnprintf, extends buf if needed
  */
 void
-MemBuf::vPrintf(const char *fmt, va_list vargs)
+MemBuf::vappendf(const char *fmt, va_list vargs)
 {
 #ifdef VA_COPY
     va_list ap;
@@ -397,6 +387,6 @@ void
 memBufReport(MemBuf * mb)
 {
     assert(mb);
-    mb->Printf("memBufReport is not yet implemented @?@\n");
+    mb->appendf("memBufReport is not yet implemented @?@\n");
 }
 
@@ -9,14 +9,14 @@
 #ifndef SQUID_MEMBUF_H
 #define SQUID_MEMBUF_H
 
+#include "base/Packable.h"
 #include "cbdata.h"
-#include "Packer.h"
 
 /**
- * Auto-growing memory-resident buffer with printf interface
+ * Auto-growing memory-resident buffer with Packable interface
  * \deprecated Use SBuf instead.
  */
-class MemBuf
+class MemBuf : public Packable
 {
     CBDATA_CLASS(MemBuf);
 
@@ -28,7 +28,7 @@ class MemBuf
         capacity(0),
         stolen(0)
     {}
-    ~MemBuf() {
+    virtual ~MemBuf() {
         if (!stolen && buf)
             clean();
     }
@@ -75,7 +75,6 @@ class MemBuf
     void consume(mb_size_t sz);  // removes sz bytes, moving content left
     void consumeWhitespacePrefix();    ///< removes all prefix whitespace, moving content left
 
-    void append(const char *c, mb_size_t sz); // grows if needed and possible
     void appended(mb_size_t sz); // updates content size after external append
     void truncate(mb_size_t sz);  // removes sz last bytes
 
@@ -98,23 +97,17 @@ class MemBuf
     /** unfirtunate hack to test if the buffer has been Init()ialized */
     int isNull();
 
-    /**
-     * calls snprintf, extends buffer if needed
-     \note  we use Printf instead of printf so the compiler won't
-     *      think we're calling the libc printf()
-     */
-    void Printf(const char *fmt,...) PRINTF_FORMAT_ARG2;
-
-    /** vPrintf for other printf()'s to use */
-    void vPrintf(const char *fmt, va_list ap);
-
     /**
      * freezes the object! and returns function to clear it up.
      *
      \retval free() function to be used.
      */
     FREE *freeFunc();
 
+    /* Packable API */
+    virtual void append(const char *c, int sz);
+    virtual void vappendf(const char *fmt, va_list ap);
+
 private:
     /**
      * private copy constructor and assignment operator generates
@@ -161,8 +154,6 @@ class MemBuf
 
 /** returns free() function to be used, _freezes_ the object! */
 void memBufReport(MemBuf * mb);
-/** pack content into a mem buf. */
-void packerToMemInit(Packer * p, MemBuf * mb);
 
 #endif /* SQUID_MEMBUF_H */
 
@@ -92,22 +92,31 @@ MemObject::setUris(char const *aStoreId, char const *aLogUri, const HttpRequestM
 #endif
 }
 
-MemObject::MemObject(): smpCollapsed(false)
+MemObject::MemObject() :
+    inmem_lo(0),
+    nclients(0),
+    smpCollapsed(false),
+    request(NULL),
+    ping_reply_callback(NULL),
+    ircb_data(NULL),
+    id(0),
+    object_sz(-1),
+    swap_hdr_sz(0),
+#if URL_CHECKSUM_DEBUG
+    chksum(0),
+#endif
+    vary_headers(NULL)
 {
-    debugs(20, 3, HERE << "new MemObject " << this);
+    debugs(20, 3, "new MemObject " << this);
+    memset(&start_ping, 0, sizeof(start_ping));
+    memset(&abort, 0, sizeof(abort));
     _reply = new HttpReply;
     HTTPMSGLOCK(_reply);
-
-    object_sz = -1;
-
-    /* XXX account log_url */
-
-    swapout.decision = SwapOut::swNeedsCheck;
 }
 
 MemObject::~MemObject()
 {
-    debugs(20, 3, HERE << "del MemObject " << this);
+    debugs(20, 3, "del MemObject " << this);
     const Ctx ctx = ctx_enter(hasUris() ? urlXXX() : "[unknown_ctx]");
 
 #if URL_CHECKSUM_DEBUG
@@ -220,28 +229,24 @@ struct StoreClientStats : public unary_function<store_client, void> {
 void
 MemObject::stat(MemBuf * mb) const
 {
-    mb->Printf("\t" SQUIDSBUFPH " %s\n", SQUIDSBUFPRINT(method.image()), logUri());
+    mb->appendf("\t" SQUIDSBUFPH " %s\n", SQUIDSBUFPRINT(method.image()), logUri());
     if (vary_headers)
-        mb->Printf("\tvary_headers: %s\n", vary_headers);
-    mb->Printf("\tinmem_lo: %" PRId64 "\n", inmem_lo);
-    mb->Printf("\tinmem_hi: %" PRId64 "\n", data_hdr.endOffset());
-    mb->Printf("\tswapout: %" PRId64 " bytes queued\n",
-               swapout.queue_offset);
+        mb->appendf("\tvary_headers: %s\n", vary_headers);
+    mb->appendf("\tinmem_lo: %" PRId64 "\n", inmem_lo);
+    mb->appendf("\tinmem_hi: %" PRId64 "\n", data_hdr.endOffset());
+    mb->appendf("\tswapout: %" PRId64 " bytes queued\n", swapout.queue_offset);
 
     if (swapout.sio.getRaw())
-        mb->Printf("\tswapout: %" PRId64 " bytes written\n",
-                   (int64_t) swapout.sio->offset());
+        mb->appendf("\tswapout: %" PRId64 " bytes written\n", (int64_t) swapout.sio->offset());
 
     if (xitTable.index >= 0)
-        mb->Printf("\ttransient index: %d state: %d\n",
-                   xitTable.index, xitTable.io);
+        mb->appendf("\ttransient index: %d state: %d\n", xitTable.index, xitTable.io);
     if (memCache.index >= 0)
-        mb->Printf("\tmem-cache index: %d state: %d offset: %" PRId64 "\n",
-                   memCache.index, memCache.io, memCache.offset);
+        mb->appendf("\tmem-cache index: %d state: %d offset: %" PRId64 "\n", memCache.index, memCache.io, memCache.offset);
     if (object_sz >= 0)
-        mb->Printf("\tobject_sz: %" PRId64 "\n", object_sz);
+        mb->appendf("\tobject_sz: %" PRId64 "\n", object_sz);
     if (smpCollapsed)
-        mb->Printf("\tsmp-collapsed\n");
+        mb->appendf("\tsmp-collapsed\n");
 
     StoreClientStats statsVisitor(mb);
 
@@ -96,7 +96,6 @@ class MemObject
     int64_t inmem_lo;
     dlink_list clients;
 
-    /** \todo move into .cc or .cci */
     size_t clientCount() const {return nclients;}
 
     bool clientIsFirst(void *sc) const {return (clients.head && sc == clients.head->data);}
@@ -105,8 +104,9 @@ class MemObject
 
     class SwapOut
     {
-
     public:
+        SwapOut() : queue_offset(0), decision(swNeedsCheck) {}
+
         int64_t queue_offset; ///< number of bytes sent to SwapDir for writing
         StoreIOState::Pointer sio;
 
@@ -801,12 +801,8 @@ MemStoreRr::finalizeConfig()
 {
     // decide whether to use a shared memory cache if the user did not specify
     if (!Config.memShared.configured()) {
-        Config.memShared.configure(Ipc::Atomic::Enabled() &&
-                                   Ipc::Mem::Segment::Enabled() && UsingSmp() &&
+        Config.memShared.configure(Ipc::Mem::Segment::Enabled() && UsingSmp() &&
                                    Config.memMaxSize > 0);
-    } else if (Config.memShared && !Ipc::Atomic::Enabled()) {
-        // bail if the user wants shared memory cache but we cannot support it
-        fatal("memory_cache_shared is on, but no support for atomic operations detected");
     } else if (Config.memShared && !Ipc::Mem::Segment::Enabled()) {
         fatal("memory_cache_shared is on, but no support for shared memory detected");
     } else if (Config.memShared && !UsingSmp()) {
@@ -1,141 +0,0 @@
-/*
- * Copyright (C) 1996-2015 The Squid Software Foundation and contributors
- *
- * Squid software is distributed under GPLv2+ license and includes
- * contributions from numerous individuals and organizations.
- * Please see the COPYING and CONTRIBUTORS files for details.
- */
-
-/* DEBUG: section 60    Packer: A uniform interface to store-like modules */
-
-/*
- * Rationale:
- * ----------
- *
- * OK, we have two major interfaces comm.c and store.c.
- *
- * Store.c has a nice storeAppend[Printf] capability which makes "storing"
- * things easy and painless.
- *
- * Comm.c lacks commAppend[Printf] because comm does not handle its own
- * buffers (no mem_obj equivalent for comm.c).
- *
- * Thus, if one wants to be able to store _and_ Comm::Write an object, s/he
- * has to implement two almost identical functions.
- *
- * Packer
- * ------
- *
- * Packer provides for a more uniform interface to store and comm modules.
- * Packer has its own append and printf routines that "know" where to send
- * incoming data. In case of store interface, Packer sends data to
- * storeAppend.  Otherwise, Packer uses a MemBuf that can be flushed later to
- * Comm::Write.
- *
- * Thus, one can write just one function that will either "pack" things for
- * Comm::Write or "append" things to store, depending on actual packer
- * supplied.
- *
- * It is amazing how much work a tiny object can save. :)
- */
-
-#include "squid.h"
-#include "MemBuf.h"
-#include "Store.h"
-
-/*
- * We do have one potential problem here. Both append_f and vprintf_f types
- * cannot match real functions precisely (at least because of the difference in
- * the type of the first parameter). Thus, we have to use type cast. If somebody
- * changes the prototypes of real functions, Packer will not notice that because
- * of the type cast.
- *
- * Solution: we use the constants below to *hard code* current prototypes of
- * real functions. If real prototypes change, these constants will produce a
- * warning (e.g., "warning: assignment from incompatible pointer type").
- */
-
-static void
-memBufAppend(MemBuf *mb, const char *buf, mb_size_t len)
-{
-    mb->append(buf, len);
-}
-
-static void
-memBufVPrintf(MemBuf * mb, const char *fmt, va_list vargs)
-{
-    mb->vPrintf(fmt, vargs);
-}
-
-static void
-storeEntryAppend(StoreEntry *e, const char *buf, int len)
-{
-    e->append(buf, len);
-}
-
-/* append()'s */
-static void (*const store_append) (StoreEntry *, const char *, int) = &storeEntryAppend;
-static void (*const memBuf_append) (MemBuf *, const char *, mb_size_t) = &memBufAppend;
-
-/* vprintf()'s */
-static void (*const store_vprintf) (StoreEntry *, const char *, va_list ap) = &storeAppendVPrintf;
-static void (*const memBuf_vprintf) (MemBuf *, const char *, va_list ap) = &memBufVPrintf;
-
-/* init/clean */
-
-/* init with this to forward data to StoreEntry */
-void
-packerToStoreInit(Packer * p, StoreEntry * e)
-{
-    assert(p && e);
-    p->append = (append_f) store_append;
-    p->packer_vprintf = (vprintf_f) store_vprintf;
-    p->real_handler = e;
-    e->buffer();
-}
-
-/* init with this to accumulate data in MemBuf */
-void
-packerToMemInit(Packer * p, MemBuf * mb)
-{
-    assert(p && mb);
-    p->append = (append_f) memBuf_append;
-    p->packer_vprintf = (vprintf_f) memBuf_vprintf;
-    p->real_handler = mb;
-}
-
-/* call this when you are done */
-void
-packerClean(Packer * p)
-{
-    assert(p);
-
-    if (p->append == (append_f) store_append && p->real_handler)
-        static_cast<StoreEntry*>(p->real_handler)->flush();
-
-    /* it is not really necessary to do this, but, just in case... */
-    p->append = NULL;
-    p->packer_vprintf = NULL;
-    p->real_handler = NULL;
-}
-
-void
-packerAppend(Packer * p, const char *buf, int sz)
-{
-    assert(p);
-    assert(p->real_handler && p->append);
-    p->append(p->real_handler, buf, sz);
-}
-
-void
-packerPrintf(Packer * p, const char *fmt,...)
-{
-    va_list args;
-    va_start(args, fmt);
-
-    assert(p);
-    assert(p->real_handler && p->packer_vprintf);
-    p->packer_vprintf(p->real_handler, fmt, args);
-    va_end(args);
-}
-
@@ -1,37 +0,0 @@
-/*
- * Copyright (C) 1996-2015 The Squid Software Foundation and contributors
- *
- * Squid software is distributed under GPLv2+ license and includes
- * contributions from numerous individuals and organizations.
- * Please see the COPYING and CONTRIBUTORS files for details.
- */
-
-#ifndef SQUID_PACKER_H
-#define SQUID_PACKER_H
-
-/* see Packer.cc for description */
-class Packer;
-
-/* a common objPackInto interface; used by debugObj */
-typedef void (*ObjPackMethod) (void *obj, Packer * p);
-
-/* append/vprintf's for Packer */
-typedef void (*append_f) (void *, const char *buf, int size);
-typedef void (*vprintf_f) (void *, const char *fmt, va_list args);
-
-class Packer
-{
-
-public:
-    /* protected, use interface functions instead */
-    append_f append;
-    vprintf_f packer_vprintf;
-    void *real_handler;     /* first parameter to real append and vprintf */
-};
-
-void packerClean(Packer * p);
-void packerAppend(Packer * p, const char *buf, int size);
-void packerPrintf(Packer * p, const char *fmt,...) PRINTF_FORMAT_ARG2;
-
-#endif /* SQUID_PACKER_H */
-
@@ -24,21 +24,23 @@
 #include "SquidTime.h"
 #if USE_OPENSSL
 #include "ssl/PeerConnector.h"
+#else
+#include "security/EncryptorAnswer.h"
 #endif
 
 CBDATA_CLASS_INIT(PeerPoolMgr);
 
 #if USE_OPENSSL
 /// Gives Ssl::PeerConnector access to Answer in the PeerPoolMgr callback dialer.
-class MyAnswerDialer: public UnaryMemFunT<PeerPoolMgr, Ssl::PeerConnectorAnswer, Ssl::PeerConnectorAnswer&>,
+class MyAnswerDialer: public UnaryMemFunT<PeerPoolMgr, Security::EncryptorAnswer, Security::EncryptorAnswer&>,
     public Ssl::PeerConnector::CbDialer
 {
 public:
     MyAnswerDialer(const JobPointer &aJob, Method aMethod):
-        UnaryMemFunT<PeerPoolMgr, Ssl::PeerConnectorAnswer, Ssl::PeerConnectorAnswer&>(aJob, aMethod, Ssl::PeerConnectorAnswer()) {}
+        UnaryMemFunT<PeerPoolMgr, Security::EncryptorAnswer, Security::EncryptorAnswer&>(aJob, aMethod, Security::EncryptorAnswer()) {}
 
     /* Ssl::PeerConnector::CbDialer API */
-    virtual Ssl::PeerConnectorAnswer &answer() { return arg1; }
+    virtual Security::EncryptorAnswer &answer() { return arg1; }
 };
 #endif
 
@@ -65,7 +67,7 @@ PeerPoolMgr::start()
     // ErrorState, getOutgoingAddress(), and other APIs may require a request.
     // We fake one. TODO: Optionally send this request to peers?
     request = new HttpRequest(Http::METHOD_OPTIONS, AnyP::PROTO_HTTP, "*");
-    request->SetHost(peer->host);
+    request->url.host(peer->host);
 
     checkpoint("peer initialized");
 }
@@ -113,7 +115,7 @@ PeerPoolMgr::handleOpenedConnection(const CommConnectCbParams &params)
 
 #if USE_OPENSSL
     // Handle SSL peers.
-    if (peer->use_ssl) {
+    if (peer->secure.encryptTransport) {
         typedef CommCbMemFunT<PeerPoolMgr, CommCloseCbParams> CloserDialer;
         closer = JobCallback(48, 3, CloserDialer, this,
                              PeerPoolMgr::handleSecureClosure);
@@ -127,8 +129,8 @@ PeerPoolMgr::handleOpenedConnection(const CommConnectCbParams &params)
         const int timeUsed = squid_curtime - params.conn->startTime();
         // Use positive timeout when less than one second is left for conn.
         const int timeLeft = max(1, (peerTimeout - timeUsed));
-        Ssl::PeerConnector *connector =
-            new Ssl::PeerConnector(request, params.conn, NULL, securer, timeLeft);
+        Ssl::BlindPeerConnector *connector =
+            new Ssl::BlindPeerConnector(request, params.conn, securer, timeLeft);
         AsyncJob::Start(connector); // will call our callback
         return;
     }
@@ -146,9 +148,8 @@ PeerPoolMgr::pushNewConnection(const Comm::ConnectionPointer &conn)
     // push() will trigger a checkpoint()
 }
 
-#if USE_OPENSSL
 void
-PeerPoolMgr::handleSecuredPeer(Ssl::PeerConnectorAnswer &answer)
+PeerPoolMgr::handleSecuredPeer(Security::EncryptorAnswer &answer)
 {
     Must(securer != NULL);
     securer = NULL;
@@ -190,7 +191,6 @@ PeerPoolMgr::handleSecureClosure(const CommCloseCbParams &params)
     // allow the closing connection to fully close before we check again
     Checkpoint(this, "conn closure while securing");
 }
-#endif
 
 void
 PeerPoolMgr::openNewConnection()
@@ -11,18 +11,12 @@
 
 #include "base/AsyncJob.h"
 #include "comm/forward.h"
+#include "security/forward.h"
 
 class HttpRequest;
 class CachePeer;
 class CommConnectCbParams;
 
-#if USE_OPENSSL
-namespace Ssl
-{
-class PeerConnectorAnswer;
-}
-#endif
-
 /// Maintains an fixed-size "standby" PconnPool for a single CachePeer.
 class PeerPoolMgr: public AsyncJob
 {
@@ -56,12 +50,13 @@ class PeerPoolMgr: public AsyncJob
 
     /// Comm::ConnOpener calls this when done opening a connection for us
     void handleOpenedConnection(const CommConnectCbParams &params);
-#if USE_OPENSSL
+
     /// Ssl::PeerConnector callback
-    void handleSecuredPeer(Ssl::PeerConnectorAnswer &answer);
+    void handleSecuredPeer(Security::EncryptorAnswer &answer);
+
     /// called when the connection we are trying to secure is closed by a 3rd party
     void handleSecureClosure(const CommCloseCbParams &params);
-#endif
+
     /// the final step in connection opening (and, optionally, securing) sequence
     void pushNewConnection(const Comm::ConnectionPointer &conn);
 
@@ -53,7 +53,7 @@ class ps_state
 
     // Produce a URL for display identifying the transaction we are
     // trying to locate a peer for.
-    const char * url() const;
+    const SBuf url() const;
 
     HttpRequest *request;
     AccessLogEntry::Pointer al; ///< info for the future access.log entry
@@ -32,7 +32,6 @@ class RefreshPattern
         bool reload_into_ims;
         bool ignore_reload;
         bool ignore_no_store;
-        bool ignore_must_revalidate;
         bool ignore_private;
 #endif
     } flags;
@@ -182,7 +182,7 @@ SBuf::rawSpace(size_type minSpace)
     // it's available, we're effectively claiming ownership
     // of it. If it's not, we need to go away (realloc)
     if (store_->canAppend(off_+len_, minSpace)) {
-        debugs(24, 7, "not growing");
+        debugs(24, 7, id << " not growing");
         return bufEnd();
     }
     // TODO: we may try to memmove before realloc'ing in order to avoid
@@ -508,7 +508,7 @@ SBuf::consume(size_type n)
         n = length();
     else
         n = min(n, length());
-    debugs(24, 8, "consume " << n);
+    debugs(24, 8, id << " consume " << n);
     SBuf rv(substr(0, n));
     chop(n);
     return rv;
@@ -539,6 +539,8 @@ SBuf::rawContent() const
 void
 SBuf::forceSize(size_type newSize)
 {
+    debugs(24, 8, id << " force " << (newSize > length() ? "grow" : "shrink") << " to length=" << newSize);
+
     Must(store_->LockCount() == 1);
     if (newSize > min(maxSize,store_->capacity-off_))
         throw SBufTooBigException(__FILE__,__LINE__);
@@ -563,12 +565,18 @@ SBuf::c_str()
 SBuf&
 SBuf::chop(size_type pos, size_type n)
 {
-    if (pos == npos || pos > length() || n == 0) {
+    if (pos == npos || pos > length())
+        pos = length();
+
+    if (n == npos || (pos+n) > length())
+        n = length() - pos;
+
+    // if there will be nothing left, reset the buffer while we can
+    if (pos == length() || n == 0) {
         clear();
         return *this;
     }
-    if (n == npos || (pos+n) > length())
-        n = length()-pos;
+
     ++stats.chop;
     off_ += pos;
     len_ = n;
@@ -902,7 +910,7 @@ SBuf::toString() const
 void
 SBuf::reAlloc(size_type newsize)
 {
-    debugs(24, 8, "new size: " << newsize);
+    debugs(24, 8, id << " new size: " << newsize);
     if (newsize > maxSize)
         throw SBufTooBigException(__FILE__, __LINE__);
     MemBlob::Pointer newbuf = new MemBlob(newsize);
@@ -911,7 +919,7 @@ SBuf::reAlloc(size_type newsize)
     store_ = newbuf;
     off_ = 0;
     ++stats.cowSlow;
-    debugs(24, 7, "new store capacity: " << store_->capacity);
+    debugs(24, 7, id << " new store capacity: " << store_->capacity);
 }
 
 SBuf&
@@ -932,12 +940,12 @@ SBuf::lowAppend(const char * memArea, size_type areaSize)
 void
 SBuf::cow(SBuf::size_type newsize)
 {
-    debugs(24, 8, "new size:" << newsize);
+    debugs(24, 8, id << " new size:" << newsize);
     if (newsize == npos || newsize < length())
         newsize = length();
 
     if (store_->LockCount() == 1 && newsize == length()) {
-        debugs(24, 8, "no cow needed");
+        debugs(24, 8, id << " no cow needed");
         ++stats.cowFast;
         return;
     }
@@ -138,12 +138,14 @@ class SBuf
     /// create an empty (zero-size) SBuf
     SBuf();
     SBuf(const SBuf &S);
+#if __cplusplus >= 201103L
     SBuf(SBuf&& S) : store_(std::move(S.store_)), off_(S.off_), len_(S.len_) {
         ++stats.moves;
-        S.store_=NULL;
+        S.store_=NULL; //RefCount supports NULL, and S is about to be destructed
         S.off_=0;
-        S.len_=0; //RefCount supports NULL
+        S.len_=0;
     }
+#endif
 
     /** Constructor: import c-style string
      *
@@ -180,6 +182,7 @@ class SBuf
      * Current SBuf will share backing store with the assigned one.
      */
     SBuf& operator =(const SBuf & S) {return assign(S);}
+#if __cplusplus >= 201103L
     SBuf& operator =(SBuf &&S) {
         ++stats.moves;
         if (this != &S) {
@@ -192,6 +195,7 @@ class SBuf
         }
         return *this;
     }
+#endif
 
     /** Import a c-string into a SBuf, copying the data.
      *
@@ -82,7 +82,9 @@ SBufStatsAction::unpack(const Ipc::TypedMsgHdr& msg)
     msg.getPod(mbdata);
 }
 
-static const bool Registered = (Mgr::RegisterAction("sbuf",
-                                "String-Buffer statistics", &SBufStatsAction::Create, 0 , 1),
-                                true);
+void
+SBufStatsAction::RegisterWithCacheManager()
+{
+    Mgr::RegisterAction("sbuf", "String-Buffer statistics", &SBufStatsAction::Create, 0 , 1);
+}
 
@@ -21,6 +21,7 @@ class SBufStatsAction: public Mgr::Action
 public:
     /// Mgr::ClassActionCreationHandler for Mgr::RegisterAction()
     static Pointer Create(const Mgr::CommandPointer &cmd);
+    static void RegisterWithCacheManager(void);
 
 protected:
     explicit SBufStatsAction(const Mgr::CommandPointer &cmd);
@@ -15,16 +15,12 @@
 #include "DelayConfig.h"
 #include "helper/ChildConfig.h"
 #include "HttpHeaderTools.h"
-#include "icmp/IcmpConfig.h"
 #include "ip/Address.h"
 #include "Notes.h"
+#include "security/forward.h"
 #include "YesNoNone.h"
 
 #if USE_OPENSSL
-#if HAVE_OPENSSL_SSL_H
-#include <openssl/ssl.h>
-#endif
-
 class sslproxy_cert_sign;
 class sslproxy_cert_adapt;
 #endif
@@ -148,10 +144,6 @@ class SquidConfig
     } Wccp2;
 #endif
 
-#if USE_ICMP
-    IcmpConfig pinger;
-#endif
-
     char *as_whois_server;
 
     struct {
@@ -497,25 +489,14 @@ class SquidConfig
     time_t minimum_expiry_time; /* seconds */
     external_acl *externalAclHelperList;
 
-#if USE_OPENSSL
-
     struct {
-        char *cert;
-        char *key;
-        int version;
-        char *options;
-        long parsedOptions;
-        char *cipher;
-        char *cafile;
-        char *capath;
-        char *crlfile;
-        char *flags;
+        Security::ContextPointer sslContext;
+#if USE_OPENSSL
         acl_access *cert_error;
-        SSL_CTX *sslContext;
         sslproxy_cert_sign *cert_sign;
         sslproxy_cert_adapt *cert_adapt;
-    } ssl_client;
 #endif
+    } ssl_client;
 
     char *accept_filter;
     int umask;
@@ -39,8 +39,13 @@ StatHist::init(unsigned int newCapacity, hbase_f * val_in_, hbase_f * val_out_,
 }
 
 StatHist::StatHist(const StatHist &src) :
-    capacity_(src.capacity_), min_(src.min_), max_(src.max_),
-    scale_(src.scale_), val_in(src.val_in), val_out(src.val_out)
+    bins(NULL),
+    capacity_(src.capacity_),
+    min_(src.min_),
+    max_(src.max_),
+    scale_(src.scale_),
+    val_in(src.val_in),
+    val_out(src.val_out)
 {
     if (src.bins!=NULL) {
         bins = static_cast<bins_type *>(xcalloc(src.capacity_, sizeof(bins_type)));
@@ -60,7 +65,6 @@ StatHist::count(double v)
 unsigned int
 StatHist::findBin(double v)
 {
-
     v -= min_;      /* offset */
 
     if (v <= 0.0)       /* too small */
@@ -9,11 +9,7 @@
 #ifndef SQUID_STORE_H
 #define SQUID_STORE_H
 
-/**
- \defgroup StoreAPI  Store API
- \ingroup FileSystems
- */
-
+#include "base/Packable.h"
 #include "base/RefCount.h"
 #include "comm/forward.h"
 #include "CommRead.h"
@@ -35,7 +31,6 @@
 
 class AsyncCall;
 class HttpRequest;
-class Packer;
 class RequestFlags;
 class StoreClient;
 class StoreSearch;
@@ -46,10 +41,7 @@ extern StoreIoStats store_io_stats;
 /// maximum number of entries per cache_dir
 enum { SwapFilenMax = 0xFFFFFF }; // keep in sync with StoreEntry::swap_filen
 
-/**
- \ingroup StoreAPI
- */
-class StoreEntry : public hash_link
+class StoreEntry : public hash_link, public Packable
 {
 
 public:
@@ -190,8 +182,6 @@ class StoreEntry : public hash_link
 
     ESIElement::Pointer cachedESITree;
 #endif
-    /** append bytes to the buffer */
-    virtual void append(char const *, int len);
     /** disable sending content to the clients */
     virtual void buffer();
     /** flush any buffered content */
@@ -222,6 +212,10 @@ class StoreEntry : public hash_link
     void kickProducer();
 #endif
 
+    /* Packable API */
+    virtual void append(char const *, int);
+    virtual void vappendf(const char *, va_list);
+
 protected:
     void transientsAbandonmentCheck();
 
@@ -502,12 +496,6 @@ void storeReplAdd(const char *, REMOVALPOLICYCREATE *);
 /// \ingroup StoreAPI
 extern FREE destroyStoreEntry;
 
-/**
- \ingroup StoreAPI
- \todo should be a subclass of Packer perhaps ?
- */
-void packerToStoreInit(Packer * p, StoreEntry * e);
-
 /// \ingroup StoreAPI
 void storeGetMemSpace(int size);
 
@@ -81,7 +81,7 @@ class store_client
     void scheduleMemRead();
     void scheduleRead();
     bool startSwapin();
-    void unpackHeader(char const *buf, ssize_t len);
+    bool unpackHeader(char const *buf, ssize_t len);
 
     int type;
     bool object_ok;
@@ -9,7 +9,6 @@
 #ifndef SQUID_STOREIOBUFFER_H
 #define SQUID_STOREIOBUFFER_H
 
-/* TODO: move this and the range() method into a .cci */
 #include "MemBuf.h"
 #include "Range.h"
 
@@ -26,21 +26,21 @@ StoreIOState::operator delete (void *)
     assert(0);
 }
 
-StoreIOState::StoreIOState() :
-    swap_dirn(-1), swap_filen(-1), e(NULL), mode(O_BINARY),
-    offset_(0), file_callback(NULL), callback(NULL), callback_data(NULL)
+StoreIOState::StoreIOState(StoreIOState::STFNCB *cbFile, StoreIOState::STIOCB *cbIo, void *data) :
+    swap_dirn(-1),
+    swap_filen(-1),
+    e(NULL),
+    mode(O_BINARY),
+    offset_(0),
+    file_callback(cbFile),
+    callback(cbIo),
+    callback_data(cbdataReference(data))
 {
     read.callback = NULL;
     read.callback_data = NULL;
     flags.closing = false;
 }
 
-off_t
-StoreIOState::offset() const
-{
-    return offset_;
-}
-
 StoreIOState::~StoreIOState()
 {
     debugs(20,3, "StoreIOState::~StoreIOState: " << this);
@@ -51,11 +51,11 @@ class StoreIOState : public RefCountable
     /* StoreIOState does not get mempooled - it's children do */
     void *operator new (size_t amount);
     void operator delete (void *address);
-    virtual ~StoreIOState();
 
-    StoreIOState();
+    StoreIOState(StoreIOState::STFNCB *cbFile, StoreIOState::STIOCB *cbIo, void *data);
+    virtual ~StoreIOState();
 
-    off_t offset() const;
+    off_t offset() const {return offset_;}
 
     virtual void read_(char *buf, size_t size, off_t offset, STRCB * callback, void *callback_data) = 0;
     /** write the given buffer and free it when it is no longer needed
@@ -10,14 +10,6 @@
 
 #include <cstring>
 
-#if HAVE_STDINT_H
-#include <stdint.h>
-#else /* HAVE_STDINT_H */
-#ifndef INT_MAX
-#define INT_MAX 1<<31 //hack but a safe bet
-#endif /* INT_MAX */
-#endif /* HAVE_STDINT_H */
-
 String::String() : size_(0), len_(0), buf_(NULL)
 {
 #if DEBUGSTRINGS
@@ -10,34 +10,82 @@
 #define SQUID_SRC_URL_H
 
 #include "anyp/UriScheme.h"
+#include "ip/Address.h"
+#include "rfc2181.h"
 #include "SBuf.h"
 
+#include <iosfwd>
+
 /**
  * The URL class represents a Uniform Resource Location
+ *
+ * Governed by RFC 3986
  */
 class URL
 {
     MEMPROXY_CLASS(URL);
 
 public:
-    URL() : scheme_() {}
-    URL(AnyP::UriScheme const &aScheme) : scheme_(aScheme) {}
+    URL() : scheme_(), hostIsNumeric_(false), port_(0) {*host_=0;}
+    URL(AnyP::UriScheme const &aScheme) : scheme_(aScheme), hostIsNumeric_(false), port_(0) {*host_=0;}
 
     void clear() {
         scheme_=AnyP::PROTO_NONE;
+        hostIsNumeric_ = false;
+        *host_ = 0;
+        hostAddr_.setEmpty();
+        port_ = 0;
+        touch();
     }
+    void touch(); ///< clear the cached URI display forms
 
     AnyP::UriScheme const & getScheme() const {return scheme_;}
 
     /// convert the URL scheme to that given
-    void setScheme(const AnyP::ProtocolType &p) {scheme_=p;}
+    void setScheme(const AnyP::ProtocolType &p) {scheme_=p; touch();}
 
-    void userInfo(const SBuf &s) {userInfo_=s;}
+    void userInfo(const SBuf &s) {userInfo_=s; touch();}
     const SBuf &userInfo() const {return userInfo_;}
 
+    void host(const char *src);
+    const char *host(void) const {return host_;}
+    int hostIsNumeric(void) const {return hostIsNumeric_;}
+    Ip::Address const & hostIP(void) const {return hostAddr_;}
+
+    void port(unsigned short p) {port_=p; touch();}
+    unsigned short port() const {return port_;}
+
+    void path(const char *p) {path_=p; touch();}
+    void path(const SBuf &p) {path_=p; touch();}
+    const SBuf &path() const;
+
+    /// the static '/' default URL-path
+    static const SBuf &SlashPath();
+
     /// the static '*' pseudo-URL
     static const SBuf &Asterisk();
 
+    /**
+     * The authority-form URI for currently stored values.
+     *
+     * As defined by RFC 7230 section 5.3.3 this form omits the
+     * userinfo@ field from RFC 3986 defined authority segment.
+     *
+     * \param requirePort when true the port will be included, otherwise
+     *                    port will be elided when it is the default for
+     *                    the current scheme.
+     */
+    SBuf &authority(bool requirePort = false) const;
+
+    /**
+     * The absolute-form URI for currently stored values.
+     *
+     * As defined by RFC 7230 section 5.3.3 this form omits the
+     * userinfo@ field from RFC 3986 defined authority segments
+     * when the protocol scheme is http: or https:.
+     */
+    SBuf &absolute() const;
+
 private:
     /**
      \par
@@ -62,24 +110,78 @@ class URL
     AnyP::UriScheme scheme_;
 
     SBuf userInfo_; // aka 'URL-login'
+
+    // XXX: uses char[] instead of SBUf to reduce performance regressions
+    //      from c_str() since most code using this is not yet using SBuf
+    char host_[SQUIDHOSTNAMELEN];   ///< string representation of the URI authority name or IP
+    bool hostIsNumeric_;            ///< whether the authority 'host' is a raw-IP
+    Ip::Address hostAddr_;          ///< binary representation of the URI authority if it is a raw-IP
+
+    unsigned short port_;   ///< URL port
+
+    // XXX: for now includes query-string.
+    SBuf path_;     ///< URL path segment
+
+    // pre-assembled URL forms
+    mutable SBuf authorityHttp_;     ///< RFC 7230 section 5.3.3 authority, maybe without default-port
+    mutable SBuf authorityWithPort_; ///< RFC 7230 section 5.3.3 authority with explicit port
+    mutable SBuf absolute_;          ///< RFC 7230 section 5.3.2 absolute-URI
 };
 
+inline std::ostream &
+operator <<(std::ostream &os, const URL &url)
+{
+    if (const char *sc = url.getScheme().c_str())
+        os << sc << ":";
+    os << "//" << url.authority() << url.path();
+    return os;
+}
+
 class HttpRequest;
 class HttpRequestMethod;
 
 AnyP::ProtocolType urlParseProtocol(const char *, const char *e = NULL);
 void urlInitialize(void);
 HttpRequest *urlParse(const HttpRequestMethod&, char *, HttpRequest *request = NULL);
-const char *urlCanonical(HttpRequest *);
 char *urlCanonicalClean(const HttpRequest *);
 const char *urlCanonicalFakeHttps(const HttpRequest * request);
 bool urlIsRelative(const char *);
 char *urlMakeAbsolute(const HttpRequest *, const char *);
 char *urlRInternal(const char *host, unsigned short port, const char *dir, const char *name);
 char *urlInternal(const char *dir, const char *name);
-int matchDomainName(const char *host, const char *domain);
+
+/**
+ * matchDomainName() compares a hostname (usually extracted from traffic)
+ * with a domainname (usually from an ACL) according to the following rules:
+ *
+ *    HOST      |   DOMAIN    |   MATCH?
+ * -------------|-------------|------
+ *    foo.com   |   foo.com   |     YES
+ *   .foo.com   |   foo.com   |     YES
+ *  x.foo.com   |   foo.com   |     NO
+ *    foo.com   |  .foo.com   |     YES
+ *   .foo.com   |  .foo.com   |     YES
+ *  x.foo.com   |  .foo.com   |     YES
+ *
+ *  We strip leading dots on hosts (but not domains!) so that
+ *  ".foo.com" is always the same as "foo.com".
+ *
+ * if honorWildcards is true then the matchDomainName() also accepts
+ * optional wildcards on hostname:
+ *
+ *    HOST      |    DOMAIN    |  MATCH?
+ * -------------|--------------|-------
+ *    *.foo.com |   x.foo.com  |   YES
+ *    *.foo.com |  .x.foo.com  |   YES
+ *    *.foo.com |    .foo.com  |   YES
+ *    *.foo.com |     foo.com  |   NO
+ *
+ * \retval 0 means the host matches the domain
+ * \retval 1 means the host is greater than the domain
+ * \retval -1 means the host is less than the domain
+ */
+int matchDomainName(const char *host, const char *domain, bool honorWildcards = false);
 int urlCheckRequest(const HttpRequest *);
-int urlDefaultPort(AnyP::ProtocolType p);
 char *urlHostname(const char *url);
 void urlExtMethodConfigure(void);
 
@@ -6,8 +6,8 @@
  * Please see the COPYING and CONTRIBUTORS files for details.
  */
 
-#ifndef _SQUID_SRC_ACL_ADDRESS_H_
-#define _SQUID_SRC_ACL_ADDRESS_H_
+#ifndef _SQUID_SRC_ACL_ADDRESS_H
+#define _SQUID_SRC_ACL_ADDRESS_H
 
 #include "acl/Acl.h"
 #include "ip/Address.h"
@@ -32,5 +32,5 @@ class Address
 
 } // namespace Acl
 
-#endif /* _SQUID_SRC_ACL_ADDRESS_H_ */
+#endif /* _SQUID_SRC_ACL_ADDRESS_H */
 
@@ -62,7 +62,7 @@ Acl::AllOf::parse()
 
         MemBuf wholeCtx;
         wholeCtx.init();
-        wholeCtx.Printf("(%s lines)", name);
+        wholeCtx.appendf("(%s lines)", name);
         wholeCtx.terminate();
 
         Acl::OrNode *newWhole = new Acl::OrNode;
@@ -79,7 +79,7 @@ Acl::AllOf::parse()
 
     MemBuf lineCtx;
     lineCtx.init();
-    lineCtx.Printf("(%s line #%d)", name, lineId);
+    lineCtx.appendf("(%s line #%d)", name, lineId);
     lineCtx.terminate();
 
     Acl::AndNode *line = new AndNode;
@@ -602,7 +602,7 @@ ACLSourceASNStrategy ACLSourceASNStrategy::Instance_;
 int
 ACLDestinationASNStrategy::match (ACLData<MatchType> * &data, ACLFilledChecklist *checklist, ACLFlags &)
 {
-    const ipcache_addrs *ia = ipcache_gethostbyname(checklist->request->GetHost(), IP_LOOKUP_IF_MISS);
+    const ipcache_addrs *ia = ipcache_gethostbyname(checklist->request->url.host(), IP_LOOKUP_IF_MISS);
 
     if (ia) {
         for (int k = 0; k < (int) ia->count; ++k) {
@@ -614,7 +614,7 @@ ACLDestinationASNStrategy::match (ACLData<MatchType> * &data, ACLFilledChecklist
 
     } else if (!checklist->request->flags.destinationIpLookedUp) {
         /* No entry in cache, lookup not attempted */
-        debugs(28, 3, "asnMatchAcl: Can't yet compare '" << AclMatchedName << "' ACL for '" << checklist->request->GetHost() << "'");
+        debugs(28, 3, "can't yet compare '" << AclMatchedName << "' ACL for " << checklist->request->url.host());
         if (checklist->goAsync(DestinationIPLookup::Instance()))
             return -1;
         // else fall through to noaddr match, hiding the lookup failure (XXX)
@@ -28,7 +28,7 @@ ACLCertificateStrategy::match (ACLData<MatchType> * &data, ACLFilledChecklist *c
 {
     const int fd = checklist->fd();
     const bool goodDescriptor = 0 <= fd && fd <= Biggest_FD;
-    SSL *ssl = goodDescriptor ? fd_table[fd].ssl : 0;
+    auto ssl = goodDescriptor ? fd_table[fd].ssl : nullptr;
     X509 *cert = SSL_get_peer_certificate(ssl);
     const bool res = data->match (cert);
     X509_free(cert);
@@ -127,8 +127,29 @@ ACLCertificateData::parse()
                     debugs(28, DBG_CRITICAL, "FATAL: An acl must use consistent attributes in all config lines (" << newAttribute << "!=" << attribute << ").");
                     self_destruct();
                 }
-            } else
+            } else {
+                if (strcasecmp(newAttribute, "DN") != 0) {
+                    int nid = OBJ_txt2nid(newAttribute);
+                    if (nid == 0) {
+                        const size_t span = strspn(newAttribute, "0123456789.");
+                        if(newAttribute[span] == '\0') { // looks like a numerical OID
+                            // create a new object based on this attribute
+
+                            // NOTE: Not a [bad] leak: If the same attribute
+                            // has been added before, the OBJ_txt2nid call
+                            // would return a valid nid value.
+                            // TODO: call OBJ_cleanup() on reconfigure?
+                            nid = OBJ_create(newAttribute, newAttribute,  newAttribute);
+                            debugs(28, 7, "New SSL certificate attribute created with name: " << newAttribute << " and nid: " << nid);
+                        }
+                    }
+                    if (nid == 0) {
+                        debugs(28, DBG_CRITICAL, "FATAL: Not valid SSL certificate attribute name or numerical OID: " << newAttribute);
+                        self_destruct();
+                    }
+                }
                 attribute = xstrdup(newAttribute);
+            }
         }
     }
 
@@ -46,28 +46,28 @@ ACLDestinationDomainStrategy::match (ACLData<MatchType> * &data, ACLFilledCheckl
 {
     assert(checklist != NULL && checklist->request != NULL);
 
-    if (data->match(checklist->request->GetHost())) {
+    if (data->match(checklist->request->url.host())) {
         return 1;
     }
 
     if (flags.isSet(ACL_F_NO_LOOKUP)) {
-        debugs(28, 3, "aclMatchAcl:  No-lookup DNS ACL '" << AclMatchedName << "' for '" << checklist->request->GetHost() << "'");
+        debugs(28, 3, "No-lookup DNS ACL '" << AclMatchedName << "' for " << checklist->request->url.host());
         return 0;
     }
 
     /* numeric IPA? no, trust the above result. */
-    if (checklist->request->GetHostIsNumeric() == 0) {
+    if (!checklist->request->url.hostIsNumeric()) {
         return 0;
     }
 
     /* do we already have the rDNS? match on it if we do. */
     if (checklist->dst_rdns) {
-        debugs(28, 3, "aclMatchAcl: '" << AclMatchedName << "' match with stored rDNS '" << checklist->dst_rdns << "' for '" << checklist->request->GetHost() << "'");
+        debugs(28, 3, "'" << AclMatchedName << "' match with stored rDNS '" << checklist->dst_rdns << "' for " << checklist->request->url.host());
         return data->match(checklist->dst_rdns);
     }
 
     /* raw IP without rDNS? look it up and wait for the result */
-    const ipcache_addrs *ia = ipcacheCheckNumeric(checklist->request->GetHost());
+    const ipcache_addrs *ia = ipcacheCheckNumeric(checklist->request->url.host());
     if (!ia) {
         /* not a valid IPA */
         checklist->dst_rdns = xstrdup("invalid");
@@ -82,7 +82,7 @@ ACLDestinationDomainStrategy::match (ACLData<MatchType> * &data, ACLFilledCheckl
         return data->match(fqdn);
     } else if (!checklist->destinationDomainChecked()) {
         /* FIXME: Using AclMatchedName here is not OO correct. Should find a way to the current acl */
-        debugs(28, 3, "aclMatchAcl: Can't yet compare '" << AclMatchedName << "' ACL for '" << checklist->request->GetHost() << "'");
+        debugs(28, 3, "Can't yet compare '" << AclMatchedName << "' ACL for " << checklist->request->url.host());
         if (checklist->goAsync(DestinationDomainLookup::Instance()))
             return -1;
         // else fall through to "none" match, hiding the lookup failure (XXX)
@@ -43,17 +43,17 @@ ACLDestinationIP::match(ACLChecklist *cl)
     }
 
     if (flags.isSet(ACL_F_NO_LOOKUP)) {
-        if (!checklist->request->GetHostIsNumeric()) {
-            debugs(28, 3, "aclMatchAcl:  No-lookup DNS ACL '" << AclMatchedName << "' for '" << checklist->request->GetHost() << "'");
+        if (!checklist->request->url.hostIsNumeric()) {
+            debugs(28, 3, "No-lookup DNS ACL '" << AclMatchedName << "' for " << checklist->request->url.host());
             return 0;
         }
 
-        if (ACLIP::match(checklist->request->host_addr))
+        if (ACLIP::match(checklist->request->url.hostIP()))
             return 1;
         return 0;
     }
 
-    const ipcache_addrs *ia = ipcache_gethostbyname(checklist->request->GetHost(), IP_LOOKUP_IF_MISS);
+    const ipcache_addrs *ia = ipcache_gethostbyname(checklist->request->url.host(), IP_LOOKUP_IF_MISS);
 
     if (ia) {
         /* Entry in cache found */
@@ -66,7 +66,7 @@ ACLDestinationIP::match(ACLChecklist *cl)
         return 0;
     } else if (!checklist->request->flags.destinationIpLookedUp) {
         /* No entry in cache, lookup not attempted */
-        debugs(28, 3, "aclMatchAcl: Can't yet compare '" << name << "' ACL for '" << checklist->request->GetHost() << "'");
+        debugs(28, 3, "can't yet compare '" << name << "' ACL for " << checklist->request->url.host());
         if (checklist->goAsync(DestinationIPLookup::Instance()))
             return -1;
         // else fall through to mismatch, hiding the lookup failure (XXX)
@@ -87,7 +87,7 @@ void
 DestinationIPLookup::checkForAsync(ACLChecklist *cl)const
 {
     ACLFilledChecklist *checklist = Filled(cl);
-    ipcache_nbgethostbyname(checklist->request->GetHost(), LookupDone, checklist);
+    ipcache_nbgethostbyname(checklist->request->url.host(), LookupDone, checklist);
 }
 
 void
@@ -19,7 +19,7 @@ class ACLDomainData : public ACLData<char const *>
 
 public:
     virtual ~ACLDomainData();
-    bool match(char const *);
+    virtual bool match(char const *);
     virtual SBufList dump() const;
     void parse();
     bool empty() const;
@@ -23,7 +23,6 @@
 CBDATA_CLASS_INIT(ACLFilledChecklist);
 
 ACLFilledChecklist::ACLFilledChecklist() :
-    dst_peer(NULL),
     dst_rdns(NULL),
     request (NULL),
     reply (NULL),
@@ -136,11 +135,10 @@ ACLFilledChecklist::markSourceDomainChecked()
  *    checkCallback() will delete the list (i.e., self).
  */
 ACLFilledChecklist::ACLFilledChecklist(const acl_access *A, HttpRequest *http_request, const char *ident):
-    dst_peer(NULL),
     dst_rdns(NULL),
     request(NULL),
     reply(NULL),
-#if USE_AUTh
+#if USE_AUTH
     auth_user_request(NULL),
 #endif
 #if SQUID_SNMP
@@ -149,6 +147,7 @@ ACLFilledChecklist::ACLFilledChecklist(const acl_access *A, HttpRequest *http_re
 #if USE_OPENSSL
     sslErrors(NULL),
 #endif
+    requestErrorType(ERR_MAX),
     conn_(NULL),
     fd_(-1),
     destinationDomainChecked_(false),
@@ -67,7 +67,7 @@ class ACLFilledChecklist: public ACLChecklist
     Ip::Address src_addr;
     Ip::Address dst_addr;
     Ip::Address my_addr;
-    CachePeer *dst_peer;
+    SBuf dst_peer_name;
     char *dst_rdns;
 
     HttpRequest *request;
@@ -172,7 +172,7 @@ aclParseAccessLine(const char *directive, ConfigParser &, acl_access **treep)
     const int ruleId = ((treep && *treep) ? (*treep)->childrenCount() : 0) + 1;
     MemBuf ctxBuf;
     ctxBuf.init();
-    ctxBuf.Printf("%s#%d", directive, ruleId);
+    ctxBuf.appendf("%s#%d", directive, ruleId);
     ctxBuf.terminate();
 
     Acl::AndNode *rule = new Acl::AndNode;
@@ -208,7 +208,7 @@ aclParseAclList(ConfigParser &, Acl::Tree **treep, const char *label)
 
     MemBuf ctxLine;
     ctxLine.init();
-    ctxLine.Printf("(%s %s line)", cfg_directive, label);
+    ctxLine.appendf("(%s %s line)", cfg_directive, label);
     ctxLine.terminate();
 
     Acl::AndNode *rule = new Acl::AndNode;
@@ -217,7 +217,7 @@ aclParseAclList(ConfigParser &, Acl::Tree **treep, const char *label)
 
     MemBuf ctxTree;
     ctxTree.init();
-    ctxTree.Printf("%s %s", cfg_directive, label);
+    ctxTree.appendf("%s %s", cfg_directive, label);
     ctxTree.terminate();
 
     // We want a cbdata-protected Tree (despite giving it only one child node).
@@ -523,7 +523,7 @@ ACLIP::empty() const
 }
 
 int
-ACLIP::match(Ip::Address &clientip)
+ACLIP::match(const Ip::Address &clientip)
 {
     static acl_ip_data ClientAddress;
     /*
@@ -63,7 +63,7 @@ class ACLIP : public ACL
 
 protected:
 
-    int match(Ip::Address &);
+    int match(const Ip::Address &);
     IPSplay *data;
 
 };
@@ -155,6 +155,8 @@ SSL_ACLS = \
         Certificate.h  \
 	ServerCertificate.cc \
 	ServerCertificate.h \
+	ServerName.cc \
+	ServerName.h \
         SslError.cc \
         SslError.h \
         SslErrorData.cc \
@@ -16,8 +16,8 @@
 int
 ACLPeerNameStrategy::match (ACLData<MatchType> * &data, ACLFilledChecklist *checklist, ACLFlags &)
 {
-    if (checklist->dst_peer != NULL && checklist->dst_peer->name != NULL)
-        return data->match(checklist->dst_peer->name);
+    if (!checklist->dst_peer_name.isEmpty())
+        return data->match(checklist->dst_peer_name.c_str());
     return 0;
 }
 
@@ -15,6 +15,8 @@
 #include "Parsing.h"
 #include "wordlist.h"
 
+#include <random>
+
 ACL *
 ACLRandom::clone() const
 {
@@ -82,7 +84,7 @@ ACLRandom::parse()
     } else if (sscanf(t, "%[0-9]/%[0-9]", bufa, bufb) == 2) {
         int a = xatoi(bufa);
         int b = xatoi(bufb);
-        if (a <= 0 || b <= 0) {
+        if (a <= 0 || b <= 0 || a > b) {
             debugs(28, DBG_CRITICAL, "ERROR: ACL random with bad pattern: '" << t << "'");
             return;
         } else
@@ -101,8 +103,14 @@ ACLRandom::parse()
 int
 ACLRandom::match(ACLChecklist *)
 {
-    // make up the random value
-    double random = ((double)rand() / (double)RAND_MAX);
+    // make up the random value.
+    // The fixed-value default seed is fine because we are
+    // actually matching whether the random value is above
+    // or below the configured threshold ratio.
+    static std::mt19937 mt;
+    static std::uniform_real_distribution<> dist(0, 1);
+
+    const double random = dist(mt);
 
     debugs(28, 3, "ACL Random: " << name << " " << pattern << " test: " << data << " > " << random << " = " << ((data > random)?"MATCH":"NO MATCH") );
     return (data > random)?1:0;
@@ -0,0 +1,123 @@
+/*
+ * Copyright (C) 1996-2015 The Squid Software Foundation and contributors
+ *
+ * Squid software is distributed under GPLv2+ license and includes
+ * contributions from numerous individuals and organizations.
+ * Please see the COPYING and CONTRIBUTORS files for details.
+ */
+
+/* DEBUG: section 28    Access Control */
+
+#include "squid.h"
+#include "acl/Checklist.h"
+#include "acl/DomainData.h"
+#include "acl/RegexData.h"
+#include "acl/ServerName.h"
+#include "client_side.h"
+#include "fde.h"
+#include "HttpRequest.h"
+#include "ipcache.h"
+#include "SquidString.h"
+#include "ssl/bio.h"
+#include "ssl/ServerBump.h"
+#include "ssl/support.h"
+#include "URL.h"
+
+// Compare function for tree search algorithms
+static int
+aclHostDomainCompare( char *const &a, char * const &b)
+{
+    const char *h = static_cast<const char *>(a);
+    const char *d = static_cast<const char *>(b);
+    debugs(28, 7, "Match:" << h << " <>  " << d);
+    return matchDomainName(h, d, true);
+}
+
+bool
+ACLServerNameData::match(const char *host)
+{
+    if (host == NULL)
+        return 0;
+
+    debugs(28, 3, "checking '" << host << "'");
+
+    char *h = const_cast<char *>(host);
+    char const * const * result = domains->find(h, aclHostDomainCompare);
+
+    debugs(28, 3, "'" << host << "' " << (result ? "found" : "NOT found"));
+
+    return (result != NULL);
+
+}
+
+ACLData<char const *> *
+ACLServerNameData::clone() const
+{
+    /* Splay trees don't clone yet. */
+    assert (!domains);
+    return new ACLServerNameData;
+}
+
+/// A helper function to be used with Ssl::matchX509CommonNames().
+/// \retval 0 when the name (cn or an alternate name) matches acl data
+/// \retval 1 when the name does not match
+template<class MatchType>
+int
+check_cert_domain( void *check_data, ASN1_STRING *cn_data)
+{
+    char cn[1024];
+    ACLData<MatchType> * data = (ACLData<MatchType> *)check_data;
+
+    if (cn_data->length > (int)sizeof(cn) - 1)
+        return 1; // ignore data that does not fit our buffer
+
+    char *s = reinterpret_cast<char *>(cn_data->data);
+    char *d = cn;
+    for (int i = 0; i < cn_data->length; ++i, ++d, ++s) {
+        if (*s == '\0')
+            return 1; // always a domain mismatch. contains 0x00
+        *d = *s;
+    }
+    cn[cn_data->length] = '\0';
+    debugs(28, 4, "Verifying certificate name/subjectAltName " << cn);
+    if (data->match(cn))
+        return 0;
+    return 1;
+}
+
+int
+ACLServerNameStrategy::match (ACLData<MatchType> * &data, ACLFilledChecklist *checklist, ACLFlags &flags)
+{
+    assert(checklist != NULL && checklist->request != NULL);
+
+    if (checklist->conn() && checklist->conn()->serverBump()) {
+        if (X509 *peer_cert = checklist->conn()->serverBump()->serverCert.get()) {
+            if (Ssl::matchX509CommonNames(peer_cert, (void *)data, check_cert_domain<MatchType>))
+                return 1;
+        }
+    }
+
+    const char *serverName = NULL;
+    if (checklist->conn() && !checklist->conn()->sslCommonName().isEmpty()) {
+        SBuf scn = checklist->conn()->sslCommonName();
+        serverName = scn.c_str();
+    }
+
+    if (serverName == NULL)
+        serverName = checklist->request->url.host();
+
+    if (serverName && data->match(serverName)) {
+        return 1;
+    }
+
+    return data->match("none");
+}
+
+ACLServerNameStrategy *
+ACLServerNameStrategy::Instance()
+{
+    return &Instance_;
+}
+
+ACLServerNameStrategy ACLServerNameStrategy::Instance_;
+
@@ -0,0 +1,60 @@
+/*
+ * Copyright (C) 1996-2015 The Squid Software Foundation and contributors
+ *
+ * Squid software is distributed under GPLv2+ license and includes
+ * contributions from numerous individuals and organizations.
+ * Please see the COPYING and CONTRIBUTORS files for details.
+ */
+
+#ifndef SQUID_ACLSERVERNAME_H
+#define SQUID_ACLSERVERNAME_H
+
+#include "acl/Acl.h"
+#include "acl/Checklist.h"
+#include "acl/Data.h"
+#include "acl/DomainData.h"
+#include "acl/Strategised.h"
+
+class ACLServerNameData : public ACLDomainData {
+    MEMPROXY_CLASS(ACLServerNameData);
+public:
+    ACLServerNameData() : ACLDomainData() {}
+    virtual bool match(const char *);
+    virtual ACLData<char const *> *clone() const;
+};
+
+class ACLServerNameStrategy : public ACLStrategy<char const *>
+{
+
+public:
+    virtual int match (ACLData<MatchType> * &, ACLFilledChecklist *, ACLFlags &);
+    static ACLServerNameStrategy *Instance();
+    virtual bool requiresRequest() const {return true;}
+
+    /**
+     * Not implemented to prevent copies of the instance.
+     \par
+     * Not private to prevent brain dead g+++ warnings about
+     * private constructors with no friends
+     */
+    ACLServerNameStrategy(ACLServerNameStrategy const &);
+
+private:
+    static ACLServerNameStrategy Instance_;
+    ACLServerNameStrategy() {}
+
+    ACLServerNameStrategy&operator=(ACLServerNameStrategy const &);
+};
+
+class ACLServerName
+{
+
+private:
+    static ACL::Prototype LiteralRegistryProtoype;
+    static ACLStrategised<char const *> LiteralRegistryEntry_;
+    static ACL::Prototype RegexRegistryProtoype;
+    static ACLStrategised<char const *> RegexRegistryEntry_;
+};
+
+#endif /* SQUID_ACLSERVERNAME_H */
+
@@ -12,16 +12,18 @@
 #include "acl/Checklist.h"
 #include "acl/RegexData.h"
 #include "acl/Url.h"
+#include "HttpRequest.h"
 #include "rfc1738.h"
 #include "src/URL.h"
 
 int
 ACLUrlStrategy::match (ACLData<char const *> * &data, ACLFilledChecklist *checklist, ACLFlags &)
 {
-    char *esc_buf = xstrdup(urlCanonical(checklist->request));
+    const SBuf &tmp = checklist->request->effectiveRequestUri();
+    char *esc_buf = xstrndup(tmp.rawContent(), tmp.length()+1);
     rfc1738_unescape(esc_buf);
     int result = data->match(esc_buf);
-    safe_free(esc_buf);
+    xfree(esc_buf);
     return result;
 }
 
@@ -18,13 +18,14 @@
 int
 ACLUrlPathStrategy::match (ACLData<char const *> * &data, ACLFilledChecklist *checklist, ACLFlags &)
 {
-    if (!checklist->request->urlpath.size())
+    if (checklist->request->url.path().isEmpty())
         return -1;
 
-    char *esc_buf = xstrdup(checklist->request->urlpath.termedBuf());
+    SBuf tmp = checklist->request->url.path();
+    char *esc_buf = xstrndup(tmp.rawContent(), tmp.length());
     rfc1738_unescape(esc_buf);
     int result = data->match(esc_buf);
-    safe_free(esc_buf);
+    xfree(esc_buf);
     return result;
 }
 
@@ -13,9 +13,9 @@
 #include "HttpRequest.h"
 
 int
-ACLUrlPortStrategy::match (ACLData<MatchType> * &data, ACLFilledChecklist *checklist, ACLFlags &)
+ACLUrlPortStrategy::match(ACLData<MatchType> * &data, ACLFilledChecklist *checklist, ACLFlags &)
 {
-    return data->match (checklist->request->port);
+    return data->match(checklist->request->url.port());
 }
 
 ACLUrlPortStrategy *
@@ -68,6 +68,8 @@ CaseSensitveSBufCompare(const SBuf &lhs, const SBuf &rhs)
 
 ACLUserData::ACLUserData() : userDataNames(CaseSensitveSBufCompare)
 {
+    flags.case_insensitive = false;
+    flags.required = false;
 }
 
 void
@@ -49,7 +49,7 @@ Adaptation::Service::wants(const ServiceFilter &filter) const
         // Sending a message to a service that does not want it is useless.
         // note that we cannot check wantsUrl for service that is not "up"
         // note that even essential services are skipped on unwanted URLs!
-        return wantsUrl(filter.request->urlpath);
+        return wantsUrl(filter.request->url.path());
     }
 
     // The service is down and is either not bypassable or not probed due
@@ -45,7 +45,7 @@ class Service: public RefCountable
     bool wants(const ServiceFilter &filter) const;
 
     // the methods below can only be called on an up() service
-    virtual bool wantsUrl(const String &urlPath) const = 0;
+    virtual bool wantsUrl(const SBuf &urlPath) const = 0;
 
     // called by transactions to report service failure
     virtual void noteFailure() = 0;
@@ -127,6 +127,18 @@ Adaptation::ServiceConfig::parse()
         else if (strcmp(name, "on-overload") == 0) {
             grokked = grokOnOverload(onOverload, value);
             onOverloadSet = true;
+        } else if (strncmp(name, "ssl", 3) == 0 || strncmp(name, "tls-", 4) == 0) {
+#if !USE_OPENSSL
+            debugs(3, DBG_PARSE_NOTE(DBG_IMPORTANT), "WARNING: adaptation option '" << name << "' requires --with-openssl. ICAP service option ignored.");
+#else
+            // name prefix is "ssl" or "tls-"
+            std::string tmp = name + (name[0] == 's' ? 3 : 4);
+            tmp += "=";
+            tmp += value;
+            secure.parse(tmp.c_str());
+            secure.encryptTransport = true;
+            grokked = true;
+#endif
         } else
             grokked = grokExtension(name, value);
 
@@ -214,6 +226,10 @@ Adaptation::ServiceConfig::grokUri(const char *value)
     }
 
     host.limitInit(s, len);
+#if USE_OPENSSL
+    if (secure.sslDomain.isEmpty())
+        secure.sslDomain.assign(host.rawBuf(), host.size());
+#endif
     s = e;
 
     port = -1;
@@ -11,6 +11,7 @@
 
 #include "adaptation/Elements.h"
 #include "base/RefCount.h"
+#include "security/PeerOptions.h"
 #include "SquidString.h"
 
 namespace Adaptation
@@ -47,6 +48,9 @@ class ServiceConfig: public RefCountable
     bool routing; ///< whether this service may determine the next service(s)
     bool ipv6;    ///< whether this service uses IPv6 transport (default IPv4)
 
+    // security settings for adaptation service
+    Security::PeerOptions secure;
+
 protected:
     Method parseMethod(const char *buf) const;
     VectPoint parseVectPoint(const char *buf) const;
@@ -91,23 +91,16 @@ Adaptation::Ecap::HeaderRep::image() const
 {
     MemBuf mb;
     mb.init();
-
-    Packer p;
-    packerToMemInit(&p, &mb);
-    theMessage.packInto(&p, true);
-    packerClean(&p);
+    theMessage.packInto(&mb, true);
     return Area::FromTempBuffer(mb.content(), mb.contentSize());
 }
 
 // throws on failures
 void
 Adaptation::Ecap::HeaderRep::parse(const Area &buf)
 {
-    MemBuf mb;
-    mb.init();
-    mb.append(buf.start, buf.size);
     Http::StatusCode error;
-    Must(theMessage.parse(&mb, true, &error));
+    Must(theMessage.parse(buf.start, buf.size, true, &error));
 }
 
 http_hdr_type
@@ -219,10 +212,11 @@ Adaptation::Ecap::RequestLineRep::uri(const Area &aUri)
 Adaptation::Ecap::RequestLineRep::Area
 Adaptation::Ecap::RequestLineRep::uri() const
 {
-    const char *fullUrl = urlCanonical(&theMessage);
-    Must(fullUrl);
+    const SBuf &fullUrl = theMessage.effectiveRequestUri();
+    // XXX: effectiveRequestUri() cannot return NULL or even empty string, some other problem?
+    Must(!fullUrl.isEmpty());
     // optimize: avoid copying by having an Area::Detail that locks theMessage
-    return Area::FromTempBuffer(fullUrl, strlen(fullUrl));
+    return Area::FromTempBuffer(fullUrl.rawContent(), fullUrl.length());
 }
 
 void
@@ -237,10 +237,12 @@ bool Adaptation::Ecap::ServiceRep::up() const
     return theService != NULL;
 }
 
-bool Adaptation::Ecap::ServiceRep::wantsUrl(const String &urlPath) const
+bool Adaptation::Ecap::ServiceRep::wantsUrl(const SBuf &urlPath) const
 {
     Must(up());
-    return theService->wantsUrl(urlPath.termedBuf());
+    SBuf nonConstUrlPath = urlPath;
+    // c_str() reallocates and terminates for libecap API
+    return theService->wantsUrl(nonConstUrlPath.c_str());
 }
 
 Adaptation::Initiate *
@@ -38,7 +38,7 @@ class ServiceRep : public Adaptation::Service
     virtual bool probed() const;
     virtual bool up() const;
     virtual Adaptation::Initiate *makeXactLauncher(HttpMsg *virginHeader, HttpRequest *virginCause, AccessLogEntry::Pointer &alp);
-    virtual bool wantsUrl(const String &urlPath) const;
+    virtual bool wantsUrl(const SBuf &urlPath) const;
     virtual void noteFailure();
     virtual const char *status() const;
     virtual void detach();
@@ -699,7 +699,7 @@ Adaptation::Ecap::XactionRep::status() const
     buf.append(" [", 2);
 
     if (makingVb)
-        buf.Printf("M%d", static_cast<int>(makingVb));
+        buf.appendf("M%d", static_cast<int>(makingVb));
 
     const BodyPipePointer &vp = theVirginRep.raw().body_pipe;
     if (!vp)
@@ -712,7 +712,7 @@ Adaptation::Ecap::XactionRep::status() const
     if (vbProductionFinished)
         buf.append(".", 1);
 
-    buf.Printf(" A%d", static_cast<int>(proxyingAb));
+    buf.appendf(" A%d", static_cast<int>(proxyingAb));
 
     if (proxyingAb == opOn) {
         MessageRep *rep = dynamic_cast<MessageRep*>(theAnswerRep.get());
@@ -726,7 +726,7 @@ Adaptation::Ecap::XactionRep::status() const
             buf.append(" A?", 3);
     }
 
-    buf.Printf(" %s%u]", id.Prefix, id.value);
+    buf.appendf(" %s%u]", id.Prefix, id.value);
 
     buf.terminate();
 
@@ -22,10 +22,10 @@
 #include "auth/UserRequest.h"
 #include "base/TextException.h"
 #include "base64.h"
-#include "ChunkedCodingParser.h"
 #include "comm.h"
 #include "comm/Connection.h"
 #include "err_detail_type.h"
+#include "http/one/TeChunkedParser.h"
 #include "HttpHeaderTools.h"
 #include "HttpMsg.h"
 #include "HttpReply.h"
@@ -375,7 +375,7 @@ void Adaptation::Icap::ModXact::addLastRequestChunk(MemBuf &buf)
 
 void Adaptation::Icap::ModXact::openChunk(MemBuf &buf, size_t chunkSize, bool ieof)
 {
-    buf.Printf((ieof ? "%x; ieof\r\n" : "%x\r\n"), (int) chunkSize);
+    buf.appendf((ieof ? "%x; ieof\r\n" : "%x\r\n"), (int) chunkSize);
 }
 
 void Adaptation::Icap::ModXact::closeChunk(MemBuf &buf)
@@ -557,10 +557,10 @@ void Adaptation::Icap::ModXact::readMore()
         return;
     }
 
-    if (readBuf.hasSpace())
+    if (readBuf.length() < SQUID_TCP_SO_RCVBUF)
         scheduleRead();
     else
-        debugs(93,3,HERE << "nothing to do because !readBuf.hasSpace()");
+        debugs(93,3,HERE << "cannot read with a full buffer");
 }
 
 // comm module read a portion of the ICAP response for us
@@ -649,9 +649,8 @@ void Adaptation::Icap::ModXact::checkConsuming()
 
 void Adaptation::Icap::ModXact::parseMore()
 {
-    debugs(93, 5, HERE << "have " << readBuf.contentSize() << " bytes to parse" <<
-           status());
-    debugs(93, 5, HERE << "\n" << readBuf.content());
+    debugs(93, 5, "have " << readBuf.length() << " bytes to parse" << status());
+    debugs(93, 5, "\n" << readBuf);
 
     if (state.parsingHeaders())
         parseHeaders();
@@ -967,11 +966,8 @@ void Adaptation::Icap::ModXact::prepEchoing()
     // parse the buffer back
     Http::StatusCode error = Http::scNone;
 
-    Must(adapted.header->parse(&httpBuf, true, &error));
-
-    if (HttpRequest *r = dynamic_cast<HttpRequest*>(adapted.header))
-        urlCanonical(r); // parse does not set HttpRequest::canonical
-
+    httpBuf.terminate(); // HttpMsg::parse requires nil-terminated buffer
+    Must(adapted.header->parse(httpBuf.content(), httpBuf.contentSize(), true, &error));
     Must(adapted.header->hdr_sz == httpBuf.contentSize()); // no leftovers
 
     httpBuf.clean();
@@ -1075,11 +1071,13 @@ void Adaptation::Icap::ModXact::parseHttpHead()
 bool Adaptation::Icap::ModXact::parseHead(HttpMsg *head)
 {
     Must(head);
-    debugs(93, 5, HERE << "have " << readBuf.contentSize() << " head bytes to parse" <<
-           "; state: " << state.parsing);
+    debugs(93, 5, "have " << readBuf.length() << " head bytes to parse; state: " << state.parsing);
 
     Http::StatusCode error = Http::scNone;
-    const bool parsed = head->parse(&readBuf, commEof, &error);
+    // XXX: performance regression. c_str() data copies
+    // XXX: HttpMsg::parse requires a terminated string buffer
+    const char *tmpBuf = readBuf.c_str();
+    const bool parsed = head->parse(tmpBuf, readBuf.length(), commEof, &error);
     Must(parsed || !error); // success or need more data
 
     if (!parsed) { // need more data
@@ -1088,9 +1086,6 @@ bool Adaptation::Icap::ModXact::parseHead(HttpMsg *head)
         return false;
     }
 
-    if (HttpRequest *r = dynamic_cast<HttpRequest*>(head))
-        urlCanonical(r); // parse does not set HttpRequest::canonical
-
     debugs(93, 5, HERE << "parse success, consume " << head->hdr_sz << " bytes, return true");
     readBuf.consume(head->hdr_sz);
     return true;
@@ -1102,7 +1097,7 @@ void Adaptation::Icap::ModXact::decideOnParsingBody()
         debugs(93, 5, HERE << "expecting a body");
         state.parsing = State::psBody;
         replyHttpBodySize = 0;
-        bodyParser = new ChunkedCodingParser;
+        bodyParser = new Http1::TeChunkedParser;
         makeAdaptedBodyPipe("adapted response from the ICAP server");
         Must(state.sending == State::sendingAdapted);
     } else {
@@ -1117,15 +1112,16 @@ void Adaptation::Icap::ModXact::parseBody()
     Must(state.parsing == State::psBody);
     Must(bodyParser);
 
-    debugs(93, 5, HERE << "have " << readBuf.contentSize() << " body bytes to parse");
+    debugs(93, 5, "have " << readBuf.length() << " body bytes to parse");
 
     // the parser will throw on errors
     BodyPipeCheckout bpc(*adapted.body_pipe);
-    const bool parsed = bodyParser->parse(&readBuf, &bpc.buf);
+    bodyParser->setPayloadBuffer(&bpc.buf);
+    const bool parsed = bodyParser->parse(readBuf);
+    readBuf = bodyParser->remaining(); // sync buffers after parse
     bpc.checkIn();
 
-    debugs(93, 5, HERE << "have " << readBuf.contentSize() << " body bytes after " <<
-           "parse; parsed all: " << parsed);
+    debugs(93, 5, "have " << readBuf.length() << " body bytes after parsed all: " << parsed);
     replyHttpBodySize += adapted.body_pipe->buf().contentSize();
 
     // TODO: expose BodyPipe::putSize() to make this check simpler and clearer
@@ -1317,16 +1313,10 @@ void Adaptation::Icap::ModXact::finalizeLogInfo()
         }
         //don't set al.cache.objectSize because it hasn't exist yet
 
-        Packer p;
         MemBuf mb;
-
         mb.init();
-        packerToMemInit(&p, &mb);
-
-        reply_->header.packInto(&p);
+        reply_->header.packInto(&mb);
         al.headers.reply = xstrdup(mb.buf);
-
-        packerClean(&p);
         mb.clean();
     }
     prepareLogWithRequestDetails(adapted_request_, alep);
@@ -1340,25 +1330,25 @@ void Adaptation::Icap::ModXact::makeRequestHeaders(MemBuf &buf)
      * XXX These should use HttpHdr interfaces instead of Printfs
      */
     const Adaptation::ServiceConfig &s = service().cfg();
-    buf.Printf("%s " SQUIDSTRINGPH " ICAP/1.0\r\n", s.methodStr(), SQUIDSTRINGPRINT(s.uri));
-    buf.Printf("Host: " SQUIDSTRINGPH ":%d\r\n", SQUIDSTRINGPRINT(s.host), s.port);
-    buf.Printf("Date: %s\r\n", mkrfc1123(squid_curtime));
+    buf.appendf("%s " SQUIDSTRINGPH " ICAP/1.0\r\n", s.methodStr(), SQUIDSTRINGPRINT(s.uri));
+    buf.appendf("Host: " SQUIDSTRINGPH ":%d\r\n", SQUIDSTRINGPRINT(s.host), s.port);
+    buf.appendf("Date: %s\r\n", mkrfc1123(squid_curtime));
 
     if (!TheConfig.reuse_connections)
-        buf.Printf("Connection: close\r\n");
+        buf.appendf("Connection: close\r\n");
 
     const HttpRequest *request = &virginRequest();
 
     // we must forward "Proxy-Authenticate" and "Proxy-Authorization"
     // as ICAP headers.
     if (virgin.header->header.has(HDR_PROXY_AUTHENTICATE)) {
         String vh=virgin.header->header.getByName("Proxy-Authenticate");
-        buf.Printf("Proxy-Authenticate: " SQUIDSTRINGPH "\r\n",SQUIDSTRINGPRINT(vh));
+        buf.appendf("Proxy-Authenticate: " SQUIDSTRINGPH "\r\n",SQUIDSTRINGPRINT(vh));
     }
 
     if (virgin.header->header.has(HDR_PROXY_AUTHORIZATION)) {
         String vh=virgin.header->header.getByName("Proxy-Authorization");
-        buf.Printf("Proxy-Authorization: " SQUIDSTRINGPH "\r\n", SQUIDSTRINGPRINT(vh));
+        buf.appendf("Proxy-Authorization: " SQUIDSTRINGPH "\r\n", SQUIDSTRINGPRINT(vh));
     } else if (request->extacl_user.size() > 0 && request->extacl_passwd.size() > 0) {
         struct base64_encode_ctx ctx;
         base64_encode_init(&ctx);
@@ -1367,7 +1357,7 @@ void Adaptation::Icap::ModXact::makeRequestHeaders(MemBuf &buf)
         resultLen += base64_encode_update(&ctx, base64buf+resultLen, 1, reinterpret_cast<const uint8_t*>(":"));
         resultLen += base64_encode_update(&ctx, base64buf+resultLen, request->extacl_passwd.size(), reinterpret_cast<const uint8_t*>(request->extacl_passwd.rawBuf()));
         resultLen += base64_encode_final(&ctx, base64buf+resultLen);
-        buf.Printf("Proxy-Authorization: Basic %.*s\r\n", (int)resultLen, base64buf);
+        buf.appendf("Proxy-Authorization: Basic %.*s\r\n", (int)resultLen, base64buf);
     }
 
     // share the cross-transactional database records if needed
@@ -1376,13 +1366,12 @@ void Adaptation::Icap::ModXact::makeRequestHeaders(MemBuf &buf)
         if (ah != NULL) {
             String name, value;
             if (ah->getXxRecord(name, value)) {
-                buf.Printf(SQUIDSTRINGPH ": " SQUIDSTRINGPH "\r\n",
-                           SQUIDSTRINGPRINT(name), SQUIDSTRINGPRINT(value));
+                buf.appendf(SQUIDSTRINGPH ": " SQUIDSTRINGPH "\r\n", SQUIDSTRINGPRINT(name), SQUIDSTRINGPRINT(value));
             }
         }
     }
 
-    buf.Printf("Encapsulated: ");
+    buf.append("Encapsulated: ", 14);
 
     MemBuf httpBuf;
 
@@ -1393,9 +1382,7 @@ void Adaptation::Icap::ModXact::makeRequestHeaders(MemBuf &buf)
 
     // to simplify, we could assume that request is always available
 
-    String urlPath;
     if (request) {
-        urlPath = request->urlpath;
         if (ICAP::methodRespmod == m)
             encapsulateHead(buf, "req-hdr", httpBuf, request);
         else if (ICAP::methodReqmod == m)
@@ -1407,16 +1394,16 @@ void Adaptation::Icap::ModXact::makeRequestHeaders(MemBuf &buf)
             encapsulateHead(buf, "res-hdr", httpBuf, prime);
 
     if (!virginBody.expected())
-        buf.Printf("null-body=%d", (int) httpBuf.contentSize());
+        buf.appendf("null-body=%d", (int) httpBuf.contentSize());
     else if (ICAP::methodReqmod == m)
-        buf.Printf("req-body=%d", (int) httpBuf.contentSize());
+        buf.appendf("req-body=%d", (int) httpBuf.contentSize());
     else
-        buf.Printf("res-body=%d", (int) httpBuf.contentSize());
+        buf.appendf("res-body=%d", (int) httpBuf.contentSize());
 
     buf.append(ICAP::crlf, 2); // terminate Encapsulated line
 
     if (preview.enabled()) {
-        buf.Printf("Preview: %d\r\n", (int)preview.ad());
+        buf.appendf("Preview: %d\r\n", (int)preview.ad());
         if (!virginBody.expected()) // there is no body to preview
             finishNullOrEmptyBodyPreview(httpBuf);
     }
@@ -1432,7 +1419,7 @@ void Adaptation::Icap::ModXact::makeRequestHeaders(MemBuf &buf)
 #endif
             client_addr = request->client_addr;
         if (!client_addr.isAnyAddr() && !client_addr.isNoAddr())
-            buf.Printf("X-Client-IP: %s\r\n", client_addr.toStr(ntoabuf,MAX_IPSTRLEN));
+            buf.appendf("X-Client-IP: %s\r\n", client_addr.toStr(ntoabuf,MAX_IPSTRLEN));
     }
 
     if (TheConfig.send_username && request)
@@ -1448,7 +1435,7 @@ void Adaptation::Icap::ModXact::makeRequestHeaders(MemBuf &buf)
         HttpReply *reply = dynamic_cast<HttpReply*>(virgin.header);
 
         if (const char *value = (*i)->match(r, reply, alMaster)) {
-            buf.Printf("%s: %s\r\n", (*i)->key.termedBuf(), value);
+            buf.appendf("%s: %s\r\n", (*i)->key.termedBuf(), value);
             Adaptation::History::Pointer ah = request->adaptHistory(false);
             if (ah != NULL) {
                 if (ah->metaHeaders == NULL)
@@ -1528,25 +1515,26 @@ void Adaptation::Icap::ModXact::makeUsernameHeader(const HttpRequest *request, M
             uint8_t base64buf[base64_encode_len(MAX_LOGIN_SZ)];
             size_t resultLen = base64_encode_update(&ctx, base64buf, strlen(value), reinterpret_cast<const uint8_t*>(value));
             resultLen += base64_encode_final(&ctx, base64buf+resultLen);
-            buf.Printf("%s: %.*s\r\n", TheConfig.client_username_header, (int)resultLen, base64buf);
+            buf.appendf("%s: %.*s\r\n", TheConfig.client_username_header, (int)resultLen, base64buf);
         } else
-            buf.Printf("%s: %s\r\n", TheConfig.client_username_header, value);
+            buf.appendf("%s: %s\r\n", TheConfig.client_username_header, value);
     }
 #endif
 }
 
 void Adaptation::Icap::ModXact::encapsulateHead(MemBuf &icapBuf, const char *section, MemBuf &httpBuf, const HttpMsg *head)
 {
     // update ICAP header
-    icapBuf.Printf("%s=%d, ", section, (int) httpBuf.contentSize());
+    icapBuf.appendf("%s=%d, ", section, (int) httpBuf.contentSize());
 
     // begin cloning
     HttpMsg::Pointer headClone;
 
     if (const HttpRequest* old_request = dynamic_cast<const HttpRequest*>(head)) {
         HttpRequest::Pointer new_request(new HttpRequest);
-        Must(old_request->canonical);
-        urlParse(old_request->method, old_request->canonical, new_request.getRaw());
+        // copy the requst-line details
+        new_request->method = old_request->method;
+        new_request->url = old_request->url;
         new_request->http_ver = old_request->http_ver;
         headClone = new_request.getRaw();
     } else if (const HttpReply *old_reply = dynamic_cast<const HttpReply*>(head)) {
@@ -1576,10 +1564,7 @@ void Adaptation::Icap::ModXact::encapsulateHead(MemBuf &icapBuf, const char *sec
 
 void Adaptation::Icap::ModXact::packHead(MemBuf &httpBuf, const HttpMsg *head)
 {
-    Packer p;
-    packerToMemInit(&p, &httpBuf);
-    head->packInto(&p, true);
-    packerClean(&p);
+    head->packInto(&httpBuf, true);
 }
 
 // decides whether to offer a preview and calculates its size
@@ -1590,10 +1575,10 @@ void Adaptation::Icap::ModXact::decideOnPreview()
         return;
     }
 
-    const String urlPath = virginRequest().urlpath;
+    const SBuf urlPath(virginRequest().url.path());
     size_t wantedSize;
     if (!service().wantsPreview(urlPath, wantedSize)) {
-        debugs(93, 5, HERE << "should not offer preview for " << urlPath);
+        debugs(93, 5, "should not offer preview for " << urlPath);
         return;
     }
 
@@ -1708,21 +1693,21 @@ void Adaptation::Icap::ModXact::fillPendingStatus(MemBuf &buf) const
         buf.append("r", 1);
 
     if (!state.doneWriting() && state.writing != State::writingInit)
-        buf.Printf("w(%d)", state.writing);
+        buf.appendf("w(%d)", state.writing);
 
     if (preview.enabled()) {
         if (!preview.done())
-            buf.Printf("P(%d)", (int) preview.debt());
+            buf.appendf("P(%d)", (int) preview.debt());
     }
 
     if (virginBodySending.active())
         buf.append("B", 1);
 
     if (!state.doneParsing() && state.parsing != State::psIcapHeader)
-        buf.Printf("p(%d)", state.parsing);
+        buf.appendf("p(%d)", state.parsing);
 
     if (!doneSending() && state.sending != State::sendingUndecided)
-        buf.Printf("S(%d)", state.sending);
+        buf.appendf("S(%d)", state.sending);
 
     if (state.readyForUob)
         buf.append("6", 1);
@@ -1746,7 +1731,7 @@ void Adaptation::Icap::ModXact::fillDoneStatus(MemBuf &buf) const
 
     if (preview.enabled()) {
         if (preview.done())
-            buf.Printf("P%s", preview.ieof() ? "(ieof)" : "");
+            buf.appendf("P%s", preview.ieof() ? "(ieof)" : "");
     }
 
     if (doneReading())
@@ -14,6 +14,7 @@
 #include "adaptation/icap/Launcher.h"
 #include "adaptation/icap/Xaction.h"
 #include "BodyPipe.h"
+#include "http/one/forward.h"
 
 /*
  * ICAPModXact implements ICAP REQMOD and RESPMOD transaction using
@@ -25,8 +26,6 @@
  * receive the HTTP body.
  */
 
-class ChunkedCodingParser;
-
 namespace Adaptation
 {
 namespace Icap
@@ -250,7 +249,7 @@ class ModXact: public Xaction, public BodyProducer, public BodyConsumer
     uint64_t virginConsumed;        // virgin data consumed so far
     Preview preview; // use for creating (writing) the preview
 
-    ChunkedCodingParser *bodyParser; // ICAP response body parser
+    Http1::TeChunkedParser *bodyParser; // ICAP response body parser
 
     bool canStartBypass; // enables bypass of transaction failures
     bool protectGroupBypass; // protects ServiceGroup-wide bypass of failures
@@ -54,20 +54,21 @@ void Adaptation::Icap::OptXact::makeRequest(MemBuf &buf)
 {
     const Adaptation::Service &s = service();
     const String uri = s.cfg().uri;
-    buf.Printf("OPTIONS " SQUIDSTRINGPH " ICAP/1.0\r\n", SQUIDSTRINGPRINT(uri));
+    buf.appendf("OPTIONS " SQUIDSTRINGPH " ICAP/1.0\r\n", SQUIDSTRINGPRINT(uri));
     const String host = s.cfg().host;
-    buf.Printf("Host: " SQUIDSTRINGPH ":%d\r\n", SQUIDSTRINGPRINT(host), s.cfg().port);
+    buf.appendf("Host: " SQUIDSTRINGPH ":%d\r\n", SQUIDSTRINGPRINT(host), s.cfg().port);
 
     if (!TheConfig.reuse_connections)
-        buf.Printf("Connection: close\r\n");
+        buf.append("Connection: close\r\n", 19);
 
     if (TheConfig.allow206_enable)
-        buf.Printf("Allow: 206\r\n");
+        buf.append("Allow: 206\r\n", 12);
     buf.append(ICAP::crlf, 2);
 
     // XXX: HttpRequest cannot fully parse ICAP Request-Line
     Http::StatusCode reqStatus;
-    Must(icapRequest->parse(&buf, true, &reqStatus) > 0);
+    buf.terminate(); // HttpMsg::parse requires terminated buffer
+    Must(icapRequest->parse(buf.content(), buf.contentSize(), true, &reqStatus) > 0);
 }
 
 void Adaptation::Icap::OptXact::handleCommWrote(size_t size)
@@ -99,9 +100,8 @@ void Adaptation::Icap::OptXact::handleCommRead(size_t)
 
 bool Adaptation::Icap::OptXact::parseResponse()
 {
-    debugs(93, 5, HERE << "have " << readBuf.contentSize() << " bytes to parse" <<
-           status());
-    debugs(93, 5, HERE << "\n" << readBuf.content());
+    debugs(93, 5, "have " << readBuf.length() << " bytes to parse" << status());
+    debugs(93, DBG_DATA, "\n" << readBuf);
 
     HttpReply::Pointer r(new HttpReply);
     r->protoPrefix = "ICAP/"; // TODO: make an IcapReply class?
@@ -43,7 +43,8 @@ Adaptation::Icap::Options::~Options()
 // future optimization note: this method is called by ICAP ACL code at least
 // twice for each HTTP message to see if the message should be ignored. For any
 // non-ignored HTTP message, ICAP calls to check whether a preview is needed.
-Adaptation::Icap::Options::TransferKind Adaptation::Icap::Options::transferKind(const String &urlPath) const
+Adaptation::Icap::Options::TransferKind
+Adaptation::Icap::Options::transferKind(const SBuf &urlPath) const
 {
     if (theTransfers.preview.matches(urlPath))
         return xferPreview;
@@ -54,7 +55,7 @@ Adaptation::Icap::Options::TransferKind Adaptation::Icap::Options::transferKind(
     if (theTransfers.ignore.matches(urlPath))
         return xferIgnore;
 
-    debugs(93,7, HERE << "url " << urlPath << " matches no extensions; " <<
+    debugs(93,7, "url " << urlPath << " matches no extensions; " <<
            "using default: " << theTransfers.byDefault->name);
     return theTransfers.byDefault->kind;
 }
@@ -184,26 +185,24 @@ void Adaptation::Icap::Options::TransferList::add(const char *extension)
     wordlistAdd(&extensions, extension);
 };
 
-bool Adaptation::Icap::Options::TransferList::matches(const String &urlPath) const
+bool Adaptation::Icap::Options::TransferList::matches(const SBuf &urlPath) const
 {
-    const int urlLen = urlPath.size();
+    const SBuf::size_type urlLen = urlPath.length();
     for (wordlist *e = extensions; e; e = e->next) {
         // optimize: store extension lengths
-        const int eLen = strlen(e->key);
+        const size_t eLen = strlen(e->key);
 
         // assume URL contains at least '/' before the extension
         if (eLen < urlLen) {
-            const int eOff = urlLen - eLen;
+            const size_t eOff = urlLen - eLen;
             // RFC 3507 examples imply that extensions come without leading '.'
-            if (urlPath[eOff-1] == '.' &&
-                    strcmp(urlPath.termedBuf() + eOff, e->key) == 0) {
-                debugs(93,7, HERE << "url " << urlPath << " matches " <<
-                       name << " extension " << e->key);
+            if (urlPath[eOff-1] == '.' && urlPath.substr(eOff).cmp(e->key, eLen) == 0) {
+                debugs(93,7, "url " << urlPath << " matches " << name << " extension " << e->key);
                 return true;
             }
         }
     }
-    debugs(93,8, HERE << "url " << urlPath << " matches no " << name << " extensions");
+    debugs(93,8, "url " << urlPath << " matches no " << name << " extensions");
     return false;
 }
 
@@ -42,7 +42,7 @@ class Options
     time_t timestamp() const { return theTimestamp; };
 
     typedef enum { xferNone, xferPreview, xferIgnore, xferComplete } TransferKind;
-    TransferKind transferKind(const String &urlPath) const;
+    TransferKind transferKind(const SBuf &urlPath) const;
 
 public:
     const char *error; // human-readable information; set iff !valid()
@@ -68,7 +68,7 @@ class Options
         TransferList();
         ~TransferList();
 
-        bool matches(const String &urlPath) const;
+        bool matches(const SBuf &urlPath) const;
 
         void parse(const String &buf, bool &foundStar);
         void add(const char *extension);
@@ -26,10 +26,17 @@
 #include "SquidConfig.h"
 #include "SquidTime.h"
 
+#define DEFAULT_ICAP_PORT   1344
+#define DEFAULT_ICAPS_PORT 11344
+
 CBDATA_NAMESPACED_CLASS_INIT(Adaptation::Icap, ServiceRep);
 
 Adaptation::Icap::ServiceRep::ServiceRep(const ServiceConfigPointer &svcCfg):
     AsyncJob("Adaptation::Icap::ServiceRep"), Adaptation::Service(svcCfg),
+    sslContext(NULL),
+#if USE_OPENSSL
+    sslSession(NULL),
+#endif
     theOptions(NULL), theOptionsFetcher(0), theLastUpdate(0),
     theBusyConns(0),
     theAllWaiters(0),
@@ -59,15 +66,27 @@ Adaptation::Icap::ServiceRep::finalize()
     // use /etc/services or default port if needed
     const bool have_port = cfg().port >= 0;
     if (!have_port) {
-        struct servent *serv = getservbyname("icap", "tcp");
+        struct servent *serv;
+        if (cfg().protocol.caseCmp("icaps") == 0)
+            serv = getservbyname("icaps", "tcp");
+        else
+            serv = getservbyname("icap", "tcp");
 
         if (serv) {
             writeableCfg().port = htons(serv->s_port);
         } else {
-            writeableCfg().port = 1344;
+            writeableCfg().port = cfg().protocol.caseCmp("icaps") == 0 ? DEFAULT_ICAPS_PORT : DEFAULT_ICAP_PORT;
         }
     }
 
+    if (cfg().protocol.caseCmp("icaps") == 0)
+        writeableCfg().secure.encryptTransport = true;
+
+    if (cfg().secure.encryptTransport) {
+        debugs(3, DBG_IMPORTANT, "Initializing service " << cfg().resource << " SSL context");
+        sslContext = writeableCfg().secure.createClientContext(true);
+    }
+
     theSessionFailures.configure(TheConfig.oldest_service_failure > 0 ?
                                  TheConfig.oldest_service_failure : -1);
 }
@@ -302,13 +321,13 @@ bool Adaptation::Icap::ServiceRep::availableForOld() const
     return (available != 0); // it is -1 (no limit) or has available slots
 }
 
-bool Adaptation::Icap::ServiceRep::wantsUrl(const String &urlPath) const
+bool Adaptation::Icap::ServiceRep::wantsUrl(const SBuf &urlPath) const
 {
     Must(hasOptions());
     return theOptions->transferKind(urlPath) != Adaptation::Icap::Options::xferIgnore;
 }
 
-bool Adaptation::Icap::ServiceRep::wantsPreview(const String &urlPath, size_t &wantedSize) const
+bool Adaptation::Icap::ServiceRep::wantsPreview(const SBuf &urlPath, size_t &wantedSize) const
 {
     Must(hasOptions());
 
@@ -698,7 +717,7 @@ const char *Adaptation::Icap::ServiceRep::status() const
         buf.append(",notif", 6);
 
     if (const int failures = theSessionFailures.remembered())
-        buf.Printf(",fail%d", failures);
+        buf.appendf(",fail%d", failures);
 
     buf.append("]", 1);
     buf.terminate();
@@ -81,8 +81,8 @@ class ServiceRep : public RefCountable, public Adaptation::Service,
     void callWhenReady(AsyncCall::Pointer &cb);
 
     // the methods below can only be called on an up() service
-    bool wantsUrl(const String &urlPath) const;
-    bool wantsPreview(const String &urlPath, size_t &wantedSize) const;
+    bool wantsUrl(const SBuf &urlPath) const;
+    bool wantsPreview(const SBuf &urlPath, size_t &wantedSize) const;
     bool allows204() const;
     bool allows206() const;
     Comm::ConnectionPointer getConnection(bool isRetriable, bool &isReused);
@@ -110,6 +110,11 @@ class ServiceRep : public RefCountable, public Adaptation::Service,
     // receive either an ICAP OPTIONS response header or an abort message
     virtual void noteAdaptationAnswer(const Answer &answer);
 
+    Security::ContextPointer sslContext;
+#if USE_OPENSSL
+    SSL_SESSION *sslSession;
+#endif
+
 private:
     // stores Prepare() callback info
 
@@ -9,6 +9,7 @@
 /* DEBUG: section 93    ICAP (RFC 3507) Client */
 
 #include "squid.h"
+#include "acl/FilledChecklist.h"
 #include "adaptation/icap/Config.h"
 #include "adaptation/icap/Launcher.h"
 #include "adaptation/icap/Xaction.h"
@@ -22,6 +23,7 @@
 #include "err_detail_type.h"
 #include "fde.h"
 #include "FwdState.h"
+#include "globals.h"
 #include "HttpMsg.h"
 #include "HttpReply.h"
 #include "HttpRequest.h"
@@ -31,6 +33,45 @@
 #include "SquidConfig.h"
 #include "SquidTime.h"
 
+#if USE_OPENSSL
+/// Gives Ssl::PeerConnector access to Answer in the PeerPoolMgr callback dialer.
+class MyIcapAnswerDialer: public UnaryMemFunT<Adaptation::Icap::Xaction, Security::EncryptorAnswer, Security::EncryptorAnswer&>,
+    public Ssl::PeerConnector::CbDialer
+{
+public:
+    MyIcapAnswerDialer(const JobPointer &aJob, Method aMethod):
+        UnaryMemFunT<Adaptation::Icap::Xaction, Security::EncryptorAnswer, Security::EncryptorAnswer&>(aJob, aMethod, Security::EncryptorAnswer()) {}
+
+    /* Ssl::PeerConnector::CbDialer API */
+    virtual Security::EncryptorAnswer &answer() { return arg1; }
+};
+
+namespace Ssl
+{
+/// A simple PeerConnector for Secure ICAP services. No SslBump capabilities.
+class IcapPeerConnector: public PeerConnector {
+    CBDATA_CLASS(IcapPeerConnector);
+public:
+    IcapPeerConnector(
+        Adaptation::Icap::ServiceRep::Pointer &service,
+        const Comm::ConnectionPointer &aServerConn,
+        AsyncCall::Pointer &aCallback, const time_t timeout = 0):
+        AsyncJob("Ssl::IcapPeerConnector"),
+        PeerConnector(aServerConn, aCallback, timeout), icapService(service) {}
+
+    /* PeerConnector API */
+    virtual Security::SessionPointer initializeSsl();
+    virtual void noteNegotiationDone(ErrorState *error);
+    virtual Security::ContextPointer getSslContext() {return icapService->sslContext;}
+
+private:
+    Adaptation::Icap::ServiceRep::Pointer icapService;
+};
+} // namespace Ssl
+
+CBDATA_NAMESPACED_CLASS_INIT(Ssl, IcapPeerConnector);
+#endif
+
 Adaptation::Icap::Xaction::Xaction(const char *aTypeName, Adaptation::Icap::ServiceRep::Pointer &aService):
     AsyncJob(aTypeName),
     Adaptation::Initiate(aTypeName),
@@ -39,8 +80,6 @@ Adaptation::Icap::Xaction::Xaction(const char *aTypeName, Adaptation::Icap::Serv
     attempts(0),
     connection(NULL),
     theService(aService),
-    commBuf(NULL),
-    commBufSize(0),
     commEof(false),
     reuseConnection(true),
     isRetriable(true),
@@ -95,11 +134,6 @@ void Adaptation::Icap::Xaction::disableRepeats(const char *reason)
 void Adaptation::Icap::Xaction::start()
 {
     Adaptation::Initiate::start();
-
-    readBuf.init(SQUID_TCP_SO_RCVBUF, SQUID_TCP_SO_RCVBUF);
-    commBuf = (char*)memAllocBuf(SQUID_TCP_SO_RCVBUF, &commBufSize);
-    // make sure maximum readBuf space does not exceed commBuf size
-    Must(static_cast<size_t>(readBuf.potentialSpaceSize()) <= commBufSize);
 }
 
 static void
@@ -183,7 +217,7 @@ Adaptation::Icap::Xaction::dnsLookupDone(const ipcache_addrs *ia)
     connector = JobCallback(93,3, ConnectDialer, this, Adaptation::Icap::Xaction::noteCommConnected);
     cs = new Comm::ConnOpener(connection, connector, TheConfig.connect_timeout(service().cfg().bypass));
     cs->setHost(s.cfg().host.termedBuf());
-    AsyncJob::Start(cs);
+    AsyncJob::Start(cs.get());
 }
 
 /*
@@ -259,6 +293,23 @@ void Adaptation::Icap::Xaction::noteCommConnected(const CommConnectCbParams &io)
                         CloseDialer(this,&Adaptation::Icap::Xaction::noteCommClosed));
     comm_add_close_handler(io.conn->fd, closer);
 
+#if USE_OPENSSL
+    // If it is a reused connection and the SSL object is build
+    // we should not negotiate new SSL session
+    auto ssl = fd_table[io.conn->fd].ssl;
+    if (!ssl && service().cfg().secure.encryptTransport) {
+        CbcPointer<Adaptation::Icap::Xaction> me(this);
+        securer = asyncCall(93, 4, "Adaptation::Icap::Xaction::handleSecuredPeer",
+                            MyIcapAnswerDialer(me, &Adaptation::Icap::Xaction::handleSecuredPeer));
+
+        Ssl::PeerConnector::HttpRequestPointer tmpReq(NULL);
+        Ssl::IcapPeerConnector *sslConnector =
+            new Ssl::IcapPeerConnector(theService, io.conn, securer, TheConfig.connect_timeout(service().cfg().bypass));
+        AsyncJob::Start(sslConnector); // will call our callback
+        return;
+    }
+#endif
+
 // ??    fd_table[io.conn->fd].noteUse(icapPconnPool);
     service().noteConnectionUse(connection);
 
@@ -330,6 +381,10 @@ void Adaptation::Icap::Xaction::handleCommTimedout()
 // unexpected connection close while talking to the ICAP service
 void Adaptation::Icap::Xaction::noteCommClosed(const CommCloseCbParams &)
 {
+    if (securer != NULL) {
+        securer->cancel("Connection closed before SSL negotiation finished");
+        securer = NULL;
+    }
     closer = NULL;
     handleCommClosed();
 }
@@ -358,7 +413,7 @@ void Adaptation::Icap::Xaction::callEnd()
 
 bool Adaptation::Icap::Xaction::doneAll() const
 {
-    return !connector && !reader && !writer && Adaptation::Initiate::doneAll();
+    return !connector && !securer && !reader && !writer && Adaptation::Initiate::doneAll();
 }
 
 void Adaptation::Icap::Xaction::updateTimeout()
@@ -383,17 +438,11 @@ void Adaptation::Icap::Xaction::scheduleRead()
 {
     Must(haveConnection());
     Must(!reader);
-    Must(readBuf.hasSpace());
+    Must(readBuf.length() < SQUID_TCP_SO_RCVBUF); // will expand later if needed
 
-    /*
-     * See comments in Adaptation::Icap::Xaction.h about why we use commBuf
-     * here instead of reading directly into readBuf.buf.
-     */
     typedef CommCbMemFunT<Adaptation::Icap::Xaction, CommIoCbParams> Dialer;
-    reader = JobCallback(93, 3,
-                         Dialer, this, Adaptation::Icap::Xaction::noteCommRead);
-
-    comm_read(connection, commBuf, readBuf.spaceSize(), reader);
+    reader = JobCallback(93, 3, Dialer, this, Adaptation::Icap::Xaction::noteCommRead);
+    Comm::Read(connection, reader);
     updateTimeout();
 }
 
@@ -405,7 +454,37 @@ void Adaptation::Icap::Xaction::noteCommRead(const CommIoCbParams &io)
 
     Must(io.flag == Comm::OK);
 
-    if (!io.size) {
+    // TODO: tune this better to expected message sizes
+    readBuf.reserveCapacity(SQUID_TCP_SO_RCVBUF);
+    // we are not asked to grow beyond the allowed maximum
+    Must(readBuf.length() < SQUID_TCP_SO_RCVBUF);
+    // now we can ensure that there is space to read new data,
+    // even if readBuf.spaceSize() currently returns zero.
+    readBuf.rawSpace(1);
+
+    CommIoCbParams rd(this); // will be expanded with ReadNow results
+    rd.conn = io.conn;
+
+    switch (Comm::ReadNow(rd, readBuf)) {
+    case Comm::INPROGRESS:
+        if (readBuf.isEmpty())
+            debugs(33, 2, io.conn << ": no data to process, " << xstrerr(rd.xerrno));
+        scheduleRead();
+        return;
+
+    case Comm::OK:
+        al.icap.bytesRead += rd.size;
+
+        updateTimeout();
+
+        debugs(93, 3, "read " << rd.size << " bytes");
+
+        disableRetries(); // because pconn did not fail
+
+        /* Continue to process previously read data */
+        break;
+
+    case Comm::ENDFILE: // close detected by 0-byte read
         commEof = true;
         reuseConnection = false;
 
@@ -415,21 +494,14 @@ void Adaptation::Icap::Xaction::noteCommRead(const CommIoCbParams &io)
             mustStop("pconn race");
             return;
         }
-    } else {
-
-        al.icap.bytesRead+=io.size;
-
-        updateTimeout();
 
-        debugs(93, 3, HERE << "read " << io.size << " bytes");
+        break;
 
-        /*
-         * See comments in Adaptation::Icap::Xaction.h about why we use commBuf
-         * here instead of reading directly into readBuf.buf.
-         */
-
-        readBuf.append(commBuf, io.size);
-        disableRetries(); // because pconn did not fail
+    // case Comm::COMM_ERROR:
+    default: // no other flags should ever occur
+        debugs(11, 2, io.conn << ": read failure: " << xstrerr(rd.xerrno));
+        mustStop("unknown ICAP I/O read error");
+        return;
     }
 
     handleCommRead(io.size);
@@ -446,10 +518,12 @@ void Adaptation::Icap::Xaction::cancelRead()
 
 bool Adaptation::Icap::Xaction::parseHttpMsg(HttpMsg *msg)
 {
-    debugs(93, 5, HERE << "have " << readBuf.contentSize() << " head bytes to parse");
+    debugs(93, 5, "have " << readBuf.length() << " head bytes to parse");
 
     Http::StatusCode error = Http::scNone;
-    const bool parsed = msg->parse(&readBuf, commEof, &error);
+    // XXX: performance regression c_str() data copies
+    const char *buf = readBuf.c_str();
+    const bool parsed = msg->parse(buf, readBuf.length(), commEof, &error);
     Must(parsed || !error); // success or need more data
 
     if (!parsed) {  // need more data
@@ -465,7 +539,7 @@ bool Adaptation::Icap::Xaction::parseHttpMsg(HttpMsg *msg)
 bool Adaptation::Icap::Xaction::mayReadMore() const
 {
     return !doneReading() && // will read more data
-           readBuf.hasSpace();  // have space for more data
+           readBuf.length() < SQUID_TCP_SO_RCVBUF;  // have space for more data
 }
 
 bool Adaptation::Icap::Xaction::doneReading() const
@@ -521,7 +595,7 @@ void Adaptation::Icap::Xaction::setOutcome(const Adaptation::Icap::XactOutcome &
 void Adaptation::Icap::Xaction::swanSong()
 {
     // kids should sing first and then call the parent method.
-    if (cs) {
+    if (cs.valid()) {
         debugs(93,6, HERE << id << " about to notify ConnOpener!");
         CallJobHere(93, 3, cs, Comm::ConnOpener, noteAbort);
         cs = NULL;
@@ -530,11 +604,7 @@ void Adaptation::Icap::Xaction::swanSong()
 
     closeConnection(); // TODO: rename because we do not always close
 
-    if (!readBuf.isNull())
-        readBuf.clean();
-
-    if (commBuf)
-        memFreeBuf(commBufSize, commBuf);
+    readBuf.clear();
 
     tellQueryAborted();
 
@@ -591,15 +661,11 @@ const char *Adaptation::Icap::Xaction::status() const
 {
     static MemBuf buf;
     buf.reset();
-
     buf.append(" [", 2);
-
     fillPendingStatus(buf);
     buf.append("/", 1);
     fillDoneStatus(buf);
-
-    buf.Printf(" %s%u]", id.Prefix, id.value);
-
+    buf.appendf(" %s%u]", id.Prefix, id.value);
     buf.terminate();
 
     return buf.content();
@@ -608,7 +674,7 @@ const char *Adaptation::Icap::Xaction::status() const
 void Adaptation::Icap::Xaction::fillPendingStatus(MemBuf &buf) const
 {
     if (haveConnection()) {
-        buf.Printf("FD %d", connection->fd);
+        buf.appendf("FD %d", connection->fd);
 
         if (writer != NULL)
             buf.append("w", 1);
@@ -623,14 +689,84 @@ void Adaptation::Icap::Xaction::fillPendingStatus(MemBuf &buf) const
 void Adaptation::Icap::Xaction::fillDoneStatus(MemBuf &buf) const
 {
     if (haveConnection() && commEof)
-        buf.Printf("Comm(%d)", connection->fd);
+        buf.appendf("Comm(%d)", connection->fd);
 
     if (stopReason != NULL)
-        buf.Printf("Stopped");
+        buf.append("Stopped", 7);
 }
 
 bool Adaptation::Icap::Xaction::fillVirginHttpHeader(MemBuf &) const
 {
     return false;
 }
 
+#if USE_OPENSSL
+Security::SessionPointer
+Ssl::IcapPeerConnector::initializeSsl()
+{
+    auto ssl = Ssl::PeerConnector::initializeSsl();
+    if (!ssl)
+        return nullptr;
+
+    assert(!icapService->cfg().secure.sslDomain.isEmpty());
+    SBuf *host = new SBuf(icapService->cfg().secure.sslDomain);
+    SSL_set_ex_data(ssl, ssl_ex_index_server, host);
+
+    ACLFilledChecklist *check = (ACLFilledChecklist *)SSL_get_ex_data(ssl, ssl_ex_index_cert_error_check);
+    if (check)
+        check->dst_peer_name = *host;
+
+    if (icapService->sslSession)
+        SSL_set_session(ssl, icapService->sslSession);
+
+    return ssl;
+}
+
+void
+Ssl::IcapPeerConnector::noteNegotiationDone(ErrorState *error)
+{
+    if (error)
+        return;
+
+    const int fd = serverConnection()->fd;
+    auto ssl = fd_table[fd].ssl;
+    assert(ssl);
+    if (!SSL_session_reused(ssl)) {
+        if (icapService->sslSession)
+            SSL_SESSION_free(icapService->sslSession);
+        icapService->sslSession = SSL_get1_session(ssl);
+    }
+}
+
+void
+Adaptation::Icap::Xaction::handleSecuredPeer(Security::EncryptorAnswer &answer)
+{
+    Must(securer != NULL);
+    securer = NULL;
+
+    if (closer != NULL) {
+        if (answer.conn != NULL)
+            comm_remove_close_handler(answer.conn->fd, closer);
+        else
+            closer->cancel("securing completed");
+        closer = NULL;
+    }
+
+    if (answer.error.get()) {
+        if (answer.conn != NULL)
+            answer.conn->close();
+        debugs(93, 2, typeName <<
+               " SSL negotiation to " << service().cfg().uri << " failed");
+        service().noteConnectionFailed("failure");
+        detailError(ERR_DETAIL_ICAP_XACT_SSL_START);
+        throw TexcHere("cannot connect to the SSL ICAP service");
+    }
+
+    debugs(93, 5, "SSL negotiation to " << service().cfg().uri << " complete");
+
+    service().noteConnectionUse(answer.conn);
+
+    handleCommConnected();
+}
+#endif
+
@@ -12,11 +12,15 @@
 #include "AccessLogEntry.h"
 #include "adaptation/icap/ServiceRep.h"
 #include "adaptation/Initiate.h"
-#include "comm/forward.h"
-#include "CommCalls.h"
+#include "comm/ConnOpener.h"
 #include "HttpReply.h"
 #include "ipcache.h"
-#include "MemBuf.h"
+#include "SBuf.h"
+#if USE_OPENSSL
+#include "ssl/PeerConnector.h"
+#endif
+
+class MemBuf;
 
 namespace Adaptation
 {
@@ -70,6 +74,7 @@ class Xaction: public Adaptation::Initiate
     virtual void handleCommTimedout();
     virtual void handleCommClosed();
 
+    void handleSecuredPeer(Security::EncryptorAnswer &answer);
     /// record error detail if possible
     virtual void detailError(int) {}
 
@@ -127,20 +132,7 @@ class Xaction: public Adaptation::Initiate
     Comm::ConnectionPointer connection;     ///< ICAP server connection
     Adaptation::Icap::ServiceRep::Pointer theService;
 
-    /*
-     * We have two read buffers.   We would prefer to read directly
-     * into the MemBuf, but since comm_read isn't MemBuf-aware, and
-     * uses event-delayed callbacks, it leaves the MemBuf in an
-     * inconsistent state.  There would be data in the buffer, but
-     * MemBuf.size won't be updated until the (delayed) callback
-     * occurs.   To avoid that situation we use a plain buffer
-     * (commBuf) and then copy (append) its contents to readBuf in
-     * the callback.  If comm_read ever becomes MemBuf-aware, we
-     * can eliminate commBuf and this extra buffer copy.
-     */
-    MemBuf readBuf;
-    char *commBuf;
-    size_t commBufSize;
+    SBuf readBuf;
     bool commEof;
     bool reuseConnection;
     bool isRetriable;  ///< can retry on persistent connection failures
@@ -163,7 +155,8 @@ class Xaction: public Adaptation::Initiate
     timeval icap_tio_finish;   /*time when the last byte of the ICAP responsewas received*/
 
 private:
-    Comm::ConnOpener *cs;
+    Comm::ConnOpener::Pointer cs;
+    AsyncCall::Pointer securer; ///< whether we are securing a connection
 };
 
 } // namespace Icap
@@ -10,6 +10,7 @@
 #include "anyp/PortCfg.h"
 #include "comm.h"
 #include "fatal.h"
+#include "security/PeerOptions.h"
 #if USE_OPENSSL
 #include "ssl/support.h"
 #endif
@@ -43,17 +44,10 @@ AnyP::PortCfg::PortCfg() :
     disable_pmtu_discovery(0),
     listenConn()
 #if USE_OPENSSL
-    ,cert(NULL),
-    key(NULL),
-    version(0),
-    cipher(NULL),
-    options(NULL),
+    ,
     clientca(NULL),
-    cafile(NULL),
-    capath(NULL),
-    crlfile(NULL),
     dhfile(NULL),
-    sslflags(NULL),
+    tls_dh(NULL),
     sslContextSessionId(NULL),
     generateHostCertificates(false),
     dynamicCertMemCacheSize(std::numeric_limits<size_t>::max()),
@@ -66,9 +60,7 @@ AnyP::PortCfg::PortCfg() :
     clientVerifyCrls(),
     clientCA(),
     dhParams(),
-    contextMethod(),
-    sslContextFlags(0),
-    sslOptions(0)
+    eecdhCurve(NULL)
 #endif
 {
     memset(&tcp_keepalive, 0, sizeof(tcp_keepalive));
@@ -85,17 +77,11 @@ AnyP::PortCfg::~PortCfg()
     safe_free(defaultsite);
 
 #if USE_OPENSSL
-    safe_free(cert);
-    safe_free(key);
-    safe_free(cipher);
-    safe_free(options);
     safe_free(clientca);
-    safe_free(cafile);
-    safe_free(capath);
-    safe_free(crlfile);
     safe_free(dhfile);
-    safe_free(sslflags);
+    safe_free(tls_dh);
     safe_free(sslContextSessionId);
+    safe_free(eecdhCurve);
 #endif
 }
 
@@ -118,36 +104,22 @@ AnyP::PortCfg::clone() const
     b->ftp_track_dirs = ftp_track_dirs;
     b->disable_pmtu_discovery = disable_pmtu_discovery;
     b->tcp_keepalive = tcp_keepalive;
+    b->secure = secure;
 
 #if USE_OPENSSL
-    if (cert)
-        b->cert = xstrdup(cert);
-    if (key)
-        b->key = xstrdup(key);
-    b->version = version;
-    if (cipher)
-        b->cipher = xstrdup(cipher);
-    if (options)
-        b->options = xstrdup(options);
     if (clientca)
         b->clientca = xstrdup(clientca);
-    if (cafile)
-        b->cafile = xstrdup(cafile);
-    if (capath)
-        b->capath = xstrdup(capath);
-    if (crlfile)
-        b->crlfile = xstrdup(crlfile);
     if (dhfile)
         b->dhfile = xstrdup(dhfile);
-    if (sslflags)
-        b->sslflags = xstrdup(sslflags);
+    if (tls_dh)
+        b->tls_dh = xstrdup(tls_dh);
     if (sslContextSessionId)
         b->sslContextSessionId = xstrdup(sslContextSessionId);
 
 #if 0
     // TODO: AYJ: 2015-01-15: for now SSL does not clone the context object.
     // cloning should only be done before the PortCfg is post-configure initialized and opened
-    SSL_CTX *sslContext;
+    Security::ContextPointer sslContext;
 #endif
 
 #endif /*0*/
@@ -159,8 +131,8 @@ AnyP::PortCfg::clone() const
 void
 AnyP::PortCfg::configureSslServerContext()
 {
-    if (cert)
-        Ssl::readCertChainAndPrivateKeyFromFiles(signingCert, signPkey, certsToChain, cert, key);
+    if (!secure.certFile.isEmpty())
+        Ssl::readCertChainAndPrivateKeyFromFiles(signingCert, signPkey, certsToChain, secure.certFile.c_str(), secure.privateKeyFile.c_str());
 
     if (!signingCert) {
         char buf[128];
@@ -178,8 +150,8 @@ AnyP::PortCfg::configureSslServerContext()
         fatalf("Unable to generate signing SSL certificate for untrusted sites for %s_port %s", AnyP::ProtocolType_str[transport.protocol], s.toUrl(buf, sizeof(buf)));
     }
 
-    if (crlfile)
-        clientVerifyCrls.reset(Ssl::loadCrl(crlfile, sslContextFlags));
+    if (!secure.crlFile.isEmpty())
+        clientVerifyCrls.reset(Ssl::loadCrl(secure.crlFile.c_str(), secure.parsedFlags));
 
     if (clientca) {
         clientCA.reset(SSL_load_client_CA_file(clientca));
@@ -188,17 +160,25 @@ AnyP::PortCfg::configureSslServerContext()
         }
     }
 
-    contextMethod = Ssl::contextMethod(version);
-    if (!contextMethod)
-        fatalf("Unable to compute context method to use");
-
-    if (dhfile)
-        dhParams.reset(Ssl::readDHParams(dhfile));
-
-    if (sslflags)
-        sslContextFlags = Ssl::parse_flags(sslflags);
+    secure.updateTlsVersionLimits();
+
+    const char *dhParamsFile = dhfile; // backward compatibility for dhparams= configuration
+    safe_free(eecdhCurve); // clear any previous EECDH configuration
+    if (tls_dh && *tls_dh) {
+        eecdhCurve = xstrdup(tls_dh);
+        char *p = strchr(eecdhCurve, ':');
+        if (p) {  // tls-dh=eecdhCurve:dhParamsFile
+            *p = '\0';
+            dhParamsFile = p+1;
+        } else {  // tls-dh=dhParamsFile
+            dhParamsFile = tls_dh;
+            // a NULL eecdhCurve means "do not use EECDH"
+            safe_free(eecdhCurve);
+        }
+    }
 
-    sslOptions = Ssl::parse_options(options);
+    if (dhParamsFile && *dhParamsFile)
+        dhParams.reset(Ssl::readDHParams(dhParamsFile));
 
     staticSslContext.reset(sslCreateServerContext(*this));
 
@@ -13,6 +13,8 @@
 #include "anyp/ProtocolVersion.h"
 #include "anyp/TrafficMode.h"
 #include "comm/Connection.h"
+#include "SBuf.h"
+#include "security/PeerOptions.h"
 
 #if USE_OPENSSL
 #include "ssl/gadgets.h"
@@ -67,18 +69,13 @@ class PortCfg : public RefCountable
      */
     Comm::ConnectionPointer listenConn;
 
+    /// TLS configuration options for this listening port
+    Security::PeerOptions secure;
+
 #if USE_OPENSSL
-    char *cert;
-    char *key;
-    int version;
-    char *cipher;
-    char *options;
     char *clientca;
-    char *cafile;
-    char *capath;
-    char *crlfile;
     char *dhfile;
-    char *sslflags;
+    char *tls_dh;
     char *sslContextSessionId; ///< "session id context" for staticSslContext
     bool generateHostCertificates; ///< dynamically make host cert for sslBump
     size_t dynamicCertMemCacheSize; ///< max size of generated certificates memory cache
@@ -93,9 +90,7 @@ class PortCfg : public RefCountable
     Ssl::X509_CRL_STACK_Pointer clientVerifyCrls; ///< additional CRL lists to use when verifying the client certificate
     Ssl::X509_NAME_STACK_Pointer clientCA; ///< CA certificates to use when verifying client certificates
     Ssl::DH_Pointer dhParams; ///< DH parameters for temporary/ephemeral DH key exchanges
-    Ssl::ContextMethod contextMethod; ///< The context method (SSL_METHOD) to use when creating certificates
-    long sslContextFlags; ///< flags modifying the use of SSL
-    long sslOptions; ///< SSL engine options
+    char *eecdhCurve; ///< Elliptic curve for ephemeral EC-based DH key exchanges
 #endif
 };
 
@@ -29,3 +29,40 @@ AnyP::UriScheme::c_str() const
     return out;
 }
 
+unsigned short
+AnyP::UriScheme::defaultPort() const
+{
+    switch (theScheme_) {
+
+    case AnyP::PROTO_HTTP:
+        return 80;
+
+    case AnyP::PROTO_HTTPS:
+        return 443;
+
+    case AnyP::PROTO_FTP:
+        return 21;
+
+    case AnyP::PROTO_COAP:
+    case AnyP::PROTO_COAPS:
+        // coaps:// default is TBA as of draft-ietf-core-coap-08.
+        // Assuming IANA policy of allocating same port for base and TLS protocol versions will occur.
+        return 5683;
+
+    case AnyP::PROTO_GOPHER:
+        return 70;
+
+    case AnyP::PROTO_WAIS:
+        return 210;
+
+    case AnyP::PROTO_CACHE_OBJECT:
+        return CACHE_HTTP_PORT;
+
+    case AnyP::PROTO_WHOIS:
+        return 43;
+
+    default:
+        return 0;
+    }
+}
+
@@ -39,6 +39,8 @@ class UriScheme
      */
     char const *c_str() const;
 
+    unsigned short defaultPort() const;
+
 private:
     /// This is a typecode pointer into the enum/registry of protocols handled.
     AnyP::ProtocolType theScheme_;
@@ -27,8 +27,8 @@ class HttpRequest;
 /**
  * Maximum length (buffer size) for token strings.
  */
-// AYJ: must match re-definition in helpers/negotiate_auth/kerberos/negotiate_kerb_auth.cc
-#define MAX_AUTHTOKEN_LEN   32768
+// XXX: Keep in sync with all others: bzr grep 'define MAX_AUTHTOKEN_LEN'
+#define MAX_AUTHTOKEN_LEN   65535
 
 /**
  * Node used to link an IP address to some user credentials
@@ -147,7 +147,8 @@ Auth::Basic::Config::parse(Auth::Config * scheme, int n_configured, char *param_
 static void
 authenticateBasicStats(StoreEntry * sentry)
 {
-    helperStats(sentry, basicauthenticators, "Basic Authenticator Statistics");
+    if (basicauthenticators)
+        basicauthenticators->packStatsInto(sentry, "Basic Authenticator Statistics");
 }
 
 char *
@@ -39,6 +39,8 @@
  */
 #include "mem/Pool.h"
 
+#include <random>
+
 static AUTHSSTATS authenticateDigestStats;
 
 helper *digestauthenticators = NULL;
@@ -147,30 +149,28 @@ authenticateDigestNonceNew(void)
      * component in the nonce allows us to loop to find a unique nonce.
      * We use H(nonce_data) so the nonce is meaningless to the reciever.
      * So our nonce looks like base64(H(timestamp,pointertohash,randomdata))
-     * And even if our randomness is not very random (probably due to
-     * bad coding on my part) we don't really care - the timestamp and
-     * memory pointer also guarantee local uniqueness in the input to the hash
-     * function.
+     * And even if our randomness is not very random we don't really care
+     * - the timestamp and memory pointer also guarantee local uniqueness
+     * in the input to the hash function.
      */
+    // NP: this will likely produce the same randomness sequences for each worker
+    // since they should all start within the 1-second resolution of seed value.
+    static std::mt19937 mt(static_cast<uint32_t>(getCurrentTime() & 0xFFFFFFFF));
+    static std::uniform_int_distribution<uint32_t> newRandomData;
 
     /* create a new nonce */
     newnonce->nc = 0;
     newnonce->flags.valid = true;
     newnonce->noncedata.self = newnonce;
     newnonce->noncedata.creationtime = current_time.tv_sec;
-    newnonce->noncedata.randomdata = squid_random();
+    newnonce->noncedata.randomdata = newRandomData(mt);
 
     authDigestNonceEncode(newnonce);
-    /*
-     * loop until we get a unique nonce. The nonce creation must
-     * have a random factor
-     */
 
+    // ensure temporal uniqueness by checking for existing nonce
     while (authenticateDigestNonceFindNonce((char const *) (newnonce->key))) {
         /* create a new nonce */
-        newnonce->noncedata.randomdata = squid_random();
-        /* Bug 3526 high performance fix: add 1 second to creationtime to avoid duplication */
-        ++newnonce->noncedata.creationtime;
+        newnonce->noncedata.randomdata = newRandomData(mt);
         authDigestNonceEncode(newnonce);
     }
 
@@ -643,7 +643,8 @@ Auth::Digest::Config::type() const
 static void
 authenticateDigestStats(StoreEntry * sentry)
 {
-    helperStats(sentry, digestauthenticators, "Digest Authenticator Statistics");
+    if (digestauthenticators)
+        digestauthenticators->packStatsInto(sentry, "Digest Authenticator Statistics");
 }
 
 /* NonceUserUnlink: remove the reference to auth_user and unlink the node from the list */
@@ -32,7 +32,7 @@ struct _digest_nonce_data {
     time_t creationtime;
     /* in memory address of the nonce struct (similar purpose to an ETag) */
     digest_nonce_h *self;
-    long randomdata;
+    uint32_t randomdata;
 };
 
 /* the nonce structure we'll pass around */
@@ -244,7 +244,8 @@ Auth::Negotiate::Config::fixHeader(Auth::UserRequest::Pointer auth_user_request,
 static void
 authenticateNegotiateStats(StoreEntry * sentry)
 {
-    helperStatefulStats(sentry, negotiateauthenticators, "Negotiate Authenticator Statistics");
+    if (negotiateauthenticators)
+        negotiateauthenticators->packStatsInto(sentry, "Negotiate Authenticator Statistics");
 }
 
 /*
@@ -69,11 +69,20 @@ const char *
 Auth::Negotiate::UserRequest::credentialsStr()
 {
     static char buf[MAX_AUTHTOKEN_LEN];
+    int printResult = 0;
     if (user()->credentials() == Auth::Pending) {
-        snprintf(buf, sizeof(buf), "YR %s\n", client_blob); //CHECKME: can ever client_blob be 0 here?
+        printResult = snprintf(buf, sizeof(buf), "YR %s\n", client_blob); //CHECKME: can ever client_blob be 0 here?
     } else {
-        snprintf(buf, sizeof(buf), "KK %s\n", client_blob);
+        printResult = snprintf(buf, sizeof(buf), "KK %s\n", client_blob);
     }
+
+    // truncation is OK because we are used only for logging
+    if (printResult < 0) {
+        debugs(29, 2, "Can not build negotiate authentication credentials.");
+        buf[0] = '\0';
+    } else if (printResult >= (int)sizeof(buf))
+        debugs(29, 2, "Negotiate authentication credentials truncated.");
+
     return buf;
 }
 
@@ -126,16 +135,26 @@ Auth::Negotiate::UserRequest::startHelperLookup(HttpRequest *, AccessLogEntry::P
     debugs(29, 8, HERE << "credentials state is '" << user()->credentials() << "'");
 
     const char *keyExtras = helperRequestKeyExtras(request, al);
+    int printResult = 0;
     if (user()->credentials() == Auth::Pending) {
         if (keyExtras)
-            snprintf(buf, sizeof(buf), "YR %s %s\n", client_blob, keyExtras);
+            printResult = snprintf(buf, sizeof(buf), "YR %s %s\n", client_blob, keyExtras);
         else
-            snprintf(buf, sizeof(buf), "YR %s\n", client_blob); //CHECKME: can ever client_blob be 0 here?
+            printResult = snprintf(buf, sizeof(buf), "YR %s\n", client_blob); //CHECKME: can ever client_blob be 0 here?
     } else {
         if (keyExtras)
-            snprintf(buf, sizeof(buf), "KK %s %s\n", client_blob, keyExtras);
+            printResult = snprintf(buf, sizeof(buf), "KK %s %s\n", client_blob, keyExtras);
         else
-            snprintf(buf, sizeof(buf), "KK %s\n", client_blob);
+            printResult = snprintf(buf, sizeof(buf), "KK %s\n", client_blob);
+    }
+
+    if (printResult < 0 || printResult >= (int)sizeof(buf)) {
+        if (printResult < 0)
+            debugs(29, DBG_CRITICAL, "ERROR: Can not build negotiate authentication helper request");
+        else
+            debugs(29, DBG_CRITICAL, "ERROR: Negotiate authentication helper request too big for the " << sizeof(buf) << "-byte buffer");
+        handler(data);
+        return;
     }
 
     waiting = 1;
@@ -224,7 +224,8 @@ Auth::Ntlm::Config::fixHeader(Auth::UserRequest::Pointer auth_user_request, Http
 static void
 authenticateNTLMStats(StoreEntry * sentry)
 {
-    helperStatefulStats(sentry, ntlmauthenticators, "NTLM Authenticator Statistics");
+    if (ntlmauthenticators)
+        ntlmauthenticators->packStatsInto(sentry, "NTLM Authenticator Statistics");
 }
 
 /*
@@ -68,11 +68,20 @@ const char *
 Auth::Ntlm::UserRequest::credentialsStr()
 {
     static char buf[MAX_AUTHTOKEN_LEN];
+    int printResult;
     if (user()->credentials() == Auth::Pending) {
-        snprintf(buf, sizeof(buf), "YR %s\n", client_blob);
+        printResult = snprintf(buf, sizeof(buf), "YR %s\n", client_blob);
     } else {
-        snprintf(buf, sizeof(buf), "KK %s\n", client_blob);
+        printResult = snprintf(buf, sizeof(buf), "KK %s\n", client_blob);
     }
+
+    // truncation is OK because we are used only for logging
+    if (printResult < 0) {
+        debugs(29, 2, "Can not build ntlm authentication credentials.");
+        buf[0] = '\0';
+    } else if (printResult >= (int)sizeof(buf))
+        debugs(29, 2, "Ntlm authentication credentials truncated.");
+
     return buf;
 }
 
@@ -122,19 +131,29 @@ Auth::Ntlm::UserRequest::startHelperLookup(HttpRequest *, AccessLogEntry::Pointe
     debugs(29, 8, HERE << "credentials state is '" << user()->credentials() << "'");
 
     const char *keyExtras = helperRequestKeyExtras(request, al);
+    int printResult = 0;
     if (user()->credentials() == Auth::Pending) {
         if (keyExtras)
-            snprintf(buf, sizeof(buf), "YR %s %s\n", client_blob, keyExtras);
+            printResult = snprintf(buf, sizeof(buf), "YR %s %s\n", client_blob, keyExtras);
         else
-            snprintf(buf, sizeof(buf), "YR %s\n", client_blob); //CHECKME: can ever client_blob be 0 here?
+            printResult = snprintf(buf, sizeof(buf), "YR %s\n", client_blob); //CHECKME: can ever client_blob be 0 here?
     } else {
         if (keyExtras)
-            snprintf(buf, sizeof(buf), "KK %s %s\n", client_blob, keyExtras);
+            printResult = snprintf(buf, sizeof(buf), "KK %s %s\n", client_blob, keyExtras);
         else
-            snprintf(buf, sizeof(buf), "KK %s\n", client_blob);
+            printResult = snprintf(buf, sizeof(buf), "KK %s\n", client_blob);
     }
     waiting = 1;
 
+    if (printResult < 0 || printResult >= (int)sizeof(buf)) {
+        if (printResult < 0)
+            debugs(29, DBG_CRITICAL, "ERROR: Can not build ntlm authentication helper request");
+        else
+            debugs(29, DBG_CRITICAL, "ERROR: Ntlm authentication helper request too big for the " << sizeof(buf) << "-byte buffer.");
+        handler(data);
+        return;
+    }
+
     safe_free(client_blob);
     helperStatefulSubmit(ntlmauthenticators, buf, Auth::Ntlm::UserRequest::HandleReply,
                          new Auth::StateData(this, handler, data), authserver);
@@ -162,10 +162,9 @@ const char *AsyncJob::status() const
 
     buf.append(" [", 2);
     if (stopReason != NULL) {
-        buf.Printf("Stopped, reason:");
-        buf.Printf("%s",stopReason);
+        buf.appendf("Stopped, reason:%s", stopReason);
     }
-    buf.Printf(" %s%u]", id.Prefix, id.value);
+    buf.appendf(" %s%u]", id.Prefix, id.value);
     buf.terminate();
 
     return buf.content();
@@ -37,7 +37,7 @@ If you want to do something before starting the job, do it in the constructor
 or some custom method that the job creator will call _before_ calling
 AsyncJob::Start():
 
-    std::auto_ptr<MyJob> job(new MyJob(...)); // sync/blocking
+    std::unique_ptr<MyJob> job(new MyJob(...)); // sync/blocking
     job->prepare(...); // sync/blocking
     job->prepareSomethingElse(...); // sync/blocking
     AsyncStart(job.release()); // non-blocking
@@ -35,12 +35,13 @@ class Lock
 #if defined(LOCKCOUNT_DEBUG)
         old_debug(0,1)("Incrementing this %p from count %u\n",this,count_);
 #endif
+        assert(count_ < UINT32_MAX);
         ++count_;
     }
 
     /// Clear one lock / reference against this object.
     /// All locks must be cleared before it may be destroyed.
-    unsigned unlock() const {
+    uint32_t unlock() const {
 #if defined(LOCKCOUNT_DEBUG)
         old_debug(0,1)("Decrementing this %p from count %u\n",this,count_);
 #endif
@@ -49,10 +50,10 @@ class Lock
     }
 
     /// Inspect the current count of references.
-    unsigned LockCount() const { return count_; }
+    uint32_t LockCount() const { return count_; }
 
 private:
-    mutable unsigned count_; ///< number of references currently being tracked
+    mutable uint32_t count_; ///< number of references currently being tracked
 };
 
 // For clarity we provide some aliases for the tracking mechanisms
@@ -26,6 +26,7 @@ libbase_la_SOURCES = \
 	InstanceId.h \
 	Lock.h \
 	LruMap.h \
+	Packable.h \
 	RunnersRegistry.cc \
 	RunnersRegistry.h \
 	Subscription.h \
@@ -0,0 +1,73 @@
+/*
+ * Copyright (C) 1996-2015 The Squid Software Foundation and contributors
+ *
+ * Squid software is distributed under GPLv2+ license and includes
+ * contributions from numerous individuals and organizations.
+ * Please see the COPYING and CONTRIBUTORS files for details.
+ */
+
+#ifndef SQUID_SRC_BASE_PACKABLE_H
+#define SQUID_SRC_BASE_PACKABLE_H
+
+/**
+ * A uniform interface to store-like modules
+ *
+ * Rationale:
+ * ----------
+ *
+ * We have two major interfaces Comm and Store, which take a variety of
+ * different data buffering objects and have different output actions
+ * to be performed on data.
+ *
+ * Store has a nice storeAppend[Printf] capability which makes "storing"
+ * things easy and painless.
+ *
+ * Comm lacks commAppend[Printf] because Comm does not handle its own
+ * buffers (no mem_obj equivalent for Comm).
+ *
+ * Thus, if one wants to be able to Store _and_ Comm::Write an object, 'e
+ * has to implement almost identical functions for using all the data
+ * storage objects and their associated actions. Doing this for all the
+ * available data storage types is a tedious nightmare of almost-duplicated
+ * code.
+ *
+ * Packer
+ * ------
+ *
+ * Objects inheriting from Packable provide a uniform interface for code to
+ * assemble data before passing to Store and Comm modules.
+ *
+ * Packable objects have their own append and printf routines that "know"
+ * where to send incoming data. In case of Store interface, sending data to
+ * storeAppend. Packable buffer objects retain the data such that it can be
+ * flushed later to Comm::Write.
+ *
+ * Thus, one can write just one function that will take a Packable object
+ * and either "pack" things for Comm::Write or "append" things to Store,
+ * depending on actual Packable object supplied.
+ */
+class Packable
+{
+public:
+    /// Appends a c-string to existing packed data.
+    virtual void append(const char *buf, int size) = 0;
+
+    /// Append operation with printf-style arguments.
+    void appendf(const char *fmt,...) PRINTF_FORMAT_ARG2
+    {
+        va_list args;
+        va_start(args, fmt);
+        vappendf(fmt, args);
+        va_end(args);
+    }
+
+    /** Append operation, with vsprintf(3)-style arguments.
+     *
+     * \note arguments may be evaluated more than once, be careful
+     *       of side-effects
+     */
+    virtual void vappendf(const char *fmt, va_list ap) = 0;
+};
+
+#endif /* SQUID_SRC_BASE_PACKABLE_H */
+
@@ -39,9 +39,11 @@ class RefCount
         reference (p);
     }
 
+#if __cplusplus >= 201103L
     RefCount (RefCount &&p) : p_(std::move(p.p_)) {
         p.p_=NULL;
     }
+#endif
 
     RefCount& operator = (const RefCount& p) {
         // DO NOT CHANGE THE ORDER HERE!!!
@@ -52,13 +54,15 @@ class RefCount
         return *this;
     }
 
+#if __cplusplus >= 201103L
     RefCount& operator = (RefCount&& p) {
         if (this != &p) {
             dereference(p.p_);
             p.p_ = NULL;
         }
         return *this;
     }
+#endif
 
     bool operator !() const { return !p_; }
 
@@ -32,6 +32,14 @@ RegisterRunner(RegisteredRunner *rr)
     return runners.size();
 }
 
+int
+DeregisterRunner(RegisteredRunner *rr)
+{
+    Runners &runners = GetRunners();
+    runners.erase(rr);
+    return runners.size();
+}
+
 void
 RunRegistered(const RegisteredRunner::Method &m)
 {
@@ -68,6 +68,12 @@ class RegisteredRunner
     /// Meant for cleanup and state saving that may require other modules.
     virtual void startShutdown() {}
 
+    /// Called after shutdown_lifetime grace period ends and before stopping
+    /// the main loop. At least one main loop iteration is guaranteed after
+    /// this call.
+    /// Meant for cleanup and state saving that may require other modules.
+    virtual void endingShutdown() {}
+
     /// Called after stopping the main loop and before releasing memory.
     /// Meant for quick/basic cleanup that does not require any other modules.
     virtual ~RegisteredRunner() {}
@@ -82,6 +88,9 @@ class RegisteredRunner
 /// registers a given runner with the given registry and returns registry count
 int RegisterRunner(RegisteredRunner *rr);
 
+/// de-registers a given runner with the given registry and returns registry count
+int DeregisterRunner(RegisteredRunner *rr);
+
 /// Calls a given method of all runners.
 /// All runners are destroyed after the finishShutdown() call.
 void RunRegistered(const RegisteredRunner::Method &m);
@@ -11,7 +11,7 @@
 
 /**
  * A pointer that deletes the object it points to when the pointer's owner or
- * context is gone. Similar to std::auto_ptr but without confusing assignment
+ * context is gone. Similar to std::unique_ptr but without confusing assignment
  * and with a customizable cleanup method. Prevents memory leaks in
  * the presence of exceptions and processing short cuts.
 */
@@ -32,6 +32,7 @@
 #include "ftp/Elements.h"
 #include "globals.h"
 #include "HttpHeaderTools.h"
+#include "icmp/IcmpConfig.h"
 #include "ident/Config.h"
 #include "ip/Intercept.h"
 #include "ip/QosConfig.h"
@@ -783,13 +784,6 @@ configDoConfigure(void)
             break;
         }
 
-        for (R = Config.Refresh; R; R = R->next) {
-            if (!R->flags.ignore_must_revalidate)
-                continue;
-            debugs(22, DBG_IMPORTANT, "WARNING: use of 'ignore-must-revalidate' in 'refresh_pattern' violates HTTP");
-            break;
-        }
-
         for (R = Config.Refresh; R; R = R->next) {
             if (!R->flags.ignore_private)
                 continue;
@@ -871,22 +865,32 @@ configDoConfigure(void)
         Config2.effectiveGroupID = grp->gr_gid;
     }
 
-#if USE_OPENSSL
+    if (Security::ProxyOutgoingConfig.encryptTransport) {
+        debugs(3, DBG_IMPORTANT, "Initializing https:// proxy context");
+        Config.ssl_client.sslContext = Security::ProxyOutgoingConfig.createClientContext(false);
+        if (!Config.ssl_client.sslContext) {
+            debugs(3, DBG_CRITICAL, "ERROR: Could not initialize https:// proxy context");
+            self_destruct();
+        }
+    }
 
-    debugs(3, DBG_IMPORTANT, "Initializing https proxy context");
+    for (CachePeer *p = Config.peers; p != NULL; p = p->next) {
 
-    Config.ssl_client.sslContext = sslCreateClientContext(Config.ssl_client.cert, Config.ssl_client.key, Config.ssl_client.version, Config.ssl_client.cipher, NULL, Config.ssl_client.flags, Config.ssl_client.cafile, Config.ssl_client.capath, Config.ssl_client.crlfile);
-    // Pre-parse SSL client options to be applied when the client SSL objects created.
-    // Options must not used in the case of peek or stare bump mode.
-    Config.ssl_client.parsedOptions = Ssl::parse_options(::Config.ssl_client.options);
+        // default value for ssldomain= is the peer host/IP
+        if (p->secure.sslDomain.isEmpty())
+            p->secure.sslDomain = p->host;
 
-    for (CachePeer *p = Config.peers; p != NULL; p = p->next) {
-        if (p->use_ssl) {
-            debugs(3, DBG_IMPORTANT, "Initializing cache_peer " << p->name << " SSL context");
-            p->sslContext = sslCreateClientContext(p->sslcert, p->sslkey, p->sslversion, p->sslcipher, p->ssloptions, p->sslflags, p->sslcafile, p->sslcapath, p->sslcrlfile);
+        if (p->secure.encryptTransport) {
+            debugs(3, DBG_IMPORTANT, "Initializing cache_peer " << p->name << " TLS context");
+            p->sslContext = p->secure.createClientContext(true);
+            if (!p->sslContext) {
+                debugs(3, DBG_CRITICAL, "ERROR: Could not initialize cache_peer " << p->name << " TLS context");
+                self_destruct();
+            }
         }
     }
 
+#if USE_OPENSSL
     for (AnyP::PortCfgPointer s = HttpPortList; s != NULL; s = s->next) {
         if (!s->flags.tunnelSslBumping)
             continue;
@@ -969,6 +973,36 @@ parse_obsolete(const char *name)
         parse_onoff(&temp);
         Config.onoff.cache_miss_revalidate = !temp;
     }
+
+    if (!strncmp(name, "sslproxy_", 9)) {
+        // the replacement directive tls_outgoing_options uses options instead of whole-line input
+        SBuf tmp;
+        if (!strcmp(name, "sslproxy_cafile"))
+            tmp.append("cafile=");
+        else if (!strcmp(name, "sslproxy_capath"))
+            tmp.append("capath=");
+        else if (!strcmp(name, "sslproxy_cipher"))
+            tmp.append("cipher=");
+        else if (!strcmp(name, "sslproxy_client_certificate"))
+            tmp.append("cert=");
+        else if (!strcmp(name, "sslproxy_client_key"))
+            tmp.append("key=");
+        else if (!strcmp(name, "sslproxy_flags"))
+            tmp.append("flags=");
+        else if (!strcmp(name, "sslproxy_options"))
+            tmp.append("options=");
+        else if (!strcmp(name, "sslproxy_version"))
+            tmp.append("version=");
+        else {
+            debugs(3, DBG_CRITICAL, "ERROR: unknown directive: " << name);
+            self_destruct();
+        }
+
+        // add the value as unquoted-string because the old values did not support whitespace
+        const char *token = ConfigParser::NextQuotedOrToEol();
+        tmp.append(token, strlen(token));
+        Security::ProxyOutgoingConfig.parse(tmp.c_str());
+    }
 }
 
 /* Parse a time specification from the config file.  Store the
@@ -2152,45 +2186,19 @@ parse_peer(CachePeer ** head)
                 p->name = xstrdup(token + 5);
         } else if (!strncmp(token, "forceddomain=", 13)) {
             safe_free(p->domain);
-
             if (token[13])
                 p->domain = xstrdup(token + 13);
 
-#if USE_OPENSSL
-
-        } else if (strcmp(token, "ssl") == 0) {
-            p->use_ssl = 1;
-        } else if (strncmp(token, "sslcert=", 8) == 0) {
-            safe_free(p->sslcert);
-            p->sslcert = xstrdup(token + 8);
-        } else if (strncmp(token, "sslkey=", 7) == 0) {
-            safe_free(p->sslkey);
-            p->sslkey = xstrdup(token + 7);
-        } else if (strncmp(token, "sslversion=", 11) == 0) {
-            p->sslversion = xatoi(token + 11);
-        } else if (strncmp(token, "ssloptions=", 11) == 0) {
-            safe_free(p->ssloptions);
-            p->ssloptions = xstrdup(token + 11);
-        } else if (strncmp(token, "sslcipher=", 10) == 0) {
-            safe_free(p->sslcipher);
-            p->sslcipher = xstrdup(token + 10);
-        } else if (strncmp(token, "sslcafile=", 10) == 0) {
-            safe_free(p->sslcafile);
-            p->sslcafile = xstrdup(token + 10);
-        } else if (strncmp(token, "sslcapath=", 10) == 0) {
-            safe_free(p->sslcapath);
-            p->sslcapath = xstrdup(token + 10);
-        } else if (strncmp(token, "sslcrlfile=", 11) == 0) {
-            safe_free(p->sslcrlfile);
-            p->sslcrlfile = xstrdup(token + 11);
-        } else if (strncmp(token, "sslflags=", 9) == 0) {
-            safe_free(p->sslflags);
-            p->sslflags = xstrdup(token + 9);
-        } else if (strncmp(token, "ssldomain=", 10) == 0) {
-            safe_free(p->ssldomain);
-            p->ssldomain = xstrdup(token + 10);
+        } else if (strncmp(token, "ssl", 3) == 0) {
+#if !USE_OPENSSL
+            debugs(0, DBG_CRITICAL, "WARNING: cache_peer option '" << token << "' requires --with-openssl");
+#else
+            p->secure.encryptTransport = true;
+            p->secure.parse(token+3);
 #endif
-
+        } else if (strncmp(token, "tls-", 4) == 0) {
+            p->secure.encryptTransport = true;
+            p->secure.parse(token+4);
         } else if (strcmp(token, "front-end-https") == 0) {
             p->front_end_https = 1;
         } else if (strcmp(token, "front-end-https=on") == 0) {
@@ -2581,9 +2589,6 @@ dump_refreshpattern(StoreEntry * entry, const char *name, RefreshPattern * head)
         if (head->flags.ignore_no_store)
             storeAppendPrintf(entry, " ignore-no-store");
 
-        if (head->flags.ignore_must_revalidate)
-            storeAppendPrintf(entry, " ignore-must-revalidate");
-
         if (head->flags.ignore_private)
             storeAppendPrintf(entry, " ignore-private");
 #endif
@@ -2613,7 +2618,6 @@ parse_refreshpattern(RefreshPattern ** head)
     int reload_into_ims = 0;
     int ignore_reload = 0;
     int ignore_no_store = 0;
-    int ignore_must_revalidate = 0;
     int ignore_private = 0;
 #endif
 
@@ -2683,6 +2687,7 @@ parse_refreshpattern(RefreshPattern ** head)
             store_stale = 1;
         } else if (!strncmp(token, "max-stale=", 10)) {
             max_stale = xatoi(token + 10);
+
 #if USE_HTTP_VIOLATIONS
 
         } else if (!strcmp(token, "override-expire"))
@@ -2691,12 +2696,8 @@ parse_refreshpattern(RefreshPattern ** head)
             override_lastmod = 1;
         else if (!strcmp(token, "ignore-no-store"))
             ignore_no_store = 1;
-        else if (!strcmp(token, "ignore-must-revalidate"))
-            ignore_must_revalidate = 1;
         else if (!strcmp(token, "ignore-private"))
             ignore_private = 1;
-        else if (!strcmp(token, "ignore-auth"))
-            debugs(22, DBG_PARSE_NOTE(2), "UPGRADE: refresh_pattern option 'ignore-auth' is obsolete. Remove it.");
         else if (!strcmp(token, "reload-into-ims")) {
             reload_into_ims = 1;
             refresh_nocache_hack = 1;
@@ -2707,8 +2708,11 @@ parse_refreshpattern(RefreshPattern ** head)
             /* tell client_side.c that this is used */
 #endif
 
-        } else if (!strcmp(token, "ignore-no-cache")) {
-            debugs(22, DBG_PARSE_NOTE(2), "UPGRADE: refresh_pattern option 'ignore-no-cache' is obsolete. Remove it.");
+        } else if (!strcmp(token, "ignore-no-cache") ||
+                   !strcmp(token, "ignore-must-revalidate") ||
+                   !strcmp(token, "ignore-auth")
+                  ) {
+            debugs(22, DBG_PARSE_NOTE(2), "UPGRADE: refresh_pattern option '" << token << "' is obsolete. Remove it.");
         } else
             debugs(22, DBG_CRITICAL, "refreshAddToList: Unknown option '" << pattern << "': " << token);
     }
@@ -2759,9 +2763,6 @@ parse_refreshpattern(RefreshPattern ** head)
     if (ignore_no_store)
         t->flags.ignore_no_store = true;
 
-    if (ignore_must_revalidate)
-        t->flags.ignore_must_revalidate = true;
-
     if (ignore_private)
         t->flags.ignore_private = true;
 #endif
@@ -3565,45 +3566,42 @@ parse_port_option(AnyP::PortCfgPointer &s, char *token)
         }
 #if USE_OPENSSL
     } else if (strcmp(token, "sslBump") == 0) {
-        debugs(3, DBG_CRITICAL, "WARNING: '" << token << "' is deprecated " <<
+        debugs(3, DBG_PARSE_NOTE(1), "WARNING: '" << token << "' is deprecated " <<
                "in " << cfg_directive << ". Use 'ssl-bump' instead.");
         s->flags.tunnelSslBumping = true;
     } else if (strcmp(token, "ssl-bump") == 0) {
         s->flags.tunnelSslBumping = true;
     } else if (strncmp(token, "cert=", 5) == 0) {
-        safe_free(s->cert);
-        s->cert = xstrdup(token + 5);
+        s->secure.parse(token);
     } else if (strncmp(token, "key=", 4) == 0) {
-        safe_free(s->key);
-        s->key = xstrdup(token + 4);
+        s->secure.parse(token);
     } else if (strncmp(token, "version=", 8) == 0) {
-        s->version = xatoi(token + 8);
-        if (s->version < 1 || s->version > 4)
-            self_destruct();
+        debugs(3, DBG_PARSE_NOTE(1), "UPGRADE WARNING: '" << token << "' is deprecated " <<
+               "in " << cfg_directive << ". Use 'options=' instead.");
+        s->secure.parse(token);
     } else if (strncmp(token, "options=", 8) == 0) {
-        safe_free(s->options);
-        s->options = xstrdup(token + 8);
+        s->secure.parse(token);
     } else if (strncmp(token, "cipher=", 7) == 0) {
-        safe_free(s->cipher);
-        s->cipher = xstrdup(token + 7);
+        s->secure.parse(token);
     } else if (strncmp(token, "clientca=", 9) == 0) {
         safe_free(s->clientca);
         s->clientca = xstrdup(token + 9);
     } else if (strncmp(token, "cafile=", 7) == 0) {
-        safe_free(s->cafile);
-        s->cafile = xstrdup(token + 7);
+        s->secure.parse(token);
     } else if (strncmp(token, "capath=", 7) == 0) {
-        safe_free(s->capath);
-        s->capath = xstrdup(token + 7);
+        s->secure.parse(token);
     } else if (strncmp(token, "crlfile=", 8) == 0) {
-        safe_free(s->crlfile);
-        s->crlfile = xstrdup(token + 8);
+        s->secure.parse(token);
     } else if (strncmp(token, "dhparams=", 9) == 0) {
+        debugs(3, DBG_PARSE_NOTE(DBG_IMPORTANT), "WARNING: '" << token << "' is deprecated " <<
+               "in " << cfg_directive << ". Use 'tls-dh=' instead.");
         safe_free(s->dhfile);
         s->dhfile = xstrdup(token + 9);
+    } else if (strncmp(token, "tls-dh=", 7) == 0) {
+        safe_free(s->tls_dh);
+        s->tls_dh = xstrdup(token + 7);
     } else if (strncmp(token, "sslflags=", 9) == 0) {
-        safe_free(s->sslflags);
-        s->sslflags = xstrdup(token + 9);
+        s->secure.parse(token+3);
     } else if (strncmp(token, "sslcontext=", 11) == 0) {
         safe_free(s->sslContextSessionId);
         s->sslContextSessionId = xstrdup(token + 11);
@@ -3616,6 +3614,8 @@ parse_port_option(AnyP::PortCfgPointer &s, char *token)
     } else if (strncmp(token, "dynamic_cert_mem_cache_size=", 28) == 0) {
         parseBytesOptionValue(&s->dynamicCertMemCacheSize, B_BYTES_STR, token + 28);
 #endif
+    } else if (strncmp(token, "tls-", 4) == 0) {
+        s->secure.parse(token+4);
     } else if (strcmp(token, "ftp-track-dirs") == 0) {
         s->ftp_track_dirs = true;
     } else {
@@ -3669,6 +3669,7 @@ parsePortCfg(AnyP::PortCfgPointer *head, const char *optionName)
     }
 
     if (s->transport.protocol == AnyP::PROTO_HTTPS) {
+        s->secure.encryptTransport = true;
 #if USE_OPENSSL
         /* ssl-bump on https_port configuration requires either tproxy or intercept, and vice versa */
         const bool hijacked = s->flags.isIntercepted();
@@ -3796,36 +3797,16 @@ dump_generic_port(StoreEntry * e, const char *n, const AnyP::PortCfgPointer &s)
 #if USE_OPENSSL
     if (s->flags.tunnelSslBumping)
         storeAppendPrintf(e, " ssl-bump");
+#endif
 
-    if (s->cert)
-        storeAppendPrintf(e, " cert=%s", s->cert);
-
-    if (s->key)
-        storeAppendPrintf(e, " key=%s", s->key);
-
-    if (s->version)
-        storeAppendPrintf(e, " version=%d", s->version);
-
-    if (s->options)
-        storeAppendPrintf(e, " options=%s", s->options);
-
-    if (s->cipher)
-        storeAppendPrintf(e, " cipher=%s", s->cipher);
-
-    if (s->cafile)
-        storeAppendPrintf(e, " cafile=%s", s->cafile);
-
-    if (s->capath)
-        storeAppendPrintf(e, " capath=%s", s->capath);
-
-    if (s->crlfile)
-        storeAppendPrintf(e, " crlfile=%s", s->crlfile);
+    s->secure.dumpCfg(e, "tls-");
 
+#if USE_OPENSSL
     if (s->dhfile)
         storeAppendPrintf(e, " dhparams=%s", s->dhfile);
 
-    if (s->sslflags)
-        storeAppendPrintf(e, " sslflags=%s", s->sslflags);
+    if (s->tls_dh)
+        storeAppendPrintf(e, " tls-dh=%s", s->tls_dh);
 
     if (s->sslContextSessionId)
         storeAppendPrintf(e, " sslcontext=%s", s->sslContextSessionId);
@@ -157,45 +157,43 @@ carpSelectParent(HttpRequest * request)
         return NULL;
 
     /* calculate hash key */
-    debugs(39, 2, "carpSelectParent: Calculating hash for " << urlCanonical(request));
+    debugs(39, 2, "carpSelectParent: Calculating hash for " << request->effectiveRequestUri());
 
     /* select CachePeer */
     for (k = 0; k < n_carp_peers; ++k) {
         SBuf key;
         tp = carp_peers[k];
         if (tp->options.carp_key.set) {
-            //this code follows urlCanonical's pattern.
-            //   corner cases should use the canonical URL
+            // this code follows URI syntax pattern.
+            // corner cases should use the full effective request URI
             if (tp->options.carp_key.scheme) {
                 key.append(request->url.getScheme().c_str());
                 if (key.length()) //if the scheme is not empty
                     key.append("://");
             }
             if (tp->options.carp_key.host) {
-                key.append(request->GetHost());
+                key.append(request->url.host());
             }
             if (tp->options.carp_key.port) {
-                key.appendf(":%d", request->port);
+                key.appendf(":%u", request->url.port());
             }
             if (tp->options.carp_key.path) {
-                String::size_type pos;
-                if ((pos=request->urlpath.find('?'))!=String::npos)
-                    key.append(SBuf(request->urlpath.substr(0,pos)));
-                else
-                    key.append(SBuf(request->urlpath));
+                // XXX: fix when path and query are separate
+                key.append(request->url.path().substr(0,request->url.path().find('?'))); // 0..N
             }
             if (tp->options.carp_key.params) {
-                String::size_type pos;
-                if ((pos=request->urlpath.find('?'))!=String::npos)
-                    key.append(SBuf(request->urlpath.substr(pos,request->urlpath.size())));
+                // XXX: fix when path and query are separate
+                SBuf::size_type pos;
+                if ((pos=request->url.path().find('?')) != SBuf::npos)
+                    key.append(request->url.path().substr(pos)); // N..npos
             }
         }
         // if the url-based key is empty, e.g. because the user is
         // asking to balance on the path but the request doesn't supply any,
-        // then fall back to canonical URL
+        // then fall back to the effective request URI
 
         if (key.isEmpty())
-            key=SBuf(urlCanonical(request));
+            key=request->effectiveRequestUri();
 
         for (const char *c = key.rawContent(), *e=key.rawContent()+key.length(); c < e; ++c)
             user_hash += ROTATE_LEFT(user_hash, 19) + *c;
@@ -16,13 +16,14 @@
 #include "Store.h"
 
 #include <climits>
+
 #if USE_CBDATA_DEBUG
 #include <algorithm>
 #include <vector>
 #endif
 
 #if WITH_VALGRIND
-#define HASHED_CBDATA 1
+#include <map>
 #endif
 
 static int cbdataCount = 0;
@@ -58,7 +59,7 @@ class CBDataCall
  */
 class cbdata
 {
-#if !HASHED_CBDATA
+#if !WITH_VALGRIND
 public:
     void *operator new(size_t, void *where) {return where;}
     /**
@@ -73,16 +74,23 @@ class cbdata
     /** \todo examine making cbdata templated on this - so we get type
      * safe access to data - RBC 20030902 */
 public:
-#if HASHED_CBDATA
-    hash_link hash; // Must be first
-#endif
-
 #if USE_CBDATA_DEBUG
 
     void dump(StoreEntry *)const;
 #endif
-
+    cbdata() :
+        valid(0),
+        locks(0),
+        type(CBDATA_UNKNOWN),
+#if USE_CBDATA_DEBUG
+        file(NULL),
+        line(0),
+#endif
+        cookie(0),
+        data(NULL)
+    {}
     ~cbdata();
+
     int valid;
     int32_t locks;
     cbdata_type type;
@@ -106,18 +114,17 @@ class cbdata
     void check(int) const {assert(cookie == ((long)this ^ Cookie));}
     static const long Cookie;
 
-#if !HASHED_CBDATA
+#if !WITH_VALGRIND
     size_t dataSize() const { return sizeof(data);}
     static long MakeOffset();
     static const long Offset;
+#endif
     /* MUST be the last per-instance member */
     void *data;
-#endif
-
 };
 
 const long cbdata::Cookie((long)0xDEADBEEF);
-#if !HASHED_CBDATA
+#if !WITH_VALGRIND
 const long cbdata::Offset(MakeOffset());
 
 long
@@ -136,26 +143,13 @@ static OBJH cbdataDumpHistory;
 
 struct CBDataIndex {
     MemAllocator *pool;
-    FREE *free_func;
 }
 *cbdata_index = NULL;
 
 int cbdata_types = 0;
 
-#if HASHED_CBDATA
-static hash_table *cbdata_htable = NULL;
-
-static int
-cbdata_cmp(const void *p1, const void *p2)
-{
-    return (char *) p1 - (char *) p2;
-}
-
-static unsigned int
-cbdata_hash(const void *p, unsigned int mod)
-{
-    return ((unsigned long) p >> 8) % mod;
-}
+#if WITH_VALGRIND
+static std::map<const void *, cbdata *> cbdata_htable;
 #endif
 
 cbdata::~cbdata()
@@ -168,21 +162,10 @@ cbdata::~cbdata()
     }
 
 #endif
-
-    FREE *free_func = cbdata_index[type].free_func;
-
-#if HASHED_CBDATA
-    void *p = hash.key;
-#else
-    void *p = &data;
-#endif
-
-    if (free_func)
-        free_func(p);
 }
 
 static void
-cbdataInternalInitType(cbdata_type type, const char *name, int size, FREE * free_func)
+cbdataInternalInitType(cbdata_type type, const char *name, int size)
 {
     char *label;
     assert (type == cbdata_types + 1);
@@ -195,30 +178,23 @@ cbdataInternalInitType(cbdata_type type, const char *name, int size, FREE * free
 
     snprintf(label, strlen(name) + 20, "cbdata %s (%d)", name, (int) type);
 
-#if !HASHED_CBDATA
+#if !WITH_VALGRIND
     assert((size_t)cbdata::Offset == (sizeof(cbdata) - ((cbdata *)NULL)->dataSize()));
     size += cbdata::Offset;
 #endif
 
     cbdata_index[type].pool = memPoolCreate(label, size);
-
-    cbdata_index[type].free_func = free_func;
-
-#if HASHED_CBDATA
-    if (!cbdata_htable)
-        cbdata_htable = hash_create(cbdata_cmp, 1 << 12, cbdata_hash);
-#endif
 }
 
 cbdata_type
-cbdataInternalAddType(cbdata_type type, const char *name, int size, FREE * free_func)
+cbdataInternalAddType(cbdata_type type, const char *name, int size)
 {
     if (type)
         return type;
 
     type = (cbdata_type)(cbdata_types + 1);
 
-    cbdataInternalInitType(type, name, size, free_func);
+    cbdataInternalInitType(type, name, size);
 
     return type;
 }
@@ -246,11 +222,11 @@ cbdataInternalAlloc(cbdata_type type, const char *file, int line)
     /* placement new: the pool alloc gives us cbdata + user type memory space
      * and we init it with cbdata at the start of it
      */
-#if HASHED_CBDATA
+#if WITH_VALGRIND
     c = new cbdata;
     p = cbdata_index[type].pool->alloc();
-    c->hash.key = p;
-    hash_join(cbdata_htable, &c->hash);
+    c->data = p;
+    cbdata_htable.emplace(p,c);
 #else
     c = new (cbdata_index[type].pool->alloc()) cbdata;
     p = (void *)&c->data;
@@ -287,6 +263,17 @@ cbdataRealFree(cbdata *c, const char *file, const int line)
     dlinkDelete(&c->link, &cbdataEntries);
 #endif
 
+#if WITH_VALGRIND
+    cbdata_htable.erase(c->data);
+#if USE_CBDATA_DEBUG
+    debugs(45, 3, "Call delete " << p << " " << file << ":" << line);
+#endif
+    delete c;
+#else
+#if USE_CBDATA_DEBUG
+    debugs(45, 3, "Call cbdata::~cbdata() " << p << " " << file << ":" << line);
+#endif
+
     /* This is ugly. But: operator delete doesn't get
      * the type parameter, so we can't use that
      * to free the memory.
@@ -298,27 +285,17 @@ cbdataRealFree(cbdata *c, const char *file, const int line)
      * and it would Just Work. RBC 20030902
      */
     cbdata_type theType = c->type;
-#if HASHED_CBDATA
-    hash_remove_link(cbdata_htable, &c->hash);
-#if USE_CBDATA_DEBUG
-    debugs(45, 3, "Call delete " << p << " " << file << ":" << line);
-#endif
-    delete c;
-#else
-#if USE_CBDATA_DEBUG
-    debugs(45, 3, "Call cbdata::~cbdata() " << p << " " << file << ":" << line);
-#endif
     c->cbdata::~cbdata();
-#endif
     cbdata_index[theType].pool->freeOne(p);
+#endif
 }
 
 void *
 cbdataInternalFree(void *p, const char *file, int line)
 {
     cbdata *c;
-#if HASHED_CBDATA
-    c = (cbdata *) hash_lookup(cbdata_htable, p);
+#if WITH_VALGRIND
+    c = cbdata_htable.at(p);
 #else
     c = (cbdata *) (((char *) p) - cbdata::Offset);
 #endif
@@ -357,8 +334,8 @@ cbdataInternalLock(const void *p)
     if (p == NULL)
         return;
 
-#if HASHED_CBDATA
-    c = (cbdata *) hash_lookup(cbdata_htable, p);
+#if WITH_VALGRIND
+    c = cbdata_htable.at(p);
 #else
     c = (cbdata *) (((char *) p) - cbdata::Offset);
 #endif
@@ -389,8 +366,8 @@ cbdataInternalUnlock(const void *p)
     if (p == NULL)
         return;
 
-#if HASHED_CBDATA
-    c = (cbdata *) hash_lookup(cbdata_htable, p);
+#if WITH_VALGRIND
+    c = cbdata_htable.at(p);
 #else
     c = (cbdata *) (((char *) p) - cbdata::Offset);
 #endif
@@ -437,8 +414,8 @@ cbdataReferenceValid(const void *p)
 
     debugs(45, 9, p);
 
-#if HASHED_CBDATA
-    c = (cbdata *) hash_lookup(cbdata_htable, p);
+#if WITH_VALGRIND
+    c = cbdata_htable.at(p);
 #else
     c = (cbdata *) (((char *) p) - cbdata::Offset);
 #endif
@@ -481,8 +458,8 @@ cbdataInternalReferenceDoneValid(void **pp, void **tp)
 void
 cbdata::dump(StoreEntry *sentry) const
 {
-#if HASHED_CBDATA
-    void *p = (void *)hash.key;
+#if WITH_VALGRIND
+    void *p = data;
 #else
     void *p = (void *)&data;
 #endif
@@ -518,7 +495,7 @@ cbdataDump(StoreEntry * sentry)
         MemAllocator *pool = cbdata_index[i].pool;
 
         if (pool) {
-#if HASHED_CBDATA
+#if WITH_VALGRIND
             int obj_size = pool->objectSize();
 #else
             int obj_size = pool->objectSize() - cbdata::Offset;
@@ -272,7 +272,7 @@ int cbdataReferenceValid(const void *p);
  *
  * \note For internal CBDATA use only.
  */
-cbdata_type cbdataInternalAddType(cbdata_type type, const char *label, int size, FREE * free_func);
+cbdata_type cbdataInternalAddType(cbdata_type type, const char *label, int size);
 
 /**
  * This needs to be defined FIRST in the class definition.
@@ -282,7 +282,7 @@ cbdata_type cbdataInternalAddType(cbdata_type type, const char *label, int size,
     public: \
         void *operator new(size_t size) { \
           assert(size == sizeof(type)); \
-          if (!CBDATA_##type) CBDATA_##type = cbdataInternalAddType(CBDATA_##type, #type, sizeof(type), NULL); \
+          if (!CBDATA_##type) CBDATA_##type = cbdataInternalAddType(CBDATA_##type, #type, sizeof(type)); \
           return (type *)cbdataInternalAlloc(CBDATA_##type,__FILE__,__LINE__); \
         } \
         void operator delete (void *address) { \
@@ -48,6 +48,7 @@ icap_access_type	icap_class acl
 icap_class_type		icap_service
 icap_service_type
 icap_service_failure_limit
+icmp
 ecap_service_type
 int
 kb_int64_t
@@ -67,6 +68,7 @@ QosConfig
 TokenOrQuotedString
 refreshpattern
 removalpolicy
+securePeerOptions
 size_t
 IpAddress_list
 string
@@ -155,6 +155,54 @@ DOC_START
 	Replace with dstdomain ACLs and cache_peer_access.
 DOC_END
 
+NAME: sslproxy_cafile
+TYPE: obsolete
+DOC_START
+	Remove this line. Use tls_outgoing_options cafile= instead.
+DOC_END
+
+NAME: sslproxy_capath
+TYPE: obsolete
+DOC_START
+	Remove this line. Use tls_outgoing_options capath= instead.
+DOC_END
+
+NAME: sslproxy_cipher
+TYPE: obsolete
+DOC_START
+	Remove this line. Use tls_outgoing_options cipher= instead.
+DOC_END
+
+NAME: sslproxy_client_certificate
+TYPE: obsolete
+DOC_START
+	Remove this line. Use tls_outgoing_options cert= instead.
+DOC_END
+
+NAME: sslproxy_client_key
+TYPE: obsolete
+DOC_START
+	Remove this line. Use tls_outgoing_options key= instead.
+DOC_END
+
+NAME: sslproxy_flags
+TYPE: obsolete
+DOC_START
+	Remove this line. Use tls_outgoing_options flags= instead.
+DOC_END
+
+NAME: sslproxy_options
+TYPE: obsolete
+DOC_START
+	Remove this line. Use tls_outgoing_options options= instead.
+DOC_END
+
+NAME: sslproxy_version
+TYPE: obsolete
+DOC_START
+	Remove this line. Use tls_outgoing_options options= instead.
+DOC_END
+
 # Options removed in 3.5
 NAME: hierarchy_stoplist
 TYPE: obsolete
@@ -328,6 +376,49 @@ DOC_START
 	Replace this line with 'cache_peer' configuration.
 DOC_END
 
+COMMENT_START
+ OPTIONS FOR SMP
+ -----------------------------------------------------------------------------
+COMMENT_END
+
+NAME: workers
+TYPE: int
+LOC: Config.workers
+DEFAULT: 1
+DEFAULT_DOC: SMP support disabled.
+DOC_START
+	Number of main Squid processes or "workers" to fork and maintain.
+	0: "no daemon" mode, like running "squid -N ..."
+	1: "no SMP" mode, start one main Squid process daemon (default)
+	N: start N main Squid process daemons (i.e., SMP mode)
+
+	In SMP mode, each worker does nearly all what a single Squid daemon
+	does (e.g., listen on http_port and forward HTTP requests).
+DOC_END
+
+NAME: cpu_affinity_map
+TYPE: CpuAffinityMap
+LOC: Config.cpuAffinityMap
+DEFAULT: none
+DEFAULT_DOC: Let operating system decide.
+DOC_START
+	Usage: cpu_affinity_map process_numbers=P1,P2,... cores=C1,C2,...
+
+	Sets 1:1 mapping between Squid processes and CPU cores. For example,
+
+	    cpu_affinity_map process_numbers=1,2,3,4 cores=1,3,5,7
+
+	affects processes 1 through 4 only and places them on the first
+	four even cores, starting with core #1.
+
+	CPU cores are numbered starting from 1. Requires support for
+	sched_getaffinity(2) and sched_setaffinity(2) system calls.
+
+	Multiple cpu_affinity_map options are merged.
+
+	See also: workers
+DOC_END
+
 COMMENT_START
  OPTIONS FOR AUTHENTICATION
  -----------------------------------------------------------------------------
@@ -673,6 +764,12 @@ DOC_START
 	FORMAT specifications
 
 	  %LOGIN	Authenticated user login name
+	  %un		A user name. Expands to the first available name
+	  		from the following list of information sources:
+			- authenticated user name, like %ul or %LOGIN
+			- user name sent by an external ACL, like %EXT_USER
+			- SSL client name, like %us in logformat
+			- ident user name, like %ui in logformat
 	  %EXT_USER	Username from previous external acl
 	  %EXT_LOG	Log details from previous external acl
 	  %EXT_TAG	Tag from previous external acl
@@ -1037,11 +1134,11 @@ DOC_START
 
 	acl aclname user_cert attribute values...
 	  # match against attributes in a user SSL certificate
-	  # attribute is one of DN/C/O/CN/L/ST [fast]
+	  # attribute is one of DN/C/O/CN/L/ST or a numerical OID [fast]
 
 	acl aclname ca_cert attribute values...
 	  # match against attributes a users issuing CA SSL certificate
-	  # attribute is one of DN/C/O/CN/L/ST [fast]
+	  # attribute is one of DN/C/O/CN/L/ST or a numerical OID  [fast]
 
 	acl aclname ext_user username ...
 	acl aclname ext_user_regex [-i] pattern ...
@@ -1120,6 +1217,18 @@ IF USE_OPENSSL
 	  #   SslBump1: After getting TCP-level and HTTP CONNECT info.
 	  #   SslBump2: After getting SSL Client Hello info.
 	  #   SslBump3: After getting SSL Server Hello info.
+
+	acl aclname ssl::server_name .foo.com ...
+	  # matches server name obtained from various sources [fast]
+	  #
+	  # The server name is obtained during Ssl-Bump steps from such sources
+	  # as CONNECT request URI, client SNI, and SSL server certificate CN.
+	  # During each Ssl-Bump step, Squid may improve its understanding of a
+	  # "true server name". Unlike dstdomain, this ACL does not perform
+	  # DNS lookups.
+
+	acl aclname ssl::server_name_regex [-i] \.foo\.com ...
+	  # regex matches server name obtained from various sources [fast]
 ENDIF
 	acl aclname any-of acl1 acl2 ...
 	  # match any one of the acls [fast or slow]
@@ -1637,14 +1746,15 @@ DEFAULT: none
 DEFAULT_DOC: Respond with an error message to unidentifiable traffic
 DOC_START
 	Determines Squid behavior when encountering strange requests at the
-	beginning of an accepted TCP connection. This is especially useful in
-	interception environments where Squid is likely to see connections for
-	unsupported protocols that Squid should either terminate or tunnel at
-	TCP level.
+	beginning of an accepted TCP connection or the beginning of a bumped
+	CONNECT tunnel. Controlling Squid reaction to unexpected traffic is
+	especially useful in interception environments where Squid is likely
+	to see connections for unsupported protocols that Squid should either
+	terminate or tunnel at TCP level.
  
 		on_unsupported_protocol <action> [!]acl ...
  
-	The first matching action wins.
+	The first matching action wins. Only fast ACLs are supported.
 
 	Supported actions are:
  
@@ -1655,9 +1765,18 @@ DOC_START
 		for the Squid port that received the request (e.g., HTTP
 		for connections intercepted at the http_port). This is the
 		default.
- 
-	Currently, this directive is ignored for non-intercepted connections
-	because Squid cannot know what their intended destination is.
+
+	Squid expects the following traffic patterns:
+
+	  http_port: a plain HTTP request
+	  https_port: SSL/TLS handshake followed by an [encrypted] HTTP request
+	  ftp_port: a plain FTP command (no on_unsupported_protocol support yet!)
+	  CONNECT tunnel on http_port: same as https_port
+	  CONNECT tunnel on https_port: same as https_port
+
+ 	Currently, this directive has effect on intercepted connections and
+	bumped tunnels only. Other cases are not supported because Squid
+	cannot know the intended destination of other traffic.
 
 	For example:
 	  # define what Squid errors indicate receiving non-HTTP traffic:
@@ -1801,13 +1920,6 @@ DOC_START
 			assumed to be a combined certificate and
 			key file.
 
-	   version=	The version of SSL/TLS supported
-			    1	automatic (default)
-			    3	SSLv3 only
-			    4	TLSv1.0 only
-			    5	TLSv1.1 only
-			    6	TLSv1.2 only
-
 	   cipher=	Colon separated list of supported ciphers.
 			NOTE: some ciphers such as EDH ciphers depend on
 			      additional settings. If those settings are
@@ -1816,19 +1928,37 @@ DOC_START
 
 	   options=	Various SSL implementation options. The most important
 			being:
+
 			    NO_SSLv3    Disallow the use of SSLv3
+
 			    NO_TLSv1    Disallow the use of TLSv1.0
+
 			    NO_TLSv1_1  Disallow the use of TLSv1.1
+
 			    NO_TLSv1_2  Disallow the use of TLSv1.2
-			    SINGLE_DH_USE Always create a new key when using
+
+			    SINGLE_DH_USE
+				      Always create a new key when using
 				      temporary/ephemeral DH key exchanges
-			    NO_TICKET Disables TLS tickets extension
+
+			    SINGLE_ECDH_USE
+				      Enable ephemeral ECDH key exchange.
+				      The adopted curve should be specified
+				      using the tls-dh option.
+
+			    NO_TICKET
+				      Disable use of RFC5077 session tickets.
+				      Some servers may have problems
+				      understanding the TLS extension due
+				      to ambiguous specification in RFC4507.
+
 			    ALL       Enable various bug workarounds
 				      suggested as "harmless" by OpenSSL
 				      Be warned that this reduces SSL/TLS
 				      strength to some attacks.
-			See OpenSSL SSL_CTX_set_options documentation for a
-			complete list of options.
+
+			See the OpenSSL SSL_CTX_set_options documentation for a
+			more complete list.
 
 	   clientca=	File containing the list of CAs to use when
 			requesting a client certificate.
@@ -1844,11 +1974,15 @@ DOC_START
 			the client certificate, in addition to CRLs stored in
 			the capath. Implies VERIFY_CRL flag below.
 
-	   dhparams=	File containing DH parameters for temporary/ephemeral
-			DH key exchanges. See OpenSSL documentation for details
-			on how to create this file.
-			WARNING: EDH ciphers will be silently disabled if this
-				 option is not set.
+	   tls-dh=[curve:]file
+			File containing DH parameters for temporary/ephemeral DH key
+			exchanges, optionally prefixed by a curve for ephemeral ECDH
+			key exchanges.
+			See OpenSSL documentation for details on how to create the
+			DH parameter file. Supported curves for ECDH can be listed
+			using the "openssl ecparam -list_curves" command.
+			WARNING: EDH and EECDH ciphers will be silently disabled if
+				 this option is not set.
 
 	   sslflags=	Various flags modifying the use of SSL:
 			    DELAYED_AUTH
@@ -1974,21 +2108,41 @@ DOC_START
 			assumed to be a combined certificate and
 			key file.
 
-	   version=	The version of SSL/TLS supported
-			    1	automatic (default)
-			    3	SSLv3 only
-			    4	TLSv1 only
-
 	   cipher=	Colon separated list of supported ciphers.
 
 	   options=	Various SSL engine options. The most important
 			being:
-			    NO_SSLv3  Disallow the use of SSLv3
-			    NO_TLSv1  Disallow the use of TLSv1
-			    SINGLE_DH_USE Always create a new key when using
+
+			    NO_SSLv3    Disallow the use of SSLv3
+
+			    NO_TLSv1    Disallow the use of TLSv1.0
+
+			    NO_TLSv1_1  Disallow the use of TLSv1.1
+
+			    NO_TLSv1_2  Disallow the use of TLSv1.2
+
+			    SINGLE_DH_USE
+				      Always create a new key when using
 				      temporary/ephemeral DH key exchanges
-			See src/ssl_support.c or OpenSSL SSL_CTX_set_options
-			documentation for a complete list of options.
+
+			    SINGLE_ECDH_USE
+				      Enable ephemeral ECDH key exchange.
+				      The adopted curve should be specified
+				      using the tls-dh option.
+
+			    SSL_OP_NO_TICKET
+				      Disable use of RFC5077 session tickets.
+				      Some servers may have problems
+				      understanding the TLS extension due
+				      to ambiguous specification in RFC4507.
+
+			    ALL       Enable various bug workarounds
+				      suggested as "harmless" by OpenSSL
+				      Be warned that this reduces SSL/TLS
+				      strength to some attacks.
+
+			See the OpenSSL SSL_CTX_set_options documentation for a
+			more complete list.
 
 	   clientca=	File containing the list of CAs to use when
 			requesting a client certificate.
@@ -2004,8 +2158,10 @@ DOC_START
 			the client certificate, in addition to CRLs stored in
 			the capath. Implies VERIFY_CRL flag below.
 
-	   dhparams=	File containing DH parameters for temporary/ephemeral
-			DH key exchanges.
+	   tls-dh=[curve:]file
+			File containing DH parameters for temporary/ephemeral DH key
+			exchanges, optionally prefixed by a curve for ephemeral ECDH
+			key exchanges.
 
 	   sslflags=	Various flags modifying the use of SSL:
 			    DELAYED_AUTH
@@ -2135,9 +2291,10 @@ DOC_START
 	RFC2475, and RFC3260.
 
 	The TOS/DSCP byte must be exactly that - a octet value  0 - 255, or
-	"default" to use whatever default your host has. Note that in
-	practice often only multiples of 4 is usable as the two rightmost bits
-	have been redefined for use by ECN (RFC 3168 section 23.1).
+	"default" to use whatever default your host has.
+	Note that only multiples of 4 are usable as the two rightmost bits have
+	been redefined for use by ECN (RFC 3168 section 23.1).
+	The squid parser will enforce this by masking away the ECN bits.
 
 	Processing proceeds in the order specified, and stops at first fully
 	matching line.
@@ -2150,7 +2307,7 @@ TYPE: acl_tos
 DEFAULT: none
 LOC: Ip::Qos::TheConfig.tosToClient
 DOC_START
-	Allows you to select a TOS/Diffserv value for packets being transmitted
+	Allows you to select a TOS/DSCP value for packets being transmitted
 	on the client-side, based on an ACL.
 
 	clientside_tos ds-field [!]aclname ...
@@ -2165,6 +2322,13 @@ DOC_START
 
 	Note: This feature is incompatible with qos_flows. Any TOS values set here
 	will be overwritten by TOS values in qos_flows.
+
+	The TOS/DSCP byte must be exactly that - a octet value  0 - 255, or
+	"default" to use whatever default your host has.
+	Note that only multiples of 4 are usable as the two rightmost bits have
+	been redefined for use by ECN (RFC 3168 section 23.1).
+	The squid parser will enforce this by masking away the ECN bits.
+
 DOC_END
 
 NAME: tcp_outgoing_mark
@@ -2236,9 +2400,10 @@ DOC_START
 	know what you're specifying. For more information, see RFC2474,
 	RFC2475, and RFC3260.
 
-	The TOS/DSCP byte must be exactly that - a octet value  0 - 255. Note that
-	in practice often only multiples of 4 is usable as the two rightmost bits
-	have been redefined for use by ECN (RFC 3168 section 23.1).
+	The TOS/DSCP byte must be exactly that - a octet value  0 - 255.
+	Note that only multiples of 4 are usable as the two rightmost bits have
+	been redefined for use by ECN (RFC 3168 section 23.1).
+	The squid parser will enforce this by masking away the ECN bits.
 
 	Mark values can be any unsigned 32-bit integer value.
 
@@ -2425,124 +2590,111 @@ DOC_START
 DOC_END
 
 COMMENT_START
- SSL OPTIONS
+ TLS OPTIONS
  -----------------------------------------------------------------------------
 COMMENT_END
 
-NAME: ssl_unclean_shutdown
-IFDEF: USE_OPENSSL
-TYPE: onoff
-DEFAULT: off
-LOC: Config.SSL.unclean_shutdown
+NAME: tls_outgoing_options
+IFDEF: USE_GNUTLS||USE_OPENSSL
+TYPE: securePeerOptions
+DEFAULT: min-version=1.0
+LOC: Security::ProxyOutgoingConfig
 DOC_START
-	Some browsers (especially MSIE) bugs out on SSL shutdown
-	messages.
-DOC_END
+	disable		Do not support https:// URLs.
+	
+	cert=/path/to/client/certificate
+			A client TLS certificate to use when connecting.
+	
+	key=/path/to/client/private_key
+			The private TLS key corresponding to the cert= above.
+			If key= is not specified cert= is assumed to reference
+			a PEM file containing both the certificate and the key.
+	
+	cipher=...	The list of valid TLS ciphers to use.
 
-NAME: ssl_engine
-IFDEF: USE_OPENSSL
-TYPE: string
-LOC: Config.SSL.ssl_engine
-DEFAULT: none
-DOC_START
-	The OpenSSL engine to use. You will need to set this if you
-	would like to use hardware SSL acceleration for example.
-DOC_END
+	min-version=1.N
+			The minimum TLS protocol version to permit.
+			To control SSLv3 use the options= parameter.
+			Supported Values: 1.0 (default), 1.1, 1.2
 
-NAME: sslproxy_client_certificate
-IFDEF: USE_OPENSSL
-DEFAULT: none
-LOC: Config.ssl_client.cert
-TYPE: string
-DOC_START
-	Client SSL Certificate to use when proxying https:// URLs
-DOC_END
+	options=... 	Specify various TLS/SSL implementation options:
 
-NAME: sslproxy_client_key
-IFDEF: USE_OPENSSL
-DEFAULT: none
-LOC: Config.ssl_client.key
-TYPE: string
-DOC_START
-	Client SSL Key to use when proxying https:// URLs
-DOC_END
+			    NO_SSLv3    Disallow the use of SSLv3
 
-NAME: sslproxy_version
-IFDEF: USE_OPENSSL
-DEFAULT: 1
-DEFAULT_DOC: automatic SSL/TLS version negotiation
-LOC: Config.ssl_client.version
-TYPE: int
-DOC_START
-	SSL version level to use when proxying https:// URLs
+			    NO_TLSv1    Disallow the use of TLSv1.0
 
-	The versions of SSL/TLS supported:
+			    NO_TLSv1_1  Disallow the use of TLSv1.1
 
-	    1	automatic (default)
-	    3	SSLv3 only
-	    4	TLSv1.0 only
-	    5	TLSv1.1 only
-	    6	TLSv1.2 only
-DOC_END
+			    NO_TLSv1_2  Disallow the use of TLSv1.2
 
-NAME: sslproxy_options
-IFDEF: USE_OPENSSL
-DEFAULT: none
-LOC: Config.ssl_client.options
-TYPE: string
-DOC_START
-	SSL implementation options to use when proxying https:// URLs
-	
-	The most important being:
+			    SINGLE_DH_USE
+				      Always create a new key when using
+				      temporary/ephemeral DH key exchanges
 
-	    NO_SSLv3    Disallow the use of SSLv3
-	    NO_TLSv1    Disallow the use of TLSv1.0
-	    NO_TLSv1_1  Disallow the use of TLSv1.1
-	    NO_TLSv1_2  Disallow the use of TLSv1.2
-	    SINGLE_DH_USE
-		      Always create a new key when using temporary/ephemeral
-		      DH key exchanges
-	    SSL_OP_NO_TICKET
-		      Disable use of RFC5077 session tickets. Some servers
-		      may have problems understanding the TLS extension due
-		      to ambiguous specification in RFC4507.
-	    ALL       Enable various bug workarounds suggested as "harmless"
-		      by OpenSSL. Be warned that this may reduce SSL/TLS
-		      strength to some attacks.
-	
-	See the OpenSSL SSL_CTX_set_options documentation for a
-	complete list of possible options.
-DOC_END
+			    SSL_OP_NO_TICKET
+				      Disable use of RFC5077 session tickets.
+				      Some servers may have problems
+				      understanding the TLS extension due
+				      to ambiguous specification in RFC4507.
 
-NAME: sslproxy_cipher
-IFDEF: USE_OPENSSL
-DEFAULT: none
-LOC: Config.ssl_client.cipher
-TYPE: string
-DOC_START
-	SSL cipher list to use when proxying https:// URLs
+			    ALL       Enable various bug workarounds
+				      suggested as "harmless" by OpenSSL
+				      Be warned that this reduces SSL/TLS
+				      strength to some attacks.
 
-	Colon separated list of supported ciphers.
+			See the OpenSSL SSL_CTX_set_options documentation for a
+			more complete list.
+	
+	cafile=... 	A file containing additional CA certificates to use
+			when verifying the peer certificate.
+	
+	capath=...	A directory containing additional CA certificates to
+			use when verifying the peer certificate.
+	
+	crlfile=... 	A certificate revocation list file to use when
+			verifying the peer certificate.
+	
+	flags=...	Specify various flags modifying the TLS implementation:
+	
+			DONT_VERIFY_PEER
+				Accept certificates even if they fail to
+				verify.
+			NO_DEFAULT_CA
+				Don't use the default CA list built in
+				to OpenSSL.
+			DONT_VERIFY_DOMAIN
+				Don't verify the peer certificate
+				matches the server name
+	
+	domain= 	The peer name as advertised in its certificate.
+			Used for verifying the correctness of the received peer
+			certificate. If not specified the peer hostname will be
+			used.
 DOC_END
 
-NAME: sslproxy_cafile
+COMMENT_START
+ SSL OPTIONS
+ -----------------------------------------------------------------------------
+COMMENT_END
+
+NAME: ssl_unclean_shutdown
 IFDEF: USE_OPENSSL
-DEFAULT: none
-LOC: Config.ssl_client.cafile
-TYPE: string
+TYPE: onoff
+DEFAULT: off
+LOC: Config.SSL.unclean_shutdown
 DOC_START
-	file containing CA certificates to use when verifying server
-	certificates while proxying https:// URLs
+	Some browsers (especially MSIE) bugs out on SSL shutdown
+	messages.
 DOC_END
 
-NAME: sslproxy_capath
+NAME: ssl_engine
 IFDEF: USE_OPENSSL
-DEFAULT: none
-LOC: Config.ssl_client.capath
 TYPE: string
+LOC: Config.SSL.ssl_engine
+DEFAULT: none
 DOC_START
-	directory containing CA certificates to use when verifying
-	server certificates while proxying https:// URLs
+	The OpenSSL engine to use. You will need to set this if you
+	would like to use hardware SSL acceleration for example.
 DOC_END
 
 NAME: sslproxy_session_ttl
@@ -2666,19 +2818,6 @@ DOC_START
 	ssl_bump bump all
 DOC_END
 
-NAME: sslproxy_flags
-IFDEF: USE_OPENSSL
-DEFAULT: none
-LOC: Config.ssl_client.flags
-TYPE: string
-DOC_START
-	Various flags modifying the use of SSL while proxying https:// URLs:
-	    DONT_VERIFY_PEER	Accept certificates that fail verification.
-				For refined control, see sslproxy_cert_error.
-	    NO_DEFAULT_CA	Don't use the default CA list built in
-				to OpenSSL.
-DOC_END
-
 NAME: sslproxy_cert_error
 IFDEF: USE_OPENSSL
 DEFAULT: none
@@ -3207,26 +3346,34 @@ DOC_START
 			reference a combined file containing both the
 			certificate and the key.
 	
-	sslversion=1|3|4|5|6
-			The SSL version to use when connecting to this peer
-				1 = automatic (default)
-				3 = SSL v3 only
-				4 = TLS v1.0 only
-				5 = TLS v1.1 only
-				6 = TLS v1.2 only
-	
 	sslcipher=...	The list of valid SSL ciphers to use when connecting
 			to this peer.
-	
+
+	tls-min-version=1.N
+			The minimum TLS protocol version to permit. To control
+			SSLv3 use the ssloptions= parameter.
+			Supported Values: 1.0 (default), 1.1, 1.2
+
 	ssloptions=... 	Specify various SSL implementation options:
 
 			    NO_SSLv3    Disallow the use of SSLv3
+
 			    NO_TLSv1    Disallow the use of TLSv1.0
+
 			    NO_TLSv1_1  Disallow the use of TLSv1.1
+
 			    NO_TLSv1_2  Disallow the use of TLSv1.2
+
 			    SINGLE_DH_USE
 				      Always create a new key when using
 				      temporary/ephemeral DH key exchanges
+
+			    SSL_OP_NO_TICKET
+				      Disable use of RFC5077 session tickets.
+				      Some servers may have problems
+				      understanding the TLS extension due
+				      to ambiguous specification in RFC4507.
+
 			    ALL       Enable various bug workarounds
 				      suggested as "harmless" by OpenSSL
 				      Be warned that this reduces SSL/TLS
@@ -3249,9 +3396,11 @@ DOC_START
 			DONT_VERIFY_PEER
 				Accept certificates even if they fail to
 				verify.
+
 			NO_DEFAULT_CA
 				Don't use the default CA list built in
 				to OpenSSL.
+
 			DONT_VERIFY_DOMAIN
 				Don't verify the peer certificate
 				matches the server name
@@ -4006,6 +4155,12 @@ DOC_START
 		ue	User name from external acl helper
 		ui	User name from ident
 		us	User name from SSL
+		un	A user name. Expands to the first available name
+			from the following list of information sources:
+			- authenticated user name, like %ul
+			- user name supplied by an external ACL, like %ue
+			- SSL client name, like %us
+			- ident user name, like %ui
 		credentials Client credentials. The exact meaning depends on
 			the authentication scheme: For Basic authentication,
 			it is the password; for Digest, the realm sent by the
@@ -4784,18 +4939,18 @@ DOC_START
 DOC_END
 
 NAME: pinger_program
-TYPE: string
-DEFAULT: @DEFAULT_PINGER@
-LOC: Config.pinger.program
 IFDEF: USE_ICMP
+TYPE: icmp
+DEFAULT: @DEFAULT_PINGER@
+LOC: IcmpCfg
 DOC_START
 	Specify the location of the executable for the pinger process.
 DOC_END
 
 NAME: pinger_enable
 TYPE: onoff
 DEFAULT: on
-LOC: Config.pinger.enable
+LOC: IcmpCfg.enable
 IFDEF: USE_ICMP
 DOC_START
 	Control whether the pinger is active at run-time.
@@ -5308,9 +5463,7 @@ DOC_START
 		 reload-into-ims
 		 ignore-reload
 		 ignore-no-store
-		 ignore-must-revalidate
 		 ignore-private
-		 ignore-auth
 		 max-stale=NN
 		 refresh-ims
 		 store-stale
@@ -5346,22 +5499,11 @@ DOC_START
 		the HTTP standard. Enabling this feature could make you
 		liable for problems which it causes.
 
-		ignore-must-revalidate ignores any ``Cache-Control: must-revalidate``
-		headers received from a server. Doing this VIOLATES
-		the HTTP standard. Enabling this feature could make you
-		liable for problems which it causes.
-
 		ignore-private ignores any ``Cache-control: private''
 		headers received from a server. Doing this VIOLATES
 		the HTTP standard. Enabling this feature could make you
 		liable for problems which it causes.
 
-		ignore-auth caches responses to requests with authorization,
-		as if the originserver had sent ``Cache-control: public''
-		in the response header. Doing this VIOLATES the HTTP standard.
-		Enabling this feature could make you liable for problems which
-		it causes.
-
 		refresh-ims causes squid to contact the origin server
 		when a client issues an If-Modified-Since request. This
 		ensures that the client will receive an updated version
@@ -8268,6 +8410,12 @@ DOC_START
 
 	uri: icap://servername:port/servicepath
 		ICAP server and service location.
+	     icaps://servername:port/servicepath
+		The "icap:" URI scheme is used for traditional ICAP server and
+		service location (default port is 1344, connections are not
+		encrypted). The "icaps:" URI scheme is for Secure ICAP
+		services that use SSL/TLS-encrypted ICAP connections (by
+		default, on port 11344).
 
 	ICAP does not allow a single service to handle both REQMOD and RESPMOD
 	transactions. Squid does not enforce that requirement. You can specify
@@ -8333,12 +8481,77 @@ DOC_START
 		Use the given number as the Max-Connections limit, regardless
 		of the Max-Connections value given by the service, if any.
 
+	==== SSL / ICAPS / TLS OPTIONS ====
+
+	These options are used for Secure ICAP (icaps://....) services only.
+
+	sslcert=/path/to/ssl/certificate
+			A client SSL certificate to use when connecting to
+			this icap server.
+
+	sslkey=/path/to/ssl/key
+			The private SSL key corresponding to sslcert above.
+			If 'sslkey' is not specified 'sslcert' is assumed to
+			reference a combined file containing both the
+			certificate and the key.
+
+	sslcipher=...	The list of valid SSL ciphers to use when connecting
+			to this icap server.
+
+	tls-min-version=1.N
+			The minimum TLS protocol version to permit. To control
+			SSLv3 use the ssloptions= parameter.
+			Supported Values: 1.0 (default), 1.1, 1.2
+
+	ssloptions=...	Specify various SSL implementation options:
+
+			    NO_SSLv3    Disallow the use of SSLv3
+			    NO_TLSv1    Disallow the use of TLSv1.0
+			    NO_TLSv1_1  Disallow the use of TLSv1.1
+			    NO_TLSv1_2  Disallow the use of TLSv1.2
+			    SINGLE_DH_USE
+				      Always create a new key when using
+				      temporary/ephemeral DH key exchanges
+			    ALL       Enable various bug workarounds
+			    suggested as "harmless" by OpenSSL
+			    Be warned that this reduces SSL/TLS
+			    strength to some attacks.
+
+			See the OpenSSL SSL_CTX_set_options documentation for a
+			more complete list.
+
+	sslcafile=...	A file containing additional CA certificates to use
+			when verifying the icap server certificate.
+
+	sslcapath=...	A directory containing additional CA certificates to
+			use when verifying the icap server certificate.
+
+	sslcrlfile=...	A certificate revocation list file to use when
+			verifying the icap server certificate.
+
+	sslflags=...	Specify various flags modifying the SSL implementation:
+
+			DONT_VERIFY_PEER
+				Accept certificates even if they fail to
+				verify.
+			NO_DEFAULT_CA
+				Don't use the default CA list built in
+				to OpenSSL.
+			DONT_VERIFY_DOMAIN
+				Don't verify the icap server certificate
+				matches the server name
+
+	ssldomain=	The icap server name as advertised in it's certificate.
+			Used for verifying the correctness of the received icap
+			server certificate. If not specified the icap server
+			hostname extracted from ICAP URI will be used.
+
 	Older icap_service format without optional named parameters is
 	deprecated but supported for backward compatibility.
 
 Example:
 icap_service svcBlocker reqmod_precache icap://icap1.mydomain.net:1344/reqmod bypass=0
-icap_service svcLogger reqmod_precache icap://icap2.mydomain.net:1344/respmod routing=on
+icap_service svcLogger reqmod_precache icaps://icap2.mydomain.net:11344/reqmod routing=on
 DOC_END
 
 NAME: icap_class
@@ -9366,44 +9579,6 @@ DOC_START
 	not all I/O types supports large values (eg on Windows).
 DOC_END
 
-NAME: workers
-TYPE: int
-LOC: Config.workers
-DEFAULT: 1
-DEFAULT_DOC: SMP support disabled.
-DOC_START
-	Number of main Squid processes or "workers" to fork and maintain.
-	0: "no daemon" mode, like running "squid -N ..."
-	1: "no SMP" mode, start one main Squid process daemon (default)
-	N: start N main Squid process daemons (i.e., SMP mode)
-
-	In SMP mode, each worker does nearly all what a single Squid daemon
-	does (e.g., listen on http_port and forward HTTP requests).
-DOC_END
-
-NAME: cpu_affinity_map
-TYPE: CpuAffinityMap
-LOC: Config.cpuAffinityMap
-DEFAULT: none
-DEFAULT_DOC: Let operating system decide.
-DOC_START
-	Usage: cpu_affinity_map process_numbers=P1,P2,... cores=C1,C2,...
-
-	Sets 1:1 mapping between Squid processes and CPU cores. For example,
-
-	    cpu_affinity_map process_numbers=1,2,3,4 cores=1,3,5,7
-
-	affects processes 1 through 4 only and places them on the first
-	four even cores, starting with core #1.
-
-	CPU cores are numbered starting from 1. Requires support for
-	sched_getaffinity(2) and sched_setaffinity(2) system calls.
-
-	Multiple cpu_affinity_map options are merged.
-
-	See also: workers
-DOC_END
-
 NAME: force_request_body_continuation
 TYPE: acl_access
 LOC: Config.accessList.forceRequestBodyContinuation
@@ -391,10 +391,11 @@ main(int argc, char *argv[])
                     entries.back().nocomment.push_back(buff);
                 }
                 break;
-
+#if 0
             case sEXIT:
                 assert(0);      /* should never get here */
                 break;
+#endif
             }
 
     }
@@ -34,6 +34,7 @@ BEGIN {
 	define["USE_DELAY_POOLS"]="--enable-delay-pools"
 	define["USE_ECAP"]="--enable-ecap"
 	define["USE_ERR_LOCALES"]="--enable-auto-locale"
+	define["USE_GNUTLS||USE_OPENSSL"]="--with-gnutls or --with-openssl"
 	define["USE_HTCP"]="--enable-htcp"
 	define["USE_HTTP_VIOLATIONS"]="--enable-http-violations"
 	define["USE_ICMP"]="--enable-icmp"
@@ -83,6 +83,7 @@
 CBDATA_CLASS_INIT(clientStreamNode);
 
 clientStreamNode::clientStreamNode(CSR * aReadfunc, CSCB * aCallback, CSD * aDetach, CSS * aStatus, ClientStreamData aData) :
+    head(NULL),
     readfunc(aReadfunc),
     callback(aCallback),
     detach(aDetach),
@@ -137,7 +137,7 @@ ClientInfo * clientdbGetInfo(const Ip::Address &addr)
 }
 #endif
 void
-clientdbUpdate(const Ip::Address &addr, LogTags ltype, AnyP::ProtocolType p, size_t size)
+clientdbUpdate(const Ip::Address &addr, const LogTags &ltype, AnyP::ProtocolType p, size_t size)
 {
     char key[MAX_IPSTRLEN];
     ClientInfo *c;
@@ -157,17 +157,17 @@ clientdbUpdate(const Ip::Address &addr, LogTags ltype, AnyP::ProtocolType p, siz
 
     if (p == AnyP::PROTO_HTTP) {
         ++ c->Http.n_requests;
-        ++ c->Http.result_hist[ltype];
+        ++ c->Http.result_hist[ltype.oldType];
         kb_incr(&c->Http.kbytes_out, size);
 
-        if (logTypeIsATcpHit(ltype))
+        if (ltype.isTcpHit())
             kb_incr(&c->Http.hit_kbytes_out, size);
     } else if (p == AnyP::PROTO_ICP) {
         ++ c->Icp.n_requests;
-        ++ c->Icp.result_hist[ltype];
+        ++ c->Icp.result_hist[ltype.oldType];
         kb_incr(&c->Icp.kbytes_out, size);
 
-        if (LOG_UDP_HIT == ltype)
+        if (LOG_UDP_HIT == ltype.oldType)
             kb_incr(&c->Icp.hit_kbytes_out, size);
     }
 
@@ -287,7 +287,7 @@ clientdbDump(StoreEntry * sentry)
         storeAppendPrintf(sentry, "    ICP  Requests %d\n",
                           c->Icp.n_requests);
 
-        for (LogTags l = LOG_TAG_NONE; l < LOG_TYPE_MAX; ++l) {
+        for (LogTags_ot l = LOG_TAG_NONE; l < LOG_TYPE_MAX; ++l) {
             if (c->Icp.result_hist[l] == 0)
                 continue;
 
@@ -296,23 +296,23 @@ clientdbDump(StoreEntry * sentry)
             if (LOG_UDP_HIT == l)
                 icp_hits += c->Icp.result_hist[l];
 
-            storeAppendPrintf(sentry, "        %-20.20s %7d %3d%%\n",LogTags_str[l], c->Icp.result_hist[l], Math::intPercent(c->Icp.result_hist[l], c->Icp.n_requests));
+            storeAppendPrintf(sentry, "        %-20.20s %7d %3d%%\n", LogTags(l).c_str(), c->Icp.result_hist[l], Math::intPercent(c->Icp.result_hist[l], c->Icp.n_requests));
         }
 
         storeAppendPrintf(sentry, "    HTTP Requests %d\n", c->Http.n_requests);
 
-        for (LogTags l = LOG_TAG_NONE; l < LOG_TYPE_MAX; ++l) {
+        for (LogTags_ot l = LOG_TAG_NONE; l < LOG_TYPE_MAX; ++l) {
             if (c->Http.result_hist[l] == 0)
                 continue;
 
             http_total += c->Http.result_hist[l];
 
-            if (logTypeIsATcpHit(l))
+            if (LogTags(l).isTcpHit())
                 http_hits += c->Http.result_hist[l];
 
             storeAppendPrintf(sentry,
                               "        %-20.20s %7d %3d%%\n",
-                              LogTags_str[l],
+                              LogTags(l).c_str(),
                               c->Http.result_hist[l],
                               Math::intPercent(c->Http.result_hist[l], c->Http.n_requests));
         }
@@ -521,8 +521,8 @@ snmp_meshCtblFn(variable_list * Var, snint * ErrP)
     case MESH_CTBL_HTHITS:
         aggr = 0;
 
-        for (LogTags l = LOG_TAG_NONE; l < LOG_TYPE_MAX; ++l) {
-            if (logTypeIsATcpHit(l))
+        for (LogTags_ot l = LOG_TAG_NONE; l < LOG_TYPE_MAX; ++l) {
+            if (LogTags(l).isTcpHit())
                 aggr += c->Http.result_hist[l];
         }
 
@@ -24,7 +24,7 @@ class Address;
 class StoreEntry;
 class ClientInfo;
 
-void clientdbUpdate(const Ip::Address &, LogTags, AnyP::ProtocolType, size_t);
+void clientdbUpdate(const Ip::Address &, const LogTags &, AnyP::ProtocolType, size_t);
 int clientdbCutoffDenied(const Ip::Address &);
 void clientdbDump(StoreEntry *);
 void clientdbFreeMemory(void);
@@ -63,7 +63,6 @@
 #include "base/Subscription.h"
 #include "base/TextException.h"
 #include "CachePeer.h"
-#include "ChunkedCodingParser.h"
 #include "client_db.h"
 #include "client_side.h"
 #include "client_side_reply.h"
@@ -87,6 +86,7 @@
 #include "helper/Reply.h"
 #include "http.h"
 #include "http/one/RequestParser.h"
+#include "http/one/TeChunkedParser.h"
 #include "HttpHdrContRange.h"
 #include "HttpHeaderTools.h"
 #include "HttpReply.h"
@@ -189,16 +189,13 @@ static IDCB clientIdentDone;
 static int clientIsContentLengthValid(HttpRequest * r);
 static int clientIsRequestBodyTooLargeForPolicy(int64_t bodyLength);
 
-static void clientUpdateStatHistCounters(LogTags logType, int svc_time);
-static void clientUpdateStatCounters(LogTags logType);
+static void clientUpdateStatHistCounters(const LogTags &logType, int svc_time);
+static void clientUpdateStatCounters(const LogTags &logType);
 static void clientUpdateHierCounters(HierarchyLogEntry *);
 static bool clientPingHasFinished(ping_data const *aPing);
 void prepareLogWithRequestDetails(HttpRequest *, AccessLogEntry::Pointer &);
-#ifndef PURIFY
-static bool connIsUsable(ConnStateData * conn);
-#endif
 static void ClientSocketContextPushDeferredIfNeeded(ClientSocketContext::Pointer deferredRequest, ConnStateData * conn);
-static void clientUpdateSocketStats(LogTags logType, size_t size);
+static void clientUpdateSocketStats(const LogTags &logType, size_t size);
 
 char *skipLeadingSpace(char *aString);
 
@@ -235,7 +232,8 @@ ConnStateData::readSomeData()
 
     debugs(33, 4, HERE << clientConnection << ": reading request...");
 
-    if (!in.maybeMakeSpaceAvailable())
+    // we can only read if there is more than 1 byte of space free
+    if (Config.maxRequestBufferSize - in.buf.length() < 2)
         return;
 
     typedef CommCbMemFunT<ConnStateData, CommIoCbParams> Dialer;
@@ -389,21 +387,21 @@ clientIdentDone(const char *ident, void *data)
 #endif
 
 void
-clientUpdateStatCounters(LogTags logType)
+clientUpdateStatCounters(const LogTags &logType)
 {
     ++statCounter.client_http.requests;
 
-    if (logTypeIsATcpHit(logType))
+    if (logType.isTcpHit())
         ++statCounter.client_http.hits;
 
-    if (logType == LOG_TCP_HIT)
+    if (logType.oldType == LOG_TCP_HIT)
         ++statCounter.client_http.disk_hits;
-    else if (logType == LOG_TCP_MEM_HIT)
+    else if (logType.oldType == LOG_TCP_MEM_HIT)
         ++statCounter.client_http.mem_hits;
 }
 
 void
-clientUpdateStatHistCounters(LogTags logType, int svc_time)
+clientUpdateStatHistCounters(const LogTags &logType, int svc_time)
 {
     statCounter.client_http.allSvcTime.count(svc_time);
     /**
@@ -413,7 +411,7 @@ clientUpdateStatHistCounters(LogTags logType, int svc_time)
      * (we *tried* to validate it, but failed).
      */
 
-    switch (logType) {
+    switch (logType.oldType) {
 
     case LOG_TCP_REFRESH_UNMODIFIED:
         statCounter.client_http.nearHitSvcTime.count(svc_time);
@@ -518,35 +516,28 @@ prepareLogWithRequestDetails(HttpRequest * request, AccessLogEntry::Pointer &aLo
     assert(aLogEntry != NULL);
 
     if (Config.onoff.log_mime_hdrs) {
-        Packer p;
         MemBuf mb;
         mb.init();
-        packerToMemInit(&p, &mb);
-        request->header.packInto(&p);
+        request->header.packInto(&mb);
         //This is the request after adaptation or redirection
         aLogEntry->headers.adapted_request = xstrdup(mb.buf);
 
         // the virgin request is saved to aLogEntry->request
         if (aLogEntry->request) {
-            packerClean(&p);
             mb.reset();
-            packerToMemInit(&p, &mb);
-            aLogEntry->request->header.packInto(&p);
+            aLogEntry->request->header.packInto(&mb);
             aLogEntry->headers.request = xstrdup(mb.buf);
         }
 
 #if USE_ADAPTATION
         const Adaptation::History::Pointer ah = request->adaptLogHistory();
         if (ah != NULL) {
-            packerClean(&p);
             mb.reset();
-            packerToMemInit(&p, &mb);
-            ah->lastMeta.packInto(&p);
+            ah->lastMeta.packInto(&mb);
             aLogEntry->adapt.last_meta = xstrdup(mb.buf);
         }
 #endif
 
-        packerClean(&p);
         mb.clean();
     }
 
@@ -576,8 +567,8 @@ prepareLogWithRequestDetails(HttpRequest * request, AccessLogEntry::Pointer &aLo
 void
 ClientHttpRequest::logRequest()
 {
-    if (!out.size && !logType)
-        debugs(33, 5, HERE << "logging half-baked transaction: " << log_uri);
+    if (!out.size && logType.oldType == LOG_TAG_NONE)
+        debugs(33, 5, "logging half-baked transaction: " << log_uri);
 
     al->icp.opcode = ICP_INVALID;
     al->url = log_uri;
@@ -818,6 +809,7 @@ ConnStateData::swanSong()
 {
     debugs(33, 2, HERE << clientConnection);
     flags.readMore = false;
+    DeregisterRunner(this);
     clientdbEstablished(clientConnection->remote, -1);  /* decrement */
     assert(areAllContextsForThisConnection());
     freeAllContexts();
@@ -909,18 +901,6 @@ clientIsRequestBodyTooLargeForPolicy(int64_t bodyLength)
     return 0;
 }
 
-#ifndef PURIFY
-bool
-connIsUsable(ConnStateData * conn)
-{
-    if (conn == NULL || !cbdataReferenceValid(conn) || !Comm::IsConnOpen(conn->clientConnection))
-        return false;
-
-    return true;
-}
-
-#endif
-
 // careful: the "current" context may be gone if we wrote an early response
 ClientSocketContext::Pointer
 ConnStateData::getCurrentContext() const
@@ -1039,16 +1019,16 @@ ClientSocketContext::packChunk(const StoreIOBuffer &bodyData, MemBuf &mb)
         static_cast<uint64_t>(lengthToSend(bodyData.range()));
     noteSentBodyBytes(length);
 
-    mb.Printf("%" PRIX64 "\r\n", length);
+    mb.appendf("%" PRIX64 "\r\n", length);
     mb.append(bodyData.data, length);
-    mb.Printf("\r\n");
+    mb.append("\r\n", 2);
 }
 
 /** put terminating boundary for multiparts */
 static void
 clientPackTermBound(String boundary, MemBuf * mb)
 {
-    mb->Printf("\r\n--" SQUIDSTRINGPH "--\r\n", SQUIDSTRINGPRINT(boundary));
+    mb->appendf("\r\n--" SQUIDSTRINGPH "--\r\n", SQUIDSTRINGPRINT(boundary));
     debugs(33, 6, "clientPackTermBound: buf offset: " << mb->size);
 }
 
@@ -1057,14 +1037,13 @@ static void
 clientPackRangeHdr(const HttpReply * rep, const HttpHdrRangeSpec * spec, String boundary, MemBuf * mb)
 {
     HttpHeader hdr(hoReply);
-    Packer p;
     assert(rep);
     assert(spec);
 
     /* put boundary */
     debugs(33, 5, "clientPackRangeHdr: appending boundary: " << boundary);
     /* rfc2046 requires to _prepend_ boundary with <crlf>! */
-    mb->Printf("\r\n--" SQUIDSTRINGPH "\r\n", SQUIDSTRINGPRINT(boundary));
+    mb->appendf("\r\n--" SQUIDSTRINGPH "\r\n", SQUIDSTRINGPRINT(boundary));
 
     /* stuff the header with required entries and pack it */
 
@@ -1073,16 +1052,11 @@ clientPackRangeHdr(const HttpReply * rep, const HttpHdrRangeSpec * spec, String
 
     httpHeaderAddContRange(&hdr, *spec, rep->content_length);
 
-    packerToMemInit(&p, mb);
-
-    hdr.packInto(&p);
-
-    packerClean(&p);
-
+    hdr.packInto(mb);
     hdr.clean();
 
     /* append <crlf> (we packed a header, not a reply) */
-    mb->Printf("\r\n");
+    mb->append("\r\n", 2);
 }
 
 /**
@@ -1289,13 +1263,13 @@ ClientSocketContext::buildRangeHeader(HttpReply * rep)
     /* hits only - upstream CachePeer determines correct behaviour on misses, and client_side_reply determines
      * hits candidates
      */
-    else if (logTypeIsATcpHit(http->logType) && http->request->header.has(HDR_IF_RANGE) && !clientIfRangeMatch(http, rep))
+    else if (http->logType.isTcpHit() && http->request->header.has(HDR_IF_RANGE) && !clientIfRangeMatch(http, rep))
         range_err = "If-Range match failed";
     else if (!http->request->range->canonize(rep))
         range_err = "canonization failed";
     else if (http->request->range->isComplex())
         range_err = "too complex range header";
-    else if (!logTypeIsATcpHit(http->logType) && http->request->range->offsetLimitExceeded(roffLimit))
+    else if (!http->logType.isTcpHit() && http->request->range->offsetLimitExceeded(roffLimit))
         range_err = "range outside range_offset_limit";
 
     /* get rid of our range specs on error */
@@ -1439,6 +1413,10 @@ void
 clientSocketRecipient(clientStreamNode * node, ClientHttpRequest * http,
                       HttpReply * rep, StoreIOBuffer receivedData)
 {
+    // dont tryt to deliver if client already ABORTED
+    if (!http->getConn() || !cbdataReferenceValid(http->getConn()) || !Comm::IsConnOpen(http->getConn()->clientConnection))
+        return;
+
     /* Test preconditions */
     assert(node != NULL);
     PROF_start(clientSocketRecipient);
@@ -1451,7 +1429,6 @@ clientSocketRecipient(clientStreamNode * node, ClientHttpRequest * http,
     assert(node->node.next == NULL);
     ClientSocketContext::Pointer context = dynamic_cast<ClientSocketContext *>(node->data.getRaw());
     assert(context != NULL);
-    assert(connIsUsable(http->getConn()));
 
     /* TODO: check offset is what we asked for */
 
@@ -1621,14 +1598,14 @@ ClientSocketContext::keepaliveNextRequest()
 }
 
 void
-clientUpdateSocketStats(LogTags logType, size_t size)
+clientUpdateSocketStats(const LogTags &logType, size_t size)
 {
     if (size == 0)
         return;
 
     kb_incr(&statCounter.client_http.kbytes_out, size);
 
-    if (logTypeIsATcpHit(logType))
+    if (logType.isTcpHit())
         kb_incr(&statCounter.client_http.hit_kbytes_out, size);
 }
 
@@ -1795,10 +1772,9 @@ void
 ClientSocketContext::noteIoError(const int xerrno)
 {
     if (http) {
-        if (xerrno == ETIMEDOUT)
-            http->al->http.timedout = true;
-        else // even if xerrno is zero (which means read abort/eof)
-            http->al->http.aborted = true;
+        http->logType.err.timedout = (xerrno == ETIMEDOUT);
+        // aborted even if xerrno is zero (which means read abort/eof)
+        http->logType.err.aborted = (xerrno != ETIMEDOUT);
     }
 }
 
@@ -1867,7 +1843,7 @@ ClientSocketContext::writeComplete(const Comm::ConnectionPointer &conn, char *,
         break;
 
     case STREAM_COMPLETE:
-        debugs(33, 5, conn << "Stream complete, keepalive is " << http->request->flags.proxyKeepalive);
+        debugs(33, 5, conn << " Stream complete, keepalive is " << http->request->flags.proxyKeepalive);
         if (http->request->flags.proxyKeepalive)
             keepaliveNextRequest();
         else
@@ -1904,6 +1880,32 @@ ConnStateData::abortRequestParsing(const char *const uri)
     return context;
 }
 
+void
+ConnStateData::startShutdown()
+{
+    // RegisteredRunner API callback - Squid has been shut down
+
+    // if connection is idle terminate it now,
+    // otherwise wait for grace period to end
+    if (getConcurrentRequestCount() == 0)
+        endingShutdown();
+}
+
+void
+ConnStateData::endingShutdown()
+{
+    // RegisteredRunner API callback - Squid shutdown grace period is over
+
+    // force the client connection to close immediately
+    // swanSong() in the close handler will cleanup.
+    if (Comm::IsConnOpen(clientConnection))
+        clientConnection->close();
+
+    // deregister now to ensure finalShutdown() does not kill us prematurely.
+    // fd_table purge will cleanup if close handler was not fast enough.
+    DeregisterRunner(this);
+}
+
 char *
 skipLeadingSpace(char *aString)
 {
@@ -2048,7 +2050,7 @@ prepareAcceleratedURL(ConnStateData * conn, ClientHttpRequest *http, const Http1
 #if SHOULD_REJECT_UNKNOWN_URLS
     // reject URI which are not well-formed even after the processing above
     if (url.isEmpty() || url[0] != '/') {
-        hp->request_parse_status = Http::scBadRequest;
+        hp->parseStatusCode = Http::scBadRequest;
         return conn->abortRequestParsing("error:invalid-request");
     }
 #endif
@@ -2164,7 +2166,7 @@ parseHttpRequest(ConnStateData *csd, const Http1::RequestParserPointer &hp)
         }
 
         if (!parsedOk) {
-            if (hp->request_parse_status == Http::scRequestHeaderFieldsTooLarge || hp->request_parse_status == Http::scUriTooLong)
+            if (hp->parseStatusCode == Http::scRequestHeaderFieldsTooLarge || hp->parseStatusCode == Http::scUriTooLong)
                 return csd->abortRequestParsing("error:request-too-large");
 
             return csd->abortRequestParsing("error:invalid-request");
@@ -2182,24 +2184,24 @@ parseHttpRequest(ConnStateData *csd, const Http1::RequestParserPointer &hp)
     if (hp->method() == Http::METHOD_CONNECT && csd->port != NULL && csd->port->flags.accelSurrogate) {
         debugs(33, DBG_IMPORTANT, "WARNING: CONNECT method received on " << csd->transferProtocol << " Accelerator port " << csd->port->s.port());
         debugs(33, DBG_IMPORTANT, "WARNING: for request: " << hp->method() << " " << hp->requestUri() << " " << hp->messageProtocol());
-        hp->request_parse_status = Http::scMethodNotAllowed;
+        hp->parseStatusCode = Http::scMethodNotAllowed;
         return csd->abortRequestParsing("error:method-not-allowed");
     }
 
-    /* draft-ietf-httpbis-http2-16 section 11.6 registers the method PRI as HTTP/2 specific
+    /* RFC 7540 section 11.6 registers the method PRI as HTTP/2 specific
      * Deny "PRI" method if used in HTTP/1.x or 0.9 versions.
      * If seen it signals a broken client or proxy has corrupted the traffic.
      */
     if (hp->method() == Http::METHOD_PRI && hp->messageProtocol() < Http::ProtocolVersion(2,0)) {
         debugs(33, DBG_IMPORTANT, "WARNING: PRI method received on " << csd->transferProtocol << " port " << csd->port->s.port());
         debugs(33, DBG_IMPORTANT, "WARNING: for request: " << hp->method() << " " << hp->requestUri() << " " << hp->messageProtocol());
-        hp->request_parse_status = Http::scMethodNotAllowed;
+        hp->parseStatusCode = Http::scMethodNotAllowed;
         return csd->abortRequestParsing("error:method-not-allowed");
     }
 
     if (hp->method() == Http::METHOD_NONE) {
         debugs(33, DBG_IMPORTANT, "WARNING: Unsupported method: " << hp->method() << " " << hp->requestUri() << " " << hp->messageProtocol());
-        hp->request_parse_status = Http::scMethodNotAllowed;
+        hp->parseStatusCode = Http::scMethodNotAllowed;
         return csd->abortRequestParsing("error:unsupported-request-method");
     }
 
@@ -2227,12 +2229,7 @@ parseHttpRequest(ConnStateData *csd, const Http1::RequestParserPointer &hp)
                      clientSocketDetach, newClient, tempBuffer);
 
     /* set url */
-    // XXX: c_str() does re-allocate but here replaces explicit malloc/free.
-    // when internalCheck() accepts SBuf removing this will be a net gain for performance.
-    SBuf tmp(hp->requestUri());
-    const char *url = tmp.c_str();
-
-    debugs(33,5, HERE << "repare absolute URL from " <<
+    debugs(33,5, "Prepare absolute URL from " <<
            (csd->transparent()?"intercept":(csd->port->flags.accelSurrogate ? "accel":"")));
     /* Rewrite the URL in transparent or accelerator mode */
     /* NP: there are several cases to traverse here:
@@ -2242,7 +2239,7 @@ parseHttpRequest(ConnStateData *csd, const Http1::RequestParserPointer &hp)
      *  - intercept mode (NAT)
      *  - intercept mode with failures
      *  - accelerator mode (reverse proxy)
-     *  - internal URL
+     *  - internal relative-URL
      *  - mixed combos of the above with internal URL
      *  - remote interception with PROXY protocol
      *  - remote reverse-proxy with PROXY protocol
@@ -2251,10 +2248,10 @@ parseHttpRequest(ConnStateData *csd, const Http1::RequestParserPointer &hp)
         /* intercept or transparent mode, properly working with no failures */
         prepareTransparentURL(csd, http, hp);
 
-    } else if (internalCheck(url)) {
+    } else if (internalCheck(hp->requestUri())) { // NP: only matches relative-URI
         /* internal URL mode */
         /* prepend our name & port */
-        http->uri = xstrdup(internalLocalUri(NULL, url));
+        http->uri = xstrdup(internalLocalUri(NULL, hp->requestUri()));
         // We just re-wrote the URL. Must replace the Host: header.
         //  But have not parsed there yet!! flag for local-only handling.
         http->flags.internal = true;
@@ -2269,7 +2266,7 @@ parseHttpRequest(ConnStateData *csd, const Http1::RequestParserPointer &hp)
          * requested url. may be rewritten later, so make extra room */
         int url_sz = hp->requestUri().length() + Config.appendDomainLen + 5;
         http->uri = (char *)xcalloc(url_sz, 1);
-        strcpy(http->uri, url);
+        xstrncpy(http->uri, hp->requestUri().rawContent(), hp->requestUri().length()+1);
     }
 
     result->flags.parsed_ok = 1;
@@ -2412,9 +2409,9 @@ bool ConnStateData::serveDelayedError(ClientSocketContext *context)
     // when we can extract the intended name from the bumped HTTP request.
     if (X509 *srvCert = sslServerBump->serverCert.get()) {
         HttpRequest *request = http->request;
-        if (!Ssl::checkX509ServerValidity(srvCert, request->GetHost())) {
+        if (!Ssl::checkX509ServerValidity(srvCert, request->url.host())) {
             debugs(33, 2, "SQUID_X509_V_ERR_DOMAIN_MISMATCH: Certificate " <<
-                   "does not match domainname " << request->GetHost());
+                   "does not match domainname " << request->url.host());
 
             bool allowDomainMismatch = false;
             if (Config.ssl_client.cert_error) {
@@ -2434,7 +2431,7 @@ bool ConnStateData::serveDelayedError(ClientSocketContext *context)
 
                 // Fill the server IP and hostname for error page generation.
                 HttpRequest::Pointer const & peekerRequest = sslServerBump->request;
-                request->hier.note(peekerRequest->hier.tcpServer, request->GetHost());
+                request->hier.note(peekerRequest->hier.tcpServer, request->url.host());
 
                 // Create an error object and fill it
                 ErrorState *err = new ErrorState(ERR_SECURE_CONNECT_FAIL, Http::scServiceUnavailable, request);
@@ -2587,20 +2584,18 @@ clientProcessRequest(ConnStateData *conn, const Http1::RequestParserPointer &hp,
             request->flags.spoofClientIp = false;
     }
 
-    if (internalCheck(request->urlpath.termedBuf())) {
-        if (internalHostnameIs(request->GetHost()) && request->port == getMyPort()) {
-            debugs(33, 2, "internal URL found: " << request->url.getScheme() << "://" << request->GetHost() <<
-                   ':' << request->port);
+    if (internalCheck(request->url.path())) {
+        if (internalHostnameIs(request->url.host()) && request->url.port() == getMyPort()) {
+            debugs(33, 2, "internal URL found: " << request->url.getScheme() << "://" << request->url.authority(true));
             http->flags.internal = true;
-        } else if (Config.onoff.global_internal_static && internalStaticCheck(request->urlpath.termedBuf())) {
-            debugs(33, 2, "internal URL found: " << request->url.getScheme() << "://" << request->GetHost() <<
-                   ':' << request->port << " (global_internal_static on)");
-            request->SetHost(internalHostname());
-            request->port = getMyPort();
+        } else if (Config.onoff.global_internal_static && internalStaticCheck(request->url.path())) {
+            debugs(33, 2, "internal URL found: " << request->url.getScheme() << "://" << request->url.authority(true) << " (global_internal_static on)");
+            request->url.setScheme(AnyP::PROTO_HTTP);
+            request->url.host(internalHostname());
+            request->url.port(getMyPort());
             http->flags.internal = true;
         } else
-            debugs(33, 2, "internal URL found: " << request->url.getScheme() << "://" << request->GetHost() <<
-                   ':' << request->port << " (not this proxy)");
+            debugs(33, 2, "internal URL found: " << request->url.getScheme() << "://" << request->url.authority(true) << " (not this proxy)");
     }
 
     request->flags.internal = http->flags.internal;
@@ -2726,6 +2721,9 @@ clientProcessRequest(ConnStateData *conn, const Http1::RequestParserPointer &hp,
 int
 ConnStateData::pipelinePrefetchMax() const
 {
+    // TODO: Support pipelined requests through pinned connections.
+    if (pinning.pinned)
+        return 0;
     return Config.pipeline_max_prefetch;
 }
 
@@ -2741,7 +2739,12 @@ ConnStateData::concurrentRequestQueueFilled() const
 
     // default to the configured pipeline size.
     // add 1 because the head of pipeline is counted in concurrent requests and not prefetch queue
-    const int concurrentRequestLimit = pipelinePrefetchMax() + 1;
+#if USE_OPENSSL
+    const int internalRequest = (transparent() && sslBumpMode == Ssl::bumpSplice) ? 1 : 0;
+#else
+    const int internalRequest = 0;
+#endif
+    const int concurrentRequestLimit = pipelinePrefetchMax() + 1 + internalRequest;
 
     // when queue filled already we cant add more.
     if (existingRequestCount >= concurrentRequestLimit) {
@@ -2907,7 +2910,8 @@ ConnStateData::parseProxy1p0()
         debugs(33, 5, "PROXY/1.0 protocol on connection " << clientConnection);
         clientConnection->local = originalDest;
         clientConnection->remote = originalClient;
-        clientConnection->flags ^= COMM_TRANSPARENT; // prevent TPROXY spoofing of this new IP.
+        if ((clientConnection->flags & COMM_TRANSPARENT))
+            clientConnection->flags ^= COMM_TRANSPARENT; // prevent TPROXY spoofing of this new IP.
         debugs(33, 5, "PROXY/1.0 upgrade: " << clientConnection);
 
         // repeat fetch ensuring the new client FQDN can be logged
@@ -2997,14 +3001,16 @@ ConnStateData::parseProxy2p0()
         clientConnection->local.port(ntohs(ipu.ipv4_addr.dst_port));
         clientConnection->remote = ipu.ipv4_addr.src_addr;
         clientConnection->remote.port(ntohs(ipu.ipv4_addr.src_port));
-        clientConnection->flags ^= COMM_TRANSPARENT; // prevent TPROXY spoofing of this new IP.
+        if ((clientConnection->flags & COMM_TRANSPARENT))
+            clientConnection->flags ^= COMM_TRANSPARENT; // prevent TPROXY spoofing of this new IP.
         break;
     case 0x2: // IPv6
         clientConnection->local = ipu.ipv6_addr.dst_addr;
         clientConnection->local.port(ntohs(ipu.ipv6_addr.dst_port));
         clientConnection->remote = ipu.ipv6_addr.src_addr;
         clientConnection->remote.port(ntohs(ipu.ipv6_addr.src_port));
-        clientConnection->flags ^= COMM_TRANSPARENT; // prevent TPROXY spoofing of this new IP.
+        if ((clientConnection->flags & COMM_TRANSPARENT))
+            clientConnection->flags ^= COMM_TRANSPARENT; // prevent TPROXY spoofing of this new IP.
         break;
     default: // do nothing
         break;
@@ -3056,12 +3062,6 @@ ConnStateData::clientParseRequests()
         if (concurrentRequestQueueFilled())
             break;
 
-        /*Do not read more requests if persistent connection lifetime exceeded*/
-        if (Config.Timeout.pconnLifetime && clientConnection->lifeTime() > Config.Timeout.pconnLifetime) {
-            flags.readMore = false;
-            break;
-        }
-
         // try to parse the PROXY protocol header magic bytes
         if (needProxyProtocolHeader_ && !parseProxyProtocolHeader())
             break;
@@ -3118,6 +3118,7 @@ ConnStateData::clientReadRequest(const CommIoCbParams &io)
      * Plus, it breaks our lame *HalfClosed() detection
      */
 
+    in.maybeMakeSpaceAvailable();
     CommIoCbParams rd(this); // will be expanded with ReadNow results
     rd.conn = io.conn;
     switch (Comm::ReadNow(rd, in.buf)) {
@@ -3222,25 +3223,23 @@ ConnStateData::handleRequestBodyData()
 {
     assert(bodyPipe != NULL);
 
-    size_t putSize = 0;
-
     if (in.bodyParser) { // chunked encoding
-        if (const err_type error = handleChunkedRequestBody(putSize)) {
+        if (const err_type error = handleChunkedRequestBody()) {
             abortChunkedRequestBody(error);
             return false;
         }
     } else { // identity encoding
         debugs(33,5, HERE << "handling plain request body for " << clientConnection);
-        putSize = bodyPipe->putMoreData(in.buf.c_str(), in.buf.length());
+        const size_t putSize = bodyPipe->putMoreData(in.buf.c_str(), in.buf.length());
+        if (putSize > 0)
+            consumeInput(putSize);
+
         if (!bodyPipe->mayNeedMoreData()) {
             // BodyPipe will clear us automagically when we produced everything
             bodyPipe = NULL;
         }
     }
 
-    if (putSize > 0)
-        consumeInput(putSize);
-
     if (!bodyPipe) {
         debugs(33,5, HERE << "produced entire request body for " << clientConnection);
 
@@ -3259,7 +3258,7 @@ ConnStateData::handleRequestBodyData()
 
 /// parses available chunked encoded body bytes, checks size, returns errors
 err_type
-ConnStateData::handleChunkedRequestBody(size_t &putSize)
+ConnStateData::handleChunkedRequestBody()
 {
     debugs(33, 7, "chunked from " << clientConnection << ": " << in.buf.length());
 
@@ -3268,16 +3267,11 @@ ConnStateData::handleChunkedRequestBody(size_t &putSize)
         if (in.buf.isEmpty()) // nothing to do
             return ERR_NONE;
 
-        MemBuf raw; // ChunkedCodingParser only works with MemBufs
-        // add one because MemBuf will assert if it cannot 0-terminate
-        raw.init(in.buf.length(), in.buf.length()+1);
-        raw.append(in.buf.c_str(), in.buf.length());
-
-        const mb_size_t wasContentSize = raw.contentSize();
         BodyPipeCheckout bpc(*bodyPipe);
-        const bool parsed = in.bodyParser->parse(&raw, &bpc.buf);
+        in.bodyParser->setPayloadBuffer(&bpc.buf);
+        const bool parsed = in.bodyParser->parse(in.buf);
+        in.buf = in.bodyParser->remaining(); // sync buffers
         bpc.checkIn();
-        putSize = wasContentSize - raw.contentSize();
 
         // dechunk then check: the size limit applies to _dechunked_ content
         if (clientIsRequestBodyTooLargeForPolicy(bodyPipe->producedSize()))
@@ -3388,7 +3382,7 @@ clientLifetimeTimeout(const CommTimeoutCbParams &io)
     ClientHttpRequest *http = static_cast<ClientHttpRequest *>(io.data);
     debugs(33, DBG_IMPORTANT, "WARNING: Closing client connection due to lifetime timeout");
     debugs(33, DBG_IMPORTANT, "\t" << http->uri);
-    http->al->http.timedout = true;
+    http->logType.err.timedout = true;
     if (Comm::IsConnOpen(io.conn))
         io.conn->close();
 }
@@ -3425,6 +3419,10 @@ ConnStateData::ConnStateData(const MasterXaction::Pointer &xact) :
     transferProtocol = port->transport; // default to the *_port protocol= setting. may change later.
     log_addr = xact->tcpClient->remote;
     log_addr.applyMask(Config.Addrs.client_netmask);
+
+    // register to receive notice of Squid signal events
+    // which may affect long persisting client connections
+    RegisterRunner(this);
 }
 
 void
@@ -3433,9 +3431,6 @@ ConnStateData::start()
     BodyProducer::start();
     HttpControlMsgSink::start();
 
-    // ensure a buffer is present for this connection
-    in.maybeMakeSpaceAvailable();
-
     if (port->disable_pmtu_discovery != DISABLE_PMTU_OFF &&
             (transparent() || port->disable_pmtu_discovery == DISABLE_PMTU_ALWAYS)) {
 #if defined(IP_MTU_DISCOVER) && defined(IP_PMTUDISC_DONT)
@@ -3555,16 +3550,16 @@ httpAccept(const CommAcceptCbParams &params)
 #if USE_OPENSSL
 
 /** Create SSL connection structure and update fd_table */
-static SSL *
-httpsCreate(const Comm::ConnectionPointer &conn, SSL_CTX *sslContext)
+static Security::SessionPointer
+httpsCreate(const Comm::ConnectionPointer &conn, Security::ContextPointer sslContext)
 {
-    if (SSL *ssl = Ssl::CreateServer(sslContext, conn->fd, "client https start")) {
+    if (auto ssl = Ssl::CreateServer(sslContext, conn->fd, "client https start")) {
         debugs(33, 5, "will negotate SSL on " << conn);
         return ssl;
     }
 
     conn->close();
-    return NULL;
+    return nullptr;
 }
 
 /**
@@ -3577,11 +3572,13 @@ static int
 Squid_SSL_accept(ConnStateData *conn, PF *callback)
 {
     int fd = conn->clientConnection->fd;
-    SSL *ssl = fd_table[fd].ssl;
+    auto ssl = fd_table[fd].ssl;
     int ret;
 
+    errno = 0;
     if ((ret = SSL_accept(ssl)) <= 0) {
-        int ssl_error = SSL_get_error(ssl, ret);
+        const int xerrno = errno;
+        const int ssl_error = SSL_get_error(ssl, ret);
 
         switch (ssl_error) {
 
@@ -3594,17 +3591,11 @@ Squid_SSL_accept(ConnStateData *conn, PF *callback)
             return 0;
 
         case SSL_ERROR_SYSCALL:
-
             if (ret == 0) {
                 debugs(83, 2, "Error negotiating SSL connection on FD " << fd << ": Aborted by client: " << ssl_error);
             } else {
-                int hard = 1;
-
-                if (errno == ECONNRESET)
-                    hard = 0;
-
-                debugs(83, hard ? 1 : 2, "Error negotiating SSL connection on FD " <<
-                       fd << ": " << strerror(errno) << " (" << errno << ")");
+                debugs(83, (xerrno == ECONNRESET) ? 1 : 2, "Error negotiating SSL connection on FD " << fd << ": " <<
+                       (xerrno == 0 ? ERR_error_string(ssl_error, NULL) : xstrerr(xerrno)));
             }
             return -1;
 
@@ -3630,12 +3621,12 @@ clientNegotiateSSL(int fd, void *data)
 {
     ConnStateData *conn = (ConnStateData *)data;
     X509 *client_cert;
-    SSL *ssl = fd_table[fd].ssl;
+    auto ssl = fd_table[fd].ssl;
 
     int ret;
     if ((ret = Squid_SSL_accept(conn, clientNegotiateSSL)) <= 0) {
         if (ret < 0) // An error
-            comm_close(fd);
+            conn->clientConnection->close();
         return;
     }
 
@@ -3696,56 +3687,37 @@ clientNegotiateSSL(int fd, void *data)
                " has no certificate.");
     }
 
+#if defined(TLSEXT_NAMETYPE_host_name)
+    if (!conn->serverBump()) {
+        // when in bumpClientFirst mode, get the server name from SNI
+        if (const char *server = SSL_get_servername(ssl, TLSEXT_NAMETYPE_host_name))
+            conn->resetSslCommonName(server);
+    }
+#endif
+
     conn->readSomeData();
 }
 
 /**
- * If SSL_CTX is given, starts reading the SSL handshake.
- * Otherwise, calls switchToHttps to generate a dynamic SSL_CTX.
+ * If Security::ContextPointer is given, starts reading the TLS handshake.
+ * Otherwise, calls switchToHttps to generate a dynamic Security::ContextPointer.
  */
 static void
-httpsEstablish(ConnStateData *connState,  SSL_CTX *sslContext, Ssl::BumpMode bumpMode)
+httpsEstablish(ConnStateData *connState, Security::ContextPointer sslContext)
 {
-    SSL *ssl = NULL;
+    Security::SessionPointer ssl = nullptr;
     assert(connState);
     const Comm::ConnectionPointer &details = connState->clientConnection;
 
-    if (sslContext && !(ssl = httpsCreate(details, sslContext)))
+    if (!sslContext || !(ssl = httpsCreate(details, sslContext)))
         return;
 
     typedef CommCbMemFunT<ConnStateData, CommTimeoutCbParams> TimeoutDialer;
     AsyncCall::Pointer timeoutCall = JobCallback(33, 5, TimeoutDialer,
                                      connState, ConnStateData::requestTimeout);
     commSetConnTimeout(details, Config.Timeout.request, timeoutCall);
 
-    if (ssl)
-        Comm::SetSelect(details->fd, COMM_SELECT_READ, clientNegotiateSSL, connState, 0);
-    else {
-        char buf[MAX_IPSTRLEN];
-        assert(bumpMode != Ssl::bumpNone && bumpMode != Ssl::bumpEnd);
-        HttpRequest::Pointer fakeRequest(new HttpRequest);
-        fakeRequest->SetHost(details->local.toStr(buf, sizeof(buf)));
-        fakeRequest->port = details->local.port();
-        fakeRequest->clientConnectionManager = connState;
-        fakeRequest->client_addr = connState->clientConnection->remote;
-#if FOLLOW_X_FORWARDED_FOR
-        fakeRequest->indirect_client_addr = connState->clientConnection->remote;
-#endif
-        fakeRequest->my_addr = connState->clientConnection->local;
-        fakeRequest->flags.interceptTproxy = ((connState->clientConnection->flags & COMM_TRANSPARENT) != 0 ) ;
-        fakeRequest->flags.intercepted = ((connState->clientConnection->flags & COMM_INTERCEPTION) != 0);
-        fakeRequest->myportname = connState->port->name;
-        if (fakeRequest->flags.interceptTproxy) {
-            if (Config.accessList.spoof_client_ip) {
-                ACLFilledChecklist checklist(Config.accessList.spoof_client_ip, fakeRequest.getRaw(), NULL);
-                fakeRequest->flags.spoofClientIp = (checklist.fastCheck() == ACCESS_ALLOWED);
-            } else
-                fakeRequest->flags.spoofClientIp = true;
-        } else
-            fakeRequest->flags.spoofClientIp = false;
-        debugs(33, 4, HERE << details << " try to generate a Dynamic SSL CTX");
-        connState->switchToHttps(fakeRequest.getRaw(), bumpMode);
-    }
+    Comm::SetSelect(details->fd, COMM_SELECT_READ, clientNegotiateSSL, connState, 0);
 }
 
 /**
@@ -3834,8 +3806,8 @@ ConnStateData::postHttpsAccept()
         HttpRequest *request = new HttpRequest();
         static char ip[MAX_IPSTRLEN];
         assert(clientConnection->flags & (COMM_TRANSPARENT | COMM_INTERCEPTION));
-        request->SetHost(clientConnection->local.toStr(ip, sizeof(ip)));
-        request->port = clientConnection->local.port();
+        request->url.host(clientConnection->local.toStr(ip, sizeof(ip)));
+        request->url.port(clientConnection->local.port());
         request->myportname = port->name;
 
         ACLFilledChecklist *acl_checklist = new ACLFilledChecklist(Config.accessList.ssl_bump, request, NULL);
@@ -3844,8 +3816,8 @@ ConnStateData::postHttpsAccept()
         acl_checklist->nonBlockingCheck(httpsSslBumpAccessCheckDone, this);
         return;
     } else {
-        SSL_CTX *sslContext = port->staticSslContext.get();
-        httpsEstablish(this, sslContext, Ssl::bumpNone);
+        Security::ContextPointer sslContext = port->staticSslContext.get();
+        httpsEstablish(this, sslContext);
     }
 }
 
@@ -3859,6 +3831,11 @@ ConnStateData::sslCrtdHandleReplyWrapper(void *data, const Helper::Reply &reply)
 void
 ConnStateData::sslCrtdHandleReply(const Helper::Reply &reply)
 {
+    if (!isOpen()) {
+        debugs(33, 3, "Connection gone while waiting for ssl_crtd helper reply; helper reply:" << reply);
+        return;
+    }
+
     if (reply.result == Helper::BrokenHelper) {
         debugs(33, 5, HERE << "Certificate for " << sslConnectHostOrIp << " cannot be generated. ssl_crtd response: " << reply);
     } else if (!reply.other().hasContent()) {
@@ -3874,12 +3851,12 @@ ConnStateData::sslCrtdHandleReply(const Helper::Reply &reply)
                 debugs(33, 5, HERE << "Certificate for " << sslConnectHostOrIp << " was successfully recieved from ssl_crtd");
                 if (sslServerBump && (sslServerBump->act.step1 == Ssl::bumpPeek || sslServerBump->act.step1 == Ssl::bumpStare)) {
                     doPeekAndSpliceStep();
-                    SSL *ssl = fd_table[clientConnection->fd].ssl;
+                    auto ssl = fd_table[clientConnection->fd].ssl;
                     bool ret = Ssl::configureSSLUsingPkeyAndCertFromMemory(ssl, reply_message.getBody().c_str(), *port);
                     if (!ret)
                         debugs(33, 5, "Failed to set certificates to ssl object for PeekAndSplice mode");
                 } else {
-                    SSL_CTX *ctx = Ssl::generateSslContextUsingPkeyAndCertFromMemory(reply_message.getBody().c_str(), *port);
+                    auto ctx = Ssl::generateSslContextUsingPkeyAndCertFromMemory(reply_message.getBody().c_str(), *port);
                     getSslContextDone(ctx, true);
                 }
                 return;
@@ -3891,7 +3868,7 @@ ConnStateData::sslCrtdHandleReply(const Helper::Reply &reply)
 
 void ConnStateData::buildSslCertGenerationParams(Ssl::CertificateProperties &certProperties)
 {
-    certProperties.commonName =  sslCommonName.size() > 0 ? sslCommonName.termedBuf() : sslConnectHostOrIp.termedBuf();
+    certProperties.commonName =  sslCommonName_.isEmpty() ? sslConnectHostOrIp.termedBuf() : sslCommonName_.c_str();
 
     // fake certificate adaptation requires bump-server-first mode
     if (!sslServerBump) {
@@ -3994,7 +3971,7 @@ ConnStateData::getSslContextStart()
         if (!(sslServerBump && (sslServerBump->act.step1 == Ssl::bumpPeek || sslServerBump->act.step1 == Ssl::bumpStare))) {
             debugs(33, 5, "Finding SSL certificate for " << sslBumpCertKey << " in cache");
             Ssl::LocalContextStorage * ssl_ctx_cache = Ssl::TheGlobalContextStorage.getLocalStorage(port->s);
-            SSL_CTX * dynCtx = NULL;
+            Security::ContextPointer dynCtx = nullptr;
             Ssl::SSL_CTX_Pointer *cachedCtx = ssl_ctx_cache ? ssl_ctx_cache->get(sslBumpCertKey.termedBuf()) : NULL;
             if (cachedCtx && (dynCtx = cachedCtx->get())) {
                 debugs(33, 5, "SSL certificate for " << sslBumpCertKey << " found in cache");
@@ -4033,11 +4010,11 @@ ConnStateData::getSslContextStart()
         debugs(33, 5, HERE << "Generating SSL certificate for " << certProperties.commonName);
         if (sslServerBump && (sslServerBump->act.step1 == Ssl::bumpPeek || sslServerBump->act.step1 == Ssl::bumpStare)) {
             doPeekAndSpliceStep();
-            SSL *ssl = fd_table[clientConnection->fd].ssl;
+            auto ssl = fd_table[clientConnection->fd].ssl;
             if (!Ssl::configureSSL(ssl, certProperties, *port))
                 debugs(33, 5, "Failed to set certificates to ssl object for PeekAndSplice mode");
         } else {
-            SSL_CTX *dynCtx = Ssl::generateSslContext(certProperties, *port);
+            auto dynCtx = Ssl::generateSslContext(certProperties, *port);
             getSslContextDone(dynCtx, true);
         }
         return;
@@ -4046,7 +4023,7 @@ ConnStateData::getSslContextStart()
 }
 
 void
-ConnStateData::getSslContextDone(SSL_CTX * sslContext, bool isNew)
+ConnStateData::getSslContextDone(Security::ContextPointer sslContext, bool isNew)
 {
     // Try to add generated ssl context to storage.
     if (port->generateHostCertificates && isNew) {
@@ -4111,8 +4088,8 @@ ConnStateData::switchToHttps(HttpRequest *request, Ssl::BumpMode bumpServerMode)
 {
     assert(!switchedToHttps_);
 
-    sslConnectHostOrIp = request->GetHost();
-    sslCommonName = request->GetHost();
+    sslConnectHostOrIp = request->url.host();
+    resetSslCommonName(request->url.host());
 
     // We are going to read new request
     flags.readMore = true;
@@ -4165,7 +4142,7 @@ static void
 clientPeekAndSpliceSSL(int fd, void *data)
 {
     ConnStateData *conn = (ConnStateData *)data;
-    SSL *ssl = fd_table[fd].ssl;
+    auto ssl = fd_table[fd].ssl;
 
     debugs(83, 5, "Start peek and splice on FD " << fd);
 
@@ -4189,8 +4166,10 @@ clientPeekAndSpliceSSL(int fd, void *data)
     if (bio->gotHello()) {
         if (conn->serverBump()) {
             Ssl::Bio::sslFeatures const &features = bio->getFeatures();
-            if (!features.serverName.isEmpty())
+            if (!features.serverName.isEmpty()) {
                 conn->serverBump()->clientSni = features.serverName;
+                conn->resetSslCommonName(features.serverName.c_str());
+            }
         }
 
         debugs(83, 5, "I got hello. Start forwarding the request!!! ");
@@ -4204,7 +4183,7 @@ clientPeekAndSpliceSSL(int fd, void *data)
 void ConnStateData::startPeekAndSplice()
 {
     // will call httpsPeeked() with certificate and connection, eventually
-    SSL_CTX *unConfiguredCTX = Ssl::createSSLContext(port->signingCert, port->signPkey, *port);
+    auto unConfiguredCTX = Ssl::createSSLContext(port->signingCert, port->signPkey, *port);
     fd_table[clientConnection->fd].dynamicSslContext = unConfiguredCTX;
 
     if (!httpsCreate(clientConnection, unConfiguredCTX))
@@ -4225,7 +4204,7 @@ void ConnStateData::startPeekAndSplice()
     Comm::SetSelect(clientConnection->fd, COMM_SELECT_READ, clientPeekAndSpliceSSL, this, 0);
     switchedToHttps_ = true;
 
-    SSL *ssl = fd_table[clientConnection->fd].ssl;
+    auto ssl = fd_table[clientConnection->fd].ssl;
     BIO *b = SSL_get_rbio(ssl);
     Ssl::ClientBio *bio = static_cast<Ssl::ClientBio *>(b->ptr);
     bio->hold(true);
@@ -4256,7 +4235,7 @@ void httpsSslBumpStep2AccessCheckDone(allow_t answer, void *data)
     connState->sslBumpMode = bumpAction;
 
     if (bumpAction == Ssl::bumpTerminate) {
-        comm_close(connState->clientConnection->fd);
+        connState->clientConnection->close();
     } else if (bumpAction != Ssl::bumpSplice) {
         connState->startPeekAndSpliceDone();
     } else
@@ -4267,7 +4246,7 @@ void
 ConnStateData::splice()
 {
     //Normally we can splice here, because we just got client hello message
-    SSL *ssl = fd_table[clientConnection->fd].ssl;
+    auto ssl = fd_table[clientConnection->fd].ssl;
     BIO *b = SSL_get_rbio(ssl);
     Ssl::ClientBio *bio = static_cast<Ssl::ClientBio *>(b->ptr);
     MemBuf const &rbuf = bio->rBufData();
@@ -4327,7 +4306,7 @@ ConnStateData::startPeekAndSpliceDone()
 void
 ConnStateData::doPeekAndSpliceStep()
 {
-    SSL *ssl = fd_table[clientConnection->fd].ssl;
+    auto ssl = fd_table[clientConnection->fd].ssl;
     BIO *b = SSL_get_rbio(ssl);
     assert(b);
     Ssl::ClientBio *bio = static_cast<Ssl::ClientBio *>(b->ptr);
@@ -4345,30 +4324,11 @@ ConnStateData::httpsPeeked(Comm::ConnectionPointer serverConnection)
     Must(sslServerBump != NULL);
 
     if (Comm::IsConnOpen(serverConnection)) {
-        SSL *ssl = fd_table[serverConnection->fd].ssl;
-        assert(ssl);
-        Ssl::X509_Pointer serverCert(SSL_get_peer_certificate(ssl));
-        assert(serverCert.get() != NULL);
-        sslCommonName = Ssl::CommonHostName(serverCert.get());
-        debugs(33, 5, HERE << "HTTPS server CN: " << sslCommonName <<
-               " bumped: " << *serverConnection);
-
         pinConnection(serverConnection, NULL, NULL, false);
 
         debugs(33, 5, HERE << "bumped HTTPS server: " << sslConnectHostOrIp);
     } else {
         debugs(33, 5, HERE << "Error while bumping: " << sslConnectHostOrIp);
-        Ip::Address intendedDest;
-        intendedDest = sslConnectHostOrIp.termedBuf();
-        const bool isConnectRequest = !port->flags.isIntercepted();
-
-        // Squid serves its own error page and closes, so we want
-        // a CN that causes no additional browser errors. Possible
-        // only when bumping CONNECT with a user-typed address.
-        if (intendedDest.isAnyAddr() || isConnectRequest)
-            sslCommonName = sslConnectHostOrIp;
-        else if (sslServerBump->serverCert.get())
-            sslCommonName = Ssl::CommonHostName(sslServerBump->serverCert.get());
 
         //  copy error detail from bump-server-first request to CONNECT request
         if (currentobject != NULL && currentobject->http != NULL && currentobject->http->request)
@@ -4481,7 +4441,7 @@ clientHttpsConnectionsOpen(void)
         }
 
         if (s->flags.tunnelSslBumping && !s->staticSslContext && !s->generateHostCertificates) {
-            debugs(1, DBG_IMPORTANT, "Will not bump SSL at http_port " << s->s << " due to SSL initialization failure.");
+            debugs(1, DBG_IMPORTANT, "Will not bump SSL at https_port " << s->s << " due to SSL initialization failure.");
             s->flags.tunnelSslBumping = false;
         }
 
@@ -4769,7 +4729,7 @@ ConnStateData::startDechunkingRequest()
     Must(bodyPipe != NULL);
     debugs(33, 5, HERE << "start dechunking" << bodyPipe->status());
     assert(!in.bodyParser);
-    in.bodyParser = new ChunkedCodingParser;
+    in.bodyParser = new Http1::TeChunkedParser;
 }
 
 /// put parsed content into input buffer and clean up
@@ -4832,6 +4792,7 @@ ConnStateData::clientPinnedConnectionClosed(const CommCloseCbParams &io)
     assert(pinning.serverConnection == io.conn);
     pinning.closeHandler = NULL; // Comm unregisters handlers before calling
     const bool sawZeroReply = pinning.zeroReply; // reset when unpinning
+    pinning.serverConnection->noteClosure();
     unpinConnection(false);
 
     if (sawZeroReply && clientConnection != NULL) {
@@ -4866,8 +4827,8 @@ ConnStateData::pinNewConnection(const Comm::ConnectionPointer &pinServer, HttpRe
     // when pinning an SSL bumped connection, the request may be NULL
     const char *pinnedHost = "[unknown]";
     if (request) {
-        pinning.host = xstrdup(request->GetHost());
-        pinning.port = request->port;
+        pinning.host = xstrdup(request->url.host());
+        pinning.port = request->url.port();
         pinnedHost = pinning.host;
     } else {
         pinning.port = pinServer->remote.port();
@@ -4951,9 +4912,9 @@ ConnStateData::validatePinnedConnection(HttpRequest *request, const CachePeer *a
     bool valid = true;
     if (!Comm::IsConnOpen(pinning.serverConnection))
         valid = false;
-    else if (pinning.auth && pinning.host && request && strcasecmp(pinning.host, request->GetHost()) != 0)
+    else if (pinning.auth && pinning.host && request && strcasecmp(pinning.host, request->url.host()) != 0)
         valid = false;
-    else if (request && pinning.port != request->port)
+    else if (request && pinning.port != request->url.port())
         valid = false;
     else if (pinning.peer && !cbdataReferenceValid(pinning.peer))
         valid = false;
@@ -11,6 +11,7 @@
 #ifndef SQUID_CLIENTSIDE_H
 #define SQUID_CLIENTSIDE_H
 
+#include "base/RunnersRegistry.h"
 #include "clientStreamForward.h"
 #include "comm.h"
 #include "helper/forward.h"
@@ -28,7 +29,6 @@
 class ConnStateData;
 class ClientHttpRequest;
 class clientStreamNode;
-class ChunkedCodingParser;
 namespace AnyP
 {
 class PortCfg;
@@ -168,7 +168,7 @@ class ServerBump;
  *
  * If the above can be confirmed accurate we can call this object PipelineManager or similar
  */
-class ConnStateData : public BodyProducer, public HttpControlMsgSink
+class ConnStateData : public BodyProducer, public HttpControlMsgSink, public RegisteredRunner
 {
 
 public:
@@ -208,7 +208,7 @@ class ConnStateData : public BodyProducer, public HttpControlMsgSink
         ~In();
         bool maybeMakeSpaceAvailable();
 
-        ChunkedCodingParser *bodyParser; ///< parses chunked request body
+        Http1::TeChunkedParser *bodyParser; ///< parses chunked request body
         SBuf buf;
     } in;
 
@@ -365,7 +365,7 @@ class ConnStateData : public BodyProducer, public HttpControlMsgSink
      *
      * \param[in] isNew if generated certificate is new, so we need to add this certificate to storage.
      */
-    void getSslContextDone(SSL_CTX * sslContext, bool isNew = false);
+    void getSslContextDone(Security::ContextPointer sslContext, bool isNew = false);
     /// Callback function. It is called when squid receive message from ssl_crtd.
     static void sslCrtdHandleReplyWrapper(void *data, const Helper::Reply &reply);
     /// Proccess response from ssl_crtd.
@@ -380,6 +380,8 @@ class ConnStateData : public BodyProducer, public HttpControlMsgSink
         else
             assert(sslServerBump == srvBump);
     }
+    const SBuf &sslCommonName() const {return sslCommonName_;}
+    void resetSslCommonName(const char *name) {sslCommonName_ = name;}
     /// Fill the certAdaptParams with the required data for certificate adaptation
     /// and create the key for storing/retrieve the certificate to/from the cache
     void buildSslCertGenerationParams(Ssl::CertificateProperties &certProperties);
@@ -417,11 +419,16 @@ class ConnStateData : public BodyProducer, public HttpControlMsgSink
     /// client data which may need to forward as-is to server after an
     /// on_unsupported_protocol tunnel decision.
     SBuf preservedClientData;
+
+    /* Registered Runner API */
+    virtual void startShutdown();
+    virtual void endingShutdown();
+
 protected:
     void startDechunkingRequest();
     void finishDechunkingRequest(bool withSuccess);
     void abortChunkedRequestBody(const err_type error);
-    err_type handleChunkedRequestBody(size_t &putSize);
+    err_type handleChunkedRequestBody();
 
     void startPinnedConnectionMonitoring();
     void clientPinnedConnectionRead(const CommIoCbParams &io);
@@ -471,7 +478,7 @@ class ConnStateData : public BodyProducer, public HttpControlMsgSink
     bool switchedToHttps_;
     /// The SSL server host name appears in CONNECT request or the server ip address for the intercepted requests
     String sslConnectHostOrIp; ///< The SSL server host name as passed in the CONNECT request
-    String sslCommonName; ///< CN name for SSL certificate generation
+    SBuf sslCommonName_; ///< CN name for SSL certificate generation
     String sslBumpCertKey; ///< Key to use to store/retrieve generated certificate
 
     /// HTTPS server cert. fetching state for bump-ssl-server-first
@@ -73,8 +73,26 @@ clientReplyContext::~clientReplyContext()
     HTTPMSGUNLOCK(reply);
 }
 
-clientReplyContext::clientReplyContext(ClientHttpRequest *clientContext) : http (cbdataReference(clientContext)), old_entry (NULL), old_sc(NULL), deleting(false)
-{}
+clientReplyContext::clientReplyContext(ClientHttpRequest *clientContext) :
+    purgeStatus(Http::scNone),
+    lookingforstore(0),
+    http(cbdataReference(clientContext)),
+    headers_sz(0),
+    sc(NULL),
+    old_reqsize(0),
+    reqsize(0),
+    reqofs(0),
+#if USE_CACHE_DIGESTS
+    lookup_type(NULL),
+#endif
+    ourNode(NULL),
+    reply(NULL),
+    old_entry(NULL),
+    old_sc(NULL),
+    deleting(false)
+{
+    *tempbuf = 0;
+}
 
 /** Create an error in the store awaiting the client side to read it.
  *
@@ -492,9 +510,9 @@ clientReplyContext::cacheHit(StoreIOBuffer result)
     /*
      * Got the headers, now grok them
      */
-    assert(http->logType == LOG_TCP_HIT);
+    assert(http->logType.oldType == LOG_TCP_HIT);
 
-    if (strcmp(e->mem_obj->storeId(), http->request->storeId()) != 0) {
+    if (http->request->storeId().cmp(e->mem_obj->storeId()) != 0) {
         debugs(33, DBG_IMPORTANT, "clientProcessHit: URL mismatch, '" << e->mem_obj->storeId() << "' != '" << http->request->storeId() << "'");
         http->logType = LOG_TCP_MISS; // we lack a more precise LOG_*_MISS code
         processMiss();
@@ -637,7 +655,7 @@ clientReplyContext::processMiss()
     if (http->storeEntry()) {
         if (EBIT_TEST(http->storeEntry()->flags, ENTRY_SPECIAL)) {
             debugs(88, DBG_CRITICAL, "clientProcessMiss: miss on a special object (" << url << ").");
-            debugs(88, DBG_CRITICAL, "\tlog_type = " << LogTags_str[http->logType]);
+            debugs(88, DBG_CRITICAL, "\tlog_type = " << http->logType.c_str());
             http->storeEntry()->dump(1);
         }
 
@@ -786,7 +804,7 @@ clientReplyContext::blockedHit() const
         return false; // internal content "hits" cannot be blocked
 
     if (const HttpReply *rep = http->storeEntry()->getReply()) {
-        std::auto_ptr<ACLFilledChecklist> chl(clientAclChecklistCreate(Config.accessList.sendHit, http));
+        std::unique_ptr<ACLFilledChecklist> chl(clientAclChecklistCreate(Config.accessList.sendHit, http));
         chl->reply = const_cast<HttpReply*>(rep); // ACLChecklist API bug
         HTTPMSGLOCK(chl->reply);
         return chl->fastCheck() != ACCESS_ALLOWED; // when in doubt, block
@@ -849,8 +867,9 @@ purgeEntriesByUrl(HttpRequest * req, const char *url)
 void
 clientReplyContext::purgeAllCached()
 {
-    const char *url = urlCanonical(http->request);
-    purgeEntriesByUrl(http->request, url);
+    // XXX: performance regression, c_str() reallocates
+    SBuf url(http->request->effectiveRequestUri());
+    purgeEntriesByUrl(http->request, url.c_str());
 }
 
 void
@@ -938,7 +957,7 @@ clientReplyContext::purgeRequest()
     }
 
     /* Release both IP cache */
-    ipcacheInvalidate(http->request->GetHost());
+    ipcacheInvalidate(http->request->url.host());
 
     if (!http->flags.purging)
         purgeRequestFindObjectToPurge();
@@ -979,7 +998,7 @@ void
 clientReplyContext::purgeDoPurgeHead(StoreEntry *newEntry)
 {
     if (newEntry && !newEntry->isNull()) {
-        debugs(88, 4, "clientPurgeRequest: HEAD '" << newEntry->url() << "'" );
+        debugs(88, 4, "HEAD " << newEntry->url());
 #if USE_HTCP
         neighborsHtcpClear(newEntry, NULL, http->request, HttpRequestMethod(Http::METHOD_HEAD), HTCP_CLR_PURGE);
 #endif
@@ -991,21 +1010,23 @@ clientReplyContext::purgeDoPurgeHead(StoreEntry *newEntry)
 
     if (http->request->vary_headers
             && !strstr(http->request->vary_headers, "=")) {
-        StoreEntry *entry = storeGetPublic(urlCanonical(http->request), Http::METHOD_GET);
+        // XXX: performance regression, c_str() reallocates
+        SBuf tmp(http->request->effectiveRequestUri());
+        StoreEntry *entry = storeGetPublic(tmp.c_str(), Http::METHOD_GET);
 
         if (entry) {
-            debugs(88, 4, "clientPurgeRequest: Vary GET '" << entry->url() << "'" );
+            debugs(88, 4, "Vary GET " << entry->url());
 #if USE_HTCP
             neighborsHtcpClear(entry, NULL, http->request, HttpRequestMethod(Http::METHOD_GET), HTCP_CLR_PURGE);
 #endif
             entry->release();
             purgeStatus = Http::scOkay;
         }
 
-        entry = storeGetPublic(urlCanonical(http->request), Http::METHOD_HEAD);
+        entry = storeGetPublic(tmp.c_str(), Http::METHOD_HEAD);
 
         if (entry) {
-            debugs(88, 4, "clientPurgeRequest: Vary HEAD '" << entry->url() << "'" );
+            debugs(88, 4, "Vary HEAD " << entry->url());
 #if USE_HTCP
             neighborsHtcpClear(entry, NULL, http->request, HttpRequestMethod(Http::METHOD_HEAD), HTCP_CLR_PURGE);
 #endif
@@ -1288,7 +1309,7 @@ void
 clientReplyContext::buildReplyHeader()
 {
     HttpHeader *hdr = &reply->header;
-    int is_hit = logTypeIsATcpHit(http->logType);
+    const bool is_hit = http->logType.isTcpHit();
     HttpRequest *request = http->request;
 #if DONT_FILTER_THESE
     /* but you might want to if you run Squid as an HTTP accelerator */
@@ -1389,14 +1410,14 @@ clientReplyContext::buildReplyHeader()
     }
 
     // add Warnings required by RFC 2616 if serving a stale hit
-    if (http->request->flags.staleIfHit && logTypeIsATcpHit(http->logType)) {
+    if (http->request->flags.staleIfHit && http->logType.isTcpHit()) {
         hdr->putWarning(110, "Response is stale");
         if (http->request->flags.needValidation)
             hdr->putWarning(111, "Revalidation failed");
     }
 
     /* Filter unproxyable authentication types */
-    if (http->logType != LOG_TCP_DENIED &&
+    if (http->logType.oldType != LOG_TCP_DENIED &&
             hdr->has(HDR_WWW_AUTHENTICATE)) {
         HttpHeaderPos pos = HttpHeaderInitPos;
         HttpHeaderEntry *e;
@@ -1440,7 +1461,7 @@ clientReplyContext::buildReplyHeader()
 
 #if USE_AUTH
     /* Handle authentication headers */
-    if (http->logType == LOG_TCP_DENIED &&
+    if (http->logType.oldType == LOG_TCP_DENIED &&
             ( reply->sline.status() == Http::scProxyAuthenticationRequired ||
               reply->sline.status() == Http::scUnauthorized)
        ) {
@@ -1504,10 +1525,6 @@ clientReplyContext::buildReplyHeader()
             // The listening port closed because of a reconfigure
             debugs(88, 3, "listening port closed");
             request->flags.proxyKeepalive = false;
-        } else if (Config.Timeout.pconnLifetime && conn->clientConnection->lifeTime() > Config.Timeout.pconnLifetime && conn->getConcurrentRequestCount() <= 1) {
-            // The persistent connection lifetime exceeded and we are the last parsed request
-            debugs(88, 3, "persistent connection lifetime exceeded");
-            request->flags.proxyKeepalive = false;
         }
     }
 
@@ -1630,7 +1647,7 @@ clientReplyContext::identifyFoundObject(StoreEntry *newEntry)
       * 'invalidate' the cached IP entries for this request ???
       */
     if (r->flags.noCache || r->flags.noCacheHack())
-        ipcacheInvalidateNegative(r->GetHost());
+        ipcacheInvalidateNegative(r->url.host());
 
 #if USE_CACHE_DIGESTS
     lookup_type = http->storeEntry() ? "HIT" : "MISS";
@@ -1781,7 +1798,7 @@ clientReplyContext::doGetMoreData()
         sc->setDelayId(DelayId::DelayClient(http));
 #endif
 
-        assert(http->logType == LOG_TCP_HIT);
+        assert(http->logType.oldType == LOG_TCP_HIT);
         reqofs = 0;
         /* guarantee nothing has been sent yet! */
         assert(http->out.size == 0);
@@ -1958,8 +1975,8 @@ clientReplyContext::processReplyAccess ()
     assert(reply);
 
     /** Don't block our own responses or HTTP status messages */
-    if (http->logType == LOG_TCP_DENIED ||
-            http->logType == LOG_TCP_DENIED_REPLY ||
+    if (http->logType.oldType == LOG_TCP_DENIED ||
+            http->logType.oldType == LOG_TCP_DENIED_REPLY ||
             alwaysAllowResponse(reply->sline.status())) {
         headers_sz = reply->hdr_sz;
         processReplyAccessResult(ACCESS_ALLOWED);
@@ -2127,7 +2144,7 @@ clientReplyContext::sendMoreData (StoreIOBuffer result)
         memcpy(buf, result.data, result.length);
     }
 
-    if (reqofs==0 && !logTypeIsATcpHit(http->logType) && Comm::IsConnOpen(conn->clientConnection)) {
+    if (reqofs==0 && !http->logType.isTcpHit() && Comm::IsConnOpen(conn->clientConnection)) {
         if (Ip::Qos::TheConfig.isHitTosActive()) {
             Ip::Qos::doTosLocalMiss(conn->clientConnection, http->request->hier.code);
         }
@@ -83,17 +83,17 @@ class clientReplyContext : public RefCountable, public StoreClient
     int old_reqsize;        /* ... again, for the buffer */
     size_t reqsize;
     size_t reqofs;
-    char tempbuf[HTTP_REQBUF_SZ];   /* a temporary buffer if we need working storage */
+    char tempbuf[HTTP_REQBUF_SZ];   ///< a temporary buffer if we need working storage
 #if USE_CACHE_DIGESTS
 
     const char *lookup_type;    /* temporary hack: storeGet() result: HIT/MISS/NONE */
 #endif
 
-    struct {
+    struct Flags {
+        Flags() : storelogiccomplete(0), complete(0), headersSent(false) {}
 
         unsigned storelogiccomplete:1;
-
-        unsigned complete:1;        /* we have read all we can from upstream */
+        unsigned complete:1;        ///< we have read all we can from upstream
         bool headersSent;
     } flags;
     clientStreamNode *ourNode;  /* This will go away if/when this file gets refactored some more */
@@ -112,20 +112,33 @@ ClientRequestContext::~ClientRequestContext()
         cbdataReferenceDone(http);
 
     delete error;
-    debugs(85,3, HERE << this << " ClientRequestContext destructed");
+    debugs(85,3, "ClientRequestContext destructed, this=" << this);
 }
 
-ClientRequestContext::ClientRequestContext(ClientHttpRequest *anHttp) : http(cbdataReference(anHttp)), acl_checklist (NULL), redirect_state (REDIRECT_NONE), store_id_state(REDIRECT_NONE),error(NULL), readNextRequest(false)
-{
-    http_access_done = false;
-    redirect_done = false;
-    store_id_done = false;
-    no_cache_done = false;
-    interpreted_req_hdrs = false;
+ClientRequestContext::ClientRequestContext(ClientHttpRequest *anHttp) :
+    http(cbdataReference(anHttp)),
+    acl_checklist(NULL),
+    redirect_state(REDIRECT_NONE),
+    store_id_state(REDIRECT_NONE),
+    host_header_verify_done(false),
+    http_access_done(false),
+    adapted_http_access_done(false),
+#if USE_ADAPTATION
+    adaptation_acl_check_done(false),
+#endif
+    redirect_done(false),
+    store_id_done(false),
+    no_cache_done(false),
+    interpreted_req_hdrs(false),
+    tosToClientDone(false),
+    nfmarkToClientDone(false),
 #if USE_OPENSSL
-    sslBumpCheckDone = false;
+    sslBumpCheckDone(false),
 #endif
-    debugs(85,3, HERE << this << " ClientRequestContext constructed");
+    error(NULL),
+    readNextRequest(false)
+{
+    debugs(85, 3, "ClientRequestContext constructed, this=" << this);
 }
 
 CBDATA_CLASS_INIT(ClientHttpRequest);
@@ -134,7 +147,23 @@ ClientHttpRequest::ClientHttpRequest(ConnStateData * aConn) :
 #if USE_ADAPTATION
     AsyncJob("ClientHttpRequest"),
 #endif
-    loggingEntry_(NULL)
+    request(NULL),
+    uri(NULL),
+    log_uri(NULL),
+    req_sz(0),
+    logType(LOG_TAG_NONE),
+    calloutContext(NULL),
+    maxReplyBodySize_(0),
+    entry_(NULL),
+    loggingEntry_(NULL),
+    conn_(NULL)
+#if USE_OPENSSL
+    , sslBumpNeed_(Ssl::bumpEnd)
+#endif
+#if USE_ADAPTATION
+    , request_satisfaction_mode(false)
+    , request_satisfaction_offset(0)
+#endif
 {
     setConn(aConn);
     al = new AccessLogEntry;
@@ -145,17 +174,11 @@ ClientHttpRequest::ClientHttpRequest(ConnStateData * aConn) :
 
 #if USE_OPENSSL
     if (aConn->clientConnection != NULL && aConn->clientConnection->isOpen()) {
-        if (SSL *ssl = fd_table[aConn->clientConnection->fd].ssl)
+        if (auto ssl = fd_table[aConn->clientConnection->fd].ssl)
             al->cache.sslClientCert.reset(SSL_get_peer_certificate(ssl));
     }
 #endif
     dlinkAdd(this, &active, &ClientActiveRequests);
-#if USE_ADAPTATION
-    request_satisfaction_mode = false;
-#endif
-#if USE_OPENSSL
-    sslBumpNeed_ = Ssl::bumpEnd;
-#endif
 }
 
 /*
@@ -251,7 +274,6 @@ ClientHttpRequest::~ClientHttpRequest()
     /* the ICP check here was erroneous
      * - StoreEntry::releaseRequest was always called if entry was valid
      */
-    assert(logType < LOG_TYPE_MAX);
 
     logRequest();
 
@@ -537,7 +559,7 @@ ClientRequestContext::hostHeaderVerifyFailed(const char *A, const char *B)
     // NP: we do not yet handle CONNECT tunnels well, so ignore for them
     if (!Config.onoff.hostStrictVerify && http->request->method != Http::METHOD_CONNECT) {
         debugs(85, 3, "SECURITY ALERT: Host header forgery detected on " << http->getConn()->clientConnection <<
-               " (" << A << " does not match " << B << ") on URL: " << urlCanonical(http->request));
+               " (" << A << " does not match " << B << ") on URL: " << http->request->effectiveRequestUri());
 
         // NP: it is tempting to use 'flags.noCache' but that is all about READing cache data.
         // The problems here are about WRITE for new cache content, which means flags.cachable
@@ -552,7 +574,7 @@ ClientRequestContext::hostHeaderVerifyFailed(const char *A, const char *B)
     debugs(85, DBG_IMPORTANT, "SECURITY ALERT: Host header forgery detected on " <<
            http->getConn()->clientConnection << " (" << A << " does not match " << B << ")");
     debugs(85, DBG_IMPORTANT, "SECURITY ALERT: By user agent: " << http->request->header.getStr(HDR_USER_AGENT));
-    debugs(85, DBG_IMPORTANT, "SECURITY ALERT: on URL: " << urlCanonical(http->request));
+    debugs(85, DBG_IMPORTANT, "SECURITY ALERT: on URL: " << http->request->effectiveRequestUri());
 
     // IP address validation for Host: failed. reject the connection.
     clientStreamNode *node = (clientStreamNode *)http->client_stream.tail->prev->data;
@@ -625,11 +647,11 @@ ClientRequestContext::hostHeaderVerify()
         }
     }
 
-    debugs(85, 3, HERE << "validate host=" << host << ", port=" << port << ", portStr=" << (portStr?portStr:"NULL"));
+    debugs(85, 3, "validate host=" << host << ", port=" << port << ", portStr=" << (portStr?portStr:"NULL"));
     if (http->request->flags.intercepted || http->request->flags.interceptTproxy) {
         // verify the Host: port (if any) matches the apparent destination
         if (portStr && port != http->getConn()->clientConnection->local.port()) {
-            debugs(85, 3, HERE << "FAIL on validate port " << http->getConn()->clientConnection->local.port() <<
+            debugs(85, 3, "FAIL on validate port " << http->getConn()->clientConnection->local.port() <<
                    " matches Host: port " << port << " (" << portStr << ")");
             hostHeaderVerifyFailed("intercepted port", portStr);
         } else {
@@ -639,28 +661,28 @@ ClientRequestContext::hostHeaderVerify()
             ipcache_nbgethostbyname(host, hostHeaderIpVerifyWrapper, this);
         }
     } else if (!Config.onoff.hostStrictVerify) {
-        debugs(85, 3, HERE << "validate skipped.");
+        debugs(85, 3, "validate skipped.");
         http->doCallouts();
-    } else if (strlen(host) != strlen(http->request->GetHost())) {
+    } else if (strlen(host) != strlen(http->request->url.host())) {
         // Verify forward-proxy requested URL domain matches the Host: header
-        debugs(85, 3, HERE << "FAIL on validate URL domain length " << http->request->GetHost() << " matches Host: " << host);
-        hostHeaderVerifyFailed(host, http->request->GetHost());
-    } else if (matchDomainName(host, http->request->GetHost()) != 0) {
+        debugs(85, 3, "FAIL on validate URL domain length " << http->request->url.host() << " matches Host: " << host);
+        hostHeaderVerifyFailed(host, http->request->url.host());
+    } else if (matchDomainName(host, http->request->url.host()) != 0) {
         // Verify forward-proxy requested URL domain matches the Host: header
-        debugs(85, 3, HERE << "FAIL on validate URL domain " << http->request->GetHost() << " matches Host: " << host);
-        hostHeaderVerifyFailed(host, http->request->GetHost());
-    } else if (portStr && port != http->request->port) {
+        debugs(85, 3, "FAIL on validate URL domain " << http->request->url.host() << " matches Host: " << host);
+        hostHeaderVerifyFailed(host, http->request->url.host());
+    } else if (portStr && port != http->request->url.port()) {
         // Verify forward-proxy requested URL domain matches the Host: header
-        debugs(85, 3, HERE << "FAIL on validate URL port " << http->request->port << " matches Host: port " << portStr);
+        debugs(85, 3, "FAIL on validate URL port " << http->request->url.port() << " matches Host: port " << portStr);
         hostHeaderVerifyFailed("URL port", portStr);
-    } else if (!portStr && http->request->method != Http::METHOD_CONNECT && http->request->port != urlDefaultPort(http->request->url.getScheme())) {
+    } else if (!portStr && http->request->method != Http::METHOD_CONNECT && http->request->url.port() != http->request->url.getScheme().defaultPort()) {
         // Verify forward-proxy requested URL domain matches the Host: header
         // Special case: we don't have a default-port to check for CONNECT. Assume URL is correct.
-        debugs(85, 3, "FAIL on validate URL port " << http->request->port << " matches Host: default port " << urlDefaultPort(http->request->url.getScheme()));
+        debugs(85, 3, "FAIL on validate URL port " << http->request->url.port() << " matches Host: default port " << http->request->url.getScheme().defaultPort());
         hostHeaderVerifyFailed("URL port", "default port");
     } else {
         // Okay no problem.
-        debugs(85, 3, HERE << "validate passed.");
+        debugs(85, 3, "validate passed.");
         http->request->flags.hostVerified = true;
         http->doCallouts();
     }
@@ -812,9 +834,8 @@ ClientRequestContext::clientAccessCheckDone(const allow_t &answer)
 
     /* ACCESS_ALLOWED continues here ... */
     safe_free(http->uri);
-
-    http->uri = xstrdup(urlCanonical(http->request));
-
+    const SBuf tmp(http->request->effectiveRequestUri());
+    http->uri = xstrndup(tmp.rawContent(), tmp.length()+1);
     http->doCallouts();
 }
 
@@ -1278,7 +1299,7 @@ ClientRequestContext::clientRedirectDone(const Helper::Reply &reply)
                 // XXX: the clone() should be done only AFTER we know the new URL is valid.
                 HttpRequest *new_request = old_request->clone();
                 if (urlParse(old_request->method, const_cast<char*>(urlNote), new_request)) {
-                    debugs(61,2, HERE << "URL-rewriter diverts URL from " << urlCanonical(old_request) << " to " << urlCanonical(new_request));
+                    debugs(61, 2, "URL-rewriter diverts URL from " << old_request->effectiveRequestUri() << " to " << new_request->effectiveRequestUri());
 
                     // update the new request to flag the re-writing was done on it
                     new_request->flags.redirected = true;
@@ -1292,7 +1313,8 @@ ClientRequestContext::clientRedirectDone(const Helper::Reply &reply)
 
                     // update the current working ClientHttpRequest fields
                     safe_free(http->uri);
-                    http->uri = xstrdup(urlCanonical(new_request));
+                    const SBuf tmp(new_request->effectiveRequestUri());
+                    http->uri = xstrndup(tmp.rawContent(), tmp.length()+1);
                     HTTPMSGUNLOCK(old_request);
                     http->request = new_request;
                     HTTPMSGLOCK(http->request);
@@ -1413,7 +1435,8 @@ ClientRequestContext::sslBumpAccessCheck()
     if (bumpMode != Ssl::bumpEnd) {
         debugs(85, 5, HERE << "SslBump already decided (" << bumpMode <<
                "), " << "ignoring ssl_bump for " << http->getConn());
-        http->sslBumpNeed(bumpMode); // for processRequest() to bump if needed
+        if (!http->getConn()->serverBump())
+            http->sslBumpNeed(bumpMode); // for processRequest() to bump if needed and not already bumped
         http->al->ssl.bumpMode = bumpMode; // inherited from bumped connection
         return false;
     }
@@ -1505,7 +1528,7 @@ ClientHttpRequest::httpStart()
 {
     PROF_start(httpStart);
     logType = LOG_TAG_NONE;
-    debugs(85, 4, LogTags_str[logType] << " for '" << uri << "'");
+    debugs(85, 4, logType.c_str() << " for '" << uri << "'");
 
     /* no one should have touched this */
     assert(out.offset == 0);
@@ -1783,8 +1806,9 @@ ClientHttpRequest::doCallouts()
 #endif
 
     if (calloutContext->error) {
-        const char *storeUri = request->storeId();
-        StoreEntry *e= storeCreateEntry(storeUri, storeUri, request->flags, request->method);
+        // XXX: prformance regression. c_str() reallocates
+        SBuf storeUri(request->storeId());
+        StoreEntry *e = storeCreateEntry(storeUri.c_str(), storeUri.c_str(), request->flags, request->method);
 #if USE_OPENSSL
         if (sslBumpNeeded()) {
             // We have to serve an error, so bump the client first.
@@ -1888,14 +1912,15 @@ ClientHttpRequest::handleAdaptedHeader(HttpMsg *msg)
         HTTPMSGLOCK(request);
 
         // update the new message to flag whether URL re-writing was done on it
-        if (strcmp(urlCanonical(request),uri) != 0)
+        if (request->effectiveRequestUri().cmp(uri) != 0)
             request->flags.redirected = 1;
 
         /*
          * Store the new URI for logging
          */
         xfree(uri);
-        uri = xstrdup(urlCanonical(request));
+        const SBuf tmp(request->effectiveRequestUri());
+        uri = xstrndup(tmp.rawContent(), tmp.length());
         setLogUri(this, urlCanonicalClean(request));
         assert(request->method.id());
     } else if (HttpReply *new_rep = dynamic_cast<HttpReply*>(msg)) {
@@ -72,7 +72,9 @@ class ClientHttpRequest
     char *log_uri;
     String store_id; /* StoreID for transactions where the request member is nil */
 
-    struct {
+    struct Out {
+        Out() : offset(0), size(0), headers_sz(0) {}
+
         int64_t offset;
         int64_t size;
         size_t headers_sz;
@@ -87,16 +89,18 @@ class ClientHttpRequest
 
     AccessLogEntry::Pointer al; ///< access.log entry
 
-    struct {
+    struct Flags {
+        Flags() : accel(false), internal(false), done_copying(false), purging(false) {}
+
         bool accel;
-        //bool intercepted; //XXX: it's apparently never used.
-        //bool spoof_client_ip; //XXX: it's apparently never used.
         bool internal;
         bool done_copying;
         bool purging;
     } flags;
 
-    struct {
+    struct Redirect {
+        Redirect() : status(Http::scNone), location(NULL) {}
+
         Http::StatusCode status;
         char *location;
     } redirect;
@@ -493,8 +493,9 @@ Client::maybePurgeOthers()
         return;
 
     // XXX: should we use originalRequest() here?
-    const char *reqUrl = urlCanonical(request);
-    debugs(88, 5, "maybe purging due to " << request->method << ' ' << reqUrl);
+    SBuf tmp(request->effectiveRequestUri());
+    const char *reqUrl = tmp.c_str();
+    debugs(88, 5, "maybe purging due to " << request->method << ' ' << tmp);
     purgeEntriesByUrl(request, reqUrl);
     purgeEntriesByHeader(request, reqUrl, theFinalReply, HDR_LOCATION);
     purgeEntriesByHeader(request, reqUrl, theFinalReply, HDR_CONTENT_LOCATION);
@@ -973,8 +974,43 @@ Client::storeReplyBody(const char *data, ssize_t len)
     currentOffset += len;
 }
 
-size_t Client::replyBodySpace(const MemBuf &readBuf,
-                              const size_t minSpace) const
+size_t
+Client::calcBufferSpaceToReserve(size_t space, const size_t wantSpace) const
+{
+    if (space < wantSpace) {
+        const size_t maxSpace = SBuf::maxSize; // absolute best
+        space = min(wantSpace, maxSpace); // do not promise more than asked
+    }
+
+#if USE_ADAPTATION
+    if (responseBodyBuffer) {
+        return 0;   // Stop reading if already overflowed waiting for ICAP to catch up
+    }
+
+    if (virginBodyDestination != NULL) {
+        /*
+         * BodyPipe buffer has a finite size limit.  We
+         * should not read more data from the network than will fit
+         * into the pipe buffer or we _lose_ what did not fit if
+         * the response ends sooner that BodyPipe frees up space:
+         * There is no code to keep pumping data into the pipe once
+         * response ends and serverComplete() is called.
+         */
+        const size_t adaptor_space = virginBodyDestination->buf().potentialSpaceSize();
+
+        debugs(11,9, "Client may read up to min(" <<
+               adaptor_space << ", " << space << ") bytes");
+
+        if (adaptor_space < space)
+            space = adaptor_space;
+    }
+#endif
+
+    return space;
+}
+
+size_t
+Client::replyBodySpace(const MemBuf &readBuf, const size_t minSpace) const
 {
     size_t space = readBuf.spaceSize(); // available space w/o heroic measures
     if (space < minSpace) {
@@ -143,7 +143,10 @@ class Client:
     void adaptOrFinalizeReply();
     void addVirginReplyBody(const char *buf, ssize_t len);
     void storeReplyBody(const char *buf, ssize_t len);
+    /// \deprecated use SBuf I/O API and calcBufferSpaceToReserve() instead
     size_t replyBodySpace(const MemBuf &readBuf, const size_t minSpace) const;
+    /// determine how much space the buffer needs to reserve
+    size_t calcBufferSpaceToReserve(const size_t space, const size_t wantSpace) const;
 
     void adjustBodyBytesRead(const int64_t delta);
 
@@ -509,6 +509,8 @@ Ftp::Client::handleEpsvReply(Ip::Address &remoteAddr)
             debugs(9, DBG_IMPORTANT, "WARNING: Server at " << ctrl.conn->remote << " sent unknown protocol negotiation hint: " << buf);
             return sendPassive();
         }
+        /* coverity[unreachable] */
+        /* safeguard against possible future bugs in above conditions */
         failed(ERR_FTP_FAILURE, 0);
         return false;
     }
@@ -587,10 +589,10 @@ Ftp::Client::sendEprt()
     /* RFC 2428 defines EPRT as IPv6 equivalent to IPv4 PORT command. */
     /* Which can be used by EITHER protocol. */
     debugs(9, 3, "Listening for FTP data connection on port" << comm_local_port(data.conn->fd) << " or port?" << data.conn->local.port());
-    mb.Printf("EPRT |%d|%s|%d|%s",
-              ( data.conn->local.isIPv6() ? 2 : 1 ),
-              data.conn->local.toStr(buf,MAX_IPSTRLEN),
-              comm_local_port(data.conn->fd), Ftp::crlf );
+    mb.appendf("EPRT |%d|%s|%d|%s",
+               ( data.conn->local.isIPv6() ? 2 : 1 ),
+               data.conn->local.toStr(buf,MAX_IPSTRLEN),
+               comm_local_port(data.conn->fd), Ftp::crlf );
 
     state = SENT_EPRT;
     writeCommand(mb.content());
@@ -647,7 +649,7 @@ Ftp::Client::sendPassive()
     case SENT_EPSV_ALL: /* EPSV ALL resulted in a bad response. Try ther EPSV methods. */
         if (ctrl.conn->local.isIPv6()) {
             debugs(9, 5, "FTP Channel is IPv6 (" << ctrl.conn->remote << ") attempting EPSV 2 after EPSV ALL has failed.");
-            mb.Printf("EPSV 2%s", Ftp::crlf);
+            mb.appendf("EPSV 2%s", Ftp::crlf);
             state = SENT_EPSV_2;
             break;
         }
@@ -656,7 +658,7 @@ Ftp::Client::sendPassive()
     case SENT_EPSV_2: /* EPSV IPv6 failed. Try EPSV IPv4 */
         if (ctrl.conn->local.isIPv4()) {
             debugs(9, 5, "FTP Channel is IPv4 (" << ctrl.conn->remote << ") attempting EPSV 1 after EPSV ALL has failed.");
-            mb.Printf("EPSV 1%s", Ftp::crlf);
+            mb.appendf("EPSV 1%s", Ftp::crlf);
             state = SENT_EPSV_1;
             break;
         } else if (Config.Ftp.epsv_all) {
@@ -668,7 +670,7 @@ Ftp::Client::sendPassive()
 
     case SENT_EPSV_1: /* EPSV options exhausted. Try PASV now. */
         debugs(9, 5, "FTP Channel (" << ctrl.conn->remote << ") rejects EPSV connection attempts. Trying PASV instead.");
-        mb.Printf("PASV%s", Ftp::crlf);
+        mb.appendf("PASV%s", Ftp::crlf);
         state = SENT_PASV;
         break;
 
@@ -680,21 +682,21 @@ Ftp::Client::sendPassive()
         }
         if (!doEpsv) {
             debugs(9, 5, "EPSV support manually disabled. Sending PASV for FTP Channel (" << ctrl.conn->remote <<")");
-            mb.Printf("PASV%s", Ftp::crlf);
+            mb.appendf("PASV%s", Ftp::crlf);
             state = SENT_PASV;
         } else if (Config.Ftp.epsv_all) {
             debugs(9, 5, "EPSV ALL manually enabled. Attempting with FTP Channel (" << ctrl.conn->remote <<")");
-            mb.Printf("EPSV ALL%s", Ftp::crlf);
+            mb.appendf("EPSV ALL%s", Ftp::crlf);
             state = SENT_EPSV_ALL;
         } else {
             if (ctrl.conn->local.isIPv6()) {
                 debugs(9, 5, "FTP Channel (" << ctrl.conn->remote << "). Sending default EPSV 2");
-                mb.Printf("EPSV 2%s", Ftp::crlf);
+                mb.appendf("EPSV 2%s", Ftp::crlf);
                 state = SENT_EPSV_2;
             }
             if (ctrl.conn->local.isIPv4()) {
                 debugs(9, 5, "Channel (" << ctrl.conn->remote <<"). Sending default EPSV 1");
-                mb.Printf("EPSV 1%s", Ftp::crlf);
+                mb.appendf("EPSV 1%s", Ftp::crlf);
                 state = SENT_EPSV_1;
             }
         }
@@ -771,7 +771,7 @@ Ftp::Gateway::htmlifyListEntry(const char *line)
     if (strlen(line) > 1024) {
         html = new MemBuf();
         html->init();
-        html->Printf("<tr><td colspan=\"5\">%s</td></tr>\n", line);
+        html->appendf("<tr><td colspan=\"5\">%s</td></tr>\n", line);
         return html;
     }
 
@@ -785,7 +785,7 @@ Ftp::Gateway::htmlifyListEntry(const char *line)
 
         html = new MemBuf();
         html->init();
-        html->Printf("<tr class=\"entry\"><td colspan=\"5\">%s</td></tr>\n", line);
+        html->appendf("<tr class=\"entry\"><td colspan=\"5\">%s</td></tr>\n", line);
 
         for (p = line; *p && xisspace(*p); ++p);
         if (*p && !xisspace(*p))
@@ -870,18 +870,18 @@ Ftp::Gateway::htmlifyListEntry(const char *line)
     /* construct the table row from parts. */
     html = new MemBuf();
     html->init();
-    html->Printf("<tr class=\"entry\">"
-                 "<td class=\"icon\"><a href=\"%s%s\">%s</a></td>"
-                 "<td class=\"filename\"><a href=\"%s%s\">%s</a></td>"
-                 "<td class=\"date\">%s</td>"
-                 "<td class=\"size\">%s</td>"
-                 "<td class=\"actions\">%s%s%s%s</td>"
-                 "</tr>\n",
-                 prefix, href, icon,
-                 prefix, href, html_quote(text),
-                 parts->date,
-                 size,
-                 chdir, view, download, link);
+    html->appendf("<tr class=\"entry\">"
+                  "<td class=\"icon\"><a href=\"%s%s\">%s</a></td>"
+                  "<td class=\"filename\"><a href=\"%s%s\">%s</a></td>"
+                  "<td class=\"date\">%s</td>"
+                  "<td class=\"size\">%s</td>"
+                  "<td class=\"actions\">%s%s%s%s</td>"
+                  "</tr>\n",
+                  prefix, href, icon,
+                  prefix, href, html_quote(text),
+                  parts->date,
+                  size,
+                  chdir, view, download, link);
 
     ftpListPartsFree(&parts);
     return html;
@@ -960,7 +960,7 @@ Ftp::Gateway::parseListing()
         if ( t != NULL) {
             debugs(9, 7, HERE << "listing append: t = {" << t->contentSize() << ", '" << t->content() << "'}");
             listing.append(t->content(), t->contentSize());
-//leak?            delete t;
+            delete t;
         }
     }
 
@@ -1081,35 +1081,33 @@ Ftp::Gateway::checkAuth(const HttpHeader * req_hdr)
     return 0;           /* different username */
 }
 
-static String str_type_eq;
 void
 Ftp::Gateway::checkUrlpath()
 {
-    int l;
-    size_t t;
+    static SBuf str_type_eq("type=");
+    auto t = request->url.path().rfind(';');
 
-    if (str_type_eq.size()==0) //hack. String doesn't support global-static
-        str_type_eq="type=";
-
-    if ((t = request->urlpath.rfind(';')) != String::npos) {
-        if (request->urlpath.substr(t+1,t+1+str_type_eq.size())==str_type_eq) {
-            typecode = (char)xtoupper(request->urlpath[t+str_type_eq.size()+1]);
-            request->urlpath.cut(t);
+    if (t != SBuf::npos) {
+        auto filenameEnd = t-1;
+        if (request->url.path().substr(++t).cmp(str_type_eq, str_type_eq.length()) == 0) {
+            t += str_type_eq.length();
+            typecode = (char)xtoupper(request->url.path()[t]);
+            request->url.path(request->url.path().substr(0,filenameEnd));
         }
     }
 
-    l = request->urlpath.size();
+    int l = request->url.path().length();
     /* check for null path */
 
     if (!l) {
         flags.isdir = 1;
         flags.root_dir = 1;
         flags.need_base_href = 1;   /* Work around broken browsers */
-    } else if (!request->urlpath.cmp("/%2f/")) {
+    } else if (!request->url.path().cmp("/%2f/")) {
         /* UNIX root directory */
         flags.isdir = 1;
         flags.root_dir = 1;
-    } else if ((l >= 1) && (request->urlpath[l - 1] == '/')) {
+    } else if ((l >= 1) && (request->url.path()[l-1] == '/')) {
         /* Directory URL, ending in / */
         flags.isdir = 1;
 
@@ -1130,36 +1128,26 @@ Ftp::Gateway::buildTitleUrl()
         title_url.append("@");
     }
 
-    title_url.append(request->GetHost());
-
-    if (request->port != urlDefaultPort(AnyP::PROTO_FTP)) {
-        title_url.append(":");
-        title_url.append(xitoa(request->port));
-    }
+    SBuf authority = request->url.authority(request->url.getScheme() != AnyP::PROTO_FTP);
 
-    title_url.append (request->urlpath);
+    title_url.append(authority.rawContent(), authority.length());
+    title_url.append(request->url.path().rawContent(), request->url.path().length());
 
     base_href = "ftp://";
 
     if (strcmp(user, "anonymous") != 0) {
         base_href.append(rfc1738_escape_part(user));
 
         if (password_url) {
-            base_href.append (":");
+            base_href.append(":");
             base_href.append(rfc1738_escape_part(password));
         }
 
         base_href.append("@");
     }
 
-    base_href.append(request->GetHost());
-
-    if (request->port != urlDefaultPort(AnyP::PROTO_FTP)) {
-        base_href.append(":");
-        base_href.append(xitoa(request->port));
-    }
-
-    base_href.append(request->urlpath);
+    base_href.append(authority.rawContent(), authority.length());
+    base_href.append(request->url.path().rawContent(), request->url.path().length());
     base_href.append("/");
 }
 
@@ -1176,8 +1164,8 @@ Ftp::Gateway::start()
 
     checkUrlpath();
     buildTitleUrl();
-    debugs(9, 5, HERE << "FD " << ctrl.conn->fd << " : host=" << request->GetHost() <<
-           ", path=" << request->urlpath << ", user=" << user << ", passwd=" << password);
+    debugs(9, 5, "FD " << ctrl.conn->fd << " : host=" << request->url.host() <<
+           ", path=" << request->url.path() << ", user=" << user << ", passwd=" << password);
     state = BEGIN;
     Ftp::Client::start();
 }
@@ -1307,10 +1295,10 @@ Ftp::Gateway::ftpRealm()
     /* This request is not fully authenticated */
     if (!request) {
         snprintf(realm, 8192, "FTP %s unknown", user);
-    } else if (request->port == 21) {
-        snprintf(realm, 8192, "FTP %s %s", user, request->GetHost());
+    } else if (request->url.port() == 21) {
+        snprintf(realm, 8192, "FTP %s %s", user, request->url.host());
     } else {
-        snprintf(realm, 8192, "FTP %s %s port %d", user, request->GetHost(), request->port);
+        snprintf(realm, 8192, "FTP %s %s port %d", user, request->url.host(), request->url.port());
     }
     return realm;
 }
@@ -1323,9 +1311,7 @@ ftpSendUser(Ftp::Gateway * ftpState)
         return;
 
     if (ftpState->proxy_host != NULL)
-        snprintf(cbuf, CTRL_BUFLEN, "USER %s@%s\r\n",
-                 ftpState->user,
-                 ftpState->request->GetHost());
+        snprintf(cbuf, CTRL_BUFLEN, "USER %s@%s\r\n", ftpState->user, ftpState->request->url.host());
     else
         snprintf(cbuf, CTRL_BUFLEN, "USER %s\r\n", ftpState->user);
 
@@ -1377,18 +1363,14 @@ ftpReadPass(Ftp::Gateway * ftpState)
 static void
 ftpSendType(Ftp::Gateway * ftpState)
 {
-    const char *t;
-    const char *filename;
-    char mode;
-
     /* check the server control channel is still available */
     if (!ftpState || !ftpState->haveControlChannel("ftpSendType"))
         return;
 
     /*
      * Ref section 3.2.2 of RFC 1738
      */
-    mode = ftpState->typecode;
+    char mode = ftpState->typecode;
 
     switch (mode) {
 
@@ -1406,9 +1388,10 @@ ftpSendType(Ftp::Gateway * ftpState)
         if (ftpState->flags.isdir) {
             mode = 'A';
         } else {
-            t = ftpState->request->urlpath.rpos('/');
-            filename = t ? t + 1 : ftpState->request->urlpath.termedBuf();
-            mode = mimeGetTransferMode(filename);
+            auto t = ftpState->request->url.path().rfind('/');
+            // XXX: performance regression, c_str() may reallocate
+            SBuf filename = ftpState->request->url.path().substr(t != SBuf::npos ? t + 1 : 0);
+            mode = mimeGetTransferMode(filename.c_str());
         }
 
         break;
@@ -1435,7 +1418,8 @@ ftpReadType(Ftp::Gateway * ftpState)
     debugs(9, 3, HERE << "code=" << code);
 
     if (code == 200) {
-        p = path = xstrdup(ftpState->request->urlpath.termedBuf());
+        const SBuf tmp = ftpState->request->url.path();
+        p = path = xstrndup(tmp.rawContent(),tmp.length());
 
         if (*p == '/')
             ++p;
@@ -1818,7 +1802,12 @@ ftpOpenListenSocket(Ftp::Gateway * ftpState, int fallback)
      */
     if (fallback) {
         int on = 1;
-        setsockopt(ftpState->ctrl.conn->fd, SOL_SOCKET, SO_REUSEADDR, (char *) &on, sizeof(on));
+        errno = 0;
+        if (setsockopt(ftpState->ctrl.conn->fd, SOL_SOCKET, SO_REUSEADDR,
+                       (char *) &on, sizeof(on)) == -1) {
+            // SO_REUSEADDR is only an optimization, no need to be verbose about error
+            debugs(9, 4, "setsockopt failed: " << xstrerror());
+        }
         ftpState->ctrl.conn->flags |= COMM_REUSEADDR;
         temp->flags |= COMM_REUSEADDR;
     } else {
@@ -2380,7 +2369,9 @@ ftpTrySlashHack(Ftp::Gateway * ftpState)
     safe_free(ftpState->filepath);
 
     /* Build the new path (urlpath begins with /) */
-    path = xstrdup(ftpState->request->urlpath.termedBuf());
+    const SBuf tmp = ftpState->request->url.path();
+    path = xstrndup(tmp.rawContent(), tmp.length());
+    path[tmp.length()] = '\0';
 
     rfc1738_unescape(path);
 
@@ -2431,17 +2422,17 @@ Ftp::Gateway::hackShortcut(FTPSM * nextState)
 static void
 ftpFail(Ftp::Gateway *ftpState)
 {
-    debugs(9, 6, HERE << "flags(" <<
+    const bool slashHack = ftpState->request->url.path().caseCmp("/%2f", 4)==0;
+    debugs(9, 6, "flags(" <<
            (ftpState->flags.isdir?"IS_DIR,":"") <<
            (ftpState->flags.try_slash_hack?"TRY_SLASH_HACK":"") << "), " <<
            "mdtm=" << ftpState->mdtm << ", size=" << ftpState->theSize <<
-           "slashhack=" << (ftpState->request->urlpath.caseCmp("/%2f", 4)==0? "T":"F") );
+           "slashhack=" << (slashHack? "T":"F"));
 
     /* Try the / hack to support "Netscape" FTP URL's for retreiving files */
     if (!ftpState->flags.isdir &&   /* Not a directory */
-            !ftpState->flags.try_slash_hack &&  /* Not in slash hack */
-            ftpState->mdtm <= 0 && ftpState->theSize < 0 && /* Not known as a file */
-            ftpState->request->urlpath.caseCmp("/%2f", 4) != 0) {   /* No slash encoded */
+            !ftpState->flags.try_slash_hack && !slashHack && /* Not doing slash hack */
+            ftpState->mdtm <= 0 && ftpState->theSize < 0) { /* Not known as a file */
 
         switch (ftpState->state) {
 
@@ -2544,12 +2535,6 @@ ftpSendReply(Ftp::Gateway * ftpState)
 void
 Ftp::Gateway::appendSuccessHeader()
 {
-    const char *mime_type = NULL;
-    const char *mime_enc = NULL;
-    String urlpath = request->urlpath;
-    const char *filename = NULL;
-    const char *t = NULL;
-
     debugs(9, 3, HERE);
 
     if (flags.http_header_sent)
@@ -2565,7 +2550,12 @@ Ftp::Gateway::appendSuccessHeader()
 
     entry->buffer();    /* released when done processing current data payload */
 
-    filename = (t = urlpath.rpos('/')) ? t + 1 : urlpath.termedBuf();
+    SBuf urlPath = request->url.path();
+    auto t = urlPath.rfind('/');
+    SBuf filename = urlPath.substr(t != SBuf::npos ? t : 0);
+
+    const char *mime_type = NULL;
+    const char *mime_enc = NULL;
 
     if (flags.isdir) {
         mime_type = "text/html";
@@ -2574,16 +2564,18 @@ Ftp::Gateway::appendSuccessHeader()
 
         case 'I':
             mime_type = "application/octet-stream";
-            mime_enc = mimeGetContentEncoding(filename);
+            // XXX: performance regression, c_str() may reallocate
+            mime_enc = mimeGetContentEncoding(filename.c_str());
             break;
 
         case 'A':
             mime_type = "text/plain";
             break;
 
         default:
-            mime_type = mimeGetContentType(filename);
-            mime_enc = mimeGetContentEncoding(filename);
+            // XXX: performance regression, c_str() may reallocate
+            mime_type = mimeGetContentType(filename.c_str());
+            mime_enc = mimeGetContentEncoding(filename.c_str());
             break;
         }
     }
@@ -2655,25 +2647,25 @@ Ftp::Gateway::ftpAuthRequired(HttpRequest * request, const char *realm)
     return newrep;
 }
 
-const char *
+const SBuf &
 Ftp::UrlWith2f(HttpRequest * request)
 {
-    String newbuf = "%2f";
+    SBuf newbuf("%2f");
 
-    if (request->url.getScheme() != AnyP::PROTO_FTP)
-        return NULL;
+    if (request->url.getScheme() != AnyP::PROTO_FTP) {
+        static const SBuf nil;
+        return nil;
+    }
 
-    if ( request->urlpath[0]=='/' ) {
-        newbuf.append(request->urlpath);
-        request->urlpath.absorb(newbuf);
-        safe_free(request->canonical);
-    } else if ( !strncmp(request->urlpath.termedBuf(), "%2f", 3) ) {
-        newbuf.append(request->urlpath.substr(1,request->urlpath.size()));
-        request->urlpath.absorb(newbuf);
-        safe_free(request->canonical);
+    if (request->url.path()[0] == '/') {
+        newbuf.append(request->url.path());
+        request->url.path(newbuf);
+    } else if (!request->url.path().startsWith(newbuf)) {
+        newbuf.append(request->url.path().substr(1));
+        request->url.path(newbuf);
     }
 
-    return urlCanonical(request);
+    return request->effectiveRequestUri();
 }
 
 void
@@ -11,6 +11,7 @@
 
 class FwdState;
 class HttpRequest;
+class SBuf;
 
 class AsyncJob;
 template <class Cbc> class CbcPointer;
@@ -35,7 +36,7 @@ AsyncJobPointer StartRelay(FwdState *const fwdState);
  *
  * \todo Should be a URL class API call.
  */
-const char *UrlWith2f(HttpRequest *);
+const SBuf &UrlWith2f(HttpRequest *);
 
 } // namespace Ftp
 
@@ -581,6 +581,11 @@ commUnsetConnTimeout(const Comm::ConnectionPointer &conn)
     return commSetConnTimeout(conn, -1, nil);
 }
 
+/**
+ * Connect socket FD to given remote address.
+ * If return value is an error flag (COMM_ERROR, ERR_CONNECT, ERR_PROTOCOL, etc.),
+ * then error code will also be returned in errno.
+ */
 int
 comm_connect_addr(int sock, const Ip::Address &address)
 {
@@ -621,54 +626,50 @@ comm_connect_addr(int sock, const Ip::Address &address)
     address.getAddrInfo(AI, F->sock_family);
 
     /* Establish connection. */
-    errno = 0;
+    int xerrno = 0;
 
     if (!F->flags.called_connect) {
         F->flags.called_connect = true;
         ++ statCounter.syscalls.sock.connects;
 
-        x = connect(sock, AI->ai_addr, AI->ai_addrlen);
-
-        // XXX: ICAP code refuses callbacks during a pending comm_ call
-        // Async calls development will fix this.
-        if (x == 0) {
-            x = -1;
-            errno = EINPROGRESS;
-        }
-
-        if (x < 0) {
-            debugs(5,5, "comm_connect_addr: sock=" << sock << ", addrinfo( " <<
+        errno = 0;
+        if ((x = connect(sock, AI->ai_addr, AI->ai_addrlen)) < 0) {
+            xerrno = errno;
+            debugs(5,5, "sock=" << sock << ", addrinfo(" <<
                    " flags=" << AI->ai_flags <<
                    ", family=" << AI->ai_family <<
                    ", socktype=" << AI->ai_socktype <<
                    ", protocol=" << AI->ai_protocol <<
                    ", &addr=" << AI->ai_addr <<
-                   ", addrlen=" << AI->ai_addrlen <<
-                   " )" );
-            debugs(5, 9, "connect FD " << sock << ": (" << x << ") " << xstrerror());
-            debugs(14,9, "connecting to: " << address );
+                   ", addrlen=" << AI->ai_addrlen << " )");
+            debugs(5, 9, "connect FD " << sock << ": (" << x << ") " << xstrerr(xerrno));
+            debugs(14,9, "connecting to: " << address);
+
+        } else if (x == 0) {
+            // XXX: ICAP code refuses callbacks during a pending comm_ call
+            // Async calls development will fix this.
+            x = -1;
+            xerrno = EINPROGRESS;
         }
+
     } else {
+        errno = 0;
 #if _SQUID_NEWSOS6_
         /* Makoto MATSUSHITA <matusita@ics.es.osaka-u.ac.jp> */
+        if (connect(sock, AI->ai_addr, AI->ai_addrlen) < 0)
+            xerrno = errno;
 
-        connect(sock, AI->ai_addr, AI->ai_addrlen);
-
-        if (errno == EINVAL) {
+        if (xerrno == EINVAL) {
             errlen = sizeof(err);
             x = getsockopt(sock, SOL_SOCKET, SO_ERROR, &err, &errlen);
-
             if (x >= 0)
-                errno = x;
+                xerrno = x;
         }
-
 #else
         errlen = sizeof(err);
-
         x = getsockopt(sock, SOL_SOCKET, SO_ERROR, &err, &errlen);
-
         if (x == 0)
-            errno = err;
+            xerrno = err;
 
 #if _SQUID_SOLARIS_
         /*
@@ -677,23 +678,24 @@ comm_connect_addr(int sock, const Ip::Address &address)
         * connect and just returns EPIPE.  Create a fake
         * error message for connect.   -- fenner@parc.xerox.com
         */
-        if (x < 0 && errno == EPIPE)
-            errno = ENOTCONN;
-
+        if (x < 0 && xerrno == EPIPE)
+            xerrno = ENOTCONN;
+        else
+            xerrno = errno;
 #endif
 #endif
-
     }
 
     Ip::Address::FreeAddr(AI);
 
     PROF_stop(comm_connect_addr);
 
-    if (errno == 0 || errno == EISCONN)
+    errno = xerrno;
+    if (xerrno == 0 || xerrno == EISCONN)
         status = Comm::OK;
-    else if (ignoreErrno(errno))
+    else if (ignoreErrno(xerrno))
         status = Comm::INPROGRESS;
-    else if (errno == EAFNOSUPPORT || errno == EINVAL)
+    else if (xerrno == EAFNOSUPPORT || xerrno == EINVAL)
         return Comm::ERR_PROTOCOL;
     else
         return Comm::COMM_ERROR;
@@ -708,6 +710,7 @@ comm_connect_addr(int sock, const Ip::Address &address)
         debugs(5, DBG_DATA, "comm_connect_addr: FD " << sock << " connection pending");
     }
 
+    errno = xerrno;
     return status;
 }
 
@@ -1894,7 +1897,7 @@ comm_open_uds(int sock_type,
     debugs(50, 5, HERE << "FD " << new_socket << " is a new socket");
 
     assert(!isOpen(new_socket));
-    fd_open(new_socket, FD_MSGHDR, NULL);
+    fd_open(new_socket, FD_MSGHDR, addr->sun_path);
 
     fdd_table[new_socket].close_file = NULL;
 
@@ -75,6 +75,14 @@ Comm::Connection::close()
 {
     if (isOpen()) {
         comm_close(fd);
+        noteClosure();
+    }
+}
+
+void
+Comm::Connection::noteClosure()
+{
+    if (isOpen()) {
         fd = -1;
         if (CachePeer *p=getPeer())
             peerConnClosed(p);
@@ -75,6 +75,9 @@ class Connection : public RefCountable
     /** Close any open socket. */
     void close();
 
+    /** Synchronize with Comm: Somebody closed our connection. */
+    void noteClosure();
+
     /** determine whether this object describes an active connection or not. */
     bool isOpen() const { return (fd >= 0); }
 
@@ -113,7 +113,7 @@ Comm::IoCallback::reset()
 void
 Comm::IoCallback::finish(Comm::Flag code, int xerrn)
 {
-    debugs(5, 3, HERE << "called for " << conn << " (" << code << ", " << xerrno << ")");
+    debugs(5, 3, "called for " << conn << " (" << code << ", " << xerrn << ")");
     assert(active());
 
     /* free data */
@@ -49,7 +49,7 @@
 #include <sys/epoll.h>
 #endif
 
-static int kdpfd;
+static int kdpfd = -1;
 static int max_poll_time = 1000;
 
 static struct epoll_event *pevents;
@@ -109,17 +109,13 @@ Comm::SetSelect(int fd, unsigned int type, PF * handler, void *client_data, time
     fde *F = &fd_table[fd];
     int epoll_ctl_type = 0;
 
-    struct epoll_event ev;
     assert(fd >= 0);
     debugs(5, 5, HERE << "FD " << fd << ", type=" << type <<
            ", handler=" << handler << ", client_data=" << client_data <<
            ", timeout=" << timeout);
 
-    if (RUNNING_ON_VALGRIND) {
-        /* Keep valgrind happy.. complains about uninitialized bytes otherwise */
-        memset(&ev, 0, sizeof(ev));
-    }
-    ev.events = 0;
+    struct epoll_event ev;
+    memset(&ev, 0, sizeof(ev));
     ev.data.fd = fd;
 
     if (!F->flags.open) {
@@ -82,7 +82,9 @@ Comm::ReadNow(CommIoCbParams &params, SBuf &buf)
 {
     /* Attempt a read */
     ++ statCounter.syscalls.sock.reads;
-    const SBuf::size_type sz = buf.spaceSize();
+    SBuf::size_type sz = buf.spaceSize();
+    if (params.size > 0 && params.size < sz)
+        sz = params.size;
     char *inbuf = buf.rawSpace(sz);
     errno = 0;
     const int retval = FD_READ_METHOD(params.conn->fd, inbuf, sz);
@@ -138,22 +140,22 @@ Comm::HandleRead(int fd, void *data)
     /* For legacy callers : Attempt a read */
     // Keep in sync with Comm::ReadNow()!
     ++ statCounter.syscalls.sock.reads;
-    errno = 0;
+    int xerrno = errno = 0;
     int retval = FD_READ_METHOD(fd, ccb->buf, ccb->size);
-    debugs(5, 3, "FD " << fd << ", size " << ccb->size << ", retval " << retval << ", errno " << errno);
+    xerrno = errno;
+    debugs(5, 3, "FD " << fd << ", size " << ccb->size << ", retval " << retval << ", errno " << xerrno);
 
     /* See if we read anything */
     /* Note - read 0 == socket EOF, which is a valid read */
     if (retval >= 0) {
         fd_bytes(fd, retval, FD_READ);
         ccb->offset = retval;
-        ccb->finish(Comm::OK, errno);
+        ccb->finish(Comm::OK, 0);
         return;
-
-    } else if (retval < 0 && !ignoreErrno(errno)) {
+    } else if (retval < 0 && !ignoreErrno(xerrno)) {
         debugs(5, 3, "comm_read_try: scheduling Comm::COMM_ERROR");
         ccb->offset = 0;
-        ccb->finish(Comm::COMM_ERROR, errno);
+        ccb->finish(Comm::COMM_ERROR, xerrno);
         return;
     };
 
@@ -32,6 +32,9 @@ bool MonitorsRead(int fd);
 /**
  * Perform a read(2) on a connection immediately.
  *
+ * If params.size is non-zero will limit size of the read to either
+ * the buffer free space or params.size, whichever is smallest.
+ *
  * The returned flag is also placed in params.flag.
  *
  * \retval Comm::OK          data has been read and placed in buf, amount in params.size
@@ -132,7 +132,7 @@ Comm::TcpAcceptor::status() const
 
     static MemBuf buf;
     buf.reset();
-    buf.Printf(" FD %d, %s",conn->fd, ipbuf);
+    buf.appendf(" FD %d, %s",conn->fd, ipbuf);
 
     const char *jobStatus = AsyncJob::status();
     buf.append(jobStatus, strlen(jobStatus));
@@ -150,10 +150,10 @@ Comm::TcpAcceptor::status() const
 void
 Comm::TcpAcceptor::setListen()
 {
-    errcode = 0; // reset local errno copy.
+    errcode = errno = 0;
     if (listen(conn->fd, Squid_MaxFD >> 2) < 0) {
-        debugs(50, DBG_CRITICAL, "ERROR: listen(" << status() << ", " << (Squid_MaxFD >> 2) << "): " << xstrerror());
         errcode = errno;
+        debugs(50, DBG_CRITICAL, "ERROR: listen(" << status() << ", " << (Squid_MaxFD >> 2) << "): " << xstrerr(errcode));
         return;
     }
 
@@ -366,6 +366,7 @@ Comm::TcpAcceptor::oldAccept(Comm::ConnectionPointer &details)
         if (clientdbEstablished(details->remote, 0) > Config.client_ip_max_connections) {
             debugs(50, DBG_IMPORTANT, "WARNING: " << details->remote << " attempting more than " << Config.client_ip_max_connections << " connections.");
             Ip::Address::FreeAddr(gai);
+            PROF_stop(comm_accept);
             return Comm::COMM_ERROR;
         }
     }
@@ -376,6 +377,7 @@ Comm::TcpAcceptor::oldAccept(Comm::ConnectionPointer &details)
     if (getsockname(sock, gai->ai_addr, &gai->ai_addrlen) != 0) {
         debugs(50, DBG_IMPORTANT, "ERROR: getsockname() failed to locate local-IP on " << details << ": " << xstrerror());
         Ip::Address::FreeAddr(gai);
+        PROF_stop(comm_accept);
         return Comm::COMM_ERROR;
     }
     details->local = *gai;
@@ -404,7 +406,9 @@ Comm::TcpAcceptor::oldAccept(Comm::ConnectionPointer &details)
 
     // Perform NAT or TPROXY operations to retrieve the real client/dest IP addresses
     if (conn->flags&(COMM_TRANSPARENT|COMM_INTERCEPTION) && !Ip::Interceptor.Lookup(details, conn)) {
+        debugs(50, DBG_IMPORTANT, "ERROR: NAT/TPROXY lookup failed to locate original IPs on " << details);
         // Failed.
+        PROF_stop(comm_accept);
         return Comm::COMM_ERROR;
     }
 
@@ -102,7 +102,9 @@ Comm::HandleWrite(int fd, void *data)
 #endif /* USE_DELAY_POOLS */
 
     /* actually WRITE data */
+    int xerrno = errno = 0;
     len = FD_WRITE_METHOD(fd, state->buf + state->offset, nleft);
+    xerrno = errno;
     debugs(5, 5, HERE << "write() returns " << len);
 
 #if USE_DELAY_POOLS
@@ -133,18 +135,18 @@ Comm::HandleWrite(int fd, void *data)
         if (nleft != 0)
             debugs(5, DBG_IMPORTANT, "FD " << fd << " write failure: connection closed with " << nleft << " bytes remaining.");
 
-        state->finish(nleft ? Comm::COMM_ERROR : Comm::OK, errno);
+        state->finish(nleft ? Comm::COMM_ERROR : Comm::OK, 0);
     } else if (len < 0) {
         /* An error */
         if (fd_table[fd].flags.socket_eof) {
-            debugs(50, 2, HERE << "FD " << fd << " write failure: " << xstrerror() << ".");
-            state->finish(nleft ? Comm::COMM_ERROR : Comm::OK, errno);
-        } else if (ignoreErrno(errno)) {
-            debugs(50, 9, HERE << "FD " << fd << " write failure: " << xstrerror() << ".");
+            debugs(50, 2, "FD " << fd << " write failure: " << xstrerr(xerrno) << ".");
+            state->finish(nleft ? Comm::COMM_ERROR : Comm::OK, xerrno);
+        } else if (ignoreErrno(xerrno)) {
+            debugs(50, 9, "FD " << fd << " write failure: " << xstrerr(xerrno) << ".");
             state->selectOrQueueWrite();
         } else {
-            debugs(50, 2, HERE << "FD " << fd << " write failure: " << xstrerror() << ".");
-            state->finish(nleft ? Comm::COMM_ERROR : Comm::OK, errno);
+            debugs(50, 2, "FD " << fd << " write failure: " << xstrerr(xerrno) << ".");
+            state->finish(nleft ? Comm::COMM_ERROR : Comm::OK, xerrno);
         }
     } else {
         /* A successful write, continue */
@@ -154,7 +156,7 @@ Comm::HandleWrite(int fd, void *data)
             /* Not done, reinstall the write handler and write some more */
             state->selectOrQueueWrite();
         } else {
-            state->finish(nleft ? Comm::OK : Comm::COMM_ERROR, errno);
+            state->finish(nleft ? Comm::OK : Comm::COMM_ERROR, 0);
         }
     }
 
@@ -468,7 +468,11 @@ _db_rotate_log(void)
         remove
         (to);
 #endif
-        rename(from, to);
+        errno = 0;
+        if (rename(from, to) == -1) {
+            const auto saved_errno = errno;
+            debugs(0, DBG_IMPORTANT, "log rotation failed: " << xstrerr(saved_errno));
+        }
     }
 
     /*
@@ -483,10 +487,18 @@ _db_rotate_log(void)
     if (Debug::rotateNumber > 0) {
         snprintf(to, MAXPATHLEN, "%s.%d", debug_log_file, 0);
 #if _SQUID_WINDOWS_
-        remove
-        (to);
+        errno = 0;
+        if (remove(to) == -1) {
+            const auto saved_errno = errno;
+            debugs(0, DBG_IMPORTANT, "removal of log file " << to << " failed: " << xstrerr(saved_errno));
+        }
 #endif
-        rename(debug_log_file, to);
+        errno = 0;
+        if (rename(debug_log_file, to) == -1) {
+            const auto saved_errno = errno;
+            debugs(0, DBG_IMPORTANT, "renaming file " << debug_log_file << " to "
+                   << to << "failed: " << xstrerr(saved_errno));
+        }
     }
 
     /* Close and reopen the log.  It may have been renamed "manually"
@@ -219,8 +219,13 @@ diskHandleWrite(int fd, void *)
 
     errno = 0;
 
-    if (fdd->write_q->file_offset != -1)
-        lseek(fd, fdd->write_q->file_offset, SEEK_SET); /* XXX ignore return? */
+    if (fdd->write_q->file_offset != -1) {
+        errno = 0;
+        if (lseek(fd, fdd->write_q->file_offset, SEEK_SET) == -1) {
+            debugs(50, DBG_IMPORTANT, "error in seek for fd " << fd << ": " << xstrerror());
+            // XXX: handle error?
+        }
+    }
 
     len = FD_WRITE_METHOD(fd,
                           fdd->write_q->buf + fdd->write_q->buf_offset,
@@ -421,7 +426,12 @@ diskHandleRead(int fd, void *data)
     {
 #endif
         debugs(6, 3, "diskHandleRead: FD " << fd << " seeking to offset " << ctrl_dat->offset);
-        lseek(fd, ctrl_dat->offset, SEEK_SET);  /* XXX ignore return? */
+        errno = 0;
+        if (lseek(fd, ctrl_dat->offset, SEEK_SET) == -1) {
+            // shouldn't happen, let's detect that
+            debugs(50, DBG_IMPORTANT, "error in seek for fd " << fd << ": " << xstrerror());
+            // XXX handle failures?
+        }
         ++ statCounter.syscalls.disk.seeks;
         F->disk.offset = ctrl_dat->offset;
     }
@@ -40,6 +40,7 @@
 #include <arpa/nameser.h>
 #endif
 #include <cerrno>
+#include <random>
 #if HAVE_RESOLV_H
 #include <resolv.h>
 #endif
@@ -1054,11 +1055,14 @@ idnsFindQuery(unsigned short id)
 }
 
 static unsigned short
-idnsQueryID(void)
+idnsQueryID()
 {
-    unsigned short id = squid_random() & 0xFFFF;
+    // NP: apparently ranlux are faster, but not quite as "proven"
+    static std::mt19937 mt(static_cast<uint32_t>(getCurrentTime() & 0xFFFFFFFF));
+    unsigned short id = mt() & 0xFFFF;
     unsigned short first_id = id;
 
+    // ensure temporal uniqueness by looking for an existing use
     while (idnsFindQuery(id)) {
         ++id;
 
@@ -12,8 +12,8 @@
 typedef enum {
     ERR_DETAIL_NONE,
     ERR_DETAIL_START = 100000, // to avoid clashes with most OS error numbers
-    ERR_DETAIL_REDIRECTOR_TIMEDOUT, // External redirector request timed-out
-    ERR_DETAIL_CLT_REQMOD_ABORT = ERR_DETAIL_START, // client-facing code detected transaction abort
+    ERR_DETAIL_REDIRECTOR_TIMEDOUT = ERR_DETAIL_START, // External redirector request timed-out
+    ERR_DETAIL_CLT_REQMOD_ABORT, // client-facing code detected transaction abort
     ERR_DETAIL_CLT_REQMOD_REQ_BODY, // client-facing code detected REQMOD request body adaptation failure
     ERR_DETAIL_CLT_REQMOD_RESP_BODY, // client-facing code detected REQMOD satisfaction reply body failure
     ERR_DETAIL_SRV_REQMOD_REQ_BODY, // server-facing code detected REQMOD request body abort
@@ -23,6 +23,7 @@ typedef enum {
     ERR_DETAIL_RESPMOD_BLOCK_EARLY, // RESPMOD denied client access to HTTP response, before any part of the response was sent
     ERR_DETAIL_RESPMOD_BLOCK_LATE, // RESPMOD denied client access to HTTP response, after [a part of] the response was sent
     ERR_DETAIL_ICAP_XACT_START, // transaction start failure
+    ERR_DETAIL_ICAP_XACT_SSL_START, // transaction start failure
     ERR_DETAIL_ICAP_XACT_BODY_CONSUMER_ABORT, // transaction body consumer gone
     ERR_DETAIL_ICAP_INIT_GONE, // initiator gone
     ERR_DETAIL_ICAP_XACT_CLOSE, // ICAP connection closed unexpectedly
@@ -204,7 +204,7 @@ errorInitialize(void)
     if (Config.errorStylesheet) {
         ErrorPageFile tmpl("StylesSheet", ERR_MAX);
         tmpl.loadFromFile(Config.errorStylesheet);
-        error_stylesheet.Printf("%s",tmpl.text());
+        error_stylesheet.appendf("%s",tmpl.text());
     }
 
 #if USE_OPENSSL
@@ -702,72 +702,61 @@ ErrorState::Dump(MemBuf * mb)
 
     str.reset();
     /* email subject line */
-    str.Printf("CacheErrorInfo - %s", errorPageName(type));
-    mb->Printf("?subject=%s", rfc1738_escape_part(str.buf));
+    str.appendf("CacheErrorInfo - %s", errorPageName(type));
+    mb->appendf("?subject=%s", rfc1738_escape_part(str.buf));
     str.reset();
     /* email body */
-    str.Printf("CacheHost: %s\r\n", getMyHostname());
+    str.appendf("CacheHost: %s\r\n", getMyHostname());
     /* - Err Msgs */
-    str.Printf("ErrPage: %s\r\n", errorPageName(type));
+    str.appendf("ErrPage: %s\r\n", errorPageName(type));
 
     if (xerrno) {
-        str.Printf("Err: (%d) %s\r\n", xerrno, strerror(xerrno));
+        str.appendf("Err: (%d) %s\r\n", xerrno, strerror(xerrno));
     } else {
-        str.Printf("Err: [none]\r\n");
+        str.append("Err: [none]\r\n", 13);
     }
 #if USE_AUTH
     if (auth_user_request.getRaw() && auth_user_request->denyMessage())
-        str.Printf("Auth ErrMsg: %s\r\n", auth_user_request->denyMessage());
+        str.appendf("Auth ErrMsg: %s\r\n", auth_user_request->denyMessage());
 #endif
     if (dnsError.size() > 0)
-        str.Printf("DNS ErrMsg: %s\r\n", dnsError.termedBuf());
+        str.appendf("DNS ErrMsg: %s\r\n", dnsError.termedBuf());
 
     /* - TimeStamp */
-    str.Printf("TimeStamp: %s\r\n\r\n", mkrfc1123(squid_curtime));
+    str.appendf("TimeStamp: %s\r\n\r\n", mkrfc1123(squid_curtime));
 
     /* - IP stuff */
-    str.Printf("ClientIP: %s\r\n", src_addr.toStr(ntoabuf,MAX_IPSTRLEN));
+    str.appendf("ClientIP: %s\r\n", src_addr.toStr(ntoabuf,MAX_IPSTRLEN));
 
     if (request && request->hier.host[0] != '\0') {
-        str.Printf("ServerIP: %s\r\n", request->hier.host);
+        str.appendf("ServerIP: %s\r\n", request->hier.host);
     }
 
-    str.Printf("\r\n");
+    str.append("\r\n", 2);
     /* - HTTP stuff */
-    str.Printf("HTTP Request:\r\n");
-
-    if (NULL != request) {
-        Packer pck;
-        String urlpath_or_slash;
-
-        if (request->urlpath.size() != 0)
-            urlpath_or_slash = request->urlpath;
-        else
-            urlpath_or_slash = "/";
-
-        str.Printf(SQUIDSBUFPH " " SQUIDSTRINGPH " %s/%d.%d\n",
-                   SQUIDSBUFPRINT(request->method.image()),
-                   SQUIDSTRINGPRINT(urlpath_or_slash),
-                   AnyP::ProtocolType_str[request->http_ver.protocol],
-                   request->http_ver.major, request->http_ver.minor);
-        packerToMemInit(&pck, &str);
-        request->header.packInto(&pck);
-        packerClean(&pck);
+    str.append("HTTP Request:\r\n", 15);
+    if (request) {
+        str.appendf(SQUIDSBUFPH " " SQUIDSBUFPH " %s/%d.%d\n",
+                    SQUIDSBUFPRINT(request->method.image()),
+                    SQUIDSBUFPRINT(request->url.path()),
+                    AnyP::ProtocolType_str[request->http_ver.protocol],
+                    request->http_ver.major, request->http_ver.minor);
+        request->header.packInto(&str);
     }
 
-    str.Printf("\r\n");
+    str.append("\r\n", 2);
     /* - FTP stuff */
 
     if (ftp.request) {
-        str.Printf("FTP Request: %s\r\n", ftp.request);
-        str.Printf("FTP Reply: %s\r\n", (ftp.reply? ftp.reply:"[none]"));
-        str.Printf("FTP Msg: ");
+        str.appendf("FTP Request: %s\r\n", ftp.request);
+        str.appendf("FTP Reply: %s\r\n", (ftp.reply? ftp.reply:"[none]"));
+        str.append("FTP Msg: ", 9);
         wordlistCat(ftp.server_msg, &str);
-        str.Printf("\r\n");
+        str.append("\r\n", 2);
     }
 
-    str.Printf("\r\n");
-    mb->Printf("&body=%s", rfc1738_escape_part(str.buf));
+    str.append("\r\n", 2);
+    mb->appendf("&body=%s", rfc1738_escape_part(str.buf));
     str.clean();
     return 0;
 }
@@ -798,12 +787,16 @@ ErrorState::Convert(char token, bool building_deny_info_url, bool allowRecursion
         break;
 
     case 'b':
-        mb.Printf("%d", getMyPort());
+        mb.appendf("%u", getMyPort());
         break;
 
     case 'B':
         if (building_deny_info_url) break;
-        p = request ? Ftp::UrlWith2f(request) : "[no URL]";
+        if (request) {
+            const SBuf &tmp = Ftp::UrlWith2f(request);
+            mb.append(tmp.rawContent(), tmp.length());
+        } else
+            p = "[no URL]";
         break;
 
     case 'c':
@@ -828,18 +821,18 @@ ErrorState::Convert(char token, bool building_deny_info_url, bool allowRecursion
         }
 #endif
         if (!mb.contentSize())
-            mb.Printf("[No Error Detail]");
+            mb.append("[No Error Detail]", 17);
         break;
 
     case 'e':
-        mb.Printf("%d", xerrno);
+        mb.appendf("%d", xerrno);
         break;
 
     case 'E':
         if (xerrno)
-            mb.Printf("(%d) %s", xerrno, strerror(xerrno));
+            mb.appendf("(%d) %s", xerrno, strerror(xerrno));
         else
-            mb.Printf("[No Error]");
+            mb.append("[No Error]", 10);
         break;
 
     case 'f':
@@ -872,21 +865,21 @@ ErrorState::Convert(char token, bool building_deny_info_url, bool allowRecursion
         break;
 
     case 'h':
-        mb.Printf("%s", getMyHostname());
+        mb.appendf("%s", getMyHostname());
         break;
 
     case 'H':
         if (request) {
             if (request->hier.host[0] != '\0') // if non-empty string.
                 p = request->hier.host;
             else
-                p = request->GetHost();
+                p = request->url.host();
         } else if (!building_deny_info_url)
             p = "[unknown host]";
         break;
 
     case 'i':
-        mb.Printf("%s", src_addr.toStr(ntoabuf,MAX_IPSTRLEN));
+        mb.appendf("%s", src_addr.toStr(ntoabuf,MAX_IPSTRLEN));
         break;
 
     case 'I':
@@ -905,7 +898,7 @@ ErrorState::Convert(char token, bool building_deny_info_url, bool allowRecursion
     case 'L':
         if (building_deny_info_url) break;
         if (Config.errHtmlText) {
-            mb.Printf("%s", Config.errHtmlText);
+            mb.appendf("%s", Config.errHtmlText);
             do_quote = 0;
         } else
             p = "[not available]";
@@ -914,7 +907,10 @@ ErrorState::Convert(char token, bool building_deny_info_url, bool allowRecursion
     case 'm':
         if (building_deny_info_url) break;
 #if USE_AUTH
-        p = auth_user_request->denyMessage("[not available]");
+        if (auth_user_request.getRaw())
+            p = auth_user_request->denyMessage("[not available]");
+        else
+            p = "[not available]";
 #else
         p = "-";
 #endif
@@ -936,7 +932,7 @@ ErrorState::Convert(char token, bool building_deny_info_url, bool allowRecursion
 
     case 'p':
         if (request) {
-            mb.Printf("%d", (int) request->port);
+            mb.appendf("%u", request->url.port());
         } else if (!building_deny_info_url) {
             p = "[unknown port]";
         }
@@ -952,27 +948,21 @@ ErrorState::Convert(char token, bool building_deny_info_url, bool allowRecursion
 
     case 'R':
         if (building_deny_info_url) {
-            p = (request->urlpath.size() != 0 ? request->urlpath.termedBuf() : "/");
-            no_urlescape = 1;
+            if (request != NULL) {
+                SBuf tmp = request->url.path();
+                p = tmp.c_str();
+                no_urlescape = 1;
+            } else
+                p = "[no request]";
             break;
         }
-        if (NULL != request) {
-            Packer pck;
-            String urlpath_or_slash;
-
-            if (request->urlpath.size() != 0)
-                urlpath_or_slash = request->urlpath;
-            else
-                urlpath_or_slash = "/";
-
-            mb.Printf(SQUIDSBUFPH " " SQUIDSTRINGPH " %s/%d.%d\n",
-                      SQUIDSBUFPRINT(request->method.image()),
-                      SQUIDSTRINGPRINT(urlpath_or_slash),
-                      AnyP::ProtocolType_str[request->http_ver.protocol],
-                      request->http_ver.major, request->http_ver.minor);
-            packerToMemInit(&pck, &mb);
-            request->header.packInto(&pck, true); //hide authorization data
-            packerClean(&pck);
+        if (request != NULL) {
+            mb.appendf(SQUIDSBUFPH " " SQUIDSBUFPH " %s/%d.%d\n",
+                       SQUIDSBUFPRINT(request->method.image()),
+                       SQUIDSBUFPRINT(request->url.path()),
+                       AnyP::ProtocolType_str[request->http_ver.protocol],
+                       request->http_ver.major, request->http_ver.minor);
+            request->header.packInto(&mb, true); //hide authorization data
         } else if (request_hdrs) {
             p = request_hdrs;
         } else {
@@ -983,7 +973,11 @@ ErrorState::Convert(char token, bool building_deny_info_url, bool allowRecursion
     case 's':
         /* for backward compat we make %s show the full URL. Drop this in some future release. */
         if (building_deny_info_url) {
-            p = request ? urlCanonical(request) : url;
+            if (request) {
+                const SBuf &tmp = request->effectiveRequestUri();
+                mb.append(tmp.rawContent(), tmp.length());
+            } else
+                p = url;
             debugs(0, DBG_CRITICAL, "WARNING: deny_info now accepts coded tags. Use %u to get the full URL instead of %s");
         } else
             p = visible_appname_string;
@@ -999,7 +993,7 @@ ErrorState::Convert(char token, bool building_deny_info_url, bool allowRecursion
             const int saved_id = page_id;
             page_id = ERR_SQUID_SIGNATURE;
             MemBuf *sign_mb = BuildContent();
-            mb.Printf("%s", sign_mb->content());
+            mb.append(sign_mb->content(), sign_mb->contentSize());
             sign_mb->clean();
             delete sign_mb;
             page_id = saved_id;
@@ -1011,15 +1005,15 @@ ErrorState::Convert(char token, bool building_deny_info_url, bool allowRecursion
         break;
 
     case 't':
-        mb.Printf("%s", Time::FormatHttpd(squid_curtime));
+        mb.appendf("%s", Time::FormatHttpd(squid_curtime));
         break;
 
     case 'T':
-        mb.Printf("%s", mkrfc1123(squid_curtime));
+        mb.appendf("%s", mkrfc1123(squid_curtime));
         break;
 
     case 'U':
-        /* Using the fake-https version of canonical so error pages see https:// */
+        /* Using the fake-https version of absolute-URI so error pages see https:// */
         /* even when the url-path cannot be shown as more than '*' */
         if (request)
             p = urlCanonicalFakeHttps(request);
@@ -1030,17 +1024,18 @@ ErrorState::Convert(char token, bool building_deny_info_url, bool allowRecursion
         break;
 
     case 'u':
-        if (request)
-            p = urlCanonical(request);
-        else if (url)
+        if (request) {
+            const SBuf &tmp = request->effectiveRequestUri();
+            mb.append(tmp.rawContent(), tmp.length());
+        } else if (url)
             p = url;
         else if (!building_deny_info_url)
             p = "[no URL]";
         break;
 
     case 'w':
         if (Config.adminEmail)
-            mb.Printf("%s", Config.adminEmail);
+            mb.appendf("%s", Config.adminEmail);
         else if (!building_deny_info_url)
             p = "[unknown]";
         break;
@@ -1055,7 +1050,7 @@ ErrorState::Convert(char token, bool building_deny_info_url, bool allowRecursion
     case 'x':
 #if USE_OPENSSL
         if (detail)
-            mb.Printf("%s", detail->errorName());
+            mb.appendf("%s", detail->errorName());
         else
 #endif
             if (!building_deny_info_url)
@@ -1085,7 +1080,7 @@ ErrorState::Convert(char token, bool building_deny_info_url, bool allowRecursion
         break;
 
     default:
-        mb.Printf("%%%c", token);
+        mb.appendf("%%%c", token);
         do_quote = 0;
         break;
     }
@@ -1119,12 +1114,12 @@ ErrorState::DenyInfoLocation(const char *name, HttpRequest *, MemBuf &result)
     while ((p = strchr(m, '%'))) {
         result.append(m, p - m);       /* copy */
         t = Convert(*++p, true, true);       /* convert */
-        result.Printf("%s", t);        /* copy */
+        result.appendf("%s", t);        /* copy */
         m = p + 1;                     /* advance */
     }
 
     if (*m)
-        result.Printf("%s", m);        /* copy tail */
+        result.appendf("%s", m);        /* copy tail */
 
     assert((size_t)result.contentSize() == strlen(result.content()));
 }
@@ -1144,7 +1139,7 @@ ErrorState::BuildHttpReply()
             status = httpStatus;
         else {
             // Use 307 for HTTP/1.1 non-GET/HEAD requests.
-            if (request->method != Http::METHOD_GET && request->method != Http::METHOD_HEAD && request->http_ver >= Http::ProtocolVersion(1,1))
+            if (request != NULL && request->method != Http::METHOD_GET && request->method != Http::METHOD_HEAD && request->http_ver >= Http::ProtocolVersion(1,1))
                 status = Http::scTemporaryRedirect;
         }
 
@@ -1278,12 +1273,12 @@ MemBuf *ErrorState::ConvertText(const char *text, bool allowRecursion)
     while ((p = strchr(m, '%'))) {
         content->append(m, p - m);  /* copy */
         const char *t = Convert(*++p, false, allowRecursion);   /* convert */
-        content->Printf("%s", t);   /* copy */
+        content->appendf("%s", t);   /* copy */
         m = p + 1;          /* advance */
     }
 
     if (*m)
-        content->Printf("%s", m);   /* copy tail */
+        content->appendf("%s", m);   /* copy tail */
 
     content->terminate();
 
@@ -9,7 +9,6 @@
 /* DEBUG: section 41    Event Processing */
 
 #include "squid.h"
-#include "compat/drand48.h"
 #include "event.h"
 #include "mgr/Registration.h"
 #include "profiler/Profiler.h"
@@ -18,6 +17,7 @@
 #include "tools.h"
 
 #include <cmath>
+#include <random>
 
 /* The list of event processes */
 
@@ -88,10 +88,14 @@ EventDialer::print(std::ostream &os) const
     os << ')';
 }
 
-ev_entry::ev_entry(char const * aName, EVH * aFunction, void * aArgument, double evWhen,
-                   int aWeight, bool haveArgument) : name(aName), func(aFunction),
-    arg(haveArgument ? cbdataReference(aArgument) : aArgument), when(evWhen), weight(aWeight),
-    cbdata(haveArgument)
+ev_entry::ev_entry(char const * aName, EVH * aFunction, void * aArgument, double evWhen, int aWeight, bool haveArg) :
+    name(aName),
+    func(aFunction),
+    arg(haveArg ? cbdataReference(aArgument) : aArgument),
+    when(evWhen),
+    weight(aWeight),
+    cbdata(haveArg),
+    next(NULL)
 {
 }
 
@@ -112,12 +116,12 @@ void
 eventAddIsh(const char *name, EVH * func, void *arg, double delta_ish, int weight)
 {
     if (delta_ish >= 3.0) {
-        const double two_third = (2.0 * delta_ish) / 3.0;
-        delta_ish = two_third + (drand48() * two_third);
-        /*
-         * I'm sure drand48() isn't portable.  Tell me what function
-         * you have that returns a random double value in the range 0,1.
-         */
+        // Default seed is fine. We just need values random enough
+        // relative to each other to prevent waves of synchronised activity.
+        static std::mt19937 rng;
+        auto third = (delta_ish/3.0);
+        std::uniform_real_distribution<> thirdIsh(delta_ish - third, delta_ish + third);
+        delta_ish = thirdIsh(rng);
     }
 
     eventAdd(name, func, arg, delta_ish, weight);
@@ -151,6 +151,7 @@ class external_acl
 CBDATA_CLASS_INIT(external_acl);
 
 external_acl::external_acl() :
+    next(NULL),
     ttl(DEFAULT_EXTERNAL_ACL_TTL),
     negative_ttl(-1),
     grace(1),
@@ -417,6 +418,10 @@ parse_externalAclHelper(external_acl ** list)
 #if USE_AUTH
         else if (strcmp(token, "%EXT_USER") == 0 || strcmp(token, "%ue") == 0)
             format->type = Format::LFT_USER_EXTERNAL;
+#endif
+#if USE_AUTH || defined(USE_OPENSSL) || defined(USE_IDENT)
+        else if (strcmp(token, "%un") == 0)
+            format->type = Format::LFT_USER_NAME;
 #endif
         else if (strcmp(token, "%EXT_LOG") == 0 || strcmp(token, "%ea") == 0)
             format->type = Format::LFT_EXT_LOG;
@@ -523,6 +528,7 @@ dump_externalAclHelper(StoreEntry * sentry, const char *name, const external_acl
                 break
 #if USE_AUTH
                 DUMP_EXT_ACL_TYPE_FMT(USER_LOGIN," %%ul");
+                DUMP_EXT_ACL_TYPE_FMT(USER_NAME," %%un");
 #endif
 #if USE_IDENT
 
@@ -717,6 +723,9 @@ copyResultsFromEntry(HttpRequest *req, const ExternalACLEntryPointer &entry)
 
         if (entry->message.size())
             req->extacl_message = entry->message;
+
+        // attach the helper kv-pair to the transaction
+        UpdateRequestNotes(req->clientConnectionManager.get(), *req, entry->notes);
     }
 }
 
@@ -883,6 +892,18 @@ external_acl_cache_touch(external_acl * def, const ExternalACLEntryPointer &entr
     dlinkAdd(e, &entry->lru, &def->lru_list);
 }
 
+#if USE_OPENSSL
+static const char *
+external_acl_ssl_get_user_attribute(const ACLFilledChecklist &ch, const char *attr)
+{
+    if (ch.conn() != NULL && Comm::IsConnOpen(ch.conn()->clientConnection)) {
+        if (SSL *ssl = fd_table[ch.conn()->clientConnection->fd].ssl)
+            return sslGetUserAttribute(ssl, attr);
+    }
+    return NULL;
+}
+#endif
+
 static char *
 makeExternalAclKey(ACLFilledChecklist * ch, external_acl_data * acl_data)
 {
@@ -958,25 +979,28 @@ makeExternalAclKey(ACLFilledChecklist * ch, external_acl_data * acl_data)
             break;
 
         case Format::LFT_CLIENT_REQ_URI:
-            str = urlCanonical(request);
+            snprintf(buf, sizeof(buf), SQUIDSBUFPH, SQUIDSBUFPRINT(request->effectiveRequestUri()));
+            str = buf;
             break;
 
         case Format::LFT_CLIENT_REQ_URLDOMAIN:
-            str = request->GetHost();
+            str = request->url.host();
             break;
 
         case Format::LFT_CLIENT_REQ_URLSCHEME:
             str = request->url.getScheme().c_str();
             break;
 
         case Format::LFT_CLIENT_REQ_URLPORT:
-            snprintf(buf, sizeof(buf), "%d", request->port);
+            snprintf(buf, sizeof(buf), "%u", request->url.port());
             str = buf;
             break;
 
-        case Format::LFT_CLIENT_REQ_URLPATH:
-            str = request->urlpath.termedBuf();
-            break;
+        case Format::LFT_CLIENT_REQ_URLPATH: {
+            SBuf tmp = request->url.path();
+            str = tmp.c_str();
+        }
+        break;
 
         case Format::LFT_CLIENT_REQ_METHOD: {
             const SBuf &s = request->method.image();
@@ -1026,9 +1050,7 @@ makeExternalAclKey(ACLFilledChecklist * ch, external_acl_data * acl_data)
         case Format::LFT_EXT_ACL_USER_CERT_RAW:
 
             if (ch->conn() != NULL && Comm::IsConnOpen(ch->conn()->clientConnection)) {
-                SSL *ssl = fd_table[ch->conn()->clientConnection->fd].ssl;
-
-                if (ssl)
+                if (auto ssl = fd_table[ch->conn()->clientConnection->fd].ssl)
                     str = sslGetUserCertificatePEM(ssl);
             }
 
@@ -1037,31 +1059,21 @@ makeExternalAclKey(ACLFilledChecklist * ch, external_acl_data * acl_data)
         case Format::LFT_EXT_ACL_USER_CERTCHAIN_RAW:
 
             if (ch->conn() != NULL && Comm::IsConnOpen(ch->conn()->clientConnection)) {
-                SSL *ssl = fd_table[ch->conn()->clientConnection->fd].ssl;
-
-                if (ssl)
+                if (auto ssl = fd_table[ch->conn()->clientConnection->fd].ssl)
                     str = sslGetUserCertificateChainPEM(ssl);
             }
 
             break;
 
         case Format::LFT_EXT_ACL_USER_CERT:
 
-            if (ch->conn() != NULL && Comm::IsConnOpen(ch->conn()->clientConnection)) {
-                SSL *ssl = fd_table[ch->conn()->clientConnection->fd].ssl;
-
-                if (ssl)
-                    str = sslGetUserAttribute(ssl, format->header);
-            }
-
+            str = external_acl_ssl_get_user_attribute(*ch, format->header);
             break;
 
         case Format::LFT_EXT_ACL_USER_CA_CERT:
 
             if (ch->conn() != NULL && Comm::IsConnOpen(ch->conn()->clientConnection)) {
-                SSL *ssl = fd_table[ch->conn()->clientConnection->fd].ssl;
-
-                if (ssl)
+                if (auto ssl = fd_table[ch->conn()->clientConnection->fd].ssl)
                     str = sslGetCAAttribute(ssl, format->header);
             }
 
@@ -1099,6 +1111,24 @@ makeExternalAclKey(ACLFilledChecklist * ch, external_acl_data * acl_data)
             str = request->extacl_user.termedBuf();
             break;
 #endif
+        case Format::LFT_USER_NAME:
+            /* find the first available name from various sources */
+#if USE_AUTH
+            if (ch->auth_user_request != NULL)
+                str = ch->auth_user_request->username();
+            if ((!str || !*str) &&
+                    (request->extacl_user.size() > 0 && request->extacl_user[0] != '-'))
+                str = request->extacl_user.termedBuf();
+#endif
+#if USE_OPENSSL
+            if (!str || !*str)
+                str = external_acl_ssl_get_user_attribute(*ch, "CN");
+#endif
+#if USE_IDENT
+            if (!str || !*str)
+                str = ch->rfc931;
+#endif
+            break;
         case Format::LFT_EXT_LOG:
             str = request->extacl_log.termedBuf();
             break;
@@ -1435,9 +1465,7 @@ ExternalACLLookup::Start(ACLChecklist *checklist, external_acl_data *acl, bool i
 
         MemBuf buf;
         buf.init();
-
-        buf.Printf("%s\n", key);
-
+        buf.appendf("%s\n", key);
         debugs(82, 4, "externalAclLookup: looking up for '" << key << "' in '" << def->name << "'.");
 
         if (!def->theHelper->trySubmit(buf.buf, externalAclHandleReply, state)) {
@@ -1462,7 +1490,8 @@ externalAclStats(StoreEntry * sentry)
     for (external_acl *p = Config.externalAclHelperList; p; p = p->next) {
         storeAppendPrintf(sentry, "External ACL Statistics: %s\n", p->name);
         storeAppendPrintf(sentry, "Cache size: %d\n", p->cache->count);
-        helperStats(sentry, p->theHelper);
+        assert(p->theHelper);
+        p->theHelper->packStatsInto(sentry);
         storeAppendPrintf(sentry, "\n");
     }
 }
@@ -1534,18 +1563,6 @@ ExternalACLLookup::LookupDone(void *data, const ExternalACLEntryPointer &result)
 {
     ACLFilledChecklist *checklist = Filled(static_cast<ACLChecklist*>(data));
     checklist->extacl_entry = result;
-
-    // attach the helper kv-pair to the transaction
-    if (checklist->extacl_entry != NULL) {
-        if (HttpRequest * req = checklist->request) {
-            // XXX: we have no access to the transaction / AccessLogEntry so cant SyncNotes().
-            // workaround by using anything already set in HttpRequest
-            // OR use new and rely on a later Sync copying these to AccessLogEntry
-
-            UpdateRequestNotes(checklist->conn(), *req, checklist->extacl_entry->notes);
-        }
-    }
-
     checklist->resumeNonBlockingCheck(ExternalACLLookup::Instance());
 }
 
@@ -242,8 +242,7 @@ fd_open(int fd, unsigned int type, const char *desc)
 
     fdUpdateBiggest(fd, 1);
 
-    if (desc)
-        xstrncpy(F->desc, desc, FD_DESC_SZ);
+    fd_note(fd, desc);
 
     ++Number_FD;
 }
@@ -252,7 +251,10 @@ void
 fd_note(int fd, const char *s)
 {
     fde *F = &fd_table[fd];
-    xstrncpy(F->desc, s, FD_DESC_SZ);
+    if (s)
+        xstrncpy(F->desc, s, FD_DESC_SZ);
+    else
+        *(F->desc) = 0; // ""-string
 }
 
 void
@@ -12,10 +12,7 @@
 #include "comm.h"
 #include "defines.h"
 #include "ip/Address.h"
-
-#if HAVE_OPENSSL_SSL_H
-#include <openssl/ssl.h>
-#endif
+#include "security/forward.h"
 
 #if USE_DELAY_POOLS
 class ClientInfo;
@@ -109,10 +106,8 @@ class fde
     CommWriteStateData *wstate;         /* State data for comm_write */
     READ_HANDLER *read_method;
     WRITE_HANDLER *write_method;
-#if USE_OPENSSL
-    SSL *ssl;
-    SSL_CTX *dynamicSslContext; ///< cached and then freed when fd is closed
-#endif
+    Security::SessionPointer ssl;
+    Security::ContextPointer dynamicSslContext; ///< cached and then freed when fd is closed
 #if _SQUID_WINDOWS_
     struct {
         long handle;
@@ -161,10 +156,8 @@ class fde
         wstate = NULL;
         read_method = NULL;
         write_method = NULL;
-#if USE_OPENSSL
         ssl = NULL;
         dynamicSslContext = NULL;
-#endif
 #if _SQUID_WINDOWS_
         win32.handle = (long)NULL;
 #endif
@@ -877,14 +877,7 @@ Format::Format::assemble(MemBuf &mb, const AccessLogEntry::Pointer &al, int logS
             break;
 
         case LFT_SQUID_STATUS:
-            if (al->http.timedout || al->http.aborted) {
-                snprintf(tmp, sizeof(tmp), "%s%s", LogTags_str[al->cache.code],
-                         al->http.statusSfx());
-                out = tmp;
-            } else {
-                out = LogTags_str[al->cache.code];
-            }
-
+            out = al->cache.code.c_str();
             break;
 
         case LFT_SQUID_ERROR:
@@ -942,7 +935,9 @@ Format::Format::assemble(MemBuf &mb, const AccessLogEntry::Pointer &al, int logS
         case LFT_CLIENT_REQ_URI:
             // original client URI
             if (al->request) {
-                out = urlCanonical(al->request);
+                const SBuf &s = al->request->effectiveRequestUri();
+                sb.append(s.rawContent(), s.length());
+                out = sb.termedBuf();
                 quote = 1;
             }
             break;
@@ -956,22 +951,23 @@ Format::Format::assemble(MemBuf &mb, const AccessLogEntry::Pointer &al, int logS
 
         case LFT_CLIENT_REQ_URLDOMAIN:
             if (al->request) {
-                out = al->request->GetHost();
+                out = al->request->url.host();
                 quote = 1;
             }
             break;
 
         case LFT_CLIENT_REQ_URLPORT:
             if (al->request) {
-                outint = al->request->port;
+                outint = al->request->url.port();
                 doint = 1;
             }
             break;
 
         case LFT_REQUEST_URLPATH_OLD_31:
         case LFT_CLIENT_REQ_URLPATH:
             if (al->request) {
-                out = al->request->urlpath.termedBuf();
+                SBuf s = al->request->url.path();
+                out = s.c_str();
                 quote = 1;
             }
             break;
@@ -1016,7 +1012,9 @@ Format::Format::assemble(MemBuf &mb, const AccessLogEntry::Pointer &al, int logS
         case LFT_SERVER_REQ_URI:
             // adapted request URI sent to server/peer
             if (al->adapted_request) {
-                out = urlCanonical(al->adapted_request);
+                const SBuf &s = al->adapted_request->effectiveRequestUri();
+                sb.append(s.rawContent(), s.length());
+                out = sb.termedBuf();
                 quote = 1;
             }
             break;
@@ -1030,21 +1028,22 @@ Format::Format::assemble(MemBuf &mb, const AccessLogEntry::Pointer &al, int logS
 
         case LFT_SERVER_REQ_URLDOMAIN:
             if (al->adapted_request) {
-                out = al->adapted_request->GetHost();
+                out = al->adapted_request->url.host();
                 quote = 1;
             }
             break;
 
         case LFT_SERVER_REQ_URLPORT:
             if (al->adapted_request) {
-                outint = al->adapted_request->port;
+                outint = al->adapted_request->url.port();
                 doint = 1;
             }
             break;
 
         case LFT_SERVER_REQ_URLPATH:
             if (al->adapted_request) {
-                out = al->adapted_request->urlpath.termedBuf();
+                SBuf s = al->adapted_request->url.path();
+                out = s.c_str();
                 quote = 1;
             }
             break;
@@ -1307,9 +1306,9 @@ Format::Format::assemble(MemBuf &mb, const AccessLogEntry::Pointer &al, int logS
                                      fmt->widthMax : strlen(out);
 
                 if (fmt->left)
-                    mb.Printf("%-*.*s", minWidth, maxWidth, out);
+                    mb.appendf("%-*.*s", minWidth, maxWidth, out);
                 else
-                    mb.Printf("%*.*s", minWidth, maxWidth, out);
+                    mb.appendf("%*.*s", minWidth, maxWidth, out);
             } else
                 mb.append(out, strlen(out));
         } else {
@@ -26,7 +26,8 @@ Rock::IoState::IoState(Rock::SwapDir::Pointer &aDir,
                        StoreEntry *anEntry,
                        StoreIOState::STFNCB *cbFile,
                        StoreIOState::STIOCB *cbIo,
-                       void *data):
+                       void *data) :
+    StoreIOState(cbFile, cbIo, data),
     readableAnchor_(NULL),
     writeableAnchor_(NULL),
     sidCurrent(-1),
@@ -38,9 +39,6 @@ Rock::IoState::IoState(Rock::SwapDir::Pointer &aDir,
     e = anEntry;
     e->lock("rock I/O");
     // anchor, swap_filen, and swap_dirn are set by the caller
-    file_callback = cbFile;
-    callback = cbIo;
-    callback_data = cbdataReference(data);
     ++store_open_disk_fd; // TODO: use a dedicated counter?
     //theFile is set by SwapDir because it depends on DiskIOStrategy
 }
@@ -281,7 +281,7 @@ Rock::Rebuild::importEntry(Ipc::StoreMapAnchor &anchor, const sfileno fileno, co
     cache_key key[SQUID_MD5_DIGEST_LENGTH];
     StoreEntry loadedE;
     const uint64_t knownSize = header.entrySize > 0 ?
-                               header.entrySize : anchor.basics.swap_file_sz.get();
+                               header.entrySize : anchor.basics.swap_file_sz.load();
     if (!storeRebuildParseEntry(buf, loadedE, key, counts, knownSize))
         return false;
 
@@ -405,12 +405,20 @@ Rock::SwapDir::parseSize(const bool reconfig)
 ConfigOption *
 Rock::SwapDir::getOptionTree() const
 {
-    ConfigOptionVector *vector = dynamic_cast<ConfigOptionVector*>(::SwapDir::getOptionTree());
-    assert(vector);
-    vector->options.push_back(new ConfigOptionAdapter<SwapDir>(*const_cast<SwapDir *>(this), &SwapDir::parseSizeOption, &SwapDir::dumpSizeOption));
-    vector->options.push_back(new ConfigOptionAdapter<SwapDir>(*const_cast<SwapDir *>(this), &SwapDir::parseTimeOption, &SwapDir::dumpTimeOption));
-    vector->options.push_back(new ConfigOptionAdapter<SwapDir>(*const_cast<SwapDir *>(this), &SwapDir::parseRateOption, &SwapDir::dumpRateOption));
-    return vector;
+    ConfigOption *copt = ::SwapDir::getOptionTree();
+    ConfigOptionVector *vector = dynamic_cast<ConfigOptionVector*>(copt);
+    if (vector) {
+        // if copt is actually a ConfigOptionVector
+        vector->options.push_back(new ConfigOptionAdapter<SwapDir>(*const_cast<SwapDir *>(this), &SwapDir::parseSizeOption, &SwapDir::dumpSizeOption));
+        vector->options.push_back(new ConfigOptionAdapter<SwapDir>(*const_cast<SwapDir *>(this), &SwapDir::parseTimeOption, &SwapDir::dumpTimeOption));
+        vector->options.push_back(new ConfigOptionAdapter<SwapDir>(*const_cast<SwapDir *>(this), &SwapDir::parseRateOption, &SwapDir::dumpRateOption));
+    } else {
+        // we don't know how to handle copt, as it's not a ConfigOptionVector.
+        // free it (and return nullptr)
+        delete copt;
+        copt = nullptr;
+    }
+    return copt;
 }
 
 bool
@@ -29,8 +29,24 @@
 CBDATA_NAMESPACED_CLASS_INIT(Fs::Ufs,RebuildState);
 
 Fs::Ufs::RebuildState::RebuildState(RefCount<UFSSwapDir> aSwapDir) :
-    sd (aSwapDir), LogParser(NULL), e(NULL), fromLog(true), _done (false)
+    sd(aSwapDir),
+    n_read(0),
+    LogParser(NULL),
+    curlvl1(0),
+    curlvl2(0),
+    in_dir(0),
+    done(0),
+    fn(0),
+    entry(NULL),
+    td(NULL),
+    e(NULL),
+    fromLog(true),
+    _done(false),
+    cbdata(NULL)
 {
+    *fullpath = 0;
+    *fullfilename = 0;
+
     /*
      * If the swap.state file exists in the cache_dir, then
      * we'll use commonUfsDirRebuildFromSwapLog(), otherwise we'll
@@ -433,6 +449,7 @@ Fs::Ufs::RebuildState::getNextFile(sfileno * filn_p, int *)
         fd = -1;
 
         if (!flags.init) {  /* initialize, open first file */
+            // XXX: 0's should not be needed, constructor inits now
             done = 0;
             curlvl1 = 0;
             curlvl2 = 0;
@@ -21,15 +21,15 @@ namespace Fs
 namespace Ufs
 {
 
-class RebuildState : public RefCountable
+class RebuildState
 {
     CBDATA_CLASS(RebuildState);
 
 public:
     static EVH RebuildStep;
 
     RebuildState(RefCount<UFSSwapDir> sd);
-    ~RebuildState();
+    virtual ~RebuildState();
 
     virtual bool error() const;
     virtual bool isDone() const;
@@ -16,8 +16,11 @@
 CBDATA_NAMESPACED_CLASS_INIT(Fs::Ufs,StoreSearchUFS);
 
 Fs::Ufs::StoreSearchUFS::StoreSearchUFS(RefCount<UFSSwapDir> aSwapDir) :
-    sd(aSwapDir), walker (sd->repl->WalkInit(sd->repl)),
-    current (NULL), _done (false)
+    sd(aSwapDir),
+    walker(sd->repl->WalkInit(sd->repl)),
+    cbdata(NULL),
+    current(NULL),
+    _done(false)
 {}
 
 Fs::Ufs::StoreSearchUFS::~StoreSearchUFS()
@@ -321,14 +321,23 @@ Fs::Ufs::UFSStoreState::doCloseCallback(int errflag)
 
 /* ============= THE REAL UFS CODE ================ */
 
-Fs::Ufs::UFSStoreState::UFSStoreState(SwapDir * SD, StoreEntry * anEntry, STIOCB * callback_, void *callback_data_) : opening (false), creating (false), closing (false), reading(false), writing(false), pending_reads(NULL), pending_writes (NULL)
+Fs::Ufs::UFSStoreState::UFSStoreState(SwapDir * SD, StoreEntry * anEntry, STIOCB * cbIo, void *data) :
+    StoreIOState(NULL, cbIo, data),
+    opening(false),
+    creating(false),
+    closing(false),
+    reading(false),
+    writing(false),
+    pending_reads(NULL),
+    pending_writes(NULL),
+    read_buf(NULL)
 {
+    // StoreIOState inherited members
     swap_filen = anEntry->swap_filen;
     swap_dirn = SD->index;
-    mode = O_BINARY;
-    callback = callback_;
-    callback_data = cbdataReference(callback_data_);
     e = anEntry;
+
+    // our flags
     flags.write_draining = false;
     flags.try_closing = false;
 }
@@ -48,23 +48,25 @@ class UFSStoreState : public StoreIOState, public IORequestor
     {
         MEMPROXY_CLASS(UFSStoreState::_queued_read);
     public:
+        _queued_read() : buf(NULL), size(0), offset(0), callback(NULL), callback_data(NULL) {}
+
         char *buf;
         size_t size;
         off_t offset;
         STRCB *callback;
         void *callback_data;
-
     };
 
     class _queued_write
     {
         MEMPROXY_CLASS(UFSStoreState::_queued_write);
     public:
+        _queued_write() : buf(NULL), size(0), offset(0), free_func(NULL) {}
+
         char const *buf;
         size_t size;
         off_t offset;
         FREE *free_func;
-
     };
 
     /** \todo These should be in the IO strategy */
@@ -33,6 +33,7 @@
 
 #include <cerrno>
 #include <cmath>
+#include <random>
 #if HAVE_SYS_STAT_H
 #include <sys/stat.h>
 #endif
@@ -1042,7 +1043,9 @@ Fs::Ufs::UFSSwapDir::CleanEvent(void *)
          * value.  j equals the total number of UFS level 2
          * swap directories
          */
-        swap_index = (int) (squid_random() % j);
+        std::mt19937 mt(static_cast<uint32_t>(getCurrentTime() & 0xFFFFFFFF));
+        std::uniform_int_distribution<> dist(0, j);
+        swap_index = dist(mt);
     }
 
     /* if the rebuild is finished, start cleaning directories. */
@@ -21,6 +21,7 @@
 #include "HttpRequest.h"
 #include "MemBuf.h"
 #include "mime.h"
+#include "parser/Tokenizer.h"
 #include "rfc1738.h"
 #include "SquidConfig.h"
 #include "SquidTime.h"
@@ -253,23 +254,27 @@ gopherMimeCreate(GopherStateData * gopherState)
 static void
 gopher_request_parse(const HttpRequest * req, char *type_id, char *request)
 {
-    const char *path = req->urlpath.termedBuf();
+    ::Parser::Tokenizer tok(req->url.path());
 
     if (request)
-        request[0] = '\0';
+        *request = 0;
 
-    if (path && (*path == '/'))
-        ++path;
+    tok.skip('/'); // ignore failures? path could be ab-empty
 
-    if (!path || !*path) {
+    if (tok.atEnd()) {
         *type_id = GOPHER_DIRECTORY;
         return;
     }
 
-    *type_id = path[0];
+    static const CharacterSet anyByte("UTF-8",0x00, 0xFF);
+
+    SBuf typeId;
+    (void)tok.prefix(typeId, anyByte, 1); // never fails since !atEnd()
+    *type_id = typeId[0];
 
     if (request) {
-        xstrncpy(request, path + 1, MAX_URL);
+        SBuf path = tok.remaining().substr(0, MAX_URL-1);
+        xstrncpy(request, path.rawContent(), path.length()+1);
         /* convert %xx to char */
         rfc1738_unescape(request);
     }
@@ -830,7 +835,7 @@ gopherSendComplete(const Comm::ConnectionPointer &conn, char *buf, size_t size,
         ErrorState *err;
         err = new ErrorState(ERR_WRITE_ERROR, Http::scServiceUnavailable, gopherState->fwd->request);
         err->xerrno = xerrno;
-        err->port = gopherState->fwd->request->port;
+        err->port = gopherState->fwd->request->url.port();
         err->url = xstrdup(entry->url());
         gopherState->fwd->fail(err);
         gopherState->serverConn->close();
@@ -10,6 +10,7 @@
 
 #include "squid.h"
 #include "base/AsyncCbdataCalls.h"
+#include "base/Packable.h"
 #include "comm.h"
 #include "comm/Connection.h"
 #include "comm/Read.h"
@@ -63,7 +64,6 @@ static void helperKickQueue(helper * hlp);
 static void helperStatefulKickQueue(statefulhelper * hlp);
 static void helperStatefulServerDone(helper_stateful_server * srv);
 static void StatefulEnqueue(statefulhelper * hlp, Helper::Request * r);
-static bool helperStartStats(StoreEntry *sentry, void *hlp, const char *label);
 
 CBDATA_CLASS_INIT(helper);
 CBDATA_CLASS_INIT(helper_server);
@@ -471,7 +471,7 @@ void statefulhelper::submit(const char *buf, HLPCB * callback, void *data, helpe
     if ((buf != NULL) && lastserver) {
         debugs(84, 5, "StatefulSubmit with lastserver " << lastserver);
         assert(lastserver->flags.reserved);
-        assert(!(lastserver->request));
+        assert(!lastserver->requests.size());
 
         debugs(84, 5, "StatefulSubmit dispatching");
         helperStatefulDispatch(lastserver, r);
@@ -523,124 +523,62 @@ helperStatefulServerGetData(helper_stateful_server * srv)
     return srv->data;
 }
 
-/**
- * Dump some stats about the helper states to a StoreEntry
- */
 void
-helperStats(StoreEntry * sentry, helper * hlp, const char *label)
+helper::packStatsInto(Packable *p, const char *label) const
 {
-    if (!helperStartStats(sentry, hlp, label))
-        return;
-
-    storeAppendPrintf(sentry, "program: %s\n",
-                      hlp->cmdline->key);
-    storeAppendPrintf(sentry, "number active: %d of %d (%d shutting down)\n",
-                      hlp->childs.n_active, hlp->childs.n_max, (hlp->childs.n_running - hlp->childs.n_active) );
-    storeAppendPrintf(sentry, "requests sent: %d\n",
-                      hlp->stats.requests);
-    storeAppendPrintf(sentry, "replies received: %d\n",
-                      hlp->stats.replies);
-    storeAppendPrintf(sentry, "requests timedout: %d\n",
-                      hlp->stats.timedout);
-    storeAppendPrintf(sentry, "queue length: %d\n",
-                      hlp->stats.queue_size);
-    storeAppendPrintf(sentry, "avg service time: %d msec\n",
-                      hlp->stats.avg_svc_time);
-    storeAppendPrintf(sentry, "\n");
-    storeAppendPrintf(sentry, "%7s\t%7s\t%7s\t%11s\t%11s\t%11s\t%s\t%7s\t%7s\t%7s\n",
-                      "ID #",
-                      "FD",
-                      "PID",
-                      "# Requests",
-                      "# Replies",
-                      "# Timed-out",
-                      "Flags",
-                      "Time",
-                      "Offset",
-                      "Request");
-
-    for (dlink_node *link = hlp->servers.head; link; link = link->next) {
-        helper_server *srv = (helper_server*)link->data;
+    if (label)
+        p->appendf("%s:\n", label);
+
+    p->appendf("  program: %s\n", cmdline->key);
+    p->appendf("  number active: %d of %d (%d shutting down)\n", childs.n_active, childs.n_max, (childs.n_running - childs.n_active));
+    p->appendf("  requests sent: %d\n", stats.requests);
+    p->appendf("  replies received: %d\n", stats.replies);
+    p->appendf("  requests timedout: %d\n", stats.timedout);
+    p->appendf("  queue length: %d\n", stats.queue_size);
+    p->appendf("  avg service time: %d msec\n", stats.avg_svc_time);
+    p->append("\n",1);
+    p->appendf("%7s\t%7s\t%7s\t%11s\t%11s\t%11s\t%6s\t%7s\t%7s\t%7s\n",
+               "ID #",
+               "FD",
+               "PID",
+               "# Requests",
+               "# Replies",
+               "# Timed-out",
+               "Flags",
+               "Time",
+               "Offset",
+               "Request");
+
+    for (dlink_node *link = servers.head; link; link = link->next) {
+        HelperServerBase *srv = static_cast<HelperServerBase *>(link->data);
+        assert(srv);
         Helper::Request *request = srv->requests.empty() ? NULL : srv->requests.front();
         double tt = 0.001 * (request ? tvSubMsec(request->dispatch_time, current_time) : tvSubMsec(srv->dispatch_time, srv->answer_time));
-        storeAppendPrintf(sentry, "%7u\t%7d\t%7d\t%11" PRIu64 "\t%11" PRIu64 "\t%11" PRIu64 "\t%c%c%c%c\t%7.3f\t%7d\t%s\n",
-                          srv->index.value,
-                          srv->readPipe->fd,
-                          srv->pid,
-                          srv->stats.uses,
-                          srv->stats.replies,
-                          srv->stats.timedout,
-                          srv->stats.pending ? 'B' : ' ',
-                          srv->flags.writing ? 'W' : ' ',
-                          srv->flags.closing ? 'C' : ' ',
-                          srv->flags.shutdown ? 'S' : ' ',
-                          tt < 0.0 ? 0.0 : tt,
-                          (int) srv->roffset,
-                          request ? Format::QuoteMimeBlob(request->buf) : "(none)");
-    }
-
-    storeAppendPrintf(sentry, "\nFlags key:\n\n");
-    storeAppendPrintf(sentry, "   B = BUSY\n");
-    storeAppendPrintf(sentry, "   W = WRITING\n");
-    storeAppendPrintf(sentry, "   C = CLOSING\n");
-    storeAppendPrintf(sentry, "   S = SHUTDOWN PENDING\n");
-}
-
-void
-helperStatefulStats(StoreEntry * sentry, statefulhelper * hlp, const char *label)
-{
-    if (!helperStartStats(sentry, hlp, label))
-        return;
-
-    storeAppendPrintf(sentry, "program: %s\n",
-                      hlp->cmdline->key);
-    storeAppendPrintf(sentry, "number active: %d of %d (%d shutting down)\n",
-                      hlp->childs.n_active, hlp->childs.n_max, (hlp->childs.n_running - hlp->childs.n_active) );
-    storeAppendPrintf(sentry, "requests sent: %d\n",
-                      hlp->stats.requests);
-    storeAppendPrintf(sentry, "replies received: %d\n",
-                      hlp->stats.replies);
-    storeAppendPrintf(sentry, "queue length: %d\n",
-                      hlp->stats.queue_size);
-    storeAppendPrintf(sentry, "avg service time: %d msec\n",
-                      hlp->stats.avg_svc_time);
-    storeAppendPrintf(sentry, "\n");
-    storeAppendPrintf(sentry, "%7s\t%7s\t%7s\t%11s\t%11s\t%6s\t%7s\t%7s\t%7s\n",
-                      "ID #",
-                      "FD",
-                      "PID",
-                      "# Requests",
-                      "# Replies",
-                      "Flags",
-                      "Time",
-                      "Offset",
-                      "Request");
-
-    for (dlink_node *link = hlp->servers.head; link; link = link->next) {
-        helper_stateful_server *srv = (helper_stateful_server *)link->data;
-        double tt = 0.001 * tvSubMsec(srv->dispatch_time, srv->stats.pending ? current_time : srv->answer_time);
-        storeAppendPrintf(sentry, "%7u\t%7d\t%7d\t%11" PRIu64 "\t%11" PRIu64 "\t%c%c%c%c%c\t%7.3f\t%7d\t%s\n",
-                          srv->index.value,
-                          srv->readPipe->fd,
-                          srv->pid,
-                          srv->stats.uses,
-                          srv->stats.replies,
-                          srv->stats.pending ? 'B' : ' ',
-                          srv->flags.closing ? 'C' : ' ',
-                          srv->flags.reserved ? 'R' : ' ',
-                          srv->flags.shutdown ? 'S' : ' ',
-                          srv->request ? (srv->request->placeholder ? 'P' : ' ') : ' ',
-                          tt < 0.0 ? 0.0 : tt,
-                          (int) srv->roffset,
-                          srv->request ? Format::QuoteMimeBlob(srv->request->buf) : "(none)");
+        p->appendf("%7u\t%7d\t%7d\t%11" PRIu64 "\t%11" PRIu64 "\t%11" PRIu64 "\t%c%c%c%c%c%c\t%7.3f\t%7d\t%s\n",
+                   srv->index.value,
+                   srv->readPipe->fd,
+                   srv->pid,
+                   srv->stats.uses,
+                   srv->stats.replies,
+                   srv->stats.timedout,
+                   srv->stats.pending ? 'B' : ' ',
+                   srv->flags.writing ? 'W' : ' ',
+                   srv->flags.closing ? 'C' : ' ',
+                   srv->flags.reserved ? 'R' : ' ',
+                   srv->flags.shutdown ? 'S' : ' ',
+                   request && request->placeholder ? 'P' : ' ',
+                   tt < 0.0 ? 0.0 : tt,
+                   (int) srv->roffset,
+                   request ? Format::QuoteMimeBlob(request->buf) : "(none)");
     }
 
-    storeAppendPrintf(sentry, "\nFlags key:\n\n");
-    storeAppendPrintf(sentry, "   B = BUSY\n");
-    storeAppendPrintf(sentry, "   C = CLOSING\n");
-    storeAppendPrintf(sentry, "   R = RESERVED\n");
-    storeAppendPrintf(sentry, "   S = SHUTDOWN PENDING\n");
-    storeAppendPrintf(sentry, "   P = PLACEHOLDER\n");
+    p->append("\nFlags key:\n"
+              "   B\tBUSY\n"
+              "   W\tWRITING\n"
+              "   C\tCLOSING\n"
+              "   R\tRESERVED\n"
+              "   S\tSHUTDOWN PENDING\n"
+              "   P\tPLACEHOLDER\n", 101);
 }
 
 void
@@ -743,7 +681,6 @@ static void
 helperServerFree(helper_server *srv)
 {
     helper *hlp = srv->parent;
-    Helper::Request *r;
     int concurrency = hlp->childs.concurrency;
 
     if (!concurrency)
@@ -793,7 +730,7 @@ helperServerFree(helper_server *srv)
 
     while (!srv->requests.empty()) {
         // XXX: re-schedule these on another helper?
-        r = srv->requests.front();
+        Helper::Request *r = srv->requests.front();
         srv->requests.pop_front();
         void *cbdata;
 
@@ -814,7 +751,6 @@ static void
 helperStatefulServerFree(helper_stateful_server *srv)
 {
     statefulhelper *hlp = srv->parent;
-    Helper::Request *r;
 
     if (srv->rbuf) {
         memFreeBuf(srv->rbuf_sz, srv->rbuf);
@@ -857,18 +793,18 @@ helperStatefulServerFree(helper_stateful_server *srv)
         }
     }
 
-    if ((r = srv->request)) {
+    while (!srv->requests.empty()) {
+        // XXX: re-schedule these on another helper?
+        Helper::Request *r = srv->requests.front();
+        srv->requests.pop_front();
         void *cbdata;
 
         if (cbdataReferenceValidDone(r->data, &cbdata)) {
             Helper::Reply nilReply;
-            nilReply.whichServer = srv;
             r->callback(cbdata, nilReply);
         }
 
         delete r;
-
-        srv->request = NULL;
     }
 
     if (srv->data != NULL)
@@ -1051,7 +987,6 @@ helperStatefulHandleRead(const Comm::ConnectionPointer &conn, char *, size_t len
 {
     char *t = NULL;
     helper_stateful_server *srv = (helper_stateful_server *)data;
-    Helper::Request *r;
     statefulhelper *hlp = srv->parent;
     assert(cbdataReferenceValid(data));
 
@@ -1073,7 +1008,7 @@ helperStatefulHandleRead(const Comm::ConnectionPointer &conn, char *, size_t len
 
     srv->roffset += len;
     srv->rbuf[srv->roffset] = '\0';
-    r = srv->request;
+    Helper::Request *r = srv->requests.front();
     debugs(84, DBG_DATA, Raw("accumulated", srv->rbuf, srv->roffset));
 
     if (r == NULL) {
@@ -1087,6 +1022,7 @@ helperStatefulHandleRead(const Comm::ConnectionPointer &conn, char *, size_t len
 
     if ((t = strchr(srv->rbuf, hlp->eom))) {
         /* end of reply found */
+        srv->requests.pop_front(); // we already have it in 'r'
         int called = 1;
         int skip = 1;
         debugs(84, 3, "helperStatefulHandleRead: end of reply found");
@@ -1120,7 +1056,6 @@ helperStatefulHandleRead(const Comm::ConnectionPointer &conn, char *, size_t len
          */
         srv->roffset = 0;
         delete r;
-        srv->request = NULL;
 
         -- srv->stats.pending;
         ++ srv->stats.replies;
@@ -1386,7 +1321,7 @@ helperDispatch(helper_server * srv, Helper::Request * r)
     if (hlp->childs.concurrency) {
         srv->requestsIndex.insert(helper_server::RequestIndex::value_type(reqId, it));
         assert(srv->requestsIndex.size() == srv->requests.size());
-        srv->wqueue->Printf("%" PRIu64 " %s", reqId, r->buf);
+        srv->wqueue->appendf("%" PRIu64 " %s", reqId, r->buf);
     } else
         srv->wqueue->append(r->buf, strlen(r->buf));
 
@@ -1437,14 +1372,14 @@ helperStatefulDispatch(helper_stateful_server * srv, Helper::Request * r)
         /* and push the queue. Note that the callback may have submitted a new
          * request to the helper which is why we test for the request */
 
-        if (srv->request == NULL)
+        if (!srv->requests.size())
             helperStatefulServerDone(srv);
 
         return;
     }
 
     srv->flags.reserved = true;
-    srv->request = r;
+    srv->requests.push_back(r);
     srv->dispatch_time = current_time;
     AsyncCall::Pointer call = commCbCall(5,5, "helperStatefulDispatchWriteDone",
                                          CommIoCbPtrFun(helperStatefulDispatchWriteDone, hlp));
@@ -1489,22 +1424,6 @@ helperStatefulServerDone(helper_stateful_server * srv)
     }
 }
 
-// TODO: should helper_ and helper_stateful_ have a common parent?
-static bool
-helperStartStats(StoreEntry *sentry, void *hlp, const char *label)
-{
-    if (!hlp) {
-        if (label)
-            storeAppendPrintf(sentry, "%s: unavailable\n", label);
-        return false;
-    }
-
-    if (label)
-        storeAppendPrintf(sentry, "%s:\n", label);
-
-    return true;
-}
-
 void
 helper_server::checkForTimedOutRequests(bool const retry)
 {
@@ -24,6 +24,8 @@
 #include <list>
 #include <map>
 
+class Packable;
+
 /**
  * Managers a set of individual helper processes with a common queue of requests.
  *
@@ -68,6 +70,10 @@ class helper
     /// Submits a request to the helper or add it to the queue if none of
     /// the servers is available.
     void submitRequest(Helper::Request *r);
+
+    /// Dump some stats about the helper state to a Packable object
+    void packStatsInto(Packable *p, const char *label = NULL) const;
+
 public:
     wordlist *cmdline;
     dlink_list servers;
@@ -164,6 +170,9 @@ class HelperServerBase
         bool reserved;
     } flags;
 
+    typedef std::list<Helper::Request *> Requests;
+    Requests requests; ///< requests in order of submission/expiration
+
     struct {
         uint64_t uses;     //< requests sent to this helper
         uint64_t replies;  //< replies received from this helper
@@ -189,9 +198,6 @@ class helper_server : public HelperServerBase
 
     helper *parent;
 
-    typedef std::list<Helper::Request *> Requests;
-    Requests requests; ///< requests in order of submission/expiration
-
     // STL says storing std::list iterators is safe when changing the list
     typedef std::map<uint64_t, Requests::iterator> RequestIndex;
     RequestIndex requestsIndex; ///< maps request IDs to requests
@@ -213,7 +219,6 @@ class helper_stateful_server : public HelperServerBase
     /* MemBuf writebuf; */
 
     statefulhelper *parent;
-    Helper::Request *request;
 
     void *data;         /* State data used by the calling routines */
 };
@@ -223,8 +228,6 @@ void helperOpenServers(helper * hlp);
 void helperStatefulOpenServers(statefulhelper * hlp);
 void helperSubmit(helper * hlp, const char *buf, HLPCB * callback, void *data);
 void helperStatefulSubmit(statefulhelper * hlp, const char *buf, HLPCB * callback, void *data, helper_stateful_server * lastserver);
-void helperStats(StoreEntry * sentry, helper * hlp, const char *label = NULL);
-void helperStatefulStats(StoreEntry * sentry, statefulhelper * hlp, const char *label = NULL);
 void helperShutdown(helper * hlp);
 void helperStatefulShutdown(statefulhelper * hlp);
 void helperStatefulReleaseServer(helper_stateful_server * srv);
@@ -93,31 +93,21 @@ struct _htcpDataHeader {
     uint16_t length;
 
 #if WORDS_BIGENDIAN
-uint8_t opcode:
-    4;
-uint8_t response:
-    4;
+    uint8_t opcode:4;
+    uint8_t response:4;
 #else
-uint8_t response:
-    4;
-uint8_t opcode:
-    4;
+    uint8_t response:4;
+    uint8_t opcode:4;
 #endif
 
 #if WORDS_BIGENDIAN
-uint8_t reserved:
-    6;
-uint8_t F1:
-    1;
-uint8_t RR:
-    1;
+    uint8_t reserved:6;
+    uint8_t F1:1;
+    uint8_t RR:1;
 #else
-uint8_t RR:
-    1;
-uint8_t F1:
-    1;
-uint8_t reserved:
-    6;
+    uint8_t RR:1;
+    uint8_t F1:1;
+    uint8_t reserved:6;
 #endif
 
     uint32_t msg_id;
@@ -499,7 +489,6 @@ htcpBuildData(char *buf, size_t buflen, htcpStuff * stuff)
     ssize_t off = 0;
     ssize_t op_data_sz;
     size_t hdr_sz = sizeof(htcpDataHeader);
-    htcpDataHeader hdr;
 
     if (buflen < hdr_sz)
         return -1;
@@ -515,33 +504,25 @@ htcpBuildData(char *buf, size_t buflen, htcpStuff * stuff)
 
     debugs(31, 3, "htcpBuildData: hdr.length = " << off);
 
-    hdr.length = (uint16_t) off;
-
-    hdr.opcode = stuff->op;
-
-    hdr.response = stuff->response;
-
-    hdr.RR = stuff->rr;
-
-    hdr.F1 = stuff->f1;
-
-    hdr.msg_id = stuff->msg_id;
-
-    /* convert multi-byte fields */
-    hdr.length = htons(hdr.length);
-
-    hdr.msg_id = htonl(hdr.msg_id);
-
     if (!old_squid_format) {
+        htcpDataHeader hdr;
+        memset(&hdr, 0, sizeof(hdr));
+        /* convert multi-byte fields */
+        hdr.msg_id = htonl(stuff->msg_id);
+        hdr.length = htons(static_cast<uint16_t>(off));
+        hdr.opcode = stuff->op;
+        hdr.response = stuff->response;
+        hdr.RR = stuff->rr;
+        hdr.F1 = stuff->f1;
         memcpy(buf, &hdr, hdr_sz);
     } else {
         htcpDataHeaderSquid hdrSquid;
         memset(&hdrSquid, 0, sizeof(hdrSquid));
-        hdrSquid.length = hdr.length;
-        hdrSquid.opcode = hdr.opcode;
-        hdrSquid.response = hdr.response;
-        hdrSquid.F1 = hdr.F1;
-        hdrSquid.RR = hdr.RR;
+        hdrSquid.length = htons(static_cast<uint16_t>(off));
+        hdrSquid.opcode = stuff->op;
+        hdrSquid.response = stuff->response;
+        hdrSquid.F1 = stuff->f1;
+        hdrSquid.RR = stuff->rr;
         memcpy(buf, &hdrSquid, hdr_sz);
     }
 
@@ -849,17 +830,13 @@ htcpTstReply(htcpDataHeader * dhdr, StoreEntry * e, htcpSpecifier * spec, Ip::Ad
 {
     static char pkt[8192];
     HttpHeader hdr(hoHtcpReply);
-    MemBuf mb;
-    Packer p;
     ssize_t pktlen;
 
     htcpStuff stuff(dhdr->msg_id, HTCP_TST, RR_RESPONSE, 0);
     stuff.response = e ? 0 : 1;
     debugs(31, 3, "htcpTstReply: response = " << stuff.response);
 
     if (spec) {
-        mb.init();
-        packerToMemInit(&p, &mb);
         stuff.S.method = spec->method;
         stuff.S.uri = spec->uri;
         stuff.S.version = spec->version;
@@ -869,7 +846,9 @@ htcpTstReply(htcpDataHeader * dhdr, StoreEntry * e, htcpSpecifier * spec, Ip::Ad
             hdr.putInt(HDR_AGE, (e->timestamp <= squid_curtime ? (squid_curtime - e->timestamp) : 0) );
         else
             hdr.putInt(HDR_AGE, 0);
-        hdr.packInto(&p);
+        MemBuf mb;
+        mb.init();
+        hdr.packInto(&mb);
         stuff.D.resp_hdrs = xstrdup(mb.buf);
         stuff.D.respHdrsSz = mb.contentSize();
         debugs(31, 3, "htcpTstReply: resp_hdrs = {" << stuff.D.resp_hdrs << "}");
@@ -882,7 +861,7 @@ htcpTstReply(htcpDataHeader * dhdr, StoreEntry * e, htcpSpecifier * spec, Ip::Ad
         if (e && e->lastmod > -1)
             hdr.putTime(HDR_LAST_MODIFIED, e->lastmod);
 
-        hdr.packInto(&p);
+        hdr.packInto(&mb);
 
         stuff.D.entity_hdrs = xstrdup(mb.buf);
         stuff.D.entityHdrsSz = mb.contentSize();
@@ -909,13 +888,12 @@ htcpTstReply(htcpDataHeader * dhdr, StoreEntry * e, htcpSpecifier * spec, Ip::Ad
         }
 #endif /* USE_ICMP */
 
-        hdr.packInto(&p);
+        hdr.packInto(&mb);
         stuff.D.cache_hdrs = xstrdup(mb.buf);
         stuff.D.cacheHdrsSz = mb.contentSize();
         debugs(31, 3, "htcpTstReply: cache_hdrs = {" << stuff.D.cache_hdrs << "}");
         mb.clean();
         hdr.clean();
-        packerClean(&p);
     }
 
     pktlen = htcpBuildPacket(pkt, sizeof(pkt), &stuff);
@@ -1519,8 +1497,6 @@ htcpQuery(StoreEntry * e, HttpRequest * req, CachePeer * p)
     ssize_t pktlen;
     char vbuf[32];
     HttpHeader hdr(hoRequest);
-    Packer pa;
-    MemBuf mb;
     HttpStateFlags flags;
 
     if (!Comm::IsConnOpen(htcpIncomingConn))
@@ -1537,11 +1513,10 @@ htcpQuery(StoreEntry * e, HttpRequest * req, CachePeer * p)
     stuff.S.uri = (char *) e->url();
     stuff.S.version = vbuf;
     HttpStateData::httpBuildRequestHeader(req, e, NULL, &hdr, flags);
+    MemBuf mb;
     mb.init();
-    packerToMemInit(&pa, &mb);
-    hdr.packInto(&pa);
+    hdr.packInto(&mb);
     hdr.clean();
-    packerClean(&pa);
     stuff.S.req_hdrs = mb.buf;
     pktlen = htcpBuildPacket(pkt, sizeof(pkt), &stuff);
     mb.clean();
@@ -1571,7 +1546,6 @@ htcpClear(StoreEntry * e, const char *uri, HttpRequest * req, const HttpRequestM
     ssize_t pktlen;
     char vbuf[32];
     HttpHeader hdr(hoRequest);
-    Packer pa;
     MemBuf mb;
     HttpStateFlags flags;
 
@@ -1601,10 +1575,8 @@ htcpClear(StoreEntry * e, const char *uri, HttpRequest * req, const HttpRequestM
     if (reason != HTCP_CLR_INVALIDATION) {
         HttpStateData::httpBuildRequestHeader(req, e, NULL, &hdr, flags);
         mb.init();
-        packerToMemInit(&pa, &mb);
-        hdr.packInto(&pa);
+        hdr.packInto(&mb);
         hdr.clean();
-        packerClean(&pa);
         stuff.S.req_hdrs = mb.buf;
     } else {
         stuff.S.req_hdrs = NULL;
@@ -1672,7 +1644,7 @@ static void
 htcpLogHtcp(Ip::Address &caddr, int opcode, LogTags logcode, const char *url)
 {
     AccessLogEntry::Pointer al = new AccessLogEntry;
-    if (LOG_TAG_NONE == logcode)
+    if (LOG_TAG_NONE == logcode.oldType)
         return;
     if (!Config.onoff.log_udp)
         return;
@@ -19,16 +19,19 @@
 #include "base/TextException.h"
 #include "base64.h"
 #include "CachePeer.h"
-#include "ChunkedCodingParser.h"
 #include "client_side.h"
 #include "comm/Connection.h"
+#include "comm/Read.h"
 #include "comm/Write.h"
+#include "CommRead.h"
 #include "err_detail_type.h"
 #include "errorpage.h"
 #include "fd.h"
 #include "fde.h"
 #include "globals.h"
 #include "http.h"
+#include "http/one/ResponseParser.h"
+#include "http/one/TeChunkedParser.h"
 #include "HttpControlMsg.h"
 #include "HttpHdrCc.h"
 #include "HttpHdrContRange.h"
@@ -41,7 +44,6 @@
 #include "log/access_log.h"
 #include "MemBuf.h"
 #include "MemObject.h"
-#include "mime_header.h"
 #include "neighbors.h"
 #include "peer_proxy_negotiate_auth.h"
 #include "profiler/Profiler.h"
@@ -83,16 +85,18 @@ static void copyOneHeaderFromClientsideRequestToUpstreamRequest(const HttpHeader
 //Declared in HttpHeaderTools.cc
 void httpHdrAdd(HttpHeader *heads, HttpRequest *request, const AccessLogEntryPointer &al, HeaderWithAclList &headers_add);
 
-HttpStateData::HttpStateData(FwdState *theFwdState) : AsyncJob("HttpStateData"), Client(theFwdState),
-    lastChunk(0), header_bytes_read(0), reply_bytes_read(0),
-    body_bytes_truncated(0), httpChunkDecoder(NULL)
+HttpStateData::HttpStateData(FwdState *theFwdState) :
+    AsyncJob("HttpStateData"),
+    Client(theFwdState),
+    lastChunk(0),
+    httpChunkDecoder(NULL),
+    payloadSeen(0),
+    payloadTruncated(0)
 {
     debugs(11,5,HERE << "HttpStateData " << this << " created");
     ignoreCacheControl = false;
     surrogateNoStore = false;
     serverConnection = fwd->serverConnection();
-    readBuf = new MemBuf;
-    readBuf->init(16*1024, 256*1024);
 
     // reset peer response time stats for %<pt
     request->hier.peer_http_request_sent.tv_sec = 0;
@@ -130,11 +134,6 @@ HttpStateData::~HttpStateData()
      * don't forget that ~Client() gets called automatically
      */
 
-    if (!readBuf->isNull())
-        readBuf->clean();
-
-    delete readBuf;
-
     if (httpChunkDecoder)
         delete httpChunkDecoder;
 
@@ -407,7 +406,7 @@ HttpStateData::cacheableReply()
             mayStore = true;
 
             // HTTPbis pt6 section 3.2: a response CC:must-revalidate is present
-        } else if (rep->cache_control->mustRevalidate() && !REFRESH_OVERRIDE(ignore_must_revalidate)) {
+        } else if (rep->cache_control->mustRevalidate()) {
             debugs(22, 3, HERE << "Authenticated but server reply Cache-Control:must-revalidate");
             mayStore = true;
 
@@ -416,7 +415,7 @@ HttpStateData::cacheableReply()
             // HTTPbis WG verdict on this is that it is omitted from the spec due to being 'unexpected' by
             // some. The caching+revalidate is not exactly unsafe though with Squids interpretation of no-cache
             // (without parameters) as equivalent to must-revalidate in the reply.
-        } else if (rep->cache_control->hasNoCache() && rep->cache_control->noCache().size() == 0 && !REFRESH_OVERRIDE(ignore_must_revalidate)) {
+        } else if (rep->cache_control->hasNoCache() && rep->cache_control->noCache().size() == 0) {
             debugs(22, 3, HERE << "Authenticated but server reply Cache-Control:no-cache (equivalent to must-revalidate)");
             mayStore = true;
 #endif
@@ -675,7 +674,7 @@ HttpStateData::checkDateSkew(HttpReply *reply)
         int skew = abs((int)(reply->date - squid_curtime));
 
         if (skew > 86400)
-            debugs(11, 3, "" << request->GetHost() << "'s clock is skewed by " << skew << " seconds!");
+            debugs(11, 3, "" << request->url.host() << "'s clock is skewed by " << skew << " seconds!");
     }
 }
 
@@ -697,52 +696,86 @@ HttpStateData::processReplyHeader()
 
     assert(!flags.headers_parsed);
 
-    if (!readBuf->hasContent()) {
+    if (!inBuf.length()) {
         ctx_exit(ctx);
         return;
     }
 
-    Http::StatusCode error = Http::scNone;
+    /* Attempt to parse the first line; this will define where the protocol, status, reason-phrase and header begin */
+    {
+        if (hp == NULL)
+            hp = new Http1::ResponseParser;
+
+        bool parsedOk = hp->parse(inBuf);
+
+        // sync the buffers after parsing.
+        inBuf = hp->remaining();
+
+        if (hp->needsMoreData()) {
+            if (eof) { // no more data coming
+                /* Bug 2879: Replies may terminate with \r\n then EOF instead of \r\n\r\n.
+                 * We also may receive truncated responses.
+                 * Ensure here that we have at minimum two \r\n when EOF is seen.
+                 */
+                inBuf.append("\r\n\r\n", 4);
+                // retry the parse
+                parsedOk = hp->parse(inBuf);
+                // sync the buffers after parsing.
+                inBuf = hp->remaining();
+            } else {
+                debugs(33, 5, "Incomplete response, waiting for end of response headers");
+                ctx_exit(ctx);
+                return;
+            }
+        }
+
+        flags.headers_parsed = true;
 
-    HttpReply *newrep = new HttpReply;
-    const bool parsed = newrep->parse(readBuf, eof, &error);
-
-    if (!parsed && readBuf->contentSize() > 5 && strncmp(readBuf->content(), "HTTP/", 5) != 0 && strncmp(readBuf->content(), "ICY", 3) != 0) {
-        MemBuf *mb;
-        HttpReply *tmprep = new HttpReply;
-        tmprep->setHeaders(Http::scOkay, "Gatewaying", NULL, -1, -1, -1);
-        tmprep->header.putExt("X-Transformed-From", "HTTP/0.9");
-        mb = tmprep->pack();
-        newrep->parse(mb, eof, &error);
-        delete mb;
-        delete tmprep;
-    } else {
-        if (!parsed && error > 0) { // unrecoverable parsing error
-            debugs(11, 3, "processReplyHeader: Non-HTTP-compliant header: '" <<  readBuf->content() << "'");
-            flags.headers_parsed = true;
-            // XXX: when sanityCheck is gone and Http::StatusLine is used to parse,
-            //   the sline should be already set the appropriate values during that parser stage
-            newrep->sline.set(Http::ProtocolVersion(), error);
+        if (!parsedOk) {
+            // unrecoverable parsing error
+            debugs(11, 3, "Non-HTTP-compliant header:\n---------\n" << inBuf << "\n----------");
+            HttpReply *newrep = new HttpReply;
+            newrep->sline.set(Http::ProtocolVersion(), hp->messageStatus());
             HttpReply *vrep = setVirginReply(newrep);
             entry->replaceHttpReply(vrep);
+            // XXX: close the server connection ?
             ctx_exit(ctx);
             return;
         }
+    }
 
-        if (!parsed) { // need more data
-            assert(!error);
-            assert(!eof);
-            delete newrep;
-            ctx_exit(ctx);
-            return;
-        }
+    /* We know the whole response is in parser now */
+    debugs(11, 2, "HTTP Server " << serverConnection);
+    debugs(11, 2, "HTTP Server RESPONSE:\n---------\n" <<
+           hp->messageProtocol() << " " << hp->messageStatus() << " " << hp->reasonPhrase() << "\n" <<
+           hp->mimeHeader() <<
+           "----------");
 
-        debugs(11, 2, "HTTP Server " << serverConnection);
-        debugs(11, 2, "HTTP Server REPLY:\n---------\n" << readBuf->content() << "\n----------");
+    // reset payload tracking to begin after message headers
+    payloadSeen = inBuf.length();
 
-        header_bytes_read = headersEnd(readBuf->content(), readBuf->contentSize());
-        readBuf->consume(header_bytes_read);
-    }
+    HttpReply *newrep = new HttpReply;
+    // XXX: RFC 7230 indicates we MAY ignore the reason phrase,
+    //      and use an empty string on unknown status.
+    //      We do that now to avoid performance regression from using SBuf::c_str()
+    newrep->sline.set(Http::ProtocolVersion(1,1), hp->messageStatus() /* , hp->reasonPhrase() */);
+    newrep->sline.protocol = newrep->sline.version.protocol = hp->messageProtocol().protocol;
+    newrep->sline.version.major = hp->messageProtocol().major;
+    newrep->sline.version.minor = hp->messageProtocol().minor;
+
+    // parse headers
+    newrep->pstate = psReadyToParseHeaders;
+    if (newrep->httpMsgParseStep(hp->mimeHeader().rawContent(), hp->mimeHeader().length(), true) < 0) {
+        // XXX: when Http::ProtocolVersion is a function, remove this hack. just set with messageProtocol()
+        newrep->sline.set(Http::ProtocolVersion(), Http::scInvalidHeader);
+        newrep->sline.version.protocol = hp->messageProtocol().protocol;
+        newrep->sline.version.major = hp->messageProtocol().major;
+        newrep->sline.version.minor = hp->messageProtocol().minor;
+        debugs(11, 2, "error parsing response headers mime block");
+    }
+
+    // done with Parser, now process using the HttpReply
+    hp = NULL;
 
     newrep->removeStaleWarnings();
 
@@ -755,7 +788,7 @@ HttpStateData::processReplyHeader()
     flags.chunked = false;
     if (newrep->sline.protocol == AnyP::PROTO_HTTP && newrep->header.chunked()) {
         flags.chunked = true;
-        httpChunkDecoder = new ChunkedCodingParser;
+        httpChunkDecoder = new Http1::TeChunkedParser;
     }
 
     if (!peerSupportsConnectionPinning())
@@ -824,12 +857,7 @@ void
 HttpStateData::proceedAfter1xx()
 {
     Must(flags.handling1xx);
-
-    debugs(11, 2, HERE << "consuming " << header_bytes_read <<
-           " header and " << reply_bytes_read << " body bytes read after 1xx");
-    header_bytes_read = 0;
-    reply_bytes_read = 0;
-
+    debugs(11, 2, "continuing with " << payloadSeen << " bytes in buffer after 1xx");
     CallJobHere(11, 3, this, HttpStateData, HttpStateData::processReply);
 }
 
@@ -1085,16 +1113,12 @@ HttpStateData::persistentConnStatus() const
     /** \par
      * If the body size is known, we must wait until we've gotten all of it. */
     if (clen > 0) {
-        // old technique:
-        // if (entry->mem_obj->endOffset() < vrep->content_length + vrep->hdr_sz)
-        const int64_t body_bytes_read = reply_bytes_read - header_bytes_read;
-        debugs(11,5, "persistentConnStatus: body_bytes_read=" <<
-               body_bytes_read << " content_length=" << vrep->content_length);
+        debugs(11,5, "payloadSeen=" << payloadSeen << " content_length=" << vrep->content_length);
 
-        if (body_bytes_read < vrep->content_length)
+        if (payloadSeen < vrep->content_length)
             return INCOMPLETE_MSG;
 
-        if (body_bytes_truncated > 0) // already read more than needed
+        if (payloadTruncated > 0) // already read more than needed
             return COMPLETE_NONPERSISTENT_MSG; // disable pconns
     }
 
@@ -1103,17 +1127,23 @@ HttpStateData::persistentConnStatus() const
     return statusIfComplete();
 }
 
-/* XXX this function is too long! */
+#if USE_DELAY_POOLS
+static void
+readDelayed(void *context, CommRead const &)
+{
+    HttpStateData *state = static_cast<HttpStateData*>(context);
+    state->flags.do_next_read = true;
+    state->maybeReadVirginBody();
+}
+#endif
+
 void
 HttpStateData::readReply(const CommIoCbParams &io)
 {
-    int bin;
-    int clen;
-    int len = io.size;
-
+    Must(!flags.do_next_read); // XXX: should have been set false by mayReadVirginBody()
     flags.do_next_read = false;
 
-    debugs(11, 5, HERE << io.conn << ": len " << len << ".");
+    debugs(11, 5, io.conn);
 
     // Bail out early on Comm::ERR_CLOSING - close handlers will tidy up for us
     if (io.flag == Comm::ERR_CLOSING) {
@@ -1126,37 +1156,60 @@ HttpStateData::readReply(const CommIoCbParams &io)
         return;
     }
 
-    // handle I/O errors
-    if (io.flag != Comm::OK || len < 0) {
-        debugs(11, 2, HERE << io.conn << ": read failure: " << xstrerror() << ".");
+    Must(Comm::IsConnOpen(serverConnection));
+    Must(io.conn->fd == serverConnection->fd);
 
-        if (ignoreErrno(io.xerrno)) {
-            flags.do_next_read = true;
-        } else {
-            ErrorState *err = new ErrorState(ERR_READ_ERROR, Http::scBadGateway, fwd->request);
-            err->xerrno = io.xerrno;
-            fwd->fail(err);
-            flags.do_next_read = false;
-            serverConnection->close();
+    /*
+     * Don't reset the timeout value here. The value should be
+     * counting Config.Timeout.request and applies to the request
+     * as a whole, not individual read() calls.
+     * Plus, it breaks our lame *HalfClosed() detection
+     */
+
+    Must(maybeMakeSpaceAvailable(true));
+    CommIoCbParams rd(this); // will be expanded with ReadNow results
+    rd.conn = io.conn;
+    rd.size = entry->bytesWanted(Range<size_t>(0, inBuf.spaceSize()));
+#if USE_DELAY_POOLS
+    if (rd.size < 1) {
+        assert(entry->mem_obj);
+
+        /* read ahead limit */
+        /* Perhaps these two calls should both live in MemObject */
+        AsyncCall::Pointer nilCall;
+        if (!entry->mem_obj->readAheadPolicyCanRead()) {
+            entry->mem_obj->delayRead(DeferredRead(readDelayed, this, CommRead(io.conn, NULL, 0, nilCall)));
+            return;
         }
 
+        /* delay id limit */
+        entry->mem_obj->mostBytesAllowed().delayRead(DeferredRead(readDelayed, this, CommRead(io.conn, NULL, 0, nilCall)));
         return;
     }
+#endif
+
+    switch (Comm::ReadNow(rd, inBuf)) {
+    case Comm::INPROGRESS:
+        if (inBuf.isEmpty())
+            debugs(33, 2, io.conn << ": no data to process, " << xstrerr(rd.xerrno));
+        flags.do_next_read = true;
+        maybeReadVirginBody();
+        return;
 
-    // update I/O stats
-    if (len > 0) {
-        readBuf->appended(len);
-        reply_bytes_read += len;
+    case Comm::OK:
+    {
+        payloadSeen += rd.size;
 #if USE_DELAY_POOLS
         DelayId delayId = entry->mem_obj->mostBytesAllowed();
-        delayId.bytesIn(len);
+        delayId.bytesIn(rd.size);
 #endif
 
-        kb_incr(&(statCounter.server.all.kbytes_in), len);
-        kb_incr(&(statCounter.server.http.kbytes_in), len);
+        kb_incr(&(statCounter.server.all.kbytes_in), rd.size);
+        kb_incr(&(statCounter.server.http.kbytes_in), rd.size);
         ++ IOStats.Http.reads;
 
-        for (clen = len - 1, bin = 0; clen; ++bin)
+        int bin = 0;
+        for (int clen = rd.size - 1; clen; ++bin)
             clen >>= 1;
 
         ++ IOStats.Http.read_hist[bin];
@@ -1169,36 +1222,29 @@ HttpStateData::readReply(const CommIoCbParams &io)
             request->hier.peer_response_time.tv_sec = -1;
     }
 
-    /** \par
-     * Here the RFC says we should ignore whitespace between replies, but we can't as
-     * doing so breaks HTTP/0.9 replies beginning with witespace, and in addition
-     * the response splitting countermeasures is extremely likely to trigger on this,
-     * not allowing connection reuse in the first place.
-     *
-     * 2012-02-10: which RFC? not 2068 or 2616,
-     *     tolerance there is all about whitespace between requests and header tokens.
-     */
+        /* Continue to process previously read data */
+    break;
 
-    if (len == 0) { // reached EOF?
+    case Comm::ENDFILE: // close detected by 0-byte read
         eof = 1;
         flags.do_next_read = false;
 
-        /* Bug 2879: Replies may terminate with \r\n then EOF instead of \r\n\r\n
-         * Ensure here that we have at minimum two \r\n when EOF is seen.
-         * TODO: Add eof parameter to headersEnd() and move this hack there.
-         */
-        if (readBuf->contentSize() && !flags.headers_parsed) {
-            /*
-             * Yes Henrik, there is a point to doing this.  When we
-             * called httpProcessReplyHeader() before, we didn't find
-             * the end of headers, but now we are definately at EOF, so
-             * we want to process the reply headers.
-             */
-            /* Fake an "end-of-headers" to work around such broken servers */
-            readBuf->append("\r\n", 2);
-        }
+        /* Continue to process previously read data */
+        break;
+
+    // case Comm::COMM_ERROR:
+    default: // no other flags should ever occur
+        debugs(11, 2, io.conn << ": read failure: " << xstrerr(rd.xerrno));
+        ErrorState *err = new ErrorState(ERR_READ_ERROR, Http::scBadGateway, fwd->request);
+        err->xerrno = rd.xerrno;
+        fwd->fail(err);
+        flags.do_next_read = false;
+        io.conn->close();
+
+        return;
     }
 
+    /* Process next response from buffer */
     processReply();
 }
 
@@ -1244,7 +1290,7 @@ HttpStateData::continueAfterParsingHeader()
     }
 
     if (!flags.headers_parsed && !eof) {
-        debugs(11, 9, HERE << "needs more at " << readBuf->contentSize());
+        debugs(11, 9, "needs more at " << inBuf.length());
         flags.do_next_read = true;
         /** \retval false If we have not finished parsing the headers and may get more data.
          *                Schedules more reads to retrieve the missing data.
@@ -1263,7 +1309,7 @@ HttpStateData::continueAfterParsingHeader()
             const Http::StatusCode s = vrep->sline.status();
             const AnyP::ProtocolVersion &v = vrep->sline.version;
             if (s == Http::scInvalidHeader && v != Http::ProtocolVersion(0,9)) {
-                debugs(11, DBG_IMPORTANT, "WARNING: HTTP: Invalid Response: Bad header encountered from " << entry->url() << " AKA " << request->GetHost() << request->urlpath.termedBuf() );
+                debugs(11, DBG_IMPORTANT, "WARNING: HTTP: Invalid Response: Bad header encountered from " << entry->url() << " AKA " << request->url);
                 error = ERR_INVALID_RESP;
             } else if (s == Http::scHeaderTooLarge) {
                 fwd->dontRetry(true);
@@ -1273,18 +1319,17 @@ HttpStateData::continueAfterParsingHeader()
             }
         } else {
             // parsed headers but got no reply
-            debugs(11, DBG_IMPORTANT, "WARNING: HTTP: Invalid Response: No reply at all for " << entry->url() << " AKA " << request->GetHost() << request->urlpath.termedBuf() );
+            debugs(11, DBG_IMPORTANT, "WARNING: HTTP: Invalid Response: No reply at all for " << entry->url() << " AKA " << request->url);
             error = ERR_INVALID_RESP;
         }
     } else {
         assert(eof);
-        if (readBuf->hasContent()) {
+        if (inBuf.length()) {
             error = ERR_INVALID_RESP;
-            debugs(11, DBG_IMPORTANT, "WARNING: HTTP: Invalid Response: Headers did not parse at all for " << entry->url() << " AKA " << request->GetHost() << request->urlpath.termedBuf() );
+            debugs(11, DBG_IMPORTANT, "WARNING: HTTP: Invalid Response: Headers did not parse at all for " << entry->url() << " AKA " << request->url);
         } else {
             error = ERR_ZERO_SIZE_OBJECT;
-            debugs(11, (request->flags.accelerated?DBG_IMPORTANT:2), "WARNING: HTTP: Invalid Response: No object data received for " <<
-                   entry->url() << " AKA " << request->GetHost() << request->urlpath.termedBuf() );
+            debugs(11, (request->flags.accelerated?DBG_IMPORTANT:2), "WARNING: HTTP: Invalid Response: No object data received for " << entry->url() << " AKA " << request->url);
         }
     }
 
@@ -1308,18 +1353,17 @@ HttpStateData::truncateVirginBody()
     if (!vrep->expectingBody(request->method, clen) || clen < 0)
         return; // no body or a body of unknown size, including chunked
 
-    const int64_t body_bytes_read = reply_bytes_read - header_bytes_read;
-    if (body_bytes_read - body_bytes_truncated <= clen)
+    if (payloadSeen - payloadTruncated <= clen)
         return; // we did not read too much or already took care of the extras
 
-    if (const int64_t extras = body_bytes_read - body_bytes_truncated - clen) {
+    if (const int64_t extras = payloadSeen - payloadTruncated - clen) {
         // server sent more that the advertised content length
-        debugs(11,5, HERE << "body_bytes_read=" << body_bytes_read <<
+        debugs(11, 5, "payloadSeen=" << payloadSeen <<
                " clen=" << clen << '/' << vrep->content_length <<
-               " body_bytes_truncated=" << body_bytes_truncated << '+' << extras);
+               " trucated=" << payloadTruncated << '+' << extras);
 
-        readBuf->truncate(extras);
-        body_bytes_truncated += extras;
+        inBuf.chop(0, inBuf.length() - extras);
+        payloadTruncated += extras;
     }
 }
 
@@ -1331,10 +1375,10 @@ void
 HttpStateData::writeReplyBody()
 {
     truncateVirginBody(); // if needed
-    const char *data = readBuf->content();
-    int len = readBuf->contentSize();
+    const char *data = inBuf.rawContent();
+    int len = inBuf.length();
     addVirginReplyBody(data, len);
-    readBuf->consume(len);
+    inBuf.consume(len);
 }
 
 bool
@@ -1348,7 +1392,9 @@ HttpStateData::decodeAndWriteReplyBody()
     SQUID_ENTER_THROWING_CODE();
     MemBuf decodedData;
     decodedData.init();
-    const bool doneParsing = httpChunkDecoder->parse(readBuf,&decodedData);
+    httpChunkDecoder->setPayloadBuffer(&decodedData);
+    const bool doneParsing = httpChunkDecoder->parse(inBuf);
+    inBuf = httpChunkDecoder->remaining(); // sync buffers after parse
     len = decodedData.contentSize();
     data=decodedData.content();
     addVirginReplyBody(data, len);
@@ -1445,7 +1491,7 @@ HttpStateData::processReplyBody()
                 request->clientConnectionManager->pinConnection(serverConnection, request, _peer,
                         (request->flags.connectionAuth));
             } else {
-                fwd->pconnPush(serverConnection, request->GetHost());
+                fwd->pconnPush(serverConnection, request->url.host());
             }
 
             serverConnection = NULL;
@@ -1477,30 +1523,59 @@ HttpStateData::maybeReadVirginBody()
     if (!Comm::IsConnOpen(serverConnection) || fd_table[serverConnection->fd].closing())
         return;
 
-    // we may need to grow the buffer if headers do not fit
-    const int minRead = flags.headers_parsed ? 0 :1024;
-    const int read_size = replyBodySpace(*readBuf, minRead);
-
-    debugs(11,9, HERE << (flags.do_next_read ? "may" : "wont") <<
-           " read up to " << read_size << " bytes from " << serverConnection);
+    if (!maybeMakeSpaceAvailable(false))
+        return;
 
-    /*
-     * why <2? Because delayAwareRead() won't actually read if
-     * you ask it to read 1 byte.  The delayed read request
-     * just gets re-queued until the client side drains, then
-     * the I/O thread hangs.  Better to not register any read
-     * handler until we get a notification from someone that
-     * its okay to read again.
-     */
-    if (read_size < 2)
+    // XXX: get rid of the do_next_read flag
+    // check for the proper reasons preventing read(2)
+    if (!flags.do_next_read)
         return;
 
-    if (flags.do_next_read) {
-        flags.do_next_read = false;
-        typedef CommCbMemFunT<HttpStateData, CommIoCbParams> Dialer;
-        entry->delayAwareRead(serverConnection, readBuf->space(read_size), read_size,
-                              JobCallback(11, 5, Dialer, this,  HttpStateData::readReply));
+    flags.do_next_read = false;
+
+    // must not already be waiting for read(2) ...
+    assert(!Comm::MonitorsRead(serverConnection->fd));
+
+    // wait for read(2) to be possible.
+    typedef CommCbMemFunT<HttpStateData, CommIoCbParams> Dialer;
+    AsyncCall::Pointer call = JobCallback(11, 5, Dialer, this, HttpStateData::readReply);
+    Comm::Read(serverConnection, call);
+}
+
+bool
+HttpStateData::maybeMakeSpaceAvailable(bool doGrow)
+{
+    // how much we are allowed to buffer
+    const int limitBuffer = (flags.headers_parsed ? Config.readAheadGap : Config.maxReplyHeaderSize);
+
+    if (limitBuffer < 0 || inBuf.length() >= (SBuf::size_type)limitBuffer) {
+        // when buffer is at or over limit already
+        debugs(11, 7, "wont read up to " << limitBuffer << ". buffer has (" << inBuf.length() << "/" << inBuf.spaceSize() << ") from " << serverConnection);
+        debugs(11, DBG_DATA, "buffer has {" << inBuf << "}");
+        // Process next response from buffer
+        processReply();
+        return false;
     }
+
+    // how much we want to read
+    const size_t read_size = calcBufferSpaceToReserve(inBuf.spaceSize(), (limitBuffer - inBuf.length()));
+
+    if (!read_size) {
+        debugs(11, 7, "wont read up to " << read_size << " into buffer (" << inBuf.length() << "/" << inBuf.spaceSize() << ") from " << serverConnection);
+        return false;
+    }
+
+    // just report whether we could grow or not, dont actually do it
+    if (doGrow)
+        return (read_size >= 2);
+
+    // we may need to grow the buffer
+    inBuf.reserveSpace(read_size);
+    debugs(11, 8, (!flags.do_next_read ? "wont" : "may") <<
+           " read up to " << read_size << " bytes info buf(" << inBuf.length() << "/" << inBuf.spaceSize() <<
+           ") from " << serverConnection);
+
+    return (inBuf.spaceSize() >= 2); // only read if there is 1+ bytes of space available
 }
 
 /// called after writing the very last request byte (body, last-chunk, etc)
@@ -1756,7 +1831,7 @@ HttpStateData::httpBuildRequestHeader(HttpRequest * request,
 
             static int warnedCount = 0;
             if (warnedCount++ < 100) {
-                const char *url = entry ? entry->url() : urlCanonical(request);
+                const SBuf url(entry ? SBuf(entry->url()) : request->effectiveRequestUri());
                 debugs(11, DBG_IMPORTANT, "Warning: likely forwarding loop with " << url);
             }
         }
@@ -1788,13 +1863,9 @@ HttpStateData::httpBuildRequestHeader(HttpRequest * request,
     if (!hdr_out->has(HDR_HOST)) {
         if (request->peer_domain) {
             hdr_out->putStr(HDR_HOST, request->peer_domain);
-        } else if (request->port == urlDefaultPort(request->url.getScheme())) {
-            /* use port# only if not default */
-            hdr_out->putStr(HDR_HOST, request->GetHost());
         } else {
-            httpHeaderPutStrf(hdr_out, HDR_HOST, "%s:%d",
-                              request->GetHost(),
-                              (int) request->port);
+            SBuf authority = request->url.authority();
+            hdr_out->putStr(HDR_HOST, authority.c_str());
         }
     }
 
@@ -1830,10 +1901,9 @@ HttpStateData::httpBuildRequestHeader(HttpRequest * request,
 
         /* Add max-age only without no-cache */
         if (!cc->hasMaxAge() && !cc->hasNoCache()) {
-            const char *url =
-                entry ? entry->url() : urlCanonical(request);
-            cc->maxAge(getMaxAge(url));
-
+            // XXX: performance regression. c_str() reallocates
+            SBuf tmp(request->effectiveRequestUri());
+            cc->maxAge(getMaxAge(entry ? entry->url() : tmp.c_str()));
         }
 
         /* Enforce sibling relations */
@@ -1943,15 +2013,8 @@ copyOneHeaderFromClientsideRequestToUpstreamRequest(const HttpHeaderEntry *e, co
         else if (request->flags.redirected && !Config.onoff.redir_rewrites_host)
             hdr_out->addEntry(e->clone());
         else {
-            /* use port# only if not default */
-
-            if (request->port == urlDefaultPort(request->url.getScheme())) {
-                hdr_out->putStr(HDR_HOST, request->GetHost());
-            } else {
-                httpHeaderPutStrf(hdr_out, HDR_HOST, "%s:%d",
-                                  request->GetHost(),
-                                  (int) request->port);
-            }
+            SBuf authority = request->url.authority();
+            hdr_out->putStr(HDR_HOST, authority.c_str());
         }
 
         break;
@@ -2099,31 +2162,24 @@ HttpStateData::buildRequestPrefix(MemBuf * mb)
      * not the one we are sending. Needs checking.
      */
     const AnyP::ProtocolVersion httpver = Http::ProtocolVersion();
-    const char * url;
-    if (_peer && !_peer->options.originserver)
-        url = urlCanonical(request);
-    else
-        url = request->urlpath.termedBuf();
-    mb->Printf(SQUIDSBUFPH " %s %s/%d.%d\r\n",
-               SQUIDSBUFPRINT(request->method.image()),
-               url && *url ? url : "/",
-               AnyP::ProtocolType_str[httpver.protocol],
-               httpver.major,httpver.minor);
+    const SBuf url(_peer && !_peer->options.originserver ? request->effectiveRequestUri() : request->url.path());
+    mb->appendf(SQUIDSBUFPH " " SQUIDSBUFPH " %s/%d.%d\r\n",
+                SQUIDSBUFPRINT(request->method.image()),
+                SQUIDSBUFPRINT(url),
+                AnyP::ProtocolType_str[httpver.protocol],
+                httpver.major,httpver.minor);
     /* build and pack headers */
     {
         HttpHeader hdr(hoRequest);
-        Packer p;
         httpBuildRequestHeader(request, entry, fwd->al, &hdr, flags);
 
         if (request->flags.pinned && request->flags.connectionAuth)
             request->flags.authSent = true;
         else if (hdr.has(HDR_AUTHORIZATION))
             request->flags.authSent = true;
 
-        packerToMemInit(&p, mb);
-        hdr.packInto(&p);
+        hdr.packInto(mb);
         hdr.clean();
-        packerClean(&p);
     }
     /* append header terminator */
     mb->append(crlf, 2);
@@ -2191,18 +2247,17 @@ HttpStateData::sendRequest()
 
     if (_peer) {
         /*The old code here was
-          if (neighborType(_peer, request) == PEER_SIBLING && ...
+          if (neighborType(_peer, request->url) == PEER_SIBLING && ...
           which is equivalent to:
-          if (neighborType(_peer, NULL) == PEER_SIBLING && ...
+          if (neighborType(_peer, URL()) == PEER_SIBLING && ...
           or better:
           if (((_peer->type == PEER_MULTICAST && p->options.mcast_siblings) ||
                  _peer->type == PEER_SIBLINGS ) && _peer->options.allow_miss)
                flags.only_if_cached = 1;
 
            But I suppose it was a bug
          */
-        if (neighborType(_peer, request) == PEER_SIBLING &&
-                !_peer->options.allow_miss)
+        if (neighborType(_peer, request->url) == PEER_SIBLING && !_peer->options.allow_miss)
             flags.only_if_cached = true;
 
         flags.front_end_https = _peer->front_end_https;
@@ -2237,9 +2292,9 @@ HttpStateData::getMoreRequestBody(MemBuf &buf)
     // we may need to send: hex-chunk-size CRLF raw-data CRLF last-chunk
     buf.init(16 + 2 + rawDataSize + 2 + 5, raw.max_capacity);
 
-    buf.Printf("%x\r\n", static_cast<unsigned int>(rawDataSize));
+    buf.appendf("%x\r\n", static_cast<unsigned int>(rawDataSize));
     buf.append(raw.content(), rawDataSize);
-    buf.Printf("\r\n");
+    buf.append("\r\n", 2);
 
     Must(rawDataSize > 0); // we did not accidently created last-chunk above
 
@@ -11,9 +11,9 @@
 
 #include "clients/Client.h"
 #include "comm.h"
+#include "http/forward.h"
 #include "HttpStateFlags.h"
 
-class ChunkedCodingParser;
 class FwdState;
 class HttpHeader;
 
@@ -47,10 +47,7 @@ class HttpStateData : public Client
     int lastChunk;      /* reached last chunk of a chunk-encoded reply */
     HttpStateFlags flags;
     size_t read_sz;
-    int header_bytes_read;  // to find end of response,
-    int64_t reply_bytes_read;   // without relying on StoreEntry
-    int body_bytes_truncated; // positive when we read more than we wanted
-    MemBuf *readBuf;
+    SBuf inBuf;                ///< I/O buffer for receiving server responses
     bool ignoreCacheControl;
     bool surrogateNoStore;
 
@@ -90,6 +87,17 @@ class HttpStateData : public Client
     virtual void abortTransaction(const char *reason); // abnormal termination
     virtual bool mayReadVirginReplyBody() const;
 
+    /**
+     * determine if read buffer can have space made available
+     * for a read.
+     *
+     * \param grow  whether to actually expand the buffer
+     *
+     * \return whether the buffer can be grown to provide space
+     *         regardless of whether the grow actually happened.
+     */
+    bool maybeMakeSpaceAvailable(bool grow);
+
     // consuming request body
     virtual void handleMoreRequestBodyAvailable();
     virtual void handleRequestBodyProducerAborted();
@@ -110,7 +118,14 @@ class HttpStateData : public Client
     static bool decideIfWeDoRanges (HttpRequest * orig_request);
     bool peerSupportsConnectionPinning() const;
 
-    ChunkedCodingParser *httpChunkDecoder;
+    /// Parser being used at present to parse the HTTP/ICY server response.
+    Http1::ResponseParserPointer hp;
+    Http1::TeChunkedParser *httpChunkDecoder;
+
+    /// amount of message payload/body received so far.
+    int64_t payloadSeen;
+    /// positive when we read more than we wanted
+    int64_t payloadTruncated;
 };
 
 int httpCachable(const HttpRequestMethod&);
@@ -87,7 +87,7 @@ typedef enum _method_t {
     METHOD_UNBIND,
 #endif
 
-    // draft-ietf-httpbis-http2-16 section 11.6
+    // RFC 7540
     METHOD_PRI,
 
     // Squid extension methods
@@ -48,7 +48,7 @@ typedef enum {
     HDR_FORWARDED,                      /**< RFC 7239 */
     HDR_FROM,                           /**< RFC 7231 */
     HDR_HOST,                           /**< RFC 7230 */
-    HDR_HTTP2_SETTINGS,                 /**< HTTP/2.0 upgrade header. see draft-ietf-httpbis-http2-13 */
+    HDR_HTTP2_SETTINGS,                 /**< RFC 7540 */
     /*HDR_IF,*/                         /* RFC 2518 */
     HDR_IF_MATCH,                       /**< RFC 7232 */
     HDR_IF_MODIFIED_SINCE,              /**< RFC 7232 */
@@ -142,8 +142,11 @@ HttpRequestMethod::isHttpSafe() const
     // RFC 5323 section 2
     case Http::METHOD_SEARCH:
 
-        // RFC 5789 - none
-        // RFC 5842 - none
+    // RFC 5789 - none
+    // RFC 5842 - none
+
+    // RFC 7540 section 11.6
+    case Http::METHOD_PRI:
 
         return true;
 
@@ -187,9 +190,12 @@ HttpRequestMethod::isIdempotent() const
     case Http::METHOD_MOVE:
     case Http::METHOD_UNLOCK:
 
-        // RFC 5323 - TODO check
-        // RFC 5789 - TODO check
-        // RFC 5842 - TODO check
+    // RFC 5323 - TODO check
+    // RFC 5789 - TODO check
+    // RFC 5842 - TODO check
+
+    // RFC 7540 section 11.6
+    case Http::METHOD_PRI:
 
         return true;
 
@@ -39,7 +39,7 @@ typedef enum {
     scNotModified = 304,
     scUseProxy = 305,
     scTemporaryRedirect = 307,
-    scPermanentRedirect = 308, /**< RFC7238 */
+    scPermanentRedirect = 308, /**< RFC7538 */
     scBadRequest = 400,
     scUnauthorized = 401,
     scPaymentRequired = 402,
@@ -58,7 +58,7 @@ typedef enum {
     scUnsupportedMediaType = 415,
     scRequestedRangeNotSatisfied = 416,
     scExpectationFailed = 417,
-    scMisdirectedRequest = 421,     /**< draft-ietf-httpbis-http2-16 section 9.1.2 */
+    scMisdirectedRequest = 421,     /**< RFC7540 section 9.1.2 */
     scUnprocessableEntity = 422,    /**< RFC2518 section 10.3 / RFC4918 */
     scLocked = 423,                 /**< RFC2518 section 10.4 / RFC4918 */
     scFailedDependency = 424,       /**< RFC2518 section 10.5 / RFC4918 */
@@ -9,9 +9,9 @@
 /* DEBUG: section 57    HTTP Status-line */
 
 #include "squid.h"
+#include "base/Packable.h"
 #include "Debug.h"
 #include "http/StatusLine.h"
-#include "Packer.h"
 
 void
 Http::StatusLine::init()
@@ -43,7 +43,7 @@ Http::StatusLine::reason() const
 }
 
 void
-Http::StatusLine::packInto(Packer * p) const
+Http::StatusLine::packInto(Packable * p) const
 {
     assert(p);
 
@@ -57,14 +57,14 @@ Http::StatusLine::packInto(Packer * p) const
         debugs(57, 9, "packing sline " << this << " using " << p << ":");
         debugs(57, 9, "FORMAT=" << IcyStatusLineFormat );
         debugs(57, 9, "ICY " << status() << " " << reason());
-        packerPrintf(p, IcyStatusLineFormat, status(), reason());
+        p->appendf(IcyStatusLineFormat, status(), reason());
         return;
     }
 
     debugs(57, 9, "packing sline " << this << " using " << p << ":");
     debugs(57, 9, "FORMAT=" << Http1StatusLineFormat );
     debugs(57, 9, "HTTP/" << version.major << "." << version.minor << " " << status() << " " << reason());
-    packerPrintf(p, Http1StatusLineFormat, version.major, version.minor, status(), reason());
+    p->appendf(Http1StatusLineFormat, version.major, version.minor, status(), reason());
 }
 
 /*
@@ -13,7 +13,7 @@
 #include "http/StatusCode.h"
 #include "SquidString.h"
 
-class Packer;
+class Packable;
 class String;
 
 namespace Http
@@ -43,8 +43,8 @@ class StatusLine
     /// retrieve the reason string for this status line
     const char *reason() const;
 
-    /// pack fields using Packer
-    void packInto(Packer * p) const;
+    /// pack fields into a Packable object
+    void packInto(Packable *) const;
 
     /**
      * Parse a buffer and fill internal structures;
@@ -15,4 +15,10 @@ libhttp1_la_SOURCES = \
 	Parser.cc \
 	Parser.h \
 	RequestParser.cc \
-	RequestParser.h
+	RequestParser.h \
+	ResponseParser.cc \
+	ResponseParser.h \
+	TeChunkedParser.cc \
+	TeChunkedParser.h \
+	Tokenizer.cc \
+	Tokenizer.h
@@ -9,7 +9,8 @@
 #include "squid.h"
 #include "Debug.h"
 #include "http/one/Parser.h"
-#include "parser/Tokenizer.h"
+#include "http/one/Tokenizer.h"
+#include "mime_header.h"
 #include "SquidConfig.h"
 
 /// RFC 7230 section 2.6 - 7 magic octets
@@ -25,7 +26,7 @@ Http::One::Parser::clear()
 }
 
 bool
-Http::One::Parser::skipLineTerminator(::Parser::Tokenizer &tok) const
+Http::One::Parser::skipLineTerminator(Http1::Tokenizer &tok) const
 {
     static const SBuf crlf("\r\n");
     if (tok.skip(crlf))
@@ -37,6 +38,53 @@ Http::One::Parser::skipLineTerminator(::Parser::Tokenizer &tok) const
     return false;
 }
 
+bool
+Http::One::Parser::grabMimeBlock(const char *which, const size_t limit)
+{
+    // MIME headers block exist in (only) HTTP/1.x and ICY
+    const bool expectMime = (msgProtocol_.protocol == AnyP::PROTO_HTTP && msgProtocol_.major == 1) ||
+                            msgProtocol_.protocol == AnyP::PROTO_ICY ||
+                            hackExpectsMime_;
+
+    if (expectMime) {
+        /* NOTE: HTTP/0.9 messages do not have a mime header block.
+         *       So the rest of the code will need to deal with '0'-byte headers
+         *       (ie, none, so don't try parsing em)
+         */
+        // XXX: c_str() reallocates. performance regression.
+        if (SBuf::size_type mimeHeaderBytes = headersEnd(buf_.c_str(), buf_.length())) {
+
+            // Squid could handle these headers, but admin does not want to
+            if (firstLineSize() + mimeHeaderBytes >= limit) {
+                debugs(33, 5, "Too large " << which);
+                parseStatusCode = Http::scHeaderTooLarge;
+                buf_.consume(mimeHeaderBytes);
+                parsingStage_ = HTTP_PARSE_DONE;
+                return false;
+            }
+
+            mimeHeaderBlock_ = buf_.consume(mimeHeaderBytes);
+            debugs(74, 5, "mime header (0-" << mimeHeaderBytes << ") {" << mimeHeaderBlock_ << "}");
+
+        } else { // headersEnd() == 0
+            if (buf_.length()+firstLineSize() >= limit) {
+                debugs(33, 5, "Too large " << which);
+                parseStatusCode = Http::scHeaderTooLarge;
+                parsingStage_ = HTTP_PARSE_DONE;
+            } else
+                debugs(33, 5, "Incomplete " << which << ", waiting for end of headers");
+            return false;
+        }
+
+    } else
+        debugs(33, 3, "Missing HTTP/1.x identifier");
+
+    // NP: we do not do any further stages here yet so go straight to DONE
+    parsingStage_ = HTTP_PARSE_DONE;
+
+    return true;
+}
+
 // arbitrary maximum-length for headers which can be found by Http1Parser::getHeaderField()
 #define GET_HDR_SZ  1024
 
@@ -55,12 +103,13 @@ Http::One::Parser::getHeaderField(const char *name)
 
     // while we can find more LF in the SBuf
     static CharacterSet iso8859Line = CharacterSet("non-LF",'\0','\n'-1) + CharacterSet(NULL, '\n'+1, (unsigned char)0xFF);
-    ::Parser::Tokenizer tok(mimeHeaderBlock_);
+    Http1::Tokenizer tok(mimeHeaderBlock_);
     SBuf p;
     static const SBuf crlf("\r\n");
 
     while (tok.prefix(p, iso8859Line)) {
-        tok.skipOne(CharacterSet::LF); // move tokenizer past the LF
+        if (!tok.skipOne(CharacterSet::LF)) // move tokenizer past the LF
+            break; // error. reached invalid octet or end of buffer insted of an LF ??
 
         // header lines must start with the name (case insensitive)
         if (p.substr(0, namelen).caseCmp(name, namelen))
@@ -77,7 +126,7 @@ Http::One::Parser::getHeaderField(const char *name)
         p.consume(namelen + 1);
 
         // TODO: optimize SBuf::trim to take CharacterSet directly
-        ::Parser::Tokenizer t(p);
+        Http1::Tokenizer t(p);
         t.skipAll(CharacterSet::WSP);
         p = t.remaining();
 
@@ -11,21 +11,21 @@
 
 #include "anyp/ProtocolVersion.h"
 #include "http/one/forward.h"
+#include "http/StatusCode.h"
 #include "SBuf.h"
 
-namespace Parser {
-class Tokenizer;
-}
-
 namespace Http {
 namespace One {
 
 // Parser states
 enum ParseState {
-    HTTP_PARSE_NONE,     ///< initialized, but nothing usefully parsed yet
-    HTTP_PARSE_FIRST,    ///< HTTP/1 message first-line
-    HTTP_PARSE_MIME,     ///< HTTP/1 mime-header block
-    HTTP_PARSE_DONE      ///< parsed a message header, or reached a terminal syntax error
+    HTTP_PARSE_NONE,      ///< initialized, but nothing usefully parsed yet
+    HTTP_PARSE_FIRST,     ///< HTTP/1 message first-line
+    HTTP_PARSE_CHUNK_SZ,  ///< HTTP/1.1 chunked encoding chunk-size
+    HTTP_PARSE_CHUNK_EXT, ///< HTTP/1.1 chunked encoding chunk-ext
+    HTTP_PARSE_CHUNK,     ///< HTTP/1.1 chunked encoding chunk-data
+    HTTP_PARSE_MIME,      ///< HTTP/1 mime-header block
+    HTTP_PARSE_DONE       ///< parsed a message header, or reached a terminal syntax error
 };
 
 /** HTTP/1.x protocol parser
@@ -41,7 +41,7 @@ class Parser : public RefCountable
 public:
     typedef SBuf::size_type size_type;
 
-    Parser() : parsingStage_(HTTP_PARSE_NONE) {}
+    Parser() : parseStatusCode(Http::scNone), parsingStage_(HTTP_PARSE_NONE), hackExpectsMime_(false) {}
     virtual ~Parser() {}
 
     /// Set this parser back to a default state.
@@ -78,7 +78,7 @@ class Parser : public RefCountable
     const AnyP::ProtocolVersion & messageProtocol() const {return msgProtocol_;}
 
     /**
-     * Scan the mime header block (badly) for a header with teh given name.
+     * Scan the mime header block (badly) for a header with the given name.
      *
      * BUG: omits lines when searching for headers with obs-fold or multiple entries.
      *
@@ -91,10 +91,31 @@ class Parser : public RefCountable
     /// the remaining unprocessed section of buffer
     const SBuf &remaining() const {return buf_;}
 
+    /**
+     * HTTP status code resulting from the parse process.
+     * to be used on the invalid message handling.
+     *
+     * Http::scNone indicates incomplete parse,
+     * Http::scOkay indicates no error,
+     * other codes represent a parse error.
+     */
+    Http::StatusCode parseStatusCode;
+
 protected:
     /// detect and skip the CRLF or (if tolerant) LF line terminator
     /// consume from the tokenizer and return true only if found
-    bool skipLineTerminator(::Parser::Tokenizer &tok) const;
+    bool skipLineTerminator(Http1::Tokenizer &tok) const;
+
+    /**
+     * Scan to find the mime headers block for current message.
+     *
+     * \retval true   If mime block (or a blocks non-existence) has been
+     *                identified accurately within limit characters.
+     *                mimeHeaderBlock_ has been updated and buf_ consumed.
+     *
+     * \retval false  An error occured, or no mime terminator found within limit.
+     */
+    bool grabMimeBlock(const char *which, const size_t limit);
 
     /// RFC 7230 section 2.6 - 7 magic octets
     static const SBuf Http1magic;
@@ -110,6 +131,9 @@ class Parser : public RefCountable
 
     /// buffer holding the mime headers (if any)
     SBuf mimeHeaderBlock_;
+
+    /// Whether the invalid HTTP as HTTP/0.9 hack expects a mime header block
+    bool hackExpectsMime_;
 };
 
 } // namespace One
@@ -9,15 +9,13 @@
 #include "squid.h"
 #include "Debug.h"
 #include "http/one/RequestParser.h"
+#include "http/one/Tokenizer.h"
 #include "http/ProtocolVersion.h"
-#include "mime_header.h"
-#include "parser/Tokenizer.h"
 #include "profiler/Profiler.h"
 #include "SquidConfig.h"
 
 Http::One::RequestParser::RequestParser() :
     Parser(),
-    request_parse_status(Http::scNone),
     firstLineGarbage_(0)
 {}
 
@@ -69,12 +67,12 @@ Http::One::RequestParser::skipGarbageLines()
  * checkpoints after each successful request-line field.
  * The return value tells you whether the parsing is completed or not.
  *
- * \retval -1  an error occurred. request_parse_status indicates HTTP status result.
+ * \retval -1  an error occurred. parseStatusCode indicates HTTP status result.
  * \retval  1  successful parse. method_ is filled and buffer consumed including first delimiter.
  * \retval  0  more data is needed to complete the parse
  */
 int
-Http::One::RequestParser::parseMethodField(::Parser::Tokenizer &tok, const CharacterSet &WspDelim)
+Http::One::RequestParser::parseMethodField(Http1::Tokenizer &tok, const CharacterSet &WspDelim)
 {
     // scan for up to 16 valid method characters.
     static const size_t maxMethodLength = 16; // TODO: make this configurable?
@@ -97,12 +95,12 @@ Http::One::RequestParser::parseMethodField(::Parser::Tokenizer &tok, const Chara
     if (methodFound.length() == maxMethodLength) {
         // method longer than acceptible.
         // RFC 7230 section 3.1.1 mandatory (SHOULD) 501 response
-        request_parse_status = Http::scNotImplemented;
+        parseStatusCode = Http::scNotImplemented;
         debugs(33, 5, "invalid request-line. method too long");
     } else {
         // invalid character in the URL
         // RFC 7230 section 3.1.1 required (SHOULD) 400 response
-        request_parse_status = Http::scBadRequest;
+        parseStatusCode = Http::scBadRequest;
         debugs(33, 5, "invalid request-line. missing method delimiter");
     }
     return -1;
@@ -134,7 +132,7 @@ uriValidCharacters()
 }
 
 int
-Http::One::RequestParser::parseUriField(::Parser::Tokenizer &tok)
+Http::One::RequestParser::parseUriField(Http1::Tokenizer &tok)
 {
     // URI field is a sequence of ... what? segments all have different valid charset
     // go with non-whitespace non-binary characters for now
@@ -165,7 +163,7 @@ Http::One::RequestParser::parseUriField(::Parser::Tokenizer &tok)
         debugs(33, 5, "HTTP/0.9 syntax request-line detected");
         msgProtocol_ = Http::ProtocolVersion(0,9);
         uri_ = uriFound; // found by successful prefix() call earlier.
-        request_parse_status = Http::scOkay;
+        parseStatusCode = Http::scOkay;
         buf_ = tok.remaining(); // incremental parse checkpoint
         return 1;
 
@@ -178,18 +176,18 @@ Http::One::RequestParser::parseUriField(::Parser::Tokenizer &tok)
 
     if (uriFound.length() == maxUriLength) {
         // RFC 7230 section 3.1.1 mandatory (MUST) 414 response
-        request_parse_status = Http::scUriTooLong;
+        parseStatusCode = Http::scUriTooLong;
         debugs(33, 5, "invalid request-line. URI longer than " << maxUriLength << " bytes");
     } else {
         // RFC 7230 section 3.1.1 required (SHOULD) 400 response
-        request_parse_status = Http::scBadRequest;
+        parseStatusCode = Http::scBadRequest;
         debugs(33, 5, "invalid request-line. missing URI delimiter");
     }
     return -1;
 }
 
 int
-Http::One::RequestParser::parseHttpVersionField(::Parser::Tokenizer &tok)
+Http::One::RequestParser::parseHttpVersionField(Http1::Tokenizer &tok)
 {
     // partial match of HTTP/1 magic prefix
     if (tok.remaining().length() < Http1magic.length() && Http1magic.startsWith(tok.remaining())) {
@@ -199,7 +197,7 @@ Http::One::RequestParser::parseHttpVersionField(::Parser::Tokenizer &tok)
 
     if (!tok.skip(Http1magic)) {
         debugs(74, 5, "invalid request-line. not HTTP/1 protocol");
-        request_parse_status = Http::scHttpVersionNotSupported;
+        parseStatusCode = Http::scHttpVersionNotSupported;
         return -1;
     }
 
@@ -214,7 +212,7 @@ Http::One::RequestParser::parseHttpVersionField(::Parser::Tokenizer &tok)
 
         // found version fully AND terminator
         msgProtocol_ = Http::ProtocolVersion(1, (*digit.rawContent() - '0'));
-        request_parse_status = Http::scOkay;
+        parseStatusCode = Http::scOkay;
         buf_ = tok.remaining(); // incremental parse checkpoint
         return 1;
 
@@ -225,7 +223,7 @@ Http::One::RequestParser::parseHttpVersionField(::Parser::Tokenizer &tok)
     } // else error ...
 
     // non-DIGIT. invalid version number.
-    request_parse_status = Http::scHttpVersionNotSupported;
+    parseStatusCode = Http::scHttpVersionNotSupported;
     debugs(33, 5, "invalid request-line. garbage before line terminator");
     return -1;
 }
@@ -241,14 +239,14 @@ Http::One::RequestParser::parseHttpVersionField(::Parser::Tokenizer &tok)
  * checkpoints after each successful request-line field.
  * The return value tells you whether the parsing is completed or not.
  *
- * \retval -1  an error occurred. request_parse_status indicates HTTP status result.
+ * \retval -1  an error occurred. parseStatusCode indicates HTTP status result.
  * \retval  1  successful parse. member fields contain the request-line items
  * \retval  0  more data is needed to complete the parse
  */
 int
 Http::One::RequestParser::parseRequestFirstLine()
 {
-    ::Parser::Tokenizer tok(buf_);
+    Http1::Tokenizer tok(buf_);
 
     debugs(74, 5, "parsing possible request: buf.length=" << buf_.length());
     debugs(74, DBG_DATA, buf_);
@@ -263,6 +261,7 @@ Http::One::RequestParser::parseRequestFirstLine()
         WspDelim += CharacterSet::HTAB
                     + CharacterSet("VT,FF","\x0B\x0C")
                     + CharacterSet::CR;
+        debugs(74, 5, "using Parser relaxed WSP characters");
     }
 
     // only search for method if we have not yet found one
@@ -290,6 +289,8 @@ Http::One::RequestParser::parseRequestFirstLine()
     if (Config.onoff.relaxed_header_parser) {
         // whitespace tolerant
 
+        int warnOnError = (Config.onoff.relaxed_header_parser <= 0 ? DBG_IMPORTANT : 2);
+
         // NOTES:
         // * this would be static, except WspDelim changes with reconfigure
         // * HTTP-version charset is included by uriValidCharacters()
@@ -299,20 +300,20 @@ Http::One::RequestParser::parseRequestFirstLine()
         // seek the LF character, then tokenize the line in reverse
         SBuf line;
         if (tok.prefix(line, LfDelim) && tok.skip('\n')) {
-            ::Parser::Tokenizer rTok(line);
+            Http1::Tokenizer rTok(line);
             SBuf nil;
             (void)rTok.suffix(nil,CharacterSet::CR); // optional CR in terminator
             SBuf digit;
             if (rTok.suffix(digit,CharacterSet::DIGIT) && rTok.skipSuffix(Http1magic) && rTok.suffix(nil,WspDelim)) {
                 uri_ = rTok.remaining();
                 msgProtocol_ = Http::ProtocolVersion(1, (*digit.rawContent() - '0'));
                 if (uri_.isEmpty()) {
-                    debugs(33, 5, "invalid request-line. missing URL");
-                    request_parse_status = Http::scBadRequest;
+                    debugs(33, warnOnError, "invalid request-line. missing URL");
+                    parseStatusCode = Http::scBadRequest;
                     return -1;
                 }
 
-                request_parse_status = Http::scOkay;
+                parseStatusCode = Http::scOkay;
                 buf_ = tok.remaining(); // incremental parse checkpoint
                 return 1;
 
@@ -322,16 +323,82 @@ Http::One::RequestParser::parseRequestFirstLine()
                 msgProtocol_ = Http::ProtocolVersion(0,9);
                 static const SBuf cr("\r",1);
                 uri_ = line.trim(cr,false,true);
-                request_parse_status = Http::scOkay;
+                parseStatusCode = Http::scOkay;
                 buf_ = tok.remaining(); // incremental parse checkpoint
                 return 1;
             }
 
-            debugs(33, 5, "invalid request-line. not HTTP");
-            request_parse_status = Http::scBadRequest;
+            debugs(33, warnOnError, "invalid request-line. not HTTP");
+            parseStatusCode = Http::scBadRequest;
             return -1;
         }
 
+        if (!tok.atEnd()) {
+
+#if USE_HTTP_VIOLATIONS
+            /*
+             * RFC 3986 explicitly lists the characters permitted in URI.
+             * A non-permitted character was found somewhere in the request-line.
+             * However, as long as we can find the LF, accept the characters
+             * which we know are invalid in any URI but actively used.
+             */
+            LfDelim.add('\0'); // Java
+            LfDelim.add(' ');  // IIS
+            LfDelim.add('\"'); // Bing
+            LfDelim.add('\\'); // MSIE, Firefox
+            LfDelim.add('|');  // Amazon
+            LfDelim.add('^');  // Microsoft News
+
+            // other ASCII characters for which RFC 2396 has explicitly disallowed use
+            // since 1998 and which were not later permitted by RFC 3986 in 2005.
+            LfDelim.add('<');  // HTML embedded in URL
+            LfDelim.add('>');  // HTML embedded in URL
+            LfDelim.add('`');  // Shell Script embedded in URL
+            LfDelim.add('{');  // JSON or Javascript embedded in URL
+            LfDelim.add('}');  // JSON or Javascript embedded in URL
+
+            // reset the tokenizer from anything the above did, then seek the LF character.
+            tok.reset(buf_);
+
+            if (tok.prefix(line, LfDelim) && tok.skip('\n')) {
+
+                Http1::Tokenizer rTok(line);
+
+                // strip terminating CR (if any)
+                SBuf nil;
+                (void)rTok.suffix(nil,CharacterSet::CR); // optional CR in terminator
+                line = rTok.remaining();
+
+                // strip terminating 'WSP HTTP-version' (if any)
+                if (rTok.suffix(nil,CharacterSet::DIGIT) && rTok.skipSuffix(Http1magic) && rTok.suffix(nil,WspDelim)) {
+                    hackExpectsMime_ = true; // client thinks its speaking HTTP, probably sent a mime block.
+                    uri_ = rTok.remaining();
+                } else
+                    uri_ = line; // no HTTP/1.x label found. Use the whole line.
+
+                if (uri_.isEmpty()) {
+                    debugs(33, warnOnError, "invalid request-line. missing URL");
+                    parseStatusCode = Http::scBadRequest;
+                    return -1;
+                }
+
+                debugs(33, warnOnError, "invalid request-line. treating as HTTP/0.9" << (hackExpectsMime_?" (with mime)":""));
+                msgProtocol_ = Http::ProtocolVersion(0,9);
+                parseStatusCode = Http::scOkay;
+                buf_ = tok.remaining(); // incremental parse checkpoint
+                return 1;
+
+            } else if (tok.atEnd()) {
+                debugs(74, 5, "Parser needs more data");
+                return 0;
+            }
+            // else, drop back to invalid request-line handling
+#endif
+            const SBuf t = tok.remaining();
+            debugs(33, warnOnError, "invalid request-line characters." << Raw("data", t.rawContent(), t.length()));
+            parseStatusCode = Http::scBadRequest;
+            return -1;
+        }
         debugs(74, 5, "Parser needs more data");
         return 0;
     }
@@ -356,7 +423,7 @@ Http::One::RequestParser::parseRequestFirstLine()
     }
 
     // If we got here this method has been called too many times
-    request_parse_status = Http::scInternalServerError;
+    parseStatusCode = Http::scInternalServerError;
     debugs(33, 5, "ERROR: Parser already processed request-line");
     return -1;
 }
@@ -405,35 +472,9 @@ Http::One::RequestParser::parse(const SBuf &aBuf)
     // stage 3: locate the mime header block
     if (parsingStage_ == HTTP_PARSE_MIME) {
         // HTTP/1.x request-line is valid and parsing completed.
-        if (msgProtocol_.major == 1) {
-            /* NOTE: HTTP/0.9 requests do not have a mime header block.
-             *       So the rest of the code will need to deal with '0'-byte headers
-             *       (ie, none, so don't try parsing em)
-             */
-            int64_t mimeHeaderBytes = 0;
-            // XXX: c_str() reallocates. performance regression.
-            if ((mimeHeaderBytes = headersEnd(buf_.c_str(), buf_.length())) == 0) {
-                if (buf_.length()+firstLineSize() >= Config.maxRequestHeaderSize) {
-                    debugs(33, 5, "Too large request");
-                    request_parse_status = Http::scRequestHeaderFieldsTooLarge;
-                    parsingStage_ = HTTP_PARSE_DONE;
-                } else
-                    debugs(33, 5, "Incomplete request, waiting for end of headers");
-                return false;
-            }
-            mimeHeaderBlock_ = buf_.consume(mimeHeaderBytes);
-            debugs(74, 5, "mime header (0-" << mimeHeaderBytes << ") {" << mimeHeaderBlock_ << "}");
-
-        } else
-            debugs(33, 3, "Missing HTTP/1.x identifier");
-
-        // NP: we do not do any further stages here yet so go straight to DONE
-        parsingStage_ = HTTP_PARSE_DONE;
-
-        // Squid could handle these headers, but admin does not want to
-        if (messageHeaderSize() >= Config.maxRequestHeaderSize) {
-            debugs(33, 5, "Too large request");
-            request_parse_status = Http::scRequestHeaderFieldsTooLarge;
+        if (!grabMimeBlock("Request", Config.maxRequestHeaderSize)) {
+            if (parseStatusCode == Http::scHeaderTooLarge)
+                parseStatusCode = Http::scRequestHeaderFieldsTooLarge;
             return false;
         }
     }
@@ -11,7 +11,6 @@
 
 #include "http/one/Parser.h"
 #include "http/RequestMethod.h"
-#include "http/StatusCode.h"
 
 namespace Parser {
 class Tokenizer;
@@ -45,18 +44,12 @@ class RequestParser : public Http1::Parser
     /// the request-line URI if this is a request message, or an empty string.
     const SBuf &requestUri() const {return uri_;}
 
-    /** HTTP status code to be used on the invalid-request error page.
-     * Http::scNone indicates incomplete parse,
-     * Http::scOkay indicates no error.
-     */
-    Http::StatusCode request_parse_status;
-
 private:
     void skipGarbageLines();
     int parseRequestFirstLine();
-    int parseMethodField(::Parser::Tokenizer &, const CharacterSet &);
-    int parseUriField(::Parser::Tokenizer &);
-    int parseHttpVersionField(::Parser::Tokenizer &);
+    int parseMethodField(Http1::Tokenizer &, const CharacterSet &);
+    int parseUriField(Http1::Tokenizer &);
+    int parseHttpVersionField(Http1::Tokenizer &);
 
     /// what request method has been found on the first line
     HttpRequestMethod method_;
@@ -0,0 +1,247 @@
+/*
+ * Copyright (C) 1996-2015 The Squid Software Foundation and contributors
+ *
+ * Squid software is distributed under GPLv2+ license and includes
+ * contributions from numerous individuals and organizations.
+ * Please see the COPYING and CONTRIBUTORS files for details.
+ */
+
+#include "squid.h"
+#include "Debug.h"
+#include "http/one/ResponseParser.h"
+#include "http/one/Tokenizer.h"
+#include "http/ProtocolVersion.h"
+#include "profiler/Profiler.h"
+#include "SquidConfig.h"
+
+const SBuf Http::One::ResponseParser::IcyMagic("ICY ");
+
+Http1::Parser::size_type
+Http::One::ResponseParser::firstLineSize() const
+{
+    Http1::Parser::size_type result = 0;
+
+    switch (msgProtocol_.protocol)
+    {
+    case AnyP::PROTO_HTTP:
+        result += Http1magic.length();
+        break;
+    case AnyP::PROTO_ICY:
+        result += IcyMagic.length();
+        break;
+    default: // no other protocols supported
+        return result;
+    }
+    // NP: the parser does not accept >2 DIGIT for version numbers
+    if (msgProtocol_.minor > 9)
+        result += 2;
+    else
+        result += 1;
+
+    result += 5; /* 5 octets in: SP status SP */
+    result += reasonPhrase_.length();
+    result += 2; /* CRLF terminator */
+    return result;
+}
+
+// NP: we found the protocol version and consumed it already.
+// just need the status code and reason phrase
+int
+Http::One::ResponseParser::parseResponseStatusAndReason(Http1::Tokenizer &tok, const CharacterSet &WspDelim)
+{
+    if (!completedStatus_) {
+        debugs(74, 9, "seek status-code in: " << tok.remaining().substr(0,10) << "...");
+        /* RFC 7230 section 3.1.2 - status code is 3 DIGIT octets.
+         * There is no limit on what those octets may be.
+         * 000 through 999 are all valid.
+         */
+        int64_t statusValue;
+        if (tok.int64(statusValue, 10, false, 3) && tok.skipOne(WspDelim)) {
+
+            debugs(74, 6, "found int64 status-code=" << statusValue);
+            statusCode_ = static_cast<Http::StatusCode>(statusValue);
+
+            buf_ = tok.remaining(); // resume checkpoint
+            completedStatus_ = true;
+
+        } else if (tok.atEnd()) {
+            debugs(74, 6, "Parser needs more data");
+            return 0; // need more to be sure we have it all
+
+        } else {
+            debugs(74, 6, "invalid status-line. invalid code.");
+            return -1; // invalid status, a single SP terminator required
+        }
+        // NOTE: any whitespace after the single SP is part of the reason phrase.
+    }
+
+    if (tok.atEnd())
+        return 0; // need more to be sure we have it all
+
+    /* RFC 7230 says we SHOULD ignore the reason phrase content
+     * but it has a definite valid vs invalid character set.
+     * We interpret the SHOULD as ignoring absence and syntax, but
+     * producing an error if it contains an invalid octet.
+     */
+
+    debugs(74, 9, "seek reason-phrase in: " << tok.remaining().substr(0,50) << "...");
+
+    // if we got here we are still looking for reason-phrase bytes
+    static const CharacterSet phraseChars = CharacterSet::WSP + CharacterSet::VCHAR + CharacterSet::OBSTEXT;
+    (void)tok.prefix(reasonPhrase_, phraseChars); // optional, no error if missing
+    if (skipLineTerminator(tok)) {
+        debugs(74, DBG_DATA, "parse remaining buf={length=" << tok.remaining().length() << ", data='" << tok.remaining() << "'}");
+        buf_ = tok.remaining(); // resume checkpoint
+        return 1;
+    }
+    reasonPhrase_.clear();
+
+    if (tok.atEnd())
+        return 0; // need more to be sure we have it all
+
+    debugs(74, 6, "invalid status-line. garbage in reason phrase.");
+    return -1;
+}
+
+/**
+ * Attempt to parse the method field out of an HTTP message status-line.
+ *
+ * Governed by:
+ *  RFC 1945 section 6.1
+ *  RFC 7230 section 2.6, 3.1 and 3.5
+ *
+ * Parsing state is stored between calls. The current implementation uses
+ * checkpoints after each successful status-line field.
+ * The return value tells you whether the parsing is completed or not.
+ *
+ * \retval -1  an error occurred.
+ * \retval  1  successful parse. statusCode_ and maybe reasonPhrase_ are filled and buffer consumed including first delimiter.
+ * \retval  0  more data is needed to complete the parse
+ */
+int
+Http::One::ResponseParser::parseResponseFirstLine()
+{
+    Http1::Tokenizer tok(buf_);
+
+    CharacterSet WspDelim = CharacterSet::SP; // strict parse only accepts SP
+
+    if (Config.onoff.relaxed_header_parser) {
+        // RFC 7230 section 3.5
+        // tolerant parser MAY accept any of SP, HTAB, VT (%x0B), FF (%x0C), or bare CR
+        // as whitespace between status-line fields
+        WspDelim += CharacterSet::HTAB
+                    + CharacterSet("VT,FF","\x0B\x0C")
+                    + CharacterSet::CR;
+    }
+
+    if (msgProtocol_.protocol != AnyP::PROTO_NONE) {
+        debugs(74, 6, "continue incremental parse for " << msgProtocol_);
+        debugs(74, DBG_DATA, "parse remaining buf={length=" << tok.remaining().length() << ", data='" << tok.remaining() << "'}");
+        // we already found the magic, but not the full line. keep going.
+        return parseResponseStatusAndReason(tok, WspDelim);
+
+    } else if (tok.skip(Http1magic)) {
+        debugs(74, 6, "found prefix magic " << Http1magic);
+        // HTTP Response status-line parse
+
+        // magic contains major version, still need to find minor DIGIT
+        int64_t verMinor;
+        if (tok.int64(verMinor, 10, false, 1) && tok.skipOne(WspDelim)) {
+            msgProtocol_.protocol = AnyP::PROTO_HTTP;
+            msgProtocol_.major = 1;
+            msgProtocol_.minor = static_cast<unsigned int>(verMinor);
+
+            debugs(74, 6, "found version=" << msgProtocol_);
+
+            debugs(74, DBG_DATA, "parse remaining buf={length=" << tok.remaining().length() << ", data='" << tok.remaining() << "'}");
+            buf_ = tok.remaining(); // resume checkpoint
+            return parseResponseStatusAndReason(tok, WspDelim);
+
+        } else if (tok.atEnd())
+            return 0; // need more to be sure we have it all
+        else
+            return -1; // invalid version or delimiter, a single SP terminator required
+
+    } else if (tok.skip(IcyMagic)) {
+        debugs(74, 6, "found prefix magic " << IcyMagic);
+        // ICY Response status-line parse (same as HTTP/1 after the magic version)
+        msgProtocol_.protocol = AnyP::PROTO_ICY;
+        // NP: ICY has no /major.minor details
+        debugs(74, DBG_DATA, "parse remaining buf={length=" << tok.remaining().length() << ", data='" << tok.remaining() << "'}");
+        buf_ = tok.remaining(); // resume checkpoint
+        return parseResponseStatusAndReason(tok, WspDelim);
+
+    } else if (buf_.length() > Http1magic.length() && buf_.length() > IcyMagic.length()) {
+        debugs(74, 2, "unknown/missing prefix magic. Interpreting as HTTP/0.9");
+        // found something that looks like an HTTP/0.9 response
+        // Gateway/Transform it into HTTP/1.1
+        msgProtocol_ = Http::ProtocolVersion(1,1);
+        // XXX: probably should use version 0.9 here and upgrade on output,
+        // but the old code did 1.1 transformation now.
+        statusCode_ = Http::scOkay;
+        static const SBuf gatewayPhrase("Gatewaying");
+        reasonPhrase_ = gatewayPhrase;
+        static const SBuf fakeHttpMimeBlock("X-Transformed-From: HTTP/0.9\r\n"
+                                            /* Server: visible_appname_string */
+                                            "Mime-Version: 1.0\r\n"
+                                            /* Date: squid_curtime */
+                                            "Expires: -1\r\n\r\n");
+        mimeHeaderBlock_ = fakeHttpMimeBlock;
+        parsingStage_ = HTTP_PARSE_DONE;
+        return 1; // no more parsing
+    }
+
+    return 0; // need more to parse anything.
+}
+
+bool
+Http::One::ResponseParser::parse(const SBuf &aBuf)
+{
+    buf_ = aBuf;
+    debugs(74, DBG_DATA, "Parse buf={length=" << aBuf.length() << ", data='" << aBuf << "'}");
+
+    // stage 1: locate the status-line
+    if (parsingStage_ == HTTP_PARSE_NONE) {
+        // RFC 7230 explicitly states whether garbage whitespace is to be handled
+        // at each point of the message framing boundaries.
+        // It omits mentioning garbage prior to HTTP Responses.
+        // Therefore, if we receive anything at all treat it as Response message.
+        if (!buf_.isEmpty())
+            parsingStage_ = HTTP_PARSE_FIRST;
+        else
+            return false;
+    }
+
+    // stage 2: parse the status-line
+    if (parsingStage_ == HTTP_PARSE_FIRST) {
+        PROF_start(HttpParserParseReplyLine);
+
+        const int retcode = parseResponseFirstLine();
+
+        // first-line (or a look-alike) found successfully.
+        if (retcode > 0)
+            parsingStage_ = HTTP_PARSE_MIME;
+        debugs(74, 5, "status-line: retval " << retcode);
+        debugs(74, 5, "status-line: proto " << msgProtocol_);
+        debugs(74, 5, "status-line: status-code " << statusCode_);
+        debugs(74, 5, "status-line: reason-phrase " << reasonPhrase_);
+        debugs(74, 5, "Parser: bytes processed=" << (aBuf.length()-buf_.length()));
+        PROF_stop(HttpParserParseReplyLine);
+
+        // syntax errors already
+        if (retcode < 0) {
+            parsingStage_ = HTTP_PARSE_DONE;
+            statusCode_ = Http::scInvalidHeader;
+            return false;
+        }
+    }
+
+    // stage 3: locate the mime header block
+    if (parsingStage_ == HTTP_PARSE_MIME) {
+        if (!grabMimeBlock("Response", Config.maxReplyHeaderSize))
+            return false;
+    }
+
+    return !needsMoreData();
+}
+
@@ -0,0 +1,66 @@
+/*
+ * Copyright (C) 1996-2015 The Squid Software Foundation and contributors
+ *
+ * Squid software is distributed under GPLv2+ license and includes
+ * contributions from numerous individuals and organizations.
+ * Please see the COPYING and CONTRIBUTORS files for details.
+ */
+
+#ifndef _SQUID_SRC_HTTP_ONE_RESPONSEPARSER_H
+#define _SQUID_SRC_HTTP_ONE_RESPONSEPARSER_H
+
+#include "http/one/Parser.h"
+#include "http/StatusCode.h"
+
+namespace Http {
+namespace One {
+
+/** HTTP/1.x  protocol response parser
+ *
+ * Also capable of parsing unexpected ICY responses and
+ * upgrading HTTP/0.9 syntax responses to HTTP/1.1
+ *
+ * Works on a raw character I/O buffer and tokenizes the content into
+ * the major CRLF delimited segments of an HTTP/1 respone message:
+ *
+ * \item status-line (version SP status SP reash-phrase)
+ * \item mime-header (set of RFC2616 syntax header fields)
+ */
+class ResponseParser : public Http1::Parser
+{
+public:
+    ResponseParser() : Parser(), completedStatus_(false), statusCode_(Http::scNone) {}
+    virtual ~ResponseParser() {}
+
+    /* Http::One::Parser API */
+    virtual void clear() {*this=ResponseParser();}
+    virtual Http1::Parser::size_type firstLineSize() const;
+    virtual bool parse(const SBuf &aBuf);
+
+    /* respone specific fields, read-only */
+    Http::StatusCode messageStatus() const { return statusCode_;}
+    SBuf reasonPhrase() const { return reasonPhrase_;}
+
+private:
+    int parseResponseFirstLine();
+    int parseResponseStatusAndReason(Http1::Tokenizer&, const CharacterSet &);
+
+    /// magic prefix for identifying ICY response messages
+    static const SBuf IcyMagic;
+
+    /// Whether we found the status code yet.
+    /// We cannot rely on status value because server may send "000".
+    bool completedStatus_;
+
+    /// HTTP/1 status-line status code
+    Http::StatusCode statusCode_;
+
+    /// HTTP/1 status-line reason phrase
+    SBuf reasonPhrase_;
+};
+
+} // namespace One
+} // namespace Http
+
+#endif /* _SQUID_SRC_HTTP_ONE_RESPONSEPARSER_H */
+
@@ -0,0 +1,206 @@
+/*
+ * Copyright (C) 1996-2015 The Squid Software Foundation and contributors
+ *
+ * Squid software is distributed under GPLv2+ license and includes
+ * contributions from numerous individuals and organizations.
+ * Please see the COPYING and CONTRIBUTORS files for details.
+ */
+
+#include "squid.h"
+#include "base/TextException.h"
+#include "Debug.h"
+#include "http/one/TeChunkedParser.h"
+#include "http/one/Tokenizer.h"
+#include "http/ProtocolVersion.h"
+#include "MemBuf.h"
+#include "Parsing.h"
+
+Http::One::TeChunkedParser::TeChunkedParser()
+{
+    // chunked encoding only exists in HTTP/1.1
+    Http1::Parser::msgProtocol_ = Http::ProtocolVersion(1,1);
+
+    clear();
+}
+
+void
+Http::One::TeChunkedParser::clear()
+{
+    parsingStage_ = Http1::HTTP_PARSE_NONE;
+    buf_.clear();
+    theChunkSize = theLeftBodySize = 0;
+    theOut = NULL;
+    useOriginBody = -1;
+}
+
+bool
+Http::One::TeChunkedParser::parse(const SBuf &aBuf)
+{
+    buf_ = aBuf; // sync buffers first so calls to remaining() work properly if nothing done.
+
+    if (buf_.isEmpty()) // nothing to do (yet)
+        return false;
+
+    debugs(74, DBG_DATA, "Parse buf={length=" << aBuf.length() << ", data='" << aBuf << "'}");
+
+    Must(!buf_.isEmpty() && theOut);
+
+    if (parsingStage_ == Http1::HTTP_PARSE_NONE)
+        parsingStage_ = Http1::HTTP_PARSE_CHUNK_SZ;
+
+    Http1::Tokenizer tok(buf_);
+
+    // loop for as many chunks as we can
+    // use do-while instead of while so that we can incrementally
+    // restart in the middle of a chunk/frame
+    do {
+
+        if (parsingStage_ == Http1::HTTP_PARSE_CHUNK_EXT && !parseChunkExtension(tok, theChunkSize))
+            return false;
+
+        if (parsingStage_ == Http1::HTTP_PARSE_CHUNK && !parseChunkBody(tok))
+            return false;
+
+        if (parsingStage_ == Http1::HTTP_PARSE_MIME && !grabMimeBlock("Trailers", 64*1024 /* 64KB max */))
+            return false;
+
+        // loop for as many chunks as we can
+    } while (parsingStage_ == Http1::HTTP_PARSE_CHUNK_SZ && parseChunkSize(tok));
+
+    return !needsMoreData() && !needsMoreSpace();
+}
+
+bool
+Http::One::TeChunkedParser::needsMoreSpace() const
+{
+    assert(theOut);
+    return parsingStage_ == Http1::HTTP_PARSE_CHUNK && !theOut->hasPotentialSpace();
+}
+
+/// RFC 7230 section 4.1 chunk-size
+bool
+Http::One::TeChunkedParser::parseChunkSize(Http1::Tokenizer &tok)
+{
+    Must(theChunkSize <= 0); // Should(), really
+
+    int64_t size = -1;
+    if (tok.int64(size, 16, false) && !tok.atEnd()) {
+        if (size < 0)
+            throw TexcHere("negative chunk size");
+
+        theChunkSize = theLeftBodySize = size;
+        debugs(94,7, "found chunk: " << theChunkSize);
+        buf_ = tok.remaining(); // parse checkpoint
+        parsingStage_ = Http1::HTTP_PARSE_CHUNK_EXT;
+        return true;
+
+    } else if (tok.atEnd()) {
+        return false; // need more data
+    }
+
+    // else error
+    throw TexcHere("corrupted chunk size");
+    return false; // should not be reachable
+}
+
+/**
+ * Parses a set of RFC 7230 section 4.1.1 chunk-ext
+ * http://tools.ietf.org/html/rfc7230#section-4.1.1
+ *
+ *   chunk-ext      = *( ";" chunk-ext-name [ "=" chunk-ext-val ] )
+ *   chunk-ext-name = token
+ *   chunk-ext-val  = token / quoted-string
+ *
+ * ICAP 'use-original-body=N' extension is supported.
+ */
+bool
+Http::One::TeChunkedParser::parseChunkExtension(Http1::Tokenizer &tok, bool skipKnown)
+{
+    SBuf ext;
+    SBuf value;
+    while (tok.skip(';') && tok.prefix(ext, CharacterSet::TCHAR)) {
+
+        // whole value part is optional. if no '=' expect next chunk-ext
+        if (tok.skip('=')) {
+
+            if (!skipKnown) {
+                if (ext.cmp("use-original-body",17) == 0 && tok.int64(useOriginBody, 10)) {
+                    debugs(94, 3, "Found chunk extension " << ext << "=" << useOriginBody);
+                    buf_ = tok.remaining(); // parse checkpoint
+                    continue;
+                }
+            }
+
+            debugs(94, 5, "skipping unknown chunk extension " << ext);
+
+            // unknown might have a value token or quoted-string
+            if (tok.quotedStringOrToken(value) && !tok.atEnd()) {
+                buf_ = tok.remaining(); // parse checkpoint
+                continue;
+            }
+
+            // otherwise need more data OR corrupt syntax
+            break;
+        }
+
+        if (!tok.atEnd())
+            buf_ = tok.remaining(); // parse checkpoint (unless there might be more token name)
+    }
+
+    if (tok.atEnd())
+        return false;
+
+    if (skipLineTerminator(tok)) {
+        buf_ = tok.remaining(); // checkpoint
+        // non-0 chunk means data, 0-size means optional Trailer follows
+        parsingStage_ = theChunkSize ? Http1::HTTP_PARSE_CHUNK : Http1::HTTP_PARSE_MIME;
+        return true;
+    }
+
+    throw TexcHere("corrupted chunk extension value");
+    return false;
+}
+
+bool
+Http::One::TeChunkedParser::parseChunkBody(Http1::Tokenizer &tok)
+{
+    Must(theLeftBodySize > 0); // Should, really
+
+    buf_ = tok.remaining(); // sync buffers before buf_ use
+
+    // TODO fix type mismatches and casting for these
+    const size_t availSize = min(theLeftBodySize, (uint64_t)buf_.length());
+    const size_t safeSize = min(availSize, (size_t)theOut->potentialSpaceSize());
+
+    theOut->append(buf_.rawContent(), safeSize);
+    buf_.consume(safeSize);
+    theLeftBodySize -= safeSize;
+
+    tok.reset(buf_); // sync buffers after consume()
+
+    if (theLeftBodySize == 0)
+        return parseChunkEnd(tok);
+    else
+        Must(needsMoreData() || needsMoreSpace());
+
+    return true;
+}
+
+bool
+Http::One::TeChunkedParser::parseChunkEnd(Http1::Tokenizer &tok)
+{
+    Must(theLeftBodySize == 0); // Should(), really
+
+    if (skipLineTerminator(tok)) {
+        buf_ = tok.remaining(); // parse checkpoint
+        theChunkSize = 0; // done with the current chunk
+        parsingStage_ = Http1::HTTP_PARSE_CHUNK_SZ;
+        return true;
+
+    } else if (!tok.atEnd()) {
+        throw TexcHere("found data between chunk end and CRLF");
+    }
+
+    return false;
+}
+
@@ -0,0 +1,65 @@
+/*
+ * Copyright (C) 1996-2015 The Squid Software Foundation and contributors
+ *
+ * Squid software is distributed under GPLv2+ license and includes
+ * contributions from numerous individuals and organizations.
+ * Please see the COPYING and CONTRIBUTORS files for details.
+ */
+
+#ifndef SQUID_SRC_HTTP_ONE_TeChunkedParser_H
+#define SQUID_SRC_HTTP_ONE_TeChunkedParser_H
+
+#include "http/one/Parser.h"
+
+class MemBuf;
+
+namespace Http
+{
+namespace One
+{
+
+/**
+ * An incremental parser for chunked transfer coding
+ * defined in RFC 7230 section 4.1.
+ * http://tools.ietf.org/html/rfc7230#section-4.1
+ *
+ * The parser shovels content bytes from the raw
+ * input buffer into the content output buffer, both caller-supplied.
+ * Ignores chunk extensions except for ICAP's ieof.
+ * Trailers are available via mimeHeader() if wanted.
+ */
+class TeChunkedParser : public Http1::Parser
+{
+public:
+    TeChunkedParser();
+    virtual ~TeChunkedParser() {theOut=NULL;/* we dont own this object */}
+
+    /// set the buffer to be used to store decoded chunk data
+    void setPayloadBuffer(MemBuf *parsedContent) {theOut = parsedContent;}
+
+    bool needsMoreSpace() const;
+
+    /* Http1::Parser API */
+    virtual void clear();
+    virtual bool parse(const SBuf &);
+    virtual Parser::size_type firstLineSize() const {return 0;} // has no meaning with multiple chunks
+
+private:
+    bool parseChunkSize(Http1::Tokenizer &tok);
+    bool parseChunkExtension(Http1::Tokenizer &tok, bool skipKnown);
+    bool parseChunkBody(Http1::Tokenizer &tok);
+    bool parseChunkEnd(Http1::Tokenizer &tok);
+
+    MemBuf *theOut;
+    uint64_t theChunkSize;
+    uint64_t theLeftBodySize;
+
+public:
+    int64_t useOriginBody;
+};
+
+} // namespace One
+} // namespace Http
+
+#endif /* SQUID_SRC_HTTP_ONE_TeChunkedParser_H */
+
@@ -0,0 +1,109 @@
+/*
+ * Copyright (C) 1996-2015 The Squid Software Foundation and contributors
+ *
+ * Squid software is distributed under GPLv2+ license and includes
+ * contributions from numerous individuals and organizations.
+ * Please see the COPYING and CONTRIBUTORS files for details.
+ */
+
+#include "squid.h"
+#include "Debug.h"
+#include "http/one/Tokenizer.h"
+
+bool
+Http::One::Tokenizer::quotedString(SBuf &returnedToken, const bool http1p0)
+{
+    checkpoint();
+
+    if (!skip('"'))
+        return false;
+
+    return qdText(returnedToken, http1p0);
+}
+
+bool
+Http::One::Tokenizer::quotedStringOrToken(SBuf &returnedToken, const bool http1p0)
+{
+    checkpoint();
+
+    if (!skip('"'))
+        return prefix(returnedToken, CharacterSet::TCHAR);
+
+    return qdText(returnedToken, http1p0);
+}
+
+bool
+Http::One::Tokenizer::qdText(SBuf &returnedToken, const bool http1p0)
+{
+    // the initial DQUOTE has been skipped by the caller
+
+    /*
+     * RFC 1945 - defines qdtext:
+     *   inclusive of LWS (which includes CR and LF)
+     *   exclusive of 0x80-0xFF
+     *   includes 0x5C ('\') as just a regular character
+     */
+    static const CharacterSet qdtext1p0 = CharacterSet("qdtext (HTTP/1.0)", 0x23, 0x7E) +
+                                          CharacterSet("", "!") +
+                                          CharacterSet::CR + CharacterSet::LF + CharacterSet::HTAB + CharacterSet::SP;
+    /*
+     * RFC 7230 - defines qdtext:
+     *   exclusive of CR and LF
+     *   inclusive of 0x80-0xFF
+     *   includes 0x5C ('\') but only when part of quoted-pair
+     */
+    static const CharacterSet qdtext1p1 = CharacterSet("qdtext (HTTP/1.1)", 0x23, 0x5B) +
+                                          CharacterSet("", "!") +
+                                          CharacterSet("", 0x5D, 0x7E) +
+                                          CharacterSet::HTAB + CharacterSet::SP +
+                                          CharacterSet::OBSTEXT;
+
+    // best we can do is a conditional reference since http1p0 value may change per-client
+    const CharacterSet &tokenChars = (http1p0 ? qdtext1p0 : qdtext1p1);
+
+    for (;;) {
+        SBuf::size_type prefixLen = buf().findFirstNotOf(tokenChars);
+        returnedToken.append(consume(prefixLen));
+
+        // HTTP/1.1 allows quoted-pair, HTTP/1.0 does not
+        if (!http1p0 && skip('\\')) {
+            /* RFC 7230 section 3.2.6
+             *
+             * The backslash octet ("\") can be used as a single-octet quoting
+             * mechanism within quoted-string and comment constructs.  Recipients
+             * that process the value of a quoted-string MUST handle a quoted-pair
+             * as if it were replaced by the octet following the backslash.
+             *
+             *   quoted-pair    = "\" ( HTAB / SP / VCHAR / obs-text )
+             */
+            static const CharacterSet qPairChars = CharacterSet::HTAB + CharacterSet::SP + CharacterSet::VCHAR + CharacterSet::OBSTEXT;
+            SBuf escaped;
+            if (!prefix(escaped, qPairChars, 1)) {
+                returnedToken.clear();
+                restoreLastCheckpoint();
+                return false;
+            }
+            returnedToken.append(escaped);
+            continue;
+
+        } else if (skip('"')) {
+            break; // done
+
+        } else if (atEnd()) {
+            // need more data
+            returnedToken.clear();
+            restoreLastCheckpoint();
+            return false;
+        }
+
+        // else, we have an error
+        debugs(24, 8, "invalid bytes for set " << tokenChars.name);
+        returnedToken.clear();
+        restoreLastCheckpoint();
+        return false;
+    }
+
+    // found the whole string
+    return true;
+}
+
@@ -0,0 +1,79 @@
+/*
+ * Copyright (C) 1996-2015 The Squid Software Foundation and contributors
+ *
+ * Squid software is distributed under GPLv2+ license and includes
+ * contributions from numerous individuals and organizations.
+ * Please see the COPYING and CONTRIBUTORS files for details.
+ */
+
+#ifndef SQUID_SRC_HTTP_ONE_TOKENIZER_H
+#define SQUID_SRC_HTTP_ONE_TOKENIZER_H
+
+#include "parser/Tokenizer.h"
+
+namespace Http {
+namespace One {
+
+/**
+ * Lexical processor extended to tokenize HTTP/1.x syntax.
+ *
+ * \see ::Parser::Tokenizer for more detail
+ */
+class Tokenizer : public ::Parser::Tokenizer
+{
+public:
+    Tokenizer(SBuf &s) : ::Parser::Tokenizer(s), savedStats_(0) {}
+
+    /**
+     * Attempt to parse a quoted-string lexical construct.
+     *
+     * Governed by:
+     *  - RFC 1945 section 2.1
+     *  "
+     *    A string of text is parsed as a single word if it is quoted using
+     *    double-quote marks.
+     *
+     *        quoted-string  = ( <"> *(qdtext) <"> )
+     *
+     *        qdtext         = <any CHAR except <"> and CTLs,
+     *                         but including LWS>
+     *
+     *    Single-character quoting using the backslash ("\") character is not
+     *    permitted in HTTP/1.0.
+     *  "
+     *
+     *  - RFC 7230 section 3.2.6
+     *  "
+     *    A string of text is parsed as a single value if it is quoted using
+     *    double-quote marks.
+     *
+     *    quoted-string  = DQUOTE *( qdtext / quoted-pair ) DQUOTE
+     *    qdtext         = HTAB / SP /%x21 / %x23-5B / %x5D-7E / obs-text
+     *    obs-text       = %x80-FF
+     *  "
+     *
+     * \param escaped HTTP/1.0 does not permit \-escaped characters
+     */
+    bool quotedString(SBuf &value, const bool http1p0 = false);
+
+    /**
+     * Attempt to parse a (token / quoted-string ) lexical construct.
+     */
+    bool quotedStringOrToken(SBuf &value, const bool http1p0 = false);
+
+private:
+    /// parse the internal component of a quote-string, and terminal DQUOTE
+    bool qdText(SBuf &value, const bool http1p0);
+
+    void checkpoint() { savedCheckpoint_ = buf(); savedStats_ = parsedSize(); }
+    void restoreLastCheckpoint() { undoParse(savedCheckpoint_, savedStats_); }
+
+    SBuf savedCheckpoint_;
+    SBuf::size_type savedStats_;
+};
+
+} // namespace One
+} // namespace Http
+
+#endif /* SQUID_SRC_HTTP_ONE_TOKENIZER_H */
+
@@ -14,12 +14,19 @@
 namespace Http {
 namespace One {
 
+class Tokenizer;
+
 class Parser;
 typedef RefCount<Http::One::Parser> ParserPointer;
 
+class TeChunkedParser;
+
 class RequestParser;
 typedef RefCount<Http::One::RequestParser> RequestParserPointer;
 
+class ResponseParser;
+typedef RefCount<Http::One::ResponseParser> ResponseParserPointer;
+
 } // namespace One
 } // namespace Http
 